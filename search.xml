<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Oracle案例--机器重启后数据库启动失败（ora-00205）</title>
    <url>/2009/03/03/oracle_troubleshoot_of_oracle_startup_failed_after_reboot_machine/</url>
    <content><![CDATA[<h1 id="dan-ban-zhong-qi-hou-shu-ju-ku-qi-dong-shi-bai">单板重启后数据库启动失败</h1>
<h2 id="biao-xiang">表象</h2>
<p>逻辑卷以及raw创建并绑定，且创建实例后数据库正常使用，单板重启后，启动数据库出错，报00205错误。</p>
<p>起先手动激活逻辑卷组，并将裸设备与逻辑卷绑定，然后启动数据库，数据库依然启动失败。</p>
<p>查看一下00205是何种错误：</p>
<pre><code class="language-shell">oerr ora 00205
00205, 00000, "error in identifying control file, check alert log for more info"
// *Cause:  The system could not find a control file of the specified name and
//         size.
// *Action: Check that ALL control files are online and that they are the same
//         files that the system created at cold start time.
</code></pre>
<p>去查看alert日志信息</p>
<pre><code class="language-shell">&lt;msg time='2009-03-03T13:53:07.240+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='' pid='6789'&gt;
 &lt;txt&gt;ORA-00210: ???????????
ORA-00202: ????: &amp;apos;&amp;apos;/dev/raw/raw15&amp;apos;&amp;apos;
ORA-27041: ??????
Linux-x86_64 Error: 13: Permission denied
Additional information: 2
ORA-00210: ???????????
ORA-00202: ????: &amp;apos;&amp;apos;/dev/raw/raw14&amp;apos;&amp;apos;
ORA-27041: ??????
Linux-x86_64 Error: 13: Permission denied
Additional information: 2
ORA-00210: ???????????
ORA-00202: ????: &amp;apos;&amp;apos;/dev/raw/raw13&amp;apos;&amp;apos;
ORA-27041: ??????
Linux-x86_64 Error: 13: Permission denied
Additional information: 2
 &lt;/txt&gt;
&lt;/msg&gt;
</code></pre>
<p>根据日志，发现raw13、raw14和raw15三个裸设备出现权限限制。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>（1）更改逻辑卷组激活方式，修改/etc/init.d/boot.lvm文件。</p>
<pre><code class="language-shell">#vi /etc/init.d/boot.lvm
/sbin/vgchange -a y $LVM_VGS_ACTIVATED_ON_BOOT
</code></pre>
<p>（2）单板重启后，检测裸设备是否与逻辑卷自动绑定；</p>
<p>（3）如果绑定，oracle用户启动数据库便可成功。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--登录RAC间歇性成功</title>
    <url>/2009/03/14/oracle_troubleshoot_access_rac_login_intermittently_successful/</url>
    <content><![CDATA[<h2 id="biao-xiang">表象</h2>
<p>用户登录RAC集群数据库时，时而登录成功，时而登录失败，且TNSNAMES.ORA文件无问题。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>修改spfile文件中remote_listener 的VALUE值为空。</p>
<p>sys用户登录，修改spfile文件中remote_listener 的VALUE值为空。</p>
<pre><code class="language-shell">node1:oracle:ora11g &gt; sqlplus sys/oracle@ora11g as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on Thu May 14 17:23:06 2009

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, Real Application Clusters, OLAP, Data Mining
and Real Application Testing options

SQL&gt; show parameter remote

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
remote_dependencies_mode             string      TIMESTAMP
remote_listener                      string      //如果remote_listener的VALUE值不为空，修改值为空。
remote_login_passwordfile            string      EXCLUSIVE
remote_os_authent                    boolean     FALSE
remote_os_roles                      boolean     FALSE
result_cache_remote_expiration       integer     0
SQL&gt; alter system set remote_listener ='' scope=spfile;

系统已更改。
</code></pre>
<p>修改后重启RAC数据库实例后生效。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle升级碰到的问题</title>
    <url>/2009/03/16/oracle_upgrade_issue/</url>
    <content><![CDATA[<h1 id="xian-xiang">现象</h1>
<p>Oracle11g 11.1.0.6.0安装小补丁版本失败,安装小补丁：p6928169_111060_Linux-x86-64.zip</p>
<pre><code class="language-shell">opyright (c) 2007, Oracle Corporation.  All rights reserved.


Oracle Home       : /opt/oracle/app/product/11.1.0/db_1
Central Inventory : /opt/oraInventory
   from           : /etc/oraInst.loc
OPatch version    : 11.1.0.6.0
OUI version       : 11.1.0.6.0
OUI location      : /opt/oracle/app/product/11.1.0/db_1/oui
Log file location : /opt/oracle/app/product/11.1.0/db_1/cfgtoollogs/opatch/opatch2009-03-06_14-16-49PM.log

ApplySession applying interim patch '6928169' to OH '/opt/oracle/app/product/11.1.0/db_1'

Running prerequisite checks...
Prerequisite check "CheckActiveFilesAndExecutables" failed.
The details are:


Following executables are active :
/opt/oracle/app/product/11.1.0/db_1/bin/oracle
ApplySession failed during prerequisite checks: Prerequisite check "CheckActiveFilesAndExecutables" failed.
System intact, OPatch will not attempt to restore the system

OPatch failed with error code 74
oracle@expsmgw:/opt/oraInventory/6928169&gt;
</code></pre>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>当时没解决，只有安装了大补丁才解决问题。不过不建议这也操作，会比较麻烦，一旦升级出错，恢复数据库有难度，除非升级之前已经备份数据库。</p>
<p>正确安装信息显示如下：</p>
<pre><code class="language-shell">oracle@MMSGDS:/opt/oraInventory/6928169&gt; export OBJECT_MODE=32_64
oracle@MMSGDS:/opt/oraInventory/6928169&gt; /opt/oracle/product/11g/db_1/OPatch/opatch apply
Invoking OPatch 11.1.0.6.0

Oracle Interim Patch Installer version 11.1.0.6.0
Copyright (c) 2007, Oracle Corporation.  All rights reserved.


Oracle Home       : /opt/oracle/product/11g/db_1
Central Inventory : /opt/oraInventory
   from           : /etc/oraInst.loc
OPatch version    : 11.1.0.6.0
OUI version       : 11.1.0.6.0
OUI location      : /opt/oracle/product/11g/db_1/oui
Log file location : /opt/oracle/product/11g/db_1/cfgtoollogs/opatch/opatch2009-04-13_15-50-35PM.log

ApplySession applying interim patch '6928169' to OH '/opt/oracle/product/11g/db_1'

Running prerequisite checks...

OPatch detected non-cluster Oracle Home from the inventory and will patch the local system only.


Please shutdown Oracle instances running out of this ORACLE_HOME on the local system.
(Oracle Home = '/opt/oracle/product/11g/db_1')


Is the local system ready for patching? [y|n]
y
User Responded with: Y
Backing up files and inventory (not for auto-rollback) for the Oracle Home
Backing up files affected by the patch '6928169' for restore. This might take a while...
Backing up files affected by the patch '6928169' for rollback. This might take a while...

Patching component oracle.rdbms, 11.1.0.6.0...
Updating archive file "/opt/oracle/product/11g/db_1/lib/libserver11.a"  with "lib/libserver11.a/jska.o"
Updating archive file "/opt/oracle/product/11g/db_1/lib/libserver11.a"  with "lib/libserver11.a/jskc.o"
Running make for target ioracle
ApplySession adding interim patch '6928169' to inventory

Verifying the update...
Inventory check OK: Patch ID 6928169 is registered in Oracle Home inventory with proper meta-data.
Files check OK: Files from Patch ID 6928169 are present in Oracle Home.

The local system has been patched and can be restarted.


OPatch succeeded.
oracle@MMSGDS:/opt/oraInventory/6928169&gt;
</code></pre>
<h1 id="ora-01092-oracle-shi-li-zhong-zhi-qiang-zhi-duan-kai-lian-jie-jie-jue-fang-an">ORA-01092  ORACLE 实例终止,强制断开连接 解决方案</h1>
<h2 id="biao-xiang">表象</h2>
<pre><code class="language-shell">SQL&gt; startup 
ORACLE 例程已经启动。 

Total System Global Area  109051904 bytes 
Fixed Size                  1295272 bytes 
Variable Size              92277848 bytes 
Database Buffers            8388608 bytes 
Redo Buffers                7090176 bytes 
数据库装载完毕。 
ORA-01092: ORACLE 实例终止。强制断开连接
</code></pre>
<h2 id="fen-xi-bu-zou">分析步骤</h2>
<h3 id="alert-ri-zhi-xin-xi-pian-duan">alert日志信息片段</h3>
<pre><code class="language-shell">&lt;txt&gt;Errors in file /home/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_ora_438512.trc:
ORA-00704: 引导程序进程失败
ORA-39700: 必须用 UPGRADE 选项打开数据库
 &lt;/txt&gt;
</code></pre>
<h3 id="cha-kan-cuo-wu-ma-xin-xi">查看错误码信息</h3>
<pre><code class="language-shell">% oerr ora 01092
01092, 00000, "ORACLE instance terminated. Disconnection forced"
// *Cause:  The instance this process was connected to was terminated
//          abnormally, probably via a shutdown abort. This process
//          was forced to disconnect from the instance.
// *Action: Examine the alert log for more details. When the instance has been 
//          restarted, retry action.
%

% oerr ora 39700
39700, 00000, "database must be opened with UPGRADE option"
// *Cause:  A normal database open was attempted, but the database has not 
//          been upgraded to the current server version.
// *Action: Use the UPGRADE option when opening the database to run 
//          catupgrd.sql (for database upgrade), or to run catalog.sql 
//          and catproc.sql (after initial database creation).
</code></pre>
<h1 id="yuan-yin">原因</h1>
<p>Oracle数据库升级后，数据字典没有升级，或者数据字典升级失败</p>
<h1 id="jie-jue-fang-fa-1">解决方法</h1>
<p>oracle dba用户执行catupgrd.sql、cataproc.sql和catlog.sql</p>
<p>1、以startup upgrade打开数据库</p>
<p>2、以sysdba运行‘升级数据字典’脚本和‘创建数据字典’脚本</p>
<p>product/11g/rdbms/admin/catupgrd.sql 和 product/11g/rdbms/admin/catalog.sql和catproc.sql</p>
<p>具体的需要根据trace日志中的提示信息去执行哪个sql文件。</p>
<p>例如：</p>
<pre><code class="language-shell">/opt/oracle/product/11g/rdbms/admin/catupgrd.sql

cat /opt/oracle/product/11g/rdbms/admin/catupgrd.sql | sqlplus / as sysdba
</code></pre>
<p>如果还不行，再去刷一个catproc.sql</p>
<pre><code class="language-shell">cat /opt/oracle/product/11g/rdbms/admin/catproc.sql | sqlplus / as sysdba
</code></pre>
<p>如果还不行，再去刷一个catlog.sql</p>
<pre><code class="language-shell"> cat /opt/oracle/product/11g/rdbms/admin/catlog.sql | sqlplus / as sysdba
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle审计功能简介</title>
    <url>/2009/04/08/oracle_audit/</url>
    <content><![CDATA[<h1 id="guan-yu-shen-ji">关于审计</h1>
<p>审计（Audit)，用于监视用户所执行的数据库操作，并且Oracle会将审计跟踪结果存放到OS文件（默认位置为$ORACLE_BASE/admin /$ORACLE_SID/adump/）或数据库（存储在system表空间中的SYS.AUD$表中，可通过视图dba_audit_trail查 看）中。Oracle11g默认情况下审计是开启的。</p>
<p>不管你是否打开数据库的审计功能，以下这些操作系统会强制记录：用管理员权限连接Instance；启动数据库；关闭数据库。</p>
<h1 id="he-shen-ji-xiang-guan-de-liang-ge-zhu-yao-can-shu">和审计相关的两个主要参数</h1>
<h2 id="1-audit-sys-operations">1、Audit_sys_operations</h2>
<pre><code class="language-shell">SQL&gt; show parameter Audit_sys_operations

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
audit_sys_operations                 boolean     FALSE
SQL&gt;  
</code></pre>
<p>默认为false，当设置为true时，所有sys用户（包括以sysdba,sysoper身份登录的用户）的操作都会被记录。audit trail不会写在aud$表中，这个很好理解，如果数据库还未启动aud$不可用，那么像conn /as sysdba这样的连接信息，只能记录在其它地方。如果是windows平台，audti trail会记录在windows的事件管理中，如果是linux/unix平台则会记录在audit_file_dest参数指定的文件中。audit_file_dest参数实际是个路径信息：</p>
<pre><code class="language-shell">SQL&gt; show parameter audit_file_dest

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
audit_file_dest                      string      /opt/oracle/admin/mmsgdb/adump
SQL&gt;
</code></pre>
<h2 id="2-audit-trail">2、Audit_trail</h2>
<p>None：不做审计；<br>
DB：将audit trail 记录在数据库的审计相关表中，如aud$，审计的结果只有连接信息；<br>
DB,Extended：这样审计结果里面除了连接信息还包含了当时执行的具体语句；<br>
OS：将audit trail 记录在操作系统文件中，文件名由audit_file_dest参数指定；<br>
XML：自oracle 10g里新增的。</p>
<p>注：这两个参数是static参数，需要重新启动数据库才能生效。</p>
<h1 id="shen-ji-ji-bie">审计级别</h1>
<p>当开启审计功能后，可在三个级别对数据库进行审计：Statement(语句)、Privilege（权限）、object（对象）。</p>
<h2 id="statement">Statement</h2>
<p>按语句来审计，比如audit table 会审计数据库中所有的create table,drop table,truncate table语句，alter session by mmsg会审计mmsg用户所有的数据库连接。</p>
<h2 id="privilege">Privilege</h2>
<p>按权限来审计，当用户使用了该权限则被审计，如执行grant select any table to mmsg，当执行了audit select any table语句后，当用户mmsg 访问了用户wyz的表时（如select * from wyz.table_name）会用到select any table权限，故会被审计。</p>
<p>注:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>用户是自己表的所有者，所以用户访问自己的表不会被审计。</p>
</li>
</ul>
<h2 id="object">Object</h2>
<p>按对象审计，只审计on关键字指定对象的相关操作，如aduit alter,delete,drop,insert on mmsg.table by scott; 这里会对mmsg用户的table表进行审计，但同时使用了by子句，所以只会对scott用户发起的操作进行审计。</p>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Oracle没有提供对schema中所有对象的审计功能，只能一个一个对象审计，对于后面创建的对象，Oracle则提供on default子句来实现自动审计，比如执行audit drop on default by access;后，对于随后创建的对象的drop操作都会审计。但这个default会对之后创建的所有数据库对象有效，似乎没办法指定只对某个用户创建 的对象有效，想比 trigger可以对schema的DDL进行“审计”，这个功能稍显不足。</p>
</li>
</ul>
<h1 id="shen-ji-de-yi-xie-qi-ta-xuan-xiang">审计的一些其他选项</h1>
<p>by access / by session：<br>
by access 每一个被审计的操作都会生成一条audit trail。<br>
by session 一个会话里面同类型的操作只会生成一条audit trail，默认为by session。</p>
<p>whenever [not] successful：<br>
whenever successful 操作成功(dba_audit_trail中returncode字段为0) 才审计,<br>
whenever not successful 反之。省略该子句的话，不管操作成功与否都会审计。</p>
<h1 id="he-shen-ji-xiang-guan-de-shi-tu">和审计相关的视图</h1>
<h2 id="dba-audit-trail">dba_audit_trail</h2>
<p>保存所有的audit trail，实际上它只是一个基于aud$的视图。其它的视图 dba_audit_session,dba_audit_object,dba_audit_statement都只是dba_audit_trail 的一个子集。</p>
<h2 id="dba-stmt-audit-opts">dba_stmt_audit_opts</h2>
<p>可以用来查看statement审计级别的audit options，即数据库设置过哪些statement级别的审计。dba_obj_audit_opts,dba_priv_audit_opts视图功能与之类似.</p>
<h2 id="all-def-audit-opts">all_def_audit_opts</h2>
<p>用来查看数据库用on default子句设置了哪些默认对象审计。</p>
<h1 id="qu-xiao-shen-ji">取消审计</h1>
<p>将对应审计语句的audit改为noaudit即可，如audit session whenever successful对应的取消审计语句为noaudit session whenever successful;</p>
<h1 id="shen-ji-neng-gao-su-wo-men-shi-yao">审计能告诉我们什么</h1>
<p>Oracle 数据库审计以一种非常详细的级别捕获用户行为，它可以消除手动的、基于触发器的审计。</p>
<p>假定用户 Joe 具有更新那张表的权限，并按如下所示的方式更新了表中的一行数据：</p>
<pre><code class="language-shell">update SCOTT.EMP set salary = 12000 where empno = 123456;
</code></pre>
<p>如何在数据库中跟踪这种行为呢？在 Oracle 9i 数据库及其较低版本中，审计只能捕获“谁”执行此操作，而不能捕获执行了“什么”内容。例如，它让您知道 Joe 更新了 SCOTT 所有的表EMP，但它不会显示他更新了该表中员工号为 123456 的薪水列。它不会显示更改前的薪水列的值。要捕获如此详细的更改，你将不得不编写你自己的触发器来捕获更改前的值，或使用 LogMiner 将它们从存档日志中检索出来。</p>
<p>细粒度审计(FGA) ，是在 Oracle 9i 中引入的，能够记录 SCN 号和行级的更改以重建旧的数据，但是它们只能用于 select 语句，而不能用于 DML（Data Manipulation Language，数据操纵语言命令） ，如 update 、insert 和delete 语句。因此，对于 Oracle 数据库 10g 之前的版本，使用触发器虽然对于以行级跟踪用户初始的更改是没有吸引力的选择，但它也是唯一可靠的方法。</p>
<h1 id="ju-li-xiang-jie">举例详解</h1>
<h2 id="zhun-bei-gong-zuo">准备工作</h2>
<pre><code class="language-shell">SQL&gt; show parameter audit

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
audit_file_dest                      string      /opt/oracle/admin/mmsgdb/adump
audit_sys_operations                 boolean     FALSE
audit_syslog_level                   string
audit_trail                          string      DB
SQL&gt; show parameter spfile

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
spfile                               string      /opt/oracle/product/11g/dbs/sp
                                                 filemmsgdb.ora
SQL&gt; alter system set audit_sys_operations=TRUE scope=spfile;

系统已更改。

SQL&gt; alter system set audit_trail=db,extended scope=spfile;

系统已更改。

SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。


SQL&gt; startup force
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             620759568 bytes
Database Buffers          973078528 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt; show parameter audit

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
audit_file_dest                      string      /opt/oracle/admin/mmsgdb/adump
audit_sys_operations                 boolean     TRUE
audit_syslog_level                   string
audit_trail                          string      DB, EXTENDED
SQL&gt;
</code></pre>
<h2 id="kai-shi-shen-ji">开始审计</h2>
<pre><code class="language-shell">SQL&gt; create table wyz_test as select * from mmsg.vpncorp_300;

表已创建。

SQL&gt;

SQL&gt; audit all on wyz_test;

审计已成功。

SQL&gt; select * from wyz_test;

SHORTNUMBE MEMBERID              A
---------- --------------------- -
66666      13810243003           0
66101      13810243001           1
66102      13810243002           0

SQL&gt; insert into wyz_test(SHORTNUMBER,MEMBERID,ADMINFLAG) values (88888,13951775214,0);

已创建 1 行。
SQL&gt; delete from  wyz_test;

已删除4行。

SQL&gt; commit;

提交完成。

SQL&gt;select OS_USERNAME,username,USERHOST,TERMINAL,TIMESTAMP,OWNER,obj_name,ACTION_NAME,sessionid,os_process,sql_text from dba_audit_trail;

sql&gt; audit select table by u_test by access;
</code></pre>
<p>如果在命令后面添加by user则只对user的操作进行审计,如果省去by用户,则对系统中所有的用户进行审计(不包含sys用户).</p>
<h1 id="che-xiao-shen-ji">撤销审计</h1>
<pre><code class="language-shell">SQL&gt; noaudit all on wyz_test;
审计未成功。
</code></pre>
<h1 id="guan-bi-shu-ju-ku-shen-ji-gong-neng">关闭数据库审计功能</h1>
<p>执行此任务可以关闭Oracle的审计功能。</p>
<p>在Oracle11g中，创建数据库时默认会打开审计功能，默认的audit会记录session登录数据库的信息、数据库关闭/启动和用户授权等信息。有可能大量审计记录将写满系统表空间，导致数据库异常。</p>
<h2 id="1-deng-lu-shu-ju-ku">(1)登录数据库</h2>
<p>以oracle用户登录，连接数据库。</p>
<pre><code class="language-shell">$ sqlplus "/ as sysdba"
</code></pre>
<h2 id="2-can-shu-jian-ce">(2)参数检测</h2>
<p>检查是否进行审计。</p>
<pre><code class="language-shell">SQL&gt; show parameter audit_trail
NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
audit_trail                          string      DB
</code></pre>
<p>若audit_trail的值为DB表示进行审计，并将审计记录存储在数据库中，默认记录在sys.aud$表中。详细的审计记录信息可以查看DBA_AUDIT_TRAIL和DBA_COMMON_AUDIT_TRAIL这两个数据字典视图。</p>
<pre><code class="language-shell">SQL&gt; select action_name, count(*) from dba_audit_trail group by action_name;
ACTION_NAME                    COUNT(*)
---------------------------- ----------
LOGOFF                             2137
LOGON                              1839
CREATE ROLE                           1
ALTER USER                            1
SET ROLE                             16
SYSTEM GRANT                         24
CREATE USER                           9
ALTER DATABASE                        6
</code></pre>
<h2 id="3-xiu-gai-can-shu">(3)修改参数</h2>
<p>从表中可以看出LOGOFF记录了数据库关闭的2137条相关记录。</p>
<pre><code class="language-shell">SQL&gt; truncate table sys.aud$;
SQL&gt; alter system set audit_trail=none scope=spfile;
重新启动数据库。
SQL&gt; shutdown immediate
SQL&gt; startup
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--删除正在运行数据库的DBF文件导致数据库启动异常（ORA-01157，ORA-01110）</title>
    <url>/2009/06/19/oracle_troubleshoot_of_delete_dbf_in_running_status/</url>
    <content><![CDATA[<h1 id="shan-chu-dbf-dao-zhi-shi-li-qi-dong-shi-bai">删除DBF导致实例启动失败</h1>
<h2 id="biao-xiang">表象</h2>
<p>未通过正确渠道、直接删除了数据库正在使用的数据文件，导致数据库启动实例时出错。</p>
<pre><code class="language-shell">SQL&gt; startup
ORACLE instance started.
Total System Global Area  320309728 bytes
Fixed Size                   731616 bytes
Variable Size             285212672 bytes
Database Buffers           33554432 bytes
Redo Buffers                 811008 bytes
Database mounted.
ORA-01157: cannot identify/lock data file 14 - see DBWR trace file
ORA-01110: data file 14: '/opt/oracle/oradata/mmsgdb/mmsgdata01'
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>脱机相关数据文件后，重新启动数据库。具体步骤如下：</p>
<h3 id="jiang-gai-shu-ju-wen-jian-tuo-ji">将该数据文件脱机</h3>
<pre><code class="language-shell">SQL&gt;alter database datafile '/opt/oracle/oradata/mmsgdb/mmsgdata01' offline drop;
</code></pre>
<h3 id="guan-bi-shu-ju-ku-hou-zhong-xin-qi-dong-ze-hui-fu-zheng-chang">关闭数据库后重新启动则恢复正常</h3>
<p>drop相应的Tablespace释放资源</p>
<pre><code class="language-shell">SQL&gt;drop tablespace MMSG including contents and datafiles;
</code></pre>
<p>其中MMSG是此数据库数据文件mmsgdata01对应的表空间名称。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--应用用户登录数据库报没权限或找不到LIB库文件</title>
    <url>/2009/11/05/oracle_troubleshoot_account_permission_denied/</url>
    <content><![CDATA[<h1 id="fei-oracle-zhong-duan-yong-hu-telnet-qing-kuang-xia-ying-yong-yong-hu-deng-lu-shu-ju-ku-bao-mei-quan-xian-huo-zhao-bu-dao-lib-ku-wen-jian">非oracle终端用户telnet情况下，应用用户登录数据库报没权限或找不到LIB库文件</h1>
<h2 id="biao-xiang">表象</h2>
<p>非oracle用户telnet登录终端，如mmsg终端用户登录，执行sqlplus命令查看应用数据库信息，报没权限。</p>
<pre><code class="language-shell">30 mmsg [mmsg] :/home/mmsg&gt;p

===========华为 infoX IAG 系统运行状态 2009年11月05日 19:51:08=================
系统安装位置：/home/mmsg/mms_home。
监控进程未运行。

=================================本机IP地址列表=================================
10.164.74.222       127.0.0.1           192.164.100.222     
[2009-11-05 19:51:08.052] 数据库错误:libclntsh.so: cannot open shared object file: No such file or directory

DBMS API Library 'libclntsh.so' loading fails
This library is a part of DBMS client installation, not SQLAPI++
Make sure DBMS client is installed and
this required library is available for dynamic loading

Linux/Unix/UnixWare:
1) The directories in the user's LD_LIBRARY_PATH environment variable
2) The list of libraries cached in /etc/ld.so.cache
3) /usr/lib, followed by /lib
 dbname:"mmsgdb", dbuser:"mmsg"
31 mmsg [mmsg] :/home/mmsg&gt;cd ${ORACLE_HOME}/lib32
/opt/oracle/product/11g/lib32: 权限不够.
</code></pre>
<h2 id="yuan-yin">原因</h2>
<p>非oracle终端用户telnet情况下，该终端用户没权限访问数据库。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>将当前telnet终端用户加入oinstall组中：</p>
<p>（1）usermod -G oinstall mmsg</p>
<p>（2）当前用户退出终端，重新登录就OK啦！</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--找不到INITSID.ORA文件解决方法（ORA-01078）</title>
    <url>/2009/11/09/oracle_troubleshoot_can_not_find_file_of_initsid.ora/</url>
    <content><![CDATA[<h1 id="ora-01078-zhao-bu-dao-initsid-ora-wen-jian-jie-jue-fang-fa">ORA-01078 找不到INITSID.ORA文件解决方法</h1>
<h2 id="biao-xiang">表象</h2>
<pre><code class="language-shell">node1:oracle:mmsgdb &gt; sqlplus '/as sysdba'
SQL*Plus: Release 11.1.0.7.0 - Production on 星期一 11月 9 11:25:48 2009
Copyright (c) 1982, 2008, Oracle.  All rights reserved.
已连接到空闲例程。
SQL&gt; startup mount
ORA-01078: failure in processing system parameters
LRM-00109: ???????????????? '/opt/oracle/product/11g/dbs/initmmsgdb.ora'
SQL&gt; startup force
ORA-01078: failure in processing system parameters
LRM-00109: ???????????????? '/opt/oracle/product/11g/dbs/initmmsgdb.ora'
SQL&gt; exit
已断开连接
</code></pre>
<h2 id="yuan-yin">原因</h2>
<pre><code class="language-shell">Failure during processing of INIT.ORA parameters during system startup.
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<h3 id="fang-fa-yi">方法一</h3>
<p>拷贝init.ora.9262009101410文件到指定目录</p>
<p>步骤：</p>
<p>（1） 进入$ORACLE_BASE/admin/mmsgdb/pfile，检查文件 init.ora.xxxxxx 是否存在（如：init.ora.9262009101410），存在，执行步骤（2）；</p>
<p>（2） 拷贝文件init.ora.9262009101410到/opt/oracle/product/11g/dbs/目录下 （cp init.ora.9262009101410 /opt/oracle/product/11g/dbs/）;</p>
<p>（3）更改init.ora.9262009101410文件名为需要的init文件名（mv init.ora.9262009101410 initmmsgdb.ora）;</p>
<p>（4） 启动数据库实例</p>
<pre><code class="language-shell">sqlplus '/as sysdba'  
startup
</code></pre>
<h3 id="fang-fa-er">方法二</h3>
<p>没有init文件，就去创建这个文件。</p>
<p>Oracle最后检查的文件为initmmsgdb.ora,让我们创建这个文件,然后数据库实例即可创建:</p>
<pre><code class="language-shell">SQL&gt; ! echo "db_name=mmsgdb" &gt; /opt/oracle/product/11g/dbs/initmmsgdb.ora
SQL&gt; startup nomount;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle账号被锁--ORA-28000</title>
    <url>/2009/11/18/oracle_account_lock/</url>
    <content><![CDATA[<h1 id="biao-xiang">表象</h1>
<p>Oracle数据库帐号被锁, oralce报ORA-28000错误。</p>
<h1 id="yuan-yin">原因</h1>
<p>账户被锁：</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; oerr ora 28000
28000, 00000, "the account is locked"
// *Cause:   The user has entered wrong password consequently for maximum
//           number of times specified by the user's profile parameter
//           FAILED_LOGIN_ATTEMPTS, or the DBA has locked the account
// *Action:  Wait for PASSWORD_LOCK_TIME or contact DBA
</code></pre>
<p>账号被锁主要原因：</p>
<pre><code class="language-shell">SQL&gt; show parameter sec_max_failed_login_attempts

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
sec_max_failed_login_attempts        integer     10
SQL&gt;
</code></pre>
<p>oracle系统参数sec_max_failed_login_attempts默认值为10，即连续输入用户口令10次均不正确后，数据库自动锁住当前用户，用户一旦锁住，不会自动解锁，需要dba权限用户手工干预（关闭该功能，详见本文oralce SQL篇之账号）。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>Oracle系统用户登录数据库，对用户执行解锁操作。</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; sqlplus '/as sysdba'

SQL*Plus: Release 11.1.0.7.0 - Production on 星期三 11月 18 19:12:47 2009

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options 
SQL&gt; alter user user_name account unlock;
User altered.
SQL&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 回收站介绍</title>
    <url>/2009/11/19/oracle_recyclebin/</url>
    <content><![CDATA[<h1 id="hui-shou-zhan-recycle-bin-jie-shao">回收站(recycle bin)介绍</h1>
<p>实际上，Recycle Bin只是一个保存被drop的对象的一个数据字典表。所以，可以通过如下语句查询回收站中的信息：</p>
<pre><code class="language-shell">node1:oracle:mmsgdb &gt; sqlplus /nolog 

SQL*Plus: Release 11.1.0.7.0 - Production on 星期四 11月 19 10:34:34 2009

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

SQL&gt; conn wyz/wyz
已连接。
SQL&gt; select * from recyclebin;

OBJECT_NAME                    ORIGINAL_NAME                    OPERATION
------------------------------ -------------------------------- ---------
TYPE                      TS_NAME                        CREATETIME
------------------------- ------------------------------ -------------------
DROPTIME               DROPSCN PARTITION_NAME                   CAN CAN
------------------- ---------- -------------------------------- --- ---
   RELATED BASE_OBJECT PURGE_OBJECT      SPACE
---------- ----------- ------------ ----------
BIN$eIz0mM1Ef7DgQKjA3GRWvg==$0 VPNCORP_300                      DROP
TABLE                     WYZ                            2009-11-04:11:41:34
2009-11-17:15:20:06   10198071                                  YES YES
     46354       46354        46354          8

已选择708行。

SQL&gt;
</code></pre>
<p>除非拥有sysdba权限，每个用户只能看到属于自己的对象。所以，对于用户来说，好像每个人都拥有自己的回收站。即使用户有删除其他schema对象的权限，也只能在recyclebin中看到属于自己的对象。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="cha-xun-dang-qian-hui-shou-zhan-zhong-shu-ju">查询当前回收站中数据</h2>
<pre><code class="language-shell">node1:oracle:mmsgdb &gt; sqlplus /nolog

SQL*Plus: Release 11.1.0.7.0 - Production on 星期四 11月 19 10:45:32 2009

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

SQL&gt; conn wyz/wyz 
已连接。
SQL&gt; select * from recyclebin;

未选定行

SQL&gt;
</code></pre>
<p>上面显示回收站为空。</p>
<h2 id="shan-chu-yi-ji-lu">删除一记录</h2>
<p>数据库用户wyz删除一条记录：</p>
<pre><code class="language-shell">
SQL&gt; urop table interfaceaccount_20091117;

表已删除。
</code></pre>
<h2 id="cha-kan-hui-shou-zhan-xin-xi">查看回收站信息</h2>
<pre><code class="language-shell">SQL&gt; select object_name,original_name from recyclebin;

OBJECT_NAME                    ORIGINAL_NAME
------------------------------ --------------------------------
BIN$eLFmxee63zrgQKjA3GR4Sw==$0 IDX_I_20091117
BIN$eLFmxee73zrgQKjA3GR4Sw==$0 SYS_C0048264
BIN$eLFmxee83zrgQKjA3GR4Sw==$0 INTERFACEACCOUNT_20091117

SQL&gt;
</code></pre>
<p>上面显示3条记录，记录表interfaceaccount_20091117被删除时的信息。</p>
<p>以下几种drop不会将相关对象放进RecycleBin：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>drop tablespace： 会将RecycleBin中所有属于该tablespace的对象清除</p>
</li>
<li class="lvl-2">
<p>drop user：      会将RecycleBin中所有属于该用户的对象清除</p>
</li>
<li class="lvl-2">
<p>drop cluster：    会将RecycleBin中所有属于该cluster的成员对象清除</p>
</li>
<li class="lvl-2">
<p>drop type：      会将RecycleBin中所有依赖该type的对象清除</p>
</li>
</ul>
<p>RecycleBin中的对象会被系统自动按照规则重命名，这是为了防止命名冲突。命名格式为：BIN$unique_id$version，其中unique_id是26个字符的对象唯一标识符，version则是对象在数据库中的版本号。</p>
<h2 id="yan-zheng-ming-ming-gui-ze">验证命名规则</h2>
<p>已经删除了表interfaceaccount_20091117，创建该表，再次删除一次。</p>
<pre><code class="language-shell">SQL&gt; create table interfaceaccount_20091117 as select * from interfaceaccount_20091119 where 1=2;   #创建表interfaceaccount_20091117
SQL&gt; drop table interfaceaccount_20091117;    #再次删除表interfaceaccount_20091117

表已删除。

SQL&gt; select object_name,original_name from recyclebin;   #查看回收站信息

OBJECT_NAME                    ORIGINAL_NAME
------------------------------ --------------------------------
BIN$eLFmxee63zrgQKjA3GR4Sw==$0 IDX_I_20091117
BIN$eLFmxee73zrgQKjA3GR4Sw==$0 SYS_C0048264
BIN$eLFmxee83zrgQKjA3GR4Sw==$0 INTERFACEACCOUNT_20091117
BIN$eLFmxefD3zrgQKjA3GR4Sw==$0 INTERFACEACCOUNT_20091117

SQL&gt;
</code></pre>
<p>可以看到，删除table interfaceaccount_20091117后，重建一个名为interfaceaccount_20091117的table，再次删除，其unique_id是不一样的。</p>
<p>通过这种命名方式，避免了对于删除table后又重建了同名table的情况可能造成的命名冲突。</p>
<h1 id="qi-yong-jin-yong-hui-shou-zhan">启用/禁用回收站</h1>
<p>启用或禁用回收站，通过设置初始化参数recyclebin，可以控制是否启用回收站功能，默认是开启的。</p>
<pre><code class="language-shell">SQL&gt; alter system set recyclebin=off;        #关闭回收站
系统已更改。
SQL&gt; alter system set recyclebin=on;        #开启回收站
系统已更改。
SQL&gt; 
</code></pre>
<p>修改该参数后，重启实例生效。</p>
<h1 id="cha-kan-recycle-bin-zhong-de-xin-xi">查看RecycleBin中的信息</h1>
<p>前面已经提及，即使用：</p>
<pre><code class="language-shell">SQL&gt; select object_name,original_name from recyclebin;
</code></pre>
<p>或（必须是sysdba用户）：</p>
<pre><code class="language-shell">SQL&gt; select owner,synonym_name,table_owner,table_name from dba_synonyms where synonym_name='RECYCLEBIN';

OWNER                          SYNONYM_NAME
------------------------------ ------------------------------
TABLE_OWNER                    TABLE_NAME
------------------------------ ------------------------------
PUBLIC                         RECYCLEBIN
SYS                            USER_RECYCLEBIN


SQL&gt;
</code></pre>
<p>或</p>
<pre><code class="language-shell">SQL&gt; show recyclebin 
ORIGINAL NAME    RECYCLEBIN NAME                OBJECT TYPE  DROP TIME
---------------- ------------------------------ ------------ -------------------
INTERFACEACCOUNT BIN$eLFmxefD3zrgQKjA3GR4Sw==$0 TABLE        2009-11-19:10:58:22
_20091117
INTERFACEACCOUNT BIN$eLFmxee83zrgQKjA3GR4Sw==$0 TABLE        2009-11-19:10:49:00
_20091117
SQL&gt;
</code></pre>
<h1 id="qing-chu-recycle-bin-zhong-de-dui-xiang">清除RecycleBin中的对象</h1>
<p>Oracle10g提供了回收站功能，回收站类似Windows的回收站，是个虚拟的容器。回收站的东西多了，自然需要清除：</p>
<p>自oracle 10g之后，oracle提供了purge来执行清除recyclebin的功能。</p>
<p>purge table table_name可以清除指定的table，这里的table_name既可以是table原来的名字，也可以是回收站中按规则自动命名的名字。</p>
<pre><code class="language-shell">SQL&gt; show recyclebin 
ORIGINAL NAME    RECYCLEBIN NAME                OBJECT TYPE  DROP TIME
---------------- ------------------------------ ------------ -------------------
INTERFACEACCOUNT BIN$eLFmxefD3zrgQKjA3GR4Sw==$0 TABLE        2009-11-19:10:58:22
_20091117
INTERFACEACCOUNT BIN$eLFmxee83zrgQKjA3GR4Sw==$0 TABLE        2009-11-19:10:49:00
_20091117

SQL&gt;  purge table  INTERFACEACCOUNT_20091117;

表已清除。

SQL&gt; purge table BIN$eLFmxee83zrgQKjA3GR4Sw==$0;            
purge table BIN$eLFmxee83zrgQKjA3GR4Sw==$0
                                      *
第 1 行出现错误:
ORA-00933: SQL 命令未正确结束


SQL&gt; purge table "BIN$eLFmxefD3zrgQKjA3GR4Sw==$0";  #需要加引号

表已清除。

SQL&gt;

Purge tablespace tablespace_name user user_name则可以清除Recycle中属于指定tablespace和指定user的所有对象。
node1:oracle:mmsgdb &gt; sqlplus '/as sysdba'

SQL*Plus: Release 11.1.0.7.0 - Production on 星期四 11月 19 11:34:04 2009

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select * from dba_tablespace_usage_metrics;  #查看表空间信息

TABLESPACE_NAME                USED_SPACE TABLESPACE_SIZE USED_PERCENT
------------------------------ ---------- --------------- ------------
MMSC                                 4088           12800      31.9375
MMSG                                 4864          128000          3.8
SYSAUX                              35440         4194302   .844955847
SYSTEM                              63648         4194302    1.5174873
TEMP                                    0         4194302            0
UNDOTBS1                              816         4194302   .019454965
USERS                                 128         4194302   .003051759
WYZ                                  6008           12800      46.9375
YJH                                 10064          128000       7.8625
YKLOG_DATA                            256          256000           .1
YKLOG_INDEX                           128          128000           .1

TABLESPACE_NAME                USED_SPACE TABLESPACE_SIZE USED_PERCENT
------------------------------ ---------- --------------- ------------
ZJUN                                 4992           25600         19.5

已选择12行。

SQL&gt;
SQL&gt; select * from dba_users where username='WYZ';

USERNAME                          USER_ID PASSWORD
------------------------------ ---------- ------------------------------
ACCOUNT_STATUS                   LOCK_DATE      EXPIRY_DATE
-------------------------------- -------------- --------------
DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           CREATED
------------------------------ ------------------------------ --------------
PROFILE                        INITIAL_RSRC_CONSUMER_GROUP
------------------------------ ------------------------------
EXTERNAL_NAME
--------------------------------------------------------------------------------
PASSWORD E
-------- -
WYZ                                    36

USERNAME                          USER_ID PASSWORD
------------------------------ ---------- ------------------------------
ACCOUNT_STATUS                   LOCK_DATE      EXPIRY_DATE
-------------------------------- -------------- --------------
DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           CREATED
------------------------------ ------------------------------ --------------
PROFILE                        INITIAL_RSRC_CONSUMER_GROUP
------------------------------ ------------------------------
EXTERNAL_NAME
--------------------------------------------------------------------------------
PASSWORD E
-------- -
OPEN                                            25-4月 -10

USERNAME                          USER_ID PASSWORD
------------------------------ ---------- ------------------------------
ACCOUNT_STATUS                   LOCK_DATE      EXPIRY_DATE
-------------------------------- -------------- --------------
DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           CREATED
------------------------------ ------------------------------ --------------
PROFILE                        INITIAL_RSRC_CONSUMER_GROUP
------------------------------ ------------------------------
EXTERNAL_NAME
--------------------------------------------------------------------------------
PASSWORD E
-------- -
WYZ                            WYZ_TMP                        27-10月-09

USERNAME                          USER_ID PASSWORD
------------------------------ ---------- ------------------------------
ACCOUNT_STATUS                   LOCK_DATE      EXPIRY_DATE
-------------------------------- -------------- --------------
DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           CREATED
------------------------------ ------------------------------ --------------
PROFILE                        INITIAL_RSRC_CONSUMER_GROUP
------------------------------ ------------------------------
EXTERNAL_NAME
--------------------------------------------------------------------------------
PASSWORD E
-------- -
DEFAULT                        DEFAULT_CONSUMER_GROUP

USERNAME                          USER_ID PASSWORD
------------------------------ ---------- ------------------------------
ACCOUNT_STATUS                   LOCK_DATE      EXPIRY_DATE
-------------------------------- -------------- --------------
DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           CREATED
------------------------------ ------------------------------ --------------
PROFILE                        INITIAL_RSRC_CONSUMER_GROUP
------------------------------ ------------------------------
EXTERNAL_NAME
--------------------------------------------------------------------------------
PASSWORD E
-------- -


USERNAME                          USER_ID PASSWORD
------------------------------ ---------- ------------------------------
ACCOUNT_STATUS                   LOCK_DATE      EXPIRY_DATE
-------------------------------- -------------- --------------
DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           CREATED
------------------------------ ------------------------------ --------------
PROFILE                        INITIAL_RSRC_CONSUMER_GROUP
------------------------------ ------------------------------
EXTERNAL_NAME
--------------------------------------------------------------------------------
PASSWORD E
-------- -
10G 11G  N

USERNAME                          USER_ID PASSWORD
------------------------------ ---------- ------------------------------
ACCOUNT_STATUS                   LOCK_DATE      EXPIRY_DATE
-------------------------------- -------------- --------------
DEFAULT_TABLESPACE             TEMPORARY_TABLESPACE           CREATED
------------------------------ ------------------------------ --------------
PROFILE                        INITIAL_RSRC_CONSUMER_GROUP
------------------------------ ------------------------------
EXTERNAL_NAME
--------------------------------------------------------------------------------
PASSWORD E
-------- -


SQL&gt;

SQL&gt; purge tablespace wyz user wyz;   #第一个wyz为表空间名称，第二个wyz为数据库用户名
表空间已清除。

Purge recyclebin可以清除执行该命令的用户所能看到的所有recyclebin对象。也就是普通用户能清除属于自己的对象，而sysdba用户则能清除所有recyclebin中的对象。
SQL&gt; purge recyclebin;
回收站已清空。
</code></pre>
<p>另外，purge index可以清除index对象。</p>
<pre><code class="language-shell">SQL&gt; select object_name,original_name,type from recyclebin;

OBJECT_NAME                    ORIGINAL_NAME
------------------------------ --------------------------------
TYPE
-------------------------
BIN$eLIogOtK7vDgQKjA3GRztA==$0 INTERFACEACCOUNT_20091117
TABLE

BIN$eLIogOtS7vDgQKjA3GRztA==$0 IDX_I_20091103
INDEX

BIN$eLIogOtT7vDgQKjA3GRztA==$0 SYS_C0019958
INDEX


OBJECT_NAME                    ORIGINAL_NAME
------------------------------ --------------------------------
TYPE
-------------------------
BIN$eLIogOtU7vDgQKjA3GRztA==$0 INTERFACEACCOUNT_20091103
TABLE


SQL&gt;
SQL&gt; purge index IDX_I_20091103;

索引已清除。

SQL&gt;
</code></pre>
<p>如果出现</p>
<pre><code class="language-shell">SQL&gt; purge index IDX_I_20091103;
第 1 行出现错误:
ORA-00604: 递归 SQL 级别 1 出现错误
ORA-02429: 无法删除用于强制唯一/主键的索引
</code></pre>
<p>这里由于IDX_I_20091103是table主键的索引，所以无法单独清除。可直接清除回收站：</p>
<pre><code class="language-shell">SQL&gt; purge recyclebin;
回收站已清空。
</code></pre>
<h1 id="huan-yuan-recycle-bin-zhong-de-dui-xiang">还原RecycleBin中的对象</h1>
<p>使用Flashback table来还原过被删除的table。</p>
<pre><code class="language-shell">SQL&gt; flashback table  INTERFACEACCOUNT_20091117  to before drop rename to INTERFACEACCOUNT_wyztest;

闪回完成。

SQL&gt; select object_name,original_name,type from recyclebin;

OBJECT_NAME                    ORIGINAL_NAME
------------------------------ --------------------------------
TYPE
-------------------------
BIN$eLIogOtT7vDgQKjA3GRztA==$0 SYS_C0019958
INDEX

BIN$eLIogOtU7vDgQKjA3GRztA==$0 INTERFACEACCOUNT_20091103
TABLE


SQL&gt;
闪回完成。闪回是oracle11g的亮点。
SQL&gt; desc INTERFACEACCOUNT_wyztest;
 名称                                      是否为空? 类型
 ----------------------------------------- -------- ----------------------------
 MODULETYPE                                NOT NULL NUMBER(38)
 MODULEID                                  NOT NULL NUMBER(38)
 ACCOUNTDATANAME                           NOT NULL VARCHAR2(64)
 STARTDATETIME                             NOT NULL VARCHAR2(14)
 STOPDATETIME                              NOT NULL VARCHAR2(14)
 ACCOUNT                                   NOT NULL NUMBER(38)

SQL&gt;
</code></pre>
<p>如果多次删除同名的table，则使用上面的语句还原的是最后一个被删除的INTERFACEACCOUNT_20091117表，这里也可以使用RecycleBin给table的名字来做还原。</p>
<pre><code class="language-shell">SQL&gt; flashback table " BIN$eLIogOtU7vDgQKjA3GRztA==$0" to before drop rename to wyz_test_2009-11-19;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--非DBA用户连接oracle，报权限不允许</title>
    <url>/2010/03/19/oracle_permission_denied_for_not_oracle_user/</url>
    <content><![CDATA[<h1 id="zai-aix-cao-zuo-xi-tong-fei-dba-yong-hu-lian-jie-oracle-bao-quan-xian-bu-yun-xu">在AIX操作系统，非DBA用户连接oracle，报权限不允许</h1>
<h2 id="biao-xiang">表象</h2>
<p>在AIX操作系统，非DBA用户连接oracle，报权限不允许：</p>
<pre><code class="language-shell">2 p570flpar2 [nss] :/home/nss&gt;sql      
sqlplus startup unsuccessfully : Permission denied(13)
</code></pre>
<p>在该用户下打开oracle安装目录：</p>
<pre><code class="language-shell">7 p570flpar2 [nss] :/home/nss/mms_home/cfg&gt;cd $ORACLE_HOME
/opt/oracle/oracle/app/product/11.1.0/db_1: 文件访问许可不允许执行指定的操作。
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>从错误内容，可以知道这是权限不足问题。</p>
<p>用oracle用户登陆：</p>
<p>查看权限，发现oracle目录没有执行权限</p>
<pre><code class="language-shell">% ll 
total 4917192
drwx--x--x    2 oracle   dba             256 Mar 18 10:00 Mail
-rw-r--r--    1 oracle   dba       650295797 Mar  2 11:49 aix.ppc64_11gR1_database_1of2.zip
-rw-r--r--    1 oracle   dba      1867281765 Mar  2 14:39 aix.ppc64_11gR1_database_2of2.zip
drwxr-x---    3 oracle   dba             256 Mar  8 20:12 app
drwxr-x---    3 oracle   dba             256 Mar  2 16:39 cdy
drwxr-x---    3 oracle   dba             256 Mar  5 09:49 hzw
drwxr-x---    2 oracle   dba             256 Mar 18 10:38 infoxwebdata
drwxr-x---    3 oracle   dba             256 Mar  4 13:47 lcx
drwxr-xr-x    2 oracle   dba             256 Mar 18 11:21 mmsdata
drwxr-x---    3 oracle   dba             256 Mar  8 20:07 oracle
drwxr-x---    3 oracle   dba             256 Mar  2 16:55 oradata
-rw-r--r--    1 oracle   dba            4629 Mar 19 15:56 smit.log
-rw-r--r--    1 oracle   dba             611 Mar 19 15:56 smit.script
-rw-r--r--    1 oracle   dba            1203 Mar 19 15:56 smit.transaction
</code></pre>
<p>增加目录权限：</p>
<p><code>% chmod -R 755 oracle </code></p>
<p>然后到$ORACLE_HOME/bin目录下，给tnsping与sqlplus添加读与执行的权限：</p>
<pre><code class="language-shell">% chmod 755 tnsping
% chmod 755 sqlplus
</code></pre>
<p>修改权限，回到原用户执行命令，可以看到，数据库已经可以连上：</p>
<pre><code class="language-shell">10 p570flpar2 [nss] :/opt/oracle/oracle/app/product/11.1.0/db_1&gt;tnsping mdsp 10

TNS Ping Utility for IBM/AIX RISC System/6000: Version 11.1.0.6.0 - Production on 19-MAR-2010 16:05:38

Copyright (c) 1997, 2007, Oracle.  All rights reserved.

Used parameter files:


Used TNSNAMES adapter to resolve the alias
Attempting to contact (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = p570flpar2)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = mdsp)))
OK (100 msec)
OK (0 msec)
OK (0 msec)
OK (0 msec)
OK (10 msec)
OK (0 msec)
OK (0 msec)
OK (0 msec)
OK (0 msec)
OK (0 msec)

9 p570flpar2 [nss] :/home/nss/mms_home/cfg&gt;cd $ORACLE_HOME
10 p570flpar2 [nss] :/opt/oracle/oracle/app/product/11.1.0/db_1&gt;

16 p570flpar2 [nss] :/home/nss&gt;sql

SQL*Plus: Release 11.1.0.6.0 - Production on Fri Mar 19 16:09:02 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; exit
Disconnected from Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-00845，ORA-01102</title>
    <url>/2010/03/23/oracle_troubleshoot_ora_00845_ora_01102/</url>
    <content><![CDATA[<h1 id="ora-00845-he-ora-01102-an-li">ORA-00845  和  ORA-01102案例</h1>
<h2 id="biao-xiang">表象</h2>
<pre><code class="language-shell">oracle@mmsg01:/home&gt; sqlplus "/ as sysdba"

SQL*Plus: Release 11.1.0.7.0 - Production on Tue Mar 23 17:55:21 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

Connected to an idle instance.

SQL&gt; startup
ORA-00845: MEMORY_TARGET not supported on this system
SQL&gt; exit
Disconnected
oracle@mmsg01:/home&gt; oerr ora 00845
00845, 00000, "MEMORY_TARGET not supported on this system"
// *Cause: The MEMORY_TARGET parameter was not supported on this operating system or /dev/shm was not sized correctly on Linux.
// *Action: Refer to documentation for a list of supported operating systems. Or, size /dev/shm to be at least the SGA_MAX_SIZE on each Oracle instance running on the system.
oracle@mmsg01:/home&gt; 
</code></pre>
<h2 id="yuan-yin">原因</h2>
<p>这个问题是由于设置SGA的大小超过了操作系统/dev/shm的大小：</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>解决这个问题只有两个方法：</p>
<p>一是修改初始化参数，使得初始化参数中SGA的设置小于/dev/shm的大小；</p>
<p>二是调整/dev/shm的大小。</p>
<p>修改/dev/shm的大小可以通过修改/etc/fstab来实现</p>
<pre><code class="language-shell">mmsg01:/etc/init.d # df -k /dev/shm
Filesystem           1K-blocks      Used Available Use% Mounted on
shmfs                  4194304         0   4194304   0% /dev/shm                     

vi /etc/fstab
mmsg01:/etc/init.d # vi /etc/fstab

/dev/disk/by-id/scsi-3600508e000000000da19d06c68ac5e0b-part2 /                    reiserfs   acl,user_xattr        1 1
/dev/disk/by-id/scsi-3600508e000000000da19d06c68ac5e0b-part5 /home                reiserfs   acl,user_xattr        1 2
/dev/disk/by-id/scsi-3600508e000000000da19d06c68ac5e0b-part1 swap                 swap       defaults              0 0
proc                 /proc                proc       defaults              0 0
sysfs                /sys                 sysfs      noauto                0 0
debugfs              /sys/kernel/debug    debugfs    noauto                0 0
usbfs                /proc/bus/usb        usbfs      noauto                0 0
devpts               /dev/pts             devpts     mode=0620,gid=5       0 0
shm                  /dev/shm             tmpfs      size=8g               0 0
＃shmfs /dev/shm tmpfs size=4g 0
shmfs /dev/shm tmpfs size=8g 0  #新增加的一行
</code></pre>
<p>解邦</p>
<pre><code class="language-shell">umount /dev/shm
</code></pre>
<p>重新邦定</p>
<pre><code class="language-shell">mount /dev/shm
</code></pre>
<p>查看邦定结果</p>
<pre><code class="language-shell">df -k
mmsg01:/etc/init.d # df
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/sda2             41944376   4417892  37526484  11% /
udev                   8218880       240   8218640   1% /dev
/dev/sda5             73398648  15426492  57972156  22% /home
shm                    8388608         0   8388608   0% /dev/shm
</code></pre>
<p>启动数据库</p>
<pre><code class="language-shell">oracle@mmsg01:~/oradata/mmsgdb&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Tue Mar 23 20:33:20 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

Connected to an idle instance.

SQL&gt; startup      
ORA-00845: MEMORY_TARGET not supported on this system
SQL&gt; startup
ORA-00845: MEMORY_TARGET not supported on this system
SQL&gt; startup
ORACLE instance started.

Total System Global Area 8417955840 bytes
Fixed Size                  2161312 bytes
Variable Size            4429186400 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27185152 bytes
ORA-01102: cannot mount database in EXCLUSIVE mode


SQL&gt; 
</code></pre>
<p>出现了另外一个错误：ORA-01102</p>
<p>这个错误主要是lk<sid>文件造成的，该文件位于ORALCE_HOME下的dbs目录下, 这个lk<sid>的主要作用是：</sid></sid></p>
<p>说明DATABASE MOUNT上了,不用再去MOUNT了。</p>
<p>具体解决ORA-01102问题的步骤：</p>
<pre><code class="language-shell">oracle@mmsg01:~/product/11g/dbs&gt; /sbin/fuser -u lkMMSGDB
lkMMSGDB:            24500(oracle) 24508(oracle) 24510(oracle) 24514(oracle) 24516(oracle) 24518(oracle) 24520(oracle) 24522(oracle) 24524(oracle) 24526(oracle) 24528(oracle) 24585(oracle) 24589(oracle) 24667(oracle) 24669(oracle) 24693(oracle)
</code></pre>
<p>发现lkMMSGDB文件没有释放，使用fuser命令kill掉lkMMSGDB</p>
<pre><code class="language-shell">oracle@mmsg01:~/product/11g/dbs&gt; /sbin/fuser -k lkMMSGDB 
lkMMSGDB:            24500 24508 24510 24514 24516 24518 24520 24522 24524 24526 24528 24585 24589 24667 24669 24693
</code></pre>
<p>再去检查lkMMSGDB文件是否释放</p>
<pre><code class="language-shell">oracle@mmsg01:~/product/11g/dbs&gt; /sbin/fuser -u lkMMSGDB
</code></pre>
<p>不显示任何信息，说明lkMMSGDB文件已经释放</p>
<p>重新启动数据库</p>
<pre><code class="language-shell">oracle@mmsg01:~/product/11g/dbs&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Tue Mar 23 20:41:22 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

Connected to an idle instance.

SQL&gt; startup 
ORACLE instance started.

Total System Global Area 8417955840 bytes
Fixed Size                  2161312 bytes
Variable Size            4429186400 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27185152 bytes
Database mounted.
Database opened.
SQL&gt; exit
</code></pre>
<p>启动成功</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-01078,ORA-00119,ORA-00132</title>
    <url>/2010/03/25/oracle_troubleshoot_ora_01078_ora_00119_ora_00132/</url>
    <content><![CDATA[<h1 id="ora-01078-ora-00119-ora-00132-an-li">ORA-01078  ORA-00119 ORA-00132 案例</h1>
<h2 id="biao-xiang">表象</h2>
<pre><code class="language-shell">oracle@mmsg01:~/product/11g/network/admin&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Thu Mar 25 09:51:02 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

Connected to an idle instance.

SQL&gt; startup 
ORA-01078: failure in processing system parameters
ORA-00119: invalid specification for system parameter LOCAL_LISTENER
ORA-00132: syntax error or unresolved network name 'LISTENER_MMSGDB'
SQL&gt; exit
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>将监听文件中HOST处改成具体的IP地址</p>
<pre><code class="language-shell">LISTENER_MMSGDB =
  (ADDRESS = (PROTOCOL = TCP)(HOST = your host ip )(PORT = 1523))
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle导入导出之exp/imp</title>
    <url>/2010/03/30/oracle_exp_imp/</url>
    <content><![CDATA[<h1 id="dao-ru-dao-chu-de-zuo-yong">导入导出的作用</h1>
<p>EXP和IMP不仅可以用于实现逻辑备份和逻辑恢复,还可以实现下面的功能：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、重新组织表</p>
</li>
<li class="lvl-2">
<p>2、在用户之间移动对象</p>
</li>
<li class="lvl-2">
<p>3、在数据库之间移动对象</p>
</li>
<li class="lvl-2">
<p>4、升级数据库到其他平台</p>
</li>
<li class="lvl-2">
<p>5、升级数据库到高版本</p>
</li>
<li class="lvl-2">
<p>6、实现逻辑备份和恢复</p>
</li>
</ul>
<h1 id="exp-ming-ling-xiang-jie">exp命令详解</h1>
<p>EXP 将数据库部分或全部对象的结构和数据导出,并存储到OS文件中的过程。</p>
<h2 id="exp-ming-ling-xing-xuan-xiang">exp命令行选项</h2>
<pre><code class="language-shell">oracle@GW_8:~&gt; exp help=y

Export: Release 11.1.0.7.0 - Production on 星期五 2月 1 08:42:26 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

通过输入 EXP 命令和您的用户名/口令, 导出
操作将提示您输入参数: 

     例如: EXP SCOTT/TIGER

或者, 您也可以通过输入跟有各种参数的 EXP 命令来控制导出
的运行方式。要指定参数, 您可以使用关键字: 

     格式:  EXP KEYWORD=value 或 KEYWORD=(value1,value2,...,valueN)
     例如: EXP SCOTT/TIGER GRANTS=Y TABLES=(EMP,DEPT,MGR)
               或 TABLES=(T1:P1,T1:P2), 如果 T1 是分区表

USERID 必须是命令行中的第一个参数。

关键字   说明 (默认值)         关键字      说明 (默认值)
--------------------------------------------------------------------------
USERID   用户名/口令           FULL        导出整个文件 (N)
BUFFER   数据缓冲区大小        OWNER        所有者用户名列表
FILE     输出文件 (EXPDAT.DMP)  TABLES     表名列表
COMPRESS  导入到一个区 (Y)   RECORDLENGTH   IO 记录的长度
GRANTS    导出权限 (Y)          INCTYPE     增量导出类型
INDEXES   导出索引 (Y)         RECORD       跟踪增量导出 (Y)
DIRECT    直接路径 (N)         TRIGGERS     导出触发器 (Y)
LOG      屏幕输出的日志文件    STATISTICS    分析对象 (ESTIMATE)
ROWS      导出数据行 (Y)        PARFILE      参数文件名
CONSISTENT 交叉表的一致性 (N)   CONSTRAINTS  导出的约束条件 (Y)

OBJECT_CONSISTENT    只在对象导出期间设置为只读的事务处理 (N)
FEEDBACK             每 x 行显示进度 (0)
FILESIZE             每个转储文件的最大大小
FLASHBACK_SCN        用于将会话快照设置回以前状态的 SCN
FLASHBACK_TIME       用于获取最接近指定时间的 SCN 的时间
QUERY                用于导出表的子集的 select 子句
RESUMABLE            遇到与空格相关的错误时挂起 (N)
RESUMABLE_NAME       用于标识可恢复语句的文本字符串
RESUMABLE_TIMEOUT    RESUMABLE 的等待时间
TTS_FULL_CHECK       对 TTS 执行完整或部分相关性检查
VOLSIZE              写入每个磁带卷的字节数
TABLESPACES          要导出的表空间列表
TRANSPORT_TABLESPACE 导出可传输的表空间元数据 (N)
TEMPLATE             调用 iAS 模式导出的模板名
</code></pre>
<h3 id="1-buffer">1、BUFFER</h3>
<p>该选项用于指定提取行数据时的缓冲区尺寸.通过设置该选项,可以确定导出时数据提起尺寸.该选项只适用于常规选项.<br>
Exp scott/tiger tables=dept,emp file=a.dmp buffer=81920</p>
<h3 id="2-compress">2、COMPRESS</h3>
<p>该选项用于指定导入管理初始区(INITIAL)的方法.默认值为Y.当设置该选项为Y时,oracle会将INITIAL设置为表段的当前尺寸;当设置该选项为N时,oracle仍然使用表段的原有存储参数(INITIAL和NEXT).</p>
<h3 id="3-consistent">3、CONSISTENT</h3>
<p>该选项用于指定是否使用SET TRANSACTION READ ONLY语句确保取得一致时间点的数据,默认值为N .当设置该选项为Y时,所有被导出表会在同一个事务内完成导出.确保取得一致时间点的数据,当设置该选项为N时,每个被导出表会使用独立事务导出.需要注意,导出数据库时,为了避免snapshot too old 错误,不要将选项CONSISTENT设置为Y.</p>
<h3 id="4-constraints">4、CONSTRAINTS</h3>
<p>设是否导出表的约束,默认值为Y.</p>
<h3 id="5-direct">5、DIRECT</h3>
<p>该选项用于指定是否使用直接导出方式,默认值为N.当设置该选项为Y时,采用直接导出方式;当设置为N时,采用常规导出方式.需要注意,直接导出方式速度要优于常规导出,但要求客户端和服务端的字符集必须完全一致.</p>
<h3 id="6-feedback">6、FEEDBACK</h3>
<p>指定导出行数显示进程框,默认为0,如果设置该选项为10,则每导出10行显示一个园点(.)</p>
<h3 id="7-file">7、FILE</h3>
<p>该选项用于指定导出文件名</p>
<h3 id="8-filesize">8、FILESIZE</h3>
<p>该选项用于指定导出文件的最大尺寸.</p>
<h3 id="9-flashback-scn">9、FLASHBACK_SCN</h3>
<p>该选项用于指定导出特定SCN时刻的表数据.FLASHBACK_SCN选项和FLASHBACK_TIME选项不能同时使用.</p>
<pre><code class="language-shell">Exp system/manager tables=scott.dept,scott.emp file=a.dmp 
Flashback_scn=941931 
</code></pre>
<h3 id="10-flashback-time">10、FLASHBACK_TIME</h3>
<p>指定导出特定时刻的数据</p>
<pre><code class="language-shell">Exp system/manager tables=scott.dept,scott.emp file=a.dmp 
Flashback_time="'2004-07-06 15:59:52'"
</code></pre>
<h3 id="11-full">11、FULL</h3>
<p>指定数据库导出模式,默认值为N,当设置为Y时,导出除SYS外所有其他方案的对象.</p>
<h3 id="12-grants">12、GRANTS</h3>
<p>该选项用于指定是否导出对象权限信息,默认值为Y.</p>
<h3 id="13-help">13、HELP</h3>
<p>展示exp相关命令项信息。</p>
<h3 id="14-indexes">14、INDEXES</h3>
<p>指定是否导出与表和簇相关的索引,默认值为Y</p>
<h3 id="15-log">15、LOG</h3>
<p>指定导出日志文件的名称,默认情况下不好生成导出日志文件.</p>
<h3 id="16-object-consistent">16、OBJECT_CONSISTENT</h3>
<p>用于指定是否基于对象级设置只读事务导出,默认值为N,当设置该选项为Y时,基于每个对象设置一个只读事务,然后导出相应对象的数据。</p>
<h3 id="17-owner">17、OWNER</h3>
<p>指定用于导出模式.</p>
<h3 id="18-parfile">18、PARFILE</h3>
<p>指定导出工具要使用的参数文件名.如果经常需要使用EXP工具导出数据,可以将命令行选项放到参数文件中,然后导出时调用该参数文件.</p>
<h3 id="19-query">19、QUERY</h3>
<p>该选项用于指定WHERE条件子句,从而导出表的部分数据.需要注意,使用直接导出方式时不能指定该选项.</p>
<pre><code class="language-shell">Exp scott/tiger tables=emp query=’WHERE depot=10’ 
</code></pre>
<h3 id="20-recordlength">20、RECORDLENGTH</h3>
<p>该选项用于指定文件记录的长度,默认值为BUFFER选项值.当需要将导出文件传送到不同OS平台时,可能需要设置该选项.需要注意,该选项的值不能超过64K.</p>
<h3 id="21-resumable">21、RESUMABLE</h3>
<p>该选项用于指定是否激活”空间继续分配”特征,默认值为N,为了使用选项RESUMABLE_NAEM和RESUMABLE_TIMEOUT,必须将该选项设置为Y.</p>
<h3 id="22-resumable-name">22、RESUMABLE_NAME</h3>
<p>该选项用于指定”空间继续分配”语句所对应的标识符.</p>
<h3 id="23-resumable-timeout">23、RESUMABLE_TIMEOUT</h3>
<p>该选项用于指定错误被修正的最大周期(单位:秒),默认值为7200</p>
<h3 id="24-rows">24、ROWS</h3>
<p>该选项用于指定是否导出表行数据,默认值为Y</p>
<h3 id="25-statistics">25、STATISTICS</h3>
<p>该选项用于指定导入导出文件时生成优化统计信息的类型.默认值为ESTIMATE.</p>
<h3 id="26-tables">26、TABLES</h3>
<p>该选项用于指定导出表</p>
<h3 id="27-tablespace">27、TABLESPACE</h3>
<p>该选项用于指定表空间导出模式,使用TABLESPACES选项时,会导出特定表空间上所有表.</p>
<h3 id="28-transport-tablespace">28、TRANSPORT_TABLESPACE</h3>
<p>该选项用于指定是否导出表空间元数据,默认值为N.当设置为Y时,导出特定表空间的元数据,当设置为N时,不导出表空间的元数据.</p>
<h3 id="29-triggers">29、TRIGGERS</h3>
<p>用于指定是否导出触发器,默认为Y</p>
<h3 id="30-tts-full-check">30、TTS_FULL_CHECK</h3>
<p>该选项用于指定是否检查被搬移表空间的关联关系,默认值为N</p>
<h3 id="31-userid">31、USERID</h3>
<p>该选项用于指定执行导出操作的用于名,口令和连接字符串.</p>
<h1 id="imp-ming-ling-xiang-jie">imp命令详解</h1>
<p>IMP是将OS文件中的对象结构和数据装载到数据库中的过程。</p>
<h2 id="imp-ming-ling-xuan-xiang">imp命令选项</h2>
<pre><code class="language-shell">oracle@GW_8:~&gt; imp help=y  

Import: Release 11.1.0.7.0 - Production on 星期五 2月 1 08:54:04 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.



通过输入 IMP 命令和您的用户名/口令, 导入
操作将提示您输入参数: 

     例如: IMP SCOTT/TIGER

或者, 可以通过输入 IMP 命令和各种参数来控制导入
的运行方式。要指定参数, 您可以使用关键字: 

     格式:  IMP KEYWORD=value 或 KEYWORD=(value1,value2,...,valueN)
     例如: IMP SCOTT/TIGER IGNORE=Y TABLES=(EMP,DEPT) FULL=N
               或 TABLES=(T1:P1,T1:P2), 如果 T1 是分区表

USERID 必须是命令行中的第一个参数。

关键字   说明 (默认值)        关键字      说明 (默认值)
--------------------------------------------------------------------------
USERID   用户名/口令           FULL       导入整个文件 (N)
BUFFER   数据缓冲区大小        FROMUSER    所有者用户名列表
FILE     输入文件 (EXPDAT.DMP)  TOUSER     用户名列表
SHOW     只列出文件内容 (N)     TABLES      表名列表
IGNORE   忽略创建错误 (N)    RECORDLENGTH  IO 记录的长度
GRANTS   导入权限 (Y)          INCTYPE     增量导入类型
INDEXES   导入索引 (Y)         COMMIT       提交数组插入 (N)
ROWS     导入数据行 (Y)        PARFILE      参数文件名
LOG     屏幕输出的日志文件    CONSTRAINTS    导入限制 (Y)
DESTROY                覆盖表空间数据文件 (N)
INDEXFILE              将表/索引信息写入指定的文件
SKIP_UNUSABLE_INDEXES  跳过不可用索引的维护 (N)
FEEDBACK               每 x 行显示进度 (0)
TOID_NOVALIDATE        跳过指定类型 ID 的验证 
FILESIZE               每个转储文件的最大大小
STATISTICS             始终导入预计算的统计信息
RESUMABLE              在遇到有关空间的错误时挂起 (N)
RESUMABLE_NAME         用来标识可恢复语句的文本字符串
RESUMABLE_TIMEOUT      RESUMABLE 的等待时间 
COMPILE                编译过程, 程序包和函数 (Y)
STREAMS_CONFIGURATION  导入流的一般元数据 (Y)
STREAMS_INSTANTIATION  导入流实例化元数据 (N)
VOLSIZE                磁带的每个文件卷上的文件的字节数

下列关键字仅用于可传输的表空间
TRANSPORT_TABLESPACE 导入可传输的表空间元数据 (N)
TABLESPACES 将要传输到数据库的表空间
DATAFILES 将要传输到数据库的数据文件
TTS_OWNERS 拥有可传输表空间集中数据的用户
</code></pre>
<p>IMP命令行与EXP不一样的有:</p>
<h3 id="1-commit">1、COMMIT</h3>
<p>该选项用于指定每次数据插入完成之后是否提交数据,默认值为N</p>
<h3 id="2-compile">2、COMPILE</h3>
<p>该选项用于指定导入包,过程和函数时是否进行编译,默认值为Y</p>
<h3 id="3-constraints">3、CONSTRAINTS</h3>
<p>该选项用于指定是否导入表的约束,默认值为Y</p>
<h3 id="4-datafile">4、DATAFILE</h3>
<p>当设置选项TRANSPORT_TABLESPACE为Y时,该选项用于指定要被搬移到目标数据库的数据文件列表.</p>
<pre><code class="language-shell">IMP ‘sys/admin as sysdba ‘ TRANSPORT_TABLESPACE=Y 
DATAFILE=’g:testtools01.dbf’ 
TTS_OWNERS=RMAN FROMUSER=RMAN TOUSER=SYSTEM 
</code></pre>
<h3 id="5-destroy">5、DESTROY</h3>
<p>该选项用于指定导入时是否覆盖已存在的数据文件,默认值为N.</p>
<h3 id="6-fromuser">6、FROMUSER</h3>
<p>该选项用于指定从导出文件中摘取并导入特定用于的对象.</p>
<h3 id="7-ignore">7、IGNORE</h3>
<p>该选项用于指定是否忽略对象建立错误信息.默认为N</p>
<h3 id="8-indexfile">8、INDEXFILE</h3>
<p>该选项用于指定生成存放索引建立语句的文件名称.</p>
<h3 id="9-show">9、SHOW</h3>
<p>该选项用于指定显示导出文件的内容,默认为N</p>
<h3 id="10-skip-unusable-indexes">10、SKIP_UNUSABLE_INDEXES</h3>
<p>该选项用于指定导入时是否要跳过不可使用的索引,默认值为N</p>
<h3 id="11-statstics">11、STATSTICS</h3>
<p>该选项用于指定导入时数据库优化器要执行的操作.默认值为ALWAYS</p>
<h3 id="12-streams-configuration">12、STREAMS_CONFIGURATION</h3>
<p>该选项用于指定是否导入流元数据(Stream Matadata),默认值为Y</p>
<h3 id="13-toid-novalidate">13、TOID_NOVALIDATE</h3>
<p>该选项用于指定导入对象表时要排除校验的对象类型</p>
<h3 id="14-touser">14、TOUSER</h3>
<p>该选项用于指定将特定方案对象导入到其他用户.</p>
<h3 id="15-tts-owners">15、TTS_OWNERS</h3>
<p>当设置TRANSPORT_TABLESPACE=Y时,该选项用于列出用于被搬移表空间数据的数据库用户.</p>
<h1 id="shi-jian">实践</h1>
<h2 id="dao-chu-yi-ge-wan-zheng-shu-ju-ku">导出一个完整数据库</h2>
<pre><code class="language-shell">exp system/password file=XX.dmp log=XX.log full=y
</code></pre>
<h2 id="dao-chu-shu-ju-ku-ding-yi-er-bu-dao-chu-shu-ju">导出数据库定义而不导出数据</h2>
<pre><code class="language-shell">exp system/password file=XX.dmp log=XX.log full=y rows=n
</code></pre>
<h2 id="dao-chu-yi-ge-huo-yi-zu-zhi-ding-yong-hu-suo-shu-de-quan-bu-biao-suo-yin-he-qi-ta-dui-xiang">导出一个或一组指定用户所属的全部表、索引和其他对象</h2>
<pre><code class="language-shell">exp system/sys file=mmsg log=mmsg owner=mmsg 
</code></pre>
<h2 id="dao-chu-yi-ge-huo-duo-ge-zhi-ding-biao">导出一个或多个指定表</h2>
<pre><code class="language-shell">exp mmsg/mmsg file=vaspinfo.dmp log= vaspinfo.log tables= vaspinfo 
exp mmsg/mmsg file=tables.dmp log= tables.log tables= vaspinfo,mmscinfo,miscinfo 
</code></pre>
<h2 id="gu-ji-dao-chu-wen-jian-de-da-xiao">估计导出文件的大小</h2>
<h3 id="quan-bu-biao-zong-zi-jie-shu">全部表总字节数</h3>
<pre><code class="language-shell">SELECT sum(bytes) FROM dba_segments WHERE segment_type = 'TABLE';
</code></pre>
<h3 id="mmsg-yong-hu-suo-shu-biao-de-zong-zi-jie-shu">MMSG用户所属表的总字节数</h3>
<pre><code class="language-shell">SELECT sum(bytes) FROM dba_segments WHERE owner = 'MMSG'
AND segment_type = 'TABLE';
</code></pre>
<h3 id="mmsg-yong-hu-xia-de-aquatic-animal-biao-de-zi-jie-shu">MMSG用户下的aquatic_animal表的字节数</h3>
<pre><code class="language-shell">SELECT sum(bytes)  FROM dba_segments 
WHERE owner = 'MMSG'
　　AND segment_type = 'TABLE'
　　AND segment_name = 'AQUATIC_ANIMAL';
</code></pre>
<h2 id="dao-chu-biao-shu-ju-de-zi-ji-oracle-8-i-yi-shang">导出表数据的子集(oracle8i以上)</h2>
<pre><code class="language-shell">exp mmsg/mmsg@mmsgdb tables=mmscinfo query=\"where mmscid=910000\“
</code></pre>
<h2 id="yong-duo-ge-wen-jian-fen-ge-yi-ge-dao-chu-wen-jian">用多个文件分割一个导出文件</h2>
<pre><code class="language-shell">exp username/passwd 
file=\(paycheck_1.dmp,paycheck_2.dmp,paycheck_3.dmp,paycheck_4.dmp \)
log=XX.log, filesize=[K][M][G] tables=tables_name 
</code></pre>
<p>操作如下：</p>
<pre><code class="language-shell">exp mmsg/mmsg file=\(1.dmp,2.dmp,3.dmp\) log=test.log filesize=25K tables= mmscinfo,miscinfo,vaspinfo,areainfo 
</code></pre>
<h2 id="shi-yong-can-shu-wen-jian-xiang-jian-parfile-shi-yong-fang-fa">使用参数文件（详见parfile使用方法）</h2>
<pre><code class="language-shell">exp system/manager parfile=bible_tables.par
   bible_tables.par参数文件：
　#Export the sample tables used for the Oracle8i Database Administrator's Bible.
　file=bible_tables 
　log=bible_tables 
　tables=(
amy.artist 
　amy.books 
　seapark.checkup 
　seapark.items 
　)
</code></pre>
<p>示例如下：</p>
<p>建立一个parfile文件，命名为svclogbak.par，内容是一些导出参数，如：</p>
<pre><code class="language-shell">   file=svclogbak.dmp                   #导出的文件命名
   log=svclogbak.log                    #导出过程中产生的日志信息
   tables=(mmsgsvclog_0122_1_o_0,    #括号中存放要导出的相关表信息，以英文逗号分隔
     mmsgsvclog_0122_1_o_1,
     mmsgsvclog_0122_1_o_2,
     mmsgsvclog_20100122_1_s)         #如有需要，可增加其它参数，这里仅作示例
</code></pre>
<p>使用parfile文件，可以在不同的操作系统中执行，即是任何OS平台都适用的方法。</p>
<h3 id="dao-chu">导出</h3>
<p><code>exp username/passwd@dbname parfile=svclogbak.par </code></p>
<h3 id="dao-ru">导入</h3>
<p><code>imp username/passwd@dbname fromuser=XXX touser=XXX file=svclogbak.dmp ignore=y commit=y </code></p>
<p>其中:<br>
fromuser ，该选项用于指定从导出文件中摘取并导入特定用于的对象；<br>
touser     该选项用于指定将特定方案对象导入到其他用户。如果导入导出的用户名一致，可以直接使用如下命令进行导入：<code>imp username/passwd@dbname  file=svclogbak.dmp ignore=y  commit=y </code><br>
或者<br>
<code> imp username/passwd  file=svclogbak.dmp ignore=y commit=y</code></p>
<h2 id="zeng-liang-dao-chu">增量导出</h2>
<p>“完全”增量导出(complete)，即备份整个数据库</p>
<p><code>exp system/sys inctype=complete file=wangyunzeng_mmsg.dmp </code><br>
　<br>
“增量型”增量导出(incremental)，即备份上一次备份后改变的数据</p>
<p><code>exp system/sys inctype=incremental file= wangyunzeng_mmsg.dmp </code></p>
<p>“累计型”增量导出(cumulative)，即备份上一次“完全”导出之后改变的数据</p>
<p><code>exp system/sys inctype=cumulative file= wangyunzeng_mmsg.dmp </code></p>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>必须为 SYS 或 SYSTEM 才能执行增量导出</p>
</li>
</ul>
<h2 id="dao-ru-yi-ge-wan-zheng-shu-ju-ku">导入一个完整数据库</h2>
<pre><code class="language-shell">imp system/manager file=bible_db log=dible_db full=y ignore=y
</code></pre>
<h2 id="dao-ru-yi-ge-huo-yi-zu-zhi-ding-yong-hu-suo-shu-de-quan-bu-biao-suo-yin-he-qi-ta-dui-xiang">导入一个或一组指定用户所属的全部表、索引和其他对象</h2>
<pre><code class="language-shell">imp system/manager file=seapark log=seapark fromuser=seapark 
imp  system/manager file=seapark log=seapark fromuser=\(seapark,amy,amyc,Harold\)
</code></pre>
<h2 id="jiang-yi-ge-yong-hu-suo-shu-de-shu-ju-dao-ru-ling-yi-ge-yong-hu">将一个用户所属的数据导入另一个用户</h2>
<pre><code class="language-shell">imp system/manager file=tank log=tank fromuser=seapark touser=seapark_copy 
imp system/manager file=tank log=tank fromuser=mmsg touser=wyz 
</code></pre>
<h2 id="dao-ru-yi-ge-biao">导入一个表</h2>
<pre><code class="language-shell">imp mmsg/mmsg file=mmscinfo.dmp log=mmscinfo.log fromuser=seapark TABLES=mmscinfo 
</code></pre>
<h2 id="cong-duo-ge-wen-jian-dao-ru">从多个文件导入</h2>
<pre><code class="language-shell">imp system/manager file=\(paycheck_1,paycheck_2,paycheck_3,paycheck_4\) log=paycheck, filesize=1G full=y
</code></pre>
<h2 id="shi-yong-can-shu-wen-jian">使用参数文件</h2>
<pre><code class="language-shell"> imp system/manager parfile=bible_tables.parbible_tables.par fromuser=mmsg touser=wyz file=mmscinfo.dmp log=mmscinfo.log commit=y
</code></pre>
<h2 id="zeng-liang-dao-ru">增量导入</h2>
<pre><code class="language-shell">imp system./manager inctype= RECTORE FULL=Y FILE=A
</code></pre>
<h1 id="parfile-shi-yong-fang-fa">parfile使用方法</h1>
<p>建立一个parfile文件，命名为svclogbak.par，内容是一些导出参数，如：</p>
<pre><code class="language-shell">file=svclogbak.dmp                  #导出的文件命名
log=svclogbak.log                   #导出过程中产生的日志信息
tables=(mmsgsvclog_0122_1_o_0,      #括号中存放要导出的相关表信息，以英文逗号分隔
mmsgsvclog_0122_1_o_1,
mmsgsvclog_0122_1_o_2,
mmsgsvclog_20100122_1_s)            #如有需要，可增加其它参数，这里仅作示例
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用parfile文件，可以在不同的操作系统中执行，即是任何OS平台都适用的方法。</p>
</li>
</ul>
<h2 id="dao-chu-1">导出</h2>
<pre><code class="language-shell">exp username/passwd@dbname parfile=svclogbak.par
</code></pre>
<h2 id="dao-ru-1">导入</h2>
<pre><code>imp username/passwd@dbname fromuser=XXX touser=XXX file=svclogbak.dmp ignore=y commit=y
</code></pre>
<p>其中:<br>
fromuser  该选项用于指定从导出文件中摘取并导入特定用于的对象；<br>
touser  该选项用于指定将特定方案对象导入到其他用户。</p>
<p>如果导入导出的用户名一致，可以直接使用如下命令进行导入：</p>
<pre><code class="language-shell">imp username/passwd@dbname  file=svclogbak.dmp ignore=y  commit=y
</code></pre>
<p>或者</p>
<pre><code class="language-shell">imp username/passwd  file=svclogbak.dmp ignore=y commit=y
</code></pre>
<h2 id="biao-ming-huo-qu">表名获取</h2>
<p>通过PLSQL Developer工具获取表名</p>
<p>如果用户安装了PLSQL Developer工具，可以直接在该工具上查询相关的SVC表信息：</p>
<p>（1）按住shift键，选中这些表，按住鼠标拖到右侧新建的SQL窗口</p>
<img class="shadow" src="/img/in-post/oracle-dev-table.png" width="600">
<p>（2）点击“名称”，在SQL窗口中显示所选中的MMSGSVCLOG_X表的名称：</p>
<img class="shadow" src="/img/in-post/oracle-dev-table2.png" width="600">
<p>（3）拷贝这些表名称，修改svclogbak.par文件</p>
<p>将拷贝的表的名称保存在tables=()中的括号中，并保存svclogbak.par文件；</p>
<p>（4）执行导入操作。</p>
<h2 id="cha-xun-biao-cong-sqlplus-zhong-huo-qu">查询表，从sqlplus中获取</h2>
<p>（1）数据库应用用户登录数据库，查询SVC日志表信息：</p>
<pre><code class="language-shell">select * from tab where tname like 'MMSGSVCLOG_%';
</code></pre>
<p>（2）将查询所得的需要备份的MMSGSVCLOG_X表拷贝到svclogbak.par文件中的tables=()中的括号中，并以英文逗号分隔；</p>
<p>（3）执行导入操作。</p>
<h1 id="ce-shi-yan-zheng">测试验证</h1>
<h2 id="parfile-wen-jian-nei-rong">Parfile文件内容</h2>
<pre><code class="language-shell"># cat svclogbak.par
file=svclogbak.dmp
log=svclogbak.log
tables=(mmsgsvclog_0122_1_o_0,
mmsgsvclog_0122_1_o_1,
mmsgsvclog_0122_1_o_2,
mmsgsvclog_0122_1_o_3,
mmsgsvclog_0122_1_o_4,
mmsgsvclog_0122_1_o_5,
mmsgsvclog_0122_1_o_6,
mmsgsvclog_0122_1_o_7,
mmsgsvclog_0122_1_o_8,
mmsgsvclog_0122_1_o_9,
mmsgsvclog_0123_1_o_0,
mmsgsvclog_0123_1_o_1,
mmsgsvclog_0123_1_o_2,
mmsgsvclog_0123_1_o_3,
mmsgsvclog_0123_1_o_4,
mmsgsvclog_0123_1_o_5,
mmsgsvclog_0123_1_o_6,
mmsgsvclog_0123_1_o_7,
mmsgsvclog_0123_1_o_8,
mmsgsvclog_0123_1_o_9,
mmsgsvclog_0124_1_o_0,
mmsgsvclog_0124_1_o_1,
mmsgsvclog_0124_1_o_2,
mmsgsvclog_0124_1_o_3,
mmsgsvclog_0124_1_o_4,
mmsgsvclog_0124_1_o_5,
mmsgsvclog_0124_1_o_6,
mmsgsvclog_0124_1_o_7,
mmsgsvclog_0124_1_o_8,
mmsgsvclog_0124_1_o_9,
mmsgsvclog_0124_2_o_0,
mmsgsvclog_0124_2_o_4,
mmsgsvclog_0124_2_o_5,
mmsgsvclog_0124_2_o_6,
mmsgsvclog_0124_2_o_7,
mmsgsvclog_0124_2_o_8,
mmsgsvclog_0124_2_o_9,
mmsgsvclog_0125_1_o_0,
mmsgsvclog_0125_1_o_1,
mmsgsvclog_0125_1_o_2,
mmsgsvclog_0125_1_o_3,
mmsgsvclog_0125_1_o_4,
mmsgsvclog_0125_1_o_5,
mmsgsvclog_0125_1_o_6,
mmsgsvclog_0125_1_o_7,
mmsgsvclog_0125_1_o_8,
mmsgsvclog_0125_1_o_9,
mmsgsvclog_0126_1_o_0,
mmsgsvclog_0126_1_o_1,
mmsgsvclog_0126_1_o_2,
mmsgsvclog_0126_1_o_3,
mmsgsvclog_0126_1_o_4,
mmsgsvclog_0126_1_o_5,
mmsgsvclog_0126_1_o_6,
mmsgsvclog_0126_1_o_7,
mmsgsvclog_0126_1_o_8,
mmsgsvclog_0126_1_o_9,
mmsgsvclog_0127_1_o_0,
mmsgsvclog_0127_1_o_1,
mmsgsvclog_0127_1_o_2,
mmsgsvclog_0127_1_o_3,
mmsgsvclog_0127_1_o_4,
mmsgsvclog_0127_1_o_5,
mmsgsvclog_0127_1_o_6,
mmsgsvclog_0127_1_o_7,
mmsgsvclog_0127_1_o_8,
mmsgsvclog_0127_1_o_9,
mmsgsvclog_0128_1_o_3,
mmsgsvclog_0128_1_o_4,
mmsgsvclog_20100122_1_s,
mmsgsvclog_20100123_1_s,
mmsgsvclog_20100124_1_s,
mmsgsvclog_20100124_2_s,
mmsgsvclog_20100125_1_s,
mmsgsvclog_20100126_1_s,
mmsgsvclog_20100127_1_s,
mmsgsvclog_20100128_1_s)
</code></pre>
<h2 id="dao-chu-2">导出</h2>
<pre><code class="language-shell">129 node1 [yjh] :/home/yjh/&gt;exp yjh/yjh@mmsgdb parfile=svclogbak.par

Export: Release 11.1.0.7.0 - Production on Thu Jan 28 15:35:11 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
Export done in ZHS16GBK character set and UTF8 NCHAR character set

About to export specified tables via Conventional Path ...
. . exporting table          MMSGSVCLOG_0122_1_O_0        670 rows exported
……………………………………….. ………………………………………..中间数据省略 ……………………………………….. ………………………………………..
. . exporting table        MMSGSVCLOG_20100128_1_S        130 rows exported
Export terminated successfully without warnings.
</code></pre>
<h2 id="wen-jian-xin-xi">文件信息</h2>
<pre><code class="language-shell">130 node1 [yjh] :/home/yjh/&gt;ll
总计 150740
-rw-r--r--  1 yjh users  15056896 2010-01-28 15:35 svclogbak.dmp  #导出的文件名称
-rw-r--r--  1 yjh users      7186 2010-01-28 15:35 svclogbak.log   #导出过程中产生的日志
-rw-r--r--  1 yjh users      2156 2010-01-28 14:29 svclogbak.par
</code></pre>
<h2 id="dao-ru-2">导入</h2>
<pre><code class="language-shell">155 node1 [mmsg] :/home/mmsg&gt;imp mmsg/mmsg fromuser=yjh touser=mmsg file=svclogbak.dmp ignore=y commit=y

Import: Release 11.1.0.7.0 - Production on Thu Jan 28 15:37:55 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

Export file created by EXPORT:V11.01.00 via conventional path

Warning: the objects were exported by YJH, not by you

import done in ZHS16GBK character set and UTF8 NCHAR character set
. importing YJH's objects into MMSG
. . importing table        "MMSGSVCLOG_0122_1_O_0"        670 rows imported
……………………………………….. ………………………………………..中间数据省略 ……………………………………….. ………………………………………..
. . importing table      "MMSGSVCLOG_20100128_1_S"        122 rows imported
Import terminated successfully without warnings.
</code></pre>
<h2 id="shu-ju-ku-quan-biao-dao-chu">数据库全表导出</h2>
<h3 id="jiao-ben">脚本</h3>
<h4 id="fullback-system-sh">fullback_system.sh</h4>
<pre><code class="language-shell">#!/bin/sh

#定义备份时间
backupdate=`date +'%Y%m%d_%H%M%S'`

#定义备份路径
BakPath=/opt/oracle/oracle_table_bak

if [ ! -d $ORACLE_BASE/oracle_table_bak ];then
 mkdir -p $ORACLE_BASE/oracle_table_bak
fi

# 定义oracle用户名和密码
ACCOUNT=system     #用户名称
PASSWORD=sys       #用户密码
SID=mmsgdb         #数据库别名
echo "Please input user name,password and SID to connect to oracle"
#读入用户名
echo "username( system)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    ACCOUNT=$U_INPUT
fi

#读入密码
echo "password( sys)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    PASSWORD=$U_INPUT
fi

#读入SID
echo "SID( mmsgdb)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    SID=$U_INPUT
fi

#系统所在路径
APPHOME=`dirname $0`
if [ $APPHOME = "." ]; then
   APPHOME=`pwd`
fi
cd $APPHOME

#执行导出操作
exp $ACCOUNT/$PASSWORD@$SID file=${ORACLE_BASE}/oracle_table_bak/fullbak_$backupdate.dmp  log=${ORACLE_BASE}/oracle_table_bak/fullbak_$backupdate.log full=y
</code></pre>
<h3 id="dao-chu-guo-cheng-ri-zhi">导出过程日志</h3>
<pre><code class="language-shell">
连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
已导出 ZHS16GBK 字符集和 UTF8 NCHAR 字符集

即将导出整个数据库...
. 正在导出表空间定义
. 正在导出概要文件
. 正在导出用户定义
. 正在导出角色
. 正在导出资源成本
. 正在导出回退段定义
. 正在导出数据库链接
. 正在导出序号
. 正在导出目录别名
. 正在导出上下文名称空间
. 正在导出外部函数库名
. 导出 PUBLIC 类型同义词
. 正在导出专用类型同义词
. 正在导出对象类型定义
. 正在导出系统过程对象和操作
. 正在导出 pre-schema 过程对象和操作
. 正在导出簇定义
. 即将导出 SYSTEM 的表通过常规路径...
. . 正在导出表                     DEF$_AQCALL导出了           0 行
. . 正在导出表                    DEF$_AQERROR导出了           0 行
. . 正在导出表                   DEF$_CALLDEST导出了           0 行
. . 正在导出表                DEF$_DEFAULTDEST导出了           0 行
. . 正在导出表                DEF$_DESTINATION导出了           0 行
. . 正在导出表                      DEF$_ERROR导出了           0 行
. . 正在导出表                        DEF$_LOB导出了           0 行
. . 正在导出表                     DEF$_ORIGIN导出了           0 行
. . 正在导出表                 DEF$_PROPAGATOR导出了           0 行
. . 正在导出表        DEF$_PUSHED_TRANSACTIONS导出了           0 行
. . 正在导出表                   DEF$_TEMP$LOB导出了           0 行
. . 正在导出表                             OL$
. . 正在导出表                        OL$HINTS
. . 正在导出表                        OL$NODES
. . 正在导出表            QUEST_SOO_AT_APPNAME导出了           0 行
. . 正在导出表     QUEST_SOO_AT_EXECUTION_PLAN导出了           0 行
. . 正在导出表         QUEST_SOO_AT_OPERATIONS导出了           0 行
. . 正在导出表       QUEST_SOO_AT_PARSE_CURSOR导出了           0 行
. . 正在导出表        QUEST_SOO_AT_PARSE_ERROR导出了           0 行
. . 正在导出表        QUEST_SOO_AT_PARSE_WAITS导出了           0 行
. . 正在导出表         QUEST_SOO_AT_SESSION_ID导出了           0 行
. . 正在导出表          QUEST_SOO_AT_SQL_BINDS导出了           0 行
. . 正在导出表     QUEST_SOO_AT_SQL_EXECUTIONS导出了           0 行
. . 正在导出表     QUEST_SOO_AT_SQL_EXEC_ERROR导出了           0 行
. . 正在导出表          QUEST_SOO_AT_SQL_FETCH导出了           0 行
. . 正在导出表      QUEST_SOO_AT_SQL_STATEMENT导出了           0 行
. . 正在导出表    QUEST_SOO_AT_SQL_STMT_PIECES导出了           0 行
. . 正在导出表          QUEST_SOO_AT_SQL_WAITS导出了           0 行
. . 正在导出表         QUEST_SOO_AT_TRACE_FILE导出了           0 行
. . 正在导出表         QUEST_SOO_AT_WAIT_NAMES导出了           0 行
. . 正在导出表           QUEST_SOO_BUFFER_BUSY导出了           0 行
. . 正在导出表      QUEST_SOO_EVENT_CATEGORIES导出了        1445 行
. . 正在导出表             QUEST_SOO_LOCK_TREE导出了           0 行
. . 正在导出表      QUEST_SOO_PARSE_TIME_TRACK导出了           1 行
. . 正在导出表            QUEST_SOO_PLAN_TABLE导出了           0 行
. . 正在导出表        QUEST_SOO_SB_BUFFER_BUSY导出了           0 行
. . 正在导出表              QUEST_SOO_SB_EVENT导出了           0 行
. . 正在导出表            QUEST_SOO_SB_IO_STAT导出了           0 行
. . 正在导出表       QUEST_SOO_SCHEMA_VERSIONS导出了           1 行
. . 正在导出表               QUEST_SOO_VERSION导出了           1 行
. . 正在导出表         REPCAT$_AUDIT_ATTRIBUTE导出了           2 行
. . 正在导出表            REPCAT$_AUDIT_COLUMN导出了           0 行
. . 正在导出表            REPCAT$_COLUMN_GROUP导出了           0 行
. . 正在导出表                REPCAT$_CONFLICT导出了           0 行
. . 正在导出表                     REPCAT$_DDL导出了           0 行
. . 正在导出表              REPCAT$_EXCEPTIONS导出了           0 行
. . 正在导出表               REPCAT$_EXTENSION导出了           0 行
. . 正在导出表                 REPCAT$_FLAVORS导出了           0 行
. . 正在导出表          REPCAT$_FLAVOR_OBJECTS导出了           0 行
. . 正在导出表               REPCAT$_GENERATED导出了           0 行
. . 正在导出表          REPCAT$_GROUPED_COLUMN导出了           0 行
. . 正在导出表       REPCAT$_INSTANTIATION_DDL导出了           0 行
. . 正在导出表             REPCAT$_KEY_COLUMNS导出了           0 行
. . 正在导出表            REPCAT$_OBJECT_PARMS导出了           0 行
. . 正在导出表            REPCAT$_OBJECT_TYPES导出了          28 行
. . 正在导出表        REPCAT$_PARAMETER_COLUMN导出了           0 行
. . 正在导出表                REPCAT$_PRIORITY导出了           0 行
. . 正在导出表          REPCAT$_PRIORITY_GROUP导出了           0 行
. . 正在导出表       REPCAT$_REFRESH_TEMPLATES导出了           0 行
. . 正在导出表                  REPCAT$_REPCAT导出了           0 行
. . 正在导出表               REPCAT$_REPCATLOG导出了           0 行
. . 正在导出表               REPCAT$_REPCOLUMN导出了           0 行
. . 正在导出表          REPCAT$_REPGROUP_PRIVS导出了           0 行
. . 正在导出表               REPCAT$_REPOBJECT导出了           0 行
. . 正在导出表                 REPCAT$_REPPROP导出了           0 行
. . 正在导出表               REPCAT$_REPSCHEMA导出了           0 行
. . 正在导出表              REPCAT$_RESOLUTION导出了           0 行
. . 正在导出表       REPCAT$_RESOLUTION_METHOD导出了          19 行
. . 正在导出表   REPCAT$_RESOLUTION_STATISTICS导出了           0 行
. . 正在导出表     REPCAT$_RESOL_STATS_CONTROL导出了           0 行
. . 正在导出表           REPCAT$_RUNTIME_PARMS导出了           0 行
. . 正在导出表               REPCAT$_SITES_NEW导出了           0 行
. . 正在导出表            REPCAT$_SITE_OBJECTS导出了           0 行
. . 正在导出表               REPCAT$_SNAPGROUP导出了           0 行
. . 正在导出表        REPCAT$_TEMPLATE_OBJECTS导出了           0 行
. . 正在导出表          REPCAT$_TEMPLATE_PARMS导出了           0 行
. . 正在导出表      REPCAT$_TEMPLATE_REFGROUPS导出了           0 行
. . 正在导出表          REPCAT$_TEMPLATE_SITES导出了           0 行
. . 正在导出表         REPCAT$_TEMPLATE_STATUS导出了           3 行
. . 正在导出表        REPCAT$_TEMPLATE_TARGETS导出了           0 行
. . 正在导出表          REPCAT$_TEMPLATE_TYPES导出了           2 行
. . 正在导出表     REPCAT$_USER_AUTHORIZATIONS导出了           0 行
. . 正在导出表        REPCAT$_USER_PARM_VALUES导出了           0 行
. . 正在导出表         SQLPLUS_PRODUCT_PROFILE导出了           0 行
. 即将导出 OUTLN 的表通过常规路径...
. . 正在导出表                             OL$导出了           0 行
. . 正在导出表                        OL$HINTS导出了           0 行
. . 正在导出表                        OL$NODES导出了           0 行
. 即将导出 TSMSYS 的表通过常规路径...
. . 正在导出表                            SRS$导出了           0 行
. 即将导出 MMSG 的表通过常规路径...
. . 正在导出表                        AREAINFO导出了         374 行
. . 正在导出表                      AREANUMBER导出了         364 行
. . 正在导出表                AREANUMBERPREFIX导出了           2 行
. . 正在导出表                 BEARERVALUELIST导出了           3 行
. . 正在导出表                     CARRIERINFO导出了           1 行
. . 正在导出表                CHARGINGKPCONFIG导出了          28 行
. . 正在导出表                  CONNECTIONINFO导出了           0 行
. . 正在导出表                     COUNTRYCODE导出了          21 行
. . 正在导出表              DATAFILESTATUSCODE导出了           0 行
. . 正在导出表                DETAILSTATUSCODE导出了         247 行
. . 正在导出表                      DNSSRVINFO导出了           0 行
. . 正在导出表                   DRMACCESSCODE导出了           0 行
. . 正在导出表                      ECTOSIINFO导出了           0 行
. . 正在导出表                     ENUMSRVINFO导出了           1 行
. . 正在导出表                   EXP_CACHESTAT导出了           4 行
. . 正在导出表                     HISTORYFLOW导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100319导出了         158 行
. . 正在导出表       INTERFACEACCOUNT_20100320导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100321导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100322导出了          60 行
. . 正在导出表       INTERFACEACCOUNT_20100323导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100324导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100325导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100326导出了         270 行
. . 正在导出表       INTERFACEACCOUNT_20100327导出了         421 行
. . 正在导出表       INTERFACEACCOUNT_20100328导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100329导出了           0 行
. . 正在导出表                     INTERPREFIX导出了          21 行
. . 正在导出表                IPRANGEPARTITION导出了          93 行
. . 正在导出表                         MESSAGE导出了           0 行
. . 正在导出表                MESSAGEREFERENCE导出了           0 行
. . 正在导出表             MESSAGESENDSCHEDULE导出了          15 行
. . 正在导出表                      MIBLEAFINT导出了          79 行
. . 正在导出表                      MIBLEAFSTR导出了           8 行
. . 正在导出表                        MISCINFO导出了           2 行
. . 正在导出表                 MISCROUTERTABLE导出了           7 行
. . 正在导出表                       MMBOXTYPE导出了           5 行
. . 正在导出表            MMINTERFACELEVELINFO导出了           2 行
. . 正在导出表                        MMSCINFO导出了           2 行
. . 正在导出表                      MMSCIPINFO导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP00导出了          30 行
. . 正在导出表              MMSGMMSCMSGIDMAP01导出了          25 行
. . 正在导出表              MMSGMMSCMSGIDMAP02导出了          35 行
. . 正在导出表              MMSGMMSCMSGIDMAP03导出了          27 行
. . 正在导出表              MMSGMMSCMSGIDMAP04导出了          29 行
. . 正在导出表              MMSGMMSCMSGIDMAP05导出了          35 行
. . 正在导出表              MMSGMMSCMSGIDMAP06导出了          29 行
. . 正在导出表              MMSGMMSCMSGIDMAP07导出了          48 行
. . 正在导出表              MMSGMMSCMSGIDMAP08导出了          16 行
. . 正在导出表              MMSGMMSCMSGIDMAP09导出了          30 行
. . 正在导出表              MMSGMMSCMSGIDMAP10导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP11导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP12导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP13导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP14导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP15导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP16导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP17导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP18导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP19导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP20导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP21导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP22导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP23导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP24导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP25导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP26导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP27导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP28导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP29导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP30导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP31导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP32导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP33导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP34导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP35导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP36导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP37导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP38导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP39导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP40导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP41导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP42导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP43导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP44导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP45导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP46导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP47导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP48导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP49导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP50导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP51导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP52导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP53导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP54导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP55导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP56导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP57导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP58导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP59导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP60导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP61导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP62导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP63导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP64导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP65导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP66导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP67导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP68导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP69导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP70导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP71导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP72导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP73导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP74导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP75导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP76导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP77导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP78导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP79导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP80导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP81导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP82导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP83导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP84导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP85导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP86导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP87导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP88导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP89导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP90导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP91导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP92导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP93导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP94导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP95导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP96导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP97导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP98导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP99导出了           0 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_0导出了          55 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_1导出了          37 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_2导出了          20 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_3导出了          34 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_4导出了          41 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_5导出了          70 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_6导出了          18 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_7导出了          51 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_8导出了          32 行
. . 正在导出表           MMSGSVCLOG_0319_1_O_9导出了          35 行
. . 正在导出表           MMSGSVCLOG_0322_1_O_0导出了          25 行
. . 正在导出表           MMSGSVCLOG_0322_1_O_1导出了          11 行
. . 正在导出表           MMSGSVCLOG_0322_1_O_2导出了          17 行
. . 正在导出表           MMSGSVCLOG_0322_1_O_3导出了          13 行
. . 正在导出表           MMSGSVCLOG_0322_1_O_5导出了           9 行
. . 正在导出表           MMSGSVCLOG_0322_1_O_6导出了          30 行
. . 正在导出表           MMSGSVCLOG_0322_1_O_9导出了          16 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_0导出了         903 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_1导出了        1106 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_2导出了        1206 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_3导出了        1173 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_4导出了        1276 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_5导出了        1075 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_6导出了        1178 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_7导出了         981 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_8导出了         974 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_9导出了         781 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_0导出了        2203 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_1导出了        2165 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_2导出了        2334 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_3导出了        2102 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_4导出了        2118 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_5导出了        2256 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_6导出了        2253 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_7导出了        2556 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_8导出了        2443 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_9导出了        2660 行
. . 正在导出表         MMSGSVCLOG_20100319_1_S导出了          91 行
. . 正在导出表         MMSGSVCLOG_20100322_1_S导出了          28 行
. . 正在导出表         MMSGSVCLOG_20100326_1_S导出了        1328 行
. . 正在导出表         MMSGSVCLOG_20100327_1_S导出了        3168 行
. . 正在导出表                       MMSTARIFF导出了           1 行
. . 正在导出表                       MODULECMD导出了          18 行
. . 正在导出表                         MODULES导出了          17 行
. . 正在导出表                  MONITOREDUSERS导出了           0 行
. . 正在导出表                 MONITORPERFSTAT导出了          12 行
. . 正在导出表                MONTHORDERINFO_0导出了           0 行
. . 正在导出表                MONTHORDERINFO_1导出了           0 行
. . 正在导出表                MONTHORDERINFO_2导出了           0 行
. . 正在导出表                MONTHORDERINFO_3导出了           0 行
. . 正在导出表                MONTHORDERINFO_4导出了           0 行
. . 正在导出表                MONTHORDERINFO_5导出了           0 行
. . 正在导出表                MONTHORDERINFO_6导出了           0 行
. . 正在导出表                MONTHORDERINFO_7导出了           0 行
. . 正在导出表                MONTHORDERINFO_8导出了           0 行
. . 正在导出表                MONTHORDERINFO_9导出了           0 行
. . 正在导出表                    NATIVEPREFIX导出了           1 行
. . 正在导出表                     NETWORKCODE导出了          24 行
. . 正在导出表               PORTALLOG20100322导出了          10 行
. . 正在导出表               PORTALLOG20100325导出了          20 行
. . 正在导出表               PORTALLOG20100326导出了         166 行
. . 正在导出表               PORTALLOG20100327导出了          84 行
. . 正在导出表               PORTALLOG20100329导出了           4 行
. . 正在导出表                 PPSNUMBERPREFIX导出了           0 行
. . 正在导出表                 PROHIBITEDRIGHT导出了           0 行
. . 正在导出表                    REALTIMEFLOW导出了           0 行
. . 正在导出表                   RENTALFEEINFO导出了           1 行
. . 正在导出表                       RIGHTINFO导出了         249 行
. . 正在导出表                            ROLE导出了           4 行
. . 正在导出表                    ROLEMAPRIGHT导出了         518 行
. . 正在导出表                     ROUTERTABLE导出了           5 行
. . 正在导出表                  RPT_BUSYSERVER导出了         240 行
. . 正在导出表                   RPT_DELAYTIME导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100319导出了          41 行
. . 正在导出表          RPT_DELAYTIME_20100320导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100321导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100322导出了          13 行
. . 正在导出表          RPT_DELAYTIME_20100323导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100324导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100325导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100326导出了          91 行
. . 正在导出表          RPT_DELAYTIME_20100327导出了         151 行
. . 正在导出表          RPT_DELAYTIME_20100328导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100329导出了           0 行
. . 正在导出表                   RPT_INTERFACE导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100319导出了          79 行
. . 正在导出表          RPT_INTERFACE_20100320导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100321导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100322导出了          31 行
. . 正在导出表          RPT_INTERFACE_20100323导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100324导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100325导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100326导出了         117 行
. . 正在导出表          RPT_INTERFACE_20100327导出了         259 行
. . 正在导出表          RPT_INTERFACE_20100328导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100329导出了           0 行
. . 正在导出表                RPT_MM7_VASPSUCC导出了          46 行
. . 正在导出表                    RPT_MMSCSUCC导出了          28 行
. . 正在导出表               RPT_MMSC_20100319导出了           0 行
. . 正在导出表               RPT_MMSC_20100320导出了           0 行
. . 正在导出表               RPT_MMSC_20100321导出了           0 行
. . 正在导出表               RPT_MMSC_20100322导出了           0 行
. . 正在导出表               RPT_MMSC_20100323导出了           0 行
. . 正在导出表               RPT_MMSC_20100324导出了           0 行
. . 正在导出表               RPT_MMSC_20100325导出了           0 行
. . 正在导出表               RPT_MMSC_20100326导出了           0 行
. . 正在导出表               RPT_MMSC_20100327导出了           0 行
. . 正在导出表               RPT_MMSC_20100328导出了           0 行
. . 正在导出表               RPT_MMSC_20100329导出了           0 行
. . 正在导出表               RPT_TERMINALCOUNT导出了           0 行
. . 正在导出表                    RPT_USECOUNT导出了           0 行
. . 正在导出表               RPT_USEOFSPSERVER导出了           0 行
. . 正在导出表               RPT_VASP_20100319导出了           0 行
. . 正在导出表               RPT_VASP_20100320导出了           0 行
. . 正在导出表               RPT_VASP_20100321导出了           0 行
. . 正在导出表               RPT_VASP_20100322导出了           0 行
. . 正在导出表               RPT_VASP_20100323导出了           0 行
. . 正在导出表               RPT_VASP_20100324导出了           0 行
. . 正在导出表               RPT_VASP_20100325导出了           0 行
. . 正在导出表               RPT_VASP_20100326导出了           0 行
. . 正在导出表               RPT_VASP_20100327导出了           0 行
. . 正在导出表               RPT_VASP_20100328导出了           0 行
. . 正在导出表               RPT_VASP_20100329导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100319导出了          81 行
. . 正在导出表         SERVICEACCOUNT_20100320导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100321导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100322导出了          16 行
. . 正在导出表         SERVICEACCOUNT_20100323导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100324导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100325导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100326导出了         170 行
. . 正在导出表         SERVICEACCOUNT_20100327导出了         268 行
. . 正在导出表         SERVICEACCOUNT_20100328导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100329导出了           0 行
. . 正在导出表                          SIINFO导出了           0 行
. . 正在导出表                     SMSNOTEINFO导出了           4 行
. . 正在导出表               SMSPROTOCOLCONFIG导出了           0 行
. . 正在导出表                 SPECIALCUSTINFO导出了           0 行
. . 正在导出表                   SUBMITRESINFO导出了         128 行
. . 正在导出表                     SYSOPERATOR导出了          13 行
. . 正在导出表                 SYSTEMPARAMETER导出了         335 行
. . 正在导出表                 SZXNUMBERPREFIX导出了           0 行
. . 正在导出表               TERMINALBLACKLIST导出了           2 行
. . 正在导出表               TMP_ATTACH_RESULT导出了           0 行
. . 正在导出表                 TMP_BASE_RESULT导出了           0 行
. . 正在导出表                      TMP_RESULT导出了           0 行
. . 正在导出表                    TMP_RESULTID导出了           0 行
. . 正在导出表                   TMP_RESULTMEM导出了           0 行
. . 正在导出表                    TRACEMSGINFO导出了           0 行
. . 正在导出表                       UAPROFILE导出了           2 行
. . 正在导出表                        VASPINFO导出了          13 行
. . 正在导出表                   VASPLEVELINFO导出了           2 行
. . 正在导出表                VASPPRIORITYINFO导出了           5 行
. . 正在导出表                 VASPRIORITYINFO导出了           5 行
. . 正在导出表                 VASPSERVICE_SUP导出了          15 行
. . 正在导出表               VASSERVEDAREALIST导出了           1 行
. . 正在导出表                VASSUBSCRIBEINFO导出了           0 行
. . 正在导出表               VCARRIERNBRPREFIX导出了           5 行
. . 正在导出表              VIRTUALCARRIERINFO导出了           1 行
. . 正在导出表             VIRTUALCARRIERLEVEL导出了           1 行
. . 正在导出表                     VPNCORP_100导出了           3 行
. . 正在导出表                     VPNCORP_300导出了           3 行
. . 正在导出表                   VPNSUBSCRIBER导出了           6 行
. . 正在导出表                  VPNUNITECORPID导出了           1 行
. 即将导出 YJH 的表通过常规路径...
. . 正在导出表                        AREAINFO导出了         374 行
. . 正在导出表                      AREANUMBER导出了         364 行
. . 正在导出表                AREANUMBERPREFIX导出了           2 行
. . 正在导出表                 BEARERVALUELIST导出了           3 行
. . 正在导出表                     CARRIERINFO导出了           1 行
. . 正在导出表                CHARGINGKPCONFIG导出了          28 行
. . 正在导出表                  CONNECTIONINFO导出了           0 行
. . 正在导出表                     COUNTRYCODE导出了          21 行
. . 正在导出表              DATAFILESTATUSCODE导出了           0 行
. . 正在导出表                DETAILSTATUSCODE导出了         247 行
. . 正在导出表                      DNSSRVINFO导出了           0 行
. . 正在导出表                   DRMACCESSCODE导出了           0 行
. . 正在导出表                      ECTOSIINFO导出了           0 行
. . 正在导出表                     ENUMSRVINFO导出了           1 行
. . 正在导出表                   EXP_CACHESTAT导出了           0 行
. . 正在导出表                     HISTORYFLOW导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100322导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100323导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100324导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100326导出了          20 行
. . 正在导出表       INTERFACEACCOUNT_20100327导出了         135 行
. . 正在导出表       INTERFACEACCOUNT_20100328导出了           0 行
. . 正在导出表       INTERFACEACCOUNT_20100329导出了           0 行
. . 正在导出表                     INTERPREFIX导出了          21 行
. . 正在导出表                IPRANGEPARTITION导出了          93 行
. . 正在导出表                         MESSAGE导出了           0 行
. . 正在导出表                MESSAGEREFERENCE导出了           0 行
. . 正在导出表             MESSAGESENDSCHEDULE导出了          15 行
. . 正在导出表                      MIBLEAFINT导出了          79 行
. . 正在导出表                      MIBLEAFSTR导出了           9 行
. . 正在导出表                        MISCINFO导出了           2 行
. . 正在导出表                 MISCROUTERTABLE导出了           9 行
. . 正在导出表                       MMBOXTYPE导出了           5 行
. . 正在导出表            MMINTERFACELEVELINFO导出了           2 行
. . 正在导出表                        MMSCINFO导出了           2 行
. . 正在导出表                      MMSCIPINFO导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP00导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP01导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP02导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP03导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP04导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP05导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP06导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP07导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP08导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP09导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP10导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP11导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP12导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP13导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP14导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP15导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP16导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP17导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP18导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP19导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP20导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP21导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP22导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP23导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP24导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP25导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP26导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP27导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP28导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP29导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP30导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP31导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP32导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP33导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP34导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP35导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP36导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP37导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP38导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP39导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP40导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP41导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP42导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP43导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP44导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP45导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP46导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP47导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP48导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP49导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP50导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP51导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP52导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP53导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP54导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP55导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP56导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP57导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP58导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP59导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP60导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP61导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP62导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP63导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP64导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP65导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP66导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP67导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP68导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP69导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP70导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP71导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP72导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP73导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP74导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP75导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP76导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP77导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP78导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP79导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP80导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP81导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP82导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP83导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP84导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP85导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP86导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP87导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP88导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP89导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP90导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP91导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP92导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP93导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP94导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP95导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP96导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP97导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP98导出了           0 行
. . 正在导出表              MMSGMMSCMSGIDMAP99导出了           0 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_0导出了           5 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_1导出了          10 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_3导出了           9 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_5导出了           9 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_7导出了           5 行
. . 正在导出表           MMSGSVCLOG_0326_1_O_8导出了           5 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_0导出了          56 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_1导出了          47 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_2导出了          30 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_3导出了          65 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_4导出了          10 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_5导出了          24 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_6导出了          48 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_7导出了          30 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_8导出了          76 行
. . 正在导出表           MMSGSVCLOG_0327_1_O_9导出了          96 行
. . 正在导出表         MMSGSVCLOG_20100326_1_S导出了           7 行
. . 正在导出表         MMSGSVCLOG_20100327_1_S导出了          82 行
. . 正在导出表                       MMSTARIFF导出了           1 行
. . 正在导出表                       MODULECMD导出了          18 行
. . 正在导出表                         MODULES导出了          17 行
. . 正在导出表                  MONITOREDUSERS导出了           0 行
. . 正在导出表                 MONITORPERFSTAT导出了           0 行
. . 正在导出表                MONTHORDERINFO_0导出了           0 行
. . 正在导出表                MONTHORDERINFO_1导出了           0 行
. . 正在导出表                MONTHORDERINFO_2导出了           0 行
. . 正在导出表                MONTHORDERINFO_3导出了           0 行
. . 正在导出表                MONTHORDERINFO_4导出了           0 行
. . 正在导出表                MONTHORDERINFO_5导出了           0 行
. . 正在导出表                MONTHORDERINFO_6导出了           0 行
. . 正在导出表                MONTHORDERINFO_7导出了           0 行
. . 正在导出表                MONTHORDERINFO_8导出了           0 行
. . 正在导出表                MONTHORDERINFO_9导出了           0 行
. . 正在导出表                    NATIVEPREFIX导出了           1 行
. . 正在导出表                     NETWORKCODE导出了          24 行
. . 正在导出表               PORTALLOG20100322导出了          10 行
. . 正在导出表               PORTALLOG20100326导出了          10 行
. . 正在导出表               PORTALLOG20100327导出了          52 行
. . 正在导出表                 PPSNUMBERPREFIX导出了           0 行
. . 正在导出表                 PROHIBITEDRIGHT导出了           0 行
. . 正在导出表                    REALTIMEFLOW导出了           0 行
. . 正在导出表                   RENTALFEEINFO导出了           1 行
. . 正在导出表                       RIGHTINFO导出了         249 行
. . 正在导出表                            ROLE导出了           4 行
. . 正在导出表                    ROLEMAPRIGHT导出了         518 行
. . 正在导出表                     ROUTERTABLE导出了           5 行
. . 正在导出表                  RPT_BUSYSERVER导出了          67 行
. . 正在导出表                   RPT_DELAYTIME导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100322导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100323导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100324导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100326导出了           5 行
. . 正在导出表          RPT_DELAYTIME_20100327导出了          33 行
. . 正在导出表          RPT_DELAYTIME_20100328导出了           0 行
. . 正在导出表          RPT_DELAYTIME_20100329导出了           0 行
. . 正在导出表                   RPT_INTERFACE导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100322导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100323导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100324导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100326导出了           6 行
. . 正在导出表          RPT_INTERFACE_20100327导出了          85 行
. . 正在导出表          RPT_INTERFACE_20100328导出了           0 行
. . 正在导出表          RPT_INTERFACE_20100329导出了           0 行
. . 正在导出表                RPT_MM7_VASPSUCC导出了           8 行
. . 正在导出表                    RPT_MMSCSUCC导出了           6 行
. . 正在导出表               RPT_MMSC_20100322导出了           0 行
. . 正在导出表               RPT_MMSC_20100323导出了           0 行
. . 正在导出表               RPT_MMSC_20100324导出了           0 行
. . 正在导出表               RPT_MMSC_20100326导出了           0 行
. . 正在导出表               RPT_MMSC_20100327导出了           0 行
. . 正在导出表               RPT_MMSC_20100328导出了           0 行
. . 正在导出表               RPT_MMSC_20100329导出了           0 行
. . 正在导出表               RPT_TERMINALCOUNT导出了           0 行
. . 正在导出表                    RPT_USECOUNT导出了           0 行
. . 正在导出表               RPT_USEOFSPSERVER导出了           0 行
. . 正在导出表               RPT_VASP_20100322导出了           0 行
. . 正在导出表               RPT_VASP_20100323导出了           0 行
. . 正在导出表               RPT_VASP_20100324导出了           0 行
. . 正在导出表               RPT_VASP_20100326导出了           0 行
. . 正在导出表               RPT_VASP_20100327导出了           0 行
. . 正在导出表               RPT_VASP_20100328导出了           0 行
. . 正在导出表               RPT_VASP_20100329导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100322导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100323导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100324导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100326导出了           5 行
. . 正在导出表         SERVICEACCOUNT_20100327导出了          44 行
. . 正在导出表         SERVICEACCOUNT_20100328导出了           0 行
. . 正在导出表         SERVICEACCOUNT_20100329导出了           0 行
. . 正在导出表                          SIINFO导出了           0 行
. . 正在导出表                     SMSNOTEINFO导出了           4 行
. . 正在导出表               SMSPROTOCOLCONFIG导出了           0 行
. . 正在导出表                 SPECIALCUSTINFO导出了           0 行
. . 正在导出表                   SUBMITRESINFO导出了         128 行
. . 正在导出表                     SYSOPERATOR导出了          13 行
. . 正在导出表                 SYSTEMPARAMETER导出了         335 行
. . 正在导出表                 SZXNUMBERPREFIX导出了           0 行
. . 正在导出表               TERMINALBLACKLIST导出了           2 行
. . 正在导出表               TMP_ATTACH_RESULT导出了           0 行
. . 正在导出表                 TMP_BASE_RESULT导出了           0 行
. . 正在导出表                      TMP_RESULT导出了           0 行
. . 正在导出表                    TMP_RESULTID导出了           0 行
. . 正在导出表                   TMP_RESULTMEM导出了           0 行
. . 正在导出表                    TRACEMSGINFO导出了           0 行
. . 正在导出表                       UAPROFILE导出了           2 行
. . 正在导出表                        VASPINFO导出了          13 行
. . 正在导出表                   VASPLEVELINFO导出了           2 行
. . 正在导出表                VASPPRIORITYINFO导出了           5 行
. . 正在导出表                 VASPRIORITYINFO导出了           5 行
. . 正在导出表                 VASPSERVICE_SUP导出了          15 行
. . 正在导出表               VASSERVEDAREALIST导出了           1 行
. . 正在导出表                VASSUBSCRIBEINFO导出了           0 行
. . 正在导出表               VCARRIERNBRPREFIX导出了           5 行
. . 正在导出表              VIRTUALCARRIERINFO导出了           1 行
. . 正在导出表             VIRTUALCARRIERLEVEL导出了           1 行
. . 正在导出表                     VPNCORP_100导出了           3 行
. . 正在导出表                     VPNCORP_300导出了           3 行
. . 正在导出表                   VPNSUBSCRIBER导出了           6 行
. . 正在导出表                  VPNUNITECORPID导出了           1 行
. 正在导出同义词
. 正在导出视图
. 正在导出引用完整性约束条件
. 正在导出存储过程
. 正在导出运算符
. 正在导出索引类型
. 正在导出位图, 功能性索引和可扩展索引
. 正在导出后期表活动
. 正在导出触发器
. 正在导出实体化视图
. 正在导出快照日志
. 正在导出作业队列
. 正在导出刷新组和子组
. 正在导出维
. 正在导出 post-schema 过程对象和操作
. 正在导出用户历史记录表
. 正在导出默认值和系统审计选项
. 正在导出统计信息
成功终止导出, 没有出现警告。
</code></pre>
<h2 id="shu-ju-ku-quan-biao-dao-ru">数据库全表导入</h2>
<pre><code class="language-shell">imp username/password@sid  file=XXX.dmp  ignore=y  commit=y  full=y
</code></pre>
<p>例如：</p>
<pre><code class="language-shell">imp system/sys@mmsgdb  file=./fullbak_20100329_104203.dmp ignore=y  commit=y  full=y
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>.dmp文件必须以bin方式从节点一1 ftp到节点2</p>
</li>
</ul>
<h2 id="ying-yong-shu-ju-ku-quan-biao-dao-chu">应用数据库全表导出</h2>
<h3 id="jiao-ben-1">脚本</h3>
<pre><code class="language-shell">#!/bin/sh

#定义备份时间
backupdate=`date +'%Y%m%d_%H%M%S'`

#定义备份路径
BakPath=/opt/oracle/oracle_table_bak

if [ ! -d $ORACLE_BASE/oracle_table_bak ];then
 mkdir -p $ORACLE_BASE/oracle_table_bak
fi

# 定义oracle用户名和密码
ACCOUNT=mmsg     #用户名称
PASSWORD=mmsg       #用户密码
SID=mmsgdb         #数据库别名
echo "Please input user name,password and SID to connect to oracle"
#读入用户名
echo "username(mmsg)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    ACCOUNT=$U_INPUT
fi

#读入密码
echo "password(mmsg)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    PASSWORD=$U_INPUT
fi

#读入SID
echo "SID( mmsgdb)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    SID=$U_INPUT
fi

#系统所在路径
APPHOME=`dirname $0`
if [ $APPHOME = "." ]; then
   APPHOME=`pwd`
fi
cd $APPHOME

#执行导出操作
exp $ACCOUNT/$PASSWORD@$SID file=${ORACLE_BASE}/oracle_table_bak/fullbak_$backupdate.dmp  log=${ORACLE_BASE}/oracle_table_bak/fullbak_$backupdate.log full=y
</code></pre>
<h3 id="dao-chu-guo-cheng-ri-zhi-1">导出过程日志</h3>
<pre><code class="language-shell">oracle@mmsg:~&gt; sh fullbak_mmsg.sh 
Please input user name,password and SID to connect to oracle
username(mmsg)

password(mmsg)

SID( mmsgdb)


Export: Release 11.1.0.7.0 - Production on 星期一 3月 29 11:50:28 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
EXP-00023: 必须是 DBA 才能执行完整数据库或表空间导出操作
(2)U(用户), 或 (3)T(表): (2)U &gt;   #直接按回车键

导出权限 (yes/no): yes &gt;    #直接按回车键

导出表数据 (yes/no): yes &gt;  #直接按回车键

压缩区 (yes/no): yes &gt;      #直接按回车键

已导出 ZHS16GBK 字符集和 UTF8 NCHAR 字符集
. 正在导出 pre-schema 过程对象和操作
. 正在导出用户 MMSG 的外部函数库名
. 导出 PUBLIC 类型同义词
. 正在导出专用类型同义词
. 正在导出用户 MMSG 的对象类型定义
即将导出 MMSG 的对象...
. 正在导出数据库链接
. 正在导出序号
. 正在导出簇定义
. 即将导出 MMSG 的表通过常规路径...
. . 正在导出表                        AREAINFO导出了         374 行
. . 正在导出表                      AREANUMBER导出了         364 行
. . 正在导出表                AREANUMBERPREFIX导出了           2 行
. . 正在导出表                 BEARERVALUELIST导出了           3 行
. . 正在导出表                     CARRIERINFO导出了           1 行
. . 正在导出表                CHARGINGKPCONFIG导出了          28 行
. . 正在导出表                  CONNECTIONINFO导出了           0 行
. . 正在导出表                     COUNTRYCODE导出了          21 行
. . 正在导出表              DATAFILESTATUSCODE导出了           0 行
. . 正在导出表                DETAILSTATUSCODE导出了         247 行
……………………………………….. ………………………………………..中间数据省略 ……………………………………….. ………………………………………..
. . 正在导出表                   VPNSUBSCRIBER导出了           6 行
. . 正在导出表                  VPNUNITECORPID导出了           1 行
. 正在导出同义词
. 正在导出视图
. 正在导出存储过程
. 正在导出运算符
. 正在导出引用完整性约束条件
. 正在导出触发器
. 正在导出索引类型
. 正在导出位图, 功能性索引和可扩展索引
. 正在导出后期表活动
. 正在导出实体化视图
. 正在导出快照日志
. 正在导出作业队列
. 正在导出刷新组和子组
. 正在导出维
. 正在导出 post-schema 过程对象和操作
. 正在导出统计信息
导出成功终止, 但出现警告。
#这里告警，是因为只有DBA用户才能进行全表导出操作，根据提示信息按回车 进行下一步操作就可以了，不影响实际使用。
oracle@mmsg:~&gt;
</code></pre>
<h3 id="ying-yong-shu-ju-ku-quan-biao-dao-ru">应用数据库全表导入</h3>
<pre><code class="language-shell">imp  username/passwd@sid file=XXX.dmp ignore=y commit=y  full=y
</code></pre>
<p>或者</p>
<pre><code class="language-shell">imp username/passwd@dbname fromuser=XXX touser=XXX file= XXX.dmp ignore=y commit=y full=y
</code></pre>
<p>其中</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>fromuser  该选项用于指定从导出文件中摘取并导入特定用于的对象；</p>
</li>
<li class="lvl-2">
<p>touser 该选项用于指定将特定方案对象导入到其他用户。</p>
</li>
</ul>
<p>例如：</p>
<pre><code class="language-shell">imp mmsg/mmsg@mmsgdb fromuser=mmsg touser=yjh  file=./fullbak_20100329_104203.dmp ignore=y commit=y  full=y
</code></pre>
<p>如果导入导出的用户名一致，可以直接使用如下命令进行导入：</p>
<pre><code class="language-shell">imp mmsg/mmsg@mmsgdb  file=./fullbak_20100329_104203.dmp ignore=y commit=y  full=y
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>.dmp文件必须以bin方式从节点1 ftp到节点2</p>
</li>
</ul>
<h3 id="zai-aix-6-1-shang-yan-zheng-jie-guo">在AIX6.1上验证结果</h3>
<pre><code class="language-shell">% imp mmsg/mmsg@iagw file=fullbak_20100329_115026.dmp  ignore=y commit=y  full=y

Import: Release 11.1.0.6.0 - Production on 星期一 3月 29 23:33:09 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to: Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing option

Export file created by EXPORT:V11.01.00 via conventional path
import done in ZHS16GBK character set and AL16UTF16 NCHAR character set
export server uses UTF8 NCHAR character set (possible ncharset conversion)
. importing MMSG's objects into MMSG
. . importing table                     "AREAINFO"        374 rows imported
. . importing table                   "AREANUMBER"        364 rows imported
……………………………………….. ………………………………………..中间数据省略 ……………………………………….. ………………………………………..
. . importing table                "VPNSUBSCRIBER"          6 rows imported
. . importing table               "VPNUNITECORPID"          1 rows imported
Import terminated successfully without warnings.
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle SQL篇之表</title>
    <url>/2010/04/19/oracle_sql_table/</url>
    <content><![CDATA[<h1 id="cha-kan-biao-jie-gou">查看表结构</h1>
<pre><code class="language-shell">desc tablename
</code></pre>
<h1 id="xing-shu">行数</h1>
<pre><code class="language-shell">rownum
</code></pre>
<h1 id="cha-xun-yong-hu-zhi-xing-guo-na-xie-sql-cao-zuo">查询用户执行过哪些sql操作</h1>
<pre><code class="language-shell">select * from v$sqlarea t where t.PARSING_SCHEMA_NAME in ('WYZ') order by t.LAST_ACTIVE_TIME desc
</code></pre>
<h1 id="suo-biao">锁表</h1>
<pre><code class="language-shell">LOCK TABLE table1,table2,table3 IN ROW EXCLUSIVE MODE;
</code></pre>
<h1 id="shi-jin-zhi-shi-liu-jin-zhi-zhuan-huan">十进制十六进制转换</h1>
<pre><code class="language-shell">to_char(1212,'xxxx'),to_number('4bc','xxx') from dual
</code></pre>
<h1 id="cha-kan-biao-da-xiao">查看表大小</h1>
<p>有两种含义的表大小：一种是分配给一个表的物理空间数量，而不管空间是否被使用。可以这样查询获得字节数：</p>
<pre><code class="language-shell">select segment_name, bytes 
from user_segments 
where segment_type = 'TABLE'; 
</code></pre>
<p>或者</p>
<pre><code class="language-shell">Select Segment_Name,Sum(bytes)/1024/1024 From User_Extents Group By Segment_Name
</code></pre>
<p>另一种表实际使用的空间。这样查询：</p>
<pre><code class="language-shell">analyze table AREAINFO compute statistics; 

select   TABLE_NAME,TABLESPACE_NAME, NUM_ROWS ,AVG_ROW_LEN,  NUM_ROWS*AVG_ROW_LEN   
from user_tables 
where table_name = 'AREAINFO';
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>表名称要大写，红色加粗部分。</p>
</li>
</ul>
<h1 id="cha-kan-mei-ge-biao-kong-jian-de-da-xiao">查看每个表空间的大小</h1>
<p><code>Select Tablespace_Name,Sum(bytes)/1024/1024 From Dba_Segments Group By Tablespace_Name </code></p>
<h1 id="kuai-su-zuo-biao-bei-fen">快速做表备份</h1>
<p><code>create table table_name as select *  from table; </code></p>
<p>这个是创建和table表一样的表tablke_name，包含原table表中的数据信息；</p>
<p><code>create table table_name as select * from table where 1 = 2; </code></p>
<p>这个是创建和table表一样的表tablke_name，包不包含原table表中的数据信息，即为一张空表。</p>
<h1 id="ji-suan-yi-ge-biao-zhan-yong-de-kong-jian-de-da-xiao">计算一个表占用的空间的大小</h1>
<p><code>select owner,table_name,NUM_FREELIST_BLOCKS,LAST_ANALYZED,BLOCKS*AAA/1024/1024 "Size M" from dba_tables   where table_name='XXX'; </code></p>
<p>Here:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>AAA is the value of db_block_size;</p>
</li>
<li class="lvl-2">
<p>XXX is the table name you want to check</p>
</li>
</ul>
<p>或者</p>
<pre><code class="language-shell">select sum(bytes)/(1024*1024) as "size(M)" from user_segments 
where segment_name=upper('&amp;table_name');
</code></pre>
<h1 id="cha-xun-shu-ju-ku-you-duo-shao-biao">查询数据库有多少表</h1>
<pre><code class="language-shell">SQL&gt; select * from all_tables；
SQL&gt; select count(0) from all_tables;

  COUNT(0)
----------
      1331

SQL&gt;
</code></pre>
<h1 id="cha-xun-biao-zhong-zhu-jian-xin-xi">查询表中主键信息</h1>
<pre><code class="language-shell">select cu.* from user_cons_columns cu, user_constraints au 
where 
    cu.constraint_name = au.constraint_name  
and 
   au.constraint_type = 'P' and au.table_name ='RPT_DELAYTIME_20100828';
</code></pre>
<h1 id="cha-xun-biao-de-suo-you-suo-yin">查询表的所有索引</h1>
<pre><code class="language-shell">select t.*,i.index_type 
from user_ind_columns t,user_indexes i 
where 
      t.index_name = i.index_name 
and   
      t.table_name = i.table_name 
and 
      t.table_name ='RPT_DELAYTIME_20100828';
</code></pre>
<h1 id="cha-xun-biao-de-wei-yi-xing-yue-shu">查询表的唯一性约束</h1>
<pre><code class="language-shell">select column_name from user_cons_columns cu, user_constraints au 
where 
 cu.constraint_name = au.constraint_name 
and 
au.constraint_type = 'U' 
and 
au.table_name = 'RPT_DELAYTIME_20100828';
</code></pre>
<h1 id="cha-zhao-biao-de-wai-jian">查找表的外键</h1>
<pre><code class="language-shell">select c.* from user_constraints c 
where 
     c.constraint_type = 'R' 
and 
c.table_name = 'RPT_DELAYTIME_20100828';
</code></pre>
<h1 id="wai-jian-yue-shu-de-lie-ming">外键约束的列名</h1>
<pre><code class="language-shell">select cl.* from user_cons_columns cl where cl.constraint_name = 外键名称
</code></pre>
<h1 id="yin-yong-biao-de-jian-de-lie-ming">引用表的键的列名</h1>
<pre><code class="language-shell">select cl.* from user_cons_columns cl where cl.constraint_name = 外键引用表的键名
</code></pre>
<h1 id="ting-zhi-wai-jian-yu-ju">停止外键语句</h1>
<pre><code class="language-shell">alter table T_BME_TASK disable constraints FK_TASKDEFINITION_TASKDEFID;
alter table T_BME_TASKRUNRESULT disable constraints FK_TASKRUNRESULT_TASKID;
alter table T_BME_TASKNOTIFYINFO disable constraints FK_TASKNOTIFYINFO_TASKID;
</code></pre>
<h1 id="qi-yong-wai-jian-yu-ju">启用外键语句</h1>
<pre><code class="language-shell">alter table T_BME_TASK enable constraints FK_TASKDEFINITION_TASKDEFID;
alter table T_BME_TASKRUNRESULT enable constraints FK_TASKRUNRESULT_TASKID;
alter table T_BME_TASKNOTIFYINFO enable constraints FK_TASKNOTIFYINFO_TASKID;
</code></pre>
<h1 id="cha-xun-biao-de-suo-you-lie-ji-qi-shu-xing">查询表的所有列及其属性</h1>
<pre><code class="language-shell">select t.*,c.COMMENTS from user_tab_columns t,user_col_comments c
 where 
t.table_name = c.table_name 
and 
t.column_name = c.column_name 
and 
t.table_name =  'RPT_DELAYTIME_20100828';
</code></pre>
<h1 id="xiu-gai-biao-ming">修改表名</h1>
<pre><code class="language-shell">SQL&gt; alter table old_table_name rename to new_table_name;
</code></pre>
<h1 id="cha-xun-sou-suo-chu-qian-n-tiao-ji-lu">查询/搜索出前N条记录</h1>
<pre><code class="language-shell">select * from table_name where rownum &lt;N;
select * from systemparameter where rownum &lt;30
</code></pre>
<h1 id="ru-he-huo-de-mou-zhang-biao-dui-ying-de-biao-kong-jian-xin-xi">如何获得某张表对应的表空间信息</h1>
<pre><code class="language-shell">oracle@mmsg:~&gt; sqlplus mmsg/mmsg@mmsgdb   //应用级用户登录oracle数据库

SQL*Plus: Release 11.1.0.7.0 - Production on 星期四 7月 1 17:34:15 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select tablespace_name from user_tables where table_name like 'VPNCORP_30%';

TABLESPACE_NAME
------------------------------------------------------------
MMSG

SQL&gt;
</code></pre>
<h1 id="oracle-ru-he-qu-fen-64-bit-32-bit-ban-ben">oracle如何区分 64-bit/32bit 版本？</h1>
<pre><code class="language-shell">oracle@linux:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期四 7月 1 17:48:20 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select * from v$version;

BANNER
--------------------------------------------------------------------------------
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
PL/SQL Release 11.1.0.7.0 - Production
CORE    11.1.0.7.0      Production
TNS for Linux: Version 11.1.0.7.0 - Production
NLSRTL Version 11.1.0.7.0 - Production

SQL&gt;
</code></pre>
<h1 id="fen-bian-mou-ge-yong-hu-shi-cong-na-tai-ji-qi-deng-lu-oracle-de">分辨某个用户是从哪台机器登陆ORACLE的</h1>
<pre><code class="language-shell">SQL&gt; SELECT machine,terminal FROM V$SESSION;
MACHINE                                                          TERMINAL
---------------------------------------------------------------- ------------------------------
linux                                                            pts/2
linux                                                            pts/2
linux                                                            pts/1
linux                                                            pts/1
linux                                                            pts/1
linux                                                            pts/2
linux                                                            pts/1
linux                                                            pts/1
linux                                                            pts/1

已选择9行。

SQL&gt;
</code></pre>
<h1 id="cha-kan-zui-da-hui-hua-shu">查看最大会话数</h1>
<pre><code class="language-shell">SQL&gt; select * from v$parameter where name like 'proc%';
SQL&gt; show parameter processes

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
aq_tm_processes                      integer     0
db_writer_processes                  integer     1
gcs_server_processes                 integer     0
global_txn_processes                 integer     1
job_queue_processes                  integer     1000
log_archive_max_processes            integer     4
processes                            integer     1000
SQL&gt;

SQL&gt; select * from v$license;  

SESSIONS_MAX SESSIONS_WARNING SESSIONS_CURRENT SESSIONS_HIGHWATER  USERS_MAX CPU_COUNT_CURRENT CPU_CORE_COUNT_CURRENT CPU_SOCKET_COUNT_CURRENT
------------ ---------------- ---------------- ------------------ ---------- ----------------- ---------------------- ------------------------
CPU_COUNT_HIGHWATER CPU_CORE_COUNT_HIGHWATER CPU_SOCKET_COUNT_HIGHWATER
------------------- ------------------------ --------------------------
           0                0               83                482          0                 8                      8                   2
                  8                        8                          2

SQL&gt; 
</code></pre>
<p>其中sessions_highwater纪录曾经到达的最大会话数</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>session数，session=processe*1.1 + 5</p>
</li>
</ul>
<h1 id="cha-kan-xi-tong-bei-suo-de-shi-wu-shi-jian">查看系统被锁的事务时间</h1>
<pre><code class="language-shell">SQL&gt; select * from v$locked_object;

未选定行

SQL&gt;
</code></pre>
<h1 id="cha-de-shu-ju-ku-de-sid">查得数据库的SID</h1>
<pre><code class="language-shell">SQL&gt; select name from v$database;

NAME
------------------
MMSGDB

SQL&gt;
</code></pre>
<h1 id="huo-qu-sql-yu-ju-zhi-xing-hao-shi-shi-jian">获取SQL语句执行耗时时间</h1>
<pre><code class="language-shell">SQL&gt; set timing on
SQL&gt; select instance_number,instance_name,status from v$instance;

INSTANCE_NUMBER INSTANCE_NAME                    STATUS
--------------- -------------------------------- ------------------------
              1 mmsgdb                           OPEN

已用时间:  00: 00: 00.00
SQL&gt;
</code></pre>
<h1 id="jiang-cha-xun-select-de-jie-guo-dao-ru-dao-yi-ge-wen-jian-zhong">将查询（select）的结果导入到一个文件中</h1>
<pre><code class="language-shell">oracle@mmsg:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期五 7月 2 16:55:52 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; spool test.txt
SQL&gt; select sessions_current,sessions_highwater from v$license;

SESSIONS_CURRENT SESSIONS_HIGHWATER
---------------- ------------------
              38                 53

SQL&gt; select instance_number,instance_name,status from v$instance;

INSTANCE_NUMBER INSTANCE_NAME                    STATUS
--------------- -------------------------------- ------------------------
              1 mmsgdb                           OPEN

SQL&gt; show parameter spfile

NAME                                 TYPE
------------------------------------ ----------------------
VALUE
------------------------------
spfile                               string
/opt/oracle/product/11g/dbs/sp
filemmsgdb.ora
SQL&gt; show parameter license

NAME                                 TYPE
------------------------------------ ----------------------
VALUE
------------------------------
license_max_sessions                 integer
0
license_max_users                    integer
0
license_sessions_warning             integer
0
SQL&gt; quit  
从 Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开
oracle@mmsg:~&gt; more test.txt 
SQL&gt; select sessions_current,sessions_highwater from v$license;

SESSIONS_CURRENT SESSIONS_HIGHWATER                                             
---------------- ------------------                                             
              38                 53                                             

SQL&gt; select instance_number,instance_name,status from v$instance;

INSTANCE_NUMBER INSTANCE_NAME                    STATUS                         
--------------- -------------------------------- ------------------------       
              1 mmsgdb                           OPEN                           

SQL&gt; show parameter spfile

NAME                                 TYPE                                       
------------------------------------ ----------------------                     
VALUE                                                                           
------------------------------                                                  
spfile                               string                                     
/opt/oracle/product/11g/dbs/sp                                                  
filemmsgdb.ora                                                                  
SQL&gt; show parameter license

NAME                                 TYPE                                       
------------------------------------ ----------------------                     
VALUE                                                                           
------------------------------                                                  
license_max_sessions                 integer                                    
0                                                                               
license_max_users                    integer                                    
0                                                                               
license_sessions_warning             integer                                    
0                                                                               
SQL&gt; quit
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>相当于边操作边记录操作信息，并将信息追加到指定文件中，指定的文件路径可设置。</p>
</li>
</ul>
<h1 id="cha-xun-zhong-fu-ji-lu">查询重复记录</h1>
<pre><code class="language-shell">select count(*),ACCOUNTKEY,APPLYTIME  from userdb.account 
group by ACCOUNTKEY,APPLYTIME
having count(*)&gt;1
</code></pre>
<h1 id="shan-chu-zhong-fu-ji-lu">删除重复记录</h1>
<pre><code class="language-shell">delete from userdb.account t1 where t1.id != 
(select max(id) from userdb.account t2 where t1.ACCOUNTKEY=t2.ACCOUNTKEY and t1.APPLYTIME=t2.APPLYTIME)
</code></pre>
<h1 id="zi-fu-chuan-li-jia-hui-che">字符串里加回车</h1>
<pre><code class="language-shell">select 'Welcome  to visit'||chr(10)||'www.CSD N.NET' from dual
</code></pre>
<h1 id="shi-select-yu-ju-shi-cha-xun-jie-guo-zi-dong-sheng-cheng-xu-hao">使select语句使查询结果自动生成序号</h1>
<pre><code class="language-shell">select rownum，COL from table;
</code></pre>
<h1 id="cha-ru-quan-nian-ri-qi">插入全年日期</h1>
<pre><code class="language-shell">create table BSYEAR (d date)；                   
　　insert into BSYEAR                                         
　　select to_date('20030101'，'yyyy mmdd')+rownum-1 
　　from all_objects                                             
　　where rownum &lt;= to_char(to_date('20031231'，'yyyymmdd')，'ddd')；
</code></pre>
<h1 id="hong-fa-qi">触发器</h1>
<h2 id="cha-xun-dang-qian-hong-fa-qi">查询当前触发器</h2>
<pre><code class="language-shell">SQL&gt; set wrap off
SQL&gt; col status format a15
SQL&gt; col OBJECT_NAME format a20
SQL&gt; Select object_name,status  From user_objects Where object_type='TRIGGER';
</code></pre>
<h2 id="jin-zhi-hui-fu-hong-fa-qi">禁止、恢复触发器</h2>
<h3 id="jin-zhi-hong-fa-qi">禁止触发器</h3>
<pre><code class="language-shell">alter table accounttype disable all triggers;
</code></pre>
<h3 id="hui-fu-hong-fa-qi">恢复触发器</h3>
<pre><code class="language-shell">alter table accounttype enable all triggers;
</code></pre>
<h1 id="cha-xun-dang-qian-yong-hu-xia-suo-you-shi-tu">查询当前用户下所有视图</h1>
<pre><code class="language-shell">SQL&gt; Select object_name From user_objects Where object_type='VIEW';
</code></pre>
<h1 id="cha-xun-dang-qian-yong-hu-xia-suo-you-cun-chu-guo-cheng">查询当前用户下所有存储过程</h1>
<pre><code class="language-shell">Select object_name  From user_objects Where object_type='PROCEDURE'
</code></pre>
<h1 id="cha-xun-job">查询job</h1>
<h2 id="cha-xun-suo-you-job">查询所有job</h2>
<pre><code class="language-shell">SQL&gt; col LOG_USER format a10
SQL&gt; col PRIV_USER format a10
SQL&gt; col SCHEMA_USER format a10
SQL&gt; select job, LOG_USER,SCHEMA_USER,PRIV_USER from dba_jobs;
</code></pre>
<p>或者从user_jobs中获取数据。</p>
<h2 id="cha-xun-dang-tian-pao-de-job">查询当天跑的job</h2>
<pre><code class="language-shell">select * from all_jobs where last_date&gt;=trunc(sysdate) 
</code></pre>
<h2 id="cha-xun-mou-yi-job-zhi-xing-liao-duo-shao-xiao-shi">查询某一job执行了多少小时</h2>
<pre><code class="language-shell">select  total_time/1000/60/60  from user_jobs
</code></pre>
<h1 id="cha-xun-function">查询function</h1>
<pre><code class="language-shell">select object_name from user_objects  where object_type='FUNCTION';
</code></pre>
<h1 id="cha-xun-sequence">查询sequence</h1>
<pre><code class="language-shell">SELECT OBJECT_NAME FROM USER_OBJECTS WHERE OBJECT_TYPE='FUNCTION'
</code></pre>
<h1 id="cha-xun-oracle-package-nei-rong">查询oracle package内容</h1>
<pre><code class="language-shell">SQL&gt; desc all_source
Name                                      Null?    Type
----------------------------------------- -------- ----------------------------
OWNER                                              VARCHAR2(30)
NAME                                               VARCHAR2(30)
TYPE                                               VARCHAR2(12)
LINE                                               NUMBER
TEXT                                               VARCHAR2(4000)
SQL&gt;select text from all_source where name='DBMS_OUTPUT' and type='PACKAGE'
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-00257</title>
    <url>/2010/04/07/oracle_troubleshoot_ora_00257/</url>
    <content><![CDATA[<h1 id="ora-00257-gui-dang-cheng-xu-cuo-wu-zai-shi-fang-zhi-qian-jin-xian-yu-nei-bu-lian-jie-an-li">ORA-00257  归档程序错误。在释放之前仅限于内部连接案例</h1>
<h2 id="xian-xiang">现象</h2>
<pre><code class="language-shell">========== Running state of HUAWEI infoX IAG system 20100407 09:09:05 ==========
The path of the installation : /home/mmsg/mms_home. 
The monitor process  is running well-balanced . pid:7753

=============================== List of Local IP ===============================
10.164.75.102       127.0.0.1           192.168.100.106     
[2010-04-07 09:09:05.527] DB Error :ORA-00257: 归档程序错误。在释放之前仅限于内部连接
 dbname:"mmsgdb_222", dbuser:"mmsg"
</code></pre>
<p>尝试登录数据库</p>
<pre><code class="language-shell">164 mmsg01 [mmsg] :/home/mmsg&gt;sqlplus mmsg/mmsg@mmsgdb_222

SQL*Plus: Release 11.1.0.7.0 - Production on Wed Apr 7 09:09:54 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

ERROR:
ORA-00257: 归档程序错误。在释放之前仅限于内部连接


Enter user-name: mmsg
Enter password: 
ERROR:
ORA-01034: ORACLE not available
ORA-27101: shared memory realm does not exist
Linux-x86_64 Error: 2: No such file or directory
Process ID: 0
Session ID: 0 Serial number: 0


Enter user-name:
</code></pre>
<h2 id="yuan-yin">原因</h2>
<pre><code class="language-shell">00257, 00000, "archiver error. Connect internal only, until freed."
// *Cause:  The archiver process received an error while trying to archive
//       a redo log.  If the problem is not resolved soon, the database
//       will stop executing transactions. The most likely cause of this
//       message is the destination device is out of space to store the
//       redo log file.
// *Action:  Check archiver trace file for a detailed description
//        of the problem. Also verify that the
//       device specified in the initialization parameter
//       ARCHIVE_LOG_DEST is set up properly for archiving.
</code></pre>
<p>查看数据库日志运行模式，发现是在归档模式下，上述错误码信息显示是out of space to store the redo log file.存储空间不足。</p>
<p>查看文件系统</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; df
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/sda2             30969600   3364888  26031548  12% /
udev                   8218880       176   8218704   1% /dev
/dev/sda5             50150072  29613880  17988688  63% /home
/dev/sda6             41286796  39191128         0 100% /opt
opt空间已满！
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>1、停止数据录和监听，清除oracle目录下相关文件，包括告警、trace日志文件，以及在归档模式下产生的归档日志文件（dbs目录下的.dbf文件）；</p>
<p>2、查看文件系统空间信息</p>
<pre><code class="language-shell">oracle@mmsg:/opt/oraInventory&gt; df
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/sda2             30969600   3364888  26031548  12% /
udev                   8218880       176   8218704   1% /dev
/dev/sda5             50150072  29615732  17986836  63% /home
/dev/sda6             41286796  35579632   3609880  91% /opt
</code></pre>
<p>3、修改数据库日志运行模式，由原来的归档模式修改为非归档模式，并启动数据库。</p>
<pre><code class="language-shell">SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             620759568 bytes
Database Buffers          973078528 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。

SQL&gt; alter database noarchivelog;

数据库已更改。

SQL&gt; alter database open;

数据库已更改。

SQL&gt; archive log list
数据库日志模式             非存档模式
自动存档             禁用
存档终点            /opt/oracle/product/11g/dbs/arch
最早的联机日志序列     626
当前日志序列           628
SQL&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle日志</title>
    <url>/2010/05/19/oracle_log/</url>
    <content><![CDATA[<h1 id="ri-zhi-fen-lei">日志分类</h1>
<p>oracle数据库日志分为告警日志（alert）和跟踪日志（trace）两类，可通过查询系统参数获取日志文件存放路径：</p>
<pre><code class="language-shell">SQL&gt; show parameter dump

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
background_core_dump                 string      partial
background_dump_dest                 string      /opt/oracle/diag/rdbms/mmsgdb/
                                                 mmsgdb/trace
core_dump_dest                       string      /opt/oracle/diag/rdbms/mmsgdb/
                                                 mmsgdb/cdump
max_dump_file_size                   string      unlimited
shadow_core_dump                     string      partial
user_dump_dest                       string      /opt/oracle/diag/rdbms/mmsgdb/
                                                 mmsgdb/trace
</code></pre>
<h1 id="jian-kong-shu-ju-ku-de-cao-zuo">监控数据库的操作</h1>
<p>定期监控数据库的操作很重要，因为这样做，不仅可以提前通知管理员数据库存在的错误，让管理员提高警惕，同时也可以让管理员更好的理解数据库的操作。</p>
<h1 id="jian-kong-shu-ju-ku-de-cuo-wu-yu-gao-jing">监控数据库的错误与告警</h1>
<p>使用跟踪文件和告警日志监控数据库的操作。</p>
<p>当前oracle数据库的跟踪和告警日志以XML文件进行维护，可以使用任意编辑器来查看文本格式的告警日志，也可以使用ADRCI应用程序来查看XML格式的告警日志，同时，在ADRCI应用程序中，可以改变当前的ADR位置，也可以使用show home命令来显示所有的ADR位置，适应show alert 命令来显示告警日志，操作如下：</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; whoami
oracle
oracle@mmsg:~&gt; adrci

ADRCI: Release 11.1.0.7.0 - Production on 星期三 5月 19 16:46:21 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

ADR base = "/opt/oracle"
adrci&gt; show home
ADR Homes: 
diag/rdbms/mmsgdb/mmsgdb
diag/tnslsnr/mmsg/listener
adrci&gt; show homes
ADR Homes: 
diag/rdbms/mmsgdb/mmsgdb
diag/tnslsnr/mmsg/listener
adrci&gt; show homepath
ADR Homes: 
diag/rdbms/mmsgdb/mmsgdb
diag/tnslsnr/mmsg/listener
adrci&gt; show alert -tail
DIA-48449: Tail alert can only apply to single ADR home

adrci&gt; exit
oracle@mmsg:~&gt; oerr dia 48449
48449, 00000, "Tail alert can only apply to single ADR home"
// *Document: YES
// *Cause: There are multiple homes in the current setting
// *Action: Use command SET HOMEPATH to set a single home
oracle@mmsg:~&gt; adrci

ADRCI: Release 11.1.0.7.0 - Production on 星期三 5月 19 16:46:57 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

ADR base = "/opt/oracle"
adrci&gt; set homepath diag/tnslsnr/mmsg/listener
adrci&gt; show alert -tail
2010-05-19 16:47:08.815000 +08:00
19-5月 -2010 16:47:08 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=25644)) * establish * mmsgdb * 0
2010-05-19 16:47:11.377000 +08:00
19-5月 -2010 16:47:11 * service_update * mmsgdb * 0
2010-05-19 16:47:13.132000 +08:00
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=35728)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=58040)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=7921)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=10131)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=21875)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=10084)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=22965)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=2304)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=15243)) * establish * mmsgdb * 0
19-5月 -2010 16:47:13 * (CONNECT_DATA=(SID=mmsgdb)(CID=(PROGRAM=)(HOST=__jdbc__)(USER=))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=3562)) * establish * mmsgdb * 0
2010-05-19 16:47:14.379000 +08:00
19-5月 -2010 16:47:14 * service_update * mmsgdb * 0
adrci&gt; exit
oracle@mmsg:~&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--因USER表空间无法扩展配额，导致imp导入数据失败(IMP-00003,ORA-01536,IMP-00017)</title>
    <url>/2010/06/02/oracle_troubleshoot_space_quota_exceeded/</url>
    <content><![CDATA[<p>因USER表空间无法扩展配额，导致imp导入数据失败</p>
<h1 id="biao-xiang">表象</h1>
<pre><code class="language-shell">IMP-00003: ORACLE error 1536 encountered
ORA-01536: space quota exceeded for tablespace 'USERS'
IMP-00017: following statement failed with ORACLE error 1536:
 "CREATE TABLE "VIRTUALCARRIERINFO" ("VIRTUALCARRIERID" NUMBER(*,0) NOT NULL "
 "ENABLE, "VCARRIERLEVELID" NUMBER(*,0), "VIRTUALCARRIERNAME" VARCHAR2(64) NO"
 "T NULL ENABLE, "DESCRIPTION" VARCHAR2(1024))  PCTFREE 10 PCTUSED 40 INITRAN"
 "S 1 MAXTRANS 255 STORAGE(INITIAL 65536 FREELISTS 1 FREELIST GROUPS 1)      "
 "              LOGGING NOCOMPRESS"
IMP-00003: ORACLE error 1536 encountered
ORA-01536: space quota exceeded for tablespace 'USERS'
IMP-00017: following statement failed with ORACLE error 1536:
 "CREATE TABLE "VIRTUALCARRIERLEVEL" ("VCARRIERLEVELID" NUMBER(*,0) NOT NULL "
 "ENABLE, "FLUXLIMIT" NUMBER(*,0) NOT NULL ENABLE, "MESSAGESIZELIMIT" NUMBER("
 "*,0) NOT NULL ENABLE, "RECIPIENTSNUMBER" NUMBER(*,0) NOT NULL ENABLE)  PCTF"
 "REE 10 PCTUSED 40 INITRANS 1 MAXTRANS 255 STORAGE(INITIAL 65536 FREELISTS 1"
 " FREELIST GROUPS 1)                    LOGGING NOCOMPRESS"
IMP-00003: ORACLE error 1536 encountered
ORA-01536: space quota exceeded for tablespace 'USERS'
Import terminated successfully with warnings.
</code></pre>
<h1 id="yuan-yin">原因</h1>
<p>USER表空间扩展配置受限制</p>
<pre><code class="language-shell">% oerr ora 01536
01536, 00000, "space quota exceeded for tablespace '%s'"
// *Cause:  The space quota for the segment owner in the tablespace has
//          been exhausted and the operation attempted the creation of a
//          new segment extent in the tablespace.
// *Action: Either drop unnecessary objects in the tablespace to reclaim
//          space or have a privileged user increase the quota on this
//          tablespace for the segment owner.
</code></pre>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>dba用户修改表空间属性信息：</p>
<pre><code class="language-shell">GRANT UNLIMITED TABLESPACE TO &lt;username&gt;;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Excel数据导入到oracle数据库中</title>
    <url>/2010/06/03/import_excel_data_to_oracle/</url>
    <content><![CDATA[<h1 id="fang-fa-yi-sql-loader">方法一：SQL*Loader</h1>
<p>这个是用的较多的方法，前提必须oracle数据中目的表已经存在。</p>
<p>大体步骤如下：</p>
<h2 id="bu-zou-yi-zhun-bei-yuan-shi-wen-jian">步骤一、准备原始文件</h2>
<p>将excle文件另存为一个新文件比如文件名为text.txt，文件类型选文本文件（制表符分隔），这里选择类型为csv（逗号分隔）也行，但是在写后面的control.ctl时要将字段终止符改为’,'(fields      terminated      by      ‘,’)，假设保存到c盘根目录。</p>
<h2 id="bu-zou-er-chuang-jian-ce-shi-biao">步骤二、创建测试表</h2>
<p>如果没有存在的表结构，则创建,假设表为test，有两列为dm，ms。</p>
<h2 id="bu-zou-san-zhun-bei-ctl-wen-jian">步骤三、准备ctl文件</h2>
<p>用记事本创建SQL*Loader控制文件，网上说的文件名后缀为ctl，其实我自己发现就用txt后缀也行。比如命名为control.ctl，内容如下：(–后面的为注释，实际不需要）</p>
<pre><code class="language-shell">     　　load      data　　　　　　　　　　         --控制文件标识   
     　　infile      '/opt/oracle/test.csv'　　--要输入的数据文件名为test.csv   
     　　append  into  table  test　　　　       --向表test中追加记录   
     　　fields  erminated  y  X'09'　　         --字段终止于X'09'，是一个制表符（TAB）   
     　　(dm,ms)　　                                --定义列对应顺序   
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>数据导入的方式上例中用的append，有一下几种</p>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">insert，为缺省方式，在数据装载开始时要求表为空</li>
</ul>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">append，在表中追加新记录</li>
</ul>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">replace，删除旧记录，替换成新装载的记录</li>
</ul>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">truncate，同replace</li>
</ul>
</li>
</ul>
<h2 id="bu-zou-si-zhi-xing-sqlldr-ming-ling">步骤四、执行sqlldr命令</h2>
<p>在命令行提示符下使用SQL*Loader命令实现数据的输入</p>
<pre><code class="language-shell">     sqlldr  userid=system/manager    control='/opt/oracle/control.ctl'   
</code></pre>
<h1 id="fang-fa-er-li-yong-plsql-developer">方法二：利用PLSQL Developer</h1>
<p>使用PLSQL  Developer工具，这个可是大名鼎鼎的Oracle DBA最常使用的工具。</p>
<p>在单个文件不大的情况下(少于100000行)，并且目的表结构已经存在的情况下——对于excel而言肯定不会超过了，因为excel文件的最大行为65536—— 可以全选数据复制，然后用PLSQL  Developer工具。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、在PLSQL     Developer的sql      window里输入<code>select      *      from      test      for      update;   </code></p>
</li>
<li class="lvl-2">
<p>2、按F8执行</p>
</li>
<li class="lvl-2">
<p>3、打开锁,      再按一下加号.      鼠标点到第一列的列头，使全列成选中状态，然后粘贴，最后commit提交即可.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle数据库中数据导入到Excel中</title>
    <url>/2010/06/04/export_oracle_data_to_excel/</url>
    <content><![CDATA[<h1 id="fang-fa-yi-shi-yong-windows-xi-tong-de-odbc">方法一：使用windows系统的ODBC</h1>
<p>ODBC是Open Database Connectivity 的缩写，就是开放式数据库互连。利用ODBC实现动态数据交换的前提条件很简单，只需先在本机安装微软OFFICE中的EXCEL,然后根据需要运行编写的SQL文件。</p>
<p>步骤如下：</p>
<h2 id="1-shou-xian-pei-zhi-odbc-shu-ju-yuan">1、首先配置ODBC数据源</h2>
<p>在控制面板中，选ODBC数据源，添加选安装ODBC FOR ORACLE。在给定数据源名称和描述时，用户可自定义，用户名称和服务器则需根据在ORACLE 数据库中设置好的数据库名来设置。如：</p>
<pre><code class="language-shell">　　数据源名称：mmsgdb_114
　　描述：114oracle
　　用户名称：mmsg
　　服务器：10.137.49.114
 
</code></pre>
<img class="shadow" src="/img/in-post/oracle-odbc-1.png" width="400">
<img class="shadow" src="/img/in-post/oracle-odbc-2.png" width="300">
<h2 id="2-excel-yu-oracle-shu-ju-ku-jian-li-lian-jie">2、excel与oracle数据库建立连接</h2>
<p>打开EXCLE，在数据(D)菜单下，选择 导入外部数据(D) 导入数据(D) ，如下图所示：</p>
<img class="shadow" src="/img/in-post/oracle-excel-1.png" width="400">
<p>弹出“选择数据源”，如下图所示：</p>
<img class="shadow" src="/img/in-post/oracle-excel-2.png" width="400"> 
<p>选择“连接到新数据源”，弹出如下界面：</p>
<img class="shadow" src="/img/in-post/oracle-guide-1.png" width="400">
<p>在上图中选择 “Oracle”，点击“下一步(N)”，弹出如下界面：</p>
<img class="shadow" src="/img/in-post/oracle-guide-2.png" width="400">
<p>正确输入服务器名称和登录数据</p>
<img class="shadow" src="/img/in-post/oracle-guide-3.png" width="400"> 
<p>点击“下一步(N)”,弹出如下界面：</p>
<img class="shadow" src="/img/in-post/oracle-guide-4.png" width="400">
<p>选择数据库中表，点击“完成(F)”，弹出如下界面：</p>
<img class="shadow" src="/img/in-post/oracle-guide-5.png" width="400">
<p>点击“确定”按钮后，弹出如下界面：</p>
<img class="shadow" src="/img/in-post/oracle-guide-6.png" width="400">
<p>在上述界面中输入连接应用数据库的密码，点击“确定”按钮，查询出数据：</p>
<img class="shadow" src="/img/in-post/oracle-guide-7.png" width="400">
<p>如果选择“边界查询(Q)”按钮，弹出如下界面：</p>
<img class="shadow" src="/img/in-post/oracle-guide-8.png" width="400">
<p>在 命令文本(E) 中可编辑查询条件</p>
<img class="shadow" src="/img/in-post/oracle-guide-9.png" width="400">
<p>点击“确定”按钮后弹出“导入输出”界面，点击“确定”后，弹出 输入密码 界面，点击“确定”，得出相关数据信息。</p>
<h2 id="3-bao-cun-wen-jian">3、保存文件</h2>
<p>将该文件保存起来就可以了，至此，数据导出成功。</p>
<p>要是重新执行该文件，只需在MICRSOFT QUERY窗口中选择打开该查询并执行，即可得到实时的数据；然后可利用ＥＸＣＥＬ强大的编辑功能，对这些数据进行分析修改，相当方便。</p>
<h1 id="fang-fa-er-shi-yong-plsql-developer-gong-ju-fu-zhu">方法二 使用PLSQL Developer工具辅助</h1>
<p>使用PLSQL Developer工具，简单而快捷。</p>
<img class="shadow" src="/img/in-post/oracle-sql-view.png" height="700" width="500">
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>联通数据库切换验证</title>
    <url>/2010/05/28/oracle_verify_un_db/</url>
    <content><![CDATA[<h1 id="bei-jing">背景</h1>
<p>现状:</p>
<p>数据库与业务分别设立在不同的单板上（suse10 + ora11g)</p>
<p>调整:</p>
<p>把数据库切换到AIX机器上，业务单板不变。</p>
<p>示意图如下：</p>
<img class="shadow" src="/img/in-post/un_to_be.png" width="360">
<p>数据迁移流程图</p>
<img class="shadow" src="/img/in-post/un_db_change.png" width="600">
<h1 id="cao-zuo-guo-cheng">操作过程</h1>
<h2 id="shu-ju-ku-a-ying-yong-shu-ju-quan-biao-dao-chu">数据库A应用数据全表导出</h2>
<p>脚本:</p>
<pre><code class="language-shell">#!/bin/sh

#定义备份时间
backupdate=`date +'%Y%m%d_%H%M%S'`

#定义备份路径
BakPath=/opt/oracle/oracle_table_bak

if [ ! -d $ORACLE_BASE/oracle_table_bak ];then
 mkdir -p $ORACLE_BASE/oracle_table_bak
fi

# 定义oracle用户名和密码
ACCOUNT=mmsg        #用户名称
PASSWORD=mmsg       #用户密码
SID=mmsgdb          #数据库别名
echo "Please input user name,password and SID to connect to oracle"
#读入用户名
echo "username(mmsg)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    ACCOUNT=$U_INPUT
fi

#读入密码
echo "password(mmsg)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    PASSWORD=$U_INPUT
fi

#读入SID
echo "SID( mmsgdb)"
read U_INPUT
if [ "x$U_INPUT" != "x" ]; then
    SID=$U_INPUT
fi

#系统所在路径
APPHOME=`dirname $0`
if [ $APPHOME = "." ]; then
   APPHOME=`pwd`
fi
cd $APPHOME

#执行导出操作
exp $ACCOUNT/$PASSWORD@$SID file=${ORACLE_BASE}/oracle_table_bak/fullbak_$backupdate.dmp  log=${ORACLE_BASE}/oracle_table_bak/fullbak_$backupdate.log full=y
</code></pre>
<h2 id="dao-chu">导出</h2>
<p>1、oracle用户上传fullbak_mmsg.sh脚本，并为fullbak_mmsg.sh脚本增加可执行权限</p>
<p><code>chmod +x fullbak_mmsg.sh </code></p>
<p>2、使用oracle用户执行fullbak_mmsg.sh脚本</p>
<p><code>sh fullbak_mmsg.sh </code></p>
<p>3、导出过程日志信息片段如下</p>
<pre><code class="language-shell">Connected to: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
Export done in ZHS16GBK character set and UTF8 NCHAR character set

About to export the entire database ...
. exporting tablespace definitions
. exporting profiles
. exporting user definitions
. exporting roles
. exporting resource costs
. exporting rollback segment definitions
. exporting database links
. exporting sequence numbers
. exporting directory aliases
. exporting context namespaces
. exporting foreign function library names
. exporting PUBLIC type synonyms
. exporting private type synonyms
. exporting object type definitions
. exporting system procedural objects and actions
. exporting pre-schema procedural objects and actions
. exporting cluster definitions
. about to export SYSTEM's tables via Conventional Path ...
. . exporting table                    DEF$_AQCALL          0 rows exported
. . exporting table                   DEF$_AQERROR          0 rows exported
. . exporting table                  DEF$_CALLDEST          0 rows exported
. . exporting table               DEF$_DEFAULTDEST          0 rows exported
…………………………………………………………………………………………
. . exporting table                 VPNUNITECORPID          1 rows exported
. exporting synonyms
. exporting views
. exporting referential integrity constraints
. exporting stored procedures
. exporting operators
. exporting indextypes
. exporting bitmap, functional and extensible indexes
. exporting posttables actions
. exporting triggers
. exporting materialized views
. exporting snapshot logs
. exporting job queues
. exporting refresh groups and children
. exporting dimensions
. exporting post-schema procedural objects and actions
. exporting user history table
. exporting default and system auditing options
. exporting statistics
Export terminated successfully without warnings.
</code></pre>
<h2 id="ke-neng-chu-xian-de-wen-ti-jie-jue-fang-fa">可能出现的问题解决方法</h2>
<h3 id="ora-06550-exp-00008-pls-0020-ora-06512-cuo-wu">ORA-06550、EXP-00008、PLS-0020、ORA-06512错误</h3>
<p>在导出过程中如果出现如下错误：</p>
<pre><code class="language-shell">EXP-00008: ORACLE error 6550 encountered
ORA-06550: line 1, column 19:
PLS-00201: identifier 'SYS.DBMS_DEFER_IMPORT_INTERNAL' must be declared
ORA-06550: line 1, column 7:
PL/SQL: Statement ignored
ORA-06512: at "SYS.DBMS_SQL", line 1575
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 97
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 126
ORA-06512: at line 1
. . exporting table                   DEF$_AQERROR
EXP-00008: ORACLE error 6510 encountered
ORA-06510: PL/SQL: unhandled user-defined exception
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 50
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 126
ORA-06512: at line 1
. . exporting table                  DEF$_CALLDEST
EXP-00008: ORACLE error 6550 encountered
ORA-06550: line 1, column 19:
PLS-00201: identifier 'SYS.DBMS_DEFER_IMPORT_INTERNAL' must be declared
ORA-06550: line 1, column 7:
PL/SQL: Statement ignored
ORA-06512: at "SYS.DBMS_SQL", line 1575
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 97
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 126
ORA-06512: at line 1
. . exporting table               DEF$_DEFAULTDEST
EXP-00008: ORACLE error 6510 encountered
ORA-06510: PL/SQL: unhandled user-defined exception
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 50
ORA-06512: at "SYS.DBMS_EXPORT_EXTENSION", line 126
ORA-06512: at line 1
</code></pre>
<p>请使用如下方法解决：</p>
<p>1、将DBMS_EXPORT_EXTENSION和DBMS_DEFER_IMPORT_INTERNAL执行权限赋予导出用户</p>
<pre><code class="language-shell">grant execute on DBMS_EXPORT_EXTENSION to 导出用户;
grant execute on DBMS_DEFER_IMPORT_INTERNAL to 导出用户;
</code></pre>
<p>2、成功赋予权限后，执行应用全表导出操作</p>
<pre><code class="language-shell">sh fullbak_mmsg.sh
</code></pre>
<h2 id="ying-yong-quan-biao-dao-ru-dao-shu-ju-ku-b">应用全表导入到数据库B</h2>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>在将数据库A中表数据导入到数据库B中 之前，请务必先备份数据库B中数据，备份操作请参考“数据库A应用数据全表导出”部分内容。</p>
</li>
</ul>
<h3 id="1-shan-chu-yuan-you-shu-ju-ku-zhong-suo-you-ying-yong-biao">1、删除原有数据库中所有应用表</h3>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>本段的操作，必须是在正确完成上述应用数据库B中数据的导出工作后进行！</p>
</li>
</ul>
<p>删除原有数据库中所有应用表操作步骤</p>
<h4 id="a-zhun-bei-cun-chu-guo-cheng">A、准备存储过程</h4>
<p>新增一存储过程drop_tbl_table，sql脚本代码如下：</p>
<pre><code class="language-shell">create or replace procedure drop_tbl_table(tname in varchar)

is
    v_sql      varchar(100);    -- 动态SQL语句
    v_count    number(10);      -- 数据库中drop过的表数


begin
    v_count := 0;
    
    for v1 in (select * from all_tables where owner = 'MMSG')
    loop
        v_sql := 'drop table ' || v1.table_name;
        v_count := v_count + 1;
        execute immediate v_sql;
    end loop;
    dbms_output.put_line(v_count);
end drop_tbl_table;
/
</code></pre>
<p>将上述脚本拷贝到文件中，以asc方式上传到oracle数据库某节点下，并将该文件命名为ora_proc_drop_tbl_tables.sql，如下：</p>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>sql脚本中select * from all_tables where owner = 'MMSG'</code> 的 MMSG为表的属主，请根据现网环境选择正确属主，否则会造成误删不相关的表，造成数据丢失。</p>
</li>
</ul>
<h4 id="b-chuang-jian-cun-chu-guo-cheng">B、创建存储过程</h4>
<p>oracle用户成功登录终端，以应用用户（如数据库应用用户mmsg）与数据库建立连接，执行ora_proc_drop_tbl_tables.sql脚本</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; cat ora_proc_drop_tbl_tables.sql | sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.7.0 - Production on 星期一 7月 12 18:08:17 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt;   2    3    4    5    6    7    8    9   10   11   12   13   14   15   16   17   18   19  
过程已创建。

SQL&gt; 从 Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开
oracle@mmsg:~&gt;
</code></pre>
<h4 id="c-zhi-xing-cun-chu-guo-cheng">C、执行存储过程</h4>
<p>执行存储过程，删除所有应用表。</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.7.0 - Production on 星期一 7月 12 17:52:44 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; exec drop_tbl_table(0)

PL/SQL 过程已成功完成。

SQL&gt;
</code></pre>
<p>注意事项：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、存储过程的执行过程需要一定的时间（尤其应用表数量较多时），请耐心等待。切勿执行退出命令，否则会导致表删除不全。</p>
</li>
<li class="lvl-2">
<p>2、存储过程执行完毕后，输入sqlplus中输入如下命令查看表是否删除完毕：<code>select  count(0)  from all_tables where owner = 'MMSG'; </code><br>
如果查询结果是0，则 表删除完毕。</p>
</li>
</ul>
<h2 id="2-dao-ru">2、导入</h2>
<p><code>imp  username/passwd@sid file=XXX.dmp ignore=y commit=y  full=y</code></p>
<p>或者</p>
<p><code>imp username/passwd@dbname fromuser=XXX touser=XXX file= XXX.dmp ignore=y commit=y full=y </code></p>
<p>其中:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>fromuser  该选项用于指定从导出文件中摘取并导入特定用于的对象；</p>
</li>
<li class="lvl-2">
<p>touser    该选项用于指定将特定方案对象导入到其他用户。</p>
</li>
</ul>
<p>例如：</p>
<pre><code class="language-shell">imp wyz/wyz@iagw fromuser=mmsg touser=wyz file=./fullbak_20100507_091121.dmp ignore=y commit=y log= fullbak_20100506_194731.log
</code></pre>
<p>如果导入导出的用户名一致，可以直接使用如下命令进行导入：</p>
<pre><code class="language-shell">imp mmsg/mmsg@mmsgdb  file=./ fullbak_20100507_091121.dmp  ignore=y commit=y  full=y
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>.dmp文件必须以bin方式从数据库A ftp到数据库B</p>
</li>
</ul>
<h2 id="ke-neng-chu-xian-de-wen-ti-jie-jue-fang-fa-1">可能出现的问题解决方法</h2>
<p>如果在导入过程中并未出现下列问题，请跳过下列步骤，直接验证导入后数据完整性。</p>
<h3 id="imp-00013-cuo-wu">IMP-00013错误</h3>
<p>如果在导入过程中出现IMP-00013错误，如下：</p>
<pre><code class="language-shell">% imp wyz/wyz@iagw fromuser=mmsg touser=wyz file=./fullbak_20100506_200334.dmp ignore=y commit=y

Import: Release 11.1.0.6.0 - Production on 星期四 5月 6 20:13:59 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to: Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing option

Export file created by EXPORT:V11.01.00 via conventional path
IMP-00013: only a DBA can import a file exported by another DBA
IMP-00000: Import terminated unsuccessfully
%
</code></pre>
<p>原因:</p>
<p>导入用户不具有dba权限</p>
<p>解决方法:</p>
<p>赋予导入用户dba和imp_full_Database权限</p>
<p>操作如下:</p>
<pre><code class="language-shell">% sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期五 5月 7 09:54:40 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options

SQL&gt; grant dba to wyz;

Grant succeeded.

SQL&gt; grant imp_full_Database to wyz;

Grant succeeded.

SQL&gt; exit
</code></pre>
<h3 id="imp-00003-ora-01658-cuo-wu">IMP-00003、ORA-01658错误</h3>
<p>重新执行导入操作，如果在导入过程中出现如下错误</p>
<pre><code class="language-shell">IMP-00003: ORACLE error 1658 encountered
ORA-01658: 无法为表空间 MMSG 中的段创建 INITIAL 区
</code></pre>
<p>原因:</p>
<p>1、表空间WYZ不足；</p>
<p>2、数据从A数据库导入到B数据库，但是没有使用B数据库对应的表空间。</p>
<p>解决方法如下:</p>
<p>1、请确保被导入数据的数据库所对应的表空间足够大，如果表空间不足，请使用如下方法进行相应的表空间扩展。</p>
<p>Suse平台扩展Oracle表空间操作</p>
<p>当按照安装规划创建的表空间无法适应于当前性能测试需要时，可以通过如下方法扩大相应逻辑卷，增加空间。</p>
<p>Suse操作系统下扩展Oracle表空间一般情况我们通过扩展裸设备大小的操作，而不是通过增加裸设备个数的操作来实现。因为Suse中的裸设备raw**是需要跟lv文件进行绑定的，该绑定操作需要在系统重启的时候执行。而绑定关系是配置在启动文件中的（该部分可以参考安装指南）。如果增加了裸设备还需要修改绑定关系，为了减少操作，我们一般使用修改lv/裸设备大小的方式进行。</p>
<p>假设临时表空间需要扩展表空间，步骤如下：</p>
<p>扩展lv大小。先找出临时表空间用到哪个裸设备，假设为raw2，然后在安装文档或/etc/raw文件中找到raw2对应绑定的lv的名称，假设为/dev/datavg/lvora_temp1，那么可以将该lv增大2G。</p>
<p><code># lvextend -L +2G /dev/datavg/lvora_temp1 </code></p>
<p>datafile是针对一般表空间</p>
<p>当扩展的是临时表空间时，替换成tmpfile</p>
<p>扩展表空间</p>
<p>当表空间已经满时，执行数据库操作数据库会报错，例如：</p>
<pre><code class="language-shell">ORA-01653: 表 MMSG.TMP_BASE_RESULT 无法通过 8 (在表空间 MMSG 中) 扩展
ORA-06512: 在 "MMSG.LOG2DB_UTIL", line 92
ORA-06512: 在 line 1
需要扩展表空间
ORA－01653
node1:oracle:mmsgdb &gt; oerr ora 01653
01653, 00000, "unable to extend table %s.%s by %s in tablespace %s"
// *Cause:  Failed to allocate an extent of the required number of blocks for 
//          a table segment in the tablespace indicated.
// *Action: Use ALTER TABLESPACE ADD DATAFILE statement to add one or more
//          files to the tablespace indicated.
node1:oracle:mmsgdb &gt;
</code></pre>
<p>扩展操作命令如下：</p>
<pre><code class="language-shell">alter database datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' AUTOEXTEND ON NEXT 50M MAXSIZE UNLIMITED;
</code></pre>
<p>下面的两个命令也可以：</p>
<pre><code class="language-shell">alter tablespace mmsg add datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' size 1024M reuse;
alter database datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' resize 2048M;
</code></pre>
<p>扩展后重启实例，查看相关表空间是否已经扩展，</p>
<pre><code class="language-shell">select * from dba_tablespace_usage_metrics;
</code></pre>
<h3 id="oracle-yong-imp-dao-ru-yong-hu-biao-shi-xuan-ze-biao-kong-jian-de-wen-ti">Oracle用imp导入用户表时选择表空间的问题</h3>
<p>当前表空间为WYZ，但是提示信息显示无法为表空间 MMSG 中的段创建 INITIAL 区，说明数据虽然导入到了wyz用户下，但是使用的表空间依然是MMSG，而我们所需要的是表空间WYZ，而非MMSG，解决方法如下：</p>
<pre><code class="language-shell">% sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期五 5月 7 11:08:51 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options

SQL&gt; grant resource,connect to wyz; 

Grant succeeded.

SQL&gt; grant dba to wyz;     // 赋 DBA 权限

Grant succeeded.

SQL&gt; revoke unlimited tablespace from wyz;  // 撤销此权限

Revoke succeeded.

SQL&gt; alter user wyz quota 0 on system;  //将用户在 System 表空间的配额置为 0

User altered.

SQL&gt; alter user wyz quota unlimited on wyz; //设置用户在 wyz 表空间配额不受限。

User altered.

SQL&gt; exit
</code></pre>
<p>上述问题解决后，重新执行数据导入操作</p>
<h2 id="shu-ju-dao-ru">数据导入</h2>
<pre><code class="language-shell">imp wyz/wyz@iagw fromuser=mmsg touser=wyz file=./fullbak_20100507_091121.dmp ignore=y commit=y log=imp_20100507_091121.log
</code></pre>
<h2 id="dao-ru-yan-zheng">导入验证</h2>
<p>日志信息</p>
<pre><code class="language-shell">
Connected to: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
Export done in ZHS16GBK character set and UTF8 NCHAR character set

About to export the entire database ...
. exporting tablespace definitions
. exporting profiles
. exporting user definitions
. exporting roles
. exporting resource costs
. exporting rollback segment definitions
. exporting database links
. exporting sequence numbers
. exporting directory aliases
. exporting context namespaces
. exporting foreign function library names
. exporting PUBLIC type synonyms
. exporting private type synonyms
. exporting object type definitions
. exporting system procedural objects and actions
. exporting pre-schema procedural objects and actions
. exporting cluster definitions
. about to export SYSTEM's tables via Conventional Path ...
. . exporting table                    DEF$_AQCALL          0 rows exported
. . exporting table                   DEF$_AQERROR          0 rows exported
. . exporting table                  DEF$_CALLDEST          0 rows exported
. . exporting table               DEF$_DEFAULTDEST          0 rows exported
. . exporting table               DEF$_DESTINATION          0 rows exported
. . exporting table                     DEF$_ERROR          0 rows exported
. . exporting table                       DEF$_LOB          0 rows exported
. . exporting table                    DEF$_ORIGIN          0 rows exported
. . exporting table                DEF$_PROPAGATOR          0 rows exported
. . exporting table       DEF$_PUSHED_TRANSACTIONS          0 rows exported
. . exporting table                  DEF$_TEMP$LOB          0 rows exported
. . exporting table                            OL$
. . exporting table                       OL$HINTS
. . exporting table                       OL$NODES
. . exporting table           QUEST_SOO_AT_APPNAME          0 rows exported
. . exporting table    QUEST_SOO_AT_EXECUTION_PLAN          0 rows exported
. . exporting table        QUEST_SOO_AT_OPERATIONS          0 rows exported
. . exporting table      QUEST_SOO_AT_PARSE_CURSOR          0 rows exported
. . exporting table       QUEST_SOO_AT_PARSE_ERROR          0 rows exported
. . exporting table       QUEST_SOO_AT_PARSE_WAITS          0 rows exported
. . exporting table        QUEST_SOO_AT_SESSION_ID          0 rows exported
. . exporting table         QUEST_SOO_AT_SQL_BINDS          0 rows exported
. . exporting table    QUEST_SOO_AT_SQL_EXECUTIONS          0 rows exported
. . exporting table    QUEST_SOO_AT_SQL_EXEC_ERROR          0 rows exported
. . exporting table         QUEST_SOO_AT_SQL_FETCH          0 rows exported
. . exporting table     QUEST_SOO_AT_SQL_STATEMENT          0 rows exported
. . exporting table   QUEST_SOO_AT_SQL_STMT_PIECES          0 rows exported
. . exporting table         QUEST_SOO_AT_SQL_WAITS          0 rows exported
. . exporting table        QUEST_SOO_AT_TRACE_FILE          0 rows exported
. . exporting table        QUEST_SOO_AT_WAIT_NAMES          0 rows exported
. . exporting table          QUEST_SOO_BUFFER_BUSY          0 rows exported
. . exporting table     QUEST_SOO_EVENT_CATEGORIES       1445 rows exported
. . exporting table            QUEST_SOO_LOCK_TREE          0 rows exported
. . exporting table     QUEST_SOO_PARSE_TIME_TRACK          1 rows exported
. . exporting table           QUEST_SOO_PLAN_TABLE          0 rows exported
. . exporting table       QUEST_SOO_SB_BUFFER_BUSY          0 rows exported
. . exporting table             QUEST_SOO_SB_EVENT          0 rows exported
. . exporting table           QUEST_SOO_SB_IO_STAT          0 rows exported
. . exporting table      QUEST_SOO_SCHEMA_VERSIONS          1 rows exported
. . exporting table              QUEST_SOO_VERSION          1 rows exported
. . exporting table        REPCAT$_AUDIT_ATTRIBUTE          2 rows exported
. . exporting table           REPCAT$_AUDIT_COLUMN          0 rows exported
. . exporting table           REPCAT$_COLUMN_GROUP          0 rows exported
. . exporting table               REPCAT$_CONFLICT          0 rows exported
. . exporting table                    REPCAT$_DDL          0 rows exported
. . exporting table             REPCAT$_EXCEPTIONS          0 rows exported
. . exporting table              REPCAT$_EXTENSION          0 rows exported
. . exporting table                REPCAT$_FLAVORS          0 rows exported
. . exporting table         REPCAT$_FLAVOR_OBJECTS          0 rows exported
. . exporting table              REPCAT$_GENERATED          0 rows exported
. . exporting table         REPCAT$_GROUPED_COLUMN          0 rows exported
. . exporting table      REPCAT$_INSTANTIATION_DDL          0 rows exported
. . exporting table            REPCAT$_KEY_COLUMNS          0 rows exported
. . exporting table           REPCAT$_OBJECT_PARMS          0 rows exported
. . exporting table           REPCAT$_OBJECT_TYPES         28 rows exported
. . exporting table       REPCAT$_PARAMETER_COLUMN          0 rows exported
. . exporting table               REPCAT$_PRIORITY          0 rows exported
. . exporting table         REPCAT$_PRIORITY_GROUP          0 rows exported
. . exporting table      REPCAT$_REFRESH_TEMPLATES          0 rows exported
. . exporting table                 REPCAT$_REPCAT          0 rows exported
. . exporting table              REPCAT$_REPCATLOG          0 rows exported
. . exporting table              REPCAT$_REPCOLUMN          0 rows exported
. . exporting table         REPCAT$_REPGROUP_PRIVS          0 rows exported
. . exporting table              REPCAT$_REPOBJECT          0 rows exported
. . exporting table                REPCAT$_REPPROP          0 rows exported
. . exporting table              REPCAT$_REPSCHEMA          0 rows exported
. . exporting table             REPCAT$_RESOLUTION          0 rows exported
. . exporting table      REPCAT$_RESOLUTION_METHOD         19 rows exported
. . exporting table  REPCAT$_RESOLUTION_STATISTICS          0 rows exported
. . exporting table    REPCAT$_RESOL_STATS_CONTROL          0 rows exported
. . exporting table          REPCAT$_RUNTIME_PARMS          0 rows exported
. . exporting table              REPCAT$_SITES_NEW          0 rows exported
. . exporting table           REPCAT$_SITE_OBJECTS          0 rows exported
. . exporting table              REPCAT$_SNAPGROUP          0 rows exported
. . exporting table       REPCAT$_TEMPLATE_OBJECTS          0 rows exported
. . exporting table         REPCAT$_TEMPLATE_PARMS          0 rows exported
. . exporting table     REPCAT$_TEMPLATE_REFGROUPS          0 rows exported
. . exporting table         REPCAT$_TEMPLATE_SITES          0 rows exported
. . exporting table        REPCAT$_TEMPLATE_STATUS          3 rows exported
. . exporting table       REPCAT$_TEMPLATE_TARGETS          0 rows exported
. . exporting table         REPCAT$_TEMPLATE_TYPES          2 rows exported
. . exporting table    REPCAT$_USER_AUTHORIZATIONS          0 rows exported
. . exporting table       REPCAT$_USER_PARM_VALUES          0 rows exported
. . exporting table        SQLPLUS_PRODUCT_PROFILE          0 rows exported
. about to export OUTLN's tables via Conventional Path ...
. . exporting table                            OL$          0 rows exported
. . exporting table                       OL$HINTS          0 rows exported
. . exporting table                       OL$NODES          0 rows exported
. about to export TSMSYS's tables via Conventional Path ...
. . exporting table                           SRS$          0 rows exported
. about to export MMSG's tables via Conventional Path ...
. . exporting table                       AREAINFO        374 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX          2 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          1 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100428        736 rows exported
. . exporting table      INTERFACEACCOUNT_20100429        302 rows exported
. . exporting table      INTERFACEACCOUNT_20100430          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100501          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100502          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100503          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100504          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100505          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100506          0 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR         10 rows exported
. . exporting table                       MISCINFO          2 rows exported
. . exporting table                MISCROUTERTABLE          8 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          2 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_0        715 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_1        654 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_2        725 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_3        820 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_4        508 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_5        642 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_6        719 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_7        807 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_8        663 rows exported
. . exporting table          MMSGSVCLOG_0428_1_O_9        650 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_0        104 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_1         43 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_2         56 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_3         99 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_4         77 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_5         69 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_6         88 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_7         40 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_8         38 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_9         42 rows exported
. . exporting table        MMSGSVCLOG_20100428_1_S        976 rows exported
. . exporting table        MMSGSVCLOG_20100429_1_S         94 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         16 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          0 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          0 rows exported
. . exporting table               MONTHORDERINFO_2          1 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         24 rows exported
. . exporting table              PORTALLOG20100428         57 rows exported
. . exporting table              PORTALLOG20100429         12 rows exported
. . exporting table              PORTALLOG20100506         15 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          1 rows exported
. . exporting table                      RIGHTINFO        250 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        519 rows exported
. . exporting table                    ROUTERTABLE          5 rows exported
. . exporting table                 RPT_BUSYSERVER        198 rows exported
. . exporting table                  RPT_DELAYTIME          0 rows exported
. . exporting table         RPT_DELAYTIME_20100428        206 rows exported
. . exporting table         RPT_DELAYTIME_20100429         88 rows exported
. . exporting table         RPT_DELAYTIME_20100430          0 rows exported
. . exporting table         RPT_DELAYTIME_20100501          0 rows exported
. . exporting table         RPT_DELAYTIME_20100502          0 rows exported
. . exporting table         RPT_DELAYTIME_20100503          0 rows exported
. . exporting table         RPT_DELAYTIME_20100504          0 rows exported
. . exporting table         RPT_DELAYTIME_20100505          0 rows exported
. . exporting table         RPT_DELAYTIME_20100506          0 rows exported
. . exporting table                  RPT_INTERFACE          0 rows exported
. . exporting table         RPT_INTERFACE_20100428        359 rows exported
. . exporting table         RPT_INTERFACE_20100429         60 rows exported
. . exporting table         RPT_INTERFACE_20100430          0 rows exported
. . exporting table         RPT_INTERFACE_20100501          0 rows exported
. . exporting table         RPT_INTERFACE_20100502          0 rows exported
. . exporting table         RPT_INTERFACE_20100503          0 rows exported
. . exporting table         RPT_INTERFACE_20100504          0 rows exported
. . exporting table         RPT_INTERFACE_20100505          0 rows exported
. . exporting table         RPT_INTERFACE_20100506          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC         50 rows exported
. . exporting table                   RPT_MMSCSUCC         28 rows exported
. . exporting table              RPT_MMSC_20100428          0 rows exported
. . exporting table              RPT_MMSC_20100429          0 rows exported
. . exporting table              RPT_MMSC_20100430          0 rows exported
. . exporting table              RPT_MMSC_20100501          0 rows exported
. . exporting table              RPT_MMSC_20100502          0 rows exported
. . exporting table              RPT_MMSC_20100503          0 rows exported
. . exporting table              RPT_MMSC_20100504          0 rows exported
. . exporting table              RPT_MMSC_20100505          0 rows exported
. . exporting table              RPT_MMSC_20100506          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20100428          0 rows exported
. . exporting table              RPT_VASP_20100429          0 rows exported
. . exporting table              RPT_VASP_20100430          0 rows exported
. . exporting table              RPT_VASP_20100501          0 rows exported
. . exporting table              RPT_VASP_20100502          0 rows exported
. . exporting table              RPT_VASP_20100503          0 rows exported
. . exporting table              RPT_VASP_20100504          0 rows exported
. . exporting table              RPT_VASP_20100505          0 rows exported
. . exporting table              RPT_VASP_20100506          0 rows exported
. . exporting table        SERVICEACCOUNT_20100428         79 rows exported
. . exporting table        SERVICEACCOUNT_20100429        188 rows exported
. . exporting table        SERVICEACCOUNT_20100430          0 rows exported
. . exporting table        SERVICEACCOUNT_20100501          0 rows exported
. . exporting table        SERVICEACCOUNT_20100502          0 rows exported
. . exporting table        SERVICEACCOUNT_20100503          0 rows exported
. . exporting table        SERVICEACCOUNT_20100504          0 rows exported
. . exporting table        SERVICEACCOUNT_20100505          0 rows exported
. . exporting table        SERVICEACCOUNT_20100506          0 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        340 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          2 rows exported
. . exporting table              TMP_ATTACH_RESULT        201 rows exported
. . exporting table                TMP_BASE_RESULT         73 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO         12 rows exported
. . exporting table                  VASPLEVELINFO          2 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP         15 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                    VPNCORP_100          3 rows exported
. . exporting table                    VPNCORP_300          3 rows exported
. . exporting table                  VPNSUBSCRIBER          6 rows exported
. . exporting table                 VPNUNITECORPID          1 rows exported
. about to export MYENUM's tables via Conventional Path ...
. about to export YKLOG's tables via Conventional Path ...
. . exporting table         LOG_ROUTER201003010101          0 rows exported
. . exporting table         LOG_ROUTER201003190101        156 rows exported
. . exporting table         LOG_ROUTER201003230101         68 rows exported
. . exporting table         LOG_ROUTER201003240101        332 rows exported
. . exporting table         LOG_ROUTER201003250101        228 rows exported
. . exporting table         LOG_ROUTER201003260101         64 rows exported
. . exporting table         LOG_ROUTER201003270101        480 rows exported
. . exporting table         LOG_ROUTER201003290101       1073 rows exported
. . exporting table         LOG_ROUTER201003300101         64 rows exported
. . exporting table         LOG_ROUTER201003310101        181 rows exported
. . exporting table         LOG_ROUTER201004010101         62 rows exported
. . exporting table         LOG_ROUTER201004060101         10 rows exported
. . exporting table         LOG_ROUTER201004070101         60 rows exported
. . exporting table         LOG_ROUTER201004080101         47 rows exported
. . exporting table         LOG_ROUTER201004090101        734 rows exported
. . exporting table         LOG_ROUTER201004100101         44 rows exported
. . exporting table         LOG_ROUTER201004110101         16 rows exported
. . exporting table         LOG_ROUTER201004120101        168 rows exported
. . exporting table         LOG_ROUTER201004130101         62 rows exported
. . exporting table         LOG_ROUTER201004140101        116 rows exported
. . exporting table         LOG_ROUTER201004150101         60 rows exported
. . exporting table         LOG_ROUTER201004160101         24 rows exported
. . exporting table         LOG_ROUTER201004210101          1 rows exported
. . exporting table         LOG_ROUTER201004220101          2 rows exported
. . exporting table         LOG_ROUTER201004230101         75 rows exported
. . exporting table         LOG_ROUTER201004240101         27 rows exported
. . exporting table                   NOTIFYRESULT          0 rows exported
. . exporting table                  OPERATERESULT          0 rows exported
. . exporting table                   ROUTERRESULT         50 rows exported
. . exporting table             STATUS_CHECK_TABLE          0 rows exported
. about to export YJH's tables via Conventional Path ...
. . exporting table                  VPNCORP _9999          0 rows exported
. . exporting table                   VPNCORP_8888          0 rows exported
. . exporting table                       AREAINFO        374 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX          2 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          1 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100426        347 rows exported
. . exporting table      INTERFACEACCOUNT_20100427        633 rows exported
. . exporting table      INTERFACEACCOUNT_20100428        809 rows exported
. . exporting table      INTERFACEACCOUNT_20100429        419 rows exported
. . exporting table      INTERFACEACCOUNT_20100430        308 rows exported
. . exporting table      INTERFACEACCOUNT_20100501          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100502          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100503          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100504          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100505         61 rows exported
. . exporting table      INTERFACEACCOUNT_20100506        157 rows exported
. . exporting table      INTERFACEACCOUNT_20100507          0 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR          8 rows exported
. . exporting table                       MISCINFO          2 rows exported
. . exporting table                MISCROUTERTABLE          8 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          2 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          1 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_0         16 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_1         16 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_2          9 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_3          9 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_4          8 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_5         24 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_6         51 rows exported
. . exporting table          MMSGSVCLOG_0506_1_O_0         24 rows exported
. . exporting table          MMSGSVCLOG_0506_1_O_3          8 rows exported
. . exporting table          MMSGSVCLOG_0506_1_O_4         24 rows exported
. . exporting table          MMSGSVCLOG_0506_1_O_5         15 rows exported
. . exporting table          MMSGSVCLOG_0506_1_O_6         15 rows exported
. . exporting table          MMSGSVCLOG_0506_1_O_9          9 rows exported
. . exporting table        MMSGSVCLOG_20100505_1_S         16 rows exported
. . exporting table        MMSGSVCLOG_20100506_1_S         12 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         16 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          0 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          0 rows exported
. . exporting table               MONTHORDERINFO_2          0 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         24 rows exported
. . exporting table              PORTALLOG20100426        184 rows exported
. . exporting table              PORTALLOG20100427        330 rows exported
. . exporting table              PORTALLOG20100428        100 rows exported
. . exporting table              PORTALLOG20100429         75 rows exported
. . exporting table              PORTALLOG20100430         33 rows exported
. . exporting table              PORTALLOG20100505        104 rows exported
. . exporting table              PORTALLOG20100506          8 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          1 rows exported
. . exporting table                      RIGHTINFO        250 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        519 rows exported
. . exporting table                    ROUTERTABLE          5 rows exported
. . exporting table                 RPT_BUSYSERVER         18 rows exported
. . exporting table                  RPT_DELAYTIME          0 rows exported
. . exporting table         RPT_DELAYTIME_20100426         64 rows exported
. . exporting table         RPT_DELAYTIME_20100427        202 rows exported
. . exporting table         RPT_DELAYTIME_20100428        245 rows exported
. . exporting table         RPT_DELAYTIME_20100429        122 rows exported
. . exporting table         RPT_DELAYTIME_20100430         82 rows exported
. . exporting table         RPT_DELAYTIME_20100501          0 rows exported
. . exporting table         RPT_DELAYTIME_20100502          0 rows exported
. . exporting table         RPT_DELAYTIME_20100503          0 rows exported
. . exporting table         RPT_DELAYTIME_20100504          0 rows exported
. . exporting table         RPT_DELAYTIME_20100505         17 rows exported
. . exporting table         RPT_DELAYTIME_20100506         44 rows exported
. . exporting table         RPT_DELAYTIME_20100507          0 rows exported
. . exporting table                  RPT_INTERFACE          0 rows exported
. . exporting table         RPT_INTERFACE_20100426         10 rows exported
. . exporting table         RPT_INTERFACE_20100427        195 rows exported
. . exporting table         RPT_INTERFACE_20100428        385 rows exported
. . exporting table         RPT_INTERFACE_20100429         65 rows exported
. . exporting table         RPT_INTERFACE_20100430          0 rows exported
. . exporting table         RPT_INTERFACE_20100501          0 rows exported
. . exporting table         RPT_INTERFACE_20100502          0 rows exported
. . exporting table         RPT_INTERFACE_20100503          0 rows exported
. . exporting table         RPT_INTERFACE_20100504          0 rows exported
. . exporting table         RPT_INTERFACE_20100505          0 rows exported
. . exporting table         RPT_INTERFACE_20100506         75 rows exported
. . exporting table         RPT_INTERFACE_20100507          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC          6 rows exported
. . exporting table                   RPT_MMSCSUCC          4 rows exported
. . exporting table              RPT_MMSC_20100426          0 rows exported
. . exporting table              RPT_MMSC_20100427         26 rows exported
. . exporting table              RPT_MMSC_20100428          0 rows exported
. . exporting table              RPT_MMSC_20100429          0 rows exported
. . exporting table              RPT_MMSC_20100430          0 rows exported
. . exporting table              RPT_MMSC_20100501          0 rows exported
. . exporting table              RPT_MMSC_20100502          0 rows exported
. . exporting table              RPT_MMSC_20100503          0 rows exported
. . exporting table              RPT_MMSC_20100504          0 rows exported
. . exporting table              RPT_MMSC_20100505          0 rows exported
. . exporting table              RPT_MMSC_20100506          0 rows exported
. . exporting table              RPT_MMSC_20100507          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20100426          0 rows exported
. . exporting table              RPT_VASP_20100427         31 rows exported
. . exporting table              RPT_VASP_20100428          0 rows exported
. . exporting table              RPT_VASP_20100429          0 rows exported
. . exporting table              RPT_VASP_20100430          0 rows exported
. . exporting table              RPT_VASP_20100501          0 rows exported
. . exporting table              RPT_VASP_20100502          0 rows exported
. . exporting table              RPT_VASP_20100503          0 rows exported
. . exporting table              RPT_VASP_20100504          0 rows exported
. . exporting table              RPT_VASP_20100505          0 rows exported
. . exporting table              RPT_VASP_20100506          0 rows exported
. . exporting table              RPT_VASP_20100507          0 rows exported
. . exporting table        SERVICEACCOUNT_20100426        157 rows exported
. . exporting table        SERVICEACCOUNT_20100427        381 rows exported
. . exporting table        SERVICEACCOUNT_20100428        246 rows exported
. . exporting table        SERVICEACCOUNT_20100429        263 rows exported
. . exporting table        SERVICEACCOUNT_20100430        255 rows exported
. . exporting table        SERVICEACCOUNT_20100501          0 rows exported
. . exporting table        SERVICEACCOUNT_20100502          0 rows exported
. . exporting table        SERVICEACCOUNT_20100503          0 rows exported
. . exporting table        SERVICEACCOUNT_20100504          0 rows exported
. . exporting table        SERVICEACCOUNT_20100505         44 rows exported
. . exporting table        SERVICEACCOUNT_20100506         18 rows exported
. . exporting table        SERVICEACCOUNT_20100507          0 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        340 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          2 rows exported
. . exporting table              TMP_ATTACH_RESULT          0 rows exported
. . exporting table                TMP_BASE_RESULT          0 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO         12 rows exported
. . exporting table                  VASPLEVELINFO          2 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP         15 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                    VPNCORP_100          3 rows exported
. . exporting table                    VPNCORP_300          3 rows exported
. . exporting table                  VPNSUBSCRIBER          6 rows exported
. . exporting table                 VPNUNITECORPID          1 rows exported
. about to export WYZ's tables via Conventional Path ...
. . exporting table                       AREAINFO        374 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX          2 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          1 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091223         56 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR         10 rows exported
. . exporting table                       MISCINFO          1 rows exported
. . exporting table                MISCROUTERTABLE          7 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          2 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         16 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          0 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          0 rows exported
. . exporting table               MONTHORDERINFO_2          0 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         22 rows exported
. . exporting table              PORTALLOG20091223         26 rows exported
. . exporting table              PORTALLOG20100106          8 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          2 rows exported
. . exporting table                      RIGHTINFO        251 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        523 rows exported
. . exporting table                    ROUTERTABLE          4 rows exported
. . exporting table                 RPT_BUSYSERVER          1 rows exported
. . exporting table                  RPT_DELAYTIME          0 rows exported
. . exporting table         RPT_DELAYTIME_20091223         16 rows exported
. . exporting table                  RPT_INTERFACE          0 rows exported
. . exporting table         RPT_INTERFACE_20091223         31 rows exported
. . exporting table               RPT_MM7_VASPSUCC          2 rows exported
. . exporting table                   RPT_MMSCSUCC          2 rows exported
. . exporting table              RPT_MMSC_20091223          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20091223          0 rows exported
. . exporting table        SERVICEACCOUNT_20091223         23 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        328 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          2 rows exported
. . exporting table              TMP_ATTACH_RESULT          0 rows exported
. . exporting table                TMP_BASE_RESULT          0 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO         11 rows exported
. . exporting table                  VASPLEVELINFO          2 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP          9 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. about to export MMSC's tables via Conventional Path ...
. . exporting table               ACCESSEDADDRINFO          0 rows exported
. . exporting table                       AREAINFO        375 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX      36122 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         27 rows exported
. . exporting table              CNTADAPTRULETABLE          1 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091031          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091109          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091111          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091112          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091113          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091117          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091118          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091119          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091120          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091121          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091122          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091123          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091124          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091125          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091126          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091127          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091128          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091129          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091130          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091201          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091202          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091203          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091204          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091205          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091206          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091207          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091208          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091209          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091218          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091219          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20091220          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100111          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100119          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100120          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100121          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100122          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100123          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100124          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100125          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100129          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100130          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100131          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100201          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100202          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100203          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100205          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100206          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100207          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100208          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100209          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100210          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100211          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100212          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100213          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100214          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100215          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100216          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100217          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100218          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100219          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100220          0 rows exported
. . exporting table      DELAYTIMEACCOUNT_20100221          0 rows exported
. . exporting table               DETAILSTATUSCODE        242 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                    ENUMSRVINFO          1 rows exported
. . exporting table             EXTEMAILSERVERINFO          7 rows exported
. . exporting table           EXTEMAILSRVLEVELINFO          1 rows exported
. . exporting table                    EXTMMSCINFO          0 rows exported
. . exporting table                  GWACCOUNTINFO          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091031          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091109          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091111          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091112          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091113          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091117          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091118          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091119          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091120          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091121          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091122          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091123          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091124          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091125          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091126          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091127          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091128          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091129          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091130          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091201          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091202          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091203          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091204          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091205          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091206          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091207          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091208          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091209          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091218          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091219          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20091220          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100111          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100119          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100120          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100121          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100122          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100123          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100124          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100125          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100129          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100130          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100131          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100201          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100202          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100203          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100205          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100206          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100207          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100208          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100209          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100210          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100211          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100212          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100213          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100214          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100215          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100216          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100217          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100218          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100219          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100220          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100221          0 rows exported
. . exporting table    GWINTERFACEACCOUNT_20100222          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091031          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091109          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091111          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091112          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091113          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091117          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091118          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091119          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091120          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091121          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091122          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091123          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091124          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091125          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091126          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091127          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091128          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091129          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091130          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091201          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091202          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091203          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091204          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091205          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091206          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091207          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091208          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091209          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091218          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091219          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20091220          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100111          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100119          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100120          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100121          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100122          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100123          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100124          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100125          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100129          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100130          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100131          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100201          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100202          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100203          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100205          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100206          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100207          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100208          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100209          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100210          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100211          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100212          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100213          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100214          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100215          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100216          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100217          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100218          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100219          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100220          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100221          0 rows exported
. . exporting table      GWSERVICEACCOUNT_20100222          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table                        HOLIDAY          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091031          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091109          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091111          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091112          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091113          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091117          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091118          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091119          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091120          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091121          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091122          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091123          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091124          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091125          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091126          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091127          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091128          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091129          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091130          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091201          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091202          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091203          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091204          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091205          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091206          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091207          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091208          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091209          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091218          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091219          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20091220          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100111          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100119          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100120          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100121          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100122          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100123          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100124          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100125          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100129          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100130          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100131          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100201          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100202          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100203          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100205          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100206          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100207          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100208          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100209          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100210          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100211          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100212          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100213          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100214          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100215          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100216          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100217          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100218          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100219          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100220          0 rows exported
. . exporting table    IGDELAYTIMEACCOUNT_20100221          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091031          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091109          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091111          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091112          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091113          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091117          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091118          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091119          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091120          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091121          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091122          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091123          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091124          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091125          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091126          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091127          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091128          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091129          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091130          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091201          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091202          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091203          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091204          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091205          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091206          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091207          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091208          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091209          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091218          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091219          0 rows exported
. . exporting table      INTERFACEACCOUNT_20091220          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100111          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100119          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100120          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100121          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100122          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100123          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100124          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100125          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100129          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100130          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100131          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100201          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100202          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100203          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100205          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100206          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100207          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100208          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100209          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100210          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100211          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100212          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100213          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100214          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100215          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100216          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100217          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100218          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100219          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100220          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100221          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100222          0 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table              LIMITTIMESTRATEGY          0 rows exported
. . exporting table                 MCASSERVERINFO          1 rows exported
. . exporting table                 MCPSSERVERINFO          1 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         36 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR          9 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          4 rows exported
. . exporting table                       MMSCINFO          1 rows exported
. . exporting table                       MMSDINFO          0 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         23 rows exported
. . exporting table                        MODULES         23 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         22 rows exported
. . exporting table              NUMBERPREFIXFOR3G          0 rows exported
. . exporting table               PERSONALIZEDINFO          0 rows exported
. . exporting table                        PPGINFO          2 rows exported
. . exporting table                      PPGROUTER          1 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table               PUSHDRERRMAPPING         87 rows exported
. . exporting table                       PUSHINFO          1 rows exported
. . exporting table                 PUSHRECORDINFO          0 rows exported
. . exporting table                 RCPTSUBSCRIBER          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table               REJECTEDADDRINFO          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091031          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091109          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091111          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091112          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091113          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091117          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091118          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091119          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091120          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091121          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091122          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091123          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091124          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091125          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091126          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091127          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091128          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091129          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091130          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091201          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091202          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091203          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091204          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091205          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091206          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091207          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091208          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091209          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091218          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091219          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20091220          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100111          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100119          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100120          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100121          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100122          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100123          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100124          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100125          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100129          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100130          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100131          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100201          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100202          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100203          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100205          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100206          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100207          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100208          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100209          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100210          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100211          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100212          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100213          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100214          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100215          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100216          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100217          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100218          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100219          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100220          0 rows exported
. . exporting table    RENEWEDPHONENUMBER_20100221          0 rows exported
. . exporting table                  RENTALFEEINFO          2 rows exported
. . exporting table                REPLYCHARGEINFO          0 rows exported
. . exporting table                      RIGHTINFO        460 rows exported
. . exporting table                           ROLE          6 rows exported
. . exporting table                   ROLEMAPRIGHT        997 rows exported
. . exporting table                    ROUTERTABLE          1 rows exported
. . exporting table                 RPT_BUSYSERVER       2361 rows exported
. . exporting table                RPT_MM1_WAPSUCC          6 rows exported
. . exporting table                 RPT_MM3_ESSUCC          0 rows exported
. . exporting table               RPT_MM4_MMSCSUCC          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC         12 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table                RUBBISHMSGLIMIT          2 rows exported
. . exporting table                        SCPINFO          3 rows exported
. . exporting table                      SCPROUTER          3 rows exported
. . exporting table        SERVICEACCOUNT_20091031          0 rows exported
. . exporting table        SERVICEACCOUNT_20091109          0 rows exported
. . exporting table        SERVICEACCOUNT_20091111          0 rows exported
. . exporting table        SERVICEACCOUNT_20091112          0 rows exported
. . exporting table        SERVICEACCOUNT_20091113          0 rows exported
. . exporting table        SERVICEACCOUNT_20091117          0 rows exported
. . exporting table        SERVICEACCOUNT_20091118          0 rows exported
. . exporting table        SERVICEACCOUNT_20091119          0 rows exported
. . exporting table        SERVICEACCOUNT_20091120          0 rows exported
. . exporting table        SERVICEACCOUNT_20091121          0 rows exported
. . exporting table        SERVICEACCOUNT_20091122          0 rows exported
. . exporting table        SERVICEACCOUNT_20091123          0 rows exported
. . exporting table        SERVICEACCOUNT_20091124          0 rows exported
. . exporting table        SERVICEACCOUNT_20091125          0 rows exported
. . exporting table        SERVICEACCOUNT_20091126          0 rows exported
. . exporting table        SERVICEACCOUNT_20091127          0 rows exported
. . exporting table        SERVICEACCOUNT_20091128          0 rows exported
. . exporting table        SERVICEACCOUNT_20091129          0 rows exported
. . exporting table        SERVICEACCOUNT_20091130          0 rows exported
. . exporting table        SERVICEACCOUNT_20091201          0 rows exported
. . exporting table        SERVICEACCOUNT_20091202          0 rows exported
. . exporting table        SERVICEACCOUNT_20091203          0 rows exported
. . exporting table        SERVICEACCOUNT_20091204          0 rows exported
. . exporting table        SERVICEACCOUNT_20091205          0 rows exported
. . exporting table        SERVICEACCOUNT_20091206          0 rows exported
. . exporting table        SERVICEACCOUNT_20091207          0 rows exported
. . exporting table        SERVICEACCOUNT_20091208          0 rows exported
. . exporting table        SERVICEACCOUNT_20091209          0 rows exported
. . exporting table        SERVICEACCOUNT_20091218          0 rows exported
. . exporting table        SERVICEACCOUNT_20091219          0 rows exported
. . exporting table        SERVICEACCOUNT_20091220          0 rows exported
. . exporting table        SERVICEACCOUNT_20100111          0 rows exported
. . exporting table        SERVICEACCOUNT_20100119          0 rows exported
. . exporting table        SERVICEACCOUNT_20100120          0 rows exported
. . exporting table        SERVICEACCOUNT_20100121          0 rows exported
. . exporting table        SERVICEACCOUNT_20100122          0 rows exported
. . exporting table        SERVICEACCOUNT_20100123          0 rows exported
. . exporting table        SERVICEACCOUNT_20100124          0 rows exported
. . exporting table        SERVICEACCOUNT_20100125          0 rows exported
. . exporting table        SERVICEACCOUNT_20100129          0 rows exported
. . exporting table        SERVICEACCOUNT_20100130          0 rows exported
. . exporting table        SERVICEACCOUNT_20100131          0 rows exported
. . exporting table        SERVICEACCOUNT_20100201          0 rows exported
. . exporting table        SERVICEACCOUNT_20100202          0 rows exported
. . exporting table        SERVICEACCOUNT_20100203          0 rows exported
. . exporting table        SERVICEACCOUNT_20100205          0 rows exported
. . exporting table        SERVICEACCOUNT_20100206          0 rows exported
. . exporting table        SERVICEACCOUNT_20100207          0 rows exported
. . exporting table        SERVICEACCOUNT_20100208          0 rows exported
. . exporting table        SERVICEACCOUNT_20100209          0 rows exported
. . exporting table        SERVICEACCOUNT_20100210          0 rows exported
. . exporting table        SERVICEACCOUNT_20100211          0 rows exported
. . exporting table        SERVICEACCOUNT_20100212          0 rows exported
. . exporting table        SERVICEACCOUNT_20100213          0 rows exported
. . exporting table        SERVICEACCOUNT_20100214          0 rows exported
. . exporting table        SERVICEACCOUNT_20100215          0 rows exported
. . exporting table        SERVICEACCOUNT_20100216          0 rows exported
. . exporting table        SERVICEACCOUNT_20100217          0 rows exported
. . exporting table        SERVICEACCOUNT_20100218          0 rows exported
. . exporting table        SERVICEACCOUNT_20100219          0 rows exported
. . exporting table        SERVICEACCOUNT_20100220          0 rows exported
. . exporting table        SERVICEACCOUNT_20100221          0 rows exported
. . exporting table        SERVICEACCOUNT_20100222          0 rows exported
. . exporting table                    SMSNOTEINFO         35 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                    SMTPSTSINFO          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        132 rows exported
. . exporting table                     SUBSCRIBER          4 rows exported
. . exporting table                   SUBSNUMGROUP          0 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        523 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          0 rows exported
. . exporting table              TMP_ATTACH_RESULT          0 rows exported
. . exporting table                TMP_BASE_RESULT          0 rows exported
. . exporting table            TMP_USERPHONENUMBER          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                     USERBWLIST          0 rows exported
. . exporting table                USERPHONENUMBER          0 rows exported
. . exporting table                VASDELIVERGROUP          0 rows exported
. . exporting table                   VASLOCALLIST          0 rows exported
. . exporting table                       VASPINFO          1 rows exported
. . exporting table                  VASPLEVELINFO          1 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICEINFO          1 rows exported
. . exporting table                VASPSERVICE_SUP          7 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table                  VASSWITCHINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                      WAPGWINFO         25 rows exported
. . exporting table                WHITENOTIFYLIST          0 rows exported
. about to export ZJUN's tables via Conventional Path ...
. . exporting table                       AREAINFO        374 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX          2 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          1 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100406          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100427         97 rows exported
. . exporting table      INTERFACEACCOUNT_20100428          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100429        100 rows exported
. . exporting table      INTERFACEACCOUNT_20100430        198 rows exported
. . exporting table      INTERFACEACCOUNT_20100501          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100502          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100503          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100504          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100505          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100506          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100507          0 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR          8 rows exported
. . exporting table                       MISCINFO          2 rows exported
. . exporting table                MISCROUTERTABLE          9 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          2 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_0         15 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_1         59 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_3         74 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_4         24 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_5          9 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_6         24 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_7          5 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_8         40 rows exported
. . exporting table          MMSGSVCLOG_0427_1_O_9         95 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_0         18 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_1         27 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_5         11 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_6         37 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_7         24 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_8          9 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_9         20 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_0        194 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_1        121 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_2        297 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_3        306 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_4        224 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_5        191 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_6        190 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_7        101 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_8        135 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_9        212 rows exported
. . exporting table        MMSGSVCLOG_20100427_1_S         59 rows exported
. . exporting table        MMSGSVCLOG_20100429_1_S         14 rows exported
. . exporting table        MMSGSVCLOG_20100430_1_S        173 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         17 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          0 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          0 rows exported
. . exporting table               MONTHORDERINFO_2          0 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         24 rows exported
. . exporting table              PORTALLOG20100427         79 rows exported
. . exporting table              PORTALLOG20100429         31 rows exported
. . exporting table              PORTALLOG20100430          8 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          1 rows exported
. . exporting table                      RIGHTINFO        249 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        518 rows exported
. . exporting table                    ROUTERTABLE          5 rows exported
. . exporting table                 RPT_BUSYSERVER        184 rows exported
. . exporting table                  RPT_DELAYTIME         37 rows exported
. . exporting table         RPT_DELAYTIME_20100505          0 rows exported
. . exporting table         RPT_DELAYTIME_20100506          0 rows exported
. . exporting table         RPT_DELAYTIME_20100507          0 rows exported
. . exporting table                  RPT_INTERFACE         14 rows exported
. . exporting table         RPT_INTERFACE_20100505          0 rows exported
. . exporting table         RPT_INTERFACE_20100506          0 rows exported
. . exporting table         RPT_INTERFACE_20100507          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC         16 rows exported
. . exporting table                   RPT_MMSCSUCC         14 rows exported
. . exporting table              RPT_MMSC_20100406          0 rows exported
. . exporting table              RPT_MMSC_20100427          0 rows exported
. . exporting table              RPT_MMSC_20100428          0 rows exported
. . exporting table              RPT_MMSC_20100429          0 rows exported
. . exporting table              RPT_MMSC_20100430          0 rows exported
. . exporting table              RPT_MMSC_20100501          0 rows exported
. . exporting table              RPT_MMSC_20100502          0 rows exported
. . exporting table              RPT_MMSC_20100503          0 rows exported
. . exporting table              RPT_MMSC_20100504          0 rows exported
. . exporting table              RPT_MMSC_20100505          0 rows exported
. . exporting table              RPT_MMSC_20100506          0 rows exported
. . exporting table              RPT_MMSC_20100507          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20100406          0 rows exported
. . exporting table              RPT_VASP_20100427          0 rows exported
. . exporting table              RPT_VASP_20100428          0 rows exported
. . exporting table              RPT_VASP_20100429          0 rows exported
. . exporting table              RPT_VASP_20100430          0 rows exported
. . exporting table              RPT_VASP_20100501          0 rows exported
. . exporting table              RPT_VASP_20100502          0 rows exported
. . exporting table              RPT_VASP_20100503          0 rows exported
. . exporting table              RPT_VASP_20100504          0 rows exported
. . exporting table              RPT_VASP_20100505          0 rows exported
. . exporting table              RPT_VASP_20100506          0 rows exported
. . exporting table              RPT_VASP_20100507          0 rows exported
. . exporting table        SERVICEACCOUNT_20100406          0 rows exported
. . exporting table        SERVICEACCOUNT_20100427         56 rows exported
. . exporting table        SERVICEACCOUNT_20100428          0 rows exported
. . exporting table        SERVICEACCOUNT_20100429         53 rows exported
. . exporting table        SERVICEACCOUNT_20100430        114 rows exported
. . exporting table        SERVICEACCOUNT_20100501          0 rows exported
. . exporting table        SERVICEACCOUNT_20100502          0 rows exported
. . exporting table        SERVICEACCOUNT_20100503          0 rows exported
. . exporting table        SERVICEACCOUNT_20100504          0 rows exported
. . exporting table        SERVICEACCOUNT_20100505          0 rows exported
. . exporting table        SERVICEACCOUNT_20100506          0 rows exported
. . exporting table        SERVICEACCOUNT_20100507          0 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        336 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          2 rows exported
. . exporting table              TMP_ATTACH_RESULT          0 rows exported
. . exporting table                TMP_BASE_RESULT          0 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO         13 rows exported
. . exporting table                  VASPLEVELINFO          2 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP         15 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                    VPNCORP_100          3 rows exported
. . exporting table                    VPNCORP_300          3 rows exported
. . exporting table                  VPNSUBSCRIBER          6 rows exported
. . exporting table                 VPNUNITECORPID          1 rows exported
. about to export AUTOTEST's tables via Conventional Path ...
. . exporting table                       AREAINFO        374 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX      36158 rows exported
. . exporting table                 AREANUMBER_BAK        728 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          5 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100202        332 rows exported
. . exporting table      INTERFACEACCOUNT_20100203         28 rows exported
. . exporting table      INTERFACEACCOUNT_20100204        102 rows exported
. . exporting table      INTERFACEACCOUNT_20100205         15 rows exported
. . exporting table      INTERFACEACCOUNT_20100206          7 rows exported
. . exporting table      INTERFACEACCOUNT_20100207          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100208          4 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR         15 rows exported
. . exporting table                       MISCINFO          1 rows exported
. . exporting table                MISCROUTERTABLE          1 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          1 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_0        256 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_1        238 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_2        308 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_3        406 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_4        160 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_5        352 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_6        276 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_7        322 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_8        296 rows exported
. . exporting table          MMSGSVCLOG_0202_1_O_9        428 rows exported
. . exporting table          MMSGSVCLOG_0203_1_O_4         18 rows exported
. . exporting table          MMSGSVCLOG_0203_1_O_6         18 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_1         20 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_2         38 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_3         18 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_4         46 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_5         36 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_6         18 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_7         20 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_8         88 rows exported
. . exporting table          MMSGSVCLOG_0204_1_O_9         28 rows exported
. . exporting table        MMSGSVCLOG_20100202_1_S        536 rows exported
. . exporting table        MMSGSVCLOG_20100203_1_S          4 rows exported
. . exporting table        MMSGSVCLOG_20100204_1_S         42 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         16 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          0 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          0 rows exported
. . exporting table               MONTHORDERINFO_2          0 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         24 rows exported
. . exporting table                NETWORKCODE_BAK         44 rows exported
. . exporting table              PORTALLOG20100202        124 rows exported
. . exporting table              PORTALLOG20100203        158 rows exported
. . exporting table              PORTALLOG20100204        242 rows exported
. . exporting table              PORTALLOG20100205         42 rows exported
. . exporting table              PORTALLOG20100208         74 rows exported
. . exporting table              PORTALLOG20100209         52 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          2 rows exported
. . exporting table                      RIGHTINFO        247 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        515 rows exported
. . exporting table                    ROUTERTABLE          4 rows exported
. . exporting table                 RPT_BUSYSERVER        107 rows exported
. . exporting table                  RPT_DELAYTIME          0 rows exported
. . exporting table         RPT_DELAYTIME_20100202         66 rows exported
. . exporting table         RPT_DELAYTIME_20100203         12 rows exported
. . exporting table         RPT_DELAYTIME_20100204         34 rows exported
. . exporting table         RPT_DELAYTIME_20100205          5 rows exported
. . exporting table         RPT_DELAYTIME_20100206          1 rows exported
. . exporting table         RPT_DELAYTIME_20100207          0 rows exported
. . exporting table         RPT_DELAYTIME_20100208          1 rows exported
. . exporting table                  RPT_INTERFACE          0 rows exported
. . exporting table         RPT_INTERFACE_20100202         75 rows exported
. . exporting table         RPT_INTERFACE_20100203         12 rows exported
. . exporting table         RPT_INTERFACE_20100204         30 rows exported
. . exporting table         RPT_INTERFACE_20100205          0 rows exported
. . exporting table         RPT_INTERFACE_20100206          1 rows exported
. . exporting table         RPT_INTERFACE_20100207          0 rows exported
. . exporting table         RPT_INTERFACE_20100208          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC         10 rows exported
. . exporting table                   RPT_MMSCSUCC         22 rows exported
. . exporting table              RPT_MMSC_20100202          0 rows exported
. . exporting table              RPT_MMSC_20100203          0 rows exported
. . exporting table              RPT_MMSC_20100204          0 rows exported
. . exporting table              RPT_MMSC_20100205          0 rows exported
. . exporting table              RPT_MMSC_20100206          0 rows exported
. . exporting table              RPT_MMSC_20100207          0 rows exported
. . exporting table              RPT_MMSC_20100208          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20100202          0 rows exported
. . exporting table              RPT_VASP_20100203          0 rows exported
. . exporting table              RPT_VASP_20100204          0 rows exported
. . exporting table              RPT_VASP_20100205          0 rows exported
. . exporting table              RPT_VASP_20100206          0 rows exported
. . exporting table              RPT_VASP_20100207          0 rows exported
. . exporting table              RPT_VASP_20100208          0 rows exported
. . exporting table        SERVICEACCOUNT_20100202        131 rows exported
. . exporting table        SERVICEACCOUNT_20100203         20 rows exported
. . exporting table        SERVICEACCOUNT_20100204         66 rows exported
. . exporting table        SERVICEACCOUNT_20100205          5 rows exported
. . exporting table        SERVICEACCOUNT_20100206          6 rows exported
. . exporting table        SERVICEACCOUNT_20100207          0 rows exported
. . exporting table        SERVICEACCOUNT_20100208          4 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        333 rows exported
. . exporting table            SYSTEMPARAMETER_BAK        664 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          0 rows exported
. . exporting table              TMP_ATTACH_RESULT        196 rows exported
. . exporting table                TMP_BASE_RESULT        228 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO          1 rows exported
. . exporting table                  VASPLEVELINFO          1 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP          6 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                    VPNCORP_100          3 rows exported
. . exporting table                    VPNCORP_300          3 rows exported
. . exporting table                  VPNSUBSCRIBER          0 rows exported
. . exporting table                 VPNUNITECORPID          0 rows exported
. about to export AIXTEST's tables via Conventional Path ...
. . exporting table                       AREAINFO        374 rows exported
. . exporting table                   AREAINFO_BAK        748 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX          3 rows exported
. . exporting table                 AREANUMBER_BAK        728 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          1 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100324         72 rows exported
. . exporting table      INTERFACEACCOUNT_20100325        263 rows exported
. . exporting table      INTERFACEACCOUNT_20100326        120 rows exported
. . exporting table      INTERFACEACCOUNT_20100327        359 rows exported
. . exporting table      INTERFACEACCOUNT_20100328        113 rows exported
. . exporting table      INTERFACEACCOUNT_20100329        123 rows exported
. . exporting table      INTERFACEACCOUNT_20100330        751 rows exported
. . exporting table      INTERFACEACCOUNT_20100331        843 rows exported
. . exporting table      INTERFACEACCOUNT_20100401          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100402         42 rows exported
. . exporting table      INTERFACEACCOUNT_20100403          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100404          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100405          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100406          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100407          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100416         86 rows exported
. . exporting table      INTERFACEACCOUNT_20100417          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100420          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100421          0 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR         13 rows exported
. . exporting table                       MISCINFO          2 rows exported
. . exporting table                MISCROUTERTABLE          8 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          2 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_0         92 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_1         46 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_2         60 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_3         16 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_4         46 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_5         46 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_6         48 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_7         20 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_8         78 rows exported
. . exporting table          MMSGSVCLOG_0324_1_O_9        138 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_0        116 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_1         58 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_2         50 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_3         74 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_4         78 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_5         80 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_6         96 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_7         28 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_8         58 rows exported
. . exporting table          MMSGSVCLOG_0325_1_O_9        112 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_0        192 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_1        296 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_2        272 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_3        226 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_4        178 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_5        230 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_6        284 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_7        282 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_8        258 rows exported
. . exporting table          MMSGSVCLOG_0326_1_O_9        238 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_0       2450 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_1       2176 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_2       2734 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_3       2702 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_4       3590 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_5       3924 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_6       3432 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_7       2946 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_8       2482 rows exported
. . exporting table          MMSGSVCLOG_0327_1_O_9       2118 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_0       1614 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_1       1360 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_2       1390 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_3       1684 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_4       1598 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_5       1814 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_6       1758 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_7       1624 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_8       1386 rows exported
. . exporting table          MMSGSVCLOG_0328_1_O_9       1454 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_0       1250 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_1       1344 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_2       1367 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_3       1399 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_4       1208 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_5       1385 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_6       1351 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_7       1630 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_8       1420 rows exported
. . exporting table          MMSGSVCLOG_0329_1_O_9       1267 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_0       1545 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_1       1706 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_2       1470 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_3       1309 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_4       1219 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_5       1456 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_6       1384 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_7       1539 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_8       1401 rows exported
. . exporting table          MMSGSVCLOG_0330_1_O_9       1540 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_0      17978 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_1      18403 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_2      18454 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_3      18122 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_4      17853 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_5      17472 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_6      17510 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_7      17667 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_8      18157 rows exported
. . exporting table          MMSGSVCLOG_0331_1_O_9      18110 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_0         78 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_1        143 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_2         57 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_3         39 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_4         56 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_5        192 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_6         87 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_7        135 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_8        155 rows exported
. . exporting table          MMSGSVCLOG_0401_1_O_9        103 rows exported
. . exporting table          MMSGSVCLOG_0402_1_O_2         36 rows exported
. . exporting table          MMSGSVCLOG_0402_1_O_3         42 rows exported
. . exporting table          MMSGSVCLOG_0402_1_O_6         16 rows exported
. . exporting table          MMSGSVCLOG_0402_1_O_8         16 rows exported
. . exporting table        MMSGSVCLOG_20100324_1_S         86 rows exported
. . exporting table        MMSGSVCLOG_20100325_1_S        108 rows exported
. . exporting table        MMSGSVCLOG_20100326_1_S        404 rows exported
. . exporting table        MMSGSVCLOG_20100327_1_S       4118 rows exported
. . exporting table        MMSGSVCLOG_20100328_1_S       2322 rows exported
. . exporting table        MMSGSVCLOG_20100329_1_S       2076 rows exported
. . exporting table        MMSGSVCLOG_20100330_1_S       2241 rows exported
. . exporting table        MMSGSVCLOG_20100331_1_S      23131 rows exported
. . exporting table        MMSGSVCLOG_20100401_1_S        168 rows exported
. . exporting table        MMSGSVCLOG_20100402_1_S         16 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         16 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          0 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          0 rows exported
. . exporting table               MONTHORDERINFO_2          0 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         24 rows exported
. . exporting table                NETWORKCODE_BAK         44 rows exported
. . exporting table              PORTALLOG20100323         22 rows exported
. . exporting table              PORTALLOG20100324         66 rows exported
. . exporting table              PORTALLOG20100325        200 rows exported
. . exporting table              PORTALLOG20100326         74 rows exported
. . exporting table              PORTALLOG20100327        164 rows exported
. . exporting table              PORTALLOG20100329        176 rows exported
. . exporting table              PORTALLOG20100330        133 rows exported
. . exporting table              PORTALLOG20100331         90 rows exported
. . exporting table              PORTALLOG20100402         64 rows exported
. . exporting table              PORTALLOG20100416         32 rows exported
. . exporting table              PORTALLOG20100420         30 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          1 rows exported
. . exporting table                      RIGHTINFO        250 rows exported
. . exporting table                  RIGHTINFO_BAK        494 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        519 rows exported
. . exporting table               ROLEMAPRIGHT_BAK       1030 rows exported
. . exporting table                    ROUTERTABLE          5 rows exported
. . exporting table                 RPT_BUSYSERVER         56 rows exported
. . exporting table                  RPT_DELAYTIME          0 rows exported
. . exporting table         RPT_DELAYTIME_20100324         24 rows exported
. . exporting table         RPT_DELAYTIME_20100325         86 rows exported
. . exporting table         RPT_DELAYTIME_20100326         36 rows exported
. . exporting table         RPT_DELAYTIME_20100327        122 rows exported
. . exporting table         RPT_DELAYTIME_20100328         40 rows exported
. . exporting table         RPT_DELAYTIME_20100329         37 rows exported
. . exporting table         RPT_DELAYTIME_20100330        246 rows exported
. . exporting table         RPT_DELAYTIME_20100331        242 rows exported
. . exporting table         RPT_DELAYTIME_20100401          0 rows exported
. . exporting table         RPT_DELAYTIME_20100402         11 rows exported
. . exporting table         RPT_DELAYTIME_20100403          0 rows exported
. . exporting table         RPT_DELAYTIME_20100404          0 rows exported
. . exporting table         RPT_DELAYTIME_20100405          0 rows exported
. . exporting table         RPT_DELAYTIME_20100406          0 rows exported
. . exporting table         RPT_DELAYTIME_20100407          0 rows exported
. . exporting table         RPT_DELAYTIME_20100416         18 rows exported
. . exporting table         RPT_DELAYTIME_20100417          0 rows exported
. . exporting table         RPT_DELAYTIME_20100420          0 rows exported
. . exporting table         RPT_DELAYTIME_20100421          0 rows exported
. . exporting table                  RPT_INTERFACE          0 rows exported
. . exporting table         RPT_INTERFACE_20100324         36 rows exported
. . exporting table         RPT_INTERFACE_20100325        116 rows exported
. . exporting table         RPT_INTERFACE_20100326         40 rows exported
. . exporting table         RPT_INTERFACE_20100327        203 rows exported
. . exporting table         RPT_INTERFACE_20100328         63 rows exported
. . exporting table         RPT_INTERFACE_20100329         44 rows exported
. . exporting table         RPT_INTERFACE_20100330        456 rows exported
. . exporting table         RPT_INTERFACE_20100331        229 rows exported
. . exporting table         RPT_INTERFACE_20100401          0 rows exported
. . exporting table         RPT_INTERFACE_20100402         16 rows exported
. . exporting table         RPT_INTERFACE_20100403          0 rows exported
. . exporting table         RPT_INTERFACE_20100404          0 rows exported
. . exporting table         RPT_INTERFACE_20100405          0 rows exported
. . exporting table         RPT_INTERFACE_20100406          0 rows exported
. . exporting table         RPT_INTERFACE_20100407          0 rows exported
. . exporting table         RPT_INTERFACE_20100416         52 rows exported
. . exporting table         RPT_INTERFACE_20100417          0 rows exported
. . exporting table         RPT_INTERFACE_20100420          0 rows exported
. . exporting table         RPT_INTERFACE_20100421          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC          6 rows exported
. . exporting table                   RPT_MMSCSUCC          8 rows exported
. . exporting table              RPT_MMSC_20100324          0 rows exported
. . exporting table              RPT_MMSC_20100325          0 rows exported
. . exporting table              RPT_MMSC_20100326          0 rows exported
. . exporting table              RPT_MMSC_20100327          0 rows exported
. . exporting table              RPT_MMSC_20100328          0 rows exported
. . exporting table              RPT_MMSC_20100329          0 rows exported
. . exporting table              RPT_MMSC_20100330          0 rows exported
. . exporting table              RPT_MMSC_20100331          0 rows exported
. . exporting table              RPT_MMSC_20100401          0 rows exported
. . exporting table              RPT_MMSC_20100402          0 rows exported
. . exporting table              RPT_MMSC_20100403          0 rows exported
. . exporting table              RPT_MMSC_20100404          0 rows exported
. . exporting table              RPT_MMSC_20100405          0 rows exported
. . exporting table              RPT_MMSC_20100406          0 rows exported
. . exporting table              RPT_MMSC_20100407          0 rows exported
. . exporting table              RPT_MMSC_20100416          0 rows exported
. . exporting table              RPT_MMSC_20100417          0 rows exported
. . exporting table              RPT_MMSC_20100420          0 rows exported
. . exporting table              RPT_MMSC_20100421          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20100324          0 rows exported
. . exporting table              RPT_VASP_20100325          0 rows exported
. . exporting table              RPT_VASP_20100326          0 rows exported
. . exporting table              RPT_VASP_20100327          0 rows exported
. . exporting table              RPT_VASP_20100328          0 rows exported
. . exporting table              RPT_VASP_20100329          0 rows exported
. . exporting table              RPT_VASP_20100330          0 rows exported
. . exporting table              RPT_VASP_20100331          0 rows exported
. . exporting table              RPT_VASP_20100401          0 rows exported
. . exporting table              RPT_VASP_20100402          0 rows exported
. . exporting table              RPT_VASP_20100403          0 rows exported
. . exporting table              RPT_VASP_20100404          0 rows exported
. . exporting table              RPT_VASP_20100405          0 rows exported
. . exporting table              RPT_VASP_20100406          0 rows exported
. . exporting table              RPT_VASP_20100407          0 rows exported
. . exporting table              RPT_VASP_20100416          0 rows exported
. . exporting table              RPT_VASP_20100417          0 rows exported
. . exporting table              RPT_VASP_20100420          0 rows exported
. . exporting table              RPT_VASP_20100421          0 rows exported
. . exporting table        SERVICEACCOUNT_20100324         48 rows exported
. . exporting table        SERVICEACCOUNT_20100325        117 rows exported
. . exporting table        SERVICEACCOUNT_20100326         65 rows exported
. . exporting table        SERVICEACCOUNT_20100327        200 rows exported
. . exporting table        SERVICEACCOUNT_20100328         71 rows exported
. . exporting table        SERVICEACCOUNT_20100329         96 rows exported
. . exporting table        SERVICEACCOUNT_20100330        204 rows exported
. . exporting table        SERVICEACCOUNT_20100331        516 rows exported
. . exporting table        SERVICEACCOUNT_20100401          0 rows exported
. . exporting table        SERVICEACCOUNT_20100402         19 rows exported
. . exporting table        SERVICEACCOUNT_20100403          0 rows exported
. . exporting table        SERVICEACCOUNT_20100404          0 rows exported
. . exporting table        SERVICEACCOUNT_20100405          0 rows exported
. . exporting table        SERVICEACCOUNT_20100406          0 rows exported
. . exporting table        SERVICEACCOUNT_20100407          0 rows exported
. . exporting table        SERVICEACCOUNT_20100416         33 rows exported
. . exporting table        SERVICEACCOUNT_20100417          0 rows exported
. . exporting table        SERVICEACCOUNT_20100420          0 rows exported
. . exporting table        SERVICEACCOUNT_20100421          0 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        340 rows exported
. . exporting table            SYSTEMPARAMETER_BAK        662 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          2 rows exported
. . exporting table              TMP_ATTACH_RESULT          0 rows exported
. . exporting table                TMP_BASE_RESULT          0 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO         12 rows exported
. . exporting table                  VASPLEVELINFO          2 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP         15 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                    VPNCORP_100          3 rows exported
. . exporting table                    VPNCORP_300          3 rows exported
. . exporting table                  VPNSUBSCRIBER          6 rows exported
. . exporting table                 VPNUNITECORPID          1 rows exported
. about to export CHYJ's tables via Conventional Path ...
. . exporting table                       AREAINFO        374 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX      36158 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         21 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          5 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100421          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100422          0 rows exported
. . exporting table                    INTERPREFIX         21 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR         10 rows exported
. . exporting table                       MISCINFO          0 rows exported
. . exporting table                MISCROUTERTABLE          0 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          1 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         16 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          0 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          0 rows exported
. . exporting table               MONTHORDERINFO_2          0 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         24 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          1 rows exported
. . exporting table                      RIGHTINFO        250 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        519 rows exported
. . exporting table                    ROUTERTABLE          2 rows exported
. . exporting table                 RPT_BUSYSERVER         19 rows exported
. . exporting table                  RPT_DELAYTIME          0 rows exported
. . exporting table         RPT_DELAYTIME_20100421          0 rows exported
. . exporting table         RPT_DELAYTIME_20100422          0 rows exported
. . exporting table                  RPT_INTERFACE          0 rows exported
. . exporting table         RPT_INTERFACE_20100421          0 rows exported
. . exporting table         RPT_INTERFACE_20100422          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC          0 rows exported
. . exporting table                   RPT_MMSCSUCC          0 rows exported
. . exporting table              RPT_MMSC_20100421          0 rows exported
. . exporting table              RPT_MMSC_20100422          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20100421          0 rows exported
. . exporting table              RPT_VASP_20100422          0 rows exported
. . exporting table        SERVICEACCOUNT_20100421          0 rows exported
. . exporting table        SERVICEACCOUNT_20100422          0 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         13 rows exported
. . exporting table                SYSTEMPARAMETER        340 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          0 rows exported
. . exporting table              TMP_ATTACH_RESULT          0 rows exported
. . exporting table                TMP_BASE_RESULT          0 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO          1 rows exported
. . exporting table                  VASPLEVELINFO          1 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP          6 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                  VPNSUBSCRIBER          0 rows exported
. . exporting table                 VPNUNITECORPID          0 rows exported
. about to export SYC's tables via Conventional Path ...
. . exporting table                       AREAINFO        375 rows exported
. . exporting table                     AREANUMBER        364 rows exported
. . exporting table               AREANUMBERPREFIX          4 rows exported
. . exporting table                BEARERVALUELIST          3 rows exported
. . exporting table                    CARRIERINFO          1 rows exported
. . exporting table               CHARGINGKPCONFIG         28 rows exported
. . exporting table                 CONNECTIONINFO          0 rows exported
. . exporting table                    COUNTRYCODE         22 rows exported
. . exporting table             DATAFILESTATUSCODE          0 rows exported
. . exporting table               DETAILSTATUSCODE        247 rows exported
. . exporting table                     DNSSRVINFO          0 rows exported
. . exporting table                  DRMACCESSCODE          0 rows exported
. . exporting table                     ECTOSIINFO          0 rows exported
. . exporting table                    ENUMSRVINFO          1 rows exported
. . exporting table                  EXP_CACHESTAT          0 rows exported
. . exporting table                    HISTORYFLOW          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100428         37 rows exported
. . exporting table      INTERFACEACCOUNT_20100429        374 rows exported
. . exporting table      INTERFACEACCOUNT_20100430        135 rows exported
. . exporting table      INTERFACEACCOUNT_20100501          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100502          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100503          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100504          0 rows exported
. . exporting table      INTERFACEACCOUNT_20100505        103 rows exported
. . exporting table      INTERFACEACCOUNT_20100506          6 rows exported
. . exporting table      INTERFACEACCOUNT_20100507          0 rows exported
. . exporting table      INTERFACEACCOUNT_20101027        320 rows exported
. . exporting table                    INTERPREFIX         22 rows exported
. . exporting table               IPRANGEPARTITION         93 rows exported
. . exporting table                        MESSAGE          0 rows exported
. . exporting table               MESSAGEREFERENCE          0 rows exported
. . exporting table            MESSAGESENDSCHEDULE         15 rows exported
. . exporting table                     MIBLEAFINT         79 rows exported
. . exporting table                     MIBLEAFSTR          9 rows exported
. . exporting table                       MISCINFO          2 rows exported
. . exporting table                MISCROUTERTABLE          7 rows exported
. . exporting table                      MMBOXTYPE          5 rows exported
. . exporting table           MMINTERFACELEVELINFO          2 rows exported
. . exporting table                       MMSCINFO          2 rows exported
. . exporting table                     MMSCIPINFO          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP00          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP01          1 rows exported
. . exporting table             MMSGMMSCMSGIDMAP02          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP03          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP04          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP05          1 rows exported
. . exporting table             MMSGMMSCMSGIDMAP06          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP07          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP08          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP09          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP10          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP11          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP12          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP13          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP14          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP15          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP16          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP17          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP18          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP19          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP20          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP21          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP22          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP23          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP24          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP25          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP26          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP27          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP28          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP29          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP30          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP31          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP32          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP33          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP34          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP35          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP36          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP37          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP38          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP39          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP40          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP41          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP42          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP43          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP44          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP45          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP46          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP47          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP48          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP49          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP50          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP51          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP52          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP53          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP54          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP55          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP56          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP57          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP58          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP59          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP60          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP61          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP62          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP63          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP64          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP65          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP66          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP67          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP68          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP69          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP70          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP71          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP72          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP73          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP74          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP75          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP76          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP77          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP78          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP79          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP80          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP81          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP82          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP83          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP84          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP85          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP86          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP87          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP88          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP89          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP90          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP91          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP92          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP93          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP94          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP95          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP96          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP97          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP98          0 rows exported
. . exporting table             MMSGMMSCMSGIDMAP99          0 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_0         48 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_1        115 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_2         80 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_3         74 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_4         83 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_5        104 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_6        131 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_7        123 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_8        141 rows exported
. . exporting table          MMSGSVCLOG_0429_1_O_9         63 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_0       1209 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_1       1208 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_2       1253 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_3       1272 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_4       1309 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_5       1377 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_6       1358 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_7       1386 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_8       1343 rows exported
. . exporting table          MMSGSVCLOG_0430_1_O_9       1381 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_0         23 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_1         50 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_2         26 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_3         45 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_4         23 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_5         35 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_6         17 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_7         23 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_8         36 rows exported
. . exporting table          MMSGSVCLOG_0505_1_O_9         18 rows exported
. . exporting table          MMSGSVCLOG_0506_1_O_3          5 rows exported
. . exporting table        MMSGSVCLOG_20100429_1_S         95 rows exported
. . exporting table        MMSGSVCLOG_20100430_1_S       2306 rows exported
. . exporting table        MMSGSVCLOG_20100505_1_S         35 rows exported
. . exporting table        MMSGSVCLOG_20100506_1_S          1 rows exported
. . exporting table        MMSGSVCLOG_20101027_1_S        159 rows exported
. . exporting table                      MMSTARIFF          1 rows exported
. . exporting table                      MODULECMD         18 rows exported
. . exporting table                        MODULES         17 rows exported
. . exporting table                 MONITOREDUSERS          0 rows exported
. . exporting table                MONITORPERFSTAT          1 rows exported
. . exporting table               MONTHORDERINFO_0          0 rows exported
. . exporting table               MONTHORDERINFO_1          2 rows exported
. . exporting table               MONTHORDERINFO_2          1 rows exported
. . exporting table               MONTHORDERINFO_3          0 rows exported
. . exporting table               MONTHORDERINFO_4          0 rows exported
. . exporting table               MONTHORDERINFO_5          0 rows exported
. . exporting table               MONTHORDERINFO_6          0 rows exported
. . exporting table               MONTHORDERINFO_7          0 rows exported
. . exporting table               MONTHORDERINFO_8          0 rows exported
. . exporting table               MONTHORDERINFO_9          0 rows exported
. . exporting table                   NATIVEPREFIX          1 rows exported
. . exporting table                    NETWORKCODE         24 rows exported
. . exporting table              PORTALLOG20100428         86 rows exported
. . exporting table              PORTALLOG20100429        121 rows exported
. . exporting table              PORTALLOG20100430         49 rows exported
. . exporting table              PORTALLOG20100505        114 rows exported
. . exporting table              PORTALLOG20100506        184 rows exported
. . exporting table                PPSNUMBERPREFIX          0 rows exported
. . exporting table                PROHIBITEDRIGHT          0 rows exported
. . exporting table                   REALTIMEFLOW          0 rows exported
. . exporting table                  RENTALFEEINFO          1 rows exported
. . exporting table                      RIGHTINFO        250 rows exported
. . exporting table                           ROLE          4 rows exported
. . exporting table                   ROLEMAPRIGHT        519 rows exported
. . exporting table                    ROUTERTABLE          3 rows exported
. . exporting table                 RPT_BUSYSERVER        214 rows exported
. . exporting table                  RPT_DELAYTIME        105 rows exported
. . exporting table         RPT_DELAYTIME_20100506          1 rows exported
. . exporting table         RPT_DELAYTIME_20100507          0 rows exported
. . exporting table                  RPT_INTERFACE         85 rows exported
. . exporting table         RPT_INTERFACE_20100507          0 rows exported
. . exporting table               RPT_MM7_VASPSUCC         40 rows exported
. . exporting table                   RPT_MMSCSUCC         30 rows exported
. . exporting table              RPT_MMSC_20100428          0 rows exported
. . exporting table              RPT_MMSC_20100429          0 rows exported
. . exporting table              RPT_MMSC_20100430          0 rows exported
. . exporting table              RPT_MMSC_20100501          0 rows exported
. . exporting table              RPT_MMSC_20100502          0 rows exported
. . exporting table              RPT_MMSC_20100503          0 rows exported
. . exporting table              RPT_MMSC_20100504          0 rows exported
. . exporting table              RPT_MMSC_20100505          0 rows exported
. . exporting table              RPT_MMSC_20100506          0 rows exported
. . exporting table              RPT_MMSC_20100507          0 rows exported
. . exporting table              RPT_MMSC_20101027          0 rows exported
. . exporting table              RPT_TERMINALCOUNT          0 rows exported
. . exporting table                   RPT_USECOUNT          0 rows exported
. . exporting table              RPT_USEOFSPSERVER          0 rows exported
. . exporting table              RPT_VASP_20100428          0 rows exported
. . exporting table              RPT_VASP_20100429          0 rows exported
. . exporting table              RPT_VASP_20100430          0 rows exported
. . exporting table              RPT_VASP_20100501          0 rows exported
. . exporting table              RPT_VASP_20100502          0 rows exported
. . exporting table              RPT_VASP_20100503          0 rows exported
. . exporting table              RPT_VASP_20100504          0 rows exported
. . exporting table              RPT_VASP_20100505          0 rows exported
. . exporting table              RPT_VASP_20100506          0 rows exported
. . exporting table              RPT_VASP_20100507          0 rows exported
. . exporting table              RPT_VASP_20101027          0 rows exported
. . exporting table        SERVICEACCOUNT_20100428         24 rows exported
. . exporting table        SERVICEACCOUNT_20100429        227 rows exported
. . exporting table        SERVICEACCOUNT_20100430         96 rows exported
. . exporting table        SERVICEACCOUNT_20100501          0 rows exported
. . exporting table        SERVICEACCOUNT_20100502          0 rows exported
. . exporting table        SERVICEACCOUNT_20100503          0 rows exported
. . exporting table        SERVICEACCOUNT_20100504          0 rows exported
. . exporting table        SERVICEACCOUNT_20100505         80 rows exported
. . exporting table        SERVICEACCOUNT_20100506          5 rows exported
. . exporting table        SERVICEACCOUNT_20100507          0 rows exported
. . exporting table        SERVICEACCOUNT_20101027        237 rows exported
. . exporting table                         SIINFO          0 rows exported
. . exporting table                    SMSNOTEINFO          4 rows exported
. . exporting table              SMSPROTOCOLCONFIG          0 rows exported
. . exporting table                SPECIALCUSTINFO          0 rows exported
. . exporting table                  SUBMITRESINFO        128 rows exported
. . exporting table                    SYSOPERATOR         14 rows exported
. . exporting table                SYSTEMPARAMETER        340 rows exported
. . exporting table                SZXNUMBERPREFIX          0 rows exported
. . exporting table              TERMINALBLACKLIST          2 rows exported
. . exporting table              TMP_ATTACH_RESULT        161 rows exported
. . exporting table                TMP_BASE_RESULT         28 rows exported
. . exporting table                     TMP_RESULT          0 rows exported
. . exporting table                   TMP_RESULTID          0 rows exported
. . exporting table                  TMP_RESULTMEM          0 rows exported
. . exporting table                   TRACEMSGINFO          0 rows exported
. . exporting table                      UAPROFILE          2 rows exported
. . exporting table                       VASPINFO         12 rows exported
. . exporting table                  VASPLEVELINFO          2 rows exported
. . exporting table               VASPPRIORITYINFO          5 rows exported
. . exporting table                VASPRIORITYINFO          5 rows exported
. . exporting table                VASPSERVICE_SUP         15 rows exported
. . exporting table              VASSERVEDAREALIST          1 rows exported
. . exporting table               VASSUBSCRIBEINFO          0 rows exported
. . exporting table              VCARRIERNBRPREFIX          5 rows exported
. . exporting table             VIRTUALCARRIERINFO          1 rows exported
. . exporting table            VIRTUALCARRIERLEVEL          1 rows exported
. . exporting table                    VPNCORP_100          3 rows exported
. . exporting table                    VPNCORP_300          3 rows exported
. . exporting table                  VPNSUBSCRIBER          6 rows exported
. . exporting table                 VPNUNITECORPID          1 rows exported
. exporting synonyms
. exporting views
. exporting referential integrity constraints
. exporting stored procedures
. exporting operators
. exporting indextypes
. exporting bitmap, functional and extensible indexes
. exporting posttables actions
. exporting triggers
. exporting materialized views
. exporting snapshot logs
. exporting job queues
. exporting refresh groups and children
. exporting dimensions
. exporting post-schema procedural objects and actions
. exporting user history table
. exporting default and system auditing options
. exporting statistics
Export terminated successfully without warnings.
</code></pre>
<h1 id="yan-zheng-guo-cheng">验证过程</h1>
<h2 id="shu-ju-wan-zheng-xing-yan-zheng">数据完整性验证</h2>
<p>应用数据导入到数据库B后，数据完整性验证。</p>
<p>主要操作是查询导入后的数据信息，例如通过PLSQL Developer工具查询相同的表，前后进行数据对比操作。</p>
<h2 id="tns-pei-zhi">TNS配置</h2>
<p>使用oracle用户，在MMSG单板侧增加tns信息，即修改 $ORACLE_HOME/network/admin/tnsnames.ora文件</p>
<p>例如：</p>
<pre><code class="language-shell">vi $ORACLE_HOME/network/admin/tnsnames.ora

MMSGDB62 =
  (DESCRIPTION =
    (ADDRESS_LIST =
      (ADDRESS = (PROTOCOL = TCP)(HOST = 10.71.167.62)(PORT = 1523))
    )
    (CONNECT_DATA =
      (SERVICE_NAME = iagw)
    )
  )
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>蓝色部分为增加的TNS信息，请根据实际情况进行增加。</p>
</li>
</ul>
<h2 id="mmsg-yu-qie-huan-hou-de-shu-ju-ku-lian-jie-yan-zheng">MMSG与切换后的数据库连接验证</h2>
<p>使用MMSG用户登录单板，验证网关与切换后的数据库的连接是否正常</p>
<h3 id="cao-zuo-ru-xia">操作如下</h3>
<p>1、使用tnsping或者sqlplus命令验证</p>
<p><code>tnsping  dbname N </code></p>
<p>其中:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>dbname为TNS中增加的数据库的别名</p>
</li>
<li class="lvl-2">
<p>N 表示一个正整数</p>
</li>
</ul>
<p>2、使用sqlplus命令验证</p>
<pre><code class="language-shell">sqlplus  username/passwd@dbname
</code></pre>
<p>其中:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>username表示切换数据库后应用用户名</p>
</li>
<li class="lvl-2">
<p>passwd   表示切换数据库后应用用户的密码</p>
</li>
<li class="lvl-2">
<p>dbname  表示 TNS中增加的数据库名（示例中为MMSGDB62）</p>
</li>
</ul>
<h3 id="yan-zheng-ru-xia">验证如下</h3>
<pre><code class="language-shell">69 mmsg [mmsg] :/home/mmsg&gt;tnsping mmsgdb62 10

TNS Ping Utility for Linux: Version 11.1.0.7.0 - Production on 07-MAY-2010 14:33:10

Copyright (c) 1997, 2008, Oracle.  All rights reserved.

Used parameter files:


Used TNSNAMES adapter to resolve the alias
Attempting to contact (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 10.71.167.62)(PORT = 1523))) (CONNECT_DATA = (SERVICE_NAME = iagw)))
OK (50 msec)
OK (50 msec)
OK (50 msec)
OK (50 msec)
OK (50 msec)
OK (60 msec)
OK (50 msec)
OK (50 msec)
OK (50 msec)
OK (50 msec)
70 mmsg [mmsg] :/home/mmsg&gt;sqlplus wyz/wyz@mmsgdb62

SQL*Plus: Release 11.1.0.7.0 - Production on Fri May 7 14:33:43 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options

SQL&gt; select * from modules;

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      1001 OMCAgent
         1 10.137.49.114             52238
OMCAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      2001 ChargeServer
         2 10.137.49.114             52234
ChargeServer

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
         1 MMSServer
         3 10.137.49.114             52233
MMSServer

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
        80 Dispatcher
        88 10.137.49.114             52299
Dispatcher

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      1901 VASPServer
        71 10.137.49.114             52280
VASPServer

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      1811 MMSCServer
        70 10.137.49.114             52288
MMSCServer

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      1101 ENUMDNSAgent
        11 10.137.49.114             52237
EnumDNSAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      5301 VASPClient
        73 10.137.49.114             52298
VASPClient

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      5401 MMSCClient
        74 10.137.49.114             52278
MMSCClient

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      1201 DSMPAgent
        12 10.137.49.114             52281
DSMPAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      2200 LOG2DB
        22 10.137.49.114             52232
LOG2DB

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      4001 SMSAgent
         4 10.137.49.114             52235
SMSAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      8201 BILLAgent
        82 10.137.49.114             52266
BILLAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      8202 VPNBILLAgent
        82 10.137.49.114             52277
VPNBILLAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      8203 DRBILLAgent
        82 10.137.49.114             53398
DRBILLAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
      8901 VPNAgent
        89 10.137.49.114             52222
VPNAgent

  MODULEID MODULENAME
---------- ----------------------------------------------------------------
MODULETYPE MODULEIPADDR         LISTENPORT
---------- -------------------- ----------
MODULEDESC
--------------------------------------------------------------------------------
HOSTNAME                                                                PID
---------------------------------------------------------------- ----------
      PING
----------
                                                                          0
         0


16 rows selected.
</code></pre>
<h3 id="xiu-gai-mmsg-ce-pei-zhi-wen-jian">修改MMSG侧配置文件</h3>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>在修改MMSG侧配置文件前，请先停止正在运行的网关。</p>
</li>
</ul>
<h2 id="xiu-gai-mms-home-cfg-mu-lu-xia-xia-lie-wen-jian-xin-xi">修改$MMS_HOME/cfg目录下下列文件信息</h2>
<pre><code class="language-shell">cshrc
mms.cfg
log2db.cfg
vpn.cfg
</code></pre>
<pre><code class="language-shell">vi cshrc
#The SID for accessing the Oracle database must be consistent with the contents in the tnsname.ora configuration file of the Oracle client
setenv ORACLE_SID mmsgdb62   //请根据实际情况进行修改，示例中TNS为mmsgdb62
</code></pre>
<pre><code class="language-shell">vi mms.cfg
//Note: This configuration file is used for setting the database access mode of the MMSC. 
//Other settings are stored in the database. You can set the configuration items on the Web management page.
[Database]
DBName = mmsgdb62
DBUserName =wyz 
DBPassword = wyz
DBType = oracle
DBUrl = jdbc:oracle:thin:@10.71.167.62:1523:iagw
DBJdbcClass=oracle.jdbc.driver.OracleDriver
MMS_LOCAL_FLOATIP = 10.137.49.114
</code></pre>
<pre><code class="language-shell">vi log2db.cfg 
//Log2db configuration file

[Database]
//Database user name
DBUser = wyz

//Database password
DBPassword = wyz

//URL used by the database JDBC
DBUrl = jdbc:oracle:thin:@10.71.167.62:1523:iagw
//DBUrl = jdbc:db2://10.164.78.178:50003/mmsgdb
//DBUrl = jdbc:microsoft:sqlserver://127.0.0.1:1433

//Drive used by the database JDBC
DBDriver = oracle.jdbc.driver.OracleDriver
//DBDriver = com.ibm.db2.jcc.DB2Driver
//DBDriver = com.microsoft.jdbc.sqlserver.SQLServerDriver
</code></pre>
<pre><code class="language-shell">vi vpn.cfg
[DataBase]
#Database connection information. This parameter is valid only when VpnDbMode is set to 0 indicating to connect to the WEBSMS.
#Oracle database
DBUrl=jdbc:oracle:thin:@10.71.167.62:1523:iagw 
DBDriver=oracle.jdbc.driver.OracleDriver
#DB2 database
#DBUrl=jdbc:db2://10.164.75.87:50001/iagdb1
#DBDriver=com.ibm.db2.jcc.DB2Driver
DBUser=wyz
DBPassword=wyz
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、蓝色部分信息请根据实际情况进行修改。</p>
</li>
<li class="lvl-2">
<p>2、修改后重新source一下cfg目录下cshrc文件</p>
</li>
<li class="lvl-2">
<p>3、它配置信息，如后台命令执行的备份脚本等不需要做任何改动，当mms.cfg文件发生修改后，在某时刻后台执行定时任务时候会重新读取这个配置文件，故而相关的定时任务不做任何变动。</p>
</li>
<li class="lvl-2">
<p>4、如果在原数据库上进行了数据库的备份策略，请将备份策略在切换后的AIX 11g数据库上重新进行。</p>
</li>
</ul>
<h3 id="yu-jian-wen-ti-get-db-connection-is-null">遇见问题 Get DB Connection is null</h3>
<p>如果出现如下错误（Get DB Connection is null），请检查cfg目录下相关配置文件（主要是cfg目录下cshrc、mms.cfg、log2db.cfg三个文件）是否正确修改。</p>
<pre><code class="language-shell">91 mmsg [mmsg] :/home/mmsg/mms_home/cfg&gt;Get DB Connection is null
Exception in thread "main" java.lang.NullPointerException
        at com.huawei.mms.common.conf.ModulesData.getModuleNameByID(ModulesData.java:83)
        at com.huawei.mms.common.log.Alarmer.&lt;init&gt;(Alarmer.java:61)
        at com.huawei.mms.common.log.Alarmer.getInstance(Alarmer.java:74)
        at com.huawei.mms.common.dbproxy.DBProxyJDBCImp.query(DBProxyJDBCImp.java:351)
        at com.huawei.mms.common.dbproxy.DBProxyJDBCImp.query(DBProxyJDBCImp.java:271)
        at com.huawei.mms.common.conf.CfgMgr.reload(CfgMgr.java:107)
        at com.huawei.mms.init.HttpAgentData.init(HttpAgentData.java:131)
        at com.huawei.mms.init.MMSCClientInitiator.initCfgData(MMSCClientInitiator.java:155)
        at com.huawei.mms.init.Initiator.initSystem(Initiator.java:97)
        at com.huawei.mms.mm7agent.MMSCClient.main(MMSCClient.java:49)
</code></pre>
<h2 id="qi-dong-wang-guan">启动网关</h2>
<p>使用mms start命令启动数据库切换后的网关。</p>
<p>如果在启动过程中出现如下信息，请修改端口号，以server主调度模块为例</p>
<pre><code class="language-shell">[05-07 15:22:37 511][INFO][ServerApp][serverapp.cpp 263][-140986064]*****************  Initialize Static Data Successfully!!  ******
**************

[05-07 15:22:37 511][FINE][Platform][mms_acceptor.cpp 85][-140986064]Tcp Server start fail!ip address is:10.137.49.114, port no is:5
2233
[05-07 15:22:37 511][WARNING][ServerApp][serverapp.cpp 492][-140986064]Open Socket Server Failed, Exit System...!ServerIP = 10.137.4
9.114, ListenPort = 52233

[05-07 15:22:37 511][FINE][Platform][appmanager.cpp 173][-140986064]OnInit() return -1
</code></pre>
<h3 id="server-mo-kuai-qi-dong-shi-bai">server模块启动失败</h3>
<pre><code class="language-shell">144 mmsg [mmsg] :/home/mmsg/mms_home/log/server_1/run&gt;netstat -an | grep 52233
tcp        0      0 10.137.49.114:52277     10.137.49.114:52233     ESTABLISHED 
tcp        0      0 10.137.49.114:52233     10.137.49.114:52277     ESTABLISHED
</code></pre>
<p>解决方法如下</p>
<p>1、server端口信息</p>
<pre><code class="language-shell">update  modules  set listenport =52239 where MODULENAME='MMSServer';
</code></pre>
<p>2、重启server模块</p>
<pre><code class="language-shell">mms start 1
</code></pre>
<h2 id="liu-cheng-yan-zheng">流程验证</h2>
<p>网关各个模块启动后，验证流程是否通畅。</p>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>需要修改portal配置信息，因为数据库已经发生切换。本文不做介绍。</p>
</li>
</ul>
<h3 id="xia-xing-liu-cheng-bu-zhi-chi-dr-you-hua">下行流程，不支持DR优化</h3>
<h4 id="ji-fei-hua-dan">计费话单</h4>
<pre><code class="language-shell">0507155553800800011020000,008613810243001,,0,822000,008613810243001,,2,1,3,0,0,0,0,1,2,0,1000,800800,910000,822000,7800,121000,,2010
0507155553,20100507155558,,00000,1,1,1,0,0,0,050708001402708220010,
</code></pre>
<h4 id="tong-ji-hua-dan">统计话单</h4>
<pre><code class="language-shell">0507155553800800011020000,008613810243001,,0,822000,008613810243001,,2,1,3,0,0,0,0,1,2,0,0100,800800,910000,822000,7800,121000,,2010
0507155553,20100507155553,,00000,1,1,1,0,0,0,,,1,
0507155553800800011020000,008613810243001,,0,822000,008613810243001,,3,1,3,0,0,0,0,1,2,0,1000,800800,910000,822000,7800,121000,,2010
0507155553,20100507155558,,00000,1,1,1,0,0,0,,1,1,
</code></pre>
<h4 id="vaspserver-ri-zhi-pian-duan">Vaspserver日志片段</h4>
<pre><code class="language-shell">Begin to dispose message from SP!
[2010-05-07 15:55:53.335] [FINEST] [vaspserver_1901] [Tools.java:615] [ ] [Receive SOAP Message] 
HttpRequest Content:
15:55:53.334(Tools.java:362) byte[719] @3682584 {
    [HEX]    0  1  2  3  4  5  6  7-  8  9  a  b  c  d  e  f | 0123456789abcdef
  ----------------------------------------------------------------------------
  00000000: 3c 3f 78 6d 6c 20 76 65.72 73 69 6f 6e 3d 22 31 | &lt;?xml version="1
  00000010: 2e 30 22 20 65 6e 63 6f.64 69 6e 67 3d 22 55 54 | .0" encoding="UT
  00000020: 46 2d 38 22 3f 3e 3c 65.6e 76 3a 45 6e 76 65 6c | F-8"?&gt;&lt;env:Envel
  00000030: 6f 70 65 20 78 6d 6c 6e.73 3a 65 6e 76 3d 22 68 | ope xmlns:env="h
  00000040: 74 74 70 3a 2f 2f 73 63.68 65 6d 61 73 2e 78 6d |
 ttp://schemas.xm
  00000050: 6c 73 6f 61 70 2e 6f 72.67 2f 73 6f 61 70 2f 65 | lsoap.org/soap/e
  00000060: 6e 76 65 6c 6f 70 65 2f.22 3e 3c 65 6e 76 3a 48 | nvelope/"&gt;&lt;env:H
  00000070: 65 61 64 65 72 3e 3c 6d.6d 37 3a 54 72 61 6e 73 | eader&gt;&lt;mm7:Trans
  00000080: 61 63 74 69 6f 6e 49 44.20 78 6d 6c 6e 73 3a 6d | actionID xmlns:m
  00000090: 6d 37 3d 22 68 74 74 70.3a 2f 2f 77 77 77 2e 33 | m7="http://www.3
  000000a0: 67 70 70 2e 6f 72 67 2f.66 74 70 2f 53 70 65 63 | gpp.org/ftp/Spec
  000000b0: 73 2f 61 72 63 68 69 76.65 2f 32 33 5f 73 65 72 | s/archive/23_ser
  000000c0: 69 65 73 2f 32 33 2e 31.34 30 2f 73 63 68 65 6d | ies/23.140/schem
  000000d0: 61 2f 52 45 4c 2d 36 2d.4d 4d 37 2d 31 2d 30 22 | a/REL-6-MM7-1-0"
  000000e0: 20 65 6e 76 3a 6d 75 73.74 55 6e 64 65 72 73 74 |  env:mustUnderst
  000000f0: 61 6e 64 3d 22 31 22 3e.74 69 64 31 30 30 30 30 | and="1"&gt;tid10000
  00000100: 30 30 30 30 3c 2f 6d 6d.37 3a 54 72 61 6e 73 61 | 0000&lt;/mm7:Transa
  00000110: 63 74 69 6f 6e 49 44 3e.3c 2f 65 6e 76 3a 48 65 | ctionID&gt;&lt;/env:He
  00000120: 61 64 65 72 3e 3c 65 6e.76 3a 42 6f 64 79 3e 3c | ader&gt;&lt;env:Body&gt;&lt;
  00000130: 53 75 62 6d 69 74 52 65.71 20 78 6d 6c 6e 73 3d | SubmitReq xmlns=
  00000140: 22 68 74 74 70 3a 2f 2f.77 77 77 2e 33 67 70 70 | "http://www.3gpp
  00000150: 2e 6f 72 67 2f 66 74 70.2f 53 70 65 63 73 2f 61 | .org/ftp/Specs/a
  00000160: 72 63 68 69 76 65 2f 32.33 5f 73 65 72 69 65 73 | rchive/23_series
  00000170: 2f 32 33 2e 31 34 30 2f.73 63 68 65 6d 61 2f 52 | /23.140/schema/R
  00000180: 45 4c 2d 36 2d 4d 4d 37.2d 31 2d 30 22 3e 3c 4d | EL-6-MM7-1-0"&gt;&lt;M
  00000190: 4d 37 56 65 72 73 69 6f.6e 3e 36 2e 33 2e 30 3c | M7Version&gt;6.3.0&lt;
  000001a0: 2f 4d 4d 37 56 65 72 73.69 6f 6e 3e 3c 53 65 6e | /MM7Version&gt;&lt;Sen
  000001b0: 64 65 72 49 64 65 6e 74.69 66 69 63 61 74 69 6f | derIdentificatio
  000001c0: 6e 3e 3c 56 41 53 50 49.44 3e 38 32 32 30 30 30 | n&gt;&lt;VASPID&gt;822000
  000001d0: 3c 2f 56 41 53 50 49 44.3e 3c 56 41 53 49 44 3e | &lt;/VASPID&gt;&lt;VASID&gt;
  000001e0: 37 38 30 30 3c 2f 56 41.53 49 44 3e 3c 2f 53 65 | 7800&lt;/VASID&gt;&lt;/Se
  000001f0: 6e 64 65 72 49 64 65 6e.74 69 66 69 63 61 74 69 | nderIdentificati
}

[2010-05-07 15:55:53.337] [FINER] [vaspserver_1901] [HttpAgentForSoap.java:167] [ ] [SP to Server] 
Decoder soap message to mm7 message success, detail is:
MessageType = MM7-Submit.req
TransactionID = tid100000000
MM7Version = 6.3.0
To = [13810243001]
DeliveryReport = YES
Subject = This is a test.
VASPID = 822000
VASID = 7800
ServiceCode = 121000
Content: Content-Type=application/vnd.wap.multipart.mixed

[2010-05-07 15:55:53.337] [FINER] [vaspserver_1901] [VASPServerCheckTools.java:224] [ ] [VASPServer] 
MM7 Message will be sended to server!
[2010-05-07 15:55:53.338] [FINEST] [vaspserver_1901] [SocketConnection.java:612] [ ] [Send Message] 
 Send message to module[1]
15:55:53.338(Tools.java:374) byte[105000] @25068634 {
    [HEX]    0  1  2  3  4  5  6  7-  8  9  a  b  c  d  e  f | 0123456789abcdef
  ----------------------------------------------------------------------------
  00000000: 49 d9 00 00 00 76 17 40.00 00 4b e3 c7 89 01 51 | I....v.@..K....Q
  00000010: 00 47 07 6d 00 00 00 00.00 03 00 01 10 01 00 00 | .G.m............
  00000020: 00 00 00 02 8c c0 98 74.69 64 31 30 30 30 30 30 | .......tid100000
  00000030: 30 30 30 00 d5 02 06 36.86 80 96 54 68 69 73 20 | 000....6...This 
  00000040: 69 73 20 61 20 74 65 73.74 2e 00 97 31 33 38 31 | is a test...1381
  00000050: 30 32 34 33 30 30 31 00.d7 31 32 31 30 30 30 00 | 0243001..121000.
  00000060: d9 37 38 30 30 00 d8 38.32 32 30 30 30 00 ed 37 | .7800..822000..7
  00000070: 38 30 30 00 b4 01      .                        | 800...          
}

[2010-05-07 15:55:53.341] [FINEST] [vaspserver_1901] [SocketConnection.java:539] [ ] [Receive Message] 
Receive message from module[1], binary stream:
15:55:53.340(Tools.java:374) byte[200] @18818021 {
    [HEX]    0  1  2  3  4  5  6  7-  8  9  a  b  c  d  e  f | 0123456789abcdef
  ----------------------------------------------------------------------------
  00000000: 00 00 00 64 17 41 00 00.4b e3 c7 89 01 51 00 03 | ...d.A..K....Q..
  00000010: 00 01 10 01 00 01 00 47.07 6d 00 00 00 00 00 00 | .......G.m......
  00000020: 00 02 8c c1 98 74 69 64.31 30 30 30 30 30 30 30 | .....tid10000000
  00000030: 30 00 d5 02 06 30 8b 30.35 30 37 31 35 35 35 35 | 0....0.050715555
  00000040: 33 38 30 30 38 30 30 30.31 31 30 32 00 bc 02 03 | 380080001102....
  00000050: e8 be 0f ea 7f e5 8f 91.e9 80 81 e6 88 90 e5 8a | ................
  00000060: 9f 00                  .                        | ..              
}

[2010-05-07 15:55:53.341] [FINER] [vaspserver_1901] [TransactionMgr.java:157] [ ] [Message Process Interval] 
MessageType: MM7-Submit.req; SourceModuleID: 1901; TargetModuleID: 1; Interval: 4
[2010-05-07 15:55:53.341] [FINER] [vaspserver_1901] [MM7MessageSenderMgr.java:357] [ ] [SP to Server] 
Get response from MMSGserver, detail: 
MessageType = MM7-Submit.res
TransactionID = tid100000000
MM7Version = 6.3.0
MessageID = 050715555380080001102
StatusCode = 1000
StatusText = 发送成功

[2010-05-07 15:55:53.342] [FINER] [vaspserver_1901] [HttpAgentForSoap.java:456] [ ] [SP to Server] 
Get response from server or dispatcher, detail:
MessageType = MM7-Submit.res
TransactionID = tid100000000
MM7Version = 6.3.0
MessageID = 050715555380080001102
StatusCode = 1000
StatusText = 发送成功
</code></pre>
<h4 id="svc-ri-zhi-pian-duan">SVC日志片段</h4>
<pre><code class="language-shell">[2010-05-07 15:55:53 339][LgTp:FRSMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:2][SessID:0110000000001100507155553][MsgID:050715555380080001102][TransID:tid100000000][ExMsgID:][MPRP:MM7][MsgType:MM7_SUBMIT_REQ][AfrAtrbt:RCV][AfrStat:OK]; SV:NULL; MsgCls:NULL; DR:YES; RR:NULL; MsgSz:0 Byte(s); VASPID:822000; VASID:7800; SrvCd:121000; DispMsgID:;
[2010-05-07 15:55:53 340][LgTp:SRVMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:2][SessID:0110000000001100507155553][MsgID:050715555380080001102][TransID:tid100000000][ExMsgID:][MPRP:MM7][MsgType:MM7_SUBMIT_RES][AfrAtrbt:SND][AfrStat:OK]; MM7RspStat:SUCCESS; DispMsgID:;
[2010-05-07 15:55:53 345][LgTp:OFLWVR][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SessID:0110000000001100507155553][MsgID:050715555380080001102][ExMsgID:][FlwCls:NORMAL]; FlwOvrStat:SUBMIT_OK; FlwOvrStatCode:0100; DtlCd:STAT_SUBMIT_SUCCESS; DlvrTimer:0 Second(s);
[2010-05-07 15:55:53 346][LgTp:ENTRLS][SessID:0110000000001100507155553][MsgID:050715555380080001102][ExMsgID:][EntAct:SUBMIT_SESSION_RELEASE]; RealFlwCls:NORMAL;
[2010-05-07 15:55:53 346][LgTp:SRVMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:-1][SessID:0110000000002100507155553][MsgID:050715555380080001102][TransID:0110000000002100507155553001][ExMsgID:][MPRP:MM7][MsgType:MM7_SUBMIT_REQ][AfrAtrbt:SND][AfrStat:OK]; SV:NULL; MsgCls:PRSL; DR:YES; RR:NO; MsgSz:0 Byte(s); VASPID:800100; VASID:7788; SrvCd:822001;
[2010-05-07 15:55:53 470][LgTp:SRVMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:0][SessID:0110000000002100507155553][MsgID:050715555380080001102][TransID:0110000000002100507155553001][ExMsgID:050708001402708220010][MPRP:MM7][MsgType:MM7_SUBMIT_RES][AfrAtrbt:RCV][AfrStat:OK]; MM7RspStat:SUCCESS;ResOriginStat:1000;
[2010-05-07 15:55:58 638][LgTp:SRVMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:2][SessID:0110000000002100507155553][MsgID:050715555380080001102][TransID:tid00001003][ExMsgID:050708001402708220010][MPRP:MM7][MsgType:MM7_DELIVERY_REPORT_REQ][AfrAtrbt:RCV][AfrStat:OK]; FtchStat:RETRIEVED;
[2010-05-07 15:55:58 638][LgTp:SRVMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:2][SessID:0110000000002100507155553][MsgID:050715555380080001102][TransID:tid00001003][ExMsgID:050708001402708220010][MPRP:MM7][MsgType:MM7_DELIVERY_REPORT_RES][AfrAtrbt:SND][AfrStat:OK]; MM7RspStat:SUCCESS;
[2010-05-07 15:55:58 638][LgTp:TFLWVR][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SessID:0110000000002100507155553][MsgID:050715555380080001102][ExMsgID:050708001402708220010][FlwCls:NORMAL]; FlwOvrStat:DELIVER_OK; FlwOvrStatCode:1000; DtlCd:STAT_FRWRD_SNDR_ADDR_IN_FRWRD_RCVR_USER_BLKLST; RealFlwCls:NORMAL;
[2010-05-07 15:55:58 638][LgTp:SRVMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:-1][SessID:0110000000002100507155553][MsgID:050715555380080001102][TransID:0110000000002100507155553303][ExMsgID:050708001402708220010][MPRP:MM7][MsgType:MM7_DELIVERY_REPORT_REQ][AfrAtrbt:SND][AfrStat:SNDING]; FtchStat:RETRIEVED; DispMsgID:;
[2010-05-07 15:55:58 657][LgTp:SRVMSG][AfOrgn:][Sndr:7800121000][Rcvr:+8613810243001][FwdAddr:][SqncNum:0][SessID:0110000000002100507155553][MsgID:050715555380080001102][TransID:0110000000002100507155553303][ExMsgID:050708001402708220010][MPRP:MM7][MsgType:MM7_DELIVERY_REPORT_RES][AfrAtrbt:RCV][AfrStat:OK]; MM7RspStat:SUCCESS;
[2010-05-07 15:55:58 657][LgTp:ENTRLS][SessID:0110000000002100507155553][MsgID:050715555380080001102][ExMsgID:050708001402708220010][EntAct:DELIVER_SESSION_RELEASE]; RealFlwCls:NORMAL;
[2010-05-07 15:55:58 657][LgTp:ENTRLS][MsgID:050715555380080001102][ExMsgID:][EntAct:ORIGINMSG_RELEASE];
</code></pre>
<h4 id="cs-ri-zhi-pian-duan">CS日志片段</h4>
<pre><code class="language-shell">m_ucAreaFlag  = 0 
m_ucRoamingStatus  = 255 
m_strIMSI =  
m_strVisitedSGSN =  
m_addrXMmsSenderAddress end: 

m_strXMmsSenderActaulProperties =  
m_strXMmsResulText = 处理成功 
m_listRecipientAddress Start: 
 m_strXMmsTransactionIDofPPS  = 011000000999910050715555300011 

m_addrXMmsRecipientAddress Start:
m_strAddress  = +8613810243001 
m_iAddressType = 0 
m_iAddressSendType = 0
</code></pre>
<h4 id="mmscclient-ri-zhi-pian-duan">Mmscclient日志片段</h4>
<pre><code class="language-shell">[2010-05-07 15:55:53.321] [FINER] [mmscclient_5401] [ConnectionManager.java:333] [ ] [Update SocketConnection's Load] 
Update module[1]'s state to 0
[2010-05-07 15:55:53.347] [FINEST] [mmscclient_5401] [SocketConnection.java:539] [ ] [Receive Message] 
Receive message from module[1], binary stream:
15:55:53.346(Tools.java:374) byte[297] @16747636 {
    [HEX]    0  1  2  3  4  5  6  7-  8  9  a  b  c  d  e  f | 0123456789abcdef
  ----------------------------------------------------------------------------
  00000000: 00 00 00 c5 17 40 00 00.ff ff ff ff ff ff 00 03 | .....@..........
  00000010: 00 01 10 01 00 01 00 4a.15 19 00 00 00 00 ff ff | .......J........
  00000020: ff ff 8c c0 98 30 31 31.30 30 30 30 30 30 30 30 | .....01100000000
  00000030: 30 32 31 30 30 35 30 37.31 35 35 35 35 33 30 30 | 0210050715555300
  00000040: 31 00 f1 30 35 30 37 31.35 35 35 35 33 38 30 30 | 1..0507155553800
  00000050: 38 30 30 30 31 31 30 32.00 ea 38 32 32 30 30 30 | 80001102..822000
  00000060: 00 eb 37 38 30 30 00 ec.31 32 31 30 30 30 00 d5 | ..7800..121000..
  00000070: 02 06 30 d8 38 30 30 31.30 30 00 d9 37 37 38 38 | ..0.800100..7788
  00000080: 00 85 04 4b e3 c7 89 97.2b 38 36 31 33 38 31 30 | ...K....+8613810
  00000090: 32 34 33 30 30 31 00 d7.38 32 32 30 30 31 00 96 | 243001..822001..
  000000a0: 54 68 69 73 20 69 73 20.61 20 74 65 73 74 2e 00 | This is a test..
  000000b0: 8a 80 88 06 80 04 4b e3.c7 c5 86 80 90 81 d6 03 | ......K.........
  000000c0: 0d e2 b0               .                        | ...             
}

[2010-05-07 15:55:53.347] [FINER] [mmscclient_5401] [MMSCProcessor.java:56] [ ] [MMSG to MMSC] 
Begin to dispose message from MMSGserver!
[2010-05-07 15:55:53.348] [FINER] [mmscclient_5401] [MMSCProcessor.java:124] [ ] [MMSG to MMSC] 
PDU message detail is:
MessageType = MM7-Submit.req
TransactionID = 0110000000002100507155553001
MM7Version = 6.3.0
To = [+8613810243001]
Date = 2010-05-07 15:55:53 +0800
DeliveryReport = YES
Expiry = 2010-05-07 15:56:53 +0800
MessageClass = Personal
ReadReply = NO
Subject = This is a test.
MMSCID = 910000
VASPID = 800100
VASID = 7788
ServiceCode = 822001
MMSGMessageID = 050715555380080001102
RealVASPID = 822000
RealVASID = 7800
RealServiceCode = 121000

[2010-05-07 15:55:53.348] [FINER] [mmscclient_5401] [MMSCProcessor.java:240] [ ] [MMSG to MMSC] 
MMSC Don't Support DR Optimization
[2010-05-07 15:55:53.348] [FINER] [mmscclient_5401] [MMSCProxyHTTPImp.java:461] [ ] [MMSG to MMSC] 
MMSCURL(soap) is: http://10.137.48.60:1190/mmsc
[2010-05-07 15:55:53.382] [FINEST] [mmscclient_5401] [MMSCProxyHTTPImp.java:778] [ ] [MMSG to MMSC] 
Get response from MMSC, detail:
&lt;?xml version="1.0"?&gt;&lt;env:Envelope xmlns:env="http://schemas.xmlsoap.org/soap/envelope/"&gt;&lt;env:Header&gt;&lt;mm7:TransactionID xmlns:mm7="http://www.3gpp.org/ftp/Specs/archive/23_series/23.140/schema/REL-6-MM7-1-0"&gt;0110000000002100507155553001&lt;/mm7:TransactionID&gt;&lt;/env:Header&gt;&lt;env:Body&gt;&lt;SubmitRsp xmlns="http://www.3gpp.org/ftp/Specs/archive/23_series/23.140/schema/REL-6-MM7-1-0"&gt;&lt;MM7Version&gt;6.3.0&lt;/MM7Version&gt;&lt;Status&gt;&lt;StatusCode&gt;1000&lt;/StatusCode&gt;&lt;/Status&gt;&lt;MessageID&gt;050708001402708220010&lt;/MessageID&gt;&lt;/SubmitRsp&gt;&lt;/env:Body&gt;&lt;/env:Envelope&gt; 

[2010-05-07 15:55:53.382] [FINER] [mmscclient_5401] [MMSCProxyHTTPImp.java:1140] [ ] [MMSCProxyHTTPImp] 
get response from MMSC, detail:
MessageType = MM7-Submit.res
TransactionID = 0110000000002100507155553001
MM7Version = 6.3.0
MessageID = 050708001402708220010
StatusCode = 1000

[2010-05-07 15:55:53.443] [FINEST] [mmscclient_5401] [MMSCProcessor.java:665] [ ] [insert data successful. MMSGMessageID = 050715555380080001102, MMSCMessageID = 050708001402708220010 tableName:MMSGMMSCMsgIDMap04 , current time is: Fri May 07 15:55:53 CST 2010] 
[2010-05-07 15:55:53.469] [FINER] [mmscclient_5401] [MMSCProcessor.java:449] [ ] [MMSCProxyHTTPImp] 
Send response to Server, detail:
MessageType = MM7-Submit.res
TransactionID = 0110000000002100507155553001
MM7Version = 6.3.0
MessageID = 050708001402708220010
StatusCode = 1000
</code></pre>
<h3 id="shang-xing-liu-cheng">上行流程</h3>
<h4 id="svc-ri-zhi-pian-duan-1">SVC日志片段</h4>
<pre><code class="language-shell">[2010-05-07 16:00:16 177][LgTp:FRSMSG][AfOrgn:][Sndr:+8613810243001][Rcvr:7800121000][FwdAddr:][SqncNum:3][SessID:0120000000003100507160016][MsgID:050716001680080001203][TransID:tid00001004][ExMsgID:][MPRP:MM7][MsgType:MM7_DELIVER_REQ][AfrAtrbt:RCV][AfrStat:OK]; SV:NULL; MsgCls:NULL; DR:NULL; RR:NULL; Expiry:-1 Second(s); MsgSz:0 Byte(s); VASPID:; VASID:; SrvCd:; DlvrType:; SessType:Normal;
[2010-05-07 16:00:16 177][LgTp:SRVMSG][AfOrgn:][Sndr:+8613810243001][Rcvr:7800121000][FwdAddr:][SqncNum:3][SessID:0120000000003100507160016][MsgID:050716001680080001203][TransID:tid00001004][ExMsgID:][MPRP:MM7][MsgType:MM7_DELIVER_RES][AfrAtrbt:SND][AfrStat:OK]; MM7RspStat:SUCCESS;
[2010-05-07 16:00:16 182][LgTp:OFLWVR][Sndr:+8613810243001][Rcvr:7800121000][FwdAddr:][SessID:0120000000003100507160016][MsgID:050716001680080001203][ExMsgID:][FlwCls:NORMAL]; FlwOvrStat:SUBMIT_OK; FlwOvrStatCode:0400; DtlCd:STAT_SUBMIT_SUCCESS; DlvrTimer:0 Second(s);
[2010-05-07 16:00:16 182][LgTp:ENTRLS][SessID:0120000000003100507160016][MsgID:050716001680080001203][ExMsgID:][EntAct:SUBMIT_SESSION_RELEASE]; RealFlwCls:NORMAL;
[2010-05-07 16:00:16 183][LgTp:SRVMSG][AfOrgn:][Sndr:+8613810243001][Rcvr:7800121000][FwdAddr:][SqncNum:-1][SessID:0120000000004100507160016][MsgID:050716001680080001203][TransID:0120000000004100507160016001][ExMsgID:][MPRP:MM7][MsgType:MM7_DELIVER_REQ][AfrAtrbt:SND][AfrStat:SNDING]; SV:SHOW; MsgCls:PRSL; DR:NO; RR:NO; Expiry:100 Second(s); MsgSz:0 Byte(s); VASPID:822000; VASID:7800; SrvCd:121000; DlvrType:NORMAL; SessType:Normal;
[2010-05-07 16:00:16 203][LgTp:SRVMSG][AfOrgn:][Sndr:+8613810243001][Rcvr:7800121000][FwdAddr:][SqncNum:0][SessID:0120000000004100507160016][MsgID:050716001680080001203][TransID:0120000000004100507160016001][ExMsgID:][MPRP:MM7][MsgType:MM7_DELIVER_RES][AfrAtrbt:RCV][AfrStat:OK]; MM7RspStat:SUCCESS;ResOriginStat:1000;
[2010-05-07 16:00:16 203][LgTp:TFLWVR][Sndr:+8613810243001][Rcvr:7800121000][FwdAddr:][SessID:0120000000004100507160016][MsgID:050716001680080001203][ExMsgID:][FlwCls:NORMAL]; FlwOvrStat:DELIVER_OK; FlwOvrStatCode:1100; DtlCd:STAT_FRWRD_SNDR_ADDR_IN_FRWRD_RCVR_USER_BLKLST; RealFlwCls:NORMAL;
[2010-05-07 16:00:16 207][LgTp:ENTRLS][SessID:0120000000004100507160016][MsgID:050716001680080001203][ExMsgID:][EntAct:DELIVER_SESSION_RELEASE]; RealFlwCls:NORMAL;
[2010-05-07 16:00:16 207][LgTp:ENTRLS][MsgID:050716001680080001203][ExMsgID:][EntAct:ORIGINMSG_RELEASE];
</code></pre>
<h3 id="pi-jie-jian-quan">批价鉴权</h3>
<p>验证了AOMT和MOAT批价鉴权流程，流程通畅。</p>
<h3 id="er-ci-que-ren-liu-cheng">二次确认流程</h3>
<h4 id="gong-ju-ri-zhi-pian-duan">工具日志片段</h4>
<pre><code class="language-shell">[2010-05-08 16:19:54:447]  收到HTTP主动请求 AuthPriceReq, TransactionID=8008000000000007
[2010-05-08 16:19:54:447]  返回响应 AuthPriceResp, hRet = 0
[2010-05-08 16:19:59:447]  开始发送OnDemandReq
[2010-05-08 16:19:59:447]  收到响应OnDemandRes, hRet = 0
</code></pre>
<h4 id="ji-fei-hua-dan-1">计费话单</h4>
<pre><code class="language-shell">0507161533800800011060000,008613810243001,,0,008613810243001,822000,,5,1,4,0,3,0,0,1,2,0,1100,910000,800800,822000,7800,121000,,2010
0507161533,20100507161538,,00000,1,6,0,0,0,0,,
</code></pre>
<h4 id="tong-ji-hua-dan-1">统计话单</h4>
<pre><code class="language-shell">0507161533800800011060000,008613810243001,,0,008613810243001,822000,,0,1,4,0,3,0,0,1,2,0,0400,910000,800800,822000,7800,121000,,2010
0507161533,20100507161538,,00000,1,6,0,0,0,0,,1,1,
0507161533800800011060000,008613810243001,,0,008613810243001,822000,,5,1,4,0,3,0,0,1,2,0,1100,910000,800800,822000,7800,121000,,2010
0507161533,20100507161538,,00000,1,6,0,0,0,0,,,1,
</code></pre>
<h3 id="zhi-chi-dr-you-hua">支持DR优化</h3>
<p>流程正常</p>
<h4 id="mmsclient-ri-zhi-pian-duan">Mmsclient日志片段</h4>
<pre><code class="language-shell">[2010-05-07 16:18:18.985] [FINEST] [mmscclient_5401] [SocketConnection.java:539] [ ] [Receive Message] 
Receive message from module[1], binary stream:
16:18:18.985(Tools.java:374) byte[297] @15430449 {
    [HEX]    0  1  2  3  4  5  6  7-  8  9  a  b  c  d  e  f | 0123456789abcdef
  ----------------------------------------------------------------------------
  00000000: 00 00 00 c5 17 40 00 00.ff ff ff ff ff ff 00 03 | .....@..........
  00000010: 00 01 10 01 00 02 00 4a.15 19 00 00 00 00 ff ff | .......J........
  00000020: ff ff 8c c0 98 30 31 32.30 30 30 30 30 30 30 30 | .....01200000000
  00000030: 31 32 31 30 30 35 30 37.31 36 31 38 31 38 30 30 | 1210050716181800
  00000040: 31 00 f1 30 35 30 37 31.36 31 38 31 38 38 30 30 | 1..0507161818800
  00000050: 38 30 30 30 31 32 30 37.00 ea 38 32 32 30 30 30 | 80001207..822000
  00000060: 00 eb 37 38 30 30 00 ec.31 32 31 30 30 30 00 d5 | ..7800..121000..
  00000070: 02 06 30 d8 38 30 30 31.30 30 00 d9 37 37 38 38 | ..0.800100..7788
  00000080: 00 85 04 4b e3 cc ca 97.2b 38 36 31 33 38 31 30 | ...K....+8613810
  00000090: 32 34 33 30 30 31 00 d7.38 32 32 30 30 31 00 96 | 243001..822001..
  000000a0: 54 68 69 73 20 69 73 20.61 20 74 65 73 74 2e 00 | This is a test..
  000000b0: 8a 80 88 06 80 04 4b e3.cd 06 86 80 90 81 d6 03 | ......K.........
  000000c0: 0d e2 b0               .                        | ...             
}

[2010-05-07 16:18:18.986] [FINER] [mmscclient_5401] [MMSCProcessor.java:56] [ ] [MMSG to MMSC] 
Begin to dispose message from MMSGserver!
[2010-05-07 16:18:18.986] [FINER] [mmscclient_5401] [MMSCProcessor.java:124] [ ] [MMSG to MMSC] 
PDU message detail is:
MessageType = MM7-Submit.req
TransactionID = 0120000000012100507161818001
MM7Version = 6.3.0
To = [+8613810243001]
Date = 2010-05-07 16:18:18 +0800
DeliveryReport = YES
Expiry = 2010-05-07 16:19:18 +0800
MessageClass = Personal
ReadReply = NO
Subject = This is a test.
MMSCID = 910000
VASPID = 800100
VASID = 7788
ServiceCode = 822001
MMSGMessageID = 050716181880080001207
RealVASPID = 822000
RealVASID = 7800
RealServiceCode = 121000

[2010-05-07 16:18:18.986] [FINER] [mmscclient_5401] [MMSCProcessor.java:231] [ ] [MMSG to MMSC] 
MMSC Support DR Optimization
[2010-05-07 16:18:18.986] [FINER] [mmscclient_5401] [MMSCProxyHTTPImp.java:461] [ ] [MMSG to MMSC] 
MMSCURL(soap) is: http://10.137.48.60:1190/mmsc
[2010-05-07 16:18:19.022] [FINEST] [mmscclient_5401] [MMSCProxyHTTPImp.java:778] [ ] [MMSG to MMSC] 
Get response from MMSC, detail:
&lt;?xml version="1.0"?&gt;&lt;env:Envelope xmlns:env="http://schemas.xmlsoap.org/soap/envelope/"&gt;&lt;env:Header&gt;&lt;mm7:TransactionID xmlns:mm7="http://www.3gpp.org/ftp/Specs/archive/23_series/23.140/schema/REL-6-MM7-1-0"&gt;050716181880080001207&lt;/mm7:TransactionID&gt;&lt;/env:Header&gt;&lt;env:Body&gt;&lt;SubmitRsp xmlns="http://www.3gpp.org/ftp/Specs/archive/23_series/23.140/schema/REL-6-MM7-1-0"&gt;&lt;MM7Version&gt;6.3.0&lt;/MM7Version&gt;&lt;Status&gt;&lt;StatusCode&gt;1000&lt;/StatusCode&gt;&lt;/Status&gt;&lt;MessageID&gt;050708224000108220010&lt;/MessageID&gt;&lt;/SubmitRsp&gt;&lt;/env:Body&gt;&lt;/env:Envelope&gt; 

[2010-05-07 16:18:19.023] [FINER] [mmscclient_5401] [MMSCProxyHTTPImp.java:1140] [ ] [MMSCProxyHTTPImp] 
get response from MMSC, detail:
MessageType = MM7-Submit.res
TransactionID = 050716181880080001207
MM7Version = 6.3.0
MessageID = 050708224000108220010
StatusCode = 1000

[2010-05-07 16:18:19.023] [FINER] [mmscclient_5401] [MMSCProcessor.java:449] [ ] [MMSCProxyHTTPImp] 
Send response to Server, detail:
MessageType = MM7-Submit.res
TransactionID = 0120000000012100507161818001
MM7Version = 6.3.0
MessageID = 050708224000108220010
StatusCode = 1000
</code></pre>
<h4 id="yao-qiu-bao-yue-ji-fei">要求包月计费</h4>
<pre><code class="language-shell">[2010-05-08 17:04:28:277]  收到HTTP主动请求 AuthPriceReq, TransactionID=8008000000000003
[2010-05-08 17:04:28:277]  返回响应 AuthPriceResp, hRet = 0
[2010-05-08 17:04:28:480]  收到HTTP主动请求 RequireMonthFeeReq, TransactionID=8008000000000004
[2010-05-08 17:04:28:480]  返回响应 RequireMonthFeeReq, hRet = 0
</code></pre>
<h4 id="ji-fei-hua-dan-2">计费话单</h4>
<pre><code class="language-shell">0507170006800800012030000,008613810243001,,0,822000,008613810243001,,2,1,3,0,3,0,0,1,2,0,1000,800800,910000,822000,7800,121000,,2010
0507170006,20100507170007,,00000,1,1,1,0,0,0,042803088220010000035,
</code></pre>
<h4 id="tong-ji-hua-dan-2">统计话单</h4>
<pre><code class="language-shell">0507170006800800012030000,008613810243001,,0,822000,008613810243001,,2,1,3,0,3,0,0,1,2,0,0100,800800,910000,822000,7800,121000,,2010
0507170006,20100507170006,,00000,1,1,1,0,0,0,,,1,
0507170006800800012030000,008613810243001,,0,822000,008613810243001,,3,1,3,0,3,0,0,1,2,0,1000,800800,910000,822000,7800,121000,,2010
0507170006,20100507170007,,00000,1,1,1,0,0,0,,1,1,
</code></pre>
<h4 id="ye-wu-ri-zhi-cha-xun">业务日志查询</h4>
<img class="shadow" src="/img/in-post/oracle-un-query.png" width="1200">
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--sqlldr导入数据报错</title>
    <url>/2010/06/07/oracle_troubleshoot_sqlldr_error/</url>
    <content><![CDATA[<p>qlldr导入数据报错</p>
<h1 id="biao-xiang">表象</h1>
<pre><code class="language-shell">Record 47: Rejected - Error on table NAPTR_MMS, column SEQUENCENO.   
Column not found before end of logical record (use TRAILING NULLCOLS)
Record 48: Rejected - Error on table NAPTR_MMS, column SEQUENCENO.   
Column not found before end of logical record (use TRAILING NULLCOLS)
Record 49: Rejected - Error on table NAPTR_MMS, column SEQUENCENO.   
Column not found before end of logical record (use TRAILING NULLCOLS)
Record 50: Rejected - Error on table NAPTR_MMS, column SEQUENCENO.   
Column not found before end of logical record (use TRAILING NULLCOLS)
Record 51: Rejected - Error on table NAPTR_MMS, column SEQUENCENO.   
Column not found before end of logical record (use TRAILING NULLCOLS)
</code></pre>
<h1 id="yuan-yin">原因</h1>
<p>因为要导入的trim_naptr_datafile.xls文件中，列字段是不定长的，需要使用trailing nullcols。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<pre><code class="language-shell">Load      data　                                             
infile      '/opt/oracle/trim_naptr_datafile.xls'            
append  into  table  NAPTR_MMS                               
fields  terminated  by  '|'  
TRAILING NULLCOLS                                
(                                                            
   E164NUMBER  CHAR,                                             
   PRIORITY    ,                                             
   PREFERENCE  ,                                             
　  FLAGS        CHAR,                                           
   SERVICES    CHAR,                                             
   REGEXP      CHAR,                                             
   REPLACEMENT CHAR,                                             
   SEQUENCENO  CHAR,                                             
   TTL  
)
</code></pre>
<p>在ctl文件中增加了"TRAILING NULLCOLS "这行内容。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle SQL篇之账号</title>
    <url>/2010/06/10/oracle_user/</url>
    <content><![CDATA[<h1 id="xian-shi-dang-qian-lian-jie-yong-hu">显示当前连接用户</h1>
<pre><code class="language-shell">SQL&gt; show user       
USER 为 "SYS"
SQL&gt;
</code></pre>
<h1 id="zai-mou-ge-yong-hu-xia-zhao-suo-you-de-suo-yin">在某个用户下找所有的索引</h1>
<pre><code class="language-shell">select user_indexes.table_name, user_indexes	.index_name,uniqueness,column_name 	 
from user_ind_columns, user_indexes   
where user_ind_columns.index_name = user_indexes.index_name 
and user_ind_columns.table_name = user_indexes.table_name 
order by user_indexes.table_type, user_indexes.table_name, user_indexes.index_name, column_position;
</code></pre>
<h1 id="cha-xun-mei-ge-yong-hu-de-quan-xian">查询每个用户的权限</h1>
<pre><code class="language-shell">SQL&gt; SELECT * FROM DBA_SYS_PRIVS;
</code></pre>
<h1 id="huo-qu-you-na-xie-yong-hu-zai-shi-yong-shu-ju-ku">获取有哪些用户在使用数据库</h1>
<pre><code class="language-shell">SQL&gt; select username from v$session; 

USERNAME
------------------------------------------------------------
MMSG
MMSG

SYS
SYS
MMSG
MMSG
MMSG

已选择7行。

SQL&gt;
</code></pre>
<h1 id="cha-xun-yong-hu-yong-you-de-quan-xian">查询用户拥有的权限</h1>
<pre><code class="language-shell">mmsg:oracle:mmsgdb &gt; sqlplus / as sysdba

+SQL*Plus: Release 11.1.0.6.0 - Production on Tue Feb 22 15:58:54 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options


SQL&gt; SELECT *  FROM DBA_SYS_PRIVS where grantee='MMSG';

GRANTEE                        PRIVILEGE                                ADM
------------------------------ ---------------------------------------- ---
MMSG                           UNLIMITED TABLESPACE                     NO
MMSG                           CREATE VIEW                              NO
MMSG                           CREATE TABLE                             NO
MMSG                           CREATE SESSION                           NO
MMSG                           CREATE PROCEDURE                         NO
MMSG                           CREATE SEQUENCE                          NO

6 rows selected.

SQL&gt;
</code></pre>
<h1 id="suo-yong-hu-yong-hu-jie-suo">锁用户/用户解锁</h1>
<h2 id="suo-yong-hu">锁用户</h2>
<pre><code class="language-shell">SQL&gt; alter user wyz account lock;

用户已更改。

SQL&gt; connect wyz/wyz@mmsgdb
ERROR:
ORA-28000: 帐户已被锁定


警告: 您不再连接到 ORACLE。
</code></pre>
<h2 id="yong-hu-jie-suo">用户解锁</h2>
<pre><code class="language-shell">SQL&gt; alter user wyz account unlock;

用户已更改。

SQL&gt; connect wyz/wyz@mmsgdb
已连接。
SQL&gt; exit
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle SQL篇之表空间</title>
    <url>/2010/07/01/oracle_tablespace/</url>
    <content><![CDATA[<h1 id="cha-kan-biao-da-xiao">查看表大小</h1>
<p>有两种含义的表大小：一种是分配给一个表的物理空间数量，而不管空间是否被使用。可以这样查询获得字节数：</p>
<pre><code class="language-shell">select segment_name, bytes 
from user_segments 
where segment_type = 'TABLE'; 
</code></pre>
<p>或者</p>
<pre><code class="language-shell">Select Segment_Name,Sum(bytes)/1024/1024 From User_Extents Group By Segment_Name
</code></pre>
<p>另一种表实际使用的空间。这样查询：</p>
<pre><code class="language-shell">analyze table AREAINFO compute statistics; 

select   TABLE_NAME,TABLESPACE_NAME, NUM_ROWS ,AVG_ROW_LEN,  NUM_ROWS*AVG_ROW_LEN   
from user_tables 
where table_name = 'AREAINFO';
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>表名称要大写，红色加粗部分。</p>
</li>
</ul>
<h1 id="cha-kan-mei-ge-biao-kong-jian-de-da-xiao">查看每个表空间的大小</h1>
<pre><code class="language-shell">Select Tablespace_Name,Sum(bytes)/1024/1024 From Dba_Segments Group By Tablespace_Name
</code></pre>
<h1 id="kan-shu-ju-ku-you-duo-shao-ge-tablespace">看数据库有多少个tablespace</h1>
<pre><code class="language-shell">oracle@mmsg:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期四 7月 1 17:37:14 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; set wrap on
SQL&gt; set linesize 700
SQL&gt; select * from dba_tablespaces;

TABLESPACE_NAME                                              BLOCK_SIZE INITIAL_EXTENT NEXT_EXTENT MIN_EXTENTS MAX_EXTENTS   MAX_SIZE PCT_INCREASE MIN_EXTLEN STATUS                 CONTENTS           LOGGING            FORCE_ EXTENT_MANAGEMENT    ALLOCATION_TYPE    PLUGGE SEGMENT_SPAC DEF_TAB_COMPRESS RETENTION                  BIGFIL PREDICATE_EVAL ENCRYP COMPRESS_FOR
------------------------------------------------------------ ---------- -------------- ----------- ----------- ----------- ---------- ------------ ---------- ------------------ ------------------ ------------------ ------ -------------------- ------------------ ------ ------------ ---------------- ---------------------- ------ -------------- ------ ------------------------------------
SYSTEM                                                             8192          65536                       1  2147483645 2147483645                       65536 ONLINE             PERMANENT          LOGGING            NO     LOCAL                SYSTEM             NO     MANUAL   DISABLED         NOT APPLY              NO     HOST           NO
SYSAUX                                                             8192          65536                       1  2147483645 2147483645                       65536 ONLINE             PERMANENT          LOGGING            NO     LOCAL                SYSTEM             NO     AUTO     DISABLED         NOT APPLY              NO     HOST           NO
UNDOTBS1                                                           8192          65536                       1  2147483645 2147483645                       65536 ONLINE             UNDO               LOGGING            NO     LOCAL                SYSTEM             NO     MANUAL   DISABLED         NOGUARANTEE            NO     HOST           NO
TEMP                                                               8192        1048576     1048576           1             2147483645                0    1048576 ONLINE             TEMPORARY          NOLOGGING          NO     LOCAL                UNIFORM            NO     MANUAL   DISABLED         NOT APPLY              NO     HOST           NO
USERS                                                              8192          65536                       1  2147483645 2147483645                       65536 ONLINE             PERMANENT          LOGGING            NO     LOCAL                SYSTEM             NO     AUTO     DISABLED         NOT APPLY              NO     HOST           NO
MMSG                                                               8192          65536                       1  2147483645 2147483645                       65536 ONLINE             PERMANENT          LOGGING            NO     LOCAL                SYSTEM             NO     AUTO     DISABLED         NOT APPLY              NO     HOST           NO
MMSG_TMP                                                           8192        1048576     1048576           1             2147483645                0    1048576 ONLINE             TEMPORARY          NOLOGGING          NO     LOCAL                UNIFORM            NO     MANUAL   DISABLED         NOT APPLY              NO     HOST           NO

已选择7行。

SQL&gt;
</code></pre>
<h1 id="ru-he-cha-you-duo-shao-ge-shu-ju-ku-shi-li">如何查有多少个数据库实例</h1>
<pre><code class="language-shell">SQL&gt; select instance_number,instance_name,status from v$instance;

INSTANCE_NUMBER INSTANCE_NAME    STATUS
--------------- ---------------- ------------
              1 mmsgdb           OPEN

SQL&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--OEM启动失败</title>
    <url>/2010/07/20/oracle_troubleshoot_start_oem_failed/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>当前的彩信网关，一般在安装指南中并不安装oem，所以启动OEM必定会失败。对于OEM启动失败的情况下，又不知如何去解决，建议直接重新安装一次OEM.</p>
<h1 id="emca-ming-ling-shi-yong-shuo-ming">emca命令使用说明</h1>
<pre><code class="language-shell">/opt/oracle/product/11g/bin/emca [operation] [mode] [dbType] [flags] [parameters]

-h | --h | -help | --help: prints this help message 
-version: prints the version

-config dbcontrol db [-repos (create | recreate)] [-cluster] [-silent] [-backup] [parameters]: configure Database Control for a database
-config centralAgent (db | asm) [-cluster] [-silent] [parameters]: configure central agent management
-config all db [-repos (create | recreate)] [-cluster] [-silent] [-backup] [parameters]: configure both Database Control and central agent management

-deconfig dbcontrol db [-repos drop] [-cluster] [-silent] [parameters]: de-configure Database Control
-deconfig centralAgent (db | asm) [-cluster] [ -silent] [parameters]: de-configure central agent management
-deconfig all db [-repos drop] [-cluster] [-silent] [parameters]: de-configure both Database Control and central agent management

-addInst (db | asm) [-silent] [parameters]: configure EM for a new RAC instance
-deleteInst (db | asm) [-silent] [parameters]: de-configure EM for a specified RAC instance

-reconfig ports [-cluster] [parameters]: explicitly reassign Database Control ports
-reconfig dbcontrol -cluster [-silent] [parameters]: reconfigures RAC Database Control deployment

-displayConfig dbcontrol -cluster [-silent] [parameters]: displays information about the RAC Database Control configuration

-migrate -from dbcontrol -to centralAgent  [-repos drop] [-cluster] [-silent] [parameters]: migrates EM configuration from Database Control to central agent

-upgrade (db | asm | db_asm) [-cluster] [-silent] [parameters]: upgrades an earlier version of the EM configuration to the current version

-restore (db | asm | db_asm) [-cluster] [-silent] [parameters]: restores the current version of the EM configuration to an earlier version

Parameters and Options:
[parameters]: [ -respFile fileName ] [ -paramName paramValue ]* 
db: perform configuration operation for a database (including databases that use ASM)
asm: perform configuration operation for an ASM-only instance
db_asm: perform upgrade/restore operation for a database and an ASM instance
-repos create: create a new Database Control repository
-repos drop: drop the current Database Control repository
-repos recreate: drop the current Database Control repository and recreate a new one
-cluster: perform configuration operation for a RAC database
-silent: perform configuration operation without prompting for parameters
-backup: configure automatic backup for a database

Parameters for single instance databases
        ORACLE_HOSTNAME: Local hostname
        SID: Database SID
        PORT: Listener port number
        ORACLE_HOME: Database ORACLE_HOME
        HOST_USER: Host username for automatic backup
        HOST_USER_PWD: Host user password for automatic backup
        BACKUP_SCHEDULE: Automatic backup schedule (HH:MM)
        EMAIL_ADDRESS: Email address for notifications
        MAIL_SERVER_NAME: Outgoing Mail (SMTP) server for notifications
        ASM_OH: ASM ORACLE_HOME
        ASM_SID: ASM SID
        ASM_PORT: ASM port
        ASM_USER_ROLE: ASM user role
        ASM_USER_NAME: ASM username
        ASM_USER_PWD: ASM user password
        SRC_OH: ORACLE_HOME for the database to be upgraded
        DBSNMP_PWD: Password for DBSNMP user
        SYSMAN_PWD: Password for SYSMAN user
        SYS_PWD: Password for SYS user
        DBCONTROL_HTTP_PORT: Database Control HTTP port
        AGENT_PORT: EM agent port
        RMI_PORT: RMI port for Database Control
        JMS_PORT: JMS port for Database Control
        EM_SWLIB_STAGE_LOC:  Software library location
        PORTS_FILE: Path to a static file specifying the ports to use (Default value : ${ORACLE_HOME}/install/staticports.ini).

Additional Parameters for cluster databases
        CLUSTER_NAME: Cluster name
        DB_UNIQUE_NAME: Database unique name
        SERVICE_NAME: Service name
        EM_NODE: Database Control node name
        EM_SID_LIST: Agent SID list [comma separated]
oracle@mmsg:~&gt; emca -config dacontrol mmsgdb -repos recreate
/opt/oracle/product/11g/bin/emca [operation] [mode] [dbType] [flags] [parameters]

-h | --h | -help | --help: prints this help message 
-version: prints the version

-config dbcontrol db [-repos (create | recreate)] [-cluster] [-silent] [-backup] [parameters]: configure Database Control for a database
-config centralAgent (db | asm) [-cluster] [-silent] [parameters]: configure central agent management
-config all db [-repos (create | recreate)] [-cluster] [-silent] [-backup] [parameters]: configure both Database Control and central agent management

-deconfig dbcontrol db [-repos drop] [-cluster] [-silent] [parameters]: de-configure Database Control
-deconfig centralAgent (db | asm) [-cluster] [ -silent] [parameters]: de-configure central agent management
-deconfig all db [-repos drop] [-cluster] [-silent] [parameters]: de-configure both Database Control and central agent management

-addInst (db | asm) [-silent] [parameters]: configure EM for a new RAC instance
-deleteInst (db | asm) [-silent] [parameters]: de-configure EM for a specified RAC instance

-reconfig ports [-cluster] [parameters]: explicitly reassign Database Control ports
-reconfig dbcontrol -cluster [-silent] [parameters]: reconfigures RAC Database Control deployment

-displayConfig dbcontrol -cluster [-silent] [parameters]: displays information about the RAC Database Control configuration

-migrate -from dbcontrol -to centralAgent  [-repos drop] [-cluster] [-silent] [parameters]: migrates EM configuration from Database Control to central agent

-upgrade (db | asm | db_asm) [-cluster] [-silent] [parameters]: upgrades an earlier version of the EM configuration to the current version

-restore (db | asm | db_asm) [-cluster] [-silent] [parameters]: restores the current version of the EM configuration to an earlier version

Parameters and Options:
[parameters]: [ -respFile fileName ] [ -paramName paramValue ]* 
db: perform configuration operation for a database (including databases that use ASM)
asm: perform configuration operation for an ASM-only instance
db_asm: perform upgrade/restore operation for a database and an ASM instance
-repos create: create a new Database Control repository
-repos drop: drop the current Database Control repository
-repos recreate: drop the current Database Control repository and recreate a new one
-cluster: perform configuration operation for a RAC database
-silent: perform configuration operation without prompting for parameters
-backup: configure automatic backup for a database

Parameters for single instance databases
        ORACLE_HOSTNAME: Local hostname
        SID: Database SID
        PORT: Listener port number
        ORACLE_HOME: Database ORACLE_HOME
        HOST_USER: Host username for automatic backup
        HOST_USER_PWD: Host user password for automatic backup
        BACKUP_SCHEDULE: Automatic backup schedule (HH:MM)
        EMAIL_ADDRESS: Email address for notifications
        MAIL_SERVER_NAME: Outgoing Mail (SMTP) server for notifications
        ASM_OH: ASM ORACLE_HOME
        ASM_SID: ASM SID
        ASM_PORT: ASM port
        ASM_USER_ROLE: ASM user role
        ASM_USER_NAME: ASM username
        ASM_USER_PWD: ASM user password
        SRC_OH: ORACLE_HOME for the database to be upgraded
        DBSNMP_PWD: Password for DBSNMP user
        SYSMAN_PWD: Password for SYSMAN user
        SYS_PWD: Password for SYS user
        DBCONTROL_HTTP_PORT: Database Control HTTP port
        AGENT_PORT: EM agent port
        RMI_PORT: RMI port for Database Control
        JMS_PORT: JMS port for Database Control
        EM_SWLIB_STAGE_LOC:  Software library location
        PORTS_FILE: Path to a static file specifying the ports to use (Default value : ${ORACLE_HOME}/install/staticports.ini).

Additional Parameters for cluster databases
        CLUSTER_NAME: Cluster name
        DB_UNIQUE_NAME: Database unique name
        SERVICE_NAME: Service name
        EM_NODE: Database Control node name
        EM_SID_LIST: Agent SID list [comma separated]
</code></pre>
<h1 id="zhong-xin-chuang-jian-oem">重新创建OEM</h1>
<pre><code class="language-shell">oracle@mmsg:~&gt; emca -config dbcontrol db -repos recreate

STARTED EMCA at Jul 20, 2010 2:46:53 PM
EM Configuration Assistant, Version 11.1.0.7.0 Production
Copyright (c) 2003, 2005, Oracle.  All rights reserved.

Enter the following information:
Database SID: mmsgdb
Listener port number: 1521
Password for SYS user:  
Password for SYSMAN user: 
Email address for notifications (optional):   #这个是可选的
Outgoing Mail (SMTP) server for notifications (optional):  #这个是可选的
-----------------------------------------------------------------

You have specified the following settings

Database ORACLE_HOME ................ /opt/oracle/product/11g

Local hostname ................ mmsg
Listener port number ................ 1521
Database SID ................ mmsgdb
Email address for notifications ............... 
Outgoing Mail (SMTP) server for notifications ............... 

-----------------------------------------------------------------
Do you wish to continue? [yes(Y)/no(N)]: yes
Jul 20, 2010 2:48:24 PM oracle.sysman.emcp.EMConfig perform
INFO: This operation is being logged at /opt/oracle/cfgtoollogs/emca/mmsgdb/emca_2010_07_20_14_46_53.log.
Jul 20, 2010 2:48:25 PM oracle.sysman.emcp.EMReposConfig invoke
INFO: Dropping the EM repository (this may take a while) ...
Jul 20, 2010 2:50:18 PM oracle.sysman.emcp.EMReposConfig invoke
INFO: Repository successfully dropped
Jul 20, 2010 2:50:18 PM oracle.sysman.emcp.EMReposConfig createRepository
INFO: Creating the EM repository (this may take a while) ...
Jul 20, 2010 2:54:51 PM oracle.sysman.emcp.EMReposConfig invoke
INFO: Repository successfully created
Jul 20, 2010 2:54:54 PM oracle.sysman.emcp.EMReposConfig uploadConfigDataToRepository
INFO: Uploading configuration data to EM repository (this may take a while) ...
Jul 20, 2010 2:55:36 PM oracle.sysman.emcp.EMReposConfig invoke
INFO: Uploaded configuration data successfully
Jul 20, 2010 2:55:38 PM oracle.sysman.emcp.util.DBControlUtil configureSoftwareLib
INFO: Software library configured successfully.
Jul 20, 2010 2:55:38 PM oracle.sysman.emcp.EMDBPostConfig configureSoftwareLibrary
INFO: Deploying Provisioning archives ...
Jul 20, 2010 2:55:45 PM oracle.sysman.emcp.EMDBPostConfig configureSoftwareLibrary
INFO: Provisioning archives deployed successfully.
Jul 20, 2010 2:55:45 PM oracle.sysman.emcp.util.DBControlUtil secureDBConsole
INFO: Securing Database Control (this may take a while) ...
Jul 20, 2010 2:55:56 PM oracle.sysman.emcp.util.DBControlUtil secureDBConsole
INFO: Database Control secured successfully.
Jul 20, 2010 2:55:56 PM oracle.sysman.emcp.util.DBControlUtil startOMS
INFO: Starting Database Control (this may take a while) ...
Jul 20, 2010 2:56:16 PM oracle.sysman.emcp.EMDBPostConfig performConfiguration
INFO: Database Control started successfully
Jul 20, 2010 2:56:16 PM oracle.sysman.emcp.EMDBPostConfig performConfiguration
INFO: &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; The Database Control URL is https://mmsg:1158/em &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
Jul 20, 2010 2:56:19 PM oracle.sysman.emcp.EMDBPostConfig invoke
WARNING: 
************************  WARNING  ************************

Management Repository has been placed in secure mode wherein Enterprise Manager data will be encrypted.  The encryption key has been placed in the file: /opt/oracle/product/11g/mmsg_mmsgdb/sysman/config/emkey.ora.   Please ensure this file is backed up as the encrypted data will become unusable if this file is lost. 

***********************************************************
Enterprise Manager configuration completed successfully
FINISHED EMCA at Jul 20, 2010 2:56:19 PM
oracle@mmsg:~&gt;
</code></pre>
<h1 id="deng-lu-oem">登录OEM</h1>
<p>创建OEM成功后，登陆OEM，默认端口1158,登录方式是：<code>https://hostip:1158/em/ </code>，成功登录后，如下图所示：</p>
<img class="shadow" src="/img/in-post/oracle-login-oem.png" width="400">
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle Dataguard</title>
    <url>/2010/08/12/oracle_dataguard/</url>
    <content><![CDATA[<h1 id="dataguard-gai-shu">dataguard概述</h1>
<p>Oracle Dataguard主要实现数据库的容灾，根据archive log进行数据的同步，当主库异常时，自动切换到备库。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="bei-jing">背景</h2>
<p>XX行业网关，本期配置了4块服务器（4C8G），分别部署在A地和B地两地，组成两两双机的对等集群。A地和B地两地相距30KM，采用千兆专线拉通，具体拓扑如下图所示：</p>
<img class="shadow" src="/img/in-post/oracle-dg.png" width="1200">
<h3 id="shu-ju-ku-rong-zai-fang-an">数据库容灾方案</h3>
<p>在A地和B地业务、数据库和计费服务器均进行合设。平时A地节点作为数据库生产节点，B地节点作为数据库容灾节点，生产节点和容灾节点通过DATAGUARD进行数据同步。</p>
<p>数据库生产节点和容灾节点通过F5实现对业务服务器的统一IP。即在F5上为数据库专门配置一个POOL和VISUAL SERVER。VISUAL SERVER是对外提供的数据库统一IP，将数据库生产节点优先级设置为高优先级，容杂节点设置为低优先级。平时F5会将流量发送高优先级的生产节点处理，当生产节点不可用时会自动发送给低优先级的容灾节点。</p>
<h2 id="shi-yan-huan-jing">试验环境</h2>
<p>SUSE Linux Enterprise Server 10 SP1 (x86_64) - Kernel 2.6.16.46-0.12-smp (3)</p>
<p>IP规划如下：</p>
<table>
<thead>
<tr>
<th>IP</th>
<th>硬件类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>10.137.49.114</td>
<td>R2+单板</td>
<td>primary数据库</td>
</tr>
<tr>
<td>10.137.49.167</td>
<td>R2单板</td>
<td>standby数据库</td>
</tr>
</tbody>
</table>
<h2 id="ruan-jian-huan-jing">软件环境</h2>
<p>Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production</p>
<h2 id="data-guard-cao-zuo">Data guard 操作</h2>
<h3 id="pei-zhi-cao-zuo">配置操作</h3>
<h4 id="1-que-ren-primary-shu-ju-ku-chu-yu-gui-dang-mo-shi">1、 确认primary数据库处于归档模式</h4>
<pre><code class="language-shell">SQL&gt; archive log list
数据库日志模式             非存档模式
自动存档             禁用
存档终点            /opt/oracle/product/11g/dbs/arch
最早的联机日志序列     1
当前日志序列           2
SQL&gt;
</code></pre>
<p>如果为非归档模式，请执行下列命令修改</p>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
SQL&gt; ALTER DATABASE ARCHIVELOG;

数据库已更改。

SQL&gt; ALTER DATABASE OPEN;

数据库已更改。

SQL&gt;
</code></pre>
<h4 id="2-she-zhi-gui-dang-ri-zhi-lu-jing">2、 设置归档日志路径</h4>
<pre><code class="language-shell">SQL&gt; show parameter log_archive_dest

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
log_archive_dest                     string
log_archive_dest_1                   string
log_archive_dest_10                  string
log_archive_dest_2                   string
log_archive_dest_3                   string
log_archive_dest_4                   string
log_archive_dest_5                   string
log_archive_dest_6                   string
log_archive_dest_7                   string
log_archive_dest_8                   string
log_archive_dest_9                   string

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
log_archive_dest_state_1             string      enable
log_archive_dest_state_10            string      enable
log_archive_dest_state_2             string      enable
log_archive_dest_state_3             string      enable
log_archive_dest_state_4             string      enable
log_archive_dest_state_5             string      enable
log_archive_dest_state_6             string      enable
log_archive_dest_state_7             string      enable
log_archive_dest_state_8             string      enable
log_archive_dest_state_9             string      enable

#arch目录请到dbs目录下手工创建
SQL&gt; alter system set log_archive_dest_1=' location=/opt/oracle/diag/arch ' scope=spfile;
系统已更改。

SQL&gt; alter system set log_archive_format=' arch_%t_%s_%r.arc' scope=spfile;

系统已更改。
SQL&gt; 
</code></pre>
<h4 id="3-jiang-primary-shu-ju-ku-zhi-wei-force-logging-mo-shi">3、 将primary数据库置为FORCE LOGGING模式</h4>
<p>通过下列语句：</p>
<pre><code class="language-shell">SQL&gt; alter database force logging; 

数据库已更改。

#需要重启数据库，做如下操作：
SQL&gt; shutdown immediate
SQL&gt; startup
SQL&gt; show parameter log_archive_dest
SQL&gt; 
</code></pre>
<h4 id="4-primary-shu-ju-ku-chuang-jian-standby-shu-ju-ku-kong-zhi-wen-jian">4、 primary数据库创建standby数据库控制文件</h4>
<pre><code class="language-shell">SQL&gt; shutdown immediate
SQL&gt; startup mount
SQL&gt; alter database create standby controlfile as '/opt/oracle/oradata/mmsgdb/backupctl.ctl';  

数据库已更改。

SQL&gt; SQL&gt; alter database open;

数据库已更改。

SQL&gt; alter system archive log current;

系统已更改。

SQL&gt;
</code></pre>
<h4 id="5-chuang-jian-primary-shu-ju-ku-ke-hu-duan-chu-shi-hua-can-shu-wen-jian">5、 创建primary数据库客户端初始化参数文件</h4>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>主要此处修改项较多，为了方便，我们首先创建并修改pfile，然后再通过pfile重建spfile，你当然也可以通过alter system set命令直接修改spfile内容，不过，麻烦。</p>
</li>
</ul>
<pre><code class="language-shell">SQL&gt; create pfile from spfile;

文件已创建。
</code></pre>
<p>将该初始化参数文件复制一份，做为standby数据库的客户端初始化参数文件</p>
<pre><code class="language-shell">SQL&gt; host
oracle@mmsg:~&gt; cp /opt/oracle/product/11g/dbs/initmmsgdb.ora  /opt/oracle/product/11g/dbs/bakinitmmsgdb.ora
</code></pre>
<p>备份已有的spfile文件</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; cd $ORACLE_HOME/dbs
oracle@mmsg:~/product/11g/dbs&gt; cp spfilemmsgdb.ora bak_spfilemmsgdb.ora
</code></pre>
<p>修改客户端初始化参数文件，增加下列内容</p>
<pre><code class="language-shell">*.DB_UNIQUE_NAME=uqn_primary              //自定义一个unique_name名字
*.LOG_ARCHIVE_CONFIG='DG_CONFIG=(uqn_primary,uqn_standby)'  //此处为主备服务器的unique_name
*.LOG_ARCHIVE_DEST_2='SERVICE=standby ASYNC VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=uqn_standby'
*.LOG_ARCHIVE_DEST_STATE_1=ENABLE
*.LOG_ARCHIVE_DEST_STATE_2=ENABLE
*.LOG_ARCHIVE_MAX_PROCESSES=30

#--------配置standby角色的参数用于角色转换
*.FAL_SERVER=standby                        //这里为net service name
*.FAL_CLIENT=primary
*.STANDBY_FILE_MANAGEMENT=AUTO
</code></pre>
<p>上述新增内容中的注释部分不需要，请添加时去掉。</p>
<p>初始化参数参考</p>
<p>对于primary数据库，需要定义几个primary角色的初始化参数控制redo传输服务，还有几个附加的standby角色的参数需要添加以控制接收redo数据库并应用(switchover/failover后primary/standby角色可能互换，所以建议对于两类角色 相关的 初始化参数都进行配置)。</p>
<p>下列参数为primary角色相关的初始化参数：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>DB_NAME</td>
<td>注意保持同一个Data Guard中所有数据库DB_NAME相同。 例如：DB_NAME=mmsgdb</td>
</tr>
<tr>
<td>DB_UNIQUE_NAME</td>
<td>为每一个数据库指定一个唯一的名称，该参数一经指定不会再发生变化，除非你主动修改它。 例如：DB_UNIQUE_NAME= uqn_mmsgdb</td>
</tr>
<tr>
<td>LOG_ARCHIVE_CONFIG</td>
<td>该参数通过DG_CONFIG属性罗列同一个Data Guard中所有DB_UNIQUE_NAME(含primary db及standby db)，以逗号分隔 例如：LOG_ARCHIVE_CONFIG=‘DB_CONFIG= uqn_primary, uqn_standby)’</td>
</tr>
<tr>
<td>CONTROL_FILES</td>
<td>没啥说的，控制文件所在路径。</td>
</tr>
<tr>
<td>LOG_ARCHIVE_DEST_n</td>
<td>归档文件的生成路径 。该参数非常重要，并且属性和子参数也特别多(这里不一一列举，后面用到时单独讲解;如果你很好奇，建议直接查询oracle官方文档。Data guard白皮书第14章专门介绍了该参数各属性及子参数的功能和设置)。 例如： LOG_ARCHIVE_DEST_1= ‘LOCATION= /opt/oracle/diag/arch VALID_FOR=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME= uqn_primary’</td>
</tr>
<tr>
<td>LOG_ARCHIVE_DEST_STATE_n</td>
<td>指定参数值为ENABLE，允许redo传输服务传输redo数据到指定的路径。 该参数共拥有4个属性值，功能各不相同。</td>
</tr>
<tr>
<td>REMOTE_LOGIN_PASSWORDFILE</td>
<td>推荐设置参数值为EXCLUSIVE或者SHARED，注意保证相同Data Guard配置中所有db服务器sys密码相同。</td>
</tr>
<tr>
<td>LOG_ARCHIVE_FORMAT</td>
<td>指定归档文件格式。</td>
</tr>
<tr>
<td>LOG_ARCHIVE_MAX_PRODUCESSES</td>
<td>指定归档进程的数量(1-30)，默认值通常是4 。</td>
</tr>
</tbody>
</table>
<p>以下参数为standby角色相关的参数，建议在Primary数据库 的初始化参数中也进行设置，这样在role transition后(Primary转为Standby)也能正常运行：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>FAL_SERVER</td>
<td>指定一个数据库SID，通常该库为primary角色。 例如：FAL_SERVER=primary</td>
</tr>
<tr>
<td>FAL_CLIENT</td>
<td>指定一个数据库SID，通常该库为standby角色。 例如：FAL_CLIENT=standby</td>
</tr>
<tr>
<td>提示：FAL是Fetch Archived Log的缩写</td>
<td></td>
</tr>
<tr>
<td>DB_FILE_NAME_CONVERT</td>
<td>在做duplicate复制和传输表空间的时候这类参数讲过很多遍，该参数及上述内容中同名参数功能，格式等完全相同。</td>
</tr>
<tr>
<td>LOG_FILE_NAME_CONVERT</td>
<td>同上</td>
</tr>
<tr>
<td>STANDBY_FILE_MANAGEMENT</td>
<td>如果primary数据库数据文件发生修改（如新建，重命名等）则按照本参数的设置在standby中做相应修改。设为AUTO表示自动管理。设为MANUAL表示需要手工管理。例如：STANDBY_FILE_MANAGEMENT=AUTO</td>
</tr>
</tbody>
</table>
<p>注意：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>上面列举的这些参数仅只是对于primary/standby两角色可能会相关的参数，还有一些基础性参数比如*_dest,*_size等数据库相关的参数在具体配置时也需要根据实际情况做出适当修改。</p>
</li>
</ul>
<p>通过pfile重建spfile</p>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup pfile='/opt/oracle/product/11g/dbs/initmmsgdb.ora'
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt;

SQL&gt; create spfile='/opt/oracle/product/11g/dbs/spfilemmsgdb.ora' from pfile='/opt/oracle/product/11g/dbs/initmmsgdb.ora';

文件已创建。

SQL&gt;
SQL&gt; shutdown immediate
</code></pre>
<h4 id="6-fu-zhi-shu-ju-wen-jian-dao-standby-fu-wu-qi-fang-shi-duo-yang-bu-xiang-shu">6、 复制数据文件到standby服务器(方式多样，不详述)</h4>
<p>注:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>要先停止primary和standby服务器上的oracle数据库，然后复制所有数据文件，备份的控制文件及客户端初始化参数文件（数据文件、口令文件、pfile文件、控制文件）到standby数据库（同时，建议先备份一下standby数据库侧的数据文件、控制文件、参数文件和口令文件） ，具体文件列表信息如下：</p>
</li>
</ul>
<pre><code class="language-shell">#控制文件
backupctl.ctl
control01.ctl
control02.ctl
control03.ctl
#重做日志文件
redo01.log
redo02.log
redo03.log
#数据文件
sysaux01.dbf
system01.dbf
temp01.dbf
undotbs01.dbf
users01.dbf
#口令文件
orapwmmsgdb
参数文件
initmmsgdb.ora
</code></pre>
<p>还需要到STANDBY服务器上执行下面的操作。</p>
<pre><code class="language-shell">oracle@mmsg1:~&gt; cd /opt/oracle/oradata/ora11g
oracle@mmsg1:~/oradata/ora11g&gt; rm -rf control0*
oracle@mmsg1:~/oradata/ora11g&gt; mv backupctl.ctl  control01.ctl
oracle@mmsg1:~/oradata/ora11g&gt; cp control01.ctl control02.ctl
oracle@mmsg1:~/oradata/ora11g&gt; cp control01.ctl control03.ctl
oracle@mmsg1:~&gt; cd $ORACLE_HOME/dbs 
# 替换口令（如果sys密码不同）和pfile文件
oracle@mmsg1:~/product/11g/dbs&gt; ftp 10.137.49.114
Connected to 10.137.49.114.
220-Welcome to Pure-FTPd.
220-You are user number 1 of 50 allowed.
220-IPv6 connections are also welcome on this server.
220 You will be disconnected after 15 minutes of inactivity.
Name (10.137.49.114:root): oracle
331 User oracle OK. Password required
Password:
230-User oracle has group access to:  dba      oinstall
230 OK. Current directory is /opt/oracle
Remote system type is UNIX.
Using binary mode to transfer files.
ftp&gt; cd ~/product/11g/dbs
250 OK. Current directory is /opt/oracle/product/11g/dbs
ftp&gt; ls
229 Extended Passive mode OK (|||60900|)
150 Accepted data connection
-rw-r-----    1 oracle   oinstall     2560 Aug  9 15:16 bak_spfilemmsgdb.ora
-rw-r--r--    1 oracle   oinstall      908 Aug  9 15:00 bakinitmmsgdb.ora
-rw-rw----    1 oracle   oinstall     1552 Aug  9 16:16 hc_mmsgdb.dat
-rw-r--r--    1 oracle   oinstall     2774 Sep 11  2007 init.ora
-rw-r--r--    1 oracle   oinstall    12920 May  3  2001 initdw.ora
-rw-r--r--    1 oracle   oinstall     1262 Aug  9 16:14 initmmsgdb.ora
-rw-r-----    1 oracle   oinstall       24 Aug  9 12:38 lkMMSGDB
-rw-r-----    1 oracle   oinstall     1536 Aug  9 13:31 orapwmmsgdb
-rw-r-----    1 oracle   oinstall     3584 Aug  9 16:18 spfilemmsgdb.ora
226-Options: -l 
226 9 matches total
ftp&gt; asc
200 TYPE is now ASCII
ftp&gt; get initmmsgdb.ora
local: initmmsgdb.ora remote: initmmsgdb.ora
229 Extended Passive mode OK (|||11762|)
150 Accepted data connection
100% |*****************************************************************************************|  1300       3.44 MB/s    --:-- ETA
226-File successfully transferred
226 0.000 seconds (measured here), 25.62 Mbytes per second
1300 bytes received in 00:00 (31.72 KB/s)
ftp&gt; bin
200 TYPE is now 8-bit binary
ftp&gt; get orapwmmsgdb
local: orapwmmsgdb remote: orapwmmsgdb
229 Extended Passive mode OK (|||59851|)
150 Accepted data connection
100% |*****************************************************************************************|  1536       6.28 MB/s    00:00 ETA
226-File successfully transferred
226 0.000 seconds (measured here), 34.13 Mbytes per second
1536 bytes received in 00:00 (36.22 KB/s)
ftp&gt; by
221-Goodbye. You uploaded 0 and downloaded 3 kbytes.
221 Logout.
</code></pre>
<h4 id="7-xiu-gai-standby-shu-ju-ku-can-shu-wen-jian">7、 修改standby数据库参数文件</h4>
<pre><code class="language-shell">*.DB_UNIQUE_NAME=uqn_standby
*.LOG_ARCHIVE_CONFIG='DG_CONFIG=(uqn_primary,uqn_standby)'
*.LOG_ARCHIVE_DEST_2='SERVICE=primary ASYNC VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=uqn_primary'
*.LOG_ARCHIVE_DEST_STATE_1=ENABLE
*.LOG_ARCHIVE_DEST_STATE_2=ENABLE
*.LOG_ARCHIVE_MAX_PROCESSES=30

#--------配置standby角色的参数用于角色转换
*.FAL_SERVER=primary
*.FAL_CLIENT=standby
*.STANDBY_FILE_MANAGEMENT=AUTO
</code></pre>
<h4 id="8-xiu-gai-listener-ji-tns-xin-xi">8、 修改listener及tns信息</h4>
<p>配置primary数据库和standby数据库的listener及net service names(方式多样，不详述)</p>
<pre><code class="language-shell">SID_LIST_LISTENER =
(SID_LIST =
   (SID_DESC =
      (SID_NAME = PLSExtProc)
      (ORACLE_HOME = /opt/oracle/product/11g)
      (PROGRAM = extproc)
  )
    (SID_DESC =
        (GLOBAL_DBNAME = mmsgdb)
        (ORACLE_HOME = /opt/oracle/product/11g)
        (SID_NAME = mmsgdb)           
     )
  )

LISTENER =
  (DESCRIPTION_LIST =
    (DESCRIPTION =
      (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.49.114)(PORT = 1521))
      (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521))
    )
  )
</code></pre>
<p>上面为primary数据库的listener信息，standby数据库同理。其中"SID_LIST_LISTENER = "内容为新增信息，红色部分为primary数据库ip地址。</p>
<p>配置primary数据库和standby数据库的tnsnames.ora文件，修改成如下信息</p>
<pre><code class="language-shell">PRIMARY =
  (DESCRIPTION =
    (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.49.114)(PORT = 1521))
    (CONNECT_DATA =
      (SERVER = DEDICATED)
      (SERVICE_NAME = mmsgdb)
    )
  )
  
STANDBY =
  (DESCRIPTION =
    (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.49.167)(PORT = 1521))
    (CONNECT_DATA =
      (SERVER = DEDICATED)
      (SERVICE_NAME = mmsgdb)
    )
  )
</code></pre>
<p>完成之后重启primary数据库和standby数据库的listener，并测试监听:</p>
<pre><code class="language-shell">oracle@mmsg:~/product/11g/network/admin&gt; lsnrctl stop
oracle@mmsg:~/product/11g/network/admin&gt; lsnrctl start
oracle@mmsg:~/product/11g/network/admin&gt; tnsping primary 10

TNS Ping Utility for Linux: Version 11.1.0.7.0 - Production on 10-8月 -2010 11:14:02

Copyright (c) 1997, 2008, Oracle.  All rights reserved.

已使用的参数文件:


已使用 TNSNAMES 适配器来解析别名
Attempting to contact (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.49.114)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = mmsgdb)))
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
oracle@mmsg:~/product/11g/network/admin&gt; tnsping standby 10

TNS Ping Utility for Linux: Version 11.1.0.7.0 - Production on 10-8月 -2010 11:14:08

Copyright (c) 1997, 2008, Oracle.  All rights reserved.

已使用的参数文件:


已使用 TNSNAMES 适配器来解析别名
Attempting to contact (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.49.167)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = mmsgdb)))
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)
OK (0 毫秒)

oracle@mmsg:~/product/11g/network/admin&gt; 
</code></pre>
<p>执行ping操作，primary和standby互ping一下ip地址，如果能ping通，则继续执行下面的操作，如果ping不通，请检查配置。</p>
<h4 id="9-qi-dong-standby-shu-ju-ku">9、 启动standby数据库</h4>
<pre><code class="language-shell">oracle@mmsg1:~/product/11g/dbs&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期二 8月 10 14:47:21 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

已连接到空闲例程。

SQL&gt; create spfile from pfile='/opt/oracle/product/11g/dbs/initmmsgdb.ora';

文件已创建。

SQL&gt;

启动standby数据库到mount状态
SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
SQL&gt; alter database recover managed standby database disconnect from session; 

数据库已更改。

SQL&gt;
</code></pre>
<h3 id="cha-kan-tong-bu-qing-kuang">查看同步情况</h3>
<h4 id="fang-fa-yi">方法一</h4>
<h5 id="shou-xian-lian-jie-dao-primary-shu-ju-ku">首先连接到primary数据库</h5>
<pre><code class="language-shell">SQL&gt; show parameter instance_name

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
instance_name                        string      mmsgdb
SQL&gt; alter system switch logfile;

系统已更改。

SQL&gt; select max(sequence#) from v$archived_log; 

MAX(SEQUENCE#)
--------------
             5

SQL&gt; 
</code></pre>
<h5 id="lian-jie-dao-standby-shu-ju-ku">连接到standby数据库</h5>
<pre><code class="language-shell">SQL&gt; alter database recover managed standby database disconnect from session; 

数据库已更改。

SQL&gt; show parameter instance_name

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
instance_name                        string      mmsgdb
SQL&gt; select max(sequence#) from v$archived_log;

MAX(SEQUENCE#)
--------------
             5
SQL&gt;

MAX(SEQUENCE#)值一致，同步成功。
</code></pre>
<h4 id="fang-fa-er">方法二</h4>
<p>在standby服务器，执行如下操作：</p>
<pre><code class="language-shell">SQL&gt; SELECT SEQUENCE#, FIRST_TIME, NEXT_TIME FROM V$ARCHIVED_LOG ORDER BY SEQUENCE#;

 SEQUENCE# FIRST_TIME     NEXT_TIME
---------- -------------- --------------
         2 09-8月 -10     10-8月 -10
         3 10-8月 -10     10-8月 -10
         4 10-8月 -10     10-8月 -10
         5 10-8月 -10     10-8月 -10
</code></pre>
<p>在primary服务器，执行归档操作：</p>
<pre><code class="language-shell">SQL&gt; ALTER SYSTEM SWITCH LOGFILE; 

系统已更改。

SQL&gt;
</code></pre>
<p>返回standby服务器</p>
<pre><code class="language-shell">SQL&gt; SELECT SEQUENCE#, FIRST_TIME, NEXT_TIME FROM V$ARCHIVED_LOG ORDER BY SEQUENCE#;

 SEQUENCE# FIRST_TIME     NEXT_TIME
---------- -------------- --------------
         2 09-8月 -10     10-8月 -10
         3 10-8月 -10     10-8月 -10
         4 10-8月 -10     10-8月 -10
         5 10-8月 -10     10-8月 -10
         6 10-8月 -10     10-8月 -10

SQL&gt; SELECT SEQUENCE#,APPLIED FROM V$ARCHIVED_LOG ORDER BY SEQUENCE#;

 SEQUENCE# APPLIED
---------- ---------
         2 YES
         3 YES
         4 YES
         5 YES
         6 YES

SQL&gt;
</code></pre>
<p>发现有一条新的记录,说明同步是正常的。</p>
<h2 id="rong-zai-guan-bi">容灾关闭</h2>
<p>关闭数据库一定要先关闭primary数据库，然后再去关闭standby数据库。</p>
<p>primary数据库</p>
<pre><code class="language-shell">SQL&gt; shutdown immediate
</code></pre>
<p>standby数据库</p>
<pre><code class="language-shell">SQL&gt; alter database recover managed standby database cancel;

数据库已更改。

SQL&gt; shutdown immediate
</code></pre>
<h3 id="zhu-bei-qie-huan">主备切换</h3>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>主备切换必须先主切备，在备切主。</p>
</li>
</ul>
<h4 id="1-primary-qie-huan-dao-standby-shu-ju-ku">1、 primary切换到standby 数据库</h4>
<p>在primary数据库做如下操作</p>
<pre><code class="language-shell">SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt; alter system switch logfile; //主备切换做好做一次归档

系统已更改。

SQL&gt; alter database commit to switchover to standby with session shutdown;

数据库已更改。

SQL&gt; shutdown immediate
ORA-01507: 未装载数据库


ORACLE 例程已经关闭。
SQL&gt; startup nomount               
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
SQL&gt; alter database mount standby database;

数据库已更改。

SQL&gt; alter database recover managed standby database disconnect from session;

数据库已更改。

SQL&gt;
</code></pre>
<h4 id="2-standby-qie-huan-dao-primary">2、 standby 切换到 primary</h4>
<pre><code class="language-shell">SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
SQL&gt; alter database commit to switchover to primary with session shutdown;
alter database commit to switchover to primary with session shutdown
*
第 1 行出现错误:
ORA-16139: 需要介质恢复


SQL&gt; shutdown immediate
ORA-01109: 数据库未打开


已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt; 
</code></pre>
<p>至此，primary与standby数据库已经切换完成</p>
<p>如果想再去切换回来，请重复上述操作，注意primary和standby数据库已经发生了变化，以前的primary现在为standby数据库了。</p>
<h3 id="qie-huan-de-zui-da-ke-yong-mo-shi">切换的最大可用模式</h3>
<h4 id="1-shou-xian-ying-dang-zai-standby-shu-ju-ku-chuang-jian-standby-redolog">1、 首先应当在standby数据库创建standby redolog</h4>
<pre><code class="language-shell">SQL&gt; startup mount
SQL&gt; alter  database recover managed standby database cancel;
alter  database recover managed standby database cancel
*
第 1 行出现错误:	
ORA-16136: 受管备用恢复未激活

注：
此时只是暂时redo应用，并不是停止Standby数据库，standby仍会保持接收只不过不会再应用接收到的归档，直到你再次启动redo应用为止。

SQL&gt; alter database add standby logfile group 4 '/opt/oracle/oradata/mmsgdb/stdREDO01.LOG' size 500M;  

数据库已更改。

SQL&gt; alter database add standby logfile group 5 '/opt/oracle/oradata/mmsgdb/stdREDO02.LOG' size 500M;

数据库已更改。

SQL&gt; alter database add standby logfile group 6 '/opt/oracle/oradata/mmsgdb/stdREDO03.LOG' size 500M;

数据库已更改。

SQL&gt; alter database add standby logfile group 7 '/opt/oracle/oradata/mmsgdb/stdREDO04.LOG' size 500M;


数据库已更改。

SQL&gt; SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;     //启动实时应用

数据库已更改。

SQL&gt; 
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、standy redelog的组数参考公式：（online redolog组数+1）*数据库线程数：单机线程数为1，RAC一般为2</p>
</li>
<li class="lvl-2">
<p>2、stabdby redolog的组成员数和大小也尽量和online redolog一样</p>
</li>
</ul>
<p>检查standby redolog是否已经添加成功</p>
<pre><code class="language-shell">SQL&gt; select group#,thread#,sequence#,archived,status from v$standby_log;

    GROUP#    THREAD#  SEQUENCE# ARC STATUS
---------- ---------- ---------- --- ----------
         4          0          0 YES UNASSIGNED
         5          0          0 YES UNASSIGNED
         6          0          0 YES UNASSIGNED
         7          0          0 YES UNASSIGNED

SQL&gt;
</code></pre>
<h4 id="2-standby-shu-ju-ku-zhong-xin-qi-dong-hui-fu-guan-li-mo-shi">2、 standby数据库重新启动恢复管理模式</h4>
<pre><code class="language-shell">SQL&gt; alter database recover managed standby database disconnect from session;
alter database recover managed standby database disconnect from session
*
第 1 行出现错误:
ORA-01153: 激活了不兼容的介质恢复


SQL&gt; 
</code></pre>
<h4 id="3-xiu-gai-primary-shu-ju-ku-can-shu">3、 修改primary数据库参数</h4>
<p>设置standby数据库为最大性能模式（primary库优先）</p>
<pre><code class="language-shell">SQL&gt; alter system set log_archive_dest_2='SERVICE=STANDBY SYNC LGWR AFFIRM NET_TIMEOUT=10' SCOPE=SPFILE;

系统已更改。

SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。

SQL&gt; alter database set standby database to maximize availability;

数据库已更改。

SQL&gt; alter database open;

数据库已更改。

SQL&gt;
</code></pre>
<h4 id="4-primary-shu-ju-ku-ce-cha-kan-bao-hu-mo-shi">4、 primary数据库侧，查看保护模式</h4>
<pre><code class="language-shell">SQL&gt; select protection_mode ,protection_level from v$database;

PROTECTION_MODE      PROTECTION_LEVEL
-------------------- --------------------
MAXIMUM AVAILABILITY RESYNCHRONIZATION

SQL&gt;
显示当前为最大可用模式。
</code></pre>
<h4 id="5-zhu-primary-bei-standby-qie-huan">5、 主（primary）备（standby）切换</h4>
<p>如果要使得主备库可以切换，则应如步骤1~4同理在主备库做相应修改。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle SQL篇之监控</title>
    <url>/2010/08/20/oracle_monitor/</url>
    <content><![CDATA[<h1 id="jian-kong-shi-li-de-deng-dai">监控事例的等待</h1>
<pre><code class="language-shell">select event,sum(decode(wait_Time,0,0,1)) "Prev", sum(decode(wait_Time,0,1,0)) "Curr",count(*) "Tot" from v$session_Wait    group by event order by 4;
</code></pre>
<h1 id="hui-gun-duan-de-zheng-yong-qing-kuang">回滚段的争用情况</h1>
<pre><code class="language-shell">select name, waits, gets, waits/gets "Ratio"	from v$rollstat C, v$rollname D   where C.usn = D.usn;
</code></pre>
<h1 id="jian-kong-biao-kong-jian-de-i-o-bi-li">监控表空间的 I/O 比例</h1>
<pre><code class="language-shell">select B.tablespace_name nam, 
        A.phyblkrd pbr,
        A.phywrts pyw, 
        B.file_name "file", 
        A.phyrds pyr, 
        A.PHYBLKWRT pbw 
from v$filestat A, dba_data_files B   
where A.file# = B.file_id   order by B.tablespace_name;     
</code></pre>
<h1 id="jian-kong-wen-jian-xi-tong-de-i-o-bi-li">监控文件系统的 I/O 比例</h1>
<pre><code class="language-shell">select substr(C.file#,1,2) "#",substr(C.name,1,30) "Name", C.bytes, D.phyrds, D.PHYWRTS, C.status from v$datafile C, v$filestat D           
where C.file# = D.file#;
</code></pre>
<h1 id="jian-kong-sga-de-ming-zhong-lu">监控 SGA 的命中率</h1>
<pre><code class="language-shell">select a.value +	b.value "logical_reads", c.	value "phys_reads", round(100 * ((a.value+b.value)-c.value) / (a.value+b.value)) "BUFFER HIT RATIO" 
from v$sysstat a, v$sysstat 	b, v$sysstat c 
where a.statistic# = 38 and 	b.statistic# = 39 and c.statistic# = 40;
</code></pre>
<h1 id="jian-kong-sga-zhong-zi-dian-huan-chong-qu-de-ming-zhong-lu">监控 SGA 中字典缓冲区的命中率</h1>
<pre><code class="language-shell">select parameter, gets,Getmisses , getmisses/(gets+getmisses)*100 "miss ratio",
(1-(sum(getmisses)/ (sum(getmisses)+sum(getmisses))))*100 "Hit ratio" 
from v$rowcache 
where gets+getmisses &lt;&gt;0 
group by parameter, gets, getmisses;
</code></pre>
<h1 id="jian-kong-sga-zhong-gong-xiang-huan-cun-qu-de-ming-zhong-lu-ying-gai-xiao-yu-1">监控 SGA 中共享缓存区的命中率，应该小于1%</h1>
<pre><code class="language-shell">select sum(pins)	"Total Pins", sum(reloads)  "Total Reloads", 
sum(reloads)/sum(pins) *100 libcache 
from v$librarycache;                     

select sum(pinhits-reloads)/sum(pins) "hit radio",sum(reloads)/sum(pins) "reload percent" from v$librarycache;
</code></pre>
<h1 id="jian-kong-sga-zhong-zhong-zuo-ri-zhi-huan-cun-qu-de-ming-zhong-lu-ying-gai-xiao-yu-1">监控 SGA 中重做日志缓存区的命中率，应该小于1%</h1>
<pre><code class="language-shell">SELECT name, gets, misses, immediate_gets, immediate_misses, Decode(gets,0,0,	misses/gets*100) ratio1, 
Decode(immediate_gets+immediate_misses,0,0, immediate_misses/(immediate_gets+immediate_misses)*100) ratio2 
FROM v$latch WHERE name IN ('redo allocation	', 'redo copy');
</code></pre>
<h1 id="shu-ju-ku-biao-kong-jian-shi-yong-qing-kuang-jian-kong-zi-dian-guan-li-biao-kong-jian">数据库表空间使用情况监控(字典管理表空间)</h1>
<p>数据库运行了一段时间后，由于不断的在表空间上创建和删除对象，会在表空间上产生大量的碎片，DBA应该及时了解表空间的碎片和可用空间情况，以决定是否要对碎片进行整理或为表空间增加数据文件。以下为引用的内容：</p>
<pre><code class="language-shell">select tablespace_name, 
count(*) chunks , 
max(bytes/1024/1024) max_chunk 
from dba_free_space 
group by tablespace_name; 
</code></pre>
<p>上面的SQL列出了数据库中每个表空间的空闲块情况,如下所示:<br>
以下为引用的内容：</p>
<pre><code class="language-shell">TABLESPACE_NAME         CHUNKS      MAX_CHUNK 
--------------------  ----------   ---------- 
INDX                 1           57.9921875 
RBS                  3           490.992188 
RMAN_TS             1            16.515625 
SYSTEM               1           207.296875 
TEMP                 20          70.8046875 
TOOLS                1           11.8359375 
USERS                67          71.3671875
</code></pre>
<p>其中，CHUNKS列表示表空间中有多少可用的空闲块(每个空闲块是由一些连续的Oracle数据块组成)，如果这样的空闲块过多，比如平均到每个数据文件上超过了100个，那么该表空间的碎片状况就比较严重了，可以尝试用以下的SQL命令进行表空间相邻碎片的接合:</p>
<pre><code class="language-shell">alter tablespace 表空间名 coalesce;
</code></pre>
<p>然后再执行查看表空间碎片的SQL语句，看表空间的碎片有没有减少。如果没有效果，并且表空间的碎片已经严重影响到了数据库的运行，则考虑对该表空间进行重建。<br>
MAX_CHUNK列的结果是表空间上最大的可用块大小，如果该表空间上的对象所需分配的空间(NEXT值)大于可用块的大小的话，就会提示ORA-1652、ORA-1653、ORA-1654的错误信息，DBA应该及时对表空间的空间进行扩充，以避免这些错误发生。</p>
<h1 id="cha-kan-shu-ju-ku-de-lian-jie-qing-kuang">查看数据库的连接情况</h1>
<p>DBA要定时对数据库的连接情况进行检查，看与数据库建立的会话数目是不是正常，如果建立了过多的连接，会消耗数据库的资源。同时，对一些“挂死”的连接，可能会需要DBA手工进行清理。以下的SQL语句列出当前数据库建立的会话情况: 以下为引用的内容：</p>
<pre><code class="language-shell">select sid,serial#,username,program,machine,status 
from v$session; 
</code></pre>
<p>输出结果为: 以下为引用的内容：</p>
<pre><code class="language-shell">SID   SERIAL#    USERNAME    PROGRAM    MACHINE    STATUS 
----  -------  ---------- ----------- ---------------  -------- 
1       1                    ORACLE.EXE   WORK3      ACTIVE 
2       1                    ORACLE.EXE   WORK3      ACTIVE 
3       1                    ORACLE.EXE   WORK3      ACTIVE 
4       1                    ORACLE.EXE   WORK3      ACTIVE 
5       3                    ORACLE.EXE   WORK3      ACTIVE 
6       1                    ORACLE.EXE   WORK3      ACTIVE 
7       1                    ORACLE.EXE   WORK3      ACTIVE 
8       27        SYS        SQLPLUS.EXE  WORKGROUP\WORK3  ACTIVE 
11      5        DBSNMP    dbsnmp.exe   WORKGROUP\WORK3   INACTIVE
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>SID 会话(session)的ID号；</p>
</li>
<li class="lvl-2">
<p>SERIAL# 会话的序列号，和SID一起用来唯一标识一个会话；</p>
</li>
<li class="lvl-2">
<p>USERNAME 建立该会话的用户名；</p>
</li>
<li class="lvl-2">
<p>PROGRAM 这个会话是用什么工具连接到数据库的；</p>
</li>
<li class="lvl-2">
<p>STATUS 当前这个会话的状态，ACTIVE表示会话正在执行某些任务，INACTIVE表示当前会话没有执行任何操作。</p>
</li>
<li class="lvl-2">
<p>如果DBA要手工断开某个会话，则执行:</p>
</li>
</ul>
<pre><code class="language-shell">alter system kill session 'SID,SERIAL#'; 
</code></pre>
<p>注意，上例中SID为1到7(USERNAME列为空)的会话，是Oracle的后台进程，不要对这些会话进行任何操作。</p>
<h1 id="cha-kan-undo-hui-gun-lu">查看undo回滚率</h1>
<pre><code class="language-shell">SELECT NAME, VALUE FROM v$sysstat WHERE NAME IN ('user commits', 'transaction rollbacks');
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle SQL篇之常用视图与表汇总</title>
    <url>/2010/08/29/oracle_view_and_tables/</url>
    <content><![CDATA[<h1 id="dba">DBA_</h1>
<pre><code class="language-shell">DBA_2PC_NEIGHBORS                包含待处理事务进入连接和退出连接信息。
DBA_2PC_PENDING                 包含等待恢复的分布式事务的信息。
DBA_ALL_TABLES                 显示数据库中所有表（对象表和关系表）的描述。
DBA_ANALYZE_OBJECTS         列出分析对象。
DBA_ASSOCIATIONS                 列出用户定义的统计信息。
DBA_AUDIT_EXISTS                 列出由AUDIT NOT EXISTS(不存在审计)和AUDIT EXISTS（存在审
计）产生的审计跟踪条目。
DBA_AUDIT_OBJECT         包含系统中所有对象的审计跟踪记录。
DBA_AUDIT_SESSION         列出关于CONNECT（连接）和DISCONNECT（断开连接）的所有审讯跟踪记录。
DBA_AUDIT_STATEMENT 列出关于GRANT（授权）、REVOKE（取消）、AUDIT〔审计〕、NOAUDIT（不审计）和ALTER SYSTEM(改变系统)语句的审记跟踪记录。
DBA_AUDIT_TRAIL　        列出所有的审记跟踪条目。
DBA_BLOCKERS　        列出所有人等待一个会话持有的锁的所有会话，但并非它们自己在等待一个锁。
DBA_CATALOG         列出所有数据库表、视图、同义词和序列。
DBA_CLU_COLUMNS         列出表列到簇列的映射。
DBA_CLUSTER_HASH_EXPRESSIONS     列出所有簇的散列（hash）函数。
DBA_CLUSTERS         包含数据库中所有族的描述。
DBA_COL_COMMENS        列出所有表和视图列的注解。
DBA_COL_PRIVS        列出数据库中授予列的所有权限。
DBA_COLL_TYPES        显示数据库中所有命名的集合类型，如VARRAY（数组）、嵌套表、对象表，等等；
DBA_CONS_COLUMNS        包含在约束定义中的，可访问的列的信息
DBA_CONSTRAINTS        包含所有表上的约束定义。
DBA_CONTEXT        列出所有上下文名字空间的信息。
DBA_DATA_FILES        包含有关数据库文件的信息
DBA_DB_LINKS        列出数据库中的所有数据库链接。
DBA_DDL_LOCKS        列出数据库持有的所有DDL锁，及所有对一个DDL锁的未定请求。
DBA_DEPENDENCIES        列出对象之间的依赖性。在没有任何数据库链接时所创建的视图上的依赖性也是可用的。
DBA_DIM_ATTRIBUTES        代表维级和功能依赖的列之间的关系。维级列所在的表，必须与所依赖列所在的表相匹配。
DBA_DIM_CHILD_OF        代表在维中的一对维级之间的1：n的层次关系。
DBA_DIM_HIERARCHIES        代表一个维层次。
DBA_DIM_JOIN_KEY        代表两个维表之间的连接。这种连接通常在一个双亲维级列和一个子列之间指定。
DBA_DIM_LEVEL_KEY        代表一个维级的列。一个级中列的位置通过KEY_POSITION来指定。
DBA_DIM_LEVELS        代表一个维级。一个维级的所有列，必须来自于同一关系。
DBA_DIMENSIONS        代表维对象。
DBA_DIRECTORIES        提供数据库中所有目录对象的信息。
DBA_DML_LOCKS        列出数据库中持有的所有DML锁，和对一个DML锁的所有未决请求。
DBA_ERRORS         列出数据库中所有存储的对象的当前错误。
DBA_EXP_FILES        包含导出文件的描述。
DBA_EXP_OBJECTS        列出以增量方式导出的对象。
DBA_EXP_VERSION        包含最后导出会话的版本号。
DBA_EXTENTS        列出数据库中组成所有段的区。
DBA_FREE_SPACE        列出所有表空间中的空闲分区。
DBA_FREE_SPACE_COALESCED        包含表空间中合并空间的统计数据。
DBA_IND_COLUMNS        包含在所有表和簇中组成索引的列的描述。
DBA_IND_EXPRESSIONS        列出在所有表和簇中函数型索引的表达示。
DBA_IND_PARTITIONS        为每一个索引分区，描述分区级的分区信息、分区的存储参数和由ANALYZE决定的各种分区统计数据。
DBA_IND_SUBPARTITIONS                                为当前用户拥有的每一个索引子分区，描述分区级的分区信息、子分区的存储参数和由ANALYZE决定的各种分区统计数据。
DBA_INDEXES        包含数据库中所有索引的描述。
DBA_INDEXTYPE_OPERATORS                列出由索引类型支持的所有操作符。
DBA_INDEXTYPES        列出所有的索引类型。
DBA_JOBS        列出数据库中的所有作业。
DBA_JOBS_RUNNING        列出数据库中当前运行的所有作业。
DBA_LIBRARIES        列出数据库中所有的库。
DBA_LOB_PARTITIONS        显示包含在表中的用户可访问的LOB。
DBA_LOB_SUBPARTITIONS                 显示LOB数据子分区中的分区级属性。
DBA_LOBS         显示包含在所有表中的LOB.
DBA_LOCK_INTERNAL         包含每个被持有的锁或简易锁的一行信息，及锁或简易锁的每一个未决定请求的一行信息。
DBA_LOCKS         列出数据库中持有的所有锁或简易锁，及一个锁或简易锁的所有未决请求。
DBA_METHOD_PARAMS        包含数据库中类型的方法参数的描述。
DBA_METHOD_RESULTS        包含数据库中所有类型的方法结果的描述。
DBA_MVIEW_AGGREGATES                代表在聚集实例化视图的SELECT列表中出现的分组函数（聚集方法）。
DBA_MVIEW_ANALYSIS        代表潜在地支持查询重写，并有可用于应用程序分析的附加信息的实例化视图。这种视图包括任何引用远程表或者包括如SYSDATE或USER等非静态值的实例化视图。
DBA_MVIEW_DETAIL_RELATIONS                代表命名细节关系，这些关系或者在一个实例化视图的FROM列表中，或者直接通过FORM列表中的视图引用。在这个表中，没有表示实例化视图中的内嵌视图。
DBA_MVIEW_JOINS        在一个实例化视图的WHERE子句中，代表两个列之间的连接。
DBA_MVIEW_KEYS        代表命名细节关系，这些关系或者在一个实例化视图的FROM列表中，或者直接通过FORM列表中的视图引用。在这个表中，没有表示实例化视图中的内嵌视图。
DBA_NESTED_TABLES        显示包含在所有表中的嵌套表的描述。
DBA_OBJ_AUDIT_OPTS        列出一个用户所拥有的所有对象的审计选项。
DBA_OBJECT_SIZE         列出各类PL/SQL对象的、用字节数表示大小。
DBA_OBJECT_TABLES        显示数据库中所有对象表的描述。
DBA_OBJECTS         列出数据库中所有的对象。
DBA_OPANCILLARY         列出操作符连接的附加信息。
DBA_OPARGUMENTS        列出操作符连接的参数信息。
DBA_OPBINDINGS        列出操作符连接。
DBA_OPERATORS         列出操作符。
DBA_OUTLINE_HINTS         列出组成概要的提示集。
DBA_OUTLINES          列出有关概要的信息。
DBA_PART_COL_STATISTICS                 包含所有表分区的列统计数据和直方图信息。
DBA_PART_HISTOGRAMS        包含所有表分区上直方图的直方图数据（每个直方图的端点）。
DBA_PART_INDEXES        列出所有分区索引的对象级分区信息。
DBA_PART_KEY_COLUMNS        描述所有分区对象的分区关键字列。
DBA_PART_LOBS        描述分区LOB的表级信息，包括LOB数据分区的缺省属性。
DBA_PART_TABLES         列出所有分区表的对象级分区信息。
DBA_PARTIAL_DROP_TABS         描述部分删除的表。
DBA_PENDING_TRANSACTIONS         提供关于未完成事务（由于故障或协调器没有提交或回滚）的信息。
DBA_POLICIES         列出策略。
DBA_PRIV_AUDIT_OPTS         描述通过系统和由用户审计的当前系统权限。
DBA_PROFILES         显示所有启动文件及其限制
DBA_QUEUE_SCHEDULES        描述当前传播信息的方案。
DBA_QUEUE_TABLES        描述在数据库中建立的所有队列表中的队列的名称和类型。
DBA_QUEUE        描述数据库中每一个队列的操作特征。
DBA_RCHILD        列出任何刷新组中的所有子组。
DBA_REFRESH        列出所有刷新组。
DBA_REFRESH_CHILDREN        列出刷新组中所有对象。
DBA_REFS        描述数据库中所有表的对象类型列中的REF列和REF属性。
DBA_REGISTERED_SNAPSHOT_GROUPS        列出该场地的所有快照登记组。
DBA_REGISTERED_SNAPSHOT                                检索本地表的远程快照的信息。
DBA_REPCAT_REFRESH_TEMPLATES                与Advanced Replication(高级复制)一起使用。
DBA_REPCAT_TEMPLATES_PARMS                        与Advanced Replication(高级复制)一起使用。
DBA_REPCAT_TEMPLATES_SITES                        与Advanced Replication(高级复制)一起使用。
DBA_REPCAT_USER_AUTHORIZATIONS                与Advanced Replication(高级复制)一起使用。
DBA_REPCAT_USER_PARM_VALUES                与Advanced Replication(高级复制)一起使用。
DBA_REPCATLOG                                                与Advanced Replication(高级复制)一起使用。
DBA_REPCOLUMN                                                与Advanced Replication(高级复制)一起使用。
DBA_REPCOLUMN_GROUP                                        与Advanced Replication(高级复制)一起使用。
DBA_REPCONFLICT                                                与Advanced Replication(高级复制)一起使用。
DBA_REPDDL                                                与Advanced Replication(高级复制)一起使用。
DBA_REPGENERATED                                                与Advanced Replication(高级复制)一起使用。
DBA_REPGENOBJECTS                                                与Advanced Replication(高级复制)一起使用。
DBA_REPGROUP                                                与Advanced Replication(高级复制)一起使用。
DBA_REPGROUPED_COLUMN                                与Advanced Replication(高级复制)一起使用。
DBA_REPKEY_COLUMNS                                                与Advanced Replication(高级复制)一起使用。
DBA_REPOBJECT                                                与Advanced Replication(高级复制)一起使用。
DBA_REPPARAMETER_COLUMN                        与Advanced Replication(高级复制)一起使用。
DBA_REPPRIORITY                                                与Advanced Replication(高级复制)一起使用。
DBA_REPPRIORITY_GROUP                                与Advanced Replication(高级复制)一起使用。
DBA_REPPROP                                                与Advanced Replication(高级复制)一起使用。
DBA_REPPESOL_STATS_CONTROL                        与Advanced Replication(高级复制)一起使用。
DBA_REPRESOLUTION                                                与Advanced Replication(高级复制)一起使用。
DBA_REPRESOLUTION_METHOD                        与Advanced Replication(高级复制)一起使用。
DBA_REPSITES                                                与Advanced Replication(高级复制)一起使用。
DBA_RGROUP                                                列出所有刷新组。
DBA_ROLE_PRIIVS                                                     列出授予用户和角色的角色
DBA_ROLES                                                    列出数据库中存在的所有角色
DBA_ROLLBACK_SEGS                                                   包含回滚段的描述
DBA_RSRC_CONSUMER_GROUP_PRIVS           列出所有已授权的资源消费组、用户和角色。
DBA_RSRC_CONSUMER_GROUPS                    列出数据库中存在的所有资源消费组。
DBA_RSRC_MANAGER_SYSTEM_PRIVS           列出所有已授予属于资源管理员系统权限的用户
和角色。
DBA_RSRC_PLAN_DIRECTIVES                            列出数据库中存在的所有资源计划的指示。
DBA_RSRC_PLANS                                                     列出数据库中存在的所有资源计划。
DBA_RULESETS                                                     列出规则集信息。
DBA_SEGMENTS                                                     包含分配级所有数据库段的存储信息。
DBA_SEOUENCES                                                     包含数据库中所有序列的描述。
DBA_SNAPSHOT_LOG_FILTER_COLS    列出记录在快照日志上的所有过滤列（不包括PK列）
DBA_SNAPSHOT_LOGS                                    列出数据库中所有的快照日志。
DBA_SNAPSHOT_REFRESH_TIMES                   列出快照刷新次数。
DBA_SNAPSHOTS                                                    列出数据库中所有的快照。
DBA_SOURCE                                                   包含数据库中所有存储对象的来源。
DBA_STMT_AUDIT_OPTS                                   包含的信息为：描述通过系统并由用户审计的当前
系统审计选项。
DBA_SUBPART_COL_STATISTICS                   列出表子分区的列统计数据和直方图信息。
DBA_SUBPART_HISTOGRAMS           列出表子分区中直方图的实际数据（每个直方图的端点）。
DBA_SUBPART_KEY_COLUMNS   列出用Composite  Range(复合排列)或HASH方法进行分区
的表（和表上的本地索引）的子分区关键字列。
DBA_SYNONYMS                                   列出数据库中所有同义词
DBA_SYS_PRIVS                                   列出授予用户和角色的系统权限。
DBA_TAB_COL_STATISTICS                   包含在DBA_TAB_COLUMNS视图中的列统计数据和直方图信息。
DBA_ TAB_COLUMNS                                   包含所有表、视图和簇的描述列的信息。
DBA_TAB_COMMENTS                                  包含对数据库中所有表和视图的注解。
DBA_TAB_HISTOGRAMS                   列出所有表中列的直方图。
DBA_TAB_PARTITIONS                                  对每一个表分区，描述它的分区级分区信息、分区的存储参数，和由
ANALYZE                        决定的各种分区统计数据。
DBA_TAB_PRIVS                          列出数据库中所有授予对象的授权。
DBA_TAB_SUBPARTITIONS   对每一个表的子分区，描述它的名称、表的名称和它所属的分区，
以及它的存储属性。
DBA_TABLES                          包含数据库中所有关系表的描述。
DBA_TABLESPACES                          包含所有表空间的描述
DBA_TEMP_FILES                          包含数据库临时文件的信息。
DBA_TRIGGER_COLS                          列出所有触发器中列的用法。
DBA_TRIGGERS                          列出数据库中所有触发器。
DBA_TS_QUOTAS                          列出所有用户的表空间限额。
DBA_TYPE_ATTRS                           显示数据库中类型的属性。
DBA_TYPE_METHODS                          描述数据库中所有类型的方法。
DBA_TYPES                           显示数据库中所有的抽象数据类型。
DBA_UNUSED_COL_TABS          包含对所有具有未使用列的表的描述。
DBA_UPDATABLE_COLUMNS  包含对可在一个连接视图中，由数据库管理员更新的列的描述。
DBA_USERS                          列出数据库中所有用户的信息。
DBA_USTATS                           包含当前用户的信息。
DBA_VARRAYS                           列出用户可以访问的视图的文本。
DBA_VIEWS                            包含数据库中所有视图的文本。
DBA_WAITERS                           列出所有正在等待一个锁的会话，以及列出正在阻止它们获得该锁的会话。
</code></pre>
<h1 id="v-dong-tai-shi-tu">$(v$动态视图)</h1>
<pre><code class="language-shell">V$ACCESS           显示当前被锁定的数据库中的对象及正在访问它们的会话。
V$ACTIVE_INSTANCES  为当前安装的数据库中出现的所有实例建立从实例名到实例号码的
映射
V$AQ                  描述当前数据库中队列的统计量。
V$ARCHIVE           包含归档所需的重做日志文件中的信息。每一行提供了一个线程所需的信息。这些信息在V$LOG中也是可用的。Oracle建议你使用V$LOG.
V$ARCHIVE_DEST          描述当前实例的所有归档日志目的文件及它们的当前值、模式和状态。
V$ARCHIVED_LOG          显示控制文件中的归档日志信息，包括归档日志名。在联重做日志文件成功地归档或清除（如果日志被清除，名字列将为NULL）后，一条归档日志记录被插入。如果这个日志被归档两次，那么就将有两条具有相同THREAD#，SEQUENCE#，FIRST_CHANG#值的归档日志记录，但它们的名字不同。当一个归档日志从一个备份集或一个副本中被恢复时，一个归档日志记录也将被插入。
V$ARCHIVE_PROCESSES   为一个实例提供关于不同ARCH进程状态的信息。
V$BACKUP          显示所有联机数据文件的备份状态。
V$BACKUP_ASYNC_IO   从控制文件中显示备份集的信息。在这个备份集成功完成后，一个
备份集记录将被插入。
V$BACKUP_CORRUPTION    从控制文件中显示数据文件备份中有关损坏的信息。注意在控
制文件和归档日志备份文件中损坏是不能容忍的
V$BACKUP_DATAFILE   从控制文件中显示备份数据文件和备份控制文件的信息。
V$BACKUP_DEVICE                           显示关于支持备份设备的信息。如果一个设备类型不支持指名的设备，那么将为这个设备类型返回一个带有设备类型和NULL设备名的行。如果一个设备类型支持指名的设备，那么将为每一个这种类型的可用设备返回一行。特殊的设备类型DISK不会通过这个视图返回，因为它总是可用的 。
V$BACKUP_PIECE  从控制文件中显示备份块的信息。每一个备份集由一个更多个备份块组
成。
V$BACKUP_REDOLOG          从控制文件中显示关于备份集中归档日志的信息。注意联机的重做日
志文件不能够被直接备份。它们必须首先被存储到磁盘上然后再进行
备份。一个归档日志备份集能包含一个或多个归档日志。
V$BACKUP_SET           从控制文件中显示备份集的信息。在备份集成功完成后，一个备份集记录将被插入。
V$BACKUP_SYNC_IO    从控制文件中显示备份集的信息。在备份集成功完成后，一个备份
集记录将被插入。
V$BGPROCESS          描述后台进程。
V$BH          这是一个并行服务器视图。这个视图为系统全局区中的每一个缓冲区给出了状态和探查次数。
V$BUFFER_POOL          显示关于这个实例所有可用缓冲池的信息。这个“集合数”属于LRU简易锁集的数目。
V$BUFFER_POOL_STATISTICS  显示关于这个实例所有可用缓冲池的信息。这个“集合数”
属于LRU简易锁集的数目。
V$CACHE          这是一个并行服务器视图。这个视图包含当前实例的SGA中的每一个块的头部信息，这个实例是与一个特殊数据库对象相关联的。
V$CACHE_LOCK           这是一个并行服务器的视图。除了特殊平台锁管理器标识符不同外，
V$CACHE_LOCK        与V$CACHE非常相似。如果这个特殊平台锁管理器为监视当前正发生的PCM锁操作提供了工具，那么这些信息可能是有用的。
V$CIRCUIT          包含关于虚电路的信息，这个虚电路是用户通过调度程序和服务器到数据库的所有连接。
V$CLASS_PING          显示每一个块类中被探查块的数目。用这个视图可以比较不同类的块竞争。
V$COMPATIBILITY          显示数据库实例使用中的特征，可能阻止系统性能下降到先前的版本。这是这些信息的动态（SGA）版本，它不可能反映出所用过的另外一些实例的特征，并可能包含暂时的不兼容性（如UNDO段），不过这将在数据库完全的关闭掉后不复存在。
V$COMPATSEG          列出数据库使用中的永久性的特征，这些特征将会阻止数据库回到早期的版本中去。
V$CONTEXT          列出当前对话的设置属性。
V$CONTROLFILE           列出控制文件的名字。
V$CONTROLFILE_RECORD_SECTION  显示关于控制文件记录部分的信息。
V$COPY_CORRUPTION  显示关于控制文件中数据文件副本损坏的信息。
V$DATABASE          包含控制文件中数据库信息。
V$DATAFILE           包含控制文件中数据库文件的信息。
V$DATAFILE_COPY          显示控制文件中数据文件副本的信息。
V$DATAFILE_HEADER  显示数据文件头部的数据文件信息。
V$DBFILE          列出组成数据库中的所有数据文件。这个视图是为历史兼容性保留的，我们建议用V$DATAFILE来代替。
V$DBLINK          描述由发布对V$DBLINK查询的会话所打开的所有数据库链接（用
IN_TRANSACTION=YES链接）。这些数据库链接必须在关闭前被提交或滚回。
V$DB_OBJECT_CACHE  显示缓存在库高速缓存中的数据库对象。这些对象包括表、索引、簇、
同义词定义、PL/SQL过程和包及触发器。
V$DB_PIPES          显示当前数据库中的管道。
V$DELETED_OBJECT   显示控制文件中被删除归档日志、数据文件副本和备份块的信息。这
个视图的唯一目的是优化恢复目录的再同步操作。当一个归档日志、数据文件副本或备份块被删除时，相应的记录将被做上删除标志。
V$DISPATCHER          提供调度进程的信息。
V$ DISPATCHER_RATE  为调度进程提供速率统计量。
V$DLM_ALL_LOCKS          这是一个并行服务器视图。V$DLM_ALL_LOCKS列出当前所有锁的信息，这些是锁管理器已知的被阻塞或阻塞其他对象的锁信息。
V$DLM_CONVERT_LOCAL  显示本地锁转换操作所消耗的时间。
V$DLM_CONVERT_REMOTE  显示远程锁转换操作所消耗的时间。
V$DLM_LOCKS                 这是一个并行服务器视图。V$DLM_ALL_LOCKS 列出当前所有锁的信息，这些是锁管理器已知的被阻塞或阻塞其他对象的锁信息。
V$DLM_MISC          显示多种DLM统计量。
V$DLM_RESS          这是一个并行服务器的视图，它显示了当前锁管理器已知的全部资源的信息。
V$ENABLEDPRIVS           显示被授予的权限。这些权限可以在SYS.SYSTEM_PRIVILEGES_MAP这个表中找到。
V$ENQUEUE_LOCK           显示排队状态对象所拥有的全部锁。这个视图中的列等同于V$LOCK
中的列。更多的信息参见V$LOCK.
V$EVENT_NAME           包含等待事件的信息。
V$EXECUTION           显示并行执行中的信息。
V$FALSE_PING           这是一个并行服务器视图。这个视图显示可能得到探查失败的缓冲区，探查被同样锁保护的缓冲区10次以上，如像另一个探查10次以上的缓冲区。被鉴别为获得探查失败信息的缓冲区能够被重新映射到GC_FILES_TO_LOCKS 中以减少锁的冲突。
V$FAST_START_SERVERS                  提供关于执行并行事务恢复的所有从属恢复操作的信息。
V$FAST_START_TRANSACTIONS          包含关于Oracle 恢复中的事务进展信息。
V$FILE_PING           显示每一个数据文件被探查的块数目。反过来，这些信息能被用来决定对一个存在的数据文件访问方式，同时也可以决定从数据文件块到PCM锁的新的映射。
V$FILESTAT           包含文件关于读/写统计量的信息
V$FIXED_TABLE           显示数据库中所有动态性能表、视图和导出表。一些V$表（如
V$ROLLNAME）涉及到了真正的表，没有被列出来。
V$FIXED_VIEW_DEFINITION    包含所有固定视图的定义（以V$开头的视图）。应谨慎地使
用这个表。Oracle 总是想从版本到版本保持固定视图的行为，但是固定视图的定义能够在没有通知的情况下改变。用这些定义通过使用动态性能表中的索引列可以优化你的查询。
V$GLOBAL_BLOCKED_LOCKS  显示全局块锁。
V$GLOBAL_TRANSACTION            显示当前激活的全局事务的信息。
V$HS_AGENT           标识当前运行在一个给定的主机上的HS代理的集合，每一个代理进程用一行表示。
V$HS_SESSION          标识当前为一个Oracle 服务器打开的HS会话集。
V$INDEXED_FIXED_COLUMN   显示建立索引的动态性能表中的列（X$表），X$表能够在没
有通知的情况下改变。使用这个视图仅仅在写查询方面比固定视图（V$视图）的效率要高。
V$INSTANCE           显示当前实例的状态。这个V$INSTANCE 版本同早期的V$INSTANCE 版本不兼容。
V$INSTANCE_RECOVERY   用来监视执行用户指定恢复读次数的限制机制。
V$LATCH         为非双亲简易锁列出统计表，同时为双亲简易锁列出总计统计。就是说，每一个双亲简易锁的统计量包括它的每一个子简易锁的计算值。
V$LATCHHOLDER           包含当前简易锁持有者的信息。
V$LATCHNAME           包含关于显示在V$LATCH中的简易锁的解码简易锁名字的信息。
V$LATCHNAME        中的行与V$LATCH中的行有一一对应的关系。
V$LATCH_CHILDREN   包含关于子简易锁的统计量。这个视图包括V$LATCH中的所有列和
一个CHILD#列。注意如果子简易锁LATCH#列相匹配，那么它们将具有相同的双亲。
V$LATCH_MISSES         包含试图获得一个简易锁失败的统计量。
V$LATCH_PARENT           包含关于双亲简易锁的统计量。V$LATCH_PARENT中的列与V$LATCH中的列是相等的。
V$LIBRARYCACHE          包含关于高速缓存性能和活动的统计量。
V$LICENSE           包含关于许可证限制的信息。
V$LOADCSTAT           包含在一个直接装载执行过程中所编译的SQL*Loader统计量。这些统计量适用于整个的加载。既然装载数据和查询不能在同一时间进行，那么，任何对这个表的SELECT操作都将会导致”no  rows  retured”(没有行返回)
V$LOADTSTAT          包含在一个直接装载执行过程中所编译的SQL*Loader统计量。这些统计量适用于当前的表。既然装载数据和查询不能在同一时间进行，那么，任何对这个表的SELECT操作都将会导致”no  rows  retured”(没有行返回)
V$LOCK           列出当前ORACLE服务器所持有的锁和对一个锁或简易锁的未决请求。
V$LOCK_ACTIVITY    这是一个并行服务器视图。它显示当前实例的DLM锁操作活动，每
一行对应着锁操作的类型。
V$LOCK_ELEMENT           这是一个并行服务器视图。每一个被缓冲高速缓存使用的PCM锁在
V$LOCK_ELEMENT中都有一个条目。与一个锁元素相对应的PCM锁的名字是（‘BL’，indx,class）。
V$LOCKED_OBJECT                                   列出在这个系统中每一个事务所获得的全部锁。
V$LOCKS_WITH_COLLISIONS   这是一个并行服务器视图。用这个视图可以查找保护多重锁
缓冲区的锁，这些缓冲区的每一个至少被强制性的读或写达十次以上。那些正经历着探查失败的缓冲区，主要是由于被映射到同样的锁上。
V$LOG                   包含控制文件中的日志文件信息。
V$LOGFILE            包含重做日志文件的信息。
V$LOGHIST            包含控制文件中的日志历史信息。这个视图是为历史兼容性保留的。这里建议使用V$LOG_HISTORY来代替它。
V$LOGMNR_CONTENTS           包含日志历史信息。
V$LOGMNR_DICTIONARY   包含日志历史信息。
V$LOGMNR_LOGS                          包含日志信息。
V$LOGMNR_PARAMETERS   包含日志信息。
V$LOG_HISTORY                           包含控制文件中的日志历史信息。
V$MLS_PARAMETERS           这是一个ORACLE委托服务器（Trusted Oracle Server）视图，这个视图列出ORACLE指定委托服务器的初始化参数。更多的信息，可以在你的ORACLE委托文件中查到。
V$MTS           包含调节多线程的服务器的信息。
V$MYSTAT        包含当前会话的统计量。
V$NLS_PARAMETERS   包含当前NLS参数的值。
V$NLS_VALID_VALUES    列出NLS参数所有有效的信息。
V$OBJECT_DEPENDENCY   能够通过当前装戴在共享池中的包、过程或游标来决定依赖于那
一个对象。例如，与V$SESSIONV和$SQL一起，它能被用来决定在SQL语句中使用哪一个正在被用户执行的表。要知道更多的信息，请见V$SESSION和V$SQL
V$OBSOLETE_PARAMETER   列出陈旧的参数。只要有某一值为TRUE，你就应该检查为什
么。
V$OFFLINE_CURSOR    显示控制文件中数据文件的脱机信息。
V$OPEN_CURSOR                   列出每一个用户会话当前打开的和解析的游标。
V$OPTION            列出用ORACLE服务器安装的选项。
V$PARALLEL_DEGREE_LIMIT_MTH    显示所有有效的并行度限制资源分配的方法。
V$PARAMETER                   列出关于初始化参数的信息。
V$PING            这是一个并行服务器视图。除了只显示至少被探查一次的块有所不同外，V$PING视图与V$CACHE视图完全是一样的，这个视图包含当前实例的SGA中每一块的块首部信息，这个实例是与一个特定的数据库对象相关联的。
V$PQ_SESSTAT              列出并行查询会话的统计信息。注意：这个视图在未来的版本中将会成为过的 。
V$PQ_SLAVE            列出一个实例上每个活动并行执行服务器的统计量。注意：这个视图在未来的版本中将会过时而被一个新的称做V$PX_PROCESS的视图所代替。
V$PQ_SYSSTAT            列出并行查询的系统统计量。注意：这个视图在未来的版本中将会过时而被一个新的称做V$PX_PROCESS_SYSSTAT的视图所代替。
V$PQ_TQSTAT            包含并行执行操作上的统计量。这些统计量是在完成了查询后编辑的，并且仅在会话期保持。它显示在执行树的每一级阶段，通过每一个并行运行服务器处理的行数。这个视图能够帮助在一个查询执行中测定不平衡的问题。注意：这个视图在未来的版本中将称做V$PX_TQSTAT视图。
V$PROCESS            包含关于当前活动进程的信息。当LATCHWAIT列显示一个进程正等待什么样的简易锁时，LATCHSPIN列就显示一个进程正围绕什么样简易锁运行。在多处理器机器上，ORACLE进程在等待一个简易锁之前是围绕它运行的。
V$PROXY_ARCHIVEDLOG    包含归档日志备份文件的描述信息，这些备份文件带有一个称
为Proxy副本的新特征。每一个行代表一个归档日志的备份信息。
V$PROXY_DATAFILE                   包含数据文件和控制文件备份的描述信息，这个备份文件带了一个称
为Proxy副本的新特征。每一行代表一个数据库文件的备份信息。
V$PWFILE_USERS                    列出被授予SYSDBA和SYSOPER权限的用户，这些权限就象从
password文件中衍生而来一样。
V$PX_PROCESS            包含正运行并行操作的会话的信息。
V$PX_PROCESS_SYSSTAT   包含正运行并行操作的会话的信息。
V$PX_SESSION            包含正运行并行操作的会话的信息。
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>通过数据字典可查询更详细的视图数据</p>
</li>
</ul>
<pre><code class="language-shell">SQL&gt; desc dictionary
 名称                                      是否为空? 类型
 ----------------------------------------- -------- ----------------------------
 TABLE_NAME                                         VARCHAR2(30)
 COMMENTS                                           VARCHAR2(4000)

SQL&gt; select * from dictionary;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle SQL篇之其他</title>
    <url>/2010/09/09/oracle_other_kb/</url>
    <content><![CDATA[<h1 id="sui-ji-shu-han-shu">随机数函数</h1>
<pre><code class="language-shell">dbms_random.value(100,200)
</code></pre>
<h1 id="cha-kan-cuo-wu-ma">查看错误码</h1>
<p>oracle错误码包括ORA、TNS、EXP、IMP/RMAN等，查看这里错误码含义，命令格式如下：</p>
<pre><code class="language-shell">oerr ora 错误码；
oerr tns 错误码
oerr exp错误码
oerr imp错误码
oerr rman 错误码
</code></pre>
<h1 id="zan-ting-han-shu">暂停函数</h1>
<pre><code class="language-shell">dbms_lock.sleep(5);
</code></pre>
<p>功能描述：</p>
<p>保存预定信息，比如说订票，但是超过一定时间（比如说15分钟），还没付费这个预定就失效了，也就是说把订单信息从表里删除普通数据库用户是没有这个权限的，需要dba赋予权限后才能调用dbms_lock包，如下：</p>
<pre><code class="language-shell">grant execute on dbms_lock to username;
</code></pre>
<h1 id="oracle-zhu-shi">oracle注释</h1>
<p>oracle注释支持两种，如下：</p>
<p>1、/***test***/</p>
<p>2、–</p>
<p>其中，对于/**/这个注释对中，在SQL中仅有的注释对并不被忽略，如下：</p>
<pre><code class="language-shell">SQL&gt; /*commit*/
DBA_2PC_NEIGHBORS
information about incoming and outgoing connections for pending transactions

DBA_2PC_PENDING
info about distributed transactions awaiting recovery

DBA_ADDM_FDG_BREAKDOWN


DBA_ADDM_FINDINGS


DBA_ADDM_INSTANCES


DBA_ADDM_SYSTEM_DIRECTIVES


DBA_ADDM_TASKS


DBA_ADDM_TASK_DIRECTIVES


DBA_ADVISOR_ACTIONS



已选择9行。
</code></pre>
<p>所以，在sql命令中，尽可能避免使用/**/纯粹注释对，可在该注释对中增加一些其他信息，则可避免命令被解析，如下：</p>
<pre><code class="language-shell">SQL&gt; /****commit***/
SQL&gt;
</code></pre>
<p>即：/*test*/  被SQL解析，而/**test**/不会被解析。</p>
<pre><code class="language-shell">SQL&gt; /*test*/ 
DBA_2PC_NEIGHBORS
information about incoming and outgoing connections for pending transactions

DBA_2PC_PENDING
info about distributed transactions awaiting recovery

DBA_ADDM_FDG_BREAKDOWN


DBA_ADDM_FINDINGS


DBA_ADDM_INSTANCES


DBA_ADDM_SYSTEM_DIRECTIVES


DBA_ADDM_TASKS


DBA_ADDM_TASK_DIRECTIVES


DBA_ADVISOR_ACTIONS



已选择9行。
SQL&gt; /**test**/
SQL&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 一条SQL命令的生命周期</title>
    <url>/2010/09/13/oracle_command_life_span/</url>
    <content><![CDATA[<p>手动绘制了一条图，直接上图：</p>
<img class="shadow" src="/img/in-post/oracle_sql_command_life_span.GIF" width="1200">
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle导入导出之数据泵(expdp/impdp)</title>
    <url>/2010/09/22/oracle_expdp_impdp/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>数据泵（data pump）是oracle 10g新增的功能。</p>
<p>工具EXPDP将数据库对象的元数据（对象结构）或数据导出到转储文件中；而数据泵导入则是使用工具IMPDP将转储文件中的元数据及其数据导入到Oracle数据库中。</p>
<p>EXPDP可以导出表、导出用户模式、表空间和全数据库4种方式；相应的，impdp可以导入表、导出用户模式、表空间和全数据库。</p>
<p>expdp和impdp的使用，类似与exp和dmp</p>
<pre><code class="language-shell">expdp help=y
impdp help=y
</code></pre>
<pre><code class="language-shell">oracle@GW_8:~&gt; expdp help=y

Export: Release 11.1.0.7.0 - 64bit Production on 星期五, 01 2月, 2013 9:31:19

Copyright (c) 2003, 2007, Oracle.  All rights reserved.


数据泵导出实用程序提供了一种用于在 Oracle 数据库之间传输
数据对象的机制。该实用程序可以使用以下命令进行调用:

   示例: expdp scott/tiger DIRECTORY=dmpdir DUMPFILE=scott.dmp

您可以控制导出的运行方式。具体方法是: 在 'expdp' 命令后输入 
各种参数。要指定各参数, 请使用关键字:

   格式:  expdp KEYWORD=value 或 KEYWORD=(value1,value2,...,valueN)
   示例: expdp scott/tiger DUMPFILE=scott.dmp DIRECTORY=dmpdir SCHEMAS=scott
               或 TABLES=(T1:P1,T1:P2), 如果 T1 是分区表

USERID 必须是命令行中的第一个参数。

关键字               说明 (默认)
------------------------------------------------------------------------------
ATTACH                连接到现有作业, 例如 ATTACH [=作业名]。
COMPRESSION           减小转储文件内容的大小, 其中有效关键字
                      值为: ALL, (METADATA_ONLY), DATA_ONLY 和 NONE。
CONTENT               指定要卸载的数据, 其中有效关键字
                      值为: (ALL), DATA_ONLY 和 METADATA_ONLY。
DATA_OPTIONS          数据层标记, 其中唯一有效的值为:
                      使用 CLOB 格式的 XML_CLOBS-write XML 数据类型
DIRECTORY             供转储文件和日志文件使用的目录对象。
DUMPFILE              目标转储文件 (expdat.dmp) 的列表,
                      例如 DUMPFILE=scott1.dmp, scott2.dmp, dmpdir:scott3.dmp。
ENCRYPTION            加密部分或全部转储文件, 其中有效关键字
                      值为: ALL, DATA_ONLY, METADATA_ONLY,
                      ENCRYPTED_COLUMNS_ONLY 或 NONE。
ENCRYPTION_ALGORITHM  指定应如何完成加密, 其中有效
                      关键字值为: (AES128), AES192 和 AES256。
ENCRYPTION_MODE       生成加密密钥的方法, 其中有效关键字
                      值为: DUAL, PASSWORD 和 (TRANSPARENT)。
ENCRYPTION_PASSWORD   用于创建加密列数据的口令关键字。
ESTIMATE              计算作业估计值, 其中有效关键字
                      值为: (BLOCKS) 和 STATISTICS。
ESTIMATE_ONLY         在不执行导出的情况下计算作业估计值。
EXCLUDE               排除特定的对象类型, 例如 EXCLUDE=TABLE:EMP。
FILESIZE              以字节为单位指定每个转储文件的大小。
FLASHBACK_SCN         用于将会话快照设置回以前状态的 SCN。
FLASHBACK_TIME        用于获取最接近指定时间的 SCN 的时间。
FULL                  导出整个数据库 (N)。
HELP                  显示帮助消息 (N)。
INCLUDE               包括特定的对象类型, 例如 INCLUDE=TABLE_DATA。
JOB_NAME              要创建的导出作业的名称。
LOGFILE               日志文件名 (export.log)。
NETWORK_LINK          链接到源系统的远程数据库的名称。
NOLOGFILE             不写入日志文件 (N)。
PARALLEL              更改当前作业的活动 worker 的数目。
PARFILE               指定参数文件。
QUERY                 用于导出表的子集的谓词子句。
REMAP_DATA            指定数据转换函数,
                      例如 REMAP_DATA=EMP.EMPNO:REMAPPKG.EMPNO。
REUSE_DUMPFILES       覆盖目标转储文件 (如果文件存在) (N)。
SAMPLE                要导出的数据的百分比; 
SCHEMAS               要导出的方案的列表 (登录方案)。
STATUS                在默认值 (0) 将显示可用时的新状态的情况下,
                      要监视的频率 (以秒计) 作业状态。
TABLES                标识要导出的表的列表 - 只有一个方案。
TABLESPACES           标识要导出的表空间的列表。
TRANSPORTABLE         指定是否可以使用可传输方法, 其中
                      有效关键字值为: ALWAYS, (NEVER)。
TRANSPORT_FULL_CHECK  验证所有表的存储段 (N)。
TRANSPORT_TABLESPACES 要从中卸载元数据的表空间的列表。
VERSION               要导出的对象的版本, 其中有效关键字为:
                      (COMPATIBLE), LATEST 或任何有效的数据库版本。

下列命令在交互模式下有效。
注: 允许使用缩写

命令               说明
------------------------------------------------------------------------------
ADD_FILE              向转储文件集中添加转储文件。
CONTINUE_CLIENT       返回到记录模式。如果处于空闲状态, 将重新启动作业。
EXIT_CLIENT           退出客户机会话并使作业处于运行状态。
FILESIZE              后续 ADD_FILE 命令的默认文件大小 (字节)。
HELP                  总结交互命令。
KILL_JOB              分离和删除作业。
PARALLEL              更改当前作业的活动 worker 的数目。
                      PARALLEL=&lt;worker 的数目&gt;。
REUSE_DUMPFILES       覆盖目标转储文件 (如果文件存在) (N)。
START_JOB             启动/恢复当前作业。
STATUS                在默认值 (0) 将显示可用时的新状态的情况下,
                      要监视的频率 (以秒计) 作业状态。
                      STATUS[=interval]
STOP_JOB              顺序关闭执行的作业并退出客户机。
                      STOP_JOB=IMMEDIATE 将立即关闭
                      数据泵作业。
</code></pre>
<pre><code class="language-shell">oracle@GW_8:~&gt; impdp help=y

Import: Release 11.1.0.7.0 - 64bit Production on 星期五, 01 2月, 2013 10:52:27

Copyright (c) 2003, 2007, Oracle.  All rights reserved.


数据泵导入实用程序提供了一种用于在 Oracle 数据库之间传输
数据对象的机制。该实用程序可以使用以下命令进行调用:

     示例: impdp scott/tiger DIRECTORY=dmpdir DUMPFILE=scott.dmp

您可以控制导入的运行方式。具体方法是: 在 'impdp' 命令后输入
各种参数。要指定各参数, 请使用关键字:

     格式:  impdp KEYWORD=value 或 KEYWORD=(value1,value2,...,valueN)
     示例: impdp scott/tiger DIRECTORY=dmpdir DUMPFILE=scott.dmp

USERID 必须是命令行中的第一个参数。

关键字               说明 (默认)
------------------------------------------------------------------------------
ATTACH                连接到现有作业, 例如 ATTACH [=作业名]。
CONTENT               指定要加载的数据, 其中有效关键字为:
                      (ALL), DATA_ONLY 和 METADATA_ONLY。
DATA_OPTIONS          数据层标记, 其中唯一有效的值为:
                      SKIP_CONSTRAINT_ERRORS - 约束条件错误不严重。
DIRECTORY             供转储文件, 日志文件和 sql 文件使用的目录对象。
DUMPFILE              要从 (expdat.dmp) 中导入的转储文件的列表,
                      例如 DUMPFILE=scott1.dmp, scott2.dmp, dmpdir:scott3.dmp。
ENCRYPTION_PASSWORD   用于访问加密列数据的口令关键字。
                      此参数对网络导入作业无效。
ESTIMATE              计算作业估计值, 其中有效关键字为:
                      (BLOCKS) 和 STATISTICS。
EXCLUDE               排除特定的对象类型, 例如 EXCLUDE=TABLE:EMP。
FLASHBACK_SCN         用于将会话快照设置回以前状态的 SCN。
FLASHBACK_TIME        用于获取最接近指定时间的 SCN 的时间。
FULL                  从源导入全部对象 (Y)。
HELP                  显示帮助消息 (N)。
INCLUDE               包括特定的对象类型, 例如 INCLUDE=TABLE_DATA。
JOB_NAME              要创建的导入作业的名称。
LOGFILE               日志文件名 (import.log)。
NETWORK_LINK          链接到源系统的远程数据库的名称。
NOLOGFILE             不写入日志文件。
PARALLEL              更改当前作业的活动 worker 的数目。
PARFILE               指定参数文件。
PARTITION_OPTIONS     指定应如何转换分区, 其中
                      有效关键字为: DEPARTITION, MERGE 和 (NONE)
QUERY                 用于导入表的子集的谓词子句。
REMAP_DATA            指定数据转换函数,
                      例如 REMAP_DATA=EMP.EMPNO:REMAPPKG.EMPNO
REMAP_DATAFILE        在所有 DDL 语句中重新定义数据文件引用。
REMAP_SCHEMA          将一个方案中的对象加载到另一个方案。
REMAP_TABLE           表名重新映射到另一个表,
                      例如 REMAP_TABLE=EMP.EMPNO:REMAPPKG.EMPNO。
REMAP_TABLESPACE      将表空间对象重新映射到另一个表空间。
REUSE_DATAFILES       如果表空间已存在, 则将其初始化 (N)。
SCHEMAS               要导入的方案的列表。
SKIP_UNUSABLE_INDEXES 跳过设置为无用索引状态的索引。
SQLFILE               将所有的 SQL DDL 写入指定的文件。
STATUS                在默认值 (0) 将显示可用时的新状态的情况下,
                      要监视的频率 (以秒计) 作业状态。
STREAMS_CONFIGURATION 启用流元数据的加载
TABLE_EXISTS_ACTION   导入对象已存在时执行的操作。
                      有效关键字: (SKIP), APPEND, REPLACE 和 TRUNCATE。
TABLES                标识要导入的表的列表。
TABLESPACES           标识要导入的表空间的列表。
TRANSFORM             要应用于适用对象的元数据转换。
                      有效转换关键字为: SEGMENT_ATTRIBUTES, STORAGE,
                      OID 和 PCTSPACE。
TRANSPORTABLE         用于选择可传输数据移动的选项。
                      有效关键字为: ALWAYS 和 (NEVER)。
                      仅在 NETWORK_LINK 模式导入操作中有效。
TRANSPORT_DATAFILES   按可传输模式导入的数据文件的列表。
TRANSPORT_FULL_CHECK  验证所有表的存储段 (N)。
TRANSPORT_TABLESPACES 要从中加载元数据的表空间的列表。
                      仅在 NETWORK_LINK 模式导入操作中有效。
VERSION               要导出的对象的版本, 其中有效关键字为:
                      (COMPATIBLE), LATEST 或任何有效的数据库版本。
                      仅对 NETWORK_LINK 和 SQLFILE 有效。

下列命令在交互模式下有效。
注: 允许使用缩写

命令               说明 (默认)
------------------------------------------------------------------------------
CONTINUE_CLIENT       返回到记录模式。如果处于空闲状态, 将重新启动作业。
EXIT_CLIENT           退出客户机会话并使作业处于运行状态。
HELP                  总结交互命令。
KILL_JOB              分离和删除作业。
PARALLEL              更改当前作业的活动 worker 的数目。
                      PARALLEL=&lt;worker 的数目&gt;。
START_JOB             启动/恢复当前作业。
                      START_JOB=SKIP_CURRENT 在开始作业之前将跳过
                      作业停止时执行的任意操作。 
STATUS                在默认值 (0) 将显示可用时的新状态的情况下,
                      要监视的频率 (以秒计) 作业状态。
                      STATUS[=interval]
STOP_JOB              顺序关闭执行的作业并退出客户机。
                      STOP_JOB=IMMEDIATE 将立即关闭
                      数据泵作业。
</code></pre>
<p>【注】</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>在10g之前，传统的导出导入分别使用exp工具和imp工具。从oracle database 10g开始，不仅保留了原有的exp和imp工具，还提供了数据泵导出导入工具expdp和impdp。</p>
</li>
<li class="lvl-2">
<p>从11g开始，在传统的export和import应用程序中可用的任何特性在data pump中都可用。</p>
</li>
</ul>
<p>在使用expdp和impdp工具时，应该注意以下几点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>exp和imp是客户端工具程序，它们既可以在客户端使用，也可以在服务器端使用。</p>
</li>
<li class="lvl-2">
<p>expdp和impdp是服务器工具程序，它们只能在oracle服务器端使用，不能再客户端使用。</p>
</li>
<li class="lvl-2">
<p>imp只适用于exp导出的文件，不适用于expdp导出文件；impdp只适用与expdp导出的文件，不适用于exp导出文件。data pump导出导入所得到的文件跟传统的import/export应用程序导出导入的文件不兼容。</p>
</li>
</ul>
<p>使用EXPDP和IMPDP还可以实现移动表空间，即将表空间从一个数据库移动到另一个数据库中。</p>
<p>在Oracle 10g前，移动表空间只能在相同的操作系统平台之间进行。在Oracle 11g中，不仅允许在相同平台之间移动表空间，而且允许在不同平台之间移动表空间。通过查询动态性能视图V$TRANSPORTABLE_PLATFORM，可以显示在哪些OS平台之间可以移动表空间。</p>
<h1 id="pump-shu-ju-zi-dian">pump数据字典</h1>
<table>
<thead>
<tr>
<th>数据字典</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>dba_datapump_jobs</td>
<td>显示运行数据泵作业的信息，也可以使user_datapump_jobs变量</td>
</tr>
<tr>
<td>dba_datapump_sessions</td>
<td>提供数据泵作业会话级别的信息</td>
</tr>
<tr>
<td>datapump_paths</td>
<td>提供一系列有效的对象类型，可以将其与export或者impdp的include或者exclude参数关联起来</td>
</tr>
<tr>
<td>dba_directories</td>
<td>提供一系列已定义的目录</td>
</tr>
</tbody>
</table>
<h1 id="shi-jian">实践</h1>
<h2 id="zhun-bei-gong-zuo">准备工作</h2>
<p>创建一个外部目录。</p>
<p>data pump要求为将要创建和读取的数据文件和日志文件创建目录，用来指向使用的外部目录。在oracle中创建目录对象时，可以使用 create directory语句。</p>
<pre><code class="language-shell">SQL&gt; create directory mypump as '/opt/oracle/admin/mmsgdb/dpdump/';
目录已创建。
SQL&gt; grant read, write on directory mypump to mmsg;
授权成功。
SQL&gt;
SQL&gt; select * from dba_directories;   //查询所有目录 
OWNER                          DIRECTORY_NAME                 DIRECTORY_PATH
------------------------------ ------------------------------ ------------------------------------------------------------------------------------------------------------------------------------------
SYS                            MYPUMP                         /opt/oracle/admin/mmsgdb/dpdump/
SYS                            QUEST_SOO_UDUMP_DIR            /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/
SYS                            QUEST_SOO_CDUMP_DIR            /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/cdump/
SYS                            QUEST_SOO_ADUMP_DIR            /opt/oracle/admin/mmsgdb/adump/
SYS                            QUEST_SOO_BDUMP_DIR            /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/
SYS                            DATA_PUMP_DIR                  /opt/oracle/admin/mmsgdb/dpdump/
SYS                            ORACLE_OCM_CONFIG_DIR          /opt/oracle/product/11g/ccr/state
已选择7行。
SQL&gt; 
</code></pre>
<p>至此，准备工作结束。</p>
<h2 id="biao-mo-shi-dao-chu">表模式导出</h2>
<pre><code class="language-shell">oracle@mmsg:~&gt; expdp mmsg/mmsg directory=mypump  dumpfile=table_module.dmp tables=interfaceaccount_20100916,interfaceaccount_20100920 logfile=table_module.log
Export: Release 11.1.0.7.0 - 64bit Production on 星期六, 18 9月, 2010 10:38:13
Copyright (c) 2003, 2007, Oracle.  All rights reserved.
连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
启动 "MMSG"."SYS_EXPORT_TABLE_01":  mmsg/******** directory=mypump dumpfile=table_module.dmp tables=interfaceaccount_20100916,interfaceaccount_20100920 logfile=table_module.log 
正在使用 BLOCKS 方法进行估计...
处理对象类型 TABLE_EXPORT/TABLE/TABLE_DATA
使用 BLOCKS 方法的总估计: 128 KB
处理对象类型 TABLE_EXPORT/TABLE/TABLE
处理对象类型 TABLE_EXPORT/TABLE/INDEX/INDEX
处理对象类型 TABLE_EXPORT/TABLE/CONSTRAINT/CONSTRAINT
处理对象类型 TABLE_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS
处理对象类型 TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
. . 导出了 "MMSG"."INTERFACEACCOUNT_20100916"          7.375 KB       4 行
. . 导出了 "MMSG"."INTERFACEACCOUNT_20100920"          7.507 KB       6 行
已成功加载/卸载了主表 "MMSG"."SYS_EXPORT_TABLE_01" 
******************************************************************************
MMSG.SYS_EXPORT_TABLE_01 的转储文件集为:
  /opt/oracle/admin/mmsgdb/dpdump/table_module.dmp
作业 "MMSG"."SYS_EXPORT_TABLE_01" 已于 10:38:21 成功完成
oracle@mmsg:~&gt;
</code></pre>
<p>【注意】</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>当导出的dumpfile名称与已有的dmp文件名重复时，导出失败，不覆盖原先存在的dmp文件</p>
</li>
</ul>
<pre><code class="language-shell">oracle@mmsg:~&gt; expdp mmsg/mmsg directory=mypump  dumpfile=table_module.dmp tables=interfaceaccount_20100916,interfaceaccount_20100920 logfile=table_module.log
Export: Release 11.1.0.7.0 - 64bit Production on 星期六, 18 9月, 2010 10:40:16
Copyright (c) 2003, 2007, Oracle.  All rights reserved.
连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
ORA-39001: 参数值无效
ORA-39000: 转储文件说明错误
ORA-31641: 无法创建转储文件 "/opt/oracle/admin/mmsgdb/dpdump/table_module.dmp"
ORA-27038: 所创建的文件已存在
Additional information: 1
</code></pre>
<h2 id="schema-mo-shi-dao-chu">schema模式导出</h2>
<pre><code class="language-shell">oracle@mmsg:~&gt; expdp system/sys directory=mypump dumpfile=schema.dmp schemas=mmsg nologfile=y
Export: Release 11.1.0.7.0 - 64bit Production on 星期六, 18 9月, 2010 10:49:31
Copyright (c) 2003, 2007, Oracle.  All rights reserved.
连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
启动 "SYSTEM"."SYS_EXPORT_SCHEMA_01":  system/******** directory=mypump dumpfile=schema.dmp schemas=mmsg nologfile=y 
正在使用 BLOCKS 方法进行估计...
处理对象类型 SCHEMA_EXPORT/TABLE/TABLE_DATA
使用 BLOCKS 方法的总估计: 9.375 MB
处理对象类型 SCHEMA_EXPORT/USER
处理对象类型 SCHEMA_EXPORT/SYSTEM_GRANT
处理对象类型 SCHEMA_EXPORT/DEFAULT_ROLE
处理对象类型 SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA
处理对象类型 SCHEMA_EXPORT/TABLE/TABLE
处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/INDEX
处理对象类型 SCHEMA_EXPORT/TABLE/CONSTRAINT/CONSTRAINT
处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS
处理对象类型 SCHEMA_EXPORT/PACKAGE/PACKAGE_SPEC
处理对象类型 SCHEMA_EXPORT/PROCEDURE/PROCEDURE
处理对象类型 SCHEMA_EXPORT/PACKAGE/COMPILE_PACKAGE/PACKAGE_SPEC/ALTER_PACKAGE_SPEC
处理对象类型 SCHEMA_EXPORT/PROCEDURE/ALTER_PROCEDURE
处理对象类型 SCHEMA_EXPORT/VIEW/VIEW
处理对象类型 SCHEMA_EXPORT/PACKAGE/PACKAGE_BODY
处理对象类型 SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
. . 导出了 "MMSG"."AREANUMBERPREFIX"                   5.476 KB       2 行
********************************中间数据省略************************************
. . 导出了 "MMSG"."VASSUBSCRIBEINFO"                       0 KB       0 行
已成功加载/卸载了主表 "SYSTEM"."SYS_EXPORT_SCHEMA_01" 
******************************************************************************
SYSTEM.SYS_EXPORT_SCHEMA_01 的转储文件集为:
  /opt/oracle/admin/mmsgdb/dpdump/schema.dmp
作业 “SYSTEM”.“SYS_EXPORT_SCHEMA_01” 已于 10:49:50 成功完成
</code></pre>
<h2 id="biao-kong-jian-dao-chu">表空间导出</h2>
<p>两种情况</p>
<h3 id="1-biao-kong-jian-shu-ju-de-dao-chu">1：表空间数据的导出</h3>
<pre><code class="language-shell">oracle@mmsg:~&gt; expdp system/sys directory=mypump dumpfile=tablespace_data.dmp tablespaces=mmsg 
Export: Release 11.1.0.7.0 - 64bit Production on 星期六, 18 9月, 2010 10:51:45
Copyright (c) 2003, 2007, Oracle.  All rights reserved.
连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
启动 "SYSTEM"."SYS_EXPORT_TABLESPACE_01":  system/******** directory=mypump dumpfile=tablespace_data.dmp tablespaces=mmsg 
正在使用 BLOCKS 方法进行估计...
处理对象类型 TABLE_EXPORT/TABLE/TABLE_DATA
使用 BLOCKS 方法的总估计: 9.375 MB
处理对象类型 TABLE_EXPORT/TABLE/TABLE
处理对象类型 TABLE_EXPORT/TABLE/INDEX/INDEX
处理对象类型 TABLE_EXPORT/TABLE/CONSTRAINT/CONSTRAINT
处理对象类型 TABLE_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS
处理对象类型 TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
. . 导出了 "MMSG"."AREANUMBERPREFIX"                   5.476 KB       2 行
. . 导出了 "MMSG"."ROUTERTABLE"                        5.703 KB      17 行
********************************中间数据省略************************************
. . 导出了 "MMSG"."TRACEMSGINFO"                           0 KB       0 行
. . 导出了 "MMSG"."VASMISCMAPPER"                          0 KB       0 行
. . 导出了 "MMSG"."VASSUBSCRIBEINFO"                       0 KB       0 行
已成功加载/卸载了主表 "SYSTEM"."SYS_EXPORT_TABLESPACE_01" 
******************************************************************************
SYSTEM.SYS_EXPORT_TABLESPACE_01 的转储文件集为:
  /opt/oracle/admin/mmsgdb/dpdump/tablespace_data.dmp
作业 "SYSTEM"."SYS_EXPORT_TABLESPACE_01" 已于 10:52:00 成功完成
</code></pre>
<h3 id="2-ke-yi-dong-biao-kong-jian-dao-chu">2：可移动表空间导出</h3>
<p>先将对应的表空间设置成只读状态，然后执行可移动表空间元数据导出</p>
<pre><code class="language-shell">SQL&gt; alter tablespace wyztest read only;
表空间已更改。
SQL&gt; host expdp system/sys directory=mypump dumpfile=tablespace.dmp transport_tablespaces=wyztest;
Export: Release 11.1.0.7.0 - 64bit Production on 星期六, 18 9月, 2010 10:56:48
Copyright (c) 2003, 2007, Oracle.  All rights reserved.
连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
启动 "SYSTEM"."SYS_EXPORT_TRANSPORTABLE_01":  system/******** directory=mypump dumpfile=tablespace.dmp transport_tablespaces=wyztest 
处理对象类型 TRANSPORTABLE_EXPORT/PLUGTS_BLK
处理对象类型 TRANSPORTABLE_EXPORT/POST_INSTANCE/PLUGTS_BLK
已成功加载/卸载了主表 "SYSTEM"."SYS_EXPORT_TRANSPORTABLE_01" 
******************************************************************************
SYSTEM.SYS_EXPORT_TRANSPORTABLE_01 的转储文件集为:
  /opt/oracle/admin/mmsgdb/dpdump/tablespace.dmp
******************************************************************************
可传输表空间 WYZTEST 所需的数据文件:
  /opt/oracle/oradata/mmsgdb/wyztest.dbf
  /opt/oracle/oradata/mmsgdb/wyztest01.dbf
作业 "SYSTEM"."SYS_EXPORT_TRANSPORTABLE_01" 已于 10:56:54 成功完成
SQL&gt; alter tablespace wyztest online;
表空间已更改。
SQL&gt;
</code></pre>
<h3 id="quan-ku-mo-shi-dao-chu">全库模式导出</h3>
<pre><code class="language-shell">expdp system/sys directory=mypump dumpfile=full_oracle.dmp full=y  logfile=full_oracle.log
expdp mmsg/mmsg  directory=mypump dumpfile=app_oracle.dmp full=y   logfile=full_oracle.log
</code></pre>
<h3 id="biao-mo-shi-dao-ru">表模式导入</h3>
<pre><code class="language-shell">SQL&gt; host impdp mmsg/mmsg directory=mypump dumpfile=table_module.dmp tables=interfaceaccount_20100916,interfaceaccount_20100920 table_exists_action=replace
Import: Release 11.1.0.7.0 - 64bit Production on 星期六, 18 9月, 2010 11:09:41
Copyright (c) 2003, 2007, Oracle.  All rights reserved.
连接到: Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
已成功加载/卸载了主表 "MMSG"."SYS_IMPORT_TABLE_01" 
启动 "MMSG"."SYS_IMPORT_TABLE_01":  mmsg/******** directory=mypump dumpfile=table_module.dmp tables=interfaceaccount_20100916,interfaceaccount_20100920 table_exists_action=replace 
处理对象类型 TABLE_EXPORT/TABLE/TABLE
处理对象类型 TABLE_EXPORT/TABLE/TABLE_DATA
. . 导入了 "MMSG"."INTERFACEACCOUNT_20100916"          7.375 KB       4 行
. . 导入了 "MMSG"."INTERFACEACCOUNT_20100920"          7.507 KB       6 行
处理对象类型 TABLE_EXPORT/TABLE/INDEX/INDEX
处理对象类型 TABLE_EXPORT/TABLE/CONSTRAINT/CONSTRAINT
处理对象类型 TABLE_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS
处理对象类型 TABLE_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS
作业 "MMSG"."SYS_IMPORT_TABLE_01" 已于 11:09:44 成功完成
</code></pre>
<h2 id="schema-mo-shi-dao-ru">schema模式导入</h2>
<pre><code class="language-shell">impdp system/sys directory=mypump dumpfile=schema.dmp schemas=mmsg nologfile=y
</code></pre>
<h2 id="biao-kong-jian-shu-ju-dao-ru">表空间数据导入</h2>
<pre><code class="language-shell">impdp system/sys directory=mypump dumpfile=tablespace_data.dmp tablespaces=mmsg 
</code></pre>
<h2 id="ke-yi-dong-biao-kong-jian-dao-ru">可移动表空间导入</h2>
<p>将对应的表空间设置成只读状态，然后执行可移动表空间元数据导出</p>
<pre><code class="language-shell">   SQL&gt;  alter tablespace wyztest read only;
   SQL&gt;  host impdp system/sys directory=mypump dumpfile=tablespace.dmp transport_tablespaces=wyztest;
   SQL&gt;  alter tablespace wyztest online;
</code></pre>
<h2 id="quan-ku-mo-shi-dao-ru">全库模式导入</h2>
<pre><code class="language-shell">impdp system/sys directory=mypump dumpfile=full_oracle.dmp full=y
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle数据导入之SQL Load</title>
    <url>/2010/09/24/oracle_sql_load/</url>
    <content><![CDATA[<h1 id="sql-loader-bang-zhu">SQL*Loader帮助</h1>
<p>命令行输入sqlldr，显示sqlloader帮助信息：</p>
<pre><code class="language-shell">oracle@mmsg37:~&gt; sqlldr 
SQL*Loader: Release 11.1.0.7.0 - Production on 星期四 9月 30 23:55:39 2010
Copyright (c) 1982, 2007, Oracle.  All rights reserved.
用法: SQLLDR keyword=value [,keyword=value,...]
有效的关键字: 
    userid -- ORACLE 用户名/口令        
   control -- 控制文件名                
       log -- 日志文件名                    
       bad -- 错误文件名                   
      data -- 数据文件名                  
   discard -- 废弃文件名
discardmax -- 允许废弃的文件的数目         (全部默认)
      skip -- 要跳过的逻辑记录的数目  (默认 0)
      load -- 要加载的逻辑记录的数目  (全部默认)
    errors -- 允许的错误的数目         (默认 50)
      rows -- 常规路径绑定数组中或直接路径保存数据间的行数
               (默认: 常规路径 64, 所有直接路径)
  bindsize -- 常规路径绑定数组的大小 (以字节计)  (默认 256000)
    silent -- 运行过程中隐藏消息 (标题,反馈,错误,废弃,分区)
    direct -- 使用直接路径                     (默认 FALSE)
   parfile -- 参数文件: 包含参数说明的文件的名称
  parallel -- 执行并行加载                    (默认 FALSE)
      file -- 要从以下对象中分配区的文件     
skip_unusable_indexes -- 不允许/允许使用无用的索引或索引分区  (默认 FALSE)
skip_index_maintenance -- 没有维护索引, 将受到影响的索引标记为无用  (默认 FALSE)
commit_discontinued -- 提交加载中断时已加载的行  (默认 FALSE)
  readsize -- 读取缓冲区的大小               (默认 1048576)
external_table -- 使用外部表进行加载; NOT_USED, GENERATE_ONLY, EXECUTE  (默认 NOT_USED)
columnarrayrows -- 直接路径列数组的行数  (默认 5000)
streamsize -- 直接路径流缓冲区的大小 (以字节计)  (默认 256000)
multithreading -- 在直接路径中使用多线程
 resumable -- 启用或禁用当前的可恢复会话  (默认 FALSE)
resumable_name -- 有助于标识可恢复语句的文本字符串
resumable_timeout -- RESUMABLE 的等待时间 (以秒计)  (默认 7200)
date_cache -- 日期转换高速缓存的大小 (以条目计)  (默认 1000)
PLEASE NOTE: 命令行参数可以由位置或关键字指定
。前者的例子是 'sqlload 
scott/tiger foo'; 后一种情况的一个示例是 'sqlldr control=foo 
userid=scott/tiger'.位置指定参数的时间必须早于
但不可迟于由关键字指定的参数。例如,
允许 'sqlldr scott/tiger control=foo logfile=log', 但是
不允许 'sqlldr scott/tiger control=foo log', 即使
参数 'log' 的位置正确。
</code></pre>
<h1 id="sql-loader-zu-cheng-yuan-su">SQL*Loader组成元素</h1>
<h2 id="kong-zhi-wen-jian">控制文件</h2>
<p>控制文件是用一种语言写的文本文件，这个文本文件能被SQL<em>LOADER识别。SQL</em>LOADER根据控制文件可以找到需要加载的数据。并且分析和解释这些数据。控制文件由三个部分组成：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、全局选件，行，跳过的记录数等；</p>
</li>
<li class="lvl-2">
<p>2、INFILE子句指定的输入数据；</p>
</li>
<li class="lvl-2">
<p>3、数据特性说明。</p>
</li>
</ul>
<h2 id="shu-ru-wen-jian">输入文件</h2>
<p>对于 SQL<em>Loader, 除控制文件外就是输入数据。SQL</em>Loader可从一个或多个指定的文件中读出数据。如果数据是在控制文件中指定，就要在控制文件中写成 INFILE * 格式。</p>
<h1 id="kong-zhi-wen-jian-de-ge-shi">控制文件的格式</h1>
<pre><code class="language-shell">OPTIONS （ { [SKIP=integer] [ LOAD = integer ]
[ERRORS = integer] [ROWS=integer]
[BINDSIZE=integer] [SILENT=(ALL|FEEDBACK|ERROR|DISCARD) ] )
LOAD[DATA]
[ { INFILE | INDDN } {file | * }
[STREAM | RECORD | FIXED length [BLOCKSIZE size]|
VARIABLE [length] ]
[ { BADFILE | BADDN } file ]
{DISCARDS | DISCARDMAX} integr ]
[ {INDDN | INFILE} . . . ]
[ APPEND | REPLACE | INSERT ]
[RECLENT integer]
[ { CONCATENATE integer |
CONTINUEIF { [THIS | NEXT] (start[: end])LAST }
Operator { 'string' | X 'hex' } } ]
INTO TABLE [user.]table
[APPEND | REPLACE|INSERT]
[WHEN condition [AND condition]...]
[FIELDS [delimiter] ]
(
column {
RECNUM | CONSTANT value |
SEQUENCE ( { integer | MAX |COUNT} [, increment] ) |
[POSITION ( { start [end] | * [ + integer] }
) ]
datatype
[TERMINATED [ BY ] {WHITESPACE| [X] 'character' } ]
[ [OPTIONALLY] ENCLOSE[BY] [X]'charcter']
[NULLIF condition ]
[DEFAULTIF condotion]
}
[ ,...]
)
[INTO TABLE...]
[BEGINDATA]
</code></pre>
<h1 id="sql-loader-shi-li">SQL*Loader示例</h1>
<p>详见博文：《Excel数据导入到oracle数据库中》一文中提供的方法一：SQL*Loader 中描述信息。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 11g R2安装过程中碰到的问题汇总</title>
    <url>/2010/09/26/oracle_11g_r2/</url>
    <content><![CDATA[<h1 id="oracle-11-g-r-2-an-zhuang-jie-zhi-bao">oracle 11g R2安装介质包</h1>
<table>
<thead>
<tr>
<th>文件名称</th>
<th>大小（字节）</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>p10404530_112030_Linux-x86-64_1of7.zip</td>
<td>1358,454,646</td>
<td>database安装介质</td>
</tr>
<tr>
<td>p10404530_112030_Linux-x86-64_2of7.zip</td>
<td>1142,195,302</td>
<td>database安装介质</td>
</tr>
<tr>
<td>p10404530_112030_Linux-x86-64_3of7.zip</td>
<td>979,195,792</td>
<td>grid安装介质</td>
</tr>
<tr>
<td>p10404530_112030_Linux-x86-64_4of7.zip</td>
<td>659,229,728</td>
<td>client安装介质</td>
</tr>
<tr>
<td>p10404530_112030_Linux-x86-64_5of7.zip</td>
<td>616,473,105</td>
<td>gateways安装介质</td>
</tr>
<tr>
<td>p10404530_112030_Linux-x86-64_6of7.zip</td>
<td>479,890,040</td>
<td>examples</td>
</tr>
<tr>
<td>p10404530_112030_Linux-x86-64_7of7.zip</td>
<td>113,915,106</td>
<td>deinstall</td>
</tr>
</tbody>
</table>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>Database安装介质，用于安装数据库，即数据库server端；</p>
</li>
<li class="lvl-4">
<p>Grid安装介质，用户安装grid，管理ASM；</p>
</li>
<li class="lvl-4">
<p>Client安装介质，用于安装oracle客户端；</p>
</li>
<li class="lvl-4">
<p>Gateways安装介质，用于安装网关，应用比较少；</p>
</li>
<li class="lvl-4">
<p>Examples安装介质，用户安装现成的示例演示数据库，供研究学习使用；</p>
</li>
<li class="lvl-4">
<p>Deinstall安装介质，用户卸载数据库，从R2开始，dbca不在提供卸载功能。</p>
</li>
</ul>
<h1 id="yu-jian-wen-ti-yu-jie-jue-guo-cheng">遇见问题与解决过程</h1>
<h2 id="wen-ti-1-an-zhuang-grid-bao-cuo">问题1、安装grid报错</h2>
<pre><code class="language-shell">grid@linux173:~/oraInventory/grid&gt; ./ runInstaller
You do not have sufficient permissions to access the inventory '/home/oracle/oraInventory'. Installation cannot continue. It is required that the primary group of the install user is same as the inventory owner group. 
Make sure that the install user is part of the inventory owner group and restart the installer.: Permission denied
</code></pre>
<p>原因：</p>
<p>根据提示信息，当前安装用户grid，不具有对目录“/home/oracle/oraInventory”拥有足够的写权限（sufficient permissions to access），修改方向也是根据提示信息来解决：</p>
<pre><code class="language-shell">Installation cannot continue. It is required that the primary group of the install user is same as the inventory owner group.
</code></pre>
<p>进入/home/oracle目录，修改oraInventory目录的属主为grid.oinstall，再执行runInstaller命令进行安装grid操作。</p>
<h2 id="wen-ti-2-an-zhuang-shu-ju-ku-ruan-jian-jie-zhi-bao-cuo">问题2、安装数据库软件，介质报错</h2>
<p>原因：</p>
<p>database介质包错误，即zip压缩包不完整。</p>
<p>使用unzip命令解压zip包，虽然报错，但解压操作会继续进行，将报错信息淹没，unzip命令解压完成后并不最终汇总报错信息，如果不查看解压过程日志是无法发现压缩包问题的。</p>
<p>unzip命令解压介质包，报错信息如下：</p>
<pre><code class="language-shell">  inflating: database/stage/Components/oracle.javavm.companion/11.2.0.3.0/1/DataFiles/filegroup2.jar  
   creating: database/stage/Components/oracle.jdk/
   creating: database/stage/Components/oracle.jdk/1.5.0.30.03/
   creating: database/stage/Components/oracle.jdk/1.5.0.30.03/1/
   creating: database/stage/Components/oracle.jdk/1.5.0.30.03/1/DataFiles/
  inflating: database/stage/Components/oracle.jdk/1.5.0.30.03/1/DataFiles/filegroup4.jar  
  inflating: database/stage/Components/oracle.jdk/1.5.0.30.03/1/DataFiles/filegroup5.jar  
  inflating: database/stage/Components/oracle.jdk/1.5.0.30.03/1/DataFiles/filegroup3.jar  
  error:  invalid compressed data to inflate
file #1808:  bad zipfile offset (local header sig):  799288453
file #1809:  bad zipfile offset (local header sig):  800322303
   creating: database/stage/Components/oracle.ordim.server/
   creating: database/stage/Components/oracle.ordim.server/11.2.0.3.0/
   creating: database/stage/Components/oracle.ordim.server/11.2.0.3.0/1/
</code></pre>
<p>建议使用jar命令解压zip包，因为jar命令在解压过程中，一旦遇见包错误，会立即终止继续解压操作，方便用户查看介质是否存在问题。此问题就是通过jar命令解压zip包发现的。</p>
<h2 id="wen-ti-3-mo-ren-jian-ting-wei-zhu-ce">问题3、默认监听未注册</h2>
<pre><code class="language-shell">grid@linux173:~&gt; crsctl stat res -t
--------------------------------------------------------------------------------
NAME           TARGET  STATE        SERVER                   STATE_DETAILS       
--------------------------------------------------------------------------------
Local Resources
--------------------------------------------------------------------------------
ora.DG_ORA.dg
               ONLINE  ONLINE       linux173                                     
ora.LISTENER.lsnr
               ONLINE  INTERMEDIATE linux173                 Not All Endpoints R 
                                                             egistered           
ora.asm
               ONLINE  ONLINE       linux173                 Started             
ora.ons
               OFFLINE OFFLINE      linux173                                     
--------------------------------------------------------------------------------
Cluster Resources
--------------------------------------------------------------------------------
ora.cssd
      1        ONLINE  ONLINE       linux173                                     
ora.diskmon
      1        OFFLINE OFFLINE                                                   
ora.evmd
      1        ONLINE  ONLINE       linux173
</code></pre>
<p>原因：</p>
<p>R2存在两个监听，一个是默认监听，一个是业务数据监听，信息如下：</p>
<table>
<thead>
<tr>
<th>监听名称</th>
<th>默认端口</th>
<th>管理者</th>
</tr>
</thead>
<tbody>
<tr>
<td>LISTENER</td>
<td>1521</td>
<td>grid</td>
</tr>
<tr>
<td>LISTENER_ORA</td>
<td>自定义</td>
<td>oracle</td>
</tr>
</tbody>
</table>
<p>其中，（OS级）grid用户管理默认监听LISTENER；（OS级）oracle用户管理业务监听，端口自定义，但不能使用1521端口。</p>
<p>遇见这个问题，首先查看grid的默认监听文件，确认默认监听中端口与当前crs中是否一致。通过listener.ora文件中端口与crs中启用的端口（可通过netstat –an过滤1521端口，查看1521是否处于监听状态），经相互对比，默认监听文件中端口是1522，crs中是1521，说明有人修改过默认监听配置文件中端口，导致crs中与监听配置文件中不一致。</p>
<p>解决过程如下：</p>
<p>1、修改默认监听配置文件中监听端口为1521；</p>
<p>2、停掉has中默认监听资源（crsctl stop res ora.LISTENER.lsnr）</p>
<p>3、从has中删掉默认监听资源（srvctl remove listener -l LISTENER）</p>
<pre><code class="language-shell">grid@linux173:~&gt; crsctl stat res -t
--------------------------------------------------------------------------------
NAME           TARGET  STATE        SERVER                   STATE_DETAILS       
--------------------------------------------------------------------------------
Local Resources
--------------------------------------------------------------------------------
ora.DG_ORA.dg
               ONLINE  ONLINE       linux173                                     
ora.asm
               ONLINE  ONLINE       linux173                 Started             
ora.ons
               OFFLINE OFFLINE      linux173                                     
--------------------------------------------------------------------------------
Cluster Resources
--------------------------------------------------------------------------------
ora.cssd
      1        ONLINE  ONLINE       linux173                                     
ora.diskmon
      1        OFFLINE OFFLINE                                                   
ora.evmd
      1        ONLINE  INTERMEDIATE linux173
</code></pre>
<p>结果显示是没有默认监听资源的，已经成功删除.</p>
<p>4、重新创建默认监听（srvctl add listener -l LISTENER -o $ORACLE_HOME）</p>
<pre><code class="language-shell">grid@linux173:~&gt; srvctl add listener -l LISTENER -o $ORACLE_HOME
grid@linux173:~&gt; crsctl stat res -t                             
--------------------------------------------------------------------------------
NAME           TARGET  STATE        SERVER                   STATE_DETAILS       
--------------------------------------------------------------------------------
Local Resources
--------------------------------------------------------------------------------
ora.DG_ORA.dg
               ONLINE  ONLINE       linux173                                     
ora.LISTENER.lsnr
               OFFLINE OFFLINE      linux173                                     
ora.asm
               ONLINE  ONLINE       linux173                 Started             
ora.ons
               OFFLINE OFFLINE      linux173                                     
--------------------------------------------------------------------------------
Cluster Resources
--------------------------------------------------------------------------------
ora.cssd
      1        ONLINE  ONLINE       linux173                                     
ora.diskmon
      1        OFFLINE OFFLINE                                                   
ora.evmd
      1        ONLINE  ONLINE       linux173 
</code></pre>
<p>5、启动默认监听（crsctl start res ora.LISTENER.lsnr）</p>
<pre><code class="language-shell">grid@linux173:~&gt; crsctl start res ora.LISTENER.lsnr
CRS-2672: Attempting to start 'ora.LISTENER.lsnr' on 'linux173'
CRS-2676: Start of 'ora.LISTENER.lsnr' on 'linux173' succeeded
</code></pre>
<p>6、查看默认监听状态</p>
<pre><code class="language-shell">grid@linux173:~&gt;  crsctl stat res -t                
--------------------------------------------------------------------------------
NAME           TARGET  STATE        SERVER                   STATE_DETAILS       
--------------------------------------------------------------------------------
Local Resources
--------------------------------------------------------------------------------
ora.DG_ORA.dg
               ONLINE  ONLINE       linux173                                     
ora.LISTENER.lsnr
               ONLINE  ONLINE       linux173                                     
ora.asm
               ONLINE  ONLINE       linux173                 Started             
ora.ons
               OFFLINE OFFLINE      linux173                                     
--------------------------------------------------------------------------------
Cluster Resources
--------------------------------------------------------------------------------
ora.cssd
      1        ONLINE  ONLINE       linux173                                     
ora.diskmon
      1        OFFLINE OFFLINE                                                   
ora.evmd
      1        ONLINE  ONLINE       linux173                                     
</code></pre>
<h2 id="wen-ti-4-tong-guo-bie-ming-deng-lu-shu-ju-ku-bao-cuo">问题4、通过别名登录数据库报错</h2>
<pre><code class="language-shell">oracle@linux173:~/product/11gR2/db/network/admin&gt; sqlplus websvc/websvc@infoxdb

SQL*Plus: Release 11.2.0.3.0 Production on Fri Nov 16 19:56:22 2012

Copyright (c) 1982, 2011, Oracle.  All rights reserved.

ERROR:
ORA-12154: TNS:could not resolve the connect identifier specified


Enter user-name: 
ERROR:
ORA-01017: invalid username/password; logon denied


Enter user-name: 
ERROR:
ORA-01017: invalid username/password; logon denied


SP2-0157: unable to CONNECT to ORACLE after 3 attempts, exiting SQL*Plus
oracle@linux173:~/product/11gR2/db/network/admin&gt; 
使用infoxdb别名登录，报错；不使用别名登录（sqlplus websvc/websvc），则可正常登录成功。
</code></pre>
<p>解决方法：</p>
<p>1、首先tnsping infoxdb，查看oracle scan通讯效果</p>
<p>Tnsping结果显示，报TNS中地址错误，手工检查了tns文件，尚未发现问题；</p>
<p>2、将备机中tns文件ftp到主机对应目录下，通过diff命令进行tns文件对比</p>
<pre><code class="language-shell">oracle@linux173:~/product/11gR2/db/network/admin&gt; diff  wyz/listener.ora  ./listener.ora        
8a9
&gt; 
15a17
&gt; 
oracle@linux173:~/product/11gR2/db/network/admin&gt; diff  wyz/tnsnames.ora  ./tnsnames.ora 
2a3
&gt; 
5c6
&lt;     (ADDRESS = (PROTOCOL = TCP)(HOST = 10.41.16.52)(PORT = 1522)
---
&gt;     (ADDRESS = (PROTOCOL = TCP)(HOST = 10.41.16.52)(PORT = 1522))
13a15,16
&gt; 
&gt; 
</code></pre>
<p>上述命令发现tns文件存在语法错误，少个括号。</p>
<p>对于tns文件问题，眼睛往往看不出差异，而且oracle并没有提供相关命令供用户检测tns或监听文件的合法性，只能人为的手工的进行检查，而人为手工检查往往存在已经的马虎性，往往解决不了细节上的小问题。</p>
<h2 id="wen-ti-5-duan-xin-db-60-ban-ben-shua-ku-bao-ora-01756-he-ora-02291-cuo-wu">问题5、短信DB60版本刷库报ORA-01756 和ORA-02291错误</h2>
<p>短信DB60版本直接在Release2数据库上刷库，报错信息大致如下：</p>
<pre><code class="language-shell">ERROR:
ORA-01756: quoted string not properly terminated



Comment created.


Comment created.


Table created.

ERROR:
ORA-01756: quoted string not properly terminated



insert into MENUINFO_SMS (MENUID, ParentMenuID, DESCRIPTION, MENUURL, ISSHOW, IDORDER, TARGET, KEYNAME, PicURL, MaskID) Values (200209,200200,'计费号码限定','/sms/chargeparty/doQuery.do',null,200209,'','MENU.CHARGEPARTY','',47)
*
ERROR at line 1:
ORA-02291: integrity constraint (WEBSVC.FK_MENUID_SELF_REF) violated - parent
key not found


ERROR:
ORA-01756: quoted string not properly terminated
</code></pre>
<p>原因：</p>
<p>通过vi一些sql文件，发现里面中文出现乱码，通过设置环境变量中语言解决：</p>
<pre><code class="language-shell">setenv NLS_LANG "SIMPLIFIED CHINESE"
setenv LANG en_US
</code></pre>
<h2 id="wen-ti-6-db-60-shua-ku-shi-bao-ora-12899-cuo-wu">问题6、DB60刷库时，报ORA-12899错误</h2>
<p>原因：</p>
<p>表ConfItemLangRes_SMS中ConfigName字段属性长度过小（varchar(60)），而相应的values值超过了该字段的属性范围。</p>
<pre><code class="language-shell">create table ConfItemLangRes_SMS  (
   InnerIndex           INTEGER                          not null,
   ConfItemIndex        INTEGER,
   LanguageName         varchar(10)                      not null,
   ConfigName           varchar(60)                      not null,
   ConfigDesc           varchar(500),
   constraint PK_CONFITEMLANGRES_SMS primary key (InnerIndex)
)
</code></pre>
<p>修改该字段属性，扩大长度解决问题：</p>
<pre><code class="language-shell">ConfigName           varchar(96)                      not null,
</code></pre>
<h2 id="wen-ti-7-usm-an-zhuang-oracle-11-g-release-2-wen-ti">问题7、USM安装oracle 11g Release2问题</h2>
<p>表象</p>
<p>USM执行R2安装任务，报错：</p>
<pre><code class="language-shell">2012-11-20 10:23:27 [ERROR] [1]: Execute ha_node_conf.sh on primary failed
2012-11-20 10:23:27 [ERROR] []: The /home/inst-ora/ha-conf/ha.sh is executed faild ....
</code></pre>
<p>解决过程：</p>
<p>usm版本信息如下：</p>
<pre><code class="language-shell">usm:/ataeinst # /opt/dms/bin/atae_version
[DMS]
version=ATAE USM V100R002C31
patch=
builddate=201211160851
[USMAS]
version=ATAE USM V100R002C31
patch=
builddate=201211160851
[IPA]
version=ATAE USM V100R002C31
patch=
builddate=201211160851
[SOLUTION]
version=ATAE SOLUTION V100R002C31
patch=
builddate=201211160851
</code></pre>
<p>上述报错的日志信息，是USM界面提供，该日志信息来自主机/var/adm/autoinstall/logs目录下install_script.sh.log文件，不具有参考价值。</p>
<p>先了解一下USM的大致工作过程与原理：部署任务页面添加部署任务，一旦提交部署任务，在usm端会生成一个配置文件（name.properties文件，如安装oralceR2时候的配置文件为ora11gR2_x64.properties），该文件以key=value方式存储页面中配置的数据；usm执行任务的时候，将配置文件，脚本等资料存放到执行任务的单板上，通过ftp、ssh等方式执行相关shell脚本进行任务的安装，多采用静默安装方式进行安装操作。安装过程产生的日志，在/var/adm/autoinstall/logs目录下，在任务执行过程中可参考日志，根据日志定位问题，这就是为何说USM界面中显示的日志不具有参考价值的原因所在。</p>
<p>其实此次安装报错，根据日志分析了下，如下：</p>
<p>日志报错，信息片断如下：</p>
<pre><code class="language-shell">+ '[' X/dev/sdb '!=' X ']'
+ '[' -e /dev/sdb ']'
++ ls -l /dev/disk/by-id
+++ basename /dev/sdb
++ grep scsi
++ awk '{print $9}'
++ grep -w 'sdb$'
+ DISK_DBFILE_SCSI=/dev/disk/by-id/
+ '[' /dev/disk/by-id/ == /dev/disk/by-id/ ']'
+ error_exit 'Get device /dev/sdb scsi num failed.'
+ wlogf '[ERROR]:Get device /dev/sdb scsi num failed.'
++ date '+%Y-%m-%d %H:%M:%S '
+ timestr='2012-11-20 10:23:22 '
+ echo 2012-11-20 10:23:22 '[ERROR]:Get device /dev/sdb scsi num failed.'
+ store_logfile
+ '[' -e /var/adm/autoinstall/logs/ora11gR2_x64_PRIMARY_20121120102316.log ']'
+ scp /var/adm/autoinstall/logs/ora11gR2_x64_PRIMARY_20121120102316.log 10.41.16.173:/var/adm/autoinstall/logs/
+ exit 1
</code></pre>
<p>上述报错日志，对应的shell脚本片断如下：</p>
<pre><code class="language-shell">/iso/ora11gR2_x64/ha-conf|ha_node_conf.sh，内容片断如下：
if [ "X$DISK_DBFILE" != "X" ]
then
    [ -e "$DISK_DBFILE" ] || error_exit "The device $DISK_DBFILE is not exist."
    DISK_DBFILE_SCSI="/dev/disk/by-id/"$( ls -l /dev/disk/by-id | grep -w "$(basename $DISK_DBFILE)$" | grep scsi | awk '{print $9}')
    [ $DISK_DBFILE_SCSI == "/dev/disk/by-id/" ] &amp;&amp; error_exit "Get device $DISK_DBFILE scsi num failed."
    echo "ln -f -s $DISK_DBFILE_SCSI /dev/diskgroup/dg_ora       "  &gt;&gt;/etc/init.d/linkraw_oracle.sh 
fi
</code></pre>
<p>这里的变量$DISK_DBFILE读文件（/etc/ora11gR2_x64.properties）获取，红色加粗部分，表示过滤分区对应的scsi信息，变量$(basename $DISK_DBFILE)$也是读自文件/etc/ora11gR2_x64.properties，从这里可以知道，脚本要求共享存储scsi对应的分区名称在主备机上必须保持一致，例如：主机上scsi名称为scsi-360022a110003135eb02707d900000003，对应的分区名称为sdb，那边，在备机上，scsi名称为scsi-360022a110003135eb02707d900000003的，对应的分区也必须为sdb，如果不为sdb，这里即使在主机上安装grid成功了，到备机上因无法获取sdb分区而导致脚本执行失败，一旦脚本执行失败，如果安装任务中设置了卸载操作，则执行回滚脚本进行环境的清理，包括主备机的环境的清理。</p>
<p>分析至此，发现USM31版本中的脚本，要求主备机外挂存储scsi对应分区名称必须要保持一致，这样grid才能正常进行安装，脚本不至于报错退出以致回滚。而scsi与分区对应关系，是存储与操作系统映射时候产生的文件，这个文件即使编辑了，系统并不承认编辑后的文件，即非法文件，一旦重启机器，系统会自动还原整个by-id目录以及该目录下文件，所以，想通过修改by-id目录下链接规避分区名称不一致问题，此路行不通。</p>
<p>可通过如下方法解决：</p>
<p>既然是通过读取.properties文件获取配置安装配置信息，那么，在主机进行grid安装时，如主机中scsi-360022a110003135eb02707d900000003对应sdg分区，部署任务中就填写value为sdg分区，当主机正在进行grid安装，备机尚未进行grid安装时候，root用户登录备机，修改备机上的ora11gR2_x64.properties 文件，将文件中对应的value修改为sdb，从而规避了USMC31版本的一个缺陷。</p>
<pre><code class="language-shell">gw249:/home # more /etc/ora11gR2_x64.properties
#
#Fri Nov 23 16:44:42 CST 2012
node_count.0.PRVIP=
REDOGROUP_NUM=3
ORACLE_BASE=/home/oracle
FLOATIP=
USMAS.SOFTWARE.ID=ora11gR2_x64
SCAN_PORT=1525
SYSTEM_SIZE=2G
LOGDISK=/dev/sdf
PRIMARY_PUBIP=10.41.16.185
GRID_PASSWD_encrypt=mNi2wTvj/Kfn+8Rb0naVcg\=\=
TEMP_SIZE=6G
ORACLE_OWNER=oracle
UNINSTALL_COMPONENT.0=\ 
INSTALL_TYPE=2
GRID_OWNER=grid
SYSAUX_SIZE=2G
SLAVE_PUBIP=10.41.16.249
node_count.0.VIP=
LANGUAGE=ZHS16GBK
UNINSTALL=yes
DB_PASSWD_encrypt=mNi2wTvj/Kfn+8Rb0naVcg\=\=
INDEXDISK=/dev/sde
GRID_HOME=/home/oracrs/product/11gR2/grid
SCANIP=
CTLFILE_NUM=3
SLAVE_ROOT_PASSWD_encrypt=I4SZtfrINcexo7CdV4+RUQ\=\=
node_count.NUMBER=1
ORACLE_HOME_DIRECTORY=/home/oracle
node_count.0.PUBIP=
REDOFILE_SIZE=1000M
PRIMARY_PRVIP=192.168.100.244
ASMSYS_PASSWD_encrypt=mNi2wTvj/Kfn+8Rb0naVcg\=\=
DATADISK=/dev/sdd
GRID_BASE=/home/oracrs/base
USER_LISTENER_PORT=1526
EXCUTETIMEOFTIMEJOB_RAC=
UNDO_SIZE=6G
ORACLE_SID=infoxdb
SLAVE_PRVIP=192.168.100.247
PRIMARY_ROOT_PASSWD_encrypt=I4SZtfrINcexo7CdV4+RUQ\=\=
ORACLE_HOME=/home/oracle/product/11gR2/db
DBFILEDISK=/dev/sde
ORACLE_PASSWD_encrypt=mNi2wTvj/Kfn+8Rb0naVcg\=\=
grid_basic_parameter.node_count.NUMBER=1
GRID_HOME_DIRECTORY=/home/grid
UNINSTALL_COMPONENT.NUMBER=1
node_count.0.ROOT_PASSWD_encrypt=GfNigSAbW5XN08daE0VA6w\=\=
OCRVOTINGDISK=/dev/sde
USERS_SIZE=1G
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--修改数据库实例名和数据库名</title>
    <url>/2010/09/27/oracle_modify_instance_name_and_db_name/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在oracle9i之前，修改数据库实例比较麻烦，需要重建oracle的控制文件以及需要reset redolog。从oracle 9i R2版本开始，oracle 提供了nid系统命令，使得修改oracle的数据库名和实例名更加简单。</p>
<p>本文描述将数据库名和实例名为mmsgdb的修改为inomc</p>
<h1 id="ju-ti-cao-zuo-miao-shu">具体操作描述</h1>
<h2 id="zhun-bei-gong-zuo">准备工作</h2>
<p>一个正常可以使用的oracle数据库系统，instance正常，database正常。</p>
<h2 id="cao-zuo-bu-zou">操作步骤</h2>
<p>1、shutdown 数据库</p>
<p>2、数据库启动到mount状态</p>
<p>3、创建pfile文件</p>
<p>4、执行nid命令，修改数据库名和实例名</p>
<p>5、修改pfile文件，启动数据库</p>
<p>6、创建spfile文件和口令文件</p>
<p>7、加载监听，修改tnsnames.ora文件</p>
<p>8、检测更改后的信息</p>
<p>9、备份数据库</p>
<p>关键部分的详细步骤如下：</p>
<h3 id="bu-zou-yi-cha-kan-nid-bang-zhu-xin-xi-yi-ji-nid-shi-yong-fang-fa">步骤一、查看nid帮助信息以及nid使用方法</h3>
<pre><code class="language-shell">SQL&gt; host nid –help

DBNEWID: Release 11.1.0.7.0 - Production on 星期一 9月 27 11:09:09 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

关键字      说明                    (默认值)
----------------------------------------------------
TARGET      用户名/口令              (无)
DBNAME      新的数据库名             (无)
LOGFILE     输出日志                     (无)
REVERT      还原失败的更改            否
SETNAME     仅设置新的数据库名        否
APPEND      附加至输出日志            否
HELP        显示这些消息              否

shutdown 数据库
SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt;
</code></pre>
<h3 id="bu-zou-er-qi-dong-shu-ju-ku-dao-mount-zhuang-tai">步骤二、启动数据库到mount状态</h3>
<pre><code class="language-shell">SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
SQL&gt;
</code></pre>
<h3 id="bu-zou-san-chuang-jian-pfile-wen-jian">步骤三、创建pfile文件</h3>
<pre><code class="language-shell">SQL&gt; create pfile='/opt/oracle/product/11g/dbs/pfile2010wyz ' from spfile;

文件已创建。

SQL&gt;
</code></pre>
<h3 id="bu-zou-si-xiu-gai-shu-ju-ku-ming">步骤四、修改数据库名</h3>
<pre><code class="language-shell">SQL&gt; host nid target=sys/sys dbname=inomc

DBNEWID: Release 11.1.0.7.0 - Production on 星期一 9月 27 11:10:23 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

已连接数据库 MMSGDB (DBID=3129897535)

已连接服务器版本 11.1.0

数据库中的控制文件数:
    /opt/oracle/oradata/mmsgdb/control01.ctl
    /opt/oracle/oradata/mmsgdb/control02.ctl
    /opt/oracle/oradata/mmsgdb/control03.ctl

是否将数据库 ID 和数据库名 MMSGDB 更改为 INOMC? (Y/[N]) =&gt; Y

操作继续进行
将数据库 ID 从 3129897535 更改为 1037547743
将数据库名从 MMSGDB 更改为 INOMC
    控制文件 /opt/oracle/oradata/mmsgdb/control01.ctl - 已修改
    控制文件 /opt/oracle/oradata/mmsgdb/control02.ctl - 已修改
    控制文件 /opt/oracle/oradata/mmsgdb/control03.ctl - 已修改
    数据文件 /opt/oracle/oradata/mmsgdb/system01.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/sysaux01.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/undotbs01.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/users01.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/mmsgdata0 - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/y_mmsgdb - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/wyz_mmsgdata0 - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/wyztest.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/wyztest01.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/temp01.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/mmsgdata0 - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/y_mmsgdb - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/wyz_mmsgdata0 - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/wyztesttmp.db - dbid 已更改, 已写入新名称
    数据文件 /opt/oracle/oradata/mmsgdb/wyztesttemp0.db - dbid 已更改, 已写入新名称
    控制文件 /opt/oracle/oradata/mmsgdb/control01.ctl - dbid 已更改, 已写入新名称
    控制文件 /opt/oracle/oradata/mmsgdb/control02.ctl - dbid 已更改, 已写入新名称
    控制文件 /opt/oracle/oradata/mmsgdb/control03.ctl - dbid 已更改, 已写入新名称




NID-00600: 内部错误 - [28] [1013] [0] [0]


在验证时更改数据库名和 ID 失败 - 数据库保持原样。
DBNEWID - 已完成, 但出现验证错误。
</code></pre>
<p>注意：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这里出问题了，原因如下：</p>
</li>
</ul>
<p>因为这个nid命令僵死，当使用nid更改数据库名和实例名的时候，nid僵死的几率很高，出现这个问题的时候，当发现控制文件已经更改了，数据文件、重做日志文件已经更改了之后，就可以强制终止nid操作了，于是就出现了上面的“NID-00600: 内部错误 - [28] [1013] [0] [0]”错误信息。</p>
<p>按理这里应该是出现:</p>
<pre><code class="language-shell">数据库名已经改变为INOMC
在重启数据库之前修改系统参数文件和创建新口令文件
所以的回滚以及归档的重做日志对当前数据库已经无用
关闭数据库后重启时需要使用resetlogs操作
成功改变数据库名和ID信息
DBNEWID –成功完成
</code></pre>
<p>对应英文如下：</p>
<pre><code class="language-shell">Database name changed to TESTDB.
Modify parameter file and generate a new password file before restarting.
Database ID for database TESTDB changed to 2321050327.
All previous backups and archived redo logs for this database are unusable.
Shut down database and open with RESETLOGS option.
Succesfully changed database name and ID.
DBNEWID - Completed succesfully.
</code></pre>
<h3 id="bu-zou-wu-xiu-gai-pfile-wen-jian-he-huan-jing-bian-liang">步骤五、修改pfile文件和环境变量</h3>
<h4 id="xiu-gai-pfile">修改pfile</h4>
<pre><code class="language-shell">inomc.__db_cache_size=1207959552   #"inomc"这个名称，原先是mmsgdb，这里凡是带“mmsgdb”字样的，全部被修改成inomc
inomc.__java_pool_size=16777216
inomc.__large_pool_size=16777216
inomc.__oracle_base='/opt/oracle'#ORACLE_BASE set from environment
inomc.__pga_aggregate_target=6744440832
inomc.__sga_target=1610612736
inomc.__shared_io_pool_size=0
inomc.__shared_pool_size=352321536
inomc.__streams_pool_size=0
*.audit_file_dest='/opt/oracle/admin/mmsgdb/adump'
*.audit_trail='NONE'
*.compatible='11.1.0.0.0'
*.control_files='/opt/oracle/oradata/mmsgdb/control01.ctl','/opt/oracle/oradata/mmsgdb/control02.ctl','/opt/oracle/oradata/mmsgdb/co
ntrol03.ctl'
*.db_block_size=8192
*.db_domain=''
*.db_name='inomc'   #原先是mmsgdb，这里修改成inomc
*.diagnostic_dest='/opt/oracle'
*.nls_language='SIMPLIFIED CHINESE'
*.nls_territory='CHINA'
*.open_cursors=300
*.pga_aggregate_target=6728712192
*.processes=150
*.recyclebin='OFF'
*.remote_login_passwordfile='EXCLUSIVE'
*.sga_target=1610612736
*.undo_tablespace='UNDOTBS1'
*.instance_name='inomc'   #新增的信息，因为oracle11g隐式读取这个参数，这里增加，可直接读取
*.service_names='inomc'   #新增的信息，因为oracle11g隐式读取这个参数，这里增加，可直接读取
</code></pre>
<h4 id="xiu-gai-huan-jing-bian-liang-xin-xi-profile-wen-jian">修改环境变量信息.profile文件</h4>
<p>将这个文件中的<code>ORACLE_SID=mmsgdb </code>, 修改成 <code>ORACLE_SID=inomc </code>, 重新source一下这个环境变量文件。</p>
<h3 id="bu-zou-liu-yi-pfile-wen-jian-qi-dong-shu-ju-ku">步骤六、以pfile文件启动数据库</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate     #停止数据库
ORA-01507: ??????


ORACLE 例程已经关闭。
SQL&gt; startup nomount         #启动数据库到mount状态
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes


SQL&gt; shutdown immediate
ORA-01507: ??????


ORACLE 例程已经关闭。
SQL&gt; startup pfile='/opt/oracle/product/11g/dbs/pfile2010wyz.ora'  #以pfile文件启动
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
ORA-01589: 要打开数据库则必须使用 RESETLOGS 或 NORESETLOGS 选项  #这里提示报错了，先不管


SQL&gt; create spfile from pfile = '/opt/oracle/product/11g/dbs/pfile2010wyz.ora'
  2  ;

文件已创建。                      #通过pfile文件创建spfile文件

SQL&gt; shutdown immediate      #关闭数据库
ORA-01109: 数据库未打开


已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup mount           #启动数据库到mount状态
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size             385878544 bytes
Database Buffers         1207959552 bytes
Redo Buffers                7413760 bytes
数据库装载完毕。
SQL&gt; alter database open RESETLOGS;      #使用resetlogs启动数据库

数据库已更改。

SQL&gt; select open_mode from v$database;   #查看数据库打开模式

OPEN_MODE
----------
READ WRITE

SQL&gt; show parameter name                   #查看数据库名和实例信息

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_file_name_convert                 string
db_name                              string      inomc
db_unique_name                       string      inomc
global_names                         boolean     FALSE
instance_name                        string      inomc
lock_name_space                      string
log_file_name_convert                string
service_names                        string      inomc
SQL&gt;
</code></pre>
<h3 id="bu-zou-qi-chuang-jian-kou-ling-wen-jian">步骤七、创建口令文件</h3>
<h4 id="cha-kan-orapwd-bang-zhu-xin-xi">查看orapwd帮助信息</h4>
<pre><code class="language-shell">oracle@mmsg:~/product/11g/network/admin&gt; orapwd
Usage: orapwd file=&lt;fname&gt; password=&lt;password&gt; entries=&lt;users&gt; force=&lt;y/n&gt; ignorecase=&lt;y/n&gt; nosysdba=&lt;y/n&gt;

  where
    file - name of password file (required),
    password - password for SYS, will be prompted if not specified at command line,
    entries - maximum number of distinct DBA (optional),
    force - whether to overwrite existing file (optional),
    ignorecase - passwords are case-insensitive (optional),
    nosysdba - whether to shut out the SYSDBA logon (optional Database Vault only).
    
  There must be no spaces around the equal-to (=) character.
</code></pre>
<h4 id="chuang-jian-kou-ling-wen-jian">创建口令文件</h4>
<pre><code class="language-shell">oracle@mmsg:~/product/11g/dbs&gt; orapwd  file=/opt/oracle/product/11g/dbs/orapwinomc password=sys entries=20
</code></pre>
<h3 id="bu-zou-ba-shi-hou-jian-cha">步骤八、事后检查</h3>
<h4 id="cha-kan-shi-li-xin-xi">查看实例信息</h4>
<pre><code class="language-shell">SQL&gt; select instance_name from v$instance;

INSTANCE_NAME
----------------
inomc

SQL&gt;
</code></pre>
<h4 id="xiu-gai-tnsnames-ora-wen-jian-xin-xi">修改tnsnames.ora文件信息</h4>
<pre><code class="language-shell">INOMC =
  (DESCRIPTION =
      (ADDRESS = (PROTOCOL = TCP)(HOST = mmsg)(PORT = 1521))
      (CONNECT_DATA =
        (SERVER = DEDICATED)
        (SERVICE_NAME = inomc)
      )
  )

</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>凡是mmsgdb的，修改成inomc</p>
</li>
</ul>
<h4 id="reload-jian-ting-xin-xi">reload监听信息</h4>
<pre><code class="language-shell">racle@mmsg:~/product/11g/network/admin&gt; lsnrctl reload

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 27-9月 -2010 15:20:02

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

正在连接到 (ADDRESS=(PROTOCOL=tcp)(HOST=)(PORT=1521))
命令执行成功
</code></pre>
<h3 id="bu-zou-jiu-bei-fen-shu-ju-ku">步骤九、备份数据库</h3>
<p>原因是数据库实例名和数据库名发生变更后，之前的所有备份对当前数据库已经没有任何作用了，所以建议备份一下当前修改后的数据库。</p>
<h1 id="zong-jie">总结</h1>
<p>修改实例名和数据库名与删除实例重建，前者最大的优势是原有数据不会丢失。</p>
<p>至此，数据库名和实例名修改完成。</p>
<h1 id="yu-jian-de-wen-ti-yu-jie-jue-fang-fa">遇见的问题与解决方法</h1>
<h2 id="biao-xiang">表象</h2>
<p>数据库连接与启动失败，与数据库建立连接时报ORA-00838错误。</p>
<pre><code class="language-shell">racle@mmsg:~&gt; sqlplus / as sysdba
Copyright (c) 1982, 2008, Oracle.  All rights reserved.
ORA-00838: Specified value of MEMORY_TARGET is too small, needs to be at least 7968M
oracle@mmsg:~&gt; cd product/11g/dbs

oracle@mmsg:~/product/11g/dbs&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期一 9月 27 14:55:13 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

已连接到空闲例程。

SQL&gt; startup 
ORA-00838: Specified value of MEMORY_TARGET is too small, needs to be at least 7968M
SQL&gt;
</code></pre>
<h2 id="yuan-yin">原因</h2>
<p>内存自动管理机制中MEMORY_TARGET参数值设置过小。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>当前数据库已经无法启动，也就无法查看当前memory_target值与memory_max_target的值</p>
<p>解决这个问题，只能从pfile文件中着手（因为spfiel文件是二进制文件，不能直接修改）。</p>
<h3 id="xiu-gai-pfile-wen-jian-xin-zeng-yi-xing-ji-lu">修改pfile文件，新增一行记录</h3>
<p><code>*.memory_target=8365053568 </code>,这里修改值比7968<em>1024</em>1024的值稍大点.</p>
<h3 id="yi-zhi-ding-pfile-wen-jian-fang-shi-qi-dong-shu-ju-ku">以指定pfile文件方式启动数据库</h3>
<pre><code class="language-shell">SQL&gt; startup pfile='/opt/oracle/product/11g/dbs/pfile2010wyz.ora'
ORACLE 例程已经启动。

Total System Global Area 8334446592 bytes
Fixed Size                  2176280 bytes
Variable Size            7147096808 bytes
Database Buffers         1174405120 bytes
Redo Buffers               10768384 bytes
数据库装载完毕。
数据库已经打开。
</code></pre>
<h3 id="yi-pfile-wen-jian-chuang-jian-spfile-wen-jian">以pfile文件创建spfile文件</h3>
<pre><code class="language-shell">SQL&gt; create spfile='/opt/oracle/product/11g/dbs/spfileinomc.ora' from pfile ='/opt/oracle/product/11g/dbs/pfile2010wyz.ora'
  2  ;

文件已创建。
</code></pre>
<h3 id="zhong-qi-shu-ju-ku">重启数据库</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup       
ORACLE 例程已经启动。

Total System Global Area 8351150080 bytes
Fixed Size                  2161272 bytes
Variable Size            7449085320 bytes
Database Buffers          872415232 bytes
Redo Buffers               27488256 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-01578,ORA-01110</title>
    <url>/2010/09/28/oracle_troubleshoot_ora_01578_ora_01110/</url>
    <content><![CDATA[<h1 id="ora-01578-he-ora-01110-shu-ju-ku-pi-kuai-de-chu-li">ORA-01578 和 ORA-01110数据库坏块的处理</h1>
<h2 id="biao-xiang">表象</h2>
<p>当Oracle数据库出现坏块时，Oracle会在警告日志文件(alert_SID.log)中记录坏块的信息:</p>
<pre><code class="language-shell">ORA-01578: ORACLE data block corrupted (file # 7, block # ) 
ORA-01110: data file : '/oracle1/oradata/V920/oradata/V816/users01.dbf' 
</code></pre>
<p>其中，file #代表坏块所在数据文件的绝对文件号，block #代表坏块是数据文件上的第几个数据块。出现这种情况时，应该首先检查是否是硬件及操作系统上的故障导致Oracle数据库出现坏块。在排除了数据库以外的原因后，再对发生坏块的数据库对象进行处理。</p>
<h2 id="jie-jue-guo-cheng">解决过程</h2>
<p>步骤一、确定发生坏块的数据库对象</p>
<p>以下为引用的内容：</p>
<pre><code class="language-shell">SELECT tablespace_name, segment_type, owner, segment_name FROM dba_extents 
WHERE file_id = 1
AND block_id  between block_id AND block_id+blocks-1;
</code></pre>
<p>步骤二、确立修复方法</p>
<p>如果发生坏块的对象是一个索引，那么可以直接把索引DROP掉后，再根据表里的记录进行重建；</p>
<p>如果发生坏块的表的记录可以根据其它表的记录生成的话，那么可以直接把这个表DROP掉后重建；</p>
<p>如果有数据库的备份，则恢复数据库的方法来进行修复；</p>
<p>如果表里的记录没有其它办法恢复，那么坏块上的记录就丢失了，只能把表中其它数据块上的记录取出来，然后对这个表进行重建。</p>
<p>步骤三、找出坏块</p>
<p>用Oracle提供的DBMS_REPAIR包标记出坏块:</p>
<pre><code class="language-shell">exec DBMS_REPAIR.SKIP_CORRUPT_BLOCKS(' ',''); 
</code></pre>
<p>步骤四、备份表</p>
<p>使用Create table as select命令将表中其它块上的记录保存到另一张表上以下为引用的内容：</p>
<pre><code class="language-shell">create table corrupt_table_bak as select * from corrupt_table; 
</code></pre>
<p>步骤五、删除旧表</p>
<p>用DROP TABLE命令删除有坏块的表以下为引用的内容：</p>
<p><code>drop table corrup_tatble;  </code></p>
<p>步骤六、重命名表</p>
<p>用alter table rename命令恢复原来的表以下为引用的内容：</p>
<p><code>alter table corrupt_table_bak rename to corrupt_table; </code></p>
<p>步骤七、创建索引等</p>
<p>如果表上存在索引，则要重建表上的索引。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle管理篇之几种name</title>
    <url>/2010/10/17/oracle_name/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在修改数据名、修改数据库实例名等操作过程中，需要清楚几种name。</p>
<p>本章节汇集并概述一下oracle 11g中目前显示的几种name信息。</p>
<h1 id="oracle-zhong-ji-chong-name-xin-xi">Oracle中几种name信息</h1>
<pre><code class="language-shell">oracle@mmsg37:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期日 10月 17 01:37:10 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; show parameter name

NAME                                 TYPE        VALUE
--------------------------  ----------- ------------------------------
db_file_name_convert             string
db_name                             string       mmsgdb
db_unique_name                     string       mmsgdb
global_names                       boolean      FALSE
instance_name                      string       mmsgdb
lock_name_space                    string
log_file_name_convert             string
service_names                       string      mmsgdb
SQL&gt;
</code></pre>
<h1 id="shu-ju-ku-ming">数据库名</h1>
<h2 id="ti-xian-fang-shi-db-name">体现方式db_name</h2>
<p>数据库名就是一个数据库的标识，具有唯一性，如果一个机器上安装多个数据库，每个数据库名均不同。在数据库安装完成或者创建完成之后，db_name写入参数文件中：<br>
*.db_name=‘mmsgdb’</p>
<p>在创建数据库时就应该考虑好数据库名，在创建完数据库之后，可以修改数据库名，不过在此之前需要修改二进制的控制文件。一般的不建议修改数据库名。</p>
<h2 id="shu-ju-ku-ming-de-zuo-yong">数据库名的作用</h2>
<p>数据库名是在安装数据库、创建新的数据库、创建数据库控制文件、修改数据结构、备份与恢复数据库时都需要使用到的。</p>
<p>有很多Oracle安装文件目录是与数据库名相关的，如：</p>
<pre><code class="language-shell">$ORACLE_BASE /oradata/DB_NAME/
$ORACLE_BASE/admin/DB_NAME/
$ORACLE_BASE/cfgtoollogs/dbca/DB_NAME/
$ORACLE_BASE /diag/rdbms/DB_NAME/
</code></pre>
<p>发布变更数据库结构的alter database 语句时，后面指定数据库名，如果数据库名和参数文件中不一致，发布语句报错；</p>
<p>控制文件孙损坏，数据库不能加载控制文件时，在非安装模式下创建控制文件，create controlfile命令中指定数据库名；</p>
<p>数据库的备份与恢复时，也会使用到数据库名。</p>
<h2 id="cha-kan-dang-qian-shu-ju-ku-ming">查看当前数据库名</h2>
<p>方法一：<code>select name from v$database; </code></p>
<p>方法二：<code>show parameter name，找到参数db_name 对应的strings类型值；</code></p>
<p>方法三：直接查看参数文件（spfile文件为二进制，通过strings命令查看）</p>
<h2 id="xiu-gai-shu-ju-ku-ming">修改数据库名</h2>
<p>简介一下在安装了数据库之后修改数据库名的步骤</p>
<h3 id="1-guan-bi-shu-ju-ku">1、关闭数据库</h3>
<h3 id="2-yi-nomount-fang-shi-qi-dong-shu-ju-ku">2、以nomount方式启动数据库</h3>
<h3 id="3-tong-guo-spfile-wen-jian-chuang-jian-pfile-wen-jian">3、通过spfile文件创建pfile文件</h3>
<h3 id="4-xiu-gai-pfile-wen-jian-zhong-db-name-can-shu-zhi">4、修改pfile文件中db_name参数值</h3>
<h3 id="5-chuang-jian-kong-zhi-wen-jian-zhong-zhi-zhong-zuo-ri-zhi-wen-jian-reset-redolog">5、创建控制文件，重置重做日志文件（reset redolog）</h3>
<h3 id="6-zhi-ding-pfile-wen-jian-qi-dong-shu-ju-ku-bing-chuang-jian-spfile-wen-jian">6、指定pfile文件启动数据库，并创建spfile文件</h3>
<h3 id="7-zhong-qi-shu-ju-ku">7、重启数据库</h3>
<h1 id="shu-ju-ku-shi-li-ming">数据库实例名</h1>
<p>据库实例名是用于和操作系统进行联系的标识，就是说数据库和操作系统之间的交互用的是数据库实例名。数据库实例名也写入参数：instance_name。</p>
<p>数据库名可以和实例名相同，也可以不同。一般情况下，数据库名和实例名一一对应，RAC集群环境中，一个数据库名对应多个实例名。</p>
<h2 id="cha-kan-shu-ju-ku-de-shi-li-ming">查看数据库的实例名</h2>
<p>方法一：<code>show parameter instance_name </code></p>
<p>方法二：<code>select instance_name from v$instance；</code></p>
<h2 id="oracle-sid">ORACLE_SID</h2>
<p>数据库实例名和ORACLE_SID，两者虽然都表示为数据库实例名，但仍然有区别。</p>
<p>Instance_name是数据库参数，ORACLE_SID是操作系统环境变量。</p>
<p>ORACLE_SID与操作系统交互，从操作系统的角度访问数据库，需要ORACLE_SID，且ORACLE_SID必须与instance_name一致，否则访问数据库时会报错。</p>
<h2 id="db-domain">db_domain</h2>
<p>db_domain是数据库域名，只要用于分布式数据库中。</p>
<p>比如：国家民政部系统的分布式数据库为：</p>
<p>江苏节点：js.civil<br>
江苏南京节点：nj.js.civil<br>
浙江节点：zj.civil<br>
浙江湖州：hz.zj.civil</p>
<p>当北京需要连接湖州数据库时，发布sqlplus命令，sqlplus user/passwd@name.db_domain。比如：sqlplus mmsg/mmsg@mmsgdb_119.hz.zj.civil, 这就是域名。</p>
<h2 id="cha-kan-yu-ming-xin-xi">查看域名信息</h2>
<p>方法一：select value from v$parameter where name = ‘db_domain’;<br>
方法二 ：show parameter db_domain<br>
方法三：直接查看spfile文件</p>
<h1 id="quan-ju-shu-ju-ku-ming">全局数据库名</h1>
<p>全局数据库名=数据库名+数据库域名，即如前面提到的mmsgdb_119.hz.zj.civil</p>
<p>对应参数global_names。</p>
<h1 id="shu-ju-ku-fu-wu-ming">数据库服务名</h1>
<p>对应参数service_names，从9i开始引入。</p>
<p>如果数据库有全局数据库名，则数据库服务名和数据库服务名一致，如果没有db_domain，则instance_names与数据库名一致。</p>
<h2 id="cha-kan-shu-ju-ku-fu-wu-ming">查看数据库服务名</h2>
<p>方法一：<code>show parameter service_names</code></p>
<p>方法二：<code>select value from v$parameter where name = 'service_name'; </code></p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--变更数据库中数据文件位置</title>
    <url>/2010/10/22/oracle_change_location_of_data_files/</url>
    <content><![CDATA[<h1 id="bian-geng-shu-ju-ku-zhong-shu-ju-wen-jian-wei-zhi">变更数据库中数据文件位置</h1>
<h2 id="gua-yong-tiao-jian">适用条件</h2>
<p>原存放数据库相关文件磁盘分区空间不足。</p>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>操作过程中请慎重，防止破坏数据库。</p>
</li>
</ul>
<h2 id="cao-zuo-guo-cheng">操作过程</h2>
<h3 id="bu-zou-yi-cha-kan-ci-pan-kong-jian-shi-yong-qing-kuang">步骤一、查看磁盘空间使用情况</h3>
<pre><code class="language-shell">mmsg:oracle:mmsgdb &gt; df
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/sda2             20972152   3111364  17860788  15% /
udev                   4091824       156   4091668   1% /dev
/dev/sda6             25172984  22747280   2425704  91% /home
/dev/sda5             15735128   6036132   9698996  39% /opt
shmfs                  4194304        88   4194216   1% /dev/shm
</code></pre>
<h3 id="bu-zou-er-cha-kan-yuan-shu-ju-wen-jian-wei-zhi">步骤二、查看原数据文件位置</h3>
<pre><code class="language-shell">mmsg:oracle:mmsgdb &gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on Fri Oct 22 11:54:54 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; set wrap off
SQL&gt; set linesize 200
SQL&gt; select * from dba_data_files;
FILE_NAME
---------------------------------------------------------------------------------------------------------------------------
/home/oracle/database/mmsgdb/system01.dbf
/home/oracle/database/mmsgdb/sysaux01.dbf
/home/oracle/database/mmsgdb/undotbs01.dbf
/home/oracle/database/mmsgdb/users01.dbf
/opt/oracle/oradata/mmsgdb/ymmdata01
/opt/oracle/oradata/mmsgdb/cyjdata01
/home/oracle/admin/mmsgdb/mmsgdata/chyjdata01
/home/oracle/admin/mmsgdb/mmsgdata/zzzdata01
/home/oracle/admin/mmsgdb/mmsgdata/skkdata01
/home/oracle/admin/mmsgdb/mmsgdata/zhuzhaozhongdata01
/home/oracle/admin/mmsgdb/mmsgdata/ymdata01

FILE_NAME
---------------------------------------------------------------------------------------------------------------------------
/home/oracle/database/mmsgdb/data11.dbf
/home/oracle/database/mmsgdb/data12.dbf
/home/oracle/database/mmsgdb/data13.dbf
/home/oracle/admin/mmsgdb/mmsgdata/lsjdata01
/home/oracle/admin/mmsgdb/mmsgdata/lxb01
/home/oracle/admin/mmsgdb/mmsgdata/lxb03
/opt/oracle/oradata/MMSGRPT/MMSGNODECDR.DBF
/opt/oracle/oradata/MMSGRPT/MMSGNODEDATA.DBF
/opt/oracle/oradata/MMSGRPT/PRESTAT.DBF
/opt/oracle/oradata/MMSGRPT/MMSGSERVERCDR.DBF
/opt/oracle/oradata/MMSGRPT/MMSGSERVERDATA.DBF

FILE_NAME
---------------------------------------------------------------------------------------------------------------------------
/opt/oracle/oradata/mmsgdb/mmsg.dbf

23 rows selected.
</code></pre>
<p>大量数据文件在/home路径下，空间严重不足（93%使用率）</p>
<h3 id="bu-zou-san-wen-jian-lu-jing-geng-gai-cao-zuo-zhi-xing">步骤三、文件路径更改操作执行</h3>
<p>关闭数据库</p>
<pre><code class="language-shell">SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; 
</code></pre>
<p>启动数据库到mount状态</p>
<pre><code class="language-shell">SQL&gt; startup mount
ORACLE instance started.

Total System Global Area  830984192 bytes
Fixed Size                  2148840 bytes
Variable Size             402654744 bytes
Database Buffers          419430400 bytes
Redo Buffers                6750208 bytes
Database mounted. 
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>数据库启动到安装状态后，方能进行数据文件的mv操作，否则在未启动到mount状态或者在open状态或者在shutdown状态时，或导致数据库被破坏。</p>
</li>
<li class="lvl-2">
<p>当在open状态进行cp操作文件到另外一个位置后，启动数据库到mount状态，然后发布alter database命令，可以成功修改，但是，当open数据库的时候，需要进行介质恢复，修改了多少个数据文件的位置，就需要对多少个数据文件进行介质恢复。</p>
</li>
</ul>
<h3 id="bu-zou-si-os-level-mv-shu-ju-wen-jian-dao-zhi-ding-wei-zhi">步骤四、OS Level mv数据文件到指定位置</h3>
<pre><code class="language-shell">mv chyjdata01    /opt/oracle/oradata/mmsgdb/chyjdata01  
mv zzzdata01     /opt/oracle/oradata/mmsgdb/zzzdata01
mv skkdata01     /opt/oracle/oradata/mmsgdb/skkdata01 
mv zhuzhaozhongdata01 /opt/oracle/oradata/mmsgdb/zhuzhaozhongdata01
mv ymdata01     /opt/oracle/oradata/mmsgdb/ymdata01           

mmsg:oracle:mmsgdb &gt; cd /home/oracle/database/mmsgdb/
mmsg:oracle:mmsgdb &gt; mv  data11.dbf data12.dbf data13.dbf   /opt/oracle/oradata/mmsgdb/
mmsg:oracle:mmsgdb &gt; cd /home/oracle/admin/mmsgdb/mmsgdata/
mmsg:oracle:mmsgdb &gt; mv lsjdata01 lxb01 lxb03 /opt/oracle/oradata/mmsgdb/
</code></pre>
<h3 id="bu-zou-wu-zhi-xing-xiu-gai-cao-zuo">步骤五、执行修改操作</h3>
<pre><code class="language-shell">SQL&gt; alter database rename file '/home/oracle/admin/mmsgdb/mmsgdata/chyjdata01','/home/oracle/admin/mmsgdb/mmsgdata/zzzdata01',
  2  '/home/oracle/admin/mmsgdb/mmsgdata/skkdata01','/home/oracle/admin/mmsgdb/mmsgdata/zhuzhaozhongdata01',
  3  '/home/oracle/admin/mmsgdb/mmsgdata/ymdata01'
  4  to '/opt/oracle/oradata/mmsgdb/chyjdata01','/opt/oracle/oradata/mmsgdb/zzzdata01','/opt/oracle/oradata/mmsgdb/skkdata01',
  5  '/opt/oracle/oradata/mmsgdb/zhuzhaozhongdata01','/opt/oracle/oradata/mmsgdb/ymdata01';

Database altered.

SQL&gt; alter database rename file
  2  '/home/oracle/database/mmsgdb/data11.dbf','/home/oracle/database/mmsgdb/data12.dbf',
  3  '/home/oracle/database/mmsgdb/data13.dbf','/home/oracle/admin/mmsgdb/mmsgdata/lsjdata01',
  4  '/home/oracle/admin/mmsgdb/mmsgdata/lxb01','/home/oracle/admin/mmsgdb/mmsgdata/lxb03'
  5  to
  6  '/opt/oracle/oradata/mmsgdb/data11.dbf','/opt/oracle/oradata/mmsgdb/data12.dbf',
  7  '/opt/oracle/oradata/mmsgdb/data13.dbf','/opt/oracle/oradata/mmsgdb/lsjdata01',
  8  '/opt/oracle/oradata/mmsgdb/lxb01','/opt/oracle/oradata/mmsgdb/lxb03';

Database altered.

SQL&gt; alter database open;

Database altered.
</code></pre>
<h3 id="bu-zou-liu-cha-kan-xiu-gai-hou-de-shu-ju-wen-jian-wei-zhi">步骤六、查看修改后的数据文件位置</h3>
<pre><code class="language-shell">SQL&gt; select * from dba_data_files;

FILE_NAME
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
/home/oracle/database/mmsgdb/system01.dbf
/home/oracle/database/mmsgdb/sysaux01.dbf
/home/oracle/database/mmsgdb/undotbs01.dbf
/home/oracle/database/mmsgdb/users01.dbf
/opt/oracle/oradata/mmsgdb/ymmdata01
/opt/oracle/oradata/mmsgdb/cyjdata01
/opt/oracle/oradata/mmsgdb/chyjdata01
/opt/oracle/oradata/mmsgdb/zzzdata01
/opt/oracle/oradata/mmsgdb/skkdata01
/opt/oracle/oradata/mmsgdb/zhuzhaozhongdata01
/opt/oracle/oradata/mmsgdb/ymdata01

FILE_NAME
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
/opt/oracle/oradata/mmsgdb/data11.dbf
/opt/oracle/oradata/mmsgdb/data12.dbf
/opt/oracle/oradata/mmsgdb/data13.dbf
/opt/oracle/oradata/mmsgdb/lsjdata01
/opt/oracle/oradata/mmsgdb/lxb01
/opt/oracle/oradata/mmsgdb/lxb03
/opt/oracle/oradata/MMSGRPT/MMSGNODECDR.DBF
/opt/oracle/oradata/MMSGRPT/MMSGNODEDATA.DBF
/opt/oracle/oradata/MMSGRPT/PRESTAT.DBF
/opt/oracle/oradata/MMSGRPT/MMSGSERVERCDR.DBF
/opt/oracle/oradata/MMSGRPT/MMSGSERVERDATA.DBF

FILE_NAME
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
/opt/oracle/oradata/mmsgdb/mmsg.dbf

23 rows selected.
SQL&gt; exit
Disconnected from Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
mmsg:oracle:mmsgdb &gt;
</code></pre>
<h3 id="bu-zou-qi-cha-kan-geng-gai-shu-ju-wen-jian-lu-jing-hou-de-kong-jian-shi-yong-qing-kuang">步骤七、查看更改数据文件路径后的空间使用情况</h3>
<pre><code class="language-shell">256 mmsg [wyz] :/home &gt;df
文件系统               1K-块        已用     可用 已用% 挂载点
/dev/sda2             20972152   3111392  17860760  15% /
udev                   4091824       156   4091668   1% /dev
/dev/sda6             25172984  17642036   7530948  71% /home
/dev/sda5             15735128   9672944   6062184  62% /opt
shmfs                  4194304        88   4194216   1% /dev/shm
</code></pre>
<p>至此，永久性数据库文件路径更改完毕。</p>
<p>至于临时文件的更改位置，操作和永久性文件操作方法一致，或者删除临时文件，重新创建既可，因为临时文件不存放任何数据，仅用于排序操作；对于控制文件，则需要独立创建控制文件或通过控制文件多工方式来进行转移位置，具体操作详见《oracle本地磁盘数据文件更改到lv上》中“变更控制文件位置”部分操作。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle实例与数据库的区别</title>
    <url>/2010/11/18/oracle_instance_db/</url>
    <content><![CDATA[<h1 id="oracle-shi-li-yu-shu-ju-ku-de-qu-bie">oracle实例与数据库的区别</h1>
<p>ORACLE实例 = 进程 + 进程所使用的内存(SGA)</p>
<p>实例是一个临时性的东西，你也可以认为它代表了数据库某一时刻的状态！</p>
<p>数据库 = 重做文件 + 控制文件 + 数据文件 + 临时文件</p>
<p>数据库是永久的，是一个文件的集合。</p>
<h1 id="oracle-shi-li-he-shu-ju-ku-zhi-jian-de-guan-xi">ORACLE实例和数据库之间的关系</h1>
<p>1、临时性和永久性</p>
<p>2、实例可以在没有数据文件的情况下单独启动 startup nomount , 通常没什么意义</p>
<p>3、个实例在其生存期内只能装载(alter database mount)和打开(alter database open)一个数据库</p>
<p>4、一个数据库可被许多实例同时装载和打开(即RAC)，RAC环境中实例的作用能够得到充分的体现</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--控制文件损坏如何恢复</title>
    <url>/2010/12/24/oracle_troubleshoot_controll_file_recoery/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍控制文件的损坏与恢复操作方法，控制文件的损坏分为损坏部分控制文件和全部控制文件损坏。</p>
<h1 id="bu-fen-kong-zhi-wen-jian-sun-pi-de-hui-fu">部分控制文件损坏的恢复</h1>
<p>损坏部分控制文件，只要还有其他的可用的控制文件，在关闭数据库情况下，将可用的控制文件拷贝并重命名即可。</p>
<p>具体操作如下：</p>
<h2 id="bu-zou-yi-qi-dong-shu-ju-ku-bao-cuo">步骤一  启动数据库报错</h2>
<pre><code class="language-shell">SQL&gt; alter session set nls_language = american;

Session altered.

SQL&gt; shutdown immediate
ORA-01507: database not mounted


ORACLE instance shut down.
SQL&gt; startup
ORACLE instance started.

Total System Global Area 6747725824 bytes
Fixed Size                  2160312 bytes
Variable Size            4362078536 bytes
Database Buffers         2348810240 bytes
Redo Buffers               34676736 bytes
ORA-00205: ?????????, ??????, ???????


SQL&gt;
</code></pre>
<h2 id="bu-zou-er-cha-kan-cuo-wu-ma">步骤二  查看错误码</h2>
<pre><code class="language-shell">oracle@mmsg02:~&gt; oerr ora 00205
00205, 00000, "error in identifying control file, check alert log for more info"
// *Cause:  The system could not find a control file of the specified name and
//         size.
// *Action: Check that ALL control files are online and that they are the same
//         files that the system created at cold start time.
</code></pre>
<h2 id="bu-zou-san-cha-kan-trace-ri-zhi-huo-qu-geng-xiang-xi-xin-xi">步骤三  查看trace日志，获取更详细信息</h2>
<pre><code class="language-shell">oracle@mmsg02:~/diag/rdbms/infoxdb/infoxdb/alert&gt; vi /home/oracle/diag/rdbms/infoxdb/infoxdb/trace/infoxdb_m000_2951.trc

Trace file /home/oracle/diag/rdbms/infoxdb/infoxdb/trace/infoxdb_m000_2951.trc
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options
ORACLE_HOME = /home/oracle/product/11g/db
System name:    Linux
Node name:      mmsg02
Release:        2.6.16.46-0.12-smp
Version:        #1 SMP Thu May 17 14:00:09 UTC 2007
Machine:        x86_64
Instance name: infoxdb
Redo thread mounted by this instance: 0 &lt;none&gt;
Oracle process number: 19
Unix process pid: 2951, image: oracle@mmsg02 (m000)


*** 2010-12-24 12:25:25.526
*** SESSION ID:(648.5) 2010-12-24 12:25:25.526
*** CLIENT ID:() 2010-12-24 12:25:25.526
*** SERVICE NAME:() 2010-12-24 12:25:25.526
*** MODULE NAME:(MMON_SLAVE) 2010-12-24 12:25:25.526
*** ACTION NAME:(DDE async action) 2010-12-24 12:25:25.526

========= Dump for error ORA 202 (no incident) ========
----- DDE Action: 'DB_STRUCTURE_INTEGRITY_CHECK' (Async) -----
DDE: Problem Key 'ORA 202' was flood controlled (0x1) (no incident)
ORA-00202: ????: ''/home/oracle/oradata/infoxdb/control01.ctl''
ORA-27048: skgfifi: ????????
DDE: Problem Key 'ORA 202' was flood controlled (0x1) (no incident)
ORA-00202: ????: ''/home/oracle/oradata/infoxdb/control02.ctl''
ORA-27048: skgfifi: ????????
ORA-00210: ???????????
ORA-00202: ????: ''/home/oracle/oradata/infoxdb/control01.ctl''
ORA-27048: skgfifi: ????????
kcidr_process_controlfile_error:
 IO Check was called but no error was found
ORA-00210: ???????????
ORA-00202: ????: ''/home/oracle/oradata/infoxdb/control02.ctl''
ORA-27048: skgfifi: ????????
ORA-00210: ???????????
ORA-00202: ????: ''/home/oracle/oradata/infoxdb/control01.ctl''
ORA-27048: skgfifi: ????????
kcidr_process_controlfile_error:
 IO Check was called but no error was found
ORA-00210: ???????????
ORA-00202: ????: ''/home/oracle/oradata/infoxdb/control02.ctl''
ORA-27048: skgfifi: ????????
ORA-00210: ???????????
ORA-00202: ????: ''/home/oracle/oradata/infoxdb/control01.ctl''
ORA-27048: skgfifi: ????????
-------------------------------------------------------
</code></pre>
<p>由上可知，控制文件被损坏，被损坏的控制文件分别是control01.ctl和control02.ctl</p>
<h2 id="bu-zou-si-jian-cha-shi-fou-you-ke-yong-de-kong-zhi-wen-jian">步骤四  检查是否有可用的控制文件</h2>
<p>这里由于日志未报控制文件control03.ctl出错，可以推断控制文件3是好的，也可以检查一下：</p>
<pre><code class="language-shell">oracle@mmsg02:~/oradata/infoxdb&gt; dbv file=control03.ctl  blocksize=16384

DBVERIFY: Release 11.1.0.7.0 - Production on 星期五 12月 24 12:33:39 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

DBVERIFY - 开始验证: FILE = /home/oracle/oradata/infoxdb/control03.ctl


DBVERIFY - 验证完成

检查的页总数: 602
处理的页总数 (数据): 0
失败的页总数 (数据): 0
处理的页总数 (索引): 0
失败的页总数 (索引): 0
处理的页总数 (其它): 40
处理的总页数 (段)  : 0
失败的总页数 (段)  : 0
空的页总数: 562
标记为损坏的总页数: 0
流入的页总数: 0
加密的总页数        : 0
最高块 SCN            : 5771 (65535.5771)
oracle@mmsg02:~/oradata/infoxdb&gt; 
oracle@mmsg02:~/oradata/infoxdb&gt; dbv file=control02.ctl  blocksize=16384

DBVERIFY: Release 11.1.0.7.0 - Production on 星期五 12月 24 12:33:44 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


DBV-00107: 未知标头格式 (11) (201326603)
oracle@mmsg02:~/oradata/infoxdb&gt; dbv file=control01.ctl  blocksize=16384

DBVERIFY: Release 11.1.0.7.0 - Production on 星期五 12月 24 12:33:53 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


DBV-00107: 未知标头格式 (11) (201326603)
dbv检查控制文件1和2，发现控制文件1和2被损坏，和日志正好吻合。
</code></pre>
<h2 id="bu-zou-wu-ti-huan-bei-sun-pi-de-kong-zhi-wen-jian-bing-qi-dong-shu-ju-ku">步骤五  替换被损坏的控制文件，并启动数据库</h2>
<pre><code class="language-shell">SQL&gt; shutdown immediate
ORA-01507: database not mounted


ORACLE instance shut down.
SQL&gt; host
oracle@mmsg02:~&gt; cd oradata/infoxdb/
oracle@mmsg02:~/oradata/infoxdb&gt; mv control01.ctl bak_control01.ctl
oracle@mmsg02:~/oradata/infoxdb&gt; mv control02.ctl bak_control02.ctl
oracle@mmsg02:~/oradata/infoxdb&gt; cp control03.ctl control01.ctl
oracle@mmsg02:~/oradata/infoxdb&gt; cp control03.ctl control02.ctl
oracle@mmsg02:~/oradata/infoxdb&gt; l
total 6233266
drwxrwxrwx 2 oracle oinstall        616 Dec 24 12:35 ./
drwxrwxrwx 3 oracle oinstall         72 Dec 19 19:37 ../
-rw-r----- 1 oracle oinstall 1048584192 Dec 18 11:17 INFOX_GNSROUTE_DATA.dbf
-rw-r----- 1 oracle oinstall    9879552 Dec 23 22:16 bak_control01.ctl
-rw-r----- 1 oracle oinstall    9879552 Dec 23 22:16 bak_control02.ctl
-rw-r----- 1 oracle oinstall    9879552 Dec 24 12:34 control01.ctl
-rw-r----- 1 oracle oinstall    9879552 Dec 24 12:35 control02.ctl
-rw-r----- 1 oracle oinstall    9879552 Dec 23 22:16 control03.ctl
-rw-r----- 1 oracle oinstall  209723392 Dec 23 22:15 data20
-rw-r----- 1 oracle oinstall  209723392 Dec 23 22:05 data21
-rw-r----- 1 oracle oinstall  209723392 Dec 23 22:05 data22
-rw-r----- 1 oracle oinstall   31465472 Dec 22 16:11 data23
-rw-r----- 1 oracle oinstall   52429312 Dec 23 22:08 redo01.log
-rw-r----- 1 oracle oinstall   52429312 Dec 23 22:16 redo02.log
-rw-r----- 1 oracle oinstall   52429312 Dec 23 21:56 redo03.log
-rw-r----- 1 oracle oinstall  744497152 Dec 23 22:16 sysaux01.dbf
-rw-r----- 1 oracle oinstall 3523223552 Dec 23 22:16 system01.dbf
-rw-r----- 1 oracle oinstall   29368320 Dec 23 22:11 temp01.dbf
-rw-r----- 1 oracle oinstall  214966272 Dec 23 22:16 undotbs01.dbf
-rw-r----- 1 oracle oinstall    5251072 Dec 23 22:05 users01.dbf
oracle@mmsg02:~/oradata/infoxdb&gt; exit
exit

SQL&gt; startup mount
ORACLE instance started.

Total System Global Area 6747725824 bytes
Fixed Size                  2160312 bytes
Variable Size            4362078536 bytes
Database Buffers         2348810240 bytes
Redo Buffers               34676736 bytes
Database mounted.
SQL&gt; alter session set nls_language=american;

Session altered.

SQL&gt; alter database open;

Database altered.

SQL&gt; select * from dba_data_files;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、损失单个控制文件是比较简单的，因为数据库中所有的控制文件都是镜相的，只需要简单的拷贝一个好的就可以了</p>
</li>
<li class="lvl-2">
<p>2、建议镜相控制文件在不同的磁盘上</p>
</li>
<li class="lvl-2">
<p>3、建议多做控制文件的备份，长期保留一份由alter database backup control file to trace产生的控制文件的文本备份</p>
</li>
</ul>
<h1 id="suo-you-kong-zhi-wen-jian-sun-pi-de-hui-fu">所有控制文件损坏的恢复</h1>
<p>损坏所有的控制文件或者人为的删除所有的控制文件，通过备份复制已经不能解决问题，只能重新建立新的控制文件。</p>
<p>使用具有dba权限的用户重新创建新控制文件，需要列出控制文件、数据文件、重做日志文件的路径信息，或者使用alter database backup controlfile to trace中产生的trace日志，修改这段日志脚本，使用该脚本重新创建控制文件。</p>
<p>具体测试步骤如下：</p>
<h2 id="bu-zou-yi-alter-database-backup-controlfile-to-trace">步骤一 alter database backup controlfile to trace</h2>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期三 3月 9 09:05:25 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; alter database backup controlfile to trace;

数据库已更改。

SQL&gt; 
</code></pre>
<h2 id="bu-zou-er-cha-kan-alter-he-trace-ri-zhi">步骤二 查看alter 和trace日志</h2>
<pre><code class="language-shell">&lt;msg time='2011-03-09T09:06:22.712+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='sqlplus@mmsc103 (TNS V1-V3)' pid='12477'&gt;
 &lt;txt&gt;Backup controlfile written to trace file /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_ora_12477.trc
 &lt;/txt&gt;


oracle@mmsc103:~/diag/rdbms/mmsgdb/mmsgdb/alert&gt; more /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_ora_12477.trc
Trace file /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_ora_12477.trc
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
ORACLE_HOME = /opt/oracle/product/11g
System name:    Linux
Node name:      mmsc103
Release:        2.6.16.46-0.12-smp
Version:        #1 SMP Thu May 17 14:00:09 UTC 2007
Machine:        x86_64
Instance name: mmsgdb
Redo thread mounted by this instance: 1
Oracle process number: 38
Unix process pid: 12477, image: oracle@mmsc103 (TNS V1-V3)

*** 2011-03-09 09:06:22.710
*** SESSION ID:(285.20924) 2011-03-09 09:06:22.710
*** CLIENT ID:() 2011-03-09 09:06:22.710
*** SERVICE NAME:(SYS$USERS) 2011-03-09 09:06:22.710
*** MODULE NAME:(sqlplus@mmsc103 (TNS V1-V3)) 2011-03-09 09:06:22.710
*** ACTION NAME:() 2011-03-09 09:06:22.710
 
-- The following are current System-scope REDO Log Archival related
-- parameters and can be included in the database initialization file.
--
-- LOG_ARCHIVE_DEST=''
-- LOG_ARCHIVE_DUPLEX_DEST=''
--
-- LOG_ARCHIVE_FORMAT=%t_%s_%r.dbf
--
-- DB_UNIQUE_NAME="mmsgdb"
--
-- LOG_ARCHIVE_CONFIG='SEND, RECEIVE, NODG_CONFIG'
-- LOG_ARCHIVE_MAX_PROCESSES=4
-- STANDBY_FILE_MANAGEMENT=MANUAL
-- STANDBY_ARCHIVE_DEST=?/dbs/arch
-- FAL_CLIENT=''
-- FAL_SERVER=''
--
-- LOG_ARCHIVE_DEST_10='LOCATION=USE_DB_RECOVERY_FILE_DEST'
-- LOG_ARCHIVE_DEST_10='OPTIONAL REOPEN=300 NODELAY'
-- LOG_ARCHIVE_DEST_10='ARCH NOAFFIRM NOEXPEDITE NOVERIFY SYNC'
-- LOG_ARCHIVE_DEST_10='REGISTER NOALTERNATE NODEPENDENCY'
-- LOG_ARCHIVE_DEST_10='NOMAX_FAILURE NOQUOTA_SIZE NOQUOTA_USED NODB_UNIQUE_NAME'
-- LOG_ARCHIVE_DEST_10='VALID_FOR=(PRIMARY_ROLE,ONLINE_LOGFILES)'
-- LOG_ARCHIVE_DEST_STATE_10=ENABLE
--
-- LOG_ARCHIVE_DEST_1='LOCATION=/opt/oracle/archivelog'
-- LOG_ARCHIVE_DEST_1='OPTIONAL REOPEN=300 NODELAY'
-- LOG_ARCHIVE_DEST_1='ARCH NOAFFIRM NOEXPEDITE NOVERIFY SYNC'
-- LOG_ARCHIVE_DEST_1='REGISTER NOALTERNATE NODEPENDENCY'
-- LOG_ARCHIVE_DEST_1='NOMAX_FAILURE NOQUOTA_SIZE NOQUOTA_USED NODB_UNIQUE_NAME'
-- LOG_ARCHIVE_DEST_1='VALID_FOR=(PRIMARY_ROLE,ONLINE_LOGFILES)'
-- LOG_ARCHIVE_DEST_STATE_1=ENABLE
--
-- Below are two sets of SQL statements, each of which creates a new
-- control file and uses it to open the database. The first set opens
-- the database with the NORESETLOGS option and should be used only if
-- the current versions of all online logs are available. The second
-- set opens the database with the RESETLOGS option and should be used
-- if online logs are unavailable.
-- The appropriate set of statements can be copied from the trace into
-- a script file, edited as necessary, and executed when there is a
-- need to re-create the control file.
--
--     Set #1. NORESETLOGS case
--
-- The following commands will create a new control file and use it
-- to open the database.
-- Data used by Recovery Manager will be lost.
-- Additional logs may be required for media recovery of offline
-- Use this only if the current versions of all online logs are
-- available.
-- After mounting the created controlfile, the following SQL
-- statement will place the database in the appropriate
-- protection mode:
--  ALTER DATABASE SET STANDBY DATABASE TO MAXIMIZE PERFORMANCE
STARTUP NOMOUNT
CREATE CONTROLFILE REUSE DATABASE "MMSGDB" NORESETLOGS  ARCHIVELOG
    MAXLOGFILES 16
    MAXLOGMEMBERS 3
    MAXDATAFILES 100
    MAXINSTANCES 8
    MAXLOGHISTORY 292
LOGFILE
  GROUP 1 '/opt/oracle/oradata/mmsgdb/redo01.log'  SIZE 50M,
  GROUP 2 '/opt/oracle/oradata/mmsgdb/redo02.log'  SIZE 50M,
  GROUP 3 '/opt/oracle/oradata/mmsgdb/redo03.log'  SIZE 50M
-- STANDBY LOGFILE
DATAFILE
  '/opt/oracle/oradata/mmsgdb/system01.dbf',
  '/opt/oracle/oradata/mmsgdb/sysaux01.dbf',
  '/opt/oracle/oradata/mmsgdb/undotbs01.dbf',
  '/opt/oracle/oradata/mmsgdb/users01.dbf',
  '/opt/oracle/oradata/mmsgdb/mmsgdata01',
  '/opt/oracle/oradata/mmsgdb/rman_data.dbf'
CHARACTER SET ZHS16GBK
;
-- Configure RMAN configuration record 1
VARIABLE RECNO NUMBER;
EXECUTE :RECNO := SYS.DBMS_BACKUP_RESTORE.SETCONFIG('CONTROLFILE AUTOBACKUP','ON');
-- Configure RMAN configuration record 2
VARIABLE RECNO NUMBER;
EXECUTE :RECNO := SYS.DBMS_BACKUP_RESTORE.SETCONFIG('RETENTION POLICY','TO RECOVERY WINDOW OF 10 DAYS');
-- Commands to re-create incarnation table
-- Below log names MUST be changed to existing filenames on
-- disk. Any one log file from each branch can be used to
-- re-create incarnation records.
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- Recovery is required if any of the datafiles are restored backups,
-- or if the last shutdown was not normal or immediate.
RECOVER DATABASE
-- All logs need archiving and a log switch is needed.
ALTER SYSTEM ARCHIVE LOG ALL;
-- Database can now be opened normally.
ALTER DATABASE OPEN;
-- Commands to add tempfiles to temporary tablespaces.
-- Online tempfiles have complete space information.
-- Other tempfiles may require adjustment.
ALTER TABLESPACE TEMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/temp01.dbf'
     SIZE 20971520  REUSE AUTOEXTEND ON NEXT 655360  MAXSIZE 32767M;
ALTER TABLESPACE MMSG_TMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/mmsgdata02'
     SIZE 524288000  REUSE AUTOEXTEND OFF;
ALTER TABLESPACE RMAN_TMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/rman_tmp.dbf'
     SIZE 20971520  REUSE AUTOEXTEND OFF;
-- End of tempfile additions.
--
--     Set #2. RESETLOGS case
--
-- The following commands will create a new control file and use it
-- to open the database.
-- Data used by Recovery Manager will be lost.
-- The contents of online logs will be lost and all backups will
-- be invalidated. Use this only if online logs are damaged.
-- After mounting the created controlfile, the following SQL
-- statement will place the database in the appropriate
-- protection mode:
--  ALTER DATABASE SET STANDBY DATABASE TO MAXIMIZE PERFORMANCE
STARTUP NOMOUNT
CREATE CONTROLFILE REUSE DATABASE "MMSGDB" RESETLOGS  ARCHIVELOG
    MAXLOGFILES 16
    MAXLOGMEMBERS 3
    MAXDATAFILES 100
    MAXINSTANCES 8
    MAXLOGHISTORY 292
LOGFILE
  GROUP 1 '/opt/oracle/oradata/mmsgdb/redo01.log'  SIZE 50M,
  GROUP 2 '/opt/oracle/oradata/mmsgdb/redo02.log'  SIZE 50M,
  GROUP 3 '/opt/oracle/oradata/mmsgdb/redo03.log'  SIZE 50M
-- STANDBY LOGFILE
DATAFILE
  '/opt/oracle/oradata/mmsgdb/system01.dbf',
  '/opt/oracle/oradata/mmsgdb/sysaux01.dbf',
  '/opt/oracle/oradata/mmsgdb/undotbs01.dbf',
  '/opt/oracle/oradata/mmsgdb/users01.dbf',
  '/opt/oracle/oradata/mmsgdb/mmsgdata01',
  '/opt/oracle/oradata/mmsgdb/rman_data.dbf'
CHARACTER SET ZHS16GBK
;
-- Configure RMAN configuration record 1
VARIABLE RECNO NUMBER;
EXECUTE :RECNO := SYS.DBMS_BACKUP_RESTORE.SETCONFIG('CONTROLFILE AUTOBACKUP','ON');
-- Configure RMAN configuration record 2
VARIABLE RECNO NUMBER;
EXECUTE :RECNO := SYS.DBMS_BACKUP_RESTORE.SETCONFIG('RETENTION POLICY','TO RECOVERY WINDOW OF 10 DAYS');
-- Commands to re-create incarnation table
-- Below log names MUST be changed to existing filenames on
-- disk. Any one log file from each branch can be used to
-- re-create incarnation records.
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- Recovery is required if any of the datafiles are restored backups,
-- or if the last shutdown was not normal or immediate.
RECOVER DATABASE USING BACKUP CONTROLFILE
-- Database can now be opened zeroing the online logs.
ALTER DATABASE OPEN RESETLOGS;
-- Commands to add tempfiles to temporary tablespaces.
-- Online tempfiles have complete space information.
-- Other tempfiles may require adjustment.
ALTER TABLESPACE TEMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/temp01.dbf'
     SIZE 20971520  REUSE AUTOEXTEND ON NEXT 655360  MAXSIZE 32767M;
ALTER TABLESPACE MMSG_TMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/mmsgdata02'
     SIZE 524288000  REUSE AUTOEXTEND OFF;
ALTER TABLESPACE RMAN_TMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/rman_tmp.dbf'
     SIZE 20971520  REUSE AUTOEXTEND OFF;
-- End of tempfile additions.
--
</code></pre>
<h2 id="bu-zou-san-mo-ni-kong-zhi-wen-jian-quan-bu-diu-shi">步骤三 模拟控制文件全部丢失</h2>
<pre><code class="language-shell">oracle@mmsc103:~&gt; cd oradata/mmsgdb/
oracle@mmsc103:~/oradata/mmsgdb&gt; l
total 2268880
drwxr-x--- 2 oracle oinstall       4096 2011-03-08 18:21 ./
drwxr-x--- 3 oracle oinstall       4096 2011-03-03 18:20 ../
-rw-r----- 1 oracle oinstall    9912320 2011-03-09 09:11 control01.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-09 09:11 control02.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-09 09:11 control03.ctl
-rw-r----- 1 oracle oinstall 1048584192 2011-03-09 09:11 mmsgdata01
-rw-r----- 1 oracle oinstall  524296192 2011-03-08 18:12 mmsgdata02
-rw-r----- 1 oracle oinstall   52429312 2011-03-09 09:11 redo01.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-08 22:01 redo02.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-09 03:00 redo03.log
-rw-r----- 1 oracle oinstall  209723392 2011-03-09 09:11 rman_data.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-08 18:12 rman_tmp.dbf
-rw-r----- 1 oracle oinstall  300621824 2011-03-09 09:11 sysaux01.dbf
-rw-r----- 1 oracle oinstall  356524032 2011-03-09 09:11 system01.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-09 06:28 temp01.dbf
-rw-r----- 1 oracle oinstall  209723392 2011-03-09 09:11 undotbs01.dbf
-rw-r----- 1 oracle oinstall    5251072 2011-03-09 09:11 users01.dbf
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf control0*
oracle@mmsc103:~/oradata/mmsgdb&gt; l
total 2239792
drwxr-x--- 2 oracle oinstall       4096 2011-03-09 09:12 ./
drwxr-x--- 3 oracle oinstall       4096 2011-03-03 18:20 ../
-rw-r----- 1 oracle oinstall 1048584192 2011-03-09 09:11 mmsgdata01
-rw-r----- 1 oracle oinstall  524296192 2011-03-08 18:12 mmsgdata02
-rw-r----- 1 oracle oinstall   52429312 2011-03-09 09:11 redo01.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-08 22:01 redo02.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-09 03:00 redo03.log
-rw-r----- 1 oracle oinstall  209723392 2011-03-09 09:11 rman_data.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-08 18:12 rman_tmp.dbf
-rw-r----- 1 oracle oinstall  300621824 2011-03-09 09:11 sysaux01.dbf
-rw-r----- 1 oracle oinstall  356524032 2011-03-09 09:11 system01.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-09 06:28 temp01.dbf
-rw-r----- 1 oracle oinstall  209723392 2011-03-09 09:11 undotbs01.dbf
-rw-r----- 1 oracle oinstall    5251072 2011-03-09 09:11 users01.dbf
</code></pre>
<h2 id="bu-zou-si-dong-shu-ju-ku-bao-cuo">步骤四  动数据库，报错</h2>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期三 3月 9 09:12:46 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

已连接到空闲例程。

SQL&gt; startup 
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
ORA-00205: ?????????, ??????, ???????
</code></pre>
<h2 id="bu-zou-wu-cha-kan-cuo-wu-ma-he-gen-zong-ri-zhi-huo-qu-xiang-xi-xin-xi">步骤五  查看错误码和跟踪日志，获取详细信息</h2>
<pre><code class="language-shell">SQL&gt; host
oracle@mmsc103:~&gt; oerr ora 00205
00205, 00000, "error in identifying control file, check alert log for more info"
// *Cause:  The system could not find a control file of the specified name and
//         size.
// *Action: Check that ALL control files are online and that they are the same
//         files that the system created at cold start time.
oracle@mmsc103:~&gt;

&lt;msg time='2011-03-09T09:12:51.555+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='' pid='20849'&gt;
 &lt;txt&gt;ORA-00210: ???????????
ORA-00202: ????: &amp;apos;&amp;apos;/opt/oracle/oradata/mmsgdb/control03.ctl&amp;apos;&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
ORA-00210: ???????????
ORA-00202: ????: &amp;apos;&amp;apos;/opt/oracle/oradata/mmsgdb/control02.ctl&amp;apos;&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
ORA-00210: ???????????
ORA-00202: ????: &amp;apos;&amp;apos;/opt/oracle/oradata/mmsgdb/control01.ctl&amp;apos;&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
 &lt;/txt&gt;
&lt;/msg&gt; 
</code></pre>
<h2 id="bu-zou-liu-zhong-jian-shu-ju-ku-kong-zhi-wen-jian">步骤六  重建数据库控制文件</h2>
<h3 id="xiu-gai-trace-ri-zhi-zhong-chuang-jian-kong-zhi-wen-jian-bu-fen-nei-rong">修改trace日志中创建控制文件部分内容</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; more control.sql 
STARTUP NOMOUNT
CREATE CONTROLFILE REUSE DATABASE "MMSGDB" NORESETLOGS  ARCHIVELOG
    MAXLOGFILES 16
    MAXLOGMEMBERS 3
    MAXDATAFILES 100
    MAXINSTANCES 8
    MAXLOGHISTORY 292
LOGFILE
  GROUP 1 '/opt/oracle/oradata/mmsgdb/redo01.log'  SIZE 50M,
  GROUP 2 '/opt/oracle/oradata/mmsgdb/redo02.log'  SIZE 50M,
  GROUP 3 '/opt/oracle/oradata/mmsgdb/redo03.log'  SIZE 50M
-- STANDBY LOGFILE
DATAFILE
  '/opt/oracle/oradata/mmsgdb/system01.dbf',
  '/opt/oracle/oradata/mmsgdb/sysaux01.dbf',
  '/opt/oracle/oradata/mmsgdb/undotbs01.dbf',
  '/opt/oracle/oradata/mmsgdb/users01.dbf',
  '/opt/oracle/oradata/mmsgdb/mmsgdata01',
  '/opt/oracle/oradata/mmsgdb/rman_data.dbf'
CHARACTER SET ZHS16GBK
;
-- Configure RMAN configuration record 1
VARIABLE RECNO NUMBER;
EXECUTE :RECNO := SYS.DBMS_BACKUP_RESTORE.SETCONFIG('CONTROLFILE AUTOBACKUP','ON');
-- Configure RMAN configuration record 2
VARIABLE RECNO NUMBER;
EXECUTE :RECNO := SYS.DBMS_BACKUP_RESTORE.SETCONFIG('RETENTION POLICY','TO RECOVERY WINDOW OF 10 DAYS');
-- Commands to re-create incarnation table
-- Below log names MUST be changed to existing filenames on
-- disk. Any one log file from each branch can be used to
-- re-create incarnation records.
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- ALTER DATABASE REGISTER LOGFILE '/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_09/o1_mf_1_1_%u_.arc';
-- Recovery is required if any of the datafiles are restored backups,
-- or if the last shutdown was not normal or immediate.
RECOVER DATABASE
-- All logs need archiving and a log switch is needed.
ALTER SYSTEM ARCHIVE LOG ALL;
-- Database can now be opened normally.
ALTER DATABASE OPEN;
-- Commands to add tempfiles to temporary tablespaces.
-- Online tempfiles have complete space information.
-- Other tempfiles may require adjustment.
ALTER TABLESPACE TEMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/temp01.dbf'
     SIZE 20971520  REUSE AUTOEXTEND ON NEXT 655360  MAXSIZE 32767M;
ALTER TABLESPACE MMSG_TMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/mmsgdata02'
     SIZE 524288000  REUSE AUTOEXTEND OFF;
ALTER TABLESPACE RMAN_TMP ADD TEMPFILE '/opt/oracle/oradata/mmsgdb/rman_tmp.dbf'
     SIZE 20971520  REUSE AUTOEXTEND OFF;
</code></pre>
<h3 id="zhong-xin-chuang-jian-kong-zhi-wen-jian">重新创建控制文件</h3>
<p>关闭数据库，修改trace文件中创建control文件部分</p>
<pre><code class="language-shell">SQL&gt; @control.sql
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes


控制文件已创建。


PL/SQL 过程已成功完成。


PL/SQL 过程已成功完成。

ORA-00283: ??????????
ORA-00264: ?????



系统已更改。


数据库已更改。


表空间已更改。


表空间已更改。


表空间已更改。

SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt; 
</code></pre>
<p>如果没有trace日志文件中记录的重新创建控制文件部分内容，可以手工书写重建控制文件的sql脚本，内容可参考上面的trace日志中内容。</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、重建控制文件用于恢复全部数据文件的损坏，需要注意其书写的正确性，保证包含了所有的数据文件与联机日志</p>
</li>
<li class="lvl-2">
<p>2、经常有这样一种情况，因为一个磁盘损坏，我们不能再恢复(store)数据文件到这个磁盘，因此在store到另外一个盘的时候，我们就必须重新创建控制文件，用于识别这个新的数据文件，这里也可以用这种方法用于恢复;</p>
</li>
<li class="lvl-2">
<p>3、如果数据库运行在归档方式下，有可用的控制文件的备份(CONFIGURE CONTROLFILE AUTOBACKUP ON)，则可以使用restore controlfile from ‘备份的控制文件路径+文件名’来完成控制文件的恢复操作，详细操作可参考本文中“控制文件的恢复”内容。</p>
</li>
</ul>
<h1 id="sun-pi-lin-shi-shu-ju-wen-jian-de-hui-fu-fang-fa">损坏临时数据文件的恢复方法</h1>
<p>临时数据文件的恢复是比较简单的，因为临时文件中不涉及到其它的有用的数据，仅用来排序，所以可以删除后重建。</p>
<h4 id="1-guan-bi-shu-ju-ku">1、关闭数据库</h4>
<pre><code class="language-shell">SQL&gt;shutdown immediate
</code></pre>
<h4 id="2-shan-chu-lin-shi-shu-ju-wen-jian-mo-ni-mei-ti-shi-bai">2、删除临时数据文件，模拟媒体失败</h4>
<h4 id="3-qi-dong-shu-ju-ku-jian-ce-dao-wen-jian-cuo-wu">3、启动数据库，检测到文件错误</h4>
<h4 id="4-tuo-ji-gai-shu-ju-wen-jian">4、脱机该数据文件</h4>
<pre><code class="language-shell">SQL&gt;alter database datafile ‘全路径+文件名’ offline drop;
</code></pre>
<h4 id="5-da-kai-shu-ju-ku">5、打开数据库</h4>
<pre><code class="language-shell">SQL&gt;alter database open
</code></pre>
<h4 id="6-shan-chu-gai-lin-shi-biao-kong-jian">6、删除该临时表空间</h4>
<pre><code class="language-shell">SQL&gt;drop tablespace temp(或其它临时表空间名称) including contents and datafiles;
</code></pre>
<h4 id="7-zhong-xin-chuang-jian-gai-biao-kong-jian-bing-zhong-xin-fen-pei-gei-yong-hu">7、重新创建该表空间，并重新分配给用户</h4>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、临时数据文件是非重要文件，不保存永久数据，可以随时删除重建，不影响数据库的数据安全</p>
</li>
<li class="lvl-2">
<p>2、如果重新建立以后，别忘了重新分配给用户。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle管理篇之启动与关闭</title>
    <url>/2011/02/03/oracle_startup/</url>
    <content><![CDATA[<h1 id="oracle-qi-dong-de-ji-chong-fang-shi">oracle启动的几种方式</h1>
<h2 id="1-startup-nomount">1、startup nomount</h2>
<p>非安装启动，这种方式启动下可执行：重建控制文件、重建数据库。启动instance，即启动SGA和后台进程，这种启动只需要init.ora文件。</p>
<h2 id="2-startup-mount-dbname">2、startup mount dbname</h2>
<p>安装启动，这种方式启动下可执行：数据库日志归档、数据库恢复、重新命名一些数据库文件，如：系统表空间或日志文件。</p>
<p>执行“nomount”，然后打开控制文件。</p>
<h2 id="3-startup-open-dbname">3、startup open dbname</h2>
<p>先执行“nomount”，然后执行“mount”，再打开包括Redo log文件在内的所有数据库文件，这种方式下可访问数据库中的数据。</p>
<h2 id="4-startup">4、startup</h2>
<p>startup等于以下三个命令</p>
<pre><code class="language-shell">   startup nomount  
   alter database mount  
   alter database open
</code></pre>
<h2 id="5-startup-restrict">5、startup restrict</h2>
<p>约束启动的选项是restrict，它启动数据库时装入并打开它，但是此时的数据库只能为有特殊权限的数据库管理员使用，一般用户不能联入到该数据库。</p>
<pre><code class="language-shell">SQL&gt;startup restrict
</code></pre>
<p>非特权用户访问时，会出现以下提示：</p>
<pre><code class="language-shell">   ERROR：  
   ORA-01035: ORACLE 只允许具有 RESTRICTED SESSION 权限的用户使用
</code></pre>
<p>一般说来，当用户有create session权限时，可以连入数据库，但对于restrict方式启动的数据库，则只有用户具有restricted session系统权限才允许联入。若要在数据库运行过程中改变这一方式，可用alter system命令。</p>
<pre><code class="language-shell">SQL&gt;alter system disable restricted session;
</code></pre>
<p>也可以先将数据库关闭再重新以非restrict方式启动数据库。</p>
<h2 id="6-startup-force">6、startup force</h2>
<p>强制启动方式，当不能关闭数据库时，可以用startup force来完成数据库的关闭。</p>
<p>该命令等价于：先关闭数据库，再执行正常启动数据库命令。</p>
<h2 id="7-startup-pfile-can-shu-wen-jian-ming">7、startup pfile=参数文件名</h2>
<p>带初始化参数文件的启动方式，先读取参数文件，再按参数文件中的设置启动数据库。例：</p>
<pre><code class="language-shell">startup pfile=’/opt/oracle/product/11g/dbs/mypfile,ora’  
</code></pre>
<h2 id="8-du-zhan-he-gong-xiang-qi-dong">8、独占和共享启动</h2>
<p>独占启动的选项是exclusive，表示只允许一个例程使用该数据库；</p>
<pre><code class="language-shell">startup EXCLUSIVE
</code></pre>
<p>共享启动的参数是shared，表示允许多个例程并行使用该数据库，即将数据库装入多个现场。</p>
<pre><code class="language-shell">startup shared
</code></pre>
<h1 id="ji-chong-guan-bi-fang-shi">几种关闭方式</h1>
<h2 id="1-shutdown-normal">1、shutdown normal</h2>
<p>正常方式关闭数据库。</p>
<p>正常关闭数据库所用的选项是normal，数据库在关闭前将检查所有的连接，并且发出命令后不允许再有新的用户连接，在等待所有连接都断开后再关闭数据库，再次启动数据库不需要任何恢复过程。</p>
<h2 id="2-shutdown-immediate">2、shutdown immediate</h2>
<p>该方式用在某些紧急的情况下，比如通知马上停电，此时需要紧急关闭数据库以应付这些情况。这种方式用的选项是immediate，在这种方式下并不等待所有的用户断开连接再关闭，而是由系统断开连接，然后关闭数据库。</p>
<pre><code class="language-shell">SQL&gt;shutdown immediate;
</code></pre>
<p>一旦执行了这条命令，则将当前正在处理的sql语句马上停止，然后将所有未提交的事务回退，并且不等待当前联入数据库的用户断开连接，而是由系统强行将各个联接断开。在下次启动数据库时要执行恢复动作，不过是由系统自动执行的，用户不必去了解它。</p>
<p>在SVRMGRL中执行shutdown immediate，数据库并不立即关闭,而是在Oracle执行某些清除工作后才关闭（终止会话、释放会话资源），</p>
<p>当使用shutdown不能关闭数据库时，shutdown immediate可以完成数据库关闭的操作。</p>
<h2 id="3-shutdown-abort">3、shutdown abort</h2>
<p>异常关闭选项是abort，此种方式下系统并不做任何检查和断开用户操作以及回退操作，而是直接将数据库现场撤销，这样现场中的数据库数据当然就无效了，数据库自然也就被关掉了。</p>
<pre><code class="language-shell">SQL&gt;shutdown abort;
</code></pre>
<p>以abort方式关闭数据库时只有一行关闭信息表示关闭了数据库现场。以abort方式关闭的数据库再次启动时必须要进行恢复动作，这些恢复操作同样是系统自动来完成的，需要的时间较长。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--表空间--UNDO表空间膨胀</title>
    <url>/2011/02/06/oracle_troubleshoot_undo_tablespace_large/</url>
    <content><![CDATA[<h1 id="undo-biao-kong-jian-guo-da">UNDO表空间过大</h1>
<h2 id="xian-xiang">现象</h2>
<h2 id="cha-kan-undo-biao-kong-jian-ming-cheng">查看UNDO表空间名称</h2>
<pre><code class="language-shell">SQL&gt; show parameter undo_tablespace  

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
undo_tablespace                      string      UNDOTBS1
SQL&gt;
</code></pre>
<h3 id="cha-kan-dang-qian-undo-biao-kong-jian-da-xiao">查看当前UNDO表空间大小</h3>
<pre><code class="language-shell">SQL&gt; select bytes/1024/1024 from dba_data_files where tablespace_name like 'UNDO%';

BYTES/1024/1024
---------------
           5745

SQL&gt;
</code></pre>
<h3 id="jian-cha-undo-segment-zhuang-tai">检查UNDO Segment状态</h3>
<pre><code class="language-shell">SQL&gt; select usn,xacts,rssize/1024/1024/1024,hwmsize/1024/1024/1024,shrinks from v$rollstat order by rssize;

       USN      XACTS RSSIZE/1024/1024/1024 HWMSIZE/1024/1024/1024    SHRINKS
---------- ---------- --------------------- ---------------------- ----------
         0          0            .000358582             .000358582          0
         3          0            .004020691             .030387878         92
         2          0            .004997253             .029411316         80
         9          0            .004997253             .037223816         82
         6          0            .004997253             .027458191         77
         7          0            .004997253             .028434753         85
         1          0            .005973816             .026481628         80
        10          0            .005973816             .028434753         78
         4          0            .006950378             .028434753         84
         8          0            .009880066             .028434753         82
         5          0            .013786316             .028434753         88

11 rows selected.

SQL&gt;
</code></pre>
<p>如果表空间过大，最终将mount点free空间消耗完，oracle最终将因系统空间不足而崩溃。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<h3 id="zhong-xin-chuang-jian-xin-de-undo-biao-kong-jian">重新创建新的UNDO表空间</h3>
<pre><code class="language-shell">create undo tablespace undotbs1 
datafile '/opt/oracle/oradata/mmsgdb/UNDOTBS2.dbf' size 1000m reuse 
autoextend on next 800m maxsize unlimited;
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>一般不建议这么创建，一次性给予undo表空间足够大的空间，并关闭自动增长。</p>
</li>
</ul>
<h3 id="xiu-gai-pfile-wen-jian">修改pfile文件</h3>
<pre><code class="language-shell">SQL&gt; alter system set undo_tablespace=undotbs2 scope=both;
</code></pre>
<h3 id="deng-dai-yuan-undo-biao-kong-jian-suo-you-undo-segment-offlin">等待原UNDO表空间所有UNDO SEGMENT OFFLIN</h3>
<pre><code class="language-shell">SQL&gt; select usn,xacts,rssize/1024/1024/1024,hwmsize/1024/1024/1024,shrinks from v$rollstat order by rssize;
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>创建好新的UNDO表空间后，不能立即删除原有的UNDO表空间，等到所有的回滚段offline或者达到undo_retention设定值后，方可执行drop掉旧的undo表空间。</p>
</li>
</ul>
<h3 id="shan-chu-jiu-de-undo-biao-kong-jian">删除旧的undo表空间</h3>
<pre><code class="language-shell">SQL&gt; drop tablespace undotbs1 including contents and datafiles;
</code></pre>
<h3 id="que-ren-shan-chu-shi-fou-cheng-gong">确认删除是否成功</h3>
<pre><code class="language-shell">SQL&gt;select * from dba_data_files where tablespace_name like ‘UNDO%’;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle Shared Pool与Processes参数的关系</title>
    <url>/2011/02/25/oracle_shared_pool_process/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>大家都知道，我们使用ORACLE数据库时，常常会为实例配置一个processes参数，此参数故名思意，就是设置整个数据库系统可以启动多少个进程(包括系统自己的后台进程)</p>
<p>设置不合理的processes参数值，会导致实例无法启动。此参数还有其它许许多多的含义和作用，影响着数据库系统的运行。</p>
<p>比如，ORACLE在哪里为其分配内存,分配多大内存？此内存信息在ORACLE instance级的作用？为什么processes参数是一个静态参数？</p>
<p>通过本文，相信大家能找到一个的答案。下面是通过一些测试，来回答上述问题。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="ce-shi-huan-jing">测试环境</h2>
<pre><code class="language-shell">OS: SUSE Linux Enterprise Server 10 SP1 (x86_64) Kernel 2.6.16.46-0.12-smp (1)
ORACLE VERSION: Release 11.1.0.6.0
</code></pre>
<h2 id="xiu-gai-processes">修改processes</h2>
<pre><code class="language-shell">SQL&gt; alter system set processes=20000 scope=spfile;

系统已更改。

SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。


oracle@mmsc101:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期五 6月 24 11:17:55 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

已连接到空闲例程。

SQL&gt; startup nomount
ORA-27154: post/wait create failed
ORA-27300: OS system dependent operation:semids_per_proc failed with status: 0
ORA-27301: OS failure message: Error 0
ORA-27302: failure occurred at: sskgpwcr2
ORA-27303: additional information: semids = 132, maxprocs = 20000
SQL&gt;
</code></pre>
<p>从上面的错误说明，oracle会根据processes参数的值在共享池中分配一定数量的内存，参数值越大，分配的内存也越多。</p>
<h2 id="xiu-gai-process">修改process</h2>
<p>修改process为300，重启数据库，查看shared pool  中processes值</p>
<pre><code class="language-shell">SQL&gt; show parameter processes

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
aq_tm_processes                      integer     0
db_writer_processes                  integer     1
gcs_server_processes                 integer     0
global_txn_processes                 integer     1
job_queue_processes                  integer     1000
log_archive_max_processes            integer     4
processes                            integer     300


SQL&gt; select * from v$sgastat where pool='shared pool' and name like '%process%';

POOL         NAME                            BYTES
------------ -------------------------- ----------
shared pool  generic process shared st         456
shared pool  ksb ci process list (each         688
shared pool  process count for each CI         320
shared pool  dia* process descriptor            16
shared pool  ksb cic process list              632
shared pool  Background process state           48
shared pool  process group array             66704
shared pool  ksb process so list               632
shared pool  processes                        2400  --300个进程要在共享池中分配2400字节

已选择9行。
</code></pre>
<p>修改process为100，重启数据库，查看shared pool  中processes值</p>
<pre><code class="language-shell">SQL&gt; alter system set processes = 100 scope=spfile;

系统已更改。
重启数据库后
SQL&gt; show parameter processes 

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
aq_tm_processes                      integer     0
db_writer_processes                  integer     1
gcs_server_processes                 integer     0
global_txn_processes                 integer     1
job_queue_processes                  integer     1000
log_archive_max_processes            integer     4
processes                            integer     100
SQL&gt;

SQL&gt; select * from v$sgastat where pool='shared pool' and name like '%process%';

POOL         NAME                            BYTES
------------ -------------------------- ----------
shared pool  generic process shared st         456
shared pool  ksb ci process list (each         688
shared pool  process count for each CI         320
shared pool  dia* process descriptor            16
shared pool  ksb cic process list              632
shared pool  Background process state           48
shared pool  process group array             66704
shared pool  ksb process so list               632
shared pool  processes                         800  --100个进程要在共享池中分配800字节

已选择9行。
</code></pre>
<p>从上面两次修改processes参数的值，可以看出每个进程将会在shared pool中分配8字节内存，那此8字节信息是什么呢？</p>
<p>我们查看如下的v$process视图</p>
<pre><code class="language-shell">SQL&gt;  desc v$process;
 名称                                      是否为空? 类型
 ----------------------------------------- -------- ----------------------------
 ADDR                                               RAW(8)
 PID                                                NUMBER
 SPID                                               VARCHAR2(24)
 USERNAME                                           VARCHAR2(15)
 SERIAL#                                            NUMBER
 TERMINAL                                           VARCHAR2(30)
 PROGRAM                                            VARCHAR2(48)
 TRACEID                                            VARCHAR2(255)
 TRACEFILE                                          VARCHAR2(513)
 BACKGROUND                                         VARCHAR2(1)
 LATCHWAIT                                          VARCHAR2(16)
 LATCHSPIN                                          VARCHAR2(16)
 PGA_USED_MEM                                       NUMBER
 PGA_ALLOC_MEM                                      NUMBER
 PGA_FREEABLE_MEM                                   NUMBER
 PGA_MAX_MEM                                        NUMBER


SQL&gt; select addr from v$process;

ADDR
----------------
00000000BF4EB598
00000000BF4EC588
00000000BF4ED578
00000000BF4EE568
00000000BF4EF558
00000000BF4F0548
00000000BF4F1538
00000000BF4F2528
00000000BF4F3518
00000000BF4F4508
00000000BF4F54F8

ADDR
----------------
00000000BF4F64E8
00000000BF4F74D8
00000000BF4F84C8
00000000BF4F94B8
00000000BF4FA4A8
00000000BF4FB498
00000000BF4FC488
00000000BF4FD478
00000000BF4FE468
00000000BF4FF458
00000000BF500448

已选择22行。

SQL&gt;
</code></pre>
<p>字段ADDR字段刚好为8字节 ,在共享池中保存process进程的信息很有可能就是其地址信息，知道了其地址，也就知道了PGA在哪里，从PGA里的数据结构就可以知道系统进程号等等之类的东西。PMON进程也是利用此信息，在pmon timer到来之际，通过地址信息检查各数据库服务器进程的状态；</p>
<p>此地址信息也是执行alter system kill session命令的重要纽带。怎样从Shared Pool到PGA，或者说怎样从PGA到Shared Pool?共享池中保存process进程的信息成了关键性的作用。</p>
<p>顺便提一句，在ORACLE 9i之上，共享池划分了很多的subpool,在实例启动时，oracle根据processes参数的值，只会挑选其中一个子池来保留此信息</p>
<p>为什么processes参数是一个静态参数？这跟ORACLE关于此参数的内存申请很有关系，个人猜想，此控制结构的信息是以数组的方式保存的，大家都知道数组结构是不能动态扩大的，不像队列或者线性链表。</p>
<p>db_cache与pga之间走的是数据流；shared pool保存的一些信息，可以看成了对pga的控制流。</p>
<p>刚才查看了64位AIX 6.1操作系统</p>
<pre><code class="language-shell">SQL&gt; show parameter processes

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
aq_tm_processes                      integer     0
db_writer_processes                  integer     2
gcs_server_processes                 integer     0
global_txn_processes                 integer     1
job_queue_processes                  integer     1000
log_archive_max_processes            integer     4
processes                            integer     150
SQL&gt; select * from v$sgastat where pool='shared pool' and name like '%process%';

POOL         NAME                            BYTES
------------ -------------------------- ----------
shared pool  ksb ci process list (each         688
shared pool  generic process shared st          96
shared pool  processes                        1200
shared pool  dia* process descriptor            16
shared pool  ksb process so list               632
shared pool  process count for each CI         320
shared pool  ksb cic process list              632
shared pool  Background process state           48
shared pool  process group array             66448

已选择9行。
</code></pre>
<p>AIX5.3</p>
<pre><code class="language-shell">% sqlplus "/ as sysdba"

SQL*Plus: Release 9.2.0.8.0 - Production on Fri Jun 24 12:01:48 2011

Copyright (c) 1982, 2002, Oracle Corporation.  All rights reserved.


Connected to:
Oracle9i Enterprise Edition Release 9.2.0.8.0 - 64bit Production
JServer Release 9.2.0.6.0 - Production

SQL&gt;
SQL&gt; show parameter processes

NAME                                 TYPE                   VALUE
------------------------------------ ---------------------- ------------------------------
aq_tm_processes                      integer                1
db_writer_processes                  integer                1
job_queue_processes                  integer                20
log_archive_max_processes            integer                2
processes                            integer                1000

SQL&gt; select * from v$sgastat where pool='shared pool' and name like '%process%';

POOL                   NAME                                                      BYTES
---------------------- ---------------------------------------------------- ----------
shared pool            processes                                               1368000
</code></pre>
<p>oracle11g数据库，AIX6.1系统，为每个进程在共享池中分配8字节；oracle9i数据库，AIX5.3系统每个进程在共享池中分配1368字节，看来这个分配，跟OS，与ORACLE版本都很有关系的。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-32004</title>
    <url>/2011/03/04/oracle_troubleshoot_ora_32004/</url>
    <content><![CDATA[<h1 id="ora-32004-an-li">ORA-32004  案例</h1>
<h2 id="biao-xiang">表象</h2>
<p>启动数据库时，报错误码：ORA-32004</p>
<pre><code class="language-shell">SQL&gt; startup
ORA-32004: obsolete and/or deprecated parameter(s) specified
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt; 
</code></pre>
<p>启动数据库，收到ORA-32004错误码，多是过时的且不在当前系统中使用的参数导致，遇见这类问题，直接reset即可。</p>
<h2 id="yuan-yin">原因</h2>
<p>错误码分析</p>
<pre><code class="language-shell">oracle@mmsc103:~&gt; oerr ora 32004
32004, 00000, "obsolete and/or deprecated parameter(s) specified"
// *Cause:  One or more obsolete and/or parameters were specified in 
//          the SPFILE or the PFILE on the server side.
// *Action: See alert log for a list of parameters that are obsolete.
//          or deprecated. Remove them from the SPFILE or the server 
//          side PFILE.
oracle@mmsc103:~&gt; 
</code></pre>
<p>查看告警日志</p>
<pre><code class="language-shell">&lt;msg time='2011-03-04T10:11:39.436+08:00' org_id='oracle' comp_id='rdbms'
 msg_id='kspdmp:13638:2661745733' type='WARNING' group='system_param'
 level='16' pid='5220'&gt;
 &lt;txt&gt;Deprecated system parameters with specified values:
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2011-03-04T10:11:39.437+08:00' org_id='oracle' comp_id='rdbms'
 msg_id='kspdmp:13644:2633769647' type='WARNING' group='system_param'
 level='16' pid='5220'&gt;
 &lt;txt&gt;  log_archive_start        
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2011-03-04T10:11:39.437+08:00' org_id='oracle' comp_id='rdbms'
 msg_id='kspdmp:13652:3788363585' type='WARNING' group='system_param'
 level='16' pid='5220'&gt;
 &lt;txt&gt;End of deprecated system parameter listing
 &lt;/txt&gt;
&lt;/msg&gt;
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>从spfile文件中清除过时的参数，重启数据库</p>
<pre><code class="language-shell">SQL&gt; alter system reset log_archive_start scope=spfile sid='*';

系统已更改。

SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup       #重启后未报错
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt;
</code></pre>
<p>查看当前版本不再使用的参数信息</p>
<pre><code class="language-shell">select name,description from v$parameter where isdeprecated='TRUE';
</code></pre>
<img class="shadow" src="/img/in-post/oracle-parameter.png" width="600">
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--RMAN常见问题总结</title>
    <url>/2011/03/05/oracle_troubleshoot_rman/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍在使用RMAN过程中，碰到的几个RMAN问题并进行记录/总结。</p>
<h1 id="rman-ming-ling-wu-fan-ying">RMAN命令无反应</h1>
<h2 id="biao-xiang">表象</h2>
<p>RMAN命令输入后终端无反应，一直处于等待状态，且长时间如此</p>
<pre><code class="language-shell">node1:oracle:mmsgdb &gt; rman

</code></pre>
<h2 id="yuan-yin">原    因：</h2>
<p>操作系统也有一个rman命令，这里执行的是操作系统的rman命令了，而非oracle的RMAN命令。</p>
<h2 id="jie-jue-fang-fa">解决方法：</h2>
<p>Oracle用户登陆后，修改环境变量，在.bash_profile或者.profile文件中增加如下信息，重新source一下即可：</p>
<pre><code class="language-shell">export PATH=$ORACLE_HOME:$PATH
</code></pre>
<h1 id="rman-wu-fa-jin-xing-bei-fen-cao-zuo-cha-kan-bei-fen-xin-xi-pei-zhi-xin-xi">RMAN无法进行备份操作/查看备份信息/配置信息</h1>
<h2 id="biao-xiang-1">表象</h2>
<pre><code class="language-shell">oracle@mmsc103:~&gt; rman target/

恢复管理器: Release 11.1.0.6.0 - Production on 星期六 3月 5 09:27:48 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

连接到目标数据库: MMSGDB (DBID=3148145279)

RMAN&gt; connect catalog rman/rman@mmsgdb

连接到恢复目录数据库

RMAN&gt; list backupset;

RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03002: list 命令 (在 03/05/2011 09:28:03 上) 失败
RMAN-06004: 恢复目录数据库发生 ORACLE 错误: RMAN-20001: target database not found in recovery catalog

RMAN&gt; backup database;

启动 backup 于 05-3月 -11
RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03002: backup 命令 (在 03/05/2011 09:28:32 上) 失败
RMAN-03014: 恢复目录的隐式重新同步失败
RMAN-06004: 恢复目录数据库发生 ORACLE 错误: RMAN-20001: 在恢复目录中未找到目标数据库

RMAN&gt; show all;

db_unique_name 为 MMSGDB 的数据库的 RMAN 配置参数为:
RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03002: show 命令 (在 03/05/2011 09:35:28 上) 失败
RMAN-06004: 恢复目录数据库发生 ORACLE 错误: RMAN-20001: 在恢复目录中未找到目标数据库

RMAN&gt;
</code></pre>
<h2 id="yuan-yin-1">原因</h2>
<p>RMAN未注册。</p>
<h2 id="jie-jue-fang-fa-1">解决方法</h2>
<p>注册RMAN:</p>
<pre><code class="language-shell">RMAN&gt; register database;

注册在恢复目录中的数据库
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt; 

RMAN&gt; list backupset;


RMAN&gt; show all;

db_unique_name 为 MMSGDB 的数据库的 RMAN 配置参数为:
CONFIGURE RETENTION POLICY TO REDUNDANCY 1; # default
CONFIGURE BACKUP OPTIMIZATION OFF; # default
CONFIGURE DEFAULT DEVICE TYPE TO DISK; # default
CONFIGURE CONTROLFILE AUTOBACKUP OFF; # default
CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '%F'; # default
CONFIGURE DEVICE TYPE DISK PARALLELISM 1 BACKUP TYPE TO BACKUPSET; # default
CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE MAXSETSIZE TO UNLIMITED; # default
CONFIGURE ENCRYPTION FOR DATABASE OFF; # default
CONFIGURE ENCRYPTION ALGORITHM 'AES128'; # default
CONFIGURE COMPRESSION ALGORITHM 'BZIP2'; # default
CONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # default
CONFIGURE SNAPSHOT CONTROLFILE NAME TO '/opt/oracle/product/11g/dbs/snapcf_mmsgdb.f'; # default

RMAN&gt;
</code></pre>
<h1 id="rman-bei-fen-wen-jian-yi-chang-shan-chu">RMAN备份文件异常删除</h1>
<h2 id="yuan-yin-2">原因</h2>
<p>RMAN备份的文件存放在某个目录下，该文件没有通过rman命令delete删除，而是在操作系统侧执行rm操作，导致再去删除这个备份文件时无法删除掉。</p>
<pre><code class="language-shell">RMAN-06207: 警告: 由于状态不匹配, 所以不能删除 2 对象 (对于 DISK 通道)。
RMAN-06208: 请用 CROSSCHECK 命令修正状态
RMAN-06210: 不匹配对象的列表
RMAN-06211: ==========================
RMAN-06212: 对象类型   文件名/句柄
RMAN-06213: --------------- ---------------------------------------------------
RMAN-06214: Backup Piece    /opt/oracle/rmanbak/db_u%_s%_p%
RMAN-06214: Backup Piece    /opt/oracle/flash_recovery_area/MMSGDB/autobackup/2011_03_05/o1_mf_s_744975873_6q35d3y8_.bkp
</code></pre>
<h2 id="jie-jue-fang-fa-2">解决方法</h2>
<p>使用crosscheck backupset命令检查后再去执行delete操作。</p>
<pre><code class="language-shell">RMAN&gt; list backupset by backup summary;


备份列表
===============
关键字     TY LV S 设备类型 完成时间   段数 副本数 压缩标记
------- -- -- - ----------- ---------- ------- ------- ---------- ---
98      B  F  A DISK        05-3月 -11 1       1       NO         FULL_DB_BAK
113     B  F  A DISK        05-3月 -11 1       1       NO         TAG20110305T094433

RMAN&gt; crosscheck backupset;

使用通道 ORA_DISK_1
交叉校验备份片段: 找到为 'EXPIRED'
备份片段句柄=/opt/oracle/rmanbak/db_u%_s%_p% RECID=1 STAMP=744975858
交叉校验备份片段: 找到为 'EXPIRED'
备份片段句柄=/opt/oracle/flash_recovery_area/MMSGDB/autobackup/2011_03_05/o1_mf_s_744975873_6q35d3y8_.bkp RECID=2 STAMP=744975875
已交叉检验的 2 对象


RMAN&gt; delete backupset;

使用通道 ORA_DISK_1

备份片段列表
BP 关键字  BS 关键字  Pc# Cp# 状态      设备类型段名称
------- ------- --- --- ----------- ----------- ----------
99      98      1   1   EXPIRED     DISK        /opt/oracle/rmanbak/db_u%_s%_p%
120     113     1   1   EXPIRED     DISK        /opt/oracle/flash_recovery_area/MMSGDB/autobackup/2011_03_05/o1_mf_s_744975873_6q35d3y8_.bkp

是否确定要删除以上对象 (输入 YES 或 NO)? YES
已删除备份片段
备份片段句柄=/opt/oracle/rmanbak/db_u%_s%_p% RECID=1 STAMP=744975858
已删除备份片段
备份片段句柄=/opt/oracle/flash_recovery_area/MMSGDB/autobackup/2011_03_05/o1_mf_s_744975873_6q35d3y8_.bkp RECID=2 STAMP=744975875
2 对象已删除


RMAN&gt; list backupset by backup summary;


RMAN&gt;     #无数据展示，说明已经删除完毕了.
</code></pre>
<h1 id="zhi-xing-rman-bei-fen-bao-cuo-rman-03009-ora-19809-ora-19804">执行RMAN备份报错，RMAN-03009  ORA-19809  ORA-19804</h1>
<h2 id="biao-xiang-2">表象</h2>
<pre><code class="language-shell">oracle@mmsc103:~/rmanbak&gt; rman target/

恢复管理器: Release 11.1.0.6.0 - Production on 星期三 3月 16 17:57:10 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

连接到目标数据库: MMSGDB (DBID=3148145279)

RMAN&gt; connect catalog rman/rman@mmsgdb

连接到恢复目录数据库

RMAN&gt; list backupset;


RMAN&gt; backup database;

启动 backup 于 16-3月 -11
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=294 设备类型=DISK
通道 ORA_DISK_1: 正在启动全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/oradata/mmsgdb/mmsgdata01
输入数据文件: 文件号=00007 名称=/opt/oracle/oradata/mmsgdb/mmsg_yjh
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
输入数据文件: 文件号=00006 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
通道 ORA_DISK_1: 正在启动段 1 于 16-3月 -11
DBGANY:     Mismatched message length! [17:57:48.295] (krmiduem)
DBGANY:     Mismatched message length! [17:57:48.296] (krmiduem)
MAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-00600: internal error, arguments [3045] [] [] [] []
RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03009: backup 命令 (ORA_DISK_1 通道上, 在 03/16/2011 17:57:48 上) 失败
ORA-19809: 超出了恢复文件数的限制
ORA-19804: 无法回收 52428800 字节磁盘空间 (从 2147483648 限制中)
oracle@mmsc103:~/rmanbak&gt;
</code></pre>
<h2 id="yuan-yin-3">原因</h2>
<p>开通了闪回功能后，默认的备份存储区域为闪存区域，区域大小默认为2G。</p>
<pre><code class="language-shell">SQL&gt; show parameter db_recovery_file_dest_size 

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_recovery_file_dest_size           big integer 42G
SQL&gt;
</code></pre>
<p>当归档日志文件数量总和的大小超过这个默认值后，执行备份则报错，原因就是空间不足。</p>
<h2 id="jie-jue-fang-fa-3">解决方法</h2>
<p>通过修改闪回区域大小，重启数据库后解决问题。</p>
<pre><code class="language-shell">SQL&gt; alter system set db_recovery_file_dest_size = 4G scope =spfile;

系统已更改。

SQL&gt;shutdown immediate
SQL&gt;startup
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle RMAN实践篇1</title>
    <url>/2011/03/07/oracle_rman_rman_practice_part1/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文主要介绍RMAN的一些实战操作。</p>
<h1 id="zhun-bei-gong-zuo">准备工作</h1>
<p>1、数据库运行在归档方式下；</p>
<p>2、备份整个数据库；</p>
<p>3、rman备份整个数据库与归档日志。</p>
<p>rman备份脚本如下（运行日志）：</p>
<pre><code class="language-shell">RMAN&gt; #script:fullbakup.rcv
2&gt; # creater:wangyunzeng
3&gt; # date:3.1.2011
4&gt; # desc:backup all database datafile in archive with rman
5&gt; # connect database
6&gt; #rman target/;
7&gt; #connect catalog rman/rman@inomc;
8&gt; connect catalog *
9&gt; connect target *
10&gt; 
11&gt; #start backup
12&gt; run
13&gt; {
14&gt;   allocate channel c1 type disk;
15&gt;   backup tag 'dbfull' format 'fullbak_%u_%s_%p' database
16&gt;   archivelog all;
17&gt;   sql 'alter system archive log current';
18&gt;   release channel c1;
19&gt; }
</code></pre>
<h1 id="gui-dang-mo-shi-xia-diu-shi-huo-sun-pi-yi-ge-shu-ju-wen-jian">归档模式下丢失或损坏一个数据文件</h1>
<h2 id="os-bei-fen-fang-an">OS备份方案</h2>
<p>在归档方式下，丢失或损坏一个数据文件，如果有响应的物理文件的备用以及该备份以来的归档日志，恢复数据库是比较容易的，而且可以减少宕机时间。</p>
<h3 id="bu-zou-yi-chuang-jian-ce-shi-biao">步骤一 创建测试表</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期一 3月 7 10:30:57 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; create table sybex(id int);    

表已创建。


SQL&gt; insert into  sybex values(0);

已创建 1 行。

SQL&gt; insert into  sybex values(1);

已创建 1 行。

SQL&gt; insert into  sybex values(2);

已创建 1 行。

SQL&gt; insert into  sybex values(3);

已创建 1 行。

SQL&gt; insert into  sybex values(4);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from sybex;

        ID
----------
         0
         1
         2
         3
         4

SQL&gt;
</code></pre>
<h3 id="bu-zou-er-guan-bi-shu-ju-ku-mo-ni-shu-ju-wen-jian-sun-pi-huo-diu-shi">步骤二 关闭数据库，模拟数据文件损坏或丢失</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期一 3月 7 10:44:24 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; alter database datafile 5 online;

数据库已更改。

SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; 
删除数据文件
oracle@mmsc103:~&gt; cd oradata/mmsgdb/
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf mmsgdata01 
oracle@mmsc103:~/oradata/mmsgdb&gt; 
</code></pre>
<h3 id="bu-zou-san-qi-dong-shu-ju-ku-bing-tuo-ji-shu-ju-wen-jian">步骤三 启动数据库，并脱机数据文件</h3>
<pre><code class="language-shell">SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-01157: 无法标识/锁定数据文件 5 - 请参阅 DBWR 跟踪文件
ORA-01110: 数据文件 5: '/opt/oracle/oradata/mmsgdb/mmsgdata01'


SQL&gt; alter database datafile 5 offline drop;

数据库已更改。

SQL&gt; alter database open;

数据库已更改。
</code></pre>
<h3 id="bu-zou-si-kao-bei-wen-jian-hui-fu-bing-lian-ji-gai-shu-ju-wen-jian">步骤四 拷贝文件，恢复并联机该数据文件</h3>
<p>拷贝过程省略。</p>
<pre><code class="language-shell">SQL&gt; recover datafile 5
ORA-00279: 更改 427060 (在 03/05/2011 09:46:20 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_05/o1_mf_1_29_6q3jw83d
_.arc
ORA-00280: 更改 427060 (用于线程 1) 在序列 #29 中


指定日志: {&lt;RET&gt;=suggested | filename | AUTO | CANCEL}
auto
ORA-00279: 更改 433844 (在 03/05/2011 13:00:55 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_05/o1_mf_1_30_6q477cfq
_.arc
ORA-00280: 更改 433844 (用于线程 1) 在序列 #30 中


ORA-00279: 更改 462078 (在 03/05/2011 19:22:19 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_31_6q4w04c0
_.arc
ORA-00280: 更改 462078 (用于线程 1) 在序列 #31 中


ORA-00279: 更改 489270 (在 03/06/2011 01:16:52 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_32_6q5dmrx0
_.arc
ORA-00280: 更改 489270 (用于线程 1) 在序列 #32 中


ORA-00279: 更改 519023 (在 03/06/2011 06:00:24 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_33_6q5rg0mj
_.arc
ORA-00280: 更改 519023 (用于线程 1) 在序列 #33 中


ORA-00279: 更改 537366 (在 03/06/2011 09:22:08 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_34_6q5yl1sz
_.arc
ORA-00280: 更改 537366 (用于线程 1) 在序列 #34 中


ORA-00279: 更改 549703 (在 03/06/2011 11:06:41 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_35_6q6d89j5
_.arc
ORA-00280: 更改 549703 (用于线程 1) 在序列 #35 中


ORA-00279: 更改 567132 (在 03/06/2011 15:00:25 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_36_6q6t01c4
_.arc
ORA-00280: 更改 567132 (用于线程 1) 在序列 #36 中


ORA-00279: 更改 584372 (在 03/06/2011 18:54:57 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_37_6q77sdpv
_.arc
ORA-00280: 更改 584372 (用于线程 1) 在序列 #37 中


ORA-00279: 更改 601986 (在 03/06/2011 22:50:20 生成) 对于线程 1 是必需的
ORA-00289: 建议:
/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_38_6q7sz1gn
_.arc
ORA-00280: 更改 601986 (用于线程 1) 在序列 #38 中


已应用的日志。
完成介质恢复。
SQL&gt; alter database datafile 5 online;

数据库已更改。

SQL&gt;
</code></pre>
<h3 id="bu-zou-wu-cha-xun-shu-ju-jian-cha-hui-fu-xiao-guo">步骤五   查询数据，检查恢复效果</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期一 3月 7 11:04:52 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select * from sybex;

        ID
----------
         0
         1
         2
         3
         4

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、采用热备份，需要运行在归档模式下，可以实现数据库的完全恢复，也就是说，从备份后到数据库崩溃时的数据都不会丢失。</p>
</li>
<li class="lvl-2">
<p>2、可以采用全备份数据库的方式备份，对于特殊情况，也可以只备份特定的数据文件，如只备份用户表空间（一般情况下对于某些写特别频繁的数据文件，可以单独加大备份频率）</p>
</li>
<li class="lvl-2">
<p>3、如果在恢复过程中，发现损坏的是多个数据文件，即可以采用一个一个数据文件的恢复方法（第5步中需要对数据文件一一脱机，第6步中需要对数据文件分别恢复），也可以采用整个数据库的恢复方法。</p>
</li>
<li class="lvl-2">
<p>4、如果是系统表空间的损坏，不能采用此方法</p>
</li>
</ul>
<h2 id="rman-bei-fen-fang-an">RMAN备份方案</h2>
<h3 id="bu-zou-yi-biao-zhong-cha-ru-ji-lu">步骤一  表中插入记录</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期一 3月 7 11:51:31 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; insert into sybex values(5);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from sybex;

        ID
----------
         5
         0
         1
         2
         3
         4

已选择6行。   #备份前表中有6条记录
</code></pre>
<h3 id="bu-zou-er-bei-fen-biao-kong-jian">步骤二  备份表空间</h3>
<pre><code class="language-shell">RMAN&gt; backup tablespace MMSG;

启动 backup 于 07-3月 -11
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=289 设备类型=DISK
通道 ORA_DISK_1: 正在启动全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/oradata/mmsgdb/mmsgdata01
通道 ORA_DISK_1: 正在启动段 1 于 07-3月 -11
通道 ORA_DISK_1: 已完成段 1 于 07-3月 -11
段句柄=/opt/oracle/flash_recovery_area/MMSGDB/backupset/2011_03_07/o1_mf_nnndf_TAG20110307T115233_6q8on44m_.bkp 标记=TAG20110307T115233 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 07-3月 -11

启动 Control File and SPFILE Autobackup 于 07-3月 -11
段 handle=/opt/oracle/flash_recovery_area/MMSGDB/autobackup/2011_03_07/o1_mf_s_745156357_6q8on8c8_.bkp comment=NONE
完成 Control File and SPFILE Autobackup 于 07-3月 -11

RMAN&gt;
</code></pre>
<h3 id="bu-zou-san-zai-ci-xiang-biao-zhong-cha-ru-ji-lu">步骤三  再次向表中插入记录</h3>
<pre><code class="language-shell">SQL&gt; insert into sybex values(6);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from sybex;

        ID
----------
         5
         6
         0
         1
         2
         3
         4

已选择7行。     #备份后，表中记录为7条，比备份前增加了一条

SQL&gt;
</code></pre>
<h3 id="bu-zou-si-qie-huan-relog-ri-zhi-ji-lu">步骤四  切换relog日志记录</h3>
<pre><code class="language-shell">SQL&gt; alter system switch logfile;

系统已更改。

SQL&gt; /

系统已更改。
</code></pre>
<h3 id="bu-zou-wu-guan-bi-shu-ju-ku-mo-ni-shu-ju-wen-jian-diu-shi">步骤五  关闭数据库，模拟数据文件丢失</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; host   
oracle@mmsc103:~&gt; cd oradata/mmsgdb/
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf mmsgdata01 
oracle@mmsc103:~/oradata/mmsgdb&gt; exit
exit
</code></pre>
<h3 id="bu-zou-liu-qi-dong-shu-ju-ku-bing-tuo-ji-shu-ju-wen-jian">步骤六  启动数据库，并脱机数据文件</h3>
<pre><code class="language-shell">SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-01157: 无法标识/锁定数据文件 5 - 请参阅 DBWR 跟踪文件
ORA-01110: 数据文件 5: '/opt/oracle/oradata/mmsgdb/mmsgdata01'


SQL&gt; alter database datafile 5 offline;

数据库已更改。

SQL&gt; alter database open;

数据库已更改。

SQL&gt;
</code></pre>
<h3 id="bu-zou-qi-hui-fu-biao-kong-jian">步骤七  恢复表空间</h3>
<p>恢复脚本可以是恢复单个数据文件</p>
<pre><code class="language-shell">RMAN&gt; run
2&gt; {
3&gt; allocate channel c1 type disk;
4&gt; restore datafile 5;
5&gt; recover datafile 5;
6&gt; sql 'alter database datafile 5 online';
7&gt; release channel c1;
8&gt; }
</code></pre>
<p>也可以是表空间</p>
<pre><code class="language-shell">RMAN&gt; run
2&gt; {
3&gt; allocate channel c1 type disk;
4&gt; restoretablespace MMSG;
5&gt; recover tablespace MMSG;
6&gt; sql 'alter database datafile 5 online';
7&gt; release channel c1;
8&gt; }
</code></pre>
<p>过程如下：</p>
<pre><code class="language-shell">使用目标数据库控制文件替代恢复目录
分配的通道: c1
通道 c1: SID=293 设备类型=DISK

启动 restore 于 07-3月 -11

通道 c1: 正在开始还原数据文件备份集
通道 c1: 正在指定从备份集还原的数据文件
通道 c1: 将数据文件 00005 还原到 /opt/oracle/oradata/mmsgdb/mmsgdata01
通道 c1: 正在读取备份片段 /opt/oracle/flash_recovery_area/MMSGDB/backupset/2011_03_07/o1_mf_nnndf_TAG20110307T115233_6q8on44m_.bkp
通道 c1: 段句柄 = /opt/oracle/flash_recovery_area/MMSGDB/backupset/2011_03_07/o1_mf_nnndf_TAG20110307T115233_6q8on44m_.bkp 标记 = TAG20110307T115233
通道 c1: 已还原备份片段 1
通道 c1: 还原完成, 用时: 00:00:15
完成 restore 于 07-3月 -11

启动 recover 于 07-3月 -11

正在开始介质的恢复
介质恢复完成, 用时: 00:00:00

完成 recover 于 07-3月 -11

sql 语句: alter database datafile 5 online

释放的通道: c1

RMAN&gt;
</code></pre>
<h3 id="bu-zou-ba-jian-cha-hui-fu-xiao-guo">步骤八 检查恢复效果</h3>
<pre><code class="language-shell">SQL&gt; select * from sybex;

        ID
----------
         5
         6
         0
         1
         2
         3
         4

已选择7行。   #恢复后，数据是7条，没有丢失
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、RMAN也可以实现单个表空间或数据文件的恢复，恢复过程可以在mount下或open方式下，如果在open方式下恢复，可以减少down机时间</p>
</li>
<li class="lvl-2">
<p>2、如果损坏的是一个数据文件，建议offline并在open方式下恢复</p>
</li>
<li class="lvl-2">
<p>3、这里可以看到，RMAN进行数据文件与表空间恢复的时候，代码都比较简单，而且能保证备份与恢复的可靠性，所以建议采用RMAN的备份与恢复</p>
</li>
</ul>
<h1 id="diu-shi-duo-ge-shu-ju-wen-jian-de-shu-ju-ku-hui-fu">丢失多个数据文件的数据库恢复</h1>
<h2 id="os-bei-fen-fang-an-1">OS备份方案</h2>
<h3 id="bu-zou-yi-biao-zhong-cha-ru-ji-lu-1">步骤一  表中插入记录</h3>
<pre><code class="language-shell">SQL&gt; insert into sybex values(7);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from sybex;

        ID
----------
         7
         5
         6
         0
         1
         2
         3
         4

已选择8行。        #故障前有8条记录
</code></pre>
<h3 id="bu-zou-er-guan-bi-shu-ju-ku-shan-chu-chu-lin-shi-wen-jian-wai-de-suo-you-shu-ju-wen-jian">步骤二  关闭数据库，删除除临时文件外的所有数据文件</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; host
oracle@mmsc103:~&gt; cd oradata/mmsgdb/
oracle@mmsc103:~/oradata/mmsgdb&gt; l
total 2255540
drwxr-x--- 2 oracle oinstall       4096 2011-03-07 11:59 ./
drwxr-x--- 3 oracle oinstall       4096 2011-03-03 18:20 ../
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 12:38 control01.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 12:38 control02.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 12:38 control03.ctl
-rw-r----- 1 oracle oinstall 1048584192 2011-03-07 12:38 mmsgdata01
-rw-r----- 1 oracle oinstall  524296192 2011-03-05 11:47 mmsgdata02
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 12:38 redo01.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 11:57 redo02.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 11:57 redo03.log
-rw-r----- 1 oracle oinstall  209723392 2011-03-07 12:38 rman_data.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-05 11:47 rman_tmp.dbf
-rw-r----- 1 oracle oinstall  287186944 2011-03-07 12:38 sysaux01.dbf
-rw-r----- 1 oracle oinstall  356524032 2011-03-07 12:38 system01.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-07 10:45 temp01.dbf
-rw-r----- 1 oracle oinstall  209723392 2011-03-07 12:38 undotbs01.dbf
-rw-r----- 1 oracle oinstall    5251072 2011-03-07 12:38 users01.dbf
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf mmsgdata01  sysaux01.dbf  system01.dbf  users01.dbf  undotbs01.dbf 
oracle@mmsc103:~/oradata/mmsgdb&gt; exit
exit
</code></pre>
<h3 id="bu-zou-san-qi-dong-shu-ju-ku-bing-cha-kan-gao-jing-ri-zhi">步骤三 启动数据库，并查看告警日志</h3>
<pre><code class="language-shell">SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-01157: 无法标识/锁定数据文件 1 - 请参阅 DBWR 跟踪文件
ORA-01110: 数据文件 1: '/opt/oracle/oradata/mmsgdb/system01.dbf'


SQL&gt;
</code></pre>
<p>查看告警日志</p>
<pre><code class="language-shell">&lt;msg time='2011-03-07T12:41:50.153+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='' pid='22906'&gt;
 &lt;txt&gt;Errors in file /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_dbw0_22906.trc:
ORA-01157: ????/?????? 1 - ??? DBWR ????
ORA-01110: ???? 1: &amp;apos;/opt/oracle/oradata/mmsgdb/system01.dbf&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2011-03-07T12:41:50.154+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='' pid='22906'&gt;
 &lt;txt&gt;Errors in file /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_dbw0_22906.trc:
ORA-01157: ????/?????? 2 - ??? DBWR ????
ORA-01110: ???? 2: &amp;apos;/opt/oracle/oradata/mmsgdb/sysaux01.dbf&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2011-03-07T12:41:50.154+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='' pid='22906'&gt;
 &lt;txt&gt;Errors in file /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_dbw0_22906.trc:
ORA-01157: ????/?????? 3 - ??? DBWR ????
ORA-01110: ???? 3: &amp;apos;/opt/oracle/oradata/mmsgdb/undotbs01.dbf&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2011-03-07T12:41:50.154+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='' pid='22906'&gt;
 &lt;txt&gt;Errors in file /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_dbw0_22906.trc:
ORA-01157: ????/?????? 4 - ??? DBWR ????
ORA-01110: ???? 4: &amp;apos;/opt/oracle/oradata/mmsgdb/users01.dbf&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2011-03-07T12:41:50.154+08:00' org_id='oracle' comp_id='rdbms'
 client_id='' type='UNKNOWN' level='16'
 module='' pid='22906'&gt;
 &lt;txt&gt;Errors in file /opt/oracle/diag/rdbms/mmsgdb/mmsgdb/trace/mmsgdb_dbw0_22906.trc:
ORA-01157: ????/?????? 5 - ??? DBWR ????
ORA-01110: ???? 5: &amp;apos;/opt/oracle/oradata/mmsgdb/mmsgdata01&amp;apos;
ORA-27037: ????????
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2011-03-07T12:41:50.156+08:00' org_id='oracle' comp_id='rdbms'
 msg_id='opiexe:2986:2780954927' client_id='' type='NOTIFICATION'
 group='admin_ddl' level='16' module='sqlplus@mmsc103 (TNS V1-V3)'
 pid='23023'&gt;
 &lt;txt&gt;ORA-1157 signalled during: ALTER DATABASE OPEN...
 &lt;/txt&gt;
&lt;/msg&gt;
</code></pre>
<p>通过查询视图v$recover_file可以发现</p>
<pre><code class="language-shell">SQL&gt; select * from v$recover_file;

     FILE# ONLINE  ONLINE_ ERROR                                                                CHANGE# TIME
---------- ------- ------- ----------------------------------------------------------------- ---------- --------------
         1 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         2 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         3 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         4 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         5 ONLINE  ONLINE  FILE NOT FOUND                                                             0

SQL&gt;
</code></pre>
<p>有5个数据文件需要恢复，整改是我删除的那5个数据文件。</p>
<h3 id="bu-zou-si-kao-bei-shu-ju-wen-jian-dao-mu-lu-zhao-shou-hui-fu">步骤四   拷贝数据文件到目录，着手恢复</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; cd bak_oradata/mmsgdb/
oracle@mmsc103:~/bak_oradata/mmsgdb&gt; l
total 2206832
drwxr-x--- 2 oracle oinstall       4096 2011-03-05 09:48 ./
drwxr-x--- 3 oracle oinstall       4096 2011-03-05 09:48 ../
-rw-r----- 1 oracle oinstall    9748480 2011-03-05 09:48 control01.ctl
-rw-r----- 1 oracle oinstall    9748480 2011-03-05 09:48 control02.ctl
-rw-r----- 1 oracle oinstall    9748480 2011-03-05 09:48 control03.ctl
-rw-r----- 1 oracle oinstall 1048584192 2011-03-05 09:48 mmsgdata01
-rw-r----- 1 oracle oinstall  524296192 2011-03-05 09:48 mmsgdata02
-rw-r----- 1 oracle oinstall   52429312 2011-03-05 09:48 redo01.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-05 09:48 redo02.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-05 09:48 redo03.log
-rw-r----- 1 oracle oinstall  209723392 2011-03-05 09:48 rman_data.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-05 09:48 rman_tmp.dbf
-rw-r----- 1 oracle oinstall  249438208 2011-03-05 09:48 sysaux01.dbf
-rw-r----- 1 oracle oinstall  346038272 2011-03-05 09:48 system01.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-05 09:48 temp01.dbf
-rw-r----- 1 oracle oinstall  209723392 2011-03-05 09:48 undotbs01.dbf
-rw-r----- 1 oracle oinstall    5251072 2011-03-05 09:48 users01.dbf
oracle@mmsc103:~/bak_oradata/mmsgdb&gt; cp mmsgdata01  sysaux01.dbf  system01.dbf  users01.dbf  undotbs01.dbf  ../../oradata/mmsgdb/
oracle@mmsc103:~/bak_oradata/mmsgdb&gt;
</code></pre>
<p>恢复过程如下：</p>
<pre><code class="language-shell">SQL&gt; recover database;
ORA-00279: 更改 427060 (在 03/05/2011 09:46:20 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_05/o1_mf_1_29_6q3jw83d_.arc
ORA-00280: 更改 427060 (用于线程 1) 在序列 #29 中


指定日志: {&lt;RET&gt;=suggested | filename | AUTO | CANCEL}
auto
ORA-00279: 更改 433844 (在 03/05/2011 13:00:55 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_05/o1_mf_1_30_6q477cfq_.arc
ORA-00280: 更改 433844 (用于线程 1) 在序列 #30 中


ORA-00279: 更改 462078 (在 03/05/2011 19:22:19 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_31_6q4w04c0_.arc
ORA-00280: 更改 462078 (用于线程 1) 在序列 #31 中


ORA-00279: 更改 489270 (在 03/06/2011 01:16:52 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_32_6q5dmrx0_.arc
ORA-00280: 更改 489270 (用于线程 1) 在序列 #32 中


ORA-00279: 更改 519023 (在 03/06/2011 06:00:24 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_33_6q5rg0mj_.arc
ORA-00280: 更改 519023 (用于线程 1) 在序列 #33 中


ORA-00279: 更改 537366 (在 03/06/2011 09:22:08 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_34_6q5yl1sz_.arc
ORA-00280: 更改 537366 (用于线程 1) 在序列 #34 中


ORA-00279: 更改 549703 (在 03/06/2011 11:06:41 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_35_6q6d89j5_.arc
ORA-00280: 更改 549703 (用于线程 1) 在序列 #35 中


ORA-00279: 更改 567132 (在 03/06/2011 15:00:25 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_36_6q6t01c4_.arc
ORA-00280: 更改 567132 (用于线程 1) 在序列 #36 中


ORA-00279: 更改 584372 (在 03/06/2011 18:54:57 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_06/o1_mf_1_37_6q77sdpv_.arc
ORA-00280: 更改 584372 (用于线程 1) 在序列 #37 中


ORA-00279: 更改 601986 (在 03/06/2011 22:50:20 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_38_6q7sz1gn_.arc
ORA-00280: 更改 601986 (用于线程 1) 在序列 #38 中


ORA-00279: 更改 624387 (在 03/07/2011 04:00:33 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_39_6q8k2j5f_.arc
ORA-00280: 更改 624387 (用于线程 1) 在序列 #39 中


ORA-00279: 更改 642232 (在 03/07/2011 10:34:56 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_40_6q8kl8sg_.arc
ORA-00280: 更改 642232 (用于线程 1) 在序列 #40 中


已应用的日志。
完成介质恢复。
SQL&gt; alter database open;

数据库已更改。

SQL&gt;
</code></pre>
<h3 id="bu-zou-wu-jian-cha-shu-ju-wan-zheng-xing">步骤五  检查数据完整性</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期一 3月 7 12:48:35 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select * from sybex;

        ID
----------
         7
         5
         6
         0
         1
         2
         3
         4

已选择8行。   #数据还是8条，未丢失.

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、只要有备份与归档存在，就可以实现数据库的完全恢复（不丢失数据）</p>
</li>
<li class="lvl-2">
<p>2、适合于丢失大量数据文件，或包含系统数据文件在内的数据库的恢复</p>
</li>
<li class="lvl-2">
<p>3、恢复过程在mount下进行，如果恢复成功，再打开数据库，down机时间可能比较长一些。</p>
</li>
</ul>
<h2 id="rman-bei-fen-fang-an-1">RMAN备份方案</h2>
<p>rman备份归档模式下数据库，损坏或丢失多个数据文件，可进行整个数据库的恢复。</p>
<h3 id="bu-zou-yi-biao-zhong-cha-ru-ji-lu-2">步骤一  表中插入记录</h3>
<pre><code class="language-shell">SQL&gt; insert into sybex values(8);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from sybex;

        ID
----------
         7
         8
         5
         6
         0
         1
         2
         3
         4

已选择9行。       #备份前有9条记录
</code></pre>
<h3 id="bu-zou-er-bei-fen-zheng-ge-shu-ju-ku">步骤二   备份整个数据库</h3>
<p>备份日志如下：</p>
<pre><code class="language-shell">恢复管理器: Release 11.1.0.6.0 - Production on 星期一 3月 7 13:52:27 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

RMAN&gt; #script:fullbakup.rman
2&gt; # creater:wangyunzeng
3&gt; # date:2011-03-01
4&gt; # desc:backup all database datafile in archive with rman
5&gt; # connect database
6&gt; connect target *
7&gt; connect catalog *
8&gt; 
9&gt; #start backup database
10&gt; run
11&gt; {
12&gt;   allocate channel c1 type disk;
13&gt;   backup tag 'dbfull' format 'fullbak_%u_%s_%p' database
14&gt;   archivelog all;
15&gt;   sql 'alter system archive log current';
16&gt;   release channel c1;
17&gt; }
18&gt; #end
19&gt; 
连接到目标数据库: MMSGDB (DBID=3148145279)

连接到恢复目录数据库

正在启动全部恢复目录的 resync
完成全部 resync
分配的通道: c1
通道 c1: SID=288 设备类型=DISK

启动 backup 于 07-3月 -11
通道 c1: 正在启动归档日志备份集
通道 c1: 正在指定备份集内的归档日志
输入归档日志线程=1 序列=29 RECID=30 STAMP=744987657
输入归档日志线程=1 序列=30 RECID=32 STAMP=745010540
输入归档日志线程=1 序列=31 RECID=34 STAMP=745031813
输入归档日志线程=1 序列=32 RECID=36 STAMP=745048826
输入归档日志线程=1 序列=33 RECID=38 STAMP=745060929
输入归档日志线程=1 序列=34 RECID=40 STAMP=745067203
输入归档日志线程=1 序列=35 RECID=42 STAMP=745081226
输入归档日志线程=1 序列=36 RECID=44 STAMP=745095298
输入归档日志线程=1 序列=37 RECID=46 STAMP=745109422
输入归档日志线程=1 序列=38 RECID=48 STAMP=745128034
输入归档日志线程=1 序列=39 RECID=50 STAMP=745151697
输入归档日志线程=1 序列=40 RECID=52 STAMP=745152201
输入归档日志线程=1 序列=41 RECID=54 STAMP=745156439
输入归档日志线程=1 序列=42 RECID=56 STAMP=745156440
通道 c1: 正在启动段 1 于 07-3月 -11
通道 c1: 已完成段 1 于 07-3月 -11
段句柄=/opt/oracle/product/11g/dbs/fullbak_0bm6kip0_11_1 标记=DBFULL 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:07
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/oradata/mmsgdb/mmsgdata01
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
输入数据文件: 文件号=00006 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
通道 c1: 正在启动段 1 于 07-3月 -11
通道 c1: 已完成段 1 于 07-3月 -11
段句柄=/opt/oracle/product/11g/dbs/fullbak_0cm6kip9_12_1 标记=DBFULL 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:15
完成 backup 于 07-3月 -11

启动 Control File and SPFILE Autobackup 于 07-3月 -11
段 handle=/opt/oracle/flash_recovery_area/MMSGDB/autobackup/2011_03_07/o1_mf_s_745163579_6q8woy7q_.bkp comment=NONE
完成 Control File and SPFILE Autobackup 于 07-3月 -11

sql 语句: alter system archive log current

释放的通道: c1

恢复管理器完成。
</code></pre>
<h3 id="bu-zou-san-biao-zhong-zai-ci-cha-ru-ji-lu">步骤三   表中再次插入记录</h3>
<pre><code class="language-shell">SQL&gt; insert into sybex values(9);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select count(0) from sybex;

  COUNT(0)
----------
        10    #出故障前，表中有10条记录

SQL&gt;
</code></pre>
<h3 id="bu-zou-si-guan-bi-shu-ju-ku-mo-ni-duo-ge-shu-ju-wen-jian-diu-shi-huo-sun-pi">步骤四  关闭数据库，模拟多个数据文件丢失或损坏</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; host
oracle@mmsc103:~&gt; cd oradata/mmsgdb/
oracle@mmsc103:~/oradata/mmsgdb&gt; l
total 2255540
drwxr-x--- 2 oracle oinstall       4096 2011-03-07 12:46 ./
drwxr-x--- 3 oracle oinstall       4096 2011-03-03 18:20 ../
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 13:55 control01.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 13:55 control02.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 13:55 control03.ctl
-rw-r----- 1 oracle oinstall 1048584192 2011-03-07 13:55 mmsgdata01
-rw-r----- 1 oracle oinstall  524296192 2011-03-05 11:47 mmsgdata02
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 13:53 redo01.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 13:55 redo02.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 12:48 redo03.log
-rw-r----- 1 oracle oinstall  209723392 2011-03-07 13:55 rman_data.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-05 11:47 rman_tmp.dbf
-rw-r----- 1 oracle oinstall  287186944 2011-03-07 13:55 sysaux01.dbf
-rw-r----- 1 oracle oinstall  356524032 2011-03-07 13:55 system01.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-07 10:45 temp01.dbf
-rw-r----- 1 oracle oinstall  209723392 2011-03-07 13:55 undotbs01.dbf
-rw-r----- 1 oracle oinstall    5251072 2011-03-07 13:55 users01.dbf
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf mmsgdata01  system01.dbf  sysaux01.dbf  users01.dbf  undotbs01.dbf 
oracle@mmsc103:~/oradata/mmsgdb&gt; exit
exit

SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-01157: 无法标识/锁定数据文件 1 - 请参阅 DBWR 跟踪文件
ORA-01110: 数据文件 1: '/opt/oracle/oradata/mmsgdb/system01.dbf'


SQL&gt;
</code></pre>
<pre><code class="language-shell">SQL&gt; select * from v$recover_file;

     FILE# ONLINE  ONLINE_ ERROR                                                                CHANGE# TIME
---------- ------- ------- ----------------------------------------------------------------- ---------- --------------
         1 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         2 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         3 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         4 ONLINE  ONLINE  FILE NOT FOUND                                                             0
         5 ONLINE  ONLINE  FILE NOT FOUND                                                             0

SQL&gt;
</code></pre>
<h3 id="bu-zou-wu-hui-fu-shu-ju-ku">步骤五  恢复数据库</h3>
<pre><code class="language-shell">RMAN&gt; run
2&gt; {
3&gt; allocate channel c1 type disk;
4&gt; restore database;
5&gt; recover database;
6&gt; sql 'alter database open';
7&gt; release channel c1;
8&gt; }

使用目标数据库控制文件替代恢复目录
分配的通道: c1
通道 c1: SID=317 设备类型=DISK

启动 restore 于 07-3月 -11

通道 c1: 正在开始还原数据文件备份集
通道 c1: 正在指定从备份集还原的数据文件
通道 c1: 将数据文件 00001 还原到 /opt/oracle/oradata/mmsgdb/system01.dbf
通道 c1: 将数据文件 00002 还原到 /opt/oracle/oradata/mmsgdb/sysaux01.dbf
通道 c1: 将数据文件 00003 还原到 /opt/oracle/oradata/mmsgdb/undotbs01.dbf
通道 c1: 将数据文件 00004 还原到 /opt/oracle/oradata/mmsgdb/users01.dbf
通道 c1: 将数据文件 00005 还原到 /opt/oracle/oradata/mmsgdb/mmsgdata01
通道 c1: 将数据文件 00006 还原到 /opt/oracle/oradata/mmsgdb/rman_data.dbf
通道 c1: 正在读取备份片段 /opt/oracle/product/11g/dbs/fullbak_0cm6kip9_12_1
通道 c1: 段句柄 = /opt/oracle/product/11g/dbs/fullbak_0cm6kip9_12_1 标记 = DBFULL
通道 c1: 已还原备份片段 1
通道 c1: 还原完成, 用时: 00:00:35
完成 restore 于 07-3月 -11

启动 recover 于 07-3月 -11

正在开始介质的恢复
介质恢复完成, 用时: 00:00:02

完成 recover 于 07-3月 -11

sql 语句: alter database open

释放的通道: c1

RMAN&gt;
</code></pre>
<h3 id="bu-zou-liu-hui-fu-jie-guo-jian-cha">步骤六  恢复结果检查</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期一 3月 7 14:00:33 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select count(0) from sybex;

  COUNT(0)
----------
        10       #数据库恢复后，10条记录，未丢失数据.

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、只要有备份与归档存在，RMAN也可以实现数据库的完全恢复（不丢失数据）</p>
</li>
<li class="lvl-2">
<p>2、同OS备份数据库恢复，适合于丢失大量数据文件，或包含系统数据文件在内的数据库的恢复</p>
</li>
<li class="lvl-2">
<p>3、目标数据库在mount下进行，如果恢复成功，再打开数据库。</p>
</li>
<li class="lvl-2">
<p>4、RMAN的备份与恢复命令相对比较简单并可靠，建议有条件的话，都采用RMAN进行数据库的备份。</p>
</li>
</ul>
<h1 id="bu-wan-quan-hui-fu">不完全恢复</h1>
<h2 id="os-bei-fen-xia-de-ji-yu-shi-jian-de-hui-fu">OS备份下的基于时间的恢复</h2>
<p>不完全恢复分为三种，基于时间（TIME）、基于撤销（CANCLE）、基于改变（SCN），这里以基于时间的恢复为例。</p>
<h3 id="bu-zou-yi-chuang-jian-biao">步骤一  创建表</h3>
<pre><code class="language-shell">SQL&gt; select * from sybex;

        ID
----------
         7
         8
         9
         5
         6
         0
         1
         2
         3
         4

已选择10行。

SQL&gt; create table time(id int);

表已创建。

SQL&gt; insert into time values(0);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt;
</code></pre>
<h3 id="bu-zou-er-bei-fen-shu-ju-ku">步骤二  备份数据库</h3>
<p>这里冷备整个数据库，包括临时数据文件，热物理备份也可以，这里不在赘述。</p>
<h3 id="bu-zou-san-zai-ci-cha-ru-shu-ju-bing-gui-dang">步骤三  再次插入数据，并归档</h3>
<h4 id="ying-yong-yong-hu-chuang-jian-biao-bing-cha-ru-shu-ju">应用用户创建表并插入数据。</h4>
<pre><code class="language-shell">SQL&gt; insert into time values(1);

已创建 1 行。

SQL&gt; commit
  2  ;

提交完成。

SQL&gt; 
SQL&gt; select count(0) from time;

  COUNT(0)
----------
         2
</code></pre>
<h4 id="sysdba-yong-hu-qie-huan-ri-zhi-gui-dang">sysdba用户切换日志归档</h4>
<pre><code class="language-shell">SQL&gt; alter system archive log current;

系统已更改。

SQL&gt; alter system archive log current;

系统已更改。

SQL&gt; alter system archive log current;

系统已更改。
</code></pre>
<h4 id="ying-yong-yong-hu-zhi-xing-ru-xia-cao-zuo">应用用户执行如下操作</h4>
<pre><code class="language-shell">SQL&gt; select to_char(sysdate,'yyyy-mm-dd HH24:MI:SS') from dual;

TO_CHAR(SYSDATE,'YY
-------------------
2011-03-07 15:49:29

SQL&gt; drop table time;

表已删除。

SQL&gt; commit;

提交完成。

SQL&gt;
</code></pre>
<h3 id="bu-zou-si-guan-bi-shu-ju-ku-kao-bei-hui-zhi-qian-bei-fen-de-shu-ju-wen-jian-zhe-ge-shu-ju-wen-jian-zhong-wu-shu-ju-ji-lu">步骤四  关闭数据库，拷贝回之前备份的数据文件（这个数据文件中无数据记录）</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; host
oracle@mmsc103:~&gt; cp bak_20110307/mmsgdb/* ./oradata/mmsgdb/
oracle@mmsc103:~&gt;
</code></pre>
<h3 id="bu-zou-wu-mount-shu-ju-ku-zhi-xing-bu-wan-quan-hui-fu">步骤五  mount数据库，执行不完全恢复</h3>
<pre><code class="language-shell">SQL&gt; startup mount    
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
SQL&gt; recover database until time '2011-03-07 15:49:29';
完成介质恢复。
SQL&gt; alter database open resetlogs;

数据库已更改。

SQL&gt;
数据库已更改。

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>不完全恢复，必须使用resetlogs打开数据库。</p>
</li>
</ul>
<h3 id="bu-zou-liu-shu-ju-yan-zheng">步骤六  数据验证</h3>
<pre><code class="language-shell">SQL&gt; select * from time;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、不完全恢复最好备份所有的数据，冷备份亦可，因为恢复过程是从备份点往后恢复的，如果因为其中一个数据文件的时间戳(SCN)大于要恢复的时间点，那么恢复都是不可能成功的（报错，例如：</p>
</li>
</ul>
<pre><code class="language-shell">SQL&gt; recover database until time '2011-03-07 15:06:07';
ORA-01547: 警告: RECOVER 成功但 OPEN RESETLOGS 将出现如下错误
ORA-01152: 文件 1 没有从过旧的备份中还原
ORA-01110: 数据文件 1: '/opt/oracle/oradata/mmsgdb/system01.dbf'
）。
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>2、不完全恢复有三种方式，过程都一样，仅仅是recover命令有所不一样，这里用基于时间的恢复作为示例。</p>
</li>
<li class="lvl-2">
<p>3、不完全恢复之后，都必须用resetlogs的方式打开数据库，建议马上再做一次全备份，因为resetlogs之后再用以前的备份恢复是很难了。</p>
</li>
<li class="lvl-2">
<p>4、以上是在删除之前获得时间，但是实际应用中，很难知道删除之前的实际时间，但可以采用大致时间即可，或可以采用分析日志文件(logmnr)，取得精确的需要恢复的时间。</p>
</li>
<li class="lvl-2">
<p>5、一般都是在测试机后备用机器上采用这种不完全恢复，恢复之后导出/导入被误删的表回生产系统</p>
</li>
</ul>
<h2 id="rman-bei-fen-xia-de-ji-yu-gai-bian-de-hui-fu">RMAN备份下的基于改变的恢复</h2>
<h3 id="bu-zou-yi-chuang-jian-biao-biao-zhong-cha-ru-ji-lu">步骤一  创建表，表中插入记录</h3>
<pre><code class="language-shell">SQL&gt; create table scn(id int);

表已创建。

SQL&gt; insert into scn values(0);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from scn;

        ID
----------
         0

SQL&gt;
</code></pre>
<h3 id="bu-zou-er-rman-bei-fen-zheng-ge-shu-ju-ku">步骤二  rman备份整个数据库</h3>
<pre><code class="language-shell">RMAN&gt; run
2&gt; {
3&gt; allocate channel c1 type disk;
4&gt; backup database
5&gt; (archivelog all);
6&gt; release channel c1;
7&gt; }

在恢复目录中注册的数据库的新原型
正在启动全部恢复目录的 resync
完成全部 resync
分配的通道: c1
通道 c1: SID=286 设备类型=DISK

启动 backup 于 07-3月 -11
通道 c1: 正在启动归档日志备份集
通道 c1: 正在指定备份集内的归档日志
输入归档日志线程=1 序列=29 RECID=30 STAMP=744987657
输入归档日志线程=1 序列=30 RECID=32 STAMP=745010540
输入归档日志线程=1 序列=31 RECID=34 STAMP=745031813
输入归档日志线程=1 序列=32 RECID=36 STAMP=745048826
输入归档日志线程=1 序列=33 RECID=38 STAMP=745060929
输入归档日志线程=1 序列=34 RECID=40 STAMP=745067203
输入归档日志线程=1 序列=35 RECID=42 STAMP=745081226
输入归档日志线程=1 序列=36 RECID=44 STAMP=745095298
输入归档日志线程=1 序列=37 RECID=46 STAMP=745109422
输入归档日志线程=1 序列=38 RECID=48 STAMP=745128034
输入归档日志线程=1 序列=39 RECID=50 STAMP=745151697
输入归档日志线程=1 序列=40 RECID=52 STAMP=745152201
输入归档日志线程=1 序列=41 RECID=54 STAMP=745156439
输入归档日志线程=1 序列=42 RECID=56 STAMP=745156440
输入归档日志线程=1 序列=43 RECID=58 STAMP=745163589
输入归档日志线程=1 序列=44 RECID=60 STAMP=745165838
输入归档日志线程=1 序列=45 RECID=62 STAMP=745167957
输入归档日志线程=1 序列=46 RECID=64 STAMP=745167959
输入归档日志线程=1 序列=47 RECID=66 STAMP=745169653
输入归档日志线程=1 序列=48 RECID=68 STAMP=745169660
输入归档日志线程=1 序列=49 RECID=70 STAMP=745169670
输入归档日志线程=1 序列=50 RECID=72 STAMP=745169894
输入归档日志线程=1 序列=51 RECID=74 STAMP=745169909
输入归档日志线程=1 序列=52 RECID=76 STAMP=745169920
输入归档日志线程=1 序列=53 RECID=78 STAMP=745170730
通道 c1: 正在启动段 1 于 07-3月 -11
通道 c1: 已完成段 1 于 07-3月 -11
段句柄=/opt/oracle/flash_recovery_area/MMSGDB/backupset/2011_03_07/o1_mf_annnn_TAG20110307T160808_6q94mc1l_.bkp 标记=TAG20110307T160808 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:16
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/oradata/mmsgdb/mmsgdata01
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
输入数据文件: 文件号=00006 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
通道 c1: 正在启动段 1 于 07-3月 -11
通道 c1: 已完成段 1 于 07-3月 -11
段句柄=/opt/oracle/flash_recovery_area/MMSGDB/backupset/2011_03_07/o1_mf_nnndf_TAG20110307T160808_6q94my75_.bkp 标记=TAG20110307T160808 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:15
完成 backup 于 07-3月 -11

启动 Control File and SPFILE Autobackup 于 07-3月 -11
段 handle=/opt/oracle/flash_recovery_area/MMSGDB/autobackup/2011_03_07/o1_mf_s_745171724_6q94ngyy_.bkp comment=NONE
完成 Control File and SPFILE Autobackup 于 07-3月 -11

释放的通道: c1

RMAN&gt;
</code></pre>
<h3 id="bu-zou-san-ji-xu-cha-ru-ji-lu-ying-yong-gui-dang-yi-ji-huo-qu-shan-chu-qian-scn">步骤三  继续插入记录，应用归档以及获取删除前scn</h3>
<h4 id="ying-yong-yong-hu-zhi-xing">应用用户执行</h4>
<pre><code class="language-shell">SQL&gt; insert into scn values(1);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from scn;

        ID
----------
         0
         1
#2条记录
</code></pre>
<h4 id="dba-yong-hu-zhi-xing">dba用户执行</h4>
<pre><code class="language-shell">SQL&gt; alter system switch logfile;

系统已更改。

SQL&gt; /

系统已更改。

SQL&gt; /

系统已更改。

SQL&gt; /

系统已更改。

SQL&gt; select max(ktuxescnw * power(2, 32) + ktuxescnb) scn from x$ktuxe;

       SCN
----------
    690969

SQL&gt;
</code></pre>
<h3 id="bu-zou-si-shan-chu-biao">步骤四  删除表</h3>
<pre><code class="language-shell">SQL&gt; drop table scn;

表已删除。

SQL&gt; commit;

提交完成。
</code></pre>
<h3 id="bu-zou-wu-ji-yu-scn-hui-fu">步骤五  基于SCN恢复</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate 
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
SQL&gt;

RMAN&gt; run
2&gt; {
3&gt; allocate channel c1 type disk;
4&gt; restore database;
5&gt; recover database until scn 690969;
6&gt; sql 'alter database open resetlogs';
7&gt; release channel c1;
8&gt; }

使用目标数据库控制文件替代恢复目录
分配的通道: c1
通道 c1: SID=317 设备类型=DISK

启动 restore 于 07-3月 -11

通道 c1: 正在开始还原数据文件备份集
通道 c1: 正在指定从备份集还原的数据文件
通道 c1: 将数据文件 00001 还原到 /opt/oracle/oradata/mmsgdb/system01.dbf
通道 c1: 将数据文件 00002 还原到 /opt/oracle/oradata/mmsgdb/sysaux01.dbf
通道 c1: 将数据文件 00003 还原到 /opt/oracle/oradata/mmsgdb/undotbs01.dbf
通道 c1: 将数据文件 00004 还原到 /opt/oracle/oradata/mmsgdb/users01.dbf
通道 c1: 将数据文件 00005 还原到 /opt/oracle/oradata/mmsgdb/mmsgdata01
通道 c1: 将数据文件 00006 还原到 /opt/oracle/oradata/mmsgdb/rman_data.dbf
通道 c1: 正在读取备份片段 /opt/oracle/flash_recovery_area/MMSGDB/backupset/2011_03_07/o1_mf_nnndf_TAG20110307T160808_6q94my75_.bkp
通道 c1: 段句柄 = /opt/oracle/flash_recovery_area/MMSGDB/backupset/2011_03_07/o1_mf_nnndf_TAG20110307T160808_6q94my75_.bkp 标记 = TAG20110307T160808
通道 c1: 已还原备份片段 1
通道 c1: 还原完成, 用时: 00:00:35
完成 restore 于 07-3月 -11

启动 recover 于 07-3月 -11

正在开始介质的恢复

线程 1 序列 1 的归档日志已作为文件 /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_1_6q9526m9_.arc 存在于磁盘上
线程 1 序列 2 的归档日志已作为文件 /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_2_6q9527t3_.arc 存在于磁盘上
线程 1 序列 3 的归档日志已作为文件 /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_3_6q952bqb_.arc 存在于磁盘上
归档日志文件名=/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_1_6q9526m9_.arc 线程=1 序列=1
归档日志文件名=/opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_07/o1_mf_1_2_6q9527t3_.arc 线程=1 序列=2
介质恢复完成, 用时: 00:00:02
完成 recover 于 07-3月 -11

sql 语句: alter database open resetlogs

释放的通道: c1

RMAN&gt;
</code></pre>
<h3 id="bu-zou-liu-shu-ju-jian-cha">步骤六 数据检查</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus mmsg/mmsg@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期一 3月 7 16:23:01 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select * from scn;

        ID
----------
         0
         1

SQL&gt;     #两条记录，数据未丢失
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、RMAN也可以实现不完全恢复，方法比OS备份恢复的方法更简单可靠</p>
</li>
<li class="lvl-2">
<p>2、RMAN可以基于时间，基于改变与基于日志序列的不完全恢复，基于日志序列的恢复可以指定恢复到哪个日志序列，如</p>
</li>
</ul>
<pre><code class="language-shell">run { 
allocate channel ch1 type disk; 
allocate channel ch2 type 'sbt_tape'; 
set until logseq 1234 thread 1; 
restore controlfile to '$ORACLE_HOME/dbs/cf1.f' ; 
replicate controlfile from '$ORACLE_HOME/dbs/cf1.f'; 
alter database mount; 
restore database; 
recover database; 
sql "ALTER DATABASE OPEN RESETLOGS";
}
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>3、与所有的不完全恢复一样，必须在mount下，restore所有备份数据文件，需要resetlogs</p>
</li>
<li class="lvl-2">
<p>4、基于改变的恢复比基于时间的恢复更可靠，但是可能也更复杂，需要知道需要恢复到哪一个改变号(SCN)，在正常生产中，获取SCN的办法其实也有很多，如查询数据库字典表(V$archived_log or v$log_history)，或分析归档与联机日志(logmnr)等。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--联机日志损坏</title>
    <url>/2011/03/08/oracle_troubleshoot_online_log_recovery/</url>
    <content><![CDATA[<h1 id="sun-pi-fei-dang-qian-lian-ji-ri-zhi">损坏非当前联机日志</h1>
<h2 id="bu-zou-yi-qi-dong-shu-ju-ku-bao-cuo-ora-00313-he-ora-00312">步骤一  启动数据库，报错：ORA-00313和ORA-00312</h2>
<pre><code class="language-shell">SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-00313: 无法打开日志组 3 (用于线程 1) 的成员
ORA-00312: 联机日志 3 线程 1: '/opt/oracle/oradata/mmsgdb/redo03.log'
</code></pre>
<h2 id="bu-zou-er-cha-kan-v-log-shi-tu">步骤二  查看v$log视图</h2>
<pre><code class="language-shell">SQL&gt; select group#,sequence#,archived,status from v$log;

    GROUP#  SEQUENCE# ARC STATUS
---------- ---------- --- ----------------
         1          1 NO  CURRENT
         3          0 YES UNUSED
         2          0 YES UNUSED

SQL&gt;
</code></pre>
<p>上述结果显示，联机日志3不是当前日志，且已经归档。</p>
<h2 id="bu-zou-san-yong-clear-ming-ling-zhong-jian-gai-ri-zhi-wen-jian">步骤三   用CLEAR命令重建该日志文件</h2>
<pre><code class="language-shell">SQL&gt; alter database clear logfile group 3;

数据库已更改。

如果是该日志组还没有归档，则需要用
SQL&gt;alter database clear unarchived logfile group 3;
</code></pre>
<h2 id="bu-zou-si-da-kai-shu-ju-ku-bing-bei-fen-shu-ju-ku">步骤四   打开数据库，并备份数据库</h2>
<pre><code class="language-shell">SQL&gt; alter database open;

数据库已更改。

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、如果损坏的是非当前的联机日志文件，一般只需要clear就可以重建该日志文件，但是如果该数据库处于归档状态但该日志还没有归档，就需要强行clear。</p>
</li>
<li class="lvl-2">
<p>2、建议clear，特别是强行clear后作一次数据库的全备份。</p>
</li>
<li class="lvl-2">
<p>3、此方法适用于归档与非归档数据库.</p>
</li>
</ul>
<h1 id="sun-pi-dang-qian-lian-ji-ri-zhi">损坏当前联机日志</h1>
<p>归档模式下日志损坏有两种情况，</p>
<h2 id="yi-shu-ju-ku-zheng-chang-guan-bi-ri-zhi-wen-jian-zhong-mei-you-wei-jue-de-shi-wu-xu-yao-shi-li-hui-fu">一、数据库正常关闭，日志文件中没有未决的事务需要实例恢复，</h2>
<p>当前日志组的损坏，可以直接使用alter database clear unarchived logfile group N;命令来重建，步骤如下：</p>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期二 3月 8 17:46:33 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; exit
从 Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开
oracle@mmsc103:~&gt; cd oradata/mmsgdb/
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf redo02.log 
oracle@mmsc103:~/oradata/mmsgdb&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期二 3月 8 17:47:14 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

已连接到空闲例程。

SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-00313: 无法打开日志组 2 (用于线程 1) 的成员
ORA-00312: 联机日志 2 线程 1: '/opt/oracle/oradata/mmsgdb/redo02.log'


SQL&gt; alter database clear unarchived logfile group 2;

数据库已更改。

SQL&gt; alter database open;

数据库已更改。

SQL&gt;
</code></pre>
<h2 id="er-ri-zhi-zu-zhong-you-huo-dong-shi-wu-xu-yao-jie-zhi-hui-fu">二、日志组中有活动事务，需要介质恢复，</h2>
<p>日志组需要用来数据同步，有两种解决方法：</p>
<p>1、通过不完全恢复，保持数据库数据一致性，这种方法要求数据库运行在归档方式下，且有可用的数据文件的备份；</p>
<h3 id="bu-zou-yi-mo-ni-dang-qian-ri-zhi-zu-zhong-ri-zhi-wen-jian-sun-pi">步骤一  模拟当前日志组中日志文件损坏</h3>
<pre><code class="language-shell">SQL&gt; set wrap off
SQL&gt; set linesize 200
SQL&gt; select * from v$log;

    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS           FIRST_CHANGE# FIRST_TIME
---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- --------------
         1          1          4   52428800          1 YES INACTIVE                754910 08-3月 -11
         2          1          0   52428800          1 YES UNUSED                  776870 08-3月 -11
         3          1          6   52428800          1 NO  CURRENT                 798385 08-3月 -11

SQL&gt; host          
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf redo03.log 
oracle@mmsc103:~/oradata/mmsgdb&gt; exit
exit
</code></pre>
<h3 id="bu-zou-er-qi-dong-shu-ju-ku-bao-cuo">步骤二  启动数据库，报错</h3>
<pre><code class="language-shell">SQL&gt; startup force
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-00313: 无法打开日志组 3 (用于线程 1) 的成员
ORA-00312: 联机日志 3 线程 1: '/opt/oracle/oradata/mmsgdb/redo03.log'
ORA-27037: 无法获得文件状态
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3


SQL&gt; select * from v$log;

    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS           FIRST_CHANGE# FIRST_TIME
---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- --------------
         1          1          4   52428800          1 YES INACTIVE                754910 08-3月 -11
         3          1          6   52428800          1 NO  CURRENT                 798385 08-3月 -11
         2          1          0   52428800          1 YES UNUSED                  776870 08-3月 -11

SQL&gt;
</code></pre>
<h3 id="bu-zou-san-clear-bu-cheng-gong">步骤三  clear不成功</h3>
<pre><code class="language-shell">SQL&gt; alter database clear unarchived logfile group 3;
alter database clear unarchived logfile group 3
*
第 1 行出现错误:
ORA-01624: 日志 3 是紧急恢复实例 mmsgdb (线程 1) 所必需的
ORA-00312: 联机日志 3 线程 1: '/opt/oracle/oradata/mmsgdb/redo03.log'


SQL&gt;
</code></pre>
<h3 id="bu-zou-si-kao-bei-you-xiao-de-bei-fen-jin-xing-bu-wan-quan-hui-fu">步骤四  拷贝有效的备份，进行不完全恢复</h3>
<p>文件拷贝</p>
<pre><code class="language-shell">oracle@mmsc103:~&gt; cd bak_20110307/mmsgdb/
oracle@mmsc103:~/bak_20110307/mmsgdb&gt; l
total 2256564
drwxr-x--- 2 oracle oinstall       4096 2011-03-07 15:47 ./
drwxr-x--- 3 oracle oinstall       4096 2011-03-07 15:46 ../
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 15:46 control01.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 15:46 control02.ctl
-rw-r----- 1 oracle oinstall    9912320 2011-03-07 15:46 control03.ctl
-rw-r----- 1 oracle oinstall 1048584192 2011-03-07 15:47 mmsgdata01
-rw-r----- 1 oracle oinstall  524296192 2011-03-07 15:47 mmsgdata02
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 15:47 redo01.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 15:47 redo02.log
-rw-r----- 1 oracle oinstall   52429312 2011-03-07 15:47 redo03.log
-rw-r----- 1 oracle oinstall  209723392 2011-03-07 15:47 rman_data.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-07 15:47 rman_tmp.dbf
-rw-r----- 1 oracle oinstall  288235520 2011-03-07 15:47 sysaux01.dbf
-rw-r----- 1 oracle oinstall  356524032 2011-03-07 15:47 system01.dbf
-rw-r----- 1 oracle oinstall   20979712 2011-03-07 15:47 temp01.dbf
-rw-r----- 1 oracle oinstall  209723392 2011-03-07 15:47 undotbs01.dbf
-rw-r----- 1 oracle oinstall    5251072 2011-03-07 15:47 users01.dbf
oracle@mmsc103:~/bak_20110307/mmsgdb&gt; cp * ../../oradata/mmsgdb/

不完全恢复
SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
SQL&gt; recover database until cancel;
完成介质恢复。
SQL&gt; alter database open resetlogs;

数据库已更改。

SQL&gt;
</code></pre>
<p>注意：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这个时候是不能用RMAN进行恢复的，否则报错：</p>
</li>
</ul>
<pre><code class="language-shell">ORA-00283: 恢复会话因错误而取消
ORA-00313: 无法打开日志组 3 (用于线程 1) 的成员
ORA-00312: 联机日志 3 线程 1: '/opt/oracle/oradata/mmsgdb/redo03.log'
ORA-27037: 无法获得文件状态
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、这种办法恢复的数据库是一致的不完全恢复，会丢失当前联机日志中的事务数据</p>
</li>
<li class="lvl-2">
<p>2、这种方法适合于归档数据库并且有可用的数据库全备份。</p>
</li>
<li class="lvl-2">
<p>3、恢复成功之后，记得再做一次数据库的全备份。</p>
</li>
<li class="lvl-2">
<p>4、建议联机日志文件一定要实现镜相在不同的磁盘上，避免这种情况的发生，因为任何数据的丢失对于生产来说都是不容许的。</p>
</li>
</ul>
<p>2、通过强制性恢复，这种方法会导致数据的不一致性，推荐使用方法一。</p>
<h3 id="bu-zou-yi-mo-ni-dang-qian-ri-zhi-zu-zhong-ri-zhi-cheng-yuan-bei-sun-pi">步骤一 模拟当前日志组中日志成员被损坏</h3>
<pre><code class="language-shell">SQL&gt; set wrap off
SQL&gt; set linesize 200
SQL&gt; select * from v$log;

    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS           FIRST_CHANGE# FIRST_TIME
---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- --------------
         1          1          1   52428800          1 NO  CURRENT                 688817 08-3月 -11
         2          1          0   52428800          1 YES UNUSED                       0
         3          1          0   52428800          1 YES UNUSED                       0

SQL&gt; host
oracle@mmsc103:~/oradata/mmsgdb&gt; rm -rf redo01.log 
oracle@mmsc103:~/oradata/mmsgdb&gt; exit
exit

SQL&gt; startup force
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-00313: 无法打开日志组 1 (用于线程 1) 的成员
ORA-00312: 联机日志 1 线程 1: '/opt/oracle/oradata/mmsgdb/redo01.log'
ORA-27037: 无法获得文件状态
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3

SQL&gt;
</code></pre>
<h3 id="bu-zou-er-xiu-gai-pfile-wen-jian-zeng-jia-yin-xing-can-shu">步骤二  修改pfile文件，增加隐性参数</h3>
<pre><code class="language-shell">vi /opt/oracle/admin/mmsgdb/pfile/init.ora.232011183420
#add for test by wangyunzeng
_allow_resetlogs_corruption=TRUE
</code></pre>
<h3 id="bu-zou-san-tong-guo-pfile-wen-jian-qi-dong-shu-ju-ku">步骤三  通过pfile文件启动数据库</h3>
<pre><code class="language-shell">SQL&gt; startup force pfile='/opt/oracle/admin/mmsgdb/pfile/init.ora.232011183420' 
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
ORA-00313: 无法打开日志组 1 (用于线程 1) 的成员
ORA-00312: 联机日志 1 线程 1: '/opt/oracle/oradata/mmsgdb/redo01.log'
ORA-27037: 无法获得文件状态
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
</code></pre>
<h3 id="bu-zou-si-jin-xing-jie-zhi-hui-fu">步骤四  进行介质恢复</h3>
<pre><code class="language-shell">SQL&gt; recover database until cancel;
ORA-00279: 更改 688820 (在 03/08/2011 18:14:25 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/flash_recovery_area/MMSGDB/archivelog/2011_03_08/o1_mf_1_1_%u_.arc
ORA-00280: 更改 688820 (用于线程 1) 在序列 #1 中


指定日志: {&lt;RET&gt;=suggested | filename | AUTO | CANCEL}
cancel
ORA-01547: 警告: RECOVER 成功但 OPEN RESETLOGS 将出现如下错误
ORA-01194: 文件 1 需要更多的恢复来保持一致性
ORA-01110: 数据文件 1: '/opt/oracle/oradata/mmsgdb/system01.dbf'


ORA-01112: 未启动介质恢复


SQL&gt; alter database open resetlogs;

数据库已更改。

SQL&gt;
</code></pre>
<h3 id="bu-zou-wu-guan-bi-shu-ju-ku-qu-diao-pfile-wen-jian-zhong-yin-xing-can-shu-zhong-qi-shu-ju-ku">步骤五   关闭数据库，去掉pfile文件中隐性参数，重启数据库</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8417955840 bytes
Fixed Size                  2146024 bytes
Variable Size            4429185304 bytes
Database Buffers         3959422976 bytes
Redo Buffers               27201536 bytes
数据库装载完毕。
数据库已经打开。
SQL&gt; select * from v$log;

    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS           FIRST_CHANGE# FIRST_TIME
---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- --------------
         1          1          1   52428800          1 NO  CURRENT                 688821 08-3月 -11
         2          1          0   52428800          1 YES UNUSED                       0
         3          1          0   52428800          1 YES UNUSED                       0

SQL&gt; show parameter spfile

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
spfile                               string      /opt/oracle/product/11g/dbs/sp
SQL&gt;
</code></pre>
<p>这里使用的是spfile文件，所以不需要修改pfile文件也可以，只有重启数据库就行。</p>
<h3 id="bu-zou-liu-bei-fen-zheng-ge-shu-ju-ku">步骤六 备份整个数据库</h3>
<p>物理冷备或者物理热备或者RMAN备份都行。</p>
<h3 id="bu-zou-qi-dao-ru-shu-ju">步骤七  导入数据</h3>
<p>如果有相关的exp导出的数据，可以执行imp导入操作，毕竟数据发生丢失。</p>
<h3 id="bu-zou-ba-biao-shu-ju-fen-xi">步骤八  表数据分析</h3>
<p>建议执行一下表分析</p>
<pre><code class="language-shell">SQL&gt; ANALYZE TABLE time VALIDATE STRUCTURE CASCADE;

表已分析。
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、该恢复方法是没有办法之后的恢复方法，一般情况下建议不要采用，因为该方法可能导致数据库的不一致</p>
</li>
<li class="lvl-2">
<p>2、该方法也丢失数据，但是丢失的数据没有上一种方法的数据多，主要是未写入数据文件的已提交或未提交数据。</p>
</li>
<li class="lvl-2">
<p>3、建议成功后严格执行以上的6到8步，完成数据库的检查与分析</p>
</li>
<li class="lvl-2">
<p>4、全部完成后做一次数据库的全备份</p>
</li>
<li class="lvl-2">
<p>5、建议联机日志文件一定要实现镜相在不同的磁盘上，避免这种情况的发生，因为任何数据的丢失对于生产来说都是不容许的</p>
</li>
</ul>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Perl脚本实现oracle RMAN自动备份</title>
    <url>/2011/03/11/rman_auto_backup/</url>
    <content><![CDATA[<p>通过rman，实现定期自动备份，直接上脚本</p>
<p>[oracle@mmsc103:~/rmanbak]&gt; vi <a href="http://backup.pl">backup.pl</a></p>
<pre><code class="language-shell">#!/usr/bin/perl
##################################################
###    作用：rman定时任务脚本         ###
###    日期：2011-03-11           ###
###    作者：wyz              ###
##################################################

#获取系统当前时间
my ($sec,$min,$hour,$day,$month,$year)= localtime(time());
$year+=1900;
$month=sprintf("%02d",$month+1);
$day=sprintf("%02d",$day);
$hour=sprintf("%02d",$hour);
$min=sprintf("%02d",$min);
$sec=sprintf("%02d",$sec);
my $daytime = "$year$month$day$hour$min$sec";

system("/opt/oracle/product/11g/bin/rman  cmdfile = '/opt/oracle/rmanbak/everydaybak.rman' msglog=/opt/oracle/rmanbak/everydaybak_$daytime.log");
</code></pre>
<pre><code class="language-shell">[oracle@mmsc103:~/rmanbak]&gt; more everydaybak.rman
#script.:fullbakup.rman
# creater:wangyunzeng
# date:2011-03-11
# desc:backup all database datafile in archive with rman
# connect database
connect target rman/rman;
connect catalog [rman/rman@mmsgdb];

#start backup database
run
{
allocate channel t1 type disk; 
configure controlfile autobackup format for device type disk to '/opt/oracle/rmanbak/controlfile_bak_%F';            
backup database format 'fullbak_%s_%p_%u'  (archivelog all );
crosscheck backupset;
delete noprompt obsolete;
delete noprompt archivelog until time "sysdate -3";
release channel t1;     
}
#end
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-01031</title>
    <url>/2011/03/04/oracle_troubleshoot_ora_01031/</url>
    <content><![CDATA[<h1 id="ora-01031-quan-xian-wen-ti-jie-jue-fang-fa">ORA-01031  权限问题解决方法</h1>
<h2 id="biao-xiang">表象</h2>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/network/admin&gt; sqlplus sys/sys@mmsgdb as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Sun May 15 16:44:47 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

ERROR:
ORA-01031: 鏉冮檺涓嶈冻


Enter user-name: 
</code></pre>
<p>报错，ORA-01031，用户权限不足导致，官方参考解决方法信息如下：</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/network/admin&gt; oerr ora 01031
01031, 00000, "insufficient privileges"
// *Cause: An attempt was made to change the current username or password
//         without the appropriate privilege. This error also occurs if
//         attempting to install a database without the necessary operating
//         system privileges.
//         When Trusted Oracle is configure in DBMS MAC, this error may occur
//         if the user was granted the necessary privilege at a higher label
//         than the current login.
// *Action: Ask the database administrator to perform the operation or grant
//          the required privileges.
//          For Trusted Oracle users getting this error although granted the
//          the appropriate privilege at a higher label, ask the database
//          administrator to regrant the privilege at the appropriate label.
oracle@mmsc101:~/product/11/network/admin&gt; 
</code></pre>
<h2 id="jie-jue-guo-cheng">解决过程</h2>
<p>尝试赋权限</p>
<pre><code class="language-shell">grant create session to sys with admin option;
grant dba to sys;
alter user sys default role all;
</code></pre>
<p>赋权限后尝试登陆，结果：失败</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/network/admin&gt; sqlplus sys/sys@mmsgdb as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Sun May 15 16:59:57 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

ERROR:
ORA-01031: 鏉冮檺涓嶈冻


Enter user-name: 
</code></pre>
<p>之后，查询视图</p>
<pre><code class="language-shell">SQL&gt; select * from v$pwfile_users;

no rows selected

SQL&gt;
</code></pre>
<p>视图表中无记录，说明当前oracle并没有使用口令文件，而在系统的dbs目录下，的确是有个口令文件的：orapwmmsgdb，难道口令文件有问题，还是用户的密码不对。这里先否定用户密码不对问题，因为如果密码不对，报错则不是ORA-01031了，而是其他的ORA错误码了，问题就出现在口令文件上了。</p>
<p>dbs目录下，删除原来的口令文件，尝试重新创建新的口令文件。</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/dbs&gt; orapwd
Usage: orapwd file=&lt;fname&gt; password=&lt;password&gt; entries=&lt;users&gt; force=&lt;y/n&gt; ignorecase=&lt;y/n&gt; nosysdba=&lt;y/n&gt;

  where
    file - name of password file (required),
    password - password for SYS, will be prompted if not specified at command line,
    entries - maximum number of distinct DBA (optional),
    force - whether to overwrite existing file (optional),
    ignorecase - passwords are case-insensitive (optional),
    nosysdba - whether to shut out the SYSDBA logon (optional Database Vault only).
    
  There must be no spaces around the equal-to (=) character.
</code></pre>
<p>创建新的口令文件</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/dbs&gt; orapwd file=/opt/oracle/product/11/dbs/orapwmmsgdb password=sys
</code></pre>
<p>重启数据库</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/dbs&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Sun May 15 17:08:23 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options

SQL&gt; startup force
ORACLE instance started.

Total System Global Area  567922688 bytes
Fixed Size                  2161600 bytes
Variable Size             243270720 bytes
Database Buffers          314572800 bytes
Redo Buffers                7917568 bytes
Database mounted.
Database opened.
SQL&gt; 
</code></pre>
<p>尝试登陆，还是报错，继续定位</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/dbs&gt; sqlplus sys/sys@mmsgdb as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Sun May 15 17:08:54 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

ERROR:
ORA-01031: 鏉冮檺涓嶈冻


Enter user-name: 
ERROR:
ORA-01017: invalid username/password; logon denied


Enter user-name: 
ERROR:
ORA-01017: invalid username/password; logon denied


SP2-0157: unable to CONNECT to ORACLE after 3 attempts, exiting SQL*Plus
oracle@mmsc101:~/product/11/dbs&gt; 
</code></pre>
<p>再次查询视图</p>
<pre><code class="language-shell">SQL&gt; select * from v$pwfile_users;

no rows selected

SQL&gt;
</code></pre>
<p>仍然无数据，说明还是没有使用口令文件，继续……</p>
<p>查看tns文件信息</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/network/admin&gt; more tnsnames.ora 
MMSGDB =
  (DESCRIPTION =
    (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.49.36)(PORT = 1521))
    (CONNECT_DATA =
      (SERVER = DEDICATED)
      (SERVICE_NAME = ora11)
    )
  )

MMSGDB_37 =
  (DESCRIPTION =
    (ADDRESS_LIST =
      (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.49.37)(PORT = 1521))
    )
    (CONNECT_DATA =
      (SERVICE_NAME = mmsgdb)
    )
  )
oracle@mmsc101:~/product/11/network/admin&gt;
</code></pre>
<p>tns文件信息显示，数据库名是mmsgdb，实例名是ora11，orapw的帮助命令中，并没有写明filename中该如何命名，实际命名规则则是：<br>
file=$ORACLE_HOME/dbs/orapw$ORACLE_SID</p>
<p>$ORACLE_SID是什么</p>
<p>这里的$ORACLE_SID是什么呢？数据库名？实例名？</p>
<p>都不是，确切的讲，这个东西是环境变量值。证据如下：</p>
<pre><code class="language-shell">oracle@mmsc101:~&gt; more .bash_profile 

export ORACLE_BASE=/opt/oracle
export ORACLE_HOME=/opt/oracle/product/11
export ORA_CRS_HOME=/opt/oracle/product/11
export ORACLE_SID=ora11
export ORACLE_TERM=xterm
export LD_LIBRARY_PATH=$ORACLE_HOME/lib64:$ORACLE_HOME/lib:/usr/lib
export ORACLE_DOC=$ORACLE_HOME/doc
export PATH=$ORACLE_HOME/bin:/sbin:/usr/sbin:/usr/ccs/bin:/usr/bin:/sbin:$ORACLE_HOME/OPatch_11.1.0.8.1/OPatch:$PATH:/bin:/usr/ccs/b
in
export TNS_NAMES=$ORACLE_HOME/network/admin
export TNS_ADMIN=$ORACLE_HOME/network/admin
export DISPLAY=10.137.48.37:1.0
# CLASSPATH must include the following JRE locations:
CLASSPATH=/opt/oracle/product/11/JRE:/opt/oracle/product/11/jlib:/opt/oracle/product/11/rdbms/jlib
export CLASSPATH=$CLASSPATH:/opt/oracle/product/11/network/jlib
export NLS_LANG=AMERICAN_AMERICA.AL32UTF8
</code></pre>
<p>之前orapw创建的口令文件名称是orapwmmsgdb，显然是没有正确的口令文件，导致OS认证失败，尝试与MMSGDB建立连接，没有权限去登陆其他的数据库，自然报权限问题。</p>
<h2 id="huo-qu-jie-jue-fang-fa">获取解决方法</h2>
<p>重新创建正确的口令文件：</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/network/admin&gt; orapwd file=/opt/oracle/product/11/dbs/orapwora11 password=sys
</code></pre>
<h2 id="yan-zheng-fang-fa-shi-fou-you-xiao">验证方法是否有效</h2>
<p>查询视图</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/network/admin&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Sun May 15 18:05:49 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options

SQL&gt; select * from v$pwfile_users;

USERNAME
--------------------------------------------------------------------------------
SYSDBA          SYSOPER         SYSASM
--------------- --------------- ---------------
SYS
TRUE            TRUE            FALSE


SQL&gt;
</code></pre>
<p>已经有数据了，尝试sys用户登陆试试：</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11/network/admin&gt; sqlplus sys/sys@mmsgdb as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Sun May 15 17:45:21 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options

SQL&gt; exit
Disconnected from Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options
oracle@mmsc101:~/product/11/network/admin&gt; 
</code></pre>
<p>登陆成功，问题得到解决。</p>
<h2 id="zong-jie">总结</h2>
<p>1、这个问题，开始是找寻了network/admin目录下的sqlnet.ora文件，认为数据库解析文件出现了问题，也给该文件增加了权限，没啥效果。接着尝试tnsping操作，发现是可以与数据库正常建立连接的，此路就此终止，因为不是sqlnet.ora文件导致出现的问题；</p>
<p>2、就是用户的口令了，刚开始是不知道sys用户的密码是多少，报错也就没放在心上，就直接修改了sys的密码为sys，尝试登陆，还是报错；</p>
<p>3、再接着就是给sys用户副权限，因为报错就是权限不足啊，赋了权限后还是没解决；</p>
<p>4、认证出现了问题？于是就查找口令问题（因为登陆方式中使用了口令认证方式登陆，而非OS认证），查询视图，没数据，而dbs目录下有口令文件，疑惑就产生了……</p>
<p>做了上述操作后，才发现，orapw命令的帮助信息并不是很详尽，给出的file命名规则，感觉可以随意命名的，结果却不是，规则在帮助命令中展示的并不详细。</p>
<p>ORA-01031这个权限错误问题，总的总结如下：遇见整问题，先别到处乱找东西，先查询视图，因为出现问题的最大可能性就是口令文件命名出错了，而且口令文件是区分大小写的。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle备份与恢复概述</title>
    <url>/2011/03/26/oracle_backup_restore/</url>
    <content><![CDATA[<h1 id="shi-yao-shi-bei-fen">什么是备份</h1>
<p>所谓备份，就是把数据库复制到转储设备的过程。其中，转储设备是指用于放置数据库拷贝的磁带(sbt)或磁盘(disk)。通常也将存放于转储设备中的数据库的拷贝称为原数据库的备份或转储。</p>
<h1 id="bei-fen-fen-lei">备份分类</h1>
<p>ORACLE数据库的备份分为物理备份和逻辑备份两种。</p>
<h2 id="wu-li-bei-fen">物理备份</h2>
<p>物理备份是将实际组成数据库的操作系统文件从一处拷贝到另一处的备份过程。可以使用 Oracle 的恢复管理器（Recovery Manager，RMAN）或操作系统命令进行数据库的物理备份。</p>
<h2 id="luo-ji-bei-fen">逻辑备份</h2>
<p>逻辑备份是利用SQL语言从数据库中抽取数据并存于二进制文件的过程。Oracle提供的逻辑备份工具是exp/expdp。数据库逻辑备份是物理备份的补充。</p>
<p>根据在物理备份时数据库的状态，可以将备份分为一致性备份（consistent backup）和不一致性备份（inconsistent backup）两种：</p>
<h2 id="yi-zhi-xing-bei-fen">一致性备份</h2>
<p>一致性备份是当数据库的所有可读写的数据库文件和控制文件具有相同的系统改变号（SCN），并且数据文件不包含当前 SCN 之外的任何改变。在做数据库检查点时，Oracle 使所有的控制文件和数据文件一致。对于只读表空间和脱机的表空间，Oracle 也认为它们是一致的。使数据库处于一致状态的唯一方法是数据库正常关闭（用shutdown normal 或 shutdown immediate 命令关闭）。因此，只有在以下条件下的备份是一致性备份：</p>
<p>数据库正常关闭（用shutdown normal 或 shutdown immediate 命令关闭）。</p>
<h2 id="fei-yi-zhi-xing-bei-fen">非一致性备份</h2>
<p>不一致性备份是当数据库的可读写的数据库文件和控制文件的系统改变号（SCN）在不一致条件下的备份。对于一个 7*24 工作的数据库来说，由于不可能关机，而数据库数据是不断改变的，因此只能进行不一致备份。在 SCN 号不一致的条件下，数据库必须通过应用重做日志使 SCN 一致的情况下才能启动。因此，如果进行不一致备份，数据库必须设为归档状态，并对重做日志归档才有意义。在以下条件下的备份是不一致性备份：</p>
<p>数据库处于打开状态；</p>
<p>数据库处于关闭状态，但是用非正常手段关闭的。例如，数据库是通过 shutdown abort 或机器掉电等等方法关闭的。</p>
<p>汇总如下图所示：</p>
<img class="shadow" src="/img/in-post/oracle_backup.png" width="600">
<h1 id="shi-yao-shi-hui-fu">什么是恢复</h1>
<p>所谓恢复，就是把数据库由存在故障的状态转变为无故障状态的过程。</p>
<h2 id="gen-ju-chu-xian-gu-zhang-de-yuan-yin-hui-fu-fen-wei-liang-chong-lei-xing">根据出现故障的原因，恢复分为两种类型</h2>
<h3 id="shi-li-hui-fu">实例恢复</h3>
<p>这种恢复是Oracle实例出现失败后，Oracle自动进行的恢复。</p>
<h3 id="jie-zhi-hui-fu">介质恢复</h3>
<p>这种恢复是当存放数据库的介质出现故障时所做的恢复。本文后面提到的恢复都是指介质恢复。</p>
<p>装载（restore）物理备份与恢复（recover）物理备份是介质恢复的手段。装载是将备份考回到磁盘，恢复是利用重做日志（物理备份的一部分）修改考回到磁盘的数据文件（物理备份的另一部分），从而恢复数据库的过程。</p>
<h2 id="gen-ju-shu-ju-ku-de-hui-fu-cheng-du-jiang-hui-fu-fang-fa-fen-wei-liang-chong-lei-xing">根据数据库的恢复程度，将恢复方法分为两种类型</h2>
<h3 id="wan-quan-hui-fu">完全恢复</h3>
<p>将数据库恢复到数据库失败时数据库的状态。这种恢复是通过装载数据库备份和并应用全部的重做日志做到的。</p>
<h3 id="bu-wan-quan-hui-fu">不完全恢复</h3>
<p>将数据库恢复到数据库失败前的某一时刻数据库的状态。这种恢复是通过装载数据库备份和并应用部分的重做日志做到的。进行不完全恢复后必须在启动数据库时用 resetlogs 选项重设联机重做日志。</p>
<p>例如，在上午10：00，由于磁盘损坏导致数据库中止使用。现在使用两种方法进行数据库的恢复，第一种方法使数据库可以正常使用，且使恢复后与损坏时（10：00）数据库中的数据相同，那么第一种恢复方法就属于完全恢复类型；第二种方法能使数据库正常使用，但只能使恢复后与损坏前（例如9：00）数据库中的数据相同，没能恢复数据库到失败时（10:00）数据库的状态，那么第二种恢复方法就属于不完全恢复类型。</p>
<p>事实上，如果数据库备份是一致性的备份，则装载后的数据库即可使用，从而也可以不用重做日志恢复到数据库备份时的点。这也是一种不完全恢复。</p>
<h1 id="bei-fen-yu-hui-fu-de-guan-xi">备份与恢复的关系</h1>
<p>备份一个ORACLE数据库，类似于买医疗保险——在遇到疾病之前不会意识到它的重要性，获得保险金的数量取决于保险单的种类。同理，随着制作备份的种类和频繁程度的不同，数据库发生故障后其恢复的可行性、难度与所花费的时间也不同。</p>
<p>数据库故障是指数据库运行过程中影响数据库正常使用的特殊事件。数据库故障有许多类型，最严重的是介质失败（如磁盘损坏），这种故障如不能恢复将导致数据库中数据的丢失。数据库故障类型有：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>语句失败</p>
</li>
<li class="lvl-2">
<p>用户进程失败</p>
</li>
<li class="lvl-2">
<p>实例失败</p>
</li>
<li class="lvl-2">
<p>用户或应用错误操作    #这类错误可能是意外地删除了表中的数据等错误操作。</p>
</li>
<li class="lvl-2">
<p>介质失败              #如硬盘失败，硬盘中的数据丢失。</p>
</li>
<li class="lvl-2">
<p>自然灾害              #如地震、洪水等。</p>
</li>
</ul>
<p>由于故障类型的不同，恢复数据库的方法也不同。通过装载备份来恢复数据库既是常用的恢复手段，也是恢复介质失败故障的主要方法。</p>
<h1 id="bei-fen-yu-hui-fu-yao-kao-lu-de-wen-ti">备份与恢复要考虑的问题</h1>
<p>备份与恢复要考虑以下的三个问题：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>备份与恢复策略要考虑的商业、操作、及技术问题</p>
</li>
<li class="lvl-2">
<p>灾难恢复计划的组成</p>
</li>
<li class="lvl-2">
<p>测试备份与恢复策略的重要性</p>
</li>
</ul>
<p>能够进行什么样的恢复依赖于有什么样的备份。作为 DBA，有责任从以下三个方面维护数据库的可恢复性：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使数据库的失效次数减到最少，从而使数据库保持最大的可用性</p>
</li>
<li class="lvl-2">
<p>当数据库不可避免地失效后，要使恢复时间减到最少，从而使恢复的效率达到最高</p>
</li>
<li class="lvl-2">
<p>当数据库失效后，要确保尽量少的数据丢失或根本不丢失，从而使数据具有最大的可恢复性</p>
</li>
</ul>
<h1 id="oracle-de-yun-xing-fang-shi">Oracle的运行方式</h1>
<p>oracle数据库有两种运行方式：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>归档方式（archivelog）</p>
</li>
<li class="lvl-2">
<p>非归档方式（noarchivelog）</p>
</li>
</ul>
<p>归档方式的目的是当数据库发生故障时可最大限度的恢复数据库，可以保证不丢失任何已提交的数据；不归档方式只能恢复数据库到最近的回收点（冷备份或是逻辑备份）。我们根据数据库的高可用性和用户可承受丢失的工作量的多少，对于生产数据库，强烈要求采用归档方式；那些正在开发和调试的数据库可以采用不归档方式。</p>
<p>默认情况下，安装oracle数据库是非归档方式，可以修改数据库的运行方式的，具体操作如下：</p>
<h2 id="you-fei-gui-dang-fang-shi-diao-zheng-cheng-gui-dang-fang-shi">由非归档方式调整成归档方式</h2>
<pre><code class="language-shell">node1:oracle:mmsgdb &gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Tue Feb 22 11:42:35 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; archive log list
Database log mode              No Archive Mode  #非归档方式
Automatic archival             Disabled
Archive destination            /opt/oracle/product/11g/dbs/arch
Oldest online log sequence     4911
Current log sequence           4913
SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; startup mount
ORA-32004: obsolete and/or deprecated parameter(s) specified
ORACLE instance started.

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size            1342179856 bytes
Database Buffers          251658240 bytes
Redo Buffers                7413760 bytes
Database mounted.
SQL&gt; alter database archivelog;

Database altered.

SQL&gt; alter database open;

Database altered.

SQL&gt; archive log list
Database log mode              Archive Mode   #归档模方式
Automatic archival             Enabled
Archive destination            /opt/oracle/product/11g/dbs/arch
Oldest online log sequence     4911
Next log sequence to archive   4913
Current log sequence           4913
SQL&gt;
</code></pre>
<h2 id="you-gui-dang-fang-shi-diao-zheng-cheng-fei-gui-dang-fang-shi">由归档方式调整成非归档方式</h2>
<pre><code class="language-shell">SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; startup mount
ORA-32004: obsolete and/or deprecated parameter(s) specified
ORACLE instance started.

Total System Global Area 1603411968 bytes
Fixed Size                  2160112 bytes
Variable Size            1342179856 bytes
Database Buffers          251658240 bytes
Redo Buffers                7413760 bytes
Database mounted.
SQL&gt; alter database noarchivelog;

Database altered.

SQL&gt; alter database open; 

Database altered.

SQL&gt; archive log list;
Database log mode              No Archive Mode
Automatic archival             Disabled
Archive destination            /opt/oracle/product/11g/dbs/arch
Oldest online log sequence     4911
Current log sequence           4913
SQL&gt;
</code></pre>
<p>数据库运行在归档方式下，是以消耗一部分性能作代价的，因为日志要归档，系统io比非归档方式要高，但它不会丢失已经提交的任何数据。</p>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>从归档方式修改到非归档方式后，一定要做一次数据库全冷备份。</p>
</li>
</ul>
<h1 id="wu-li-bei-fen-yu-hui-fu">物理备份与恢复</h1>
<h2 id="leng-bei">冷备</h2>
<p>冷备步骤如下：</p>
<h3 id="1-zheng-chang-guan-bi-shu-ju-ku">1、正常关闭数据库</h3>
<pre><code class="language-shell">shutdown immediate
</code></pre>
<h3 id="2-kao-bei-shu-ju-ku-wen-jian-dao-zhi-ding-cun-chu-wei-zhi">2、拷贝数据库文件到指定存储位置</h3>
<p>这里的数据库文件包括数据文件、控制文件、重做日志文件、spfile文件（可选）。</p>
<h3 id="3-qi-dong-shu-ju-ku">3、启动数据库</h3>
<pre><code class="language-shell">startup
</code></pre>
<p>冷备的优点是简单、快捷、方便，缺点是备份文件占用空间，且数据只能恢复到备份前状态。日常工作中，可以使用脚本进行数据库的冷备操作，提供一个简单oracle数据库冷备perl脚本：</p>
<pre><code class="language-shell">#/usr/bin/perl

###############################################################
##      作用：数据库备份与还原操作                        ##
##      Create： 2010-12-31                                   ##
###############################################################

## 选择1：冷备
## 选择2：逻辑备份（输入用户名和密码--全表备份或者应用级表备份）
## 选择3：冷恢复
## 选择4：数据导入

#判断当前登录用户，非oracle，退出
my $localuser;      #定义当前登录用户
$localuser = getlogin || (getpwuid($&lt;))[0] || die "Can't find a user here!!!\n";
#print "当前登录用户是$localuser\n";
@foo = @foo[0 .. $#foo];  

##判断oracle用户是否存在
if($localuser eq "oracle")
{
  #当前路径信息
  my $path = `pwd`;
  chomp($path);
  
  @foo = @foo[0 .. $#foo];  
  print '-' x 50,"\n";
  print "请选择操作类型,例如：2 \n";
  print "\n\t1:数据库冷备\t2:数据导出t3:RMAN备份\n";
  print "@foo\n";
  
  chomp ($response = &lt;STDIN&gt;);
  $response = lc($response);
    if($response eq "1")
      {   
      print "\n冷备oracle数据库......\n";
      ##剩余空间检测
      &amp;space;
      chdir "$path";
      #备份执行
      &amp;cool_bak;
      }
    elsif($response eq "2")
      {
        print "\n逻辑备份数据库.\n";
       &amp;logic;
      }
    else
      {
          print "输入非法，操作退出!\n";
          print "@foo\n"; 
      }
  
  #定义子函数
  ##冷备数据库
  sub cool_bak
  {
     #获取时间
     my ($sec,$min,$hour,$day,$month,$year)= localtime(time());
     $year+=1900;
     $month=sprintf("%02d",$month+1);
     $day=sprintf("%02d",$day);
     my $daytime = "$year$month$day$hour$min$sec";
     chomp($daytime);
     
     #备份文件存放路径
     my $path = `pwd`;
     chomp($path);
     
     #目录
     unless (-d "coolbackup")      # 如果目录不存在，创建目录
     {
         mkdir("coolbackup", 0755) || die "Make directory coolbackup error.\n";
     }
     chdir "coolbackup";
     
     
       ##导出当前数据库中系统参数、数据文件、控制文件、重做日志文件等信息
       print "\n";
       print '-' x 50, "\n";
       
       ##检测数据库运行状态，只有在open状态下才能进行参数写文件的备份
       open(SQLPLUS, "|sqlplus  / as sysdba &gt; loginfo.txt") || die "Execute sqlplus error!\n";
       close(SQLPLUS) || die "Execute sql error!\n";
       
       my $login = `cat loginfo.txt  \| head \-n 7 \| grep \-v SQL \| grep \-v Copyright \| sed \'\/\^\$\/d\'`;
       chomp($login);
       if($login=~ m/Connected to:/ || $login=~ m/连接到:/)
       {
         print "\n数据库处于open状态，可以进行下一步备份操作!\n";
         unlink("./loginfo.txt");
       }
       else
       {
         print "\n数据库被关闭，无法进行下一步备份操作！\n";
         print "\n退出当前备份。\n";
         unlink("./loginfo.txt");
         exit;
         print "\n";
       }
       
       print "oracle冷备第一步：写参数、数据文件信息到文件!\n";
       print "开始写入信息到文件......\n";
       print "\n";
       open (SQLPLUS, "|sqlplus -S / as sysdba &gt;/dev/null") || die "Execute sqlplus error!\n";
       print SQLPLUS "set feedback off\nset sqlnumber off\n";
       print SQLPLUS "set colsep \"\;\"\n";
       print SQLPLUS "set wrap off\n";
       print SQLPLUS "set pagesize 0\nset linesize 32767\n";
       print SQLPLUS "set trimspool off\n";
       print SQLPLUS "set sqlblanklines off\n";
       print SQLPLUS "spool tmp.txt\n";
       print SQLPLUS "select * from v\$parameter;\n";
       print SQLPLUS "select * from props\$;\n";
       print SQLPLUS "select * from v\$datafile;\n";
       print SQLPLUS "select * from v\$controlfile;\n";
       print SQLPLUS "select * from v\$logfile;\n";
       print "\n结束写入信息到文件.\n";
       print "\n";
       print "\n";
       
       
       print '-' x 50, "\n";
       print "oracle冷备第二步：关闭数据库，备份相关文件!\n"; 
       print SQLPLUS "set linesize 80\n";
       print SQLPLUS "spool wyztest.txt\n";
       print SQLPLUS "select \'cp \'\||name \|| \' \./\' from v\$datafile;\n";
       print SQLPLUS "select \'cp \'\||name \|| \' \./\' from v\$controlfile;\n";
       print SQLPLUS "select \'cp \'\||member \|| \' \./\' from v\$logfile;\n";
       
       print SQLPLUS "spool off\n";
       
       ##停止数据库
       system("sleep 2");
       system("cp wyztest.txt coolbak.sh");
       system("chmod \+x coolbak.sh");
       print "开始关闭数据库，请稍候......\n";
       print SQLPLUS "shutdown immediate";
       system("sleep 30");
       &amp;ckstatus;
       print "\n数据库已经停止\n";
       
       #备份文件  
       print "\n开始备份文件，请稍候......\n";
       system("sh coolbak.sh");
       print "\n备份文件结束。\n";
       print "\n";
       print "\n";  
       
       ##备份spfile文件
       print "开始备份系统参数文件\n";
       system("cp \$ORACLE_HOME\/dbs\/spfile\* \.\/");
       print "\n完成系统参数文件备份.\n";
       print "\n";
       print "\n";
       
       ##备份orapw文件
       print "开始备份口令文件\n";
       system("cp \$ORACLE_HOME\/dbs\/orapw\* \.\/");
       print "\n完成口令文件备份.\n";
       print "\n";
       print "\n";
             
       print '-' x 50, "\n";
       print "oracle冷备第三步：启动数据库\n";     
       ##启动数据库        
       print "\n开始启动数据库，请稍候......\n";
       print SQLPLUS "startup\n";
       system("sleep 30");
       &amp;ckstatus;
       print "\n数据库已经启动\n";
       close(SQLPLUS) || die "Execute sql error!\n";
       
       ##格式话parameter文件内容
       system("sed 's\/    \/\/g' tmp.txt  \&gt; tmp0.txt");
       system("sed 's\/\^\[ \\t\]\*\/\/\;s\/\[ \\t\]\*\$\/\/' tmp0.txt \&gt; database.parameter");
       unlink("./tmp.txt");
       unlink("./tmp0.txt");
       print "\n";
       print "\n"; 
       
        
       ##节约空间，压缩备份文件
       print '-' x 50, "\n";
       print "oracle冷备第四步：压缩备份文件，节约空间.\n";   
       chdir "$path";
       print "\n开始进行文件压缩......\n";
       print "\n";
       system("tar cvf coolbackup.tar coolbackup");
       system("sleep 2");
       system("gzip coolbackup.tar");
       system("rm -rf coolbackup");
       system("mv coolbackup.tar.gz coolbackup\_$daytime.tar.gz");
       print "\n文件压缩结束.\n";
       print "\noracle冷备结束.\n";
       print '-' x 50, "\n";
      
  }
  
  ##数据库运行状态检测   
  sub ckstatus
  {
     #检测oracle数据库是否运行                                
       ###已连接到空闲例程。|Connected to an idle instance.       
       ###Connected to:  | 连接到:
                                                     
     open(SQLPLUS, "|sqlplus  / as sysdba &gt; loginfo_ch.txt") || die "Execute sqlplus error!\n";
     close(SQLPLUS) || die "Execute sql error!\n";
     
     my $login_ck = `cat loginfo_ck.txt  \| head \-n 7 \| grep \-v SQL \| grep \-v Copyright \| sed \'\/\^\$\/d\'`;
     chomp($login_ck);
     if($login_ck=~ m/Connected to:/ || $login=~ m/连接到:/)
     {
       print "\t检测数据库当前状态.\n";
       print "\t数据库Open!\n";
       print "\t检测数据库状态结束.\n"; 
     }
     else
     {
       print "\t检测数据库当前状态.\n";
       print "\t数据库Closed.\n";
       print "\t检测数据库状态结束.\n";    
     }
     unlink("./loginfo_ck.txt");
  }
  
  ##剩余空间检测
  sub space
  {
     print "\n剩余空间信息检测\n";
     #判断使用空间路径
     #system("cd \$ORACLE_BASE");
     chdir "$ORACLE_BASE";
     my $orabase=`pwd`;
     chomp($orabase);
     my $mu = substr($orabase,1,3);
     
     #df | grep opt  | awk -F " " '{print $2,$3,$4,$5,$6}'
     my $max_tmp = `df \| grep $mu  \| awk \-F \" \" \'\{print \$2\}\'`;
     my $used_tmp = `df \| grep $mu  \| awk \-F \" \" \'\{print \$3\}\'`;
     my $available_tmp = `df \| grep $mu  \| awk \-F \" \" \'\{print \$4\}\'`;
     my $useper = `df \| grep $mu  | awk \-F \" \" \'\{print \$5\}\'`;
     my $mount = `df \| grep $mu  \| awk \-F \" \" \'\{print \$6}\'`;
     
     my $max= substr($max_tmp/1024/1024,0,8);
     my $used = substr($used_tmp/1024/1024,0,8);
     my $available =  substr($available_tmp/1024/1024,0,8);
     
     chomp($max);
     chomp($used);
     chomp($available);
     chomp($useper);
     chomp($mount);
     
     print "\n当前oracle所使用的空间信息如下：\n";
     print "\t挂载点    ：$mount\n";
     print "\t空间大小  ：$max G\n";
     print "\t已用空间  ：$used G\n";
     print "\t剩余空间  ：$available G\n";
     print "\t空间使用率：$useper\n";
     
     if($available &lt; 2)
      {
         print "\n检测结果如下：\n";
         print "\n\t当前剩余空间小于2G，备份空间不足，备份退出\n";
         exit;
      }
     else
      {
         print "\n检测结果如下：\n";
         print "\n\t当前剩余空间大于2G，可以进行oracle冷份\n";
      }
  }

  sub logic
  {
    print "请输入用户名:\n";
    my $user=&lt;STDIN&gt;;
    chomp($user);
    
    print "请输入密码:\n";
    my $passwd = &lt;STDIN&gt;;
    chomp($passwd);
  
    my $sql="exp $user/$passwd file=myexport$daytime.dmp log=myexport$daytime.log";
    print "\n开始数据库逻辑备份.\n";
    system("$sql");
    print "\n结束数据库逻辑备份.\n";
    
  }
}
else
{
  print "\n当前非oracle用户登录，退出!\n";
  print "\n请使用oracle用户执行本脚本.\n"; 
  print "@foo\n"; 
}
</code></pre>
<h2 id="leng-bei-de-hui-fu">冷备的恢复</h2>
<p>冷备的恢复比较简单，比如数据库数据文件损坏，则关闭数据库后，将原先备份的所有文件再拷贝到相应目录下，重启数据库即可。</p>
<p>通常情况下，控制文件有3个，但无论什么时候，实际使用的只有一个控制文件，建议备份控制文件到不同路径下，当其中一个或者两个控制文件损坏后，可以使用第三个好的控制文件替换损坏的控制文件，并正确命名这些控制文件。</p>
<h1 id="rman-gai-shu">RMAN概述</h1>
<p>RMAN（oracle恢复管理器）是数据库的一种备份与恢复工具，具有多种能力完成备份与恢复工作。RMAN有两个版本：OEM的GUI版本和命令行版本。使用OEM的GUI版本，操作简单，但中间的执行过程无法向我们展示，只有一个最终的执行结果，本文不概述这个版本的使用。</p>
<p>RMAN是一种物理备份，可以用RMAN来备份数据文件、控制文件、参数文件、归档日志文件。我们在数据库出现问题的时候可以通过RMAN物理备份恢复到数据库的失效点。</p>
<h2 id="zhun-bei-gong-zuo">准备工作</h2>
<pre><code class="language-shell">SQL&gt; create tablespace RMAN_DATA datafile '/opt/oracle/oradata/mmsgdb/rman_data.dbf'
  2  size 200M
  3  autoextend off
  4  extent management local
  5  uniform;

表空间已创建。

SQL&gt; create temporary tablespace RMAN_TMP tempfile '/opt/oracle/oradata/mmsgdb/rman_tmp.dbf'
  2  size 20M
  3  autoextend off
  4  extent management local
  5  uniform;

表空间已创建。

SQL&gt; create user rman identified by rman
  2  default tablespace RMAN_DATA
  3  temporary tablespace RMAN_TMP;

用户已创建。

SQL&gt; grant connect ,resource,recovery_catalog_owner to rman;

授权成功。

SQL&gt;exit
</code></pre>
<h2 id="qi-dong-he-lian-jie-dao-rman">启动和连接到RMAN</h2>
<p>关于启动RMAN有几个重要说明，如指定目标数据库和规定一个恢复目录等。下面了解三种使用RMAN工具的数据库连接类型。</p>
<table>
<thead>
<tr>
<th>数据库连接</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>目标数据库</td>
<td>目标数据库是将备份和恢复定为目标的数据库。为了完成任务，要求SYSDAB权限</td>
</tr>
<tr>
<td>恢复目录数据库</td>
<td>恢复目录数据库是个可选数据库，它存储有关备份、恢复的信息和重建数据</td>
</tr>
<tr>
<td>辅助数据库</td>
<td>辅助数据库是备用数据库、复制数据库或辅助实例（备用或TSPITR）</td>
</tr>
</tbody>
</table>
<p>有两种连接到目标数据库的方法：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、从命令行；</p>
</li>
<li class="lvl-2">
<p>2、使用RMAN工具</p>
</li>
</ul>
<h3 id="shi-yong-ming-ling-xing">使用命令行</h3>
<p>在命令行中指定目标和默认连接，nocatalog是可选的，如果留下空白，则为默认使用nocatalog。</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; rman target / nocatalog

恢复管理器: Release 11.1.0.7.0 - Production on 星期五 11月 12 12:31:04 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

连接到目标数据库: INOMC (DBID=1037536304)
使用目标数据库控制文件替代恢复目录

RMAN&gt;
</code></pre>
<h3 id="shi-yong-rman-gong-ju">使用RMAN工具</h3>
<pre><code class="language-shell">oracle@mmsg:~&gt; rman

恢复管理器: Release 11.1.0.7.0 - Production on 星期五 11月 12 12:33:11 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

RMAN&gt; connect target 

连接到目标数据库: INOMC (DBID=1037536304)

RMAN&gt;
</code></pre>
<p>连接到恢复目录相当简单，以下是使用恢复目录的RMAN</p>
<h4 id="ming-ling-xing">命令行</h4>
<pre><code class="language-shell">oracle@mmsg:~&gt; rman target / catalog rman/rman@inomc

恢复管理器: Release 11.1.0.7.0 - Production on 星期五 11月 12 12:34:44 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

连接到目标数据库: INOMC (DBID=1037536304)
连接到恢复目录数据库

RMAN&gt;
</code></pre>
<h4 id="rman-gong-ju">RMAN工具</h4>
<pre><code class="language-shell">oracle@mmsg:~&gt; rman

恢复管理器: Release 11.1.0.7.0 - Production on 星期五 11月 12 12:35:58 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

RMAN&gt; connect target/

连接到目标数据库: INOMC (DBID=1037536304)

RMAN&gt; connect catalog rman/rman@inomc

连接到恢复目录数据库

RMAN&gt;
</code></pre>
<h2 id="tong-dao-fen-pei">通道分配</h2>
<p>通道分配是连接RMAN和目标数据库的方法，也是确定I/O设备类型的方法，服务器进程将使用该I/O设备完成备份和重建操作。I/O设备可以是磁盘，也可以是磁带，通道分配可以自动分配也可以手工分配。</p>
<h3 id="shou-gong-fen-pei-tong-dao">手工分配通道</h3>
<p>只要发布allocate channel，即可执行手工分配通道。</p>
<p>手工分配通道的命令是</p>
<pre><code class="language-shell">allocate channel channel_name type disk/sbt
allocate channel c1 type disk
</code></pre>
<p>它用于写入磁盘文件系统，这里的磁盘包括：硬盘、光盘、软盘、U盘等。</p>
<p><code>allocate channel c2 type sbt </code><br>
它用于写入磁带。</p>
<h3 id="zi-dong-fen-pei-tong-dao">自动分配通道</h3>
<p>自动分配通道可以通过在RMAN命令提示符下设置RMAN配置来完成。使用命令configure default device type to configure device完成该任务。当执行backup、restora或者delete命令时，自动使用自动通道分配。</p>
<p>自动通道分配的完整清单如下：</p>
<pre><code class="language-shell">config device type disk backup|clear|parallelism n;
config default device type to|clear;
config channel device type disk|equal;
config channel n device type disk|equal;
</code></pre>
<p>下面的示例显示默认设备类型被设置为磁盘，并行数被设置为1，这意味着：如果没有手工分配通道，参数将如下：</p>
<pre><code class="language-shell">RMAN&gt; show all;
db_unique_name 为 INOMC 的数据库的 RMAN 配置参数为:
CONFIGURE RETENTION POLICY TO REDUNDANCY 1; # default
CONFIGURE BACKUP OPTIMIZATION OFF; # default
CONFIGURE DEFAULT DEVICE TYPE TO DISK; # default
CONFIGURE CONTROLFILE AUTOBACKUP OFF; # default
CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '%F'; # default
CONFIGURE DEVICE TYPE DISK PARALLELISM 1 BACKUP TYPE TO BACKUPSET; # default
CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE MAXSETSIZE TO UNLIMITED; # default
CONFIGURE ENCRYPTION FOR DATABASE OFF; # default
CONFIGURE ENCRYPTION ALGORITHM 'AES128'; # default
CONFIGURE COMPRESSION ALGORITHM 'BZIP2'; # default
CONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # default
CONFIGURE SNAPSHOT CONTROLFILE NAME TO '/opt/oracle/product/11g/dbs/snapcf_inomc.f'; # default
</code></pre>
<h2 id="rman-de-can-shu-he-yong-jiu-she-zhi">RMAN的参数和永久设置</h2>
<p>为RMAN设置永久设置参数是通过对每个目标数据库的配置而实现的。</p>
<p>有一些长用的有助于使用RMAN的配置参数设置，在日常操作中，这些设置很有用：</p>
<pre><code class="language-shell">device type
backup type
compressed backupset
channel disk device
channel tapy device
</code></pre>
<p>下面详细介绍如何修改或设定每个配置的设置值。</p>
<p>将默认设备设置为磁带，然后是磁盘，使用如下命令：</p>
<pre><code class="language-shell">RMAN&gt; configure default device type to sbt;

旧的 RMAN 配置参数:
CONFIGURE DEFAULT DEVICE TYPE TO 'SBT_TAPE';
新的 RMAN 配置参数:
CONFIGURE DEFAULT DEVICE TYPE TO 'SBT_TAPE';
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt; configure default device type to disk;

旧的 RMAN 配置参数:
CONFIGURE DEFAULT DEVICE TYPE TO 'SBT_TAPE';
新的 RMAN 配置参数:
CONFIGURE DEFAULT DEVICE TYPE TO DISK;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt;
</code></pre>
<p>先为图像副本设定默认备份类型，然后为备份集设定默认备份类型，使用如下命令：</p>
<p>该参数和设置值设定备份的类型是图像副本还是备份集。</p>
<pre><code class="language-shell">RMAN&gt; configure device type disk backup type to copy;

新的 RMAN 配置参数:
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COPY PARALLELISM 1;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt; configure device type disk backup type to backupset;

旧的 RMAN 配置参数:
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COPY PARALLELISM 1;
新的 RMAN 配置参数:
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO BACKUPSET PARALLELISM 1;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt;

给解压备份集配置默认设备为磁盘或者磁带，有两个特别的命令：
RMAN&gt; configure device type disk backup type to compressed backupset;

旧的 RMAN 配置参数:
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO BACKUPSET PARALLELISM 1;
新的 RMAN 配置参数:
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 1;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt; configure device type sbt backup type to compressed backupset;

新的 RMAN 配置参数:
CONFIGURE DEVICE TYPE 'SBT_TAPE' BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 1;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt;
</code></pre>
<h2 id="bao-liu-ce-lue">保留策略</h2>
<p>保留策略是为了用于可能的恢复，是备份被保留的时间长度。保留策略由参数RETENTION POLICY确定，使用show all命令可以显示此参数。</p>
<pre><code class="language-shell">RMAN&gt; show all;

db_unique_name 为 INOMC 的数据库的 RMAN 配置参数为:
CONFIGURE RETENTION POLICY TO REDUNDANCY 1; # default
CONFIGURE BACKUP OPTIMIZATION OFF; # default
CONFIGURE DEFAULT DEVICE TYPE TO DISK;
CONFIGURE CONTROLFILE AUTOBACKUP OFF; # default
CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '%F'; # default
CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE SBT_TAPE TO '%F'; # default
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 1;
CONFIGURE DEVICE TYPE 'SBT_TAPE' BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 1;
CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE SBT_TAPE TO 1; # default
CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE SBT_TAPE TO 1; # default
CONFIGURE MAXSETSIZE TO UNLIMITED; # default
CONFIGURE ENCRYPTION FOR DATABASE OFF; # default
CONFIGURE ENCRYPTION ALGORITHM 'AES128'; # default
CONFIGURE COMPRESSION ALGORITHM 'BZIP2'; # default
CONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # default
CONFIGURE SNAPSHOT CONTROLFILE NAME TO '/opt/oracle/product/11g/dbs/snapcf_inomc.f'; # default

RMAN&gt;
</code></pre>
<p>RMAN中提供了两种保留策略，分别是：基于时间和基于冗余数量。</p>
<h3 id="ji-yu-shi-jian-de-bei-fen-bao-liu-ce-lue">基于时间的备份保留策略</h3>
<p>说的简单些，就是你希望数据库最早能恢复到几天前。比如将恢复时间段设置为7，那么RMAN所保留的备份即是可以保证你将数据库恢复到一周内任何时刻下那些文件。</p>
<p>设置基于时间的备份保留策略可以通过CONFIGURE命令，例如：</p>
<pre><code class="language-shell">configure retention policy to recovery window of n days;
RMAN&gt; configure retention policy to recovery window of 2 days;

旧的 RMAN 配置参数:
CONFIGURE RETENTION POLICY TO REDUNDANCY 1;
新的 RMAN 配置参数:
CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 2 DAYS;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt;
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>n=大于0的正整数</p>
</li>
</ul>
<p>执行该命令后，RMAN将始终保留那些将数据库恢复到n天前的状态时需要用到的备份，比如，恢复时间段被设置为7天，那么各个数据文件的备份必须满足如下条件：</p>
<pre><code class="language-shell">SYSDATE-(SELECT CHECKPOINT_TIME FROM V$DATAFILE)&gt;=7 
任何不满足上述条件的备份都将被RMAN废弃并可通过
DELETE OBSOLETE命令删除。 
基于冗余数量的备份保留策略
基于冗余数量实质即某个数据文件以各种形式（包括备份集和镜像复制）存在的备份的数量。如果某个数据文件的冗余备份数量超出了指定数量，RMAN将废弃最旧的备份。 
同样，基于数量的备份保留策略也是通过CONFIGURE命令设置，例如： 
RMAN&gt;  CONFIGURE RETENTION POLICY TO  REDUNDANCY n ; 
</code></pre>
<p>同上：n=大于0的正整数</p>
<p>你也可以通过下列命令设置成不采用任何备份保留策略:</p>
<pre><code class="language-shell">RMAN&gt;  CONFIGURE RETENTION POLICY TO NONE; 
RMAN的show、report、list、crosscheck、delete命令
show
RMAN&gt; show all;

db_unique_name 为 INOMC 的数据库的 RMAN 配置参数为:
CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 2 DAYS;
CONFIGURE BACKUP OPTIMIZATION OFF; # default
CONFIGURE DEFAULT DEVICE TYPE TO DISK;
CONFIGURE CONTROLFILE AUTOBACKUP OFF; # default
CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '%F'; # default
CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE SBT_TAPE TO '%F'; # default
CONFIGURE DEVICE TYPE DISK BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 1;
CONFIGURE DEVICE TYPE 'SBT_TAPE' BACKUP TYPE TO COMPRESSED BACKUPSET PARALLELISM 1;
CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE SBT_TAPE TO 1; # default
CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default
CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE SBT_TAPE TO 1; # default
CONFIGURE MAXSETSIZE TO UNLIMITED; # default
CONFIGURE ENCRYPTION FOR DATABASE OFF; # default
CONFIGURE ENCRYPTION ALGORITHM 'AES128'; # default
CONFIGURE COMPRESSION ALGORITHM 'BZIP2'; # default
CONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # default
CONFIGURE SNAPSHOT CONTROLFILE NAME TO '/opt/oracle/product/11g/dbs/snapcf_inomc.f'; # default

RMAN&gt;
</code></pre>
<h3 id="report">report</h3>
<h4 id="bao-gao-mu-biao-shu-ju-ku-de-wu-li-jie-gou">报告目标数据库的物理结构</h4>
<pre><code class="language-shell">RMAN&gt; report schema;

db_unique_name 为 INOMC 的数据库的数据库方案报表

永久数据文件列表
===========================
文件大小 (MB) 表空间           回退段数据文件名称
---- -------- -------------------- ------- ------------------------
1    800      SYSTEM               YES     /opt/oracle/oradata/mmsgdb/system01.dbf
2    500      SYSAUX               NO      /opt/oracle/oradata/mmsgdb/sysaux01.dbf
3    800      UNDOTBS1             YES     /opt/oracle/oradata/mmsgdb/undotbs01.dbf
4    20       USERS                NO      /opt/oracle/oradata/mmsgdb/users01.dbf
5    800      IMAP_DB              NO      /opt/oracle/data/imap_db.dbf
6    1200     IMAPLOGDB            NO      /opt/oracle/data/imaplogdb.dbf
7    600      IMAPSMDB             NO      /opt/oracle/data/imapsmdb.dbf
8    800      IMAPTMDB             NO      /opt/oracle/data/imaptmdb.dbf
9    1000     ALARMDB              NO      /opt/oracle/data/alarmdb.dbf
10   2500     PERFDB               NO      /opt/oracle/data/perfdb.dbf
11   400      NMSGUEST             NO      /opt/oracle/data/nmsguest.dbf
12   1600     PERFDB_IDX           NO      /opt/oracle/data/perfdb_idx.dbf
13   71       MMSG                 NO      /opt/oracle/oradata/mmsgdb/mmsg.dbf
14   200      RMAN_DATA            NO      /opt/oracle/oradata/mmsgdb/rman_data.dbf
15   400      WYZ                  NO      /home/wyz/wyzoradata/wyz.dbf
16   1000     YJH                  NO      /home/yjh/oradata/yjhdata01
17   10       TEST                 NO      /opt/oracle/oradata/mmsgdb/test.dbf

临时文件列表
=======================
文件大小 (MB) 表空间           最大大小 (MB) 临时文件名称
---- -------- -------------------- ----------- --------------------
1    100      TEMP                 32767       /opt/oracle/oradata/mmsgdb/temp01.dbf
2    15       MMSG_TMP             15          /opt/oracle/oradata/mmsgdb/mmsg_tmp.dbf
3    20       RMAN_TMP             20          /opt/oracle/oradata/mmsgdb/rman_tmp.dbf
4    100      WYZ_TMP              200         /home/wyz/wyzoradata/wyz_tmp.dbf
5    500      YJH_TMP              500         /home/yjh/oradata/yjhdata02
6    2        TEST_TMP             2           /opt/oracle/oradata/mmsgdb/test_tmp.dbf

RMAN&gt;
</code></pre>
<h4 id="bao-gao-zui-jin-n-tian-shang-wei-bei-fen-de-shu-ju-wen-jian">报告最近N天尚未备份的数据文件</h4>
<pre><code class="language-shell">RMAN&gt; report need backup days=3;

文件报表的恢复需要超过 3 天的归档日志
文件天数据 名称
---- ----- -----------------------------------------------------
1    101   /opt/oracle/oradata/mmsgdb/system01.dbf
2    101   /opt/oracle/oradata/mmsgdb/sysaux01.dbf
3    101   /opt/oracle/oradata/mmsgdb/undotbs01.dbf
4    101   /opt/oracle/oradata/mmsgdb/users01.dbf
5    52    /opt/oracle/data/imap_db.dbf
6    52    /opt/oracle/data/imaplogdb.dbf
7    52    /opt/oracle/data/imapsmdb.dbf
8    52    /opt/oracle/data/imaptmdb.dbf
9    52    /opt/oracle/data/alarmdb.dbf
10   52    /opt/oracle/data/perfdb.dbf
11   52    /opt/oracle/data/nmsguest.dbf
12   52    /opt/oracle/data/perfdb_idx.dbf
13   30    /opt/oracle/oradata/mmsgdb/mmsg.dbf
14   25    /opt/oracle/oradata/mmsgdb/rman_data.dbf
15   24    /home/wyz/wyzoradata/wyz.dbf
16   23    /home/yjh/oradata/yjhdata01

RMAN&gt;
</code></pre>
<h4 id="bao-gao-biao-kong-jian-shang-zui-jin-n-tian-wei-bei-fen-de-shu-ju-wen-jian">报告表空间上最近N天未备份的数据文件</h4>
<pre><code class="language-shell">RMAN&gt; report need backup days=3 tablespace MMSG;

文件报表的恢复需要超过 3 天的归档日志
文件天数据 名称
---- ----- -----------------------------------------------------
13   30    /opt/oracle/oradata/mmsgdb/mmsg.dbf

RMAN&gt;
</code></pre>
<h4 id="bao-gao-hui-fu-shu-ju-wen-jian-xu-yao-de-zeng-liang-bei-fen-ge-shu-chao-guo-3-ci-de-shu-ju-wen-jian">报告恢复数据文件需要的增量备份个数超过3次的数据文件</h4>
<pre><code class="language-shell">RMAN&gt; report need backup incremental 3; 

恢复时需要超过3增量的文件报表
文件增量名称
---- ------------ ----------------------------------------------

RMAN&gt;
</code></pre>
<h4 id="bao-gao-bei-fen-wen-jian-di-yu-2-fen-de-suo-you-shu-ju-wen-jian">报告备份文件低于2份的所有数据文件</h4>
<pre><code class="language-shell">RMAN&gt; report need backup redundancy 2 database; 

文件冗余备份少于2个
文件 #bkps 名称
---- ----- -----------------------------------------------------
1    0     /opt/oracle/oradata/mmsgdb/system01.dbf
2    0     /opt/oracle/oradata/mmsgdb/sysaux01.dbf
3    0     /opt/oracle/oradata/mmsgdb/undotbs01.dbf
4    0     /opt/oracle/oradata/mmsgdb/users01.dbf
5    0     /opt/oracle/data/imap_db.dbf
6    0     /opt/oracle/data/imaplogdb.dbf
7    0     /opt/oracle/data/imapsmdb.dbf
8    0     /opt/oracle/data/imaptmdb.dbf
9    0     /opt/oracle/data/alarmdb.dbf
10   0     /opt/oracle/data/perfdb.dbf
11   0     /opt/oracle/data/nmsguest.dbf
12   0     /opt/oracle/data/perfdb_idx.dbf
13   0     /opt/oracle/oradata/mmsgdb/mmsg.dbf
14   0     /opt/oracle/oradata/mmsgdb/rman_data.dbf
15   0     /home/wyz/wyzoradata/wyz.dbf
16   0     /home/yjh/oradata/yjhdata01
17   1     /opt/oracle/oradata/mmsgdb/test.dbf

RMAN&gt;
</code></pre>
<h4 id="bao-gao-wen-jian-bao-biao-de-hui-fu-xu-yao-chao-guo-6-tian-de-gui-dang-ri-zhi-de-shu-ju-wen-jian">报告文件报表的恢复需要超过6天的归档日志的数据文件</h4>
<pre><code class="language-shell">RMAN&gt; report need backup recovery window of 6 days; 

必须备份以满足 6 天恢复窗口所需的文件报表
文件天数据 名称
---- ----- -----------------------------------------------------
1    101   /opt/oracle/oradata/mmsgdb/system01.dbf
2    101   /opt/oracle/oradata/mmsgdb/sysaux01.dbf
3    101   /opt/oracle/oradata/mmsgdb/undotbs01.dbf
4    101   /opt/oracle/oradata/mmsgdb/users01.dbf
5    52    /opt/oracle/data/imap_db.dbf
6    52    /opt/oracle/data/imaplogdb.dbf
7    52    /opt/oracle/data/imapsmdb.dbf
8    52    /opt/oracle/data/imaptmdb.dbf
9    52    /opt/oracle/data/alarmdb.dbf
10   52    /opt/oracle/data/perfdb.dbf
11   52    /opt/oracle/data/nmsguest.dbf
12   52    /opt/oracle/data/perfdb_idx.dbf
13   30    /opt/oracle/oradata/mmsgdb/mmsg.dbf
14   25    /opt/oracle/oradata/mmsgdb/rman_data.dbf
15   24    /home/wyz/wyzoradata/wyz.dbf
16   23    /home/yjh/oradata/yjhdata01

RMAN&gt;
</code></pre>
<h4 id="bao-gao-shu-ju-ku-suo-you-bu-ke-hui-fu-de-shu-ju-wen-jian">报告数据库所有不可恢复的数据文件</h4>
<pre><code class="language-shell">RMAN&gt; report unrecoverable; 

由于操作无法被恢复, 文件的报表需要备份
备份请求名称的文件类型
---- ----------------------- -----------------------------------

RMAN&gt;
</code></pre>
<h4 id="bao-gao-bei-fen-ci-shu-chao-guo-2-ci-de-chen-jiu-bei-fen">报告备份次数超过2次的陈旧备份</h4>
<pre><code class="language-shell">RMAN&gt; report obsolete redundancy 2;

未找到已废弃的备份

RMAN&gt;
</code></pre>
<h4 id="bao-gao-duo-yu-de-bei-fen">报告多余的备份</h4>
<pre><code class="language-shell">RMAN&gt; report obsolete;

RMAN 保留策略将应用于该命令
将 RMAN 保留策略设置为 2 天的恢复窗口
未找到已废弃的备份

RMAN&gt;
</code></pre>
<h3 id="list">list</h3>
<pre><code class="language-shell">list backup;                        列出详细备份
list expired backup;                列出过期备份
list backup of database;            列出所有数据文件的备份集
list backup of tablespace MMSG;    列出特定表空间的所有数据文件备份集
list backup of controlfile;            列出控制文件备份集
list backup of archivelog all;        列出归档日志备份集详细信息
list archivelog all;　　　　　　       列出归档日志备份集简要信息
list backup of spfile;                 列出SPFILE备份集
list copy of datafile 5;               列出数据文件映像副本
list copy of controlfile;              列出控制文件映像副本
list copy of archivelog all;           列出归档日志映像副本
list incarnation of database;         列出对应物/列出数据库副本
list backup summary;                概述可用的备份
     　　　　　　　　　　　                B表示backup
     　　　　　　　　　　　                F表示FULL
     　　　　　　　　　　　                A表示archive log
     　　　　　　　　　　　                S说明备份状态（A　AVAILABLE　　　X EXPIRED )
     
list backup by file;    按备份类型列出备份
                       按照数据文件备份，归档日志备份，控制文件备份，服务器参数文件备份　列出
</code></pre>
<h3 id="check">check</h3>
<pre><code class="language-shell">RMAN&gt; crosscheck backup;                            核对所有备份集  
RMAN&gt; crosscheck backup of database;                  核对所有数据文件的备份集  
RMAN&gt; crosscheck backup of tablespace MMSG;         核对特定表空间的备份集  
RMAN&gt; crosscheck backup of datafile 4;                 核对特定数据文件的备份集  
RMAN&gt; crosscheck backup of controlfile;                 核对控制文件的备份集  
RMAN&gt; crosscheck backup of spfile;                     核对SPFILE的备份集   
RMAN&gt; crosscheck backup of archivelog sequence 3;   核对归档日志的备份集 
RMAN&gt; crosscheck copy;                                核对所有映像副本
RMAN&gt; crosscheck copy of database;                    核对所有数据文件的映像副本 
RMAN&gt; crosscheck copy of tablespace MMSG;           核对特定表空间的映像副本  
RMAN&gt; crosscheck copy of datafile 6;                   核对特定数据文件的映像副本  
RMAN&gt; crosscheck copy of archivelog sequence 4;      核对归档日志的映像副本   
RMAN&gt; crosscheck copy of controlfile;                  核对控制文件的映像副本
RMAN&gt; crosscheck backup tag='SAT_BACKUP';
RMAN&gt; crosscheck backup completed after 'sysdate - 2';
RMAN&gt; crosscheck backup completed between 'sysdate - 5' and 'sysdate -2 ';
RMAN&gt; crosscheck backup device type sbt;
RMAN&gt; crosscheck archivelog all;
RMAN&gt; crosscheck archivelog like '%ARC00012.001';
RMAN&gt; crosscheck archivelog from sequence 12;
RMAN&gt; crosscheck archivelog until sequence 522;
</code></pre>
<h3 id="delete">delete</h3>
<pre><code class="language-shell">RMAN&gt; delete obsolete;                 删除陈旧备份；
RMAN&gt; delete expired backup;           删除EXPIRED备份   
RMAN&gt; delete expired copy;             删除EXPIRED副本
RMAN&gt; delete backupset 19;             删除特定备份集
RMAN&gt; delete backuppiece '/opt/oracle/oradata/backup/test.ora';   删除特定备份片
RMAN&gt; delete backup;                   删除所有备份集
RMAN&gt; delete datafilecopy '/opt/oracle/oradata/backup/test.bak';  删除特定映像副本
RMAN&gt; delete copy;                      删除所有映像副本
RMAN&gt; delete archivelog all delete input;
RMAN&gt; delete backupset 22 format = '/opt/oracle/oradata/backup/%u.bak' delete input;
                                          在备份后删除输入对象             
RMAN&gt; delete backupset id;              删除备份集
</code></pre>
<h1 id="cao-zuo-shi-li">操作示例</h1>
<h2 id="lie-chu-shu-ju-ku-zhong-suo-yi-wen-jian-de-bei-fen-de-xin-xi">列出数据库中所以文件的备份的信息</h2>
<pre><code class="language-shell">RMAN&gt; list backup of database;


备份集列表
===================


BS 关键字  类型 LV 大小       设备类型 经过时间 完成时间  
------- ---- -- ---------- ----------- ------------ ----------
812     Full    2.44M      DISK        00:00:01     18-11月-10
        BP 关键字: 813   状态: AVAILABLE  已压缩: YES  标记: TAG20101118T115451
段名:/opt/oracle/product/11g/dbs/0rltadgb_1_1
  备份集 812 中的数据文件列表
  文件 LV 类型 Ckp SCN    Ckp 时间   名称
  ---- -- ---- ---------- ---------- ----
  13      Full 3978913    18-11月-10 /opt/oracle/oradata/mmsgdb/mmsg.dbf

BS 关键字  类型 LV 大小       设备类型 经过时间 完成时间  
------- ---- -- ---------- ----------- ------------ ----------
863     Full    1.02M      DISK        00:00:00     18-11月-10
        BP 关键字: 864   状态: AVAILABLE  已压缩: YES  标记: TAG20101118T143745
段名:/opt/oracle/product/11g/dbs/0tltan1p_1_1
  备份集 863 中的数据文件列表
  文件 LV 类型 Ckp SCN    Ckp 时间   名称
  ---- -- ---- ---------- ---------- ----
  17      Full 3983755    18-11月-10 /opt/oracle/oradata/mmsgdb/test.dbf

RMAN&gt;
</code></pre>
<h2 id="lie-chu-zhi-ding-biao-kong-jian-bei-fen-xin-xi">列出指定表空间备份信息</h2>
<pre><code class="language-shell">RMAN&gt; list backup of tablespace 'MMSG';


备份集列表
===================


BS 关键字  类型 LV 大小       设备类型 经过时间 完成时间  
------- ---- -- ---------- ----------- ------------ ----------
812     Full    2.44M      DISK        00:00:01     18-11月-10
        BP 关键字: 813   状态: AVAILABLE  已压缩: YES  标记: TAG20101118T115451
段名:/opt/oracle/product/11g/dbs/0rltadgb_1_1
  备份集 812 中的数据文件列表
  文件 LV 类型 Ckp SCN    Ckp 时间   名称
  ---- -- ---- ---------- ---------- ----
  13      Full 3978913    18-11月-10 /opt/oracle/oradata/mmsgdb/mmsg.dbf
</code></pre>
<h2 id="lie-chu-zhi-ding-de-shu-ju-wen-jian-bei-fen-xin-xi">列出指定的数据文件备份信息</h2>
<pre><code class="language-shell">RMAN&gt; list backup of datafile '/opt/oracle/oradata/mmsgdb/test.dbf';


备份集列表
===================


BS 关键字  类型 LV 大小       设备类型 经过时间 完成时间  
------- ---- -- ---------- ----------- ------------ ----------
863     Full    1.02M      DISK        00:00:00     18-11月-10
        BP 关键字: 864   状态: AVAILABLE  已压缩: YES  标记: TAG20101118T143745
段名:/opt/oracle/product/11g/dbs/0tltan1p_1_1
  备份集 863 中的数据文件列表
  文件 LV 类型 Ckp SCN    Ckp 时间   名称
  ---- -- ---- ---------- ---------- ----
  17      Full 3983755    18-11月-10 /opt/oracle/oradata/mmsgdb/test.dbf

RMAN&gt;
</code></pre>
<h2 id="shan-chu-zheng-ge-shu-ju-ku-de-bei-fen">删除整个数据库的备份</h2>
<pre><code class="language-shell">RMAN&gt; delete backup;

分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=1066 设备类型=DISK

备份片段列表
BP 关键字  BS 关键字  Pc# Cp# 状态      设备类型段名称
------- ------- --- --- ----------- ----------- ----------
472     461     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873889_s16_p1
473     462     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873904_s17_p1
474     463     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873908_s18_p1
475     464     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873911_s19_p1
476     465     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873918_s20_p1
477     466     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873919_s21_p1
478     467     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873920_s22_p1
479     468     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873921_s23_p1
480     469     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873937_s24_p1
481     470     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873940_s25_p1
482     471     1   1   AVAILABLE   DISK        /opt/oracle/mmsg.load/db_t734873941_s26_p1

是否确定要删除以上对象 (输入 YES 或 NO)? yes
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873889_s16_p1 RECID=16 STAMP=734873889
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873904_s17_p1 RECID=17 STAMP=734873905
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873908_s18_p1 RECID=18 STAMP=734873908
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873911_s19_p1 RECID=19 STAMP=734873911
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873918_s20_p1 RECID=20 STAMP=734873918
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873919_s21_p1 RECID=21 STAMP=734873919
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873920_s22_p1 RECID=22 STAMP=734873920
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873921_s23_p1 RECID=23 STAMP=734873922
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873937_s24_p1 RECID=24 STAMP=734873937
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873940_s25_p1 RECID=25 STAMP=734873940
已删除备份片段
备份片段句柄=/opt/oracle/mmsg.load/db_t734873941_s26_p1 RECID=26 STAMP=734873942
11 对象已删除


RMAN&gt;
</code></pre>
<h2 id="shan-chu-biao-kong-jian-de-bei-fen">删除表空间的备份</h2>
<pre><code class="language-shell">RMAN&gt; delete backup of tablespace 'MMSG';

使用通道 ORA_DISK_1

备份片段列表
BP 关键字  BS 关键字  Pc# Cp# 状态      设备类型段名称
------- ------- --- --- ----------- ----------- ----------
813     812     1   1   AVAILABLE   DISK        /opt/oracle/product/11g/dbs/0rltadgb_1_1

是否确定要删除以上对象 (输入 YES 或 NO)? y
已删除备份片段
备份片段句柄=/opt/oracle/product/11g/dbs/0rltadgb_1_1 RECID=27 STAMP=735393291
1 对象已删除


RMAN&gt;
</code></pre>
<h2 id="shan-chu-zhi-ding-de-shu-ju-wen-jian-bei-fen">删除指定的数据文件备份</h2>
<pre><code class="language-shell">RMAN&gt; delete backup of datafile '/opt/oracle/oradata/mmsgdb/test.dbf';

使用通道 ORA_DISK_1

备份片段列表
BP 关键字  BS 关键字  Pc# Cp# 状态      设备类型段名称
------- ------- --- --- ----------- ----------- ----------
839     837     1   1   AVAILABLE   DISK        /opt/oracle/product/11g/dbs/0sltam4j_1_1

是否确定要删除以上对象 (输入 YES 或 NO)? y
已删除备份片段
备份片段句柄=/opt/oracle/product/11g/dbs/0sltam4j_1_1 RECID=28 STAMP=735402132
1 对象已删除


RMAN&gt;
</code></pre>
<h2 id="shan-chu-chen-jiu-bei-fen">删除陈旧备份</h2>
<pre><code class="language-shell">RMAN&gt; delete obsolete ; 

RMAN 保留策略将应用于该命令
将 RMAN 保留策略设置为 2 天的恢复窗口
使用通道 ORA_DISK_1
未找到已废弃的备份

RMAN&gt;
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>当使用RMAN执行备份操作时，RMAN会根据备份冗余策略确定陈旧备份。</p>
</li>
</ul>
<h1 id="rman-bei-fen-xing-shi">RMAN备份形式</h1>
<p>RMAN备份有两种形式：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、镜像备份（image copies）</p>
</li>
<li class="lvl-2">
<p>2、备份集备份（backup sets）</p>
</li>
</ul>
<h2 id="jing-xiang-bei-fen">镜像备份</h2>
<p>镜像备份实际就是RMAN利用目标数据库服务进程来完成文件的copy操作，是数据文件、控制文件或者归档日志文件的副本。</p>
<p>RMAN镜像备份的副本无法通过list backup显示，可以通过list copy显示。</p>
<h2 id="bei-fen-ji-bei-fen">备份集备份</h2>
<p>备份集是通过RMAN创建的逻辑备份对象，一个备份集中可以包括多个控制文件、数据文件、归档文件。</p>
<p>备份集在物理上由多个备份片段组成，每个备份片段就是一个操作系统文件。</p>
<h1 id="rman-bei-fen-lei-xing">RMAN备份类型</h1>
<p>利用RMAN进行备份时，可以通过三种方式来对RMAN的备份做分类:</p>
<h2 id="wan-quan-bei-fen-full-backup-yu-zeng-liang-bei-fen-incremental-backup">完全备份(Full Backup)与增量备份(Incremental Backup)</h2>
<p>全备与增备是针对数据文件而言，控制文件和归档日志文件不能进行增量备份。当然，后两者可以做备份优化。</p>
<h2 id="da-kai-bei-fen-open-backup-huo-guan-bi-bei-fen-closed-backup">打开备份(Open Backup)或关闭备份(Closed Backup)</h2>
<p>数据库打开状态下进行备份即是打开备份，数据库关闭状态下(加载状态)进行的备份即关闭备份。</p>
<h2 id="yi-zhi-bei-fen-consistent-backup-yu-bu-yi-zhi-bei-fen-inconsistent-backup">一致备份(Consistent Backup)与不一致备份(Inconsistent Backup)</h2>
<p>数据库打开状态或不干净关闭状态(shutdown abort)进行的备份是不一致备份，利用不一致的备份修复数据库后还需要做数据库的恢复。在数据库干净关闭状态进行的备份是一致备份，利用一致备份修复数据库后不需要做数据库的恢复。</p>
<h1 id="rman-bei-fen">RMAN备份</h1>
<h2 id="bei-fen-zheng-ge-shu-ju-ku">备份整个数据库</h2>
<pre><code class="language-shell">oracle@mmsg:~&gt; rman target/

恢复管理器: Release 11.1.0.7.0 - Production on 星期日 10月 24 15:37:56 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

连接到目标数据库: INOMC (DBID=1037536304)

RMAN&gt; connect catalog rman/rman@inomc

连接到恢复目录数据库


RMAN&gt; register database;

注册在恢复目录中的数据库
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt;
RMAN&gt; run { 
2&gt;  allocate channel c1 type disk; 
3&gt;  backup 
4&gt;  full 
5&gt;  tag full_db_backup 
6&gt;  format "/opt/oracle/mmsg.load/db_t%t_s%s_p%p" 
7&gt;  (database); 
8&gt;  release channel c1; 
9&gt;  }

释放的通道: ORA_DISK_1
分配的通道: c1
通道 c1: SID=1066 设备类型=DISK

启动 backup 于 12-11月-10
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00010 名称=/opt/oracle/data/perfdb.dbf
输入数据文件: 文件号=00016 名称=/home/yjh/oradata/yjhdata01
输入数据文件: 文件号=00015 名称=/home/wyz/wyzoradata/wyz.dbf
输入数据文件: 文件号=00012 名称=/opt/oracle/data/perfdb_idx.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873889_s16_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:15
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00006 名称=/opt/oracle/data/imaplogdb.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873904_s17_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:03
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00009 名称=/opt/oracle/data/alarmdb.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873908_s18_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:03
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873911_s19_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:07
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873918_s20_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:01
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/data/imap_db.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873919_s21_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:01
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00008 名称=/opt/oracle/data/imaptmdb.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873920_s22_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:01
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00014 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873921_s23_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:15
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00007 名称=/opt/oracle/data/imapsmdb.dbf
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873937_s24_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:03
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00011 名称=/opt/oracle/data/nmsguest.dbf
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873940_s25_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:01
通道 c1: 正在启动全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
备份集内包括当前控制文件
备份集内包括当前的 SPFILE
通道 c1: 正在启动段 1 于 12-11月-10
通道 c1: 已完成段 1 于 12-11月-10
段句柄=/opt/oracle/mmsg.load/db_t734873941_s26_p1 标记=FULL_DB_BACKUP 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 12-11月-10

释放的通道: c1
</code></pre>
<h2 id="bei-fen-zhi-ding-de-shu-ju-wen-jian">备份指定的数据文件</h2>
<pre><code class="language-shell">RMAN&gt; backup datafile '/opt/oracle/oradata/mmsgdb/test.dbf';

启动 backup 于 18-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00017 名称=/opt/oracle/oradata/mmsgdb/test.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/0tltan1p_1_1 标记=TAG20101118T143745 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10

RMAN&gt;
</code></pre>
<h2 id="bei-fen-biao-kong-jian">备份表空间</h2>
<pre><code class="language-shell">RMAN&gt; backup tablespace MMSG;

启动 backup 于 18-11月-10
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=1065 设备类型=DISK
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/0rltadgb_1_1 标记=TAG20101118T115451 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10

RMAN&gt;
</code></pre>
<h2 id="bei-fen-kong-zhi-wen-jian">备份控制文件</h2>
<p>1、最简单的方式就是通过configure命令修改CONTROLFILE AUTOBACKUP为on</p>
<pre><code class="language-shell">RMAN&gt; configure controlfile autobackup on;

新的 RMAN 配置参数:
CONFIGURE CONTROLFILE AUTOBACKUP ON;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt;
</code></pre>
<p>2、在自动备份打开的情况下，对数据库的任何备份，都会自动备份控制文件。</p>
<p>3、手工执行备份命令</p>
<pre><code class="language-shell">RMAN&gt; backup current controlfile;

启动 backup 于 18-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
备份集内包括当前控制文件
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/0ultau5s_1_1 标记=TAG20101118T163923 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10

RMAN&gt;
</code></pre>
<p>4、执行backup操作时，指定include current controlfile参数</p>
<pre><code class="language-shell">RMAN&gt; backup database include current controlfile;

启动 backup 于 18-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00010 名称=/opt/oracle/data/perfdb.dbf
输入数据文件: 文件号=00016 名称=/home/yjh/oradata/yjhdata01
输入数据文件: 文件号=00015 名称=/home/wyz/wyzoradata/wyz.dbf
输入数据文件: 文件号=00012 名称=/opt/oracle/data/perfdb_idx.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/0vltaue2_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:07
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00006 名称=/opt/oracle/data/imaplogdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/10ltauea_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00009 名称=/opt/oracle/data/alarmdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/11ltaueb_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/12ltauec_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/13ltauer_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/data/imap_db.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/14ltaues_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00008 名称=/opt/oracle/data/imaptmdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/15ltauet_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00007 名称=/opt/oracle/data/imapsmdb.dbf
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
输入数据文件: 文件号=00017 名称=/opt/oracle/oradata/mmsgdb/test.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/16ltauev_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:03
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00014 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/17ltauf2_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00011 名称=/opt/oracle/data/nmsguest.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/18ltaufh_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
备份集内包括当前控制文件
备份集内包括当前的 SPFILE
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/19ltaufi_1_1 标记=TAG20101118T164346 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10


RMAN&gt; backup datafile  '/opt/oracle/oradata/mmsgdb/test.dbf' include current controlfile;

启动 backup 于 18-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00017 名称=/opt/oracle/oradata/mmsgdb/test.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1altauil_1_1 标记=TAG20101118T164613 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
备份集内包括当前控制文件
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1bltauim_1_1 标记=TAG20101118T164613 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10

RMAN&gt;

RMAN&gt; backup tablespace MMSG include current controlfile;

启动 backup 于 18-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1cltaujq_1_1 标记=TAG20101118T164650 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
备份集内包括当前控制文件
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1dltaujs_1_1 标记=TAG20101118T164650 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10

RMAN&gt;
</code></pre>
<h2 id="bei-fen-gui-dang-ri-zhi-wen-jian">备份归档日志文件</h2>
<p>归档日志备份对于数据库的介质恢复非常重要，归档日志文件被破坏虽然不像控制文件被破坏后数据库崩溃那么严重，但归档日志文件的备份还是非常重要的。备份了归档日志文件后，可以将数据库恢复到备份之前的任何一个时刻。</p>
<p>备份归档日志文件方法有两种：</p>
<h3 id="li-yong-backup-archivelog-ming-ling-bei-fen">利用BACKUP ARCHIVELOG命令备份</h3>
<pre><code class="language-shell">RMAN&gt; backup archivelog all;

启动 backup 于 18-11月-10
当前日志已存档
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的归档日志备份集
通道 ORA_DISK_1: 正在指定备份集内的归档日志
输入归档日志线程=1 序列=48 RECID=28 STAMP=735350892
输入归档日志线程=1 序列=49 RECID=29 STAMP=735411706
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1eltavfr_1_1 标记=TAG20101118T170147 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
完成 backup 于 18-11月-10

RMAN&gt;
</code></pre>
<h3 id="zai-backup-guo-cheng-zhong-shi-yong-plus-archivelog-can-shu">在backup过程中，使用plus archivelog参数</h3>
<pre><code class="language-shell">RMAN&gt; backup database plus archivelog;


启动 backup 于 18-11月-10
当前日志已存档
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的归档日志备份集
通道 ORA_DISK_1: 正在指定备份集内的归档日志
输入归档日志线程=1 序列=48 RECID=28 STAMP=735350892
输入归档日志线程=1 序列=49 RECID=29 STAMP=735411706
输入归档日志线程=1 序列=50 RECID=30 STAMP=735411902
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1fltavlv_1_1 标记=TAG20101118T170503 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
完成 backup 于 18-11月-10

启动 backup 于 18-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00010 名称=/opt/oracle/data/perfdb.dbf
输入数据文件: 文件号=00016 名称=/home/yjh/oradata/yjhdata01
输入数据文件: 文件号=00015 名称=/home/wyz/wyzoradata/wyz.dbf
输入数据文件: 文件号=00012 名称=/opt/oracle/data/perfdb_idx.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1gltavme_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:07
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00006 名称=/opt/oracle/data/imaplogdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1hltavml_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00009 名称=/opt/oracle/data/alarmdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1iltavmm_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1jltavmo_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1kltavn7_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/data/imap_db.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1lltavn8_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00008 名称=/opt/oracle/data/imaptmdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1mltavn9_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00007 名称=/opt/oracle/data/imapsmdb.dbf
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
输入数据文件: 文件号=00017 名称=/opt/oracle/oradata/mmsgdb/test.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1nltavna_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00014 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1oltavnb_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00011 名称=/opt/oracle/data/nmsguest.dbf
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1pltavnr_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
备份集内包括当前控制文件
备份集内包括当前的 SPFILE
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1qltavns_1_1 标记=TAG20101118T170518 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10

启动 backup 于 18-11月-10
当前日志已存档
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的归档日志备份集
通道 ORA_DISK_1: 正在指定备份集内的归档日志
输入归档日志线程=1 序列=51 RECID=31 STAMP=735411966
通道 ORA_DISK_1: 正在启动段 1 于 18-11月-10
通道 ORA_DISK_1: 已完成段 1 于 18-11月-10
段句柄=/opt/oracle/product/11g/dbs/1rltavnv_1_1 标记=TAG20101118T170607 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 18-11月-10

RMAN&gt;
</code></pre>
<h2 id="zeng-liang-bei-fen">增量备份</h2>
<p>当数据库运行在非归档模式下，只有在数据库干净的关闭情况下，才可进行数据的一致性增量备份；当数据库运行在归档模式下，无论数据库关闭还是启动，均可以对数据库进行增量备份。</p>
<p>建立增量备份，就是在备份过程中增加参数INCREMENTAL LEVEL=n。</p>
<p>例如：建立一个增量级别为0的全库备份。</p>
<pre><code class="language-shell">RMAN&gt; backup INCREMENTAL LEVEL=0 database;

启动 backup 于 19-11月-10
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=1068 设备类型=DISK
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00010 名称=/opt/oracle/data/perfdb.dbf
输入数据文件: 文件号=00016 名称=/home/yjh/oradata/yjhdata01
输入数据文件: 文件号=00015 名称=/home/wyz/wyzoradata/wyz.dbf
输入数据文件: 文件号=00012 名称=/opt/oracle/data/perfdb_idx.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/1vltdh86_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:07
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00006 名称=/opt/oracle/data/imaplogdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/20ltdh8e_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00009 名称=/opt/oracle/data/alarmdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/21ltdh8f_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/22ltdh8g_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/23ltdh8v_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00005 名称=/opt/oracle/data/imap_db.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/24ltdh90_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00008 名称=/opt/oracle/data/imaptmdb.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/25ltdh91_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00007 名称=/opt/oracle/data/imapsmdb.dbf
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
输入数据文件: 文件号=00017 名称=/opt/oracle/oradata/mmsgdb/test.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/26ltdh93_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00014 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/27ltdh94_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:15
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00011 名称=/opt/oracle/data/nmsguest.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/28ltdh9j_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
通道 ORA_DISK_1: 正在启动压缩的增量级别 0 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
备份集内包括当前控制文件
备份集内包括当前的 SPFILE
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/29ltdh9k_1_1 标记=TAG20101119T161710 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 19-11月-10

RMAN&gt;
</code></pre>
<p>再例如：建立一个增量级别为1的数据库表空间的备份</p>
<pre><code class="language-shell">RMAN&gt; backup incremental level=1 tablespace MMSG;

启动 backup 于 19-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的增量级别 1 数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/2bltdhds_1_1 标记=TAG20101119T162012 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 19-11月-10

RMAN&gt;
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Rman默认创建的增量备份是Differential方式，如果要建立Cumulative方式的增量备份，在执行BACKUP命令时显式指定即可，例如：<code>RMAN&gt;  BACKUP INCREMENTAL LEVEL=2 CUMULATIVE DATABASE; </code></p>
</li>
</ul>
<h2 id="rong-yu-bei-fen">冗余备份</h2>
<p>RMAN提供了一种更谨慎的备份策略：Duplexed 方式备份，实质就是在生成备份集的同时，向指定位置生成指定份数(最大不超过4份)的备份集副本。防止灾难行的事故导致数据库损坏或者备份数据丢失，提高备份的可用性。</p>
<h3 id="xian-shi-zhi-ding-copies-shu-liang">显示指定copies数量</h3>
<pre><code class="language-shell">RMAN&gt; backup copies 2 tablespace MMSG;

启动 backup 于 19-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10, 有 2 个副本和标记 TAG20101119T163829
段 handle=/opt/oracle/product/11g/dbs/2cltdig5_1_1 comment=NONE
段 handle=/opt/oracle/product/11g/dbs/2cltdig5_1_2 comment=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 19-11月-10

RMAN&gt;
</code></pre>
<h3 id="zai-pi-chu-li-zhong-zeng-jia-set-backup-copies-can-shu">在批处理中增加set backup copies参数</h3>
<pre><code class="language-shell">RMAN&gt; run
2&gt; {
3&gt; set backup copies 1;
4&gt; allocate channel c1 device type disk;
5&gt; backup tablespace MMSG;
6&gt; }

正在执行命令: SET BACKUP COPIES

分配的通道: c1
通道 c1: SID=1069 设备类型=DISK

启动 backup 于 19-11月-10
使用通道 ORA_DISK_1
通道 ORA_DISK_1: 正在启动压缩的全部数据文件备份集
通道 ORA_DISK_1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
通道 ORA_DISK_1: 正在启动段 1 于 19-11月-10
通道 ORA_DISK_1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/product/11g/dbs/2dltdj5h_1_1 标记=TAG20101119T164953 注释=NONE
通道 ORA_DISK_1: 备份集已完成, 经过时间:00:00:01
完成 backup 于 19-11月-10

RMAN&gt;
</code></pre>
<h3 id="tong-guo-configure-she-ding-yu-bei-fen-duplexed-fang-shi">通过configure设定预备份Duplexed方式</h3>
<pre><code class="language-shell">RMAN&gt; configure datafile backup copies for device type disk to 1;

新的 RMAN 配置参数:
CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1;
已成功存储新的 RMAN 配置参数
正在启动全部恢复目录的 resync
完成全部 resync

RMAN&gt;
</code></pre>
<h1 id="rman-hui-fu">RMAN恢复</h1>
<h2 id="hui-fu-spfile-wen-jian">恢复spfile文件</h2>
<pre><code class="language-shell">oracle@mmsg:~&gt; rman target/

恢复管理器: Release 11.1.0.7.0 - Production on 星期四 11月 18 18:14:15 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

已连接到目标数据库 (未启动)

RMAN&gt; connect catalog rman/rman@inomc

RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-04004: 来自恢复目录数据库的警告: ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务

RMAN&gt; startup nomount

启动失败: ORA-01078: failure in processing system parameters
LRM-00109: ???????????????? '/opt/oracle/product/11g/dbs/initinomc.ora'

在没有参数文件的情况下启动 Oracle 实例以检索 spfile
Oracle 实例已启动

系统全局区域总计     158662656 字节

Fixed Size                     2157784 字节
Variable Size                 83886888 字节
Database Buffers              67108864 字节
Redo Buffers                   5509120 字节

RMAN&gt; restore spfile from autobackup;

启动 restore 于 18-11月-10
使用目标数据库控制文件替代恢复目录
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=96 设备类型=DISK

RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03002: restore 命令 (在 11/18/2010 18:14:46 上) 失败
RMAN-06495: 必须用 SET DBID 命令明确指定 DBID

RMAN&gt; set dbid=1037536304

正在执行命令: SET DBID

RMAN&gt; restore spfile from autobackup;

启动 restore 于 18-11月-10
使用通道 ORA_DISK_1

通道 ORA_DISK_1: 寻找以下日期的 AUTOBACKUP: 20101118
通道 ORA_DISK_1: 已找到的 AUTOBACKUP: c-1037536304-20101118-00
通道 ORA_DISK_1: 正在从 AUTOBACKUP c-1037536304-20101118-00 还原 spfile
通道 ORA_DISK_1: 从 AUTOBACKUP 还原 SPFILE 已完成
完成 restore 于 18-11月-10

RMAN&gt; startup force

Oracle 实例已启动
数据库已装载
数据库已打开

系统全局区域总计    8351150080 字节

Fixed Size                     2161272 字节
Variable Size               7784629640 字节
Database Buffers             536870912 字节
Redo Buffers                  27488256 字节

RMAN&gt;
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>RMAN的参数confile autobackup必须设置为on，这样才能恢复spfile文件。</p>
</li>
</ul>
<h2 id="kou-ling-wen-jian-hui-fu">口令文件恢复</h2>
<p>由于RMAN不支持口令文件的备份，所以，无法通过RMAN进行口令文件的恢复，通过orapw命令重新建立口令文件即可。</p>
<pre><code class="language-shell">oracle@mmsg:~/product/11g/dbs&gt; orapwd
Usage: orapwd file=&lt;fname&gt; password=&lt;password&gt; entries=&lt;users&gt; force=&lt;y/n&gt; ignorecase=&lt;y/n&gt; nosysdba=&lt;y/n&gt;

  where
    file - name of password file (required),
    password - password for SYS, will be prompted if not specified at command line,
    entries - maximum number of distinct DBA (optional),
    force - whether to overwrite existing file (optional),
    ignorecase - passwords are case-insensitive (optional),
    nosysdba - whether to shut out the SYSDBA logon (optional Database Vault only).
    
  There must be no spaces around the equal-to (=) character.


表空间的恢复
RMAN&gt; shutdown immediate

数据库已关闭
数据库已卸装
Oracle 实例已关闭

RMAN&gt;
RMAN&gt; startup mount

Oracle 实例已启动
数据库已装载

系统全局区域总计    8351150080 字节

Fixed Size                     2161272 字节
Variable Size               7784629640 字节
Database Buffers             536870912 字节
Redo Buffers                  27488256 字节

RMAN&gt; restore tablespace TEST;

RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-00558: 分析输入命令时出错
RMAN-01009: 语法错误: 找到 "test": 应为: "double-quoted-string, identifier, single-quoted-string" 中的一个
RMAN-01007: 在第 1 行第 20 列, 文件: standard input

RMAN&gt; restore tablespace "TEST";

启动 restore 于 23-11月-10
使用目标数据库控制文件替代恢复目录
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=1089 设备类型=DISK

通道 ORA_DISK_1: 正在开始还原数据文件备份集
通道 ORA_DISK_1: 正在指定从备份集还原的数据文件
通道 ORA_DISK_1: 将数据文件 00017 还原到 /opt/oracle/oradata/mmsgdb/test.dbf
通道 ORA_DISK_1: 正在读取备份片段 /opt/oracle/rman/full_bak_2hltdnio_1_1
通道 ORA_DISK_1: 段句柄 = /opt/oracle/rman/full_bak_2hltdnio_1_1 标记 = TAG20101119T180505
通道 ORA_DISK_1: 已还原备份片段 1
通道 ORA_DISK_1: 还原完成, 用时: 00:00:04
完成 restore 于 23-11月-10

RMAN&gt; recover tablespace "TEST"; 

启动 recover 于 23-11月-10
使用通道 ORA_DISK_1

正在开始介质的恢复
介质恢复完成, 用时: 00:00:03

完成 recover 于 23-11月-10

RMAN&gt; alter database open 
2&gt; ;

数据库已打开

RMAN&gt;    
</code></pre>
<h2 id="shu-ju-wen-jian-de-hui-fu">数据文件的恢复</h2>
<p>这个操作类似于表空间的恢复</p>
<pre><code class="language-shell">RMAN&gt;shutdown immediate
RMAN&gt;startup mount
RMAN&gt;restorer datafile datafilepath;  #或者是restore datafile datafile_num; 
RMAN&gt; recover datafile datafilepath;  #或者是recover datafile datafile_num;
RMAN&gt; alter database open
</code></pre>
<h2 id="gui-dang-mo-shi-xia-shu-ju-wen-jian-diu-shi-de-hui-fu">归档模式下，数据文件丢失的恢复</h2>
<h3 id="mo-ni-chang-jing-yu-ce-shi-zhun-bei-gong-zuo">模拟场景与测试准备工作</h3>
<p>1、先创建表空间TEST，创建test用户，默认表空间为TEST；</p>
<p>2、以test用户登陆数据库，创建表test，并向表test中insert几条记录</p>
<pre><code class="language-shell">insert into test(id) values (1);
insert into test(id) values (2);
insert into test(id) values (3);
insert into test(id) values (4);
insert into test(id) values (5);
insert into test(id) values (6);
insert into test(id) values (7);
commit;
</code></pre>
<p>3、将TEST表空间对应的数据文件mv或者rm操作</p>
<p>4、停止数据库后，再次启动数据库。</p>
<pre><code class="language-shell">oracle@mmsg:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期二 11月 23 11:17:32 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

已连接到空闲例程。

SQL&gt; startup
ORACLE 例程已经启动。

Total System Global Area 8351150080 bytes
Fixed Size                  2161272 bytes
Variable Size            7784629640 bytes
Database Buffers          536870912 bytes
Redo Buffers               27488256 bytes
数据库装载完毕。
ORA-01157: 无法标识/锁定数据文件 17 - 请参阅 DBWR 跟踪文件
ORA-01110: 数据文件 17: '/opt/oracle/oradata/mmsgdb/test.dbf'
</code></pre>
<p>5、查询数据库当前状态</p>
<pre><code class="language-shell">SQL&gt; select instance_name,status from v$instance;

INSTANCE_NAME    STATUS
---------------- ------------
inomc            MOUNTED

SQL&gt;
</code></pre>
<h3 id="rman-hui-fu-cao-zuo">RMAN恢复操作</h3>
<pre><code class="language-shell">oracle@mmsg:~&gt; rman  target/

恢复管理器: Release 11.1.0.7.0 - Production on 星期二 11月 23 11:18:24 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

已连接到目标数据库: INOMC (DBID=1037536304, 未打开)

RMAN&gt; connect catalog rman/rman@inomc

RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-04004: 来自恢复目录数据库的警告: ORA-01033: ORACLE 正在初始化或关闭

RMAN&gt; restore datafile '/opt/oracle/oradata/mmsgdb/test.dbf';

启动 restore 于 23-11月-10
使用目标数据库控制文件替代恢复目录
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=1087 设备类型=DISK

通道 ORA_DISK_1: 正在开始还原数据文件备份集
通道 ORA_DISK_1: 正在指定从备份集还原的数据文件
通道 ORA_DISK_1: 将数据文件 00017 还原到 /opt/oracle/oradata/mmsgdb/test.dbf
通道 ORA_DISK_1: 正在读取备份片段 /opt/oracle/rman/full_bak_2hltdnio_1_1
通道 ORA_DISK_1: 段句柄 = /opt/oracle/rman/full_bak_2hltdnio_1_1 标记 = TAG20101119T180505
通道 ORA_DISK_1: 已还原备份片段 1
通道 ORA_DISK_1: 还原完成, 用时: 00:00:01
完成 restore 于 23-11月-10

RMAN&gt; recover datafile '/opt/oracle/oradata/mmsgdb/test.dbf';

启动 recover 于 23-11月-10
使用通道 ORA_DISK_1

正在开始介质的恢复
介质恢复完成, 用时: 00:00:02

完成 recover 于 23-11月-10

RMAN&gt; alter database open;

数据库已打开

RMAN&gt;
oracle@mmsg:~&gt; sqlplus test/test@inomc

SQL*Plus: Release 11.1.0.7.0 - Production on 星期二 11月 23 11:20:07 2010

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select * from test;

        ID
----------
         1
         2
         3
         4
         5
         6
         7

已选择7行。

SQL&gt;
</code></pre>
<h2 id="quan-ku-de-hui-fu">全库的恢复</h2>
<pre><code class="language-shell">RMAN&gt;shutdown immediate
RMAN&gt;startup mount
RMAN&gt; run
2&gt; {
3&gt; allocate channel c1 device type disk;
4&gt; restore database;
5&gt; }
</code></pre>
<h2 id="kong-zhi-wen-jian-de-hui-fu">控制文件的恢复</h2>
<p>1、数据库启动到非安装状态(nomount)</p>
<p>2、RMAN恢复</p>
<pre><code class="language-shell">RMAN&gt; run {
2&gt; allocate channel c1 device type disk;
3&gt; restore controlfile from ‘/opt/oracle/rman/back_c-1037536304-20101123-07’;
4&gt; release channel c1;
5&gt; }
</code></pre>
<h2 id="zhong-zuo-ri-zhi-wen-jian-de-hui-fu">重做日志文件的恢复</h2>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 8351150080 bytes
Fixed Size                  2161272 bytes
Variable Size            7784629640 bytes
Database Buffers          536870912 bytes
Redo Buffers               27488256 bytes
数据库装载完毕。
SQL&gt; recover database using backup controlfile until cancel;
ORA-00279: 更改 4265765 (在 11/23/2010 15:01:28 生成) 对于线程 1 是必需的
ORA-00289: 建议: /opt/oracle/archivelog/1_63_730813273.dbf
ORA-00280: 更改 4265765 (用于线程 1) 在序列 #63 中


指定日志: {&lt;RET&gt;=suggested | filename | AUTO | CANCEL}
………………………………………………………………………………………………
…………………………………………………………………………………………………
SQL&gt; alter database open resetlogs;

数据库已更改。

SQL&gt;
</code></pre>
<h2 id="gui-dang-ri-zhi-wen-jian-de-hui-fu">归档日志文件的恢复</h2>
<pre><code class="language-shell">RMAN&gt;shutdown immediate
RMAN&gt;startup mount
RMAN&gt; run
2&gt; {
3&gt; allocate channel c1 device type disk;
4&gt; restore archivelog all;
5&gt; }
</code></pre>
<h1 id="zong-he-shi-jian">综合实践</h1>
<h2 id="chang-jing-1-ding-shi-bei-fen-shu-ju-ku-dao-ji-ding-mu-lu-xia-bing-zi-dong-shan-chu-guo-qi-bei-fen-gui-dang-ri-zhi">场景1 定时备份数据库到既定目录下，并自动删除过期备份归档日志</h2>
<h3 id="yao-qiu">要求</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>1 、每天夜间1点执行；</p>
</li>
<li class="lvl-2">
<p>2 、数据库全备，同时备份控制文件及归档日志文件，备份文件保存至：/opt/oracle/rman目录下，并在完成归档日志文件备份后，自动删除已备份的归档日志；</p>
</li>
<li class="lvl-2">
<p>3 、备份保留7天，过期则自动删除；</p>
</li>
<li class="lvl-2">
<p>4 、保留操作日志备查；</p>
</li>
</ul>
<h3 id="rman-jiao-ben">RMAN脚本</h3>
<pre><code class="language-shell">oracle@mmsg:~/rman&gt; more back_full.rman 
run
{
configure retention policy to recovery window of 7 days;
configure controlfile autobackup on;
configure controlfile autobackup format for device type disk to '/opt/oracle/rman/full_bak_%F';
allocate channel c1 device type disk format '/opt/oracle/rman/full_bak_%U';
backup database skip inaccessible filesperset 10 plus archivelog filesperset 20 delete  all input;
release channel c1; 
}
allocate channel for maintenance device type disk;
crosscheck backupset;
delete noprompt obsolete;
</code></pre>
<table>
<thead>
<tr>
<th>SKIP 选项</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>SKIP INACCESSIBLE</td>
<td>表示跳过不可读的文件。我们知道一些offline的数据文件只要存在于磁盘上就仍然可被读取，但是可能有些文件已经被删除或移到它处造成不可读，加上这个参数就会跳过这些文件</td>
</tr>
<tr>
<td>SKIP OFFLINE</td>
<td>跳过offline的数据文件</td>
</tr>
<tr>
<td>SKIP READONLY</td>
<td>跳过那些所在表空间为read-only的数据文件</td>
</tr>
</tbody>
</table>
<h3 id="ming-ling-zhi-xing">命令执行</h3>
<pre><code class="language-shell">oracle@mmsg:~/rman&gt; rman target / msglog /opt/oracle/rman/bak.log cmdfile=/opt/oracle/rman/back_full.rman
</code></pre>
<h3 id="ri-zhi">日志</h3>
<pre><code class="language-shell">oracle@mmsg:~/rman&gt; more bak.log 

恢复管理器: Release 11.1.0.7.0 - Production on 星期五 11月 19 18:04:46 2010

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

连接到目标数据库: INOMC (DBID=1037536304)

RMAN&gt; run
2&gt; {
3&gt; configure retention policy to recovery window of 7 days;
4&gt; configure controlfile autobackup on;
5&gt; configure controlfile autobackup format for device type disk to '/opt/oracle/rman/full_bak_%F';
6&gt; allocate channel c1 device type disk format '/opt/oracle/rman/full_bak_%U';
7&gt; backup database skip inaccessible filesperset 10 plus archivelog filesperset 20 delete  all input;
8&gt; release channel c1; 
9&gt; }
10&gt; allocate channel for maintenance device type disk;
11&gt; crosscheck backupset;
12&gt; delete noprompt obsolete;
13&gt; 
使用目标数据库控制文件替代恢复目录
旧的 RMAN 配置参数:
CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 2 DAYS;
新的 RMAN 配置参数:
CONFIGURE RETENTION POLICY TO RECOVERY WINDOW OF 7 DAYS;
已成功存储新的 RMAN 配置参数

旧的 RMAN 配置参数:
CONFIGURE CONTROLFILE AUTOBACKUP OFF;
新的 RMAN 配置参数:
CONFIGURE CONTROLFILE AUTOBACKUP ON;
已成功存储新的 RMAN 配置参数

新的 RMAN 配置参数:
CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '/opt/oracle/rman/full_bak_%F';
已成功存储新的 RMAN 配置参数

分配的通道: c1
通道 c1: SID=1065 设备类型=DISK

启动 backup 于 19-11月-10
当前日志已存档
通道 c1: 正在启动压缩的归档日志备份集
通道 c1: 正在指定备份集内的归档日志
输入归档日志线程=1 序列=49 RECID=29 STAMP=735411706
输入归档日志线程=1 序列=50 RECID=30 STAMP=735411902
输入归档日志线程=1 序列=51 RECID=31 STAMP=735411966
输入归档日志线程=1 序列=52 RECID=32 STAMP=735437813
输入归档日志线程=1 序列=53 RECID=33 STAMP=735501889
通道 c1: 正在启动段 1 于 19-11月-10
通道 c1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/rman/full_bak_2fltdni1_1_1 标记=TAG20101119T180449 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:15
通道 c1: 正在删除归档日志
归档日志文件名=/opt/oracle/archivelog/1_49_730813273.dbf RECID=29 STAMP=735411706
归档日志文件名=/opt/oracle/archivelog/1_50_730813273.dbf RECID=30 STAMP=735411902
归档日志文件名=/opt/oracle/archivelog/1_51_730813273.dbf RECID=31 STAMP=735411966
归档日志文件名=/opt/oracle/archivelog/1_52_730813273.dbf RECID=32 STAMP=735437813
归档日志文件名=/opt/oracle/archivelog/1_53_730813273.dbf RECID=33 STAMP=735501889
完成 backup 于 19-11月-10

启动 backup 于 19-11月-10
通道 c1: 正在启动压缩的全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00010 名称=/opt/oracle/data/perfdb.dbf
输入数据文件: 文件号=00007 名称=/opt/oracle/data/imapsmdb.dbf
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/mmsg.dbf
输入数据文件: 文件号=00016 名称=/home/yjh/oradata/yjhdata01
输入数据文件: 文件号=00015 名称=/home/wyz/wyzoradata/wyz.dbf
输入数据文件: 文件号=00012 名称=/opt/oracle/data/perfdb_idx.dbf
输入数据文件: 文件号=00006 名称=/opt/oracle/data/imaplogdb.dbf
通道 c1: 正在启动段 1 于 19-11月-10
通道 c1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/rman/full_bak_2gltdnih_1_1 标记=TAG20101119T180505 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:07
通道 c1: 正在启动压缩的全部数据文件备份集
通道 c1: 正在指定备份集内的数据文件
输入数据文件: 文件号=00009 名称=/opt/oracle/data/alarmdb.dbf
输入数据文件: 文件号=00001 名称=/opt/oracle/oradata/mmsgdb/system01.dbf
输入数据文件: 文件号=00003 名称=/opt/oracle/oradata/mmsgdb/undotbs01.dbf
输入数据文件: 文件号=00005 名称=/opt/oracle/data/imap_db.dbf
输入数据文件: 文件号=00008 名称=/opt/oracle/data/imaptmdb.dbf
输入数据文件: 文件号=00002 名称=/opt/oracle/oradata/mmsgdb/sysaux01.dbf
输入数据文件: 文件号=00011 名称=/opt/oracle/data/nmsguest.dbf
输入数据文件: 文件号=00014 名称=/opt/oracle/oradata/mmsgdb/rman_data.dbf
输入数据文件: 文件号=00004 名称=/opt/oracle/oradata/mmsgdb/users01.dbf
输入数据文件: 文件号=00017 名称=/opt/oracle/oradata/mmsgdb/test.dbf
通道 c1: 正在启动段 1 于 19-11月-10
通道 c1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/rman/full_bak_2hltdnio_1_1 标记=TAG20101119T180505 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:25
完成 backup 于 19-11月-10

启动 backup 于 19-11月-10
当前日志已存档
通道 c1: 正在启动压缩的归档日志备份集
通道 c1: 正在指定备份集内的归档日志
输入归档日志线程=1 序列=54 RECID=34 STAMP=735501938
通道 c1: 正在启动段 1 于 19-11月-10
通道 c1: 已完成段 1 于 19-11月-10
段句柄=/opt/oracle/rman/full_bak_2iltdnji_1_1 标记=TAG20101119T180538 注释=NONE
通道 c1: 备份集已完成, 经过时间:00:00:01
通道 c1: 正在删除归档日志
归档日志文件名=/opt/oracle/archivelog/1_54_730813273.dbf RECID=34 STAMP=735501938
完成 backup 于 19-11月-10

启动 Control File and SPFILE Autobackup 于 19-11月-10
段 handle=/opt/oracle/rman/full_bak_c-1037536304-20101119-00 comment=NONE
完成 Control File and SPFILE Autobackup 于 19-11月-10

释放的通道: c1

分配的通道: ORA_MAINT_DISK_1
通道 ORA_MAINT_DISK_1: SID=1065 设备类型=DISK

交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/0tltan1p_1_1 RECID=29 STAMP=735403065
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/0ultau5s_1_1 RECID=30 STAMP=735410365
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/0vltaue2_1_1 RECID=31 STAMP=735410627
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/10ltauea_1_1 RECID=32 STAMP=735410634
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/11ltaueb_1_1 RECID=33 STAMP=735410635
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/12ltauec_1_1 RECID=34 STAMP=735410636
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/13ltauer_1_1 RECID=35 STAMP=735410651
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/14ltaues_1_1 RECID=36 STAMP=735410652
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/15ltauet_1_1 RECID=37 STAMP=735410653
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/16ltauev_1_1 RECID=38 STAMP=735410655
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/17ltauf2_1_1 RECID=39 STAMP=735410658
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/18ltaufh_1_1 RECID=40 STAMP=735410673
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/19ltaufi_1_1 RECID=41 STAMP=735410675
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1altauil_1_1 RECID=42 STAMP=735410773
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1bltauim_1_1 RECID=43 STAMP=735410775
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1cltaujq_1_1 RECID=44 STAMP=735410810
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1dltaujs_1_1 RECID=45 STAMP=735410813
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1eltavfr_1_1 RECID=46 STAMP=735411707
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1fltavlv_1_1 RECID=47 STAMP=735411903
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1gltavme_1_1 RECID=48 STAMP=735411918
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1hltavml_1_1 RECID=49 STAMP=735411925
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1iltavmm_1_1 RECID=50 STAMP=735411927
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1jltavmo_1_1 RECID=51 STAMP=735411928
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1kltavn7_1_1 RECID=52 STAMP=735411943
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1lltavn8_1_1 RECID=53 STAMP=735411944
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1mltavn9_1_1 RECID=54 STAMP=735411945
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1nltavna_1_1 RECID=55 STAMP=735411946
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1oltavnb_1_1 RECID=56 STAMP=735411948
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1pltavnr_1_1 RECID=57 STAMP=735411963
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1qltavns_1_1 RECID=58 STAMP=735411965
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1rltavnv_1_1 RECID=59 STAMP=735411967
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1sltb3li_1_1 RECID=60 STAMP=735415987
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/c-1037536304-20101118-00 RECID=61 STAMP=735415990
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1ultcmae_1_1 RECID=62 STAMP=735467855
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/1vltdh86_1_1 RECID=63 STAMP=735495431
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/20ltdh8e_1_1 RECID=64 STAMP=735495438
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/21ltdh8f_1_1 RECID=65 STAMP=735495439
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/22ltdh8g_1_1 RECID=66 STAMP=735495440
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/23ltdh8v_1_1 RECID=67 STAMP=735495455
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/24ltdh90_1_1 RECID=68 STAMP=735495456
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/25ltdh91_1_1 RECID=69 STAMP=735495458
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/26ltdh93_1_1 RECID=70 STAMP=735495459
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/27ltdh94_1_1 RECID=71 STAMP=735495460
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/28ltdh9j_1_1 RECID=72 STAMP=735495475
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/29ltdh9k_1_1 RECID=73 STAMP=735495477
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/2bltdhds_1_1 RECID=74 STAMP=735495612
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/2cltdig5_1_1 RECID=75 STAMP=735496710
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/2cltdig5_1_2 RECID=76 STAMP=735496710
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/2dltdj5h_1_1 RECID=77 STAMP=735497394
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/product/11g/dbs/2eltdj89_1_1 RECID=78 STAMP=735497481
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/rman/full_bak_2fltdni1_1_1 RECID=79 STAMP=735501889
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/rman/full_bak_2gltdnih_1_1 RECID=80 STAMP=735501905
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/rman/full_bak_2hltdnio_1_1 RECID=81 STAMP=735501914
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/rman/full_bak_2iltdnji_1_1 RECID=82 STAMP=735501938
交叉校验备份片段: 找到为 'AVAILABLE'
备份片段句柄=/opt/oracle/rman/full_bak_c-1037536304-20101119-00 RECID=83 STAMP=735501940
已交叉检验的 55 对象

RMAN 保留策略将应用于该命令
将 RMAN 保留策略设置为 7 天的恢复窗口
未找到已废弃的备份

恢复管理器完成。
</code></pre>
<h3 id="zhi-xing-ding-shi-ren-wu">执行定时任务</h3>
<p>设置crontab（略）。</p>
<h2 id="chang-jing-2-bei-fen-zheng-ge-shu-ju-ku-bing-qing-chu-3-tian-tian-bei-fen-de-gui-dang-ri-zhi">场景2 备份整个数据库，并清除3天天备份的归档日志</h2>
<h3 id="yao-qiu-1">要求</h3>
<p>1、备份整个数据库，包括控制文件以及归档日志；<br>
2、清除3天前备份的归档日志。</p>
<h3 id="rman-jiao-ben-1">RMAN脚本</h3>
<pre><code class="language-shell">oracle@mmsc103:~/rmanbak&gt; more everydaybak.rman
#script:fullbakup.rman
# creater:wangyunzeng
# date:2011-03-11
# desc:backup all database datafile in archive with rman
# connect database
connect target rman/rman;
connect catalog rman/rman@mmsgdb;

#start backup database
run
{
  allocate channel t1 type disk;   
configure controlfile autobackup format for device type disk to '/opt/oracle/rmanbak/controlfile_bak_%F';                        
backup database format 'fullbak_%s_%p_%u'   (archivelog all );
crosscheck backupset;
delete noprompt obsolete;
delete noprompt archivelog until time "sysdate -3";
release channel t1;          
}
#end
</code></pre>
<h3 id="perl-jiao-ben">Perl脚本</h3>
<pre><code class="language-shell">oracle@mmsc103:~/rmanbak&gt; more backup.perl 
#!/use/bin/perl
##################################################
###        作用：rman定时任务脚本              ###
###        日期：2011-03-11                    ###
###        作者：王运增                        ###
##################################################

#获取系统当前时间
my ($sec,$min,$hour,$day,$month,$year)= localtime(time());
$year+=1900;
$month=sprintf("%02d",$month+1);
$day=sprintf("%02d",$day);
$hour=sprintf("%02d",$hour);
$min=sprintf("%02d",$min);
$sec=sprintf("%02d",$sec);
my $daytime = "$year$month$day$hour$min$sec";

system("/opt/oracle/product/11g/bin/rman   cmdfile = '/opt/oracle/rmanbak/everydaybak.rman' msglog=/opt/oracle/rmanbak/everydaybak_$
daytime.log");

oracle@mmsc103:~/rmanbak&gt;
</code></pre>
<h3 id="she-ding-ding-shi-ren-wu">设定定时任务</h3>
<pre><code class="language-shell">mmsc103:~ # crontab -e

      # DO NOT EDIT THIS FILE - edit the master and reinstall.
      # (/tmp/temp.txt installed on Wed Jan  5 17:42:07 2011)
      # (Cron version V5.0 -- $Id: crontab.c,v 1.12 2004/01/23 18:56:42 vixie Exp $)
      0 1 * * * su - oracle -c /opt/oracle/rmanbak/backup.perl
</code></pre>
<h1 id="fu-lu">附录</h1>
<h2 id="zhu-yu">术语</h2>
<h3 id="backup-sets-bei-fen-ji-he">Backup Sets （备份集合）</h3>
<p>备份集合的特性：包括一个或多个数据文件或归档日志，以oracle专有的格式保存，有一个完全的所有的备份片集合构成，构成一个完全备份或增量备份。</p>
<h3 id="backup-pieces-bei-fen-pian">Backup Pieces （备份片）</h3>
<p>一个备份集由若干个备份片组成。每个备份片是一个单独的输出文件。一个备份片的大 小是有限制的；如果没有大小的限制，  备份集就只由一个备份片构成。备份片的大小不能 大于使用的文件系统所支持的文件长度的最大值。</p>
<h3 id="image-copies-jing-xiang-bei-fen">Image Copies 镜像备份</h3>
<p>镜像备份是独立文件（数据文件、归档日志、控制文件）的备份。它很类似操作系统级 的文件备份。它不是备份集或备份片，也没有被压缩。</p>
<h3 id="full-backup-sets-quan-bei-fen-ji-he">Full backup Sets 全备份集合</h3>
<p>全备份是一个或多个数据文件中使用过的数据块的的备份。没有使用过的数据块是不被备份的，也就是说，oracle  进行备份集合的压缩。</p>
<h3 id="incremental-backup-sets-zeng-liang-bei-fen-ji-he">Incremental backup sets 增量备份集合</h3>
<p>增量备份是指备份一个或多个数据文件的自从上一次同一级别的或更低级别的备份以来被修改过的数据块。  与完全备份相同，增量备份也进行压缩。</p>
<h3 id="file-multiplexing-duo-gong">File multiplexing   多工</h3>
<p>多个数据文件可以在一个备份集中。</p>
<h3 id="recovery-catalog-resyncing-hui-fu-mu-lu-tong-bu">Recovery catalog resyncing  恢复目录同步</h3>
<p>使用恢复管理器执行 backup、copy、restore 或者 switch 命令时，恢复目录自动进行更 新，但是有关日志与归档日志信息没有自动记入恢复目录。需要进行目录同步。使用 resync catalog命令进行同步。<br>
<code>    RMAN&gt; resync catalog；</code></p>
<h3 id="incarnation-dui-ying-wu">Incarnation  对应物</h3>
<p>在不完全恢复完成之后，通常需要使用  resetlogs  选项来打开数据库。resetlogs  表示一个 数据库逻辑生存期的结束和另一个数据库逻辑生存期的开始。数据库的逻辑生存期也被称为 一个对应物（incarnation）。每次使用  resetlogs  选项来打开数据库后都会创建一个新的数据库 对应物。</p>
<h2 id="yu-rman-bei-fen-xiang-guan-de-dong-tai-xing-neng-biao">与RMAN备份相关的动态性能表</h2>
<table>
<thead>
<tr>
<th>动态性能表名</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>V$ARCHIVED_LOG</td>
<td>本视图包含了所有归档重做日志文件的创建情况，备份情况以及其他信息</td>
</tr>
<tr>
<td>V$BACKUP_CORRUPTION</td>
<td>这个视图显示了RMAN在哪些备份集中发现了损坏的数据坏。在你使用BACKUP VALIDATE命令对备份集进行检查时如果发现了损坏的数据块，RMAN将在这个视图中写入记录</td>
</tr>
<tr>
<td>V$COPY_CORRUPTIO</td>
<td>本视图显示了哪些镜像复制备份文件已经被损坏</td>
</tr>
<tr>
<td>V$BACKUP_DATAFILE</td>
<td>本视图通常用来获取每个数据文件中非空白数据块的数量，从而帮助你创建出大小基本相等的备份集。另外，在视图中也包含了数据文件中损坏的数据块的信息</td>
</tr>
<tr>
<td>V$BACKUP_REDOLOG</td>
<td>本视图显示了在现有的备份集中有哪些归档重做日志文件</td>
</tr>
<tr>
<td>V$BACKUP_SET</td>
<td>本视图显示了已经创建的备份集的信息</td>
</tr>
<tr>
<td>V$BACKUP_PIECE</td>
<td>本视图显示了已经创建的备份片段的信息</td>
</tr>
</tbody>
</table>
<h3 id="huo-de-zheng-zai-jin-xing-de-jing-xiang-fu-zhi-cao-zuo-de-zhuang-tai-xin-xi">获得正在进行的镜像复制操作的状态信息</h3>
<pre><code class="language-shell">Select  sid,serial#, context ,sofar,totalwork,totalwork,
round(sofar / totalwork *  100 ,  2 )
from v$session_longops where  opname  like  'RMAN::aggregate';
</code></pre>
<h3 id="huo-de-rman-yong-lai-wan-cheng-bei-fen-cao-zuo-de-fu-wu-jin-cheng-de-sid-yu-spid-xin-xi">获得rman用来完成备份操作的服务进程的SID与SPID信息</h3>
<pre><code class="language-shell">select  sid, spid, client_info 
from  v$process p, v$session s 
where  p.addr = s.paddr 
and  client_info  like   '%id=rman%';
</code></pre>
<h3 id="cha-xun-shu-ju-wen-jian-lin-shi-wen-jian-yu-biao-kong-jian-dui-ying-ji-shu-ju-wen-jian-xu-hao">查询数据文件，临时文件与表空间对应及数据文件序号</h3>
<pre><code class="language-shell">select  ts.tablespace_name, df.file_name, df.file_id, tf.file_name 
from  dba_tablespaces ts, dba_data_files df, dba_temp_files tf 
where  ts.tablespace_name = df.tablespace_name(+) 
and  ts.tablespace_name = tf.tablespace_name(+);
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-27046</title>
    <url>/2011/04/26/oracle_troubleshoot_ora_27046/</url>
    <content><![CDATA[<h1 id="ora-27046-cuo-wu-ma-jie-jue-fang-fa">ORA-27046  错误码解决方法</h1>
<h2 id="bei-jing">背景</h2>
<p>当前数据库undo表空间使用undotbs1，数据文件大小已大26G，严重占用系统分区空间。为了解决这个问题，重新创建另外一个undo表空间，并使数据库在使用新的undo表空间启动。在使用新的undo表空间前，创建pfile文件，结果就出现了本文描述的问题。</p>
<h2 id="xian-xiang">现象</h2>
<p>通过spfile文件创建pfile，报ORA-27046</p>
<pre><code class="language-shell">SQL&gt; create pfile='/home/oracle/product/11g/dbs/pfile' from spfile;
create pfile='/home/oracle/product/11g/dbs/pfile' from spfile
*
ERROR at line 1:
ORA-01565: 标识文件 '?/dbs/spfile@.ora' 时出错
ORA-27046: 文件大小不是逻辑块大小的倍数
Additional information: 1
</code></pre>
<h2 id="yuan-yin-fen-xi">原因分析</h2>
<p>出现这个原因，往往是因为spfile文件被破坏导致的。Spfile文件是一个二进制文件，不能修改，一旦修改，则使用该spfile文件启动数据库时，数据库是无法启动的。即：修改了spfile文件后，该文件报废。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>方法1：使用admin下init文件启动数据库，并重新创建spfile文件；</p>
<p>方法2：将现有的spfile文件中的有效内容拷贝到文本文件中，使用该文本文件启动数据库后并重新创建spfile文件。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-01940</title>
    <url>/2011/05/04/oracle_troubleshoot_ora_01940/</url>
    <content><![CDATA[<h1 id="ora-01940-wu-fa-shan-chu-dang-qian-yi-lian-jie-de-yong-hu">ORA-01940：无法删除当前已链接的用户</h1>
<h2 id="xian-xiang">现象</h2>
<pre><code class="language-shell">SQL&gt; drop user ufuser cascade;    
drop user ufuser cascade
*
ERROR at line 1:
ORA-01940: cannot drop a user that is currently connected
</code></pre>
<h2 id="yuan-yin">原因</h2>
<p>当前用户正在与数据库建立连接，session关系还在。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>Kill掉对应的session既可。</p>
<p>1、	查询对应用户与当前数据库连接的session信息</p>
<pre><code class="language-shell">SQL&gt; set wrap off    
SQL&gt; set lin 200
SQL&gt; set pagesize 0
SQL&gt; select username,sid,serial# from v$session where username ='UFUSER';
UFUSER                                513         81
UFUSER                                515         62
UFUSER                                516      49583
UFUSER                                517      38584
UFUSER                                519      12508
UFUSER                                520      36408
UFUSER                                522      64260
UFUSER                                523      59321
UFUSER                                524       4285
UFUSER                                525      42644
UFUSER                                529        181
UFUSER                                530      44970
</code></pre>
<p>2、kill session操作</p>
<pre><code class="language-shell">alter system kill session'513,81';
alter system kill session'515,62';
alter system kill session'516,49583';
alter system kill session'519,12508';
alter system kill session'520,36408';
alter system kill session'522,64260';
alter system kill session'523,59321';
alter system kill session'524,4285';
alter system kill session'525,42644';
alter system kill session'529,181';
alter system kill session'530,44970';
</code></pre>
<p>3、查询session信息确定该session是否被kill</p>
<pre><code>select saddr,sid,serial#,paddr,username,status from v$session where username is not null and username ='UFUSER';
</code></pre>
<p>status 为要删除用户的session状态，如果还为inactive，说明没有被kill掉，如果状态为killed，说明已kill。</p>
<p>4、如果session被kill掉，然后执行drop user操作。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle RMAN备份与恢复概述与实践篇2</title>
    <url>/2011/06/07/rman_bakcup_and_recovery/</url>
    <content><![CDATA[<h2 id="rman-jian-jie">RMAN简介</h2>
<p>RMAN 可以用来备份和恢复数据库文件、归档日志和控制文件，也可以用来执行完全或不完全的数据库恢复。RMAN有三种不同的用户接口：COMMAND LINE方式、GUI 方式（集成在OEM 中的备份管理器）、API 方式（用于集成到第三方的备份软件中）。具有如下特点：</p>
<p>1）功能类似物理备份，但比物理备份强大N倍，从下面的特点可以看到；</p>
<p>2）可以压缩空块；</p>
<p>3）可以在块水平上实现增量；</p>
<p>4）可以把备份的输出打包成备份集，也可以按固定大小分割备份集；</p>
<p>5）备份与恢复的过程可以自动管理；</p>
<p>6）可以使用脚本（存在Recovery catalog 中）</p>
<p>7）可以做坏块监测</p>
<h2 id="rman-bei-fen-xing-shi">RMAN备份形式</h2>
<p>RMAN备份有两种形式：</p>
<p>1、镜像备份（image copies）；</p>
<p>2、备份集备份（backup sets）。</p>
<h3 id="jing-xiang-bei-fen">镜像备份</h3>
<p>镜像备份实际就是RMAN利用目标数据库服务进程来完成文件的copy操作，是数据文件、控制文件或者归档日志文件的副本。</p>
<p>RMAN镜像备份的副本无法通过list backup显示，可以通过list copy显示。</p>
<p>本文主要描述备份集备份。</p>
<h3 id="bei-fen-ji-bei-fen">备份集备份</h3>
<p>备份集是通过RMAN创建的逻辑备份对象，一个备份集中可以包括多个控制文件、数据文件、归档文件。</p>
<p>备份集在物理上由多个备份片段组成，每个备份片段就是一个操作系统文件。</p>
<h2 id="rman-bei-fen-lei-xing">RMAN备份类型</h2>
<p>利用RMAN进行备份时，可以通过三种方式来对RMAN的备份做分类</p>
<h3 id="wan-quan-bei-fen-full-backup-yu-zeng-liang-bei-fen-incremental-backup">完全备份(Full Backup)与增量备份(Incremental Backup)</h3>
<p>全备与增备是针对数据文件而言，控制文件和归档日志文件不能进行增量备份。当然，后两者可以做备份优化。</p>
<h3 id="da-kai-bei-fen-open-backup-huo-guan-bi-bei-fen-closed-backup">打开备份(Open Backup)或关闭备份(Closed Backup)</h3>
<p>数据库打开状态下进行备份即是打开备份，数据库关闭状态下(加载状态)进行的备份即关闭备份。</p>
<h3 id="yi-zhi-bei-fen-consistent-backup-yu-bu-yi-zhi-bei-fen-inconsistent-backup">一致备份(Consistent Backup)与不一致备份(Inconsistent Backup)</h3>
<p>数据库打开状态或不干净关闭状态(shutdown abort)进行的备份是不一致备份，利用不一致的备份修复数据库后还需要做数据库的恢复。在数据库干净关闭状态进行的备份是一致备份，利用一致备份修复数据库后不需要做数据库的恢复。</p>
<h2 id="rman-report-list-delete-ming-ling-xiang-jie">RMAN report list delete命令详解</h2>
<h3 id="report">report</h3>
<pre><code class="language-shell">1. 报告目标数据库的物理结构              RMAN&gt; report schema;

2. 报告最近N天尚未备份的数据文件           RMAN&gt; report need backup days=3;

3. 报告表空间上最近N天未备份的数据文件         RMAN&gt; report need backup days=3 tablespace MMSG;

4. 报告恢复数据文件需要的增量备份个数超过3次的数据文件 RMAN&gt; report need backup incremental 3;

5. 报告备份文件低于2份的所有数据文件         RMAN&gt; report need backup redundancy 2 database;

6. 报告文件报表的恢复需要超过6天的归档日志的数据文件  RMAN&gt; report need backup recovery window of 6 days;

7. 报告数据库所有不可恢复的数据文件          RMAN&gt; report unrecoverable;

8. 报告备份次数超过2次的陈旧备份           RMAN&gt; report obsolete redundancy 2;

9. 报告多余的备份                  RMAN&gt; report obsolete;
</code></pre>
<h3 id="list">list</h3>
<pre><code class="language-shell">list backup;             列出详细备份

list expired backup;         列出过期备份

list backup of database;       列出所有数据文件的备份集

list backup of tablespace MMSG;    列出特定表空间的所有数据文件备份集

list backup of controlfile;      列出控制文件备份集

list backup of archivelog all;    列出归档日志备份集详细信息

list archivelog all;　　　　　　    列出归档日志备份集简要信息

list backup of spfile;        列出SPFILE备份集

list copy of datafile 5;       列出数据文件映像副本

list copy of controlfile;       列出控制文件映像副本

list copy of archivelog all;     列出归档日志映像副本

list incarnation of database;     列出对应物/列出数据库副本

list backup summary;         概述可用的备份（B表示backup、F表示FULL、A表示archive log、S说明备份状态（A　AVAILABLE　　　X EXPIRED )

list backup by file;         按备份类型列出备份

​                   按照数据文件备份，归档日志备份，控制文件备份，服务器参数文件备份　列出
</code></pre>
<h3 id="check">check</h3>
<pre><code class="language-shell">RMAN&gt; crosscheck backup;               核对所有备份集 

RMAN&gt; crosscheck backup of database;         核对所有数据文件的备份集 

RMAN&gt; crosscheck backup of tablespace MMSG;      核对特定表空间的备份集 

RMAN&gt; crosscheck backup of datafile 4;        核对特定数据文件的备份集 

RMAN&gt; crosscheck backup of controlfile;        核对控制文件的备份集 

RMAN&gt; crosscheck backup of spfile;          核对SPFILE的备份集 

RMAN&gt; crosscheck backup of archivelog sequence 3;   核对归档日志的备份集

RMAN&gt; crosscheck copy;                 核对所有映像副本

RMAN&gt; crosscheck copy of database;          核对所有数据文件的映像副本

RMAN&gt; crosscheck copy of tablespace MMSG;       核对特定表空间的映像副本 

RMAN&gt; crosscheck copy of datafile 6;         核对特定数据文件的映像副本 

RMAN&gt; crosscheck copy of archivelog sequence 4;    核对归档日志的映像副本 

RMAN&gt; crosscheck copy of controlfile;         核对控制文件的映像副本

RMAN&gt; crosscheck backup tag='SAT_BACKUP';

RMAN&gt; crosscheck backup completed after 'sysdate - 2';

RMAN&gt; crosscheck backup completed between 'sysdate - 5' and 'sysdate -2 ';

RMAN&gt; crosscheck backup device type sbt;

RMAN&gt; crosscheck archivelog all;

RMAN&gt; crosscheck archivelog like '%ARC00012.001';

RMAN&gt; crosscheck archivelog from sequence 12;

RMAN&gt; crosscheck archivelog until sequence 522;
</code></pre>
<h3 id="delete">delete</h3>
<pre><code class="language-shell">RMAN&gt; delete obsolete;         删除陈旧备份；

RMAN&gt; delete expired backup;      删除EXPIRED备份 

RMAN&gt; delete expired copy;       删除EXPIRED副本

RMAN&gt; delete backupset 19;       删除特定备份集

RMAN&gt; delete backuppiece '/opt/oracle/oradata/backup/test.ora';  删除特定备份片

RMAN&gt; delete backup;          删除所有备份集

RMAN&gt; delete datafilecopy '/opt/oracle/oradata/backup/test.bak'; 删除特定映像副本

RMAN&gt; delete copy;           删除所有映像副本

RMAN&gt; delete archivelog all delete input;

RMAN&gt; delete backupset 22 format = '/opt/oracle/oradata/backup/%u.bak' delete input;

​                    在备份后删除输入对象      

RMAN&gt; delete backupset id;       删除备份集
</code></pre>
<h2 id="rman-bei-fen">RMAN备份</h2>
<h3 id="bei-fen-zheng-ge-shu-ju-ku">备份整个数据库</h3>
<pre><code class="language-shell">run {

allocate channel c1 type disk;

backup

full

tag full_db_backup

format "/opt/oracle/mmsg.load/db_t%t_s%s_p%p"

(database);

release channel c1;

}
</code></pre>
<h3 id="bei-fen-zhi-ding-de-shu-ju-wen-jian">备份指定的数据文件</h3>
<pre><code class="language-shell">backup datafile '/opt/oracle/oradata/mmsgdb/test.dbf';
</code></pre>
<h3 id="bei-fen-biao-kong-jian">备份表空间</h3>
<pre><code class="language-shell">backup tablespace MMSG;
</code></pre>
<h3 id="bei-fen-kong-zhi-wen-jian">备份控制文件</h3>
<p>方法1：</p>
<pre><code class="language-shell">configure controlfile autobackup on;
</code></pre>
<p>方法2：</p>
<pre><code class="language-shell">backup current controlfile;
</code></pre>
<p>方法3:</p>
<pre><code class="language-shell">backup database include current controlfile;
</code></pre>
<h3 id="bei-fen-gui-dang-ri-zhi">备份归档日志</h3>
<pre><code class="language-shell">backup archivelog all;
</code></pre>
<h3 id="zeng-liang-bei-fen">增量备份</h3>
<p>建立一个增量级别为0的全库备份：</p>
<pre><code class="language-shell"> backup INCREMENTAL LEVEL=0 database;
</code></pre>
<p>建立一个增量级别为1的数据库表空间的备份：</p>
<pre><code class="language-shell"> backup incremental level=1 tablespace MMSG;
</code></pre>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Rman默认创建的增量备份是Differential方式，如果要建立Cumulative方式的增量备份，在执行BACKUP命令时显式指定即可，例如：</p>
</li>
</ul>
<pre><code class="language-shell">RMAN&gt; BACKUP INCREMENTAL LEVEL=2 CUMULATIVE DATABASE;
</code></pre>
<h3 id="rong-yu-bei-fen">冗余备份</h3>
<p>步骤一：显示指定copies数量</p>
<pre><code class="language-shell">RMAN&gt; backup copies 2 tablespace MMSG;
</code></pre>
<p>步骤二：在批处理中增加set backup copies参数：</p>
<pre><code class="language-shell">RMAN&gt; run

{

set backup copies 1;

allocate channel c1 device type disk;

backup tablespace MMSG;

}
</code></pre>
<p>步骤三：通过configure设定预备份Duplexed方式</p>
<h2 id="rman-hui-fu">RMAN恢复</h2>
<h3 id="hui-fu-spfile-wen-jian">恢复spfile文件</h3>
<pre><code class="language-shell">RMAN&gt; startup nomount

RMAN&gt; set dbid=1037536304

RMAN&gt; restore spfile from autobackup; #这里confile autobackup必须设置成on

RMAN&gt; startup force
</code></pre>
<h3 id="biao-kong-jian-de-hui-fu">表空间的恢复</h3>
<pre><code class="language-shell">RMAN&gt; shutdown immediate

RMAN&gt;startup mount

RMAN&gt;restore tablespace "TEST"; #TEST为要恢复的表空间名

RMAN&gt;recover tablespace "TEST";

RMAN&gt;alter database open;
</code></pre>
<h3 id="shu-ju-wen-jian-de-hui-fu">数据文件的恢复</h3>
<p>这个操作类似于表空间的恢复</p>
<pre><code class="language-shell">RMAN&gt;shutdown immediate

RMAN&gt;startup mount

RMAN&gt;restorer datafile datafilepath; #或者是restore datafile datafile_num;

RMAN&gt;recover datafile datafilepath;  #或者是recover datafile datafile_num;

RMAN&gt;alter database open
</code></pre>
<h3 id="quan-ku-de-hui-fu">全库的恢复</h3>
<pre><code class="language-shell">RMAN&gt;shutdown immediate

RMAN&gt;startup mount

RMAN&gt; run

2&gt; {

3&gt; allocate channel c1 device type disk;

4&gt; restore database;

5&gt; }
</code></pre>
<h3 id="kong-zhi-wen-jian-de-hui-fu">控制文件的恢复</h3>
<p><strong>1</strong>**、损坏部分控制文件**</p>
<p>步骤一：使用dbv命令检测控制文件是否被损坏，如：dbv file=control02.ctl blocksize=16384</p>
<p>步骤二：cp好的控制文件，并重命名</p>
<p><strong>2</strong>**、所有控制文件均被损坏**</p>
<p>损坏所有的控制文件或者人为的删除所有的控制文件，通过备份复制已经不能解决问题，只能重新建立新的控制文件。</p>
<p>保留dba用户执行 alter database backup controlfile to trace 产生的重建控制文件的命令</p>
<p>步骤一:</p>
<p>关闭数据库，修改trace文件中创建control文件部分，dba用户执行脚本重创控制文件;</p>
<p>步骤二 :</p>
<p>重启数据库</p>
<p>如果数据库运行在归档模式下，且有控制文件的备份(CONFIGURE CONTROLFILE AUTOBACKUP ON)，可以使用有可用的控制文件的备份，则可以使用restore controlfile from ‘备份的控制文件路径+文件名’来完成控制文件的恢复操作</p>
<p>1、数据库启动到非安装状态(nomount)</p>
<p>2、RMAN恢复</p>
<pre><code class="language-shell"> RMAN&gt; run {

   allocate channel c1 device type disk;

   restore controlfile from ‘/opt/oracle/rman/back_c-1037536304-20101123-07’;

   release channel c1;

   }
</code></pre>
<h3 id="zhong-zuo-ri-zhi-wen-jian-de-hui-fu">重做日志文件的恢复</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate

数据库已经关闭。

已经卸载数据库。

ORACLE 例程已经关闭。

SQL&gt; startup mount

SQL&gt; recover database using backup controlfile until cancel;

SQL&gt; alter database open resetlogs;
</code></pre>
<h3 id="gui-dang-ri-zhi-wen-jian-de-hui-fu">归档日志文件的恢复</h3>
<pre><code class="language-shell">RMAN&gt;shutdown immediate

RMAN&gt;startup mount

RMAN&gt; run

2&gt; {

3&gt; allocate channel c1 device type disk;

4&gt; restore archivelog all;

5&gt; }
</code></pre>
<h3 id="sun-pi-fei-dang-qian-lian-ji-ri-zhi">损坏非当前联机日志</h3>
<p>步骤一 启动数据库，报错：ORA-00313和ORA-00312</p>
<p>步骤二 查看v$log视图</p>
<p>步骤三  用CLEAR命令重建该日志文件</p>
<pre><code class="language-shell">SQL&gt; alter database clear logfile group 3;
</code></pre>
<p>​      如果是该日志组还没有归档，则需要用</p>
<pre><code class="language-shell">  SQL&gt;alter database clear unarchived logfile group 3;
</code></pre>
<p>步骤四  打开数据库，并备份数据库</p>
<pre><code class="language-shell"> SQL&gt; alter database open;
</code></pre>
<h3 id="sun-pi-dang-qian-lian-ji-ri-zhi">损坏当前联机日志</h3>
<p>一、数据库正常关闭，日志文件中没有未决的事务需要实例恢复，当前日志组的损坏，可以直接使用alter database clear unarchived logfile group N;命令来重建</p>
<pre><code class="language-shell">  SQL&gt; alter database clear unarchived logfile group 2;

  SQL&gt; alter database open;
</code></pre>
<p>二、日志组中有活动事务，需要介质恢复，日志组需要用来数据同步，有两种解决方法：</p>
<p>1、通过不完全恢复，保持数据库数据一致性，这种方法要求数据库运行在归档方式下，且有可用的数据文件的备份</p>
<p>步骤一 启动数据库，报错：ORA-00313 ，ORA-00312， ORA-27037</p>
<p>步骤二 模拟当前日志组中日志文件损坏 SQL&gt; select * from v$log;</p>
<p>步骤三 拷贝有效的备份，进行不完全恢复（包括所有的控制文件、数据文件、redo文件）</p>
<p>步骤四 数据库启动到mount状态，进行不完全恢复：</p>
<pre><code class="language-shell">      SQL&gt; startup mount

      SQL&gt; recover database until cancel;

      SQL&gt; alter database open resetlogs;
</code></pre>
<p>注：这个时候是不能用rman进行恢复的！</p>
<p>2、通过强制性恢复，这种方法会导致数据的不一致性，推荐使用方法一</p>
<p>步骤一 模拟当前日志组中日志成员被损坏 SQL&gt; select * from v$log;</p>
<p>步骤二 修改pfile文件，增加隐性参数</p>
<pre><code class="language-shell"> vi /opt/oracle/admin/mmsgdb/pfile/init.ora.232011183420

  \#add for test by wangyunzeng

  _allow_resetlogs_corruption=TRUE
</code></pre>
<p>步骤三 通过pfile文件启动数据库</p>
<p>步骤四 进行介质恢复</p>
<pre><code class="language-shell">SQL&gt; recover database until cancel;
</code></pre>
<p>​      出现如下信息时，选择cancel命令  指定日志:</p>
<pre><code class="language-shell"> {&lt;RET&gt;=suggested | filename | AUTO | CANCEL}
 cancel
</code></pre>
<p>步骤五 resetlogs方式启动数据库</p>
<pre><code class="language-shell">SQL&gt; alter database open resetlogs;
</code></pre>
<p>步骤六 关闭数据库，去掉pfile文件中隐性参数，重启数据库（直接执行startup命令即可）</p>
<p>步骤七 备份整个数据库  物理冷备或者物理热备或者RMAN备份都行。</p>
<p>步骤八 导入数据   如果有相关的exp导出的数据，可以执行imp导入操作，毕竟数据发生丢失。</p>
<p>步骤九 表数据分析  建议执行一下表分析</p>
<pre><code class="language-shell">SQL&gt; ANALYZE TABLE time VALIDATE STRUCTURE CASCADE;
</code></pre>
<h3 id="lin-shi-shu-ju-wen-jian-de-hui-fu">临时数据文件的恢复</h3>
<p>临时数据文件不包含有效数据，发生丢失后删除原先临时数据文件并进行重建就可以了。</p>
<h2 id="rman-shi-zhan">RMAN实战</h2>
<h3 id="shi-zhan-1">实战1</h3>
<p>要求</p>
<p>1 、每天夜间1点执行；</p>
<p>2 、数据库全备，同时备份控制文件及归档日志文件，备份文件保存至：/opt/oracle/rman目录下，并在完成归档日志文件备份后，自动删除已备份的归档日志；</p>
<p>3 、备份保留7天，过期则自动删除；</p>
<p>4 、保留操作日志备查；</p>
<p>RMAN脚本</p>
<pre><code class="language-shell">oracle@mmsg:~/rman&gt; more back_full.rman

run

{

configure retention policy to recovery window of 7 days;

configure controlfile autobackup on;

configure controlfile autobackup format for device type disk to '/opt/oracle/rman/full_bak_%F';

allocate channel c1 device type disk format '/opt/oracle/rman/full_bak_%U';

backup database skip inaccessible filesperset 10 plus archivelog filesperset 20 delete all input;

release channel c1;

}

allocate channel for maintenance device type disk;

crosscheck backupset;

delete noprompt obsolete;
</code></pre>
<p>命令执行</p>
<pre><code class="language-shell">oracle@mmsg:~/rman&gt; rman target / msglog /opt/oracle/rman/bak.log cmdfile=/opt/oracle/rman/back_full.rman
</code></pre>
<pre><code class="language-shell">oracle@mmsc103:~/rmanbak&gt; more backup.pl

#!/usr/bin/perl

###    作用：rman定时任务脚本       ###

#获取系统当前时间

my ($sec,$min,$hour,$day,$month,$year)= localtime(time());

$year+=1900;

$month=sprintf("%02d",$month+1);

$day=sprintf("%02d",$day);

$hour=sprintf("%02d",$hour);

$min=sprintf("%02d",$min);

$sec=sprintf("%02d",$sec);

my $daytime = "$year$month$day$hour$min$sec";

system("/opt/oracle/product/11g/bin/rman  cmdfile = '/opt/oracle/rmanbak/everydaybak.rman' msglog=/opt/oracle/rmanbak/everydaybak_$

daytime.log");
</code></pre>
<p>设置crontab</p>
<p>每天凌晨1点执行数据库的备份</p>
<pre><code class="language-shell">0 1 * * * su - oracle -c /opt/oracle/rmanbak/backup.pl
</code></pre>
<h3 id="shi-zhan-2">实战2</h3>
<p>1、备份整个数据库，包括控制文件以及归档日志；</p>
<p>2、清除3天前备份的归档日志。</p>
<p>RMAN脚本</p>
<pre><code class="language-shell">oracle@mmsc103:~/rmanbak&gt; more everydaybak.rman

#script.:fullbakup.rman

# creater:wangyunzeng

# date:2011-03-11

# desc:backup all database datafile in archive with rman

# connect database

connect target rman/rman;

connect catalogrman/rman@mmsgdb;

#start backup database

run

{

 allocate channel t1 type disk; 

configure controlfile autobackup format for device type disk to '/opt/oracle/rmanbak/controlfile_bak_%F';            

backup database format 'fullbak_%s_%p_%u'  (archivelog all );

crosscheck backupset;

delete noprompt obsolete;

delete noprompt archivelog until time "sysdate -3";

release channel t1;     

}

#end
</code></pre>
<h2 id="rman-chang-jian-wen-ti-jie-jue-fang-fa">RMAN常见问题解决方法</h2>
<h3 id="rman-ming-ling-shu-ru-hou-zhong-duan-wu-fan-ying-yi-zhi-chu-yu-deng-dai-zhuang-tai-qie-chang-shi-jian-ru-ci">RMAN命令输入后终端无反应，一直处于等待状态，且长时间如此</h3>
<p>原因：操作系统也有一个rman命令，这里执行的是os的rman而非Oracle的</p>
<p>解决：oracle用户设置环境变量 export PATH=$ORACLE_HOME:$PATH</p>
<h3 id="rman-wu-fa-jin-xing-bei-fen-cao-zuo-cha-kan-bei-fen-xin-xi-pei-zhi-xin-xi">RMAN无法进行备份操作/查看备份信息/配置信息</h3>
<p>RMAN-03002: list 命令 (在 03/05/2011 09:28:03 上) 失败</p>
<p>RMAN-06004: 恢复目录数据库发生 ORACLE 错误: RMAN-20001: target database not found in recovery catalog</p>
<p>RMAN-03002: backup 命令 (在 03/05/2011 09:28:32 上) 失败</p>
<p>RMAN-03014: 恢复目录的隐式重新同步失败</p>
<p>RMAN-06004: 恢复目录数据库发生 ORACLE 错误: RMAN-20001: 在恢复目录中未找到目标数据库</p>
<p>原因：RMAN未注册。</p>
<p>解决方法：注册RMAN。</p>
<pre><code class="language-shell">RMAN&gt; register database;           
</code></pre>
<p>​</p>
<h3 id="rman-bei-fen-wen-jian-yi-chang-shan-chu">RMAN备份文件异常删除</h3>
<p>原因：RMAN备份的文件存放在某个目录下，该文件没有通过rman命令delete删除，而是在操作系统侧执行rm操作，导致再去删除这个备份文件时无法删除掉。</p>
<p>解决：</p>
<pre><code class="language-shell">RMAN&gt; list backupset by backup summary;

RMAN&gt; crosscheck backupset;

RMAN&gt; delete backupset;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-01034  ORA-27101，ORA-12514</title>
    <url>/2011/07/16/oracle_troubleshoot_ora_01034_ora_27101_ora_12514/</url>
    <content><![CDATA[<h1 id="ora-01034-ora-27101-ora-12514-jie-jue-fang-fa">ORA-01034  ORA-27101，ORA-12514解决方法</h1>
<h2 id="xian-xiang">现象</h2>
<pre><code class="language-shell">ORA-01034: ORACLE not available
ORA-27101: shared memory realm does not exist
</code></pre>
<h2 id="yuan-yin">原因</h2>
<p>（1）	一般是因为数据库未正常停止导致；</p>
<p>（2）	相关数据文件过大；</p>
<p>（3）	还有其它原因，具体原因请具体对待。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>这里以数据文件过大导致上述现象的解决方法，如下：</p>
<p>在数据文件存放路径目录下发现一个文件，undotbs01.dbf 大的惊人！ 16G</p>
<p>解决方法就是压缩这个undo文件。</p>
<pre><code class="language-shell">SQL&gt; startup   
ORACLE instance started.   
  
Total System Global Area  135338868 bytes   
Fixed Size                   453492 bytes   
Variable Size             109051904 bytes   
Database Buffers           25165824 bytes   
Redo Buffers                 667648 bytes   
Database mounted.   
ORA-01157: cannot identify/lock data file 2 - see DBWR trace file   
ORA-01110: data file 2: ''D:ORACLEORADATAORCLUNDOTBS01.DBF''  
  
  
SQL&gt; alter system set undo_management=''MANUAL'' scope=spfile;   
  
System altered.   
  
SQL&gt; alter database    
datafile ''d:oracleoradataorclundotbs01.dbf'' offline drop   
;   
  
Database altered.   
  
SQL&gt; alter database open;   
  
Database altered.   
  
SQL&gt;   
  
SQL&gt;   
create undo tablespace undotbs2 datafile '   
'd:oracleoradataorclundotbs02.dbf'' size 100M;   
Tablespace created.   
SQL&gt; select * from v?$tablespace;   
  
       TS# NAME                           INC   
---------- ------------------------------ ---   
         3 CWMLITE                        YES   
         4 DRSYS                          YES   
         5 EXAMPLE                        YES   
         6 INDX                           YES   
         7 ODM                            YES   
         0 SYSTEM                         YES   
         8 TOOLS                          YES   
         1 UNDOTBS1                       YES   
         9 USERS                          YES   
        10 XDB                            YES   
         2 TEMP                           YES   
  
       TS# NAME                           INC   
---------- ------------------------------ ---   
        11 UNDOTBS2                       YES   
  
12 rows selected.   
  
  
SQL&gt; alter system set undo_management=''AUTO'' scope=spfile;   
  
System altered.   
  
SQL&gt; alter system set undo_tablespace=''UNDOTBS2'' scope=spfile;   
  
System altered.   
  
SQL&gt; shutdown immediate;   
Database closed.   
Database dismounted.   
ORACLE instance shut down.   
SQL&gt; startup   
ORACLE instance started.   
  
Total System Global Area  135338868 bytes   
Fixed Size                   453492 bytes   
Variable Size             109051904 bytes   
Database Buffers           25165824 bytes   
Redo Buffers                 667648 bytes   
Database mounted.   
Database opened.   
SQL&gt; show parameter undo   
  
NAME                                 TYPE        VALUE   
------------------------------------ ----------- -----   
undo_management                      string      AUTO   
undo_retention                       integer     10800   
undo_suppress_errors                 boolean     FALSE   
undo_tablespace                      string      UNDOTBS2   
SQL&gt;  
SQL&gt; startup
ORACLE instance started.

Total System Global Area  135338868 bytes
Fixed Size                   453492 bytes
Variable Size             109051904 bytes
Database Buffers           25165824 bytes
Redo Buffers                 667648 bytes
Database mounted.
ORA-01157: cannot identify/lock data file 2 - see DBWR trace file
ORA-01110: data file 2: ''D:ORACLEORADATAORCLUNDOTBS01.DBF''


SQL&gt; alter system set undo_management=''MANUAL'' scope=spfile;

System altered.

SQL&gt; alter database 
datafile ''d:oracleoradataorclundotbs01.dbf'' offline drop
;

Database altered.

SQL&gt; alter database open;

Database altered.

SQL&gt;

SQL&gt;
create undo tablespace undotbs2 datafile '
'd:oracleoradataorclundotbs02.dbf'' size 100M;
Tablespace created.
SQL&gt; select * from v?$tablespace;

       TS# NAME                           INC
---------- ------------------------------ ---
         3 CWMLITE                        YES
         4 DRSYS                          YES
         5 EXAMPLE                        YES
         6 INDX                           YES
         7 ODM                            YES
         0 SYSTEM                         YES
         8 TOOLS                          YES
         1 UNDOTBS1                       YES
         9 USERS                          YES
        10 XDB                            YES
         2 TEMP                           YES

       TS# NAME                           INC
---------- ------------------------------ ---
        11 UNDOTBS2                       YES

12 rows selected.


SQL&gt; alter system set undo_management=''AUTO'' scope=spfile;

System altered.

SQL&gt; alter system set undo_tablespace=''UNDOTBS2'' scope=spfile;

System altered.

SQL&gt; shutdown immediate;
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; startup
ORACLE instance started.

Total System Global Area  135338868 bytes
Fixed Size                   453492 bytes
Variable Size             109051904 bytes
Database Buffers           25165824 bytes
Redo Buffers                 667648 bytes
Database mounted.
Database opened.
SQL&gt; show parameter undo

NAME                                 TYPE        VALUE
------------------------------------ ----------- -----
undo_management                      string      AUTO
undo_retention                       integer     10800
undo_suppress_errors                 boolean     FALSE
undo_tablespace                      string      UNDOTBS2
SQL&gt;
</code></pre>
<p>完成以上操作后，重新启动oracle。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>跨库拷贝数据</title>
    <url>/2011/07/18/oracle_copy_data_between_db/</url>
    <content><![CDATA[<h1 id="kua-ku-kao-bei-shu-ju-ke-yong-yu-shi-tu-ce-shi">跨库拷贝数据（可用于视图测试）</h1>
<h2 id="shi-yong-chang-jing">使用场景</h2>
<p>创建数据库A与B的脚本是一致的，或互相拷贝的表结构字段是一致的，或者想创建表，且表和另外一个库中的表一样时，我们可以通过如下方法快速将数据库B的表数据拷贝到A的表中。</p>
<h2 id="shi-jian">实践</h2>
<p>A数据库假设是一个空的数据库。IP地址是10.164.75.164</p>
<p>B数据库假设是有大量数据的数据库。IP地址是10.168.38.52</p>
<p>将B的数据拷贝到A数据库。</p>
<h3 id="bu-zou-yi-jian-li-net-fu-wu">步骤一、建立NET服务</h3>
<p>在库A上创建到B的NET服务</p>
<h3 id="bu-zou-er-chuang-jian-database-links">步骤二、创建Database links</h3>
<p>以PLSQL登录A数据库。新建Database links，Name填写为远程连接B数据库的代号，</p>
<p>连接到部分填写连接数据库B的相关信息。注意Shared（共享）要勾选。</p>
<p>注意:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>要先在A数据库的机器上先建立一个本地连接到数据库B，且名字是如下输入框的Database要一致。</p>
</li>
</ul>
<img class="shadow" src="/img/in-post/oracle-conn.png" width="600">
<h3 id="bu-zou-san-kao-bei-shu-ju">步骤三、拷贝数据</h3>
<p>Apply【应用】这个数据库链接后，就可以直接按填写的name使用。</p>
<p>例如: <code>select * from memberinfo@ora11g </code></p>
<p>就把数据库B的memberinfo表的数据查询出来，将数据库B的memberinfo数据插入数据库A的memberinfo表使用如下语句，注意修改表名。</p>
<p><code>insert into memberinfo nologging select * from  memberinfo@ ora11g </code></p>
<p>如果没有在机器上建立本地链接，则会出现以下错误：</p>
<img class="shadow" src="/img/in-post/oracle-ora-12154.png" width="300">
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-01536</title>
    <url>/2011/07/20/oracle_troubleshoot_ora_01536/</url>
    <content><![CDATA[<h1 id="ora-01536-an-li">ORA-01536 案例</h1>
<h2 id="biao-xiang">表像</h2>
<p>执行刷库脚本，创建表报错</p>
<pre><code class="language-shell">SQL&gt; SQL&gt; SQL&gt;   2    3    4    5    6  CREATE TABLE "ECTOSIINFO"
*
ERROR at line 1:
ORA-01536: space quota exceeded for tablespace 'MMSG'
</code></pre>
<h2 id="yuan-yin-fen-xi">原因分析</h2>
<p>1、查看错误码</p>
<pre><code class="language-shell">01536, 00000, "space quota exceeded for tablespace '%s'"
// *Cause:  The space quota for the segment owner in the tablespace has
//          been exhausted and the operation attempted the creation of a
//          new segment extent in the tablespace.
// *Action: Either drop unnecessary objects in the tablespace to reclaim
//          space or have a privileged user increase the quota on this
//          tablespace for the segment owner.
</code></pre>
<p>显示可能为表空间段扩展问题。</p>
<p>2、查看表空间使用率</p>
<p>观察一下表空间是否已经满了，无法自动扩展或者扩展已达配额</p>
<pre><code class="language-shell">TABLESPACE_NAME                USED_SPACE TABLESPACE_SIZE USED_PERCENT
------------------------------ ---------- --------------- ------------
MMSG                                13384         4194302   .319099578
MMSG_TMP                                0           64000            0
</code></pre>
<p>MMSG表空间使用率很低啊，3.27G的空间只使用了104M</p>
<p>3、查看表空间限额</p>
<p>表空间限额和表空间是两个不同的概念，表空间限额约束了表空间的使用情况，如果表空间200M，表空间限额只分配20M，剩下的180M的空间能够被数据库所使用的空间就被浪费掉了。</p>
<pre><code class="language-shell">SQL&gt;select tablespace_name,username,bytes,max_bytes from dba_ts_quotas;

TABLESPACE_NAME                USERNAME                            BYTES  MAX_BYTES
------------------------------ ------------------------------ ---------- ----------
IMAPLOGDB                      IMAPLOGDB                        12779520         -1
IMAPTMDB                       IMAPTMDB                           786432         -1
IMAPSMDB                       IMAPSMDB                          5177344         -1
SYSTEM                         IMAPUSER                                0         -1
ALARMDB                        ALARMDB                          17432576         -1
PERFDB                         PERFDB                          135135232         -1
NMSGUEST                       NMSGUEST                           262144         -1
PERFDB_IDX                     PERFDB_IDX                              0         -1
IMAP_DB                        IMAP_DB                          53739520         -1
已选择9行。

SQL&gt;
</code></pre>
<p>发现并没有对表空间MMSG有限额分配的信息，推论表空间MMSG应该使用默认的分配限额（具体是多少，暂时不知）。</p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>为表空间分配使用限额，设置扩大或者不限制。方法如下：</p>
<p><code>alter user mmsg quota unlimited on MMSG; </code></p>
<p>或者</p>
<p><code>grant unlimited tablespace to MMSG;</code></p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-27086</title>
    <url>/2011/08/01/oracle_troubleshoot_ora_27086/</url>
    <content><![CDATA[<h1 id="ora-27086-unable-to-lock-file-already-in-use-an-li">ORA-27086  unable to lock file - already in use  案例</h1>
<h2 id="biao-xiang">表象</h2>
<p>静默式安装oracle11g数据库并创建实例，database安装在raw上，启动数据库时，alert日志给出如下信息：</p>
<pre><code class="language-shell">kcidr_process_controlfile_error:
IO Check was called but no error was found
ORA-00227: corrupt block detected in control file: (block 1, # blocks 1)
ORA-00202: control file: '/dev/raw/raw34'
ORA-00210: cannot open the specified control file
ORA-00202: control file: '/dev/raw/raw33'
ORA-27086: unable to lock file - already in use
Linux-x86_64 Error: 11: Resource temporarily unavailable
Additional information: 8
Additional information: 29924
ORA-00210: cannot open the specified control file
ORA-00202: control file: '/dev/raw/raw32'
ORA-27086: unable to lock file - already in use
Linux-x86_64 Error: 11: Resource temporarily unavailable
Additional information: 8
Additional information: 29924
kcidr_process_controlfile_error:
 IO Check was called but no error was found
ORA-00227: corrupt block detected in control file: (block 1, # blocks 1)
ORA-00202: control file: '/dev/raw/raw34'
ORA-00210: cannot open the specified control file
ORA-00202: control file: '/dev/raw/raw33'
ORA-27086: unable to lock file - already in use
Linux-x86_64 Error: 11: Resource temporarily unavailable
Additional information: 8
Additional information: 29924
ORA-00210: cannot open the specified control file
ORA-00202: control file: '/dev/raw/raw32'
ORA-27086: unable to lock file - already in use
Linux-x86_64 Error: 11: Resource temporarily unavailable
Additional information: 8
Additional information: 29924
</code></pre>
<h2 id="yuan-yin">原因</h2>
<pre><code class="language-shell">oracle@mmsg:~&gt; oerr ora 27086
27086, 00000, "unable to lock file - already in use"
// *Cause:  the file is locked by another process, indicating that it is
//          currently in use by a database instance.
// *Action: determine which database instance legitimately owns this file.
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>修改静默安装数据库使用的raw文件名称与map关系，避免这些raw占用现有环境上的其他raw文件。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--oracle本地磁盘数据文件更改到lv上</title>
    <url>/2011/08/31/oracle_change_data_files_to_lv/</url>
    <content><![CDATA[<h1 id="oracle-ben-di-ci-pan-shu-ju-wen-jian-geng-gai-dao-lv-shang">oracle本地磁盘数据文件更改到lv上</h1>
<h2 id="bei-jing">背景</h2>
<p>oracle数据库的所有数据文件安装在本地系统盘，现要将所有本地系统盘上的数据文件转移到外挂磁阵lv上。</p>
<h2 id="shi-xian-guo-cheng">实现过程</h2>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这里仅以一个本地永久数据文件转移到lv上为示例。</p>
</li>
</ul>
<h3 id="bu-zou-yi-chuang-jian-ce-shi-biao-kong-jian">步骤一、创建测试表空间</h3>
<h4 id="ben-di-shu-ju-wen-jian">本地数据文件</h4>
<pre><code class="language-shell">SQL&gt; create tablespace wyztest datafile '/opt/oracle/oradata/mmsgdb/wyztest.dbf' size 50M;   

表空间已创建。
</code></pre>
<h3 id="bu-zou-er-chuang-jian-yong-hu-biao-bing-cha-ru-shu-ju-ji-lu">步骤二、创建用户表，并插入数据记录</h3>
<h4 id="chuang-jian-yong-hu-bing-shou-quan">创建用户并授权</h4>
<pre><code class="language-shell">SQL&gt; create user test identified by test  
  2  default tablespace wyztest 
  3  profile default;

用户已创建。

SQL&gt; grant create table to test;

授权成功。

SQL&gt; grant create session to test;

授权成功。

SQL&gt; grant resource to test; 

授权成功。

SQL&gt; grant unlimited tablespace to test;

授权成功。

SQL&gt; commit;

提交完成。

SQL&gt; exit
</code></pre>
<p>从 Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开</p>
<h4 id="chuang-jian-yong-hu-biao-bing-cha-ru-liang-tiao-ji-lu">创建用户表，并插入两条记录</h4>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus test/test@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期三 8月 31 12:11:17 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; show user
USER 为 "TEST"
SQL&gt; create table modules (id integer not null);

表已创建。

SQL&gt; insert into modules values(1);

已创建 1 行。

SQL&gt; insert into modules values(2);

已创建 1 行。

SQL&gt; commit;

提交完成。

SQL&gt; select * from modules;        #表中数据有两条记录，用于迁移后检查数据是否有丢失

        ID
----------
         1
         2

SQL&gt; exit
</code></pre>
<h3 id="bu-zou-san-chuang-jian-lv-xiu-gai-lv-shu-zhu-wei-oracle">步骤三、创建lv，修改lv属主为oracle</h3>
<h4 id="chuang-jian-lv">创建lv</h4>
<pre><code class="language-shell">mmsc103:/opt/oracle # lvcreate -L 290M -n oratest vg_dlsc_uoa
  Rounding up size to full physical extent 292.00 MB
  Logical volume "oratest" created
</code></pre>
<h4 id="xiu-gai-lv-shu-zhu-xin-xi">修改lv属主信息</h4>
<pre><code class="language-shell">mmsc103:/opt/oracle # cd /dev
mmsc103:/dev # chown -R oracle.oinstall vg_dlsc_uoa
mmsc103:/dev # chown -R oracle.oinstall vg_dlsc_uoa/*
mmsc103:/dev/vg_dlsc_uoa # ls -l
total 0
lrwxrwxrwx 1 oracle oinstall 35 Aug 31 11:41 lv_dlsc_uoa -&gt; /dev/mapper/vg_dlsc_uoa-lv_dlsc_uoa
lrwxrwxrwx 1 oracle oinstall 31 Aug 31 12:16 oratest -&gt; /dev/mapper/vg_dlsc_uoa-oratest
mmsc103:~ # cd /dev/mapper/
mmsc103:/dev/mapper # ls -l
total 0
lrwxrwxrwx 1 root root     16 Aug 31  2011 control -&gt; ../device-mapper
brw------- 1 root root 253, 0 Aug 31 11:41 vg_dlsc_uoa-lv_dlsc_uoa
brw------- 1 root root 253, 1 Aug 31 12:16 vg_dlsc_uoa-oratest
mmsc103:/dev/mapper # chown -R oracle.oinstall vg_dlsc_uoa-oratest
mmsc103:/dev/mapper # 
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>父目录、目录下文件以及mapper文件的属主都要修改，否则rman操作会报权限不足（Permission denied）</p>
</li>
</ul>
<h3 id="bu-zou-si-mount-zhuang-tai-xia-kao-bei-ben-di-wen-jian-dao-lv-shang">步骤四、mount状态下拷贝本地文件到lv上</h3>
<h4 id="guan-bi-shu-ju-ku">关闭数据库</h4>
<pre><code class="language-shell">SQL&gt; shutdown immediate
数据库已经关闭。
已经卸载数据库。
ORACLE 例程已经关闭。
</code></pre>
<h4 id="qi-dong-shu-ju-ku-dao-mount-zhuang-tai">启动数据库到mount状态</h4>
<pre><code class="language-shell">SQL&gt; startup mount
ORACLE 例程已经启动。

Total System Global Area 1603411968 bytes
Fixed Size                  2144824 bytes
Variable Size            1124074952 bytes
Database Buffers          469762048 bytes
Redo Buffers                7430144 bytes
数据库装载完毕。
SQL&gt; exit
</code></pre>
<p>从 Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开</p>
<h4 id="fu-zhi-ben-di-shu-ju-wen-jian-dao-lv-shang">复制本地数据文件到lv上</h4>
<pre><code class="language-shell">oracle@mmsc103:~&gt; rman target/

恢复管理器: Release 11.1.0.6.0 - Production on 星期三 8月 31 11:45:14 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

已连接到目标数据库: MMSGDB (DBID=3157020426, 未打开)

RMAN&gt; copy datafile '/opt/oracle/oradata/mmsgdb/wyztest.dbf' to '/dev/vg_dlsc_uoa/oratest';

启动 backup 于 31-8月 -11
使用目标数据库控制文件替代恢复目录
分配的通道: ORA_DISK_1
通道 ORA_DISK_1: SID=316 设备类型=DISK
通道 ORA_DISK_1: 启动数据文件副本
输入数据文件: 文件号=00013 名称=/opt/oracle/oradata/mmsgdb/wyztest.dbf
输出文件名=/dev/vg_dlsc_uoa/oratest 标记=TAG20110831T115029 RECID=1 STAMP=760621832
通道 ORA_DISK_1: 数据文件复制完毕, 经过时间: 00:00:01
完成 backup 于 31-8月 -11

RMAN&gt; quit
</code></pre>
<h3 id="bu-zou-wu-xiu-gai-kong-zhi-wen-jian-bing-open-shu-ju-ku">步骤五、修改控制文件并open数据库</h3>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on 星期三 8月 31 11:50:50 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; alter database rename file '/opt/oracle/oradata/mmsgdb/wyztest.dbf' to '/dev/vg_dlsc_uoa/oratest';     

数据库已更改。

SQL&gt; alter database open;

数据库已更改。
</code></pre>
<h3 id="bu-zou-liu-cha-kan-qian-yi-jie-guo">步骤六、查看迁移结果</h3>
<pre><code class="language-shell">SQL&gt; select FILE_NAME from dba_data_files where TABLESPACE_NAME ='WYZTEST';

FILE_NAME
--------------------------------------------------------------------------------
/dev/vg_dlsc_uoa/oratest     #路径已经不是本地路径（/opt/oracle/oradata/mmsgdb）了

SQL&gt; quit 
从 Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options 断开
</code></pre>
<h4 id="cha-kan-qian-hou-hou-biao-zhong-shu-ju-ji-lu">查看前后后表中数据记录</h4>
<pre><code class="language-shell">oracle@mmsc103:~&gt; sqlplus test/test@mmsgdb

SQL*Plus: Release 11.1.0.6.0 - Production on 星期三 8月 31 12:21:50 2011

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


连接到: 
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; select * from modules;

        ID
----------
         1
         2

SQL&gt; 
</code></pre>
<p>此时看到，两条记录，数据都在。</p>
<h3 id="bu-zou-qi-huan-jing-qing-li-ke-xuan">步骤七、环境清理（可选）</h3>
<p>可以删除本地路径下的原迁移前的数据文件，可选操作。</p>
<h2 id="fu-lu">附录</h2>
<h3 id="bian-geng-yong-jiu-shu-ju-wen-jian-wei-zhi-bu-zou">变更永久数据文件位置步骤</h3>
<p>1、db处于mount状态；</p>
<p>2、mv或者cp操作，将文件拷贝到指定位置；</p>
<p>3、修改控制文件：alter database rename file ‘xxxx’ to ‘xxxxxxx’;</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>永久数据文件包括：</p>
</li>
</ul>
<pre><code class="language-shell">select file_name from dba_data_files;
system01.dbf 
sysaux01.dbf 
undotbs01.dbf
users01.dbf

select member from v$logfile;
redo01.log
redo02.log
redo03.log
</code></pre>
<h3 id="bian-geng-lin-shi-wen-jian-wei-zhi">变更临时文件位置</h3>
<p>由于临时文件不存放数据，可以将原先临时文件drop掉，并重新创建在lv上既可。</p>
<pre><code class="language-shell">select file_name from dba_temp_files;
temp01.dbf
</code></pre>
<h3 id="bian-geng-kong-zhi-wen-jian-wei-zhi">变更控制文件位置</h3>
<pre><code class="language-shell">select * from v$controlfile;
control01.ctl
control02.ctl
control03.ctl
</code></pre>
<p>由于控制文件比较特殊，并没有想到好方法，思路如下：</p>
<p>1、在lv上新增控制文件（建议数量为3个）；</p>
<p>2、创建pfile文件，修改控制文件路径信息为lv上的控制文件；</p>
<p>3、使用pfile创建spfile，并启动数据库</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>oracle自11gR2版本开始，控制文件数默认不再是三个，而是两个。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-01113</title>
    <url>/2011/09/24/oracle_troubleshoot_ora_01113/</url>
    <content><![CDATA[<h1 id="ora-01113-wen-jian-xu-yao-jie-zhi-hui-fu">ORA-01113 文件需要介质恢复</h1>
<h2 id="biao-xiang">表象</h2>
<pre><code class="language-shell">SQL&gt; startup
ORACLE instance started.

Total System Global Area 8351150080 bytes
Fixed Size                  2176320 bytes
Variable Size            4580182720 bytes
Database Buffers         3758096384 bytes
Redo Buffers               10694656 bytes
Database mounted.
ORA-01113: 文件 17 需要介质恢复
ORA-01110: 数据文件 17: '/home/oracle/dls_tbs_idx.dbf'
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<pre><code class="language-shell">oracle@linux25:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on 星期六 9月 24 17:43:45 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, Oracle Label Security, OLAP, Data Mining,
Oracle Database Vault and Real Application Testing options

SQL&gt; recover datafile '/home/oracle/dls_tbs_idx.dbf';
Media recovery complete.
SQL&gt; alter database open;

Database altered.

SQL&gt; 
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例之监听</title>
    <url>/2011/10/08/oracle_troubleshooting_of_listener/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>listener，主要用来监听客户端向数据库服务器端提出的连接请求，是基于服务器端的服务，那么它也只存在于数据库服务器端，进行监听器的设置也是在数据库服务器端完成的。</p>
<p>要排除客户端与服务器端的连接问题，首先检查客户端配置是否正确(客户端配置必须与数据库服务器端监听配置一致)，再根据错误提示解决。本文主要介绍在使用oracle过程中，碰到的一些监听故障/问题的记录/汇总。</p>
<h1 id="ora-12541-tns-mei-you-jian-ting-qi">ORA-12541: TNS: 没有监听器</h1>
<p>显而易见，服务器端的监听器没有启动，另外检查客户端IP地址或端口填写是否正确。启动监听器：</p>
<pre><code class="language-shell">$ lsnrctl start
</code></pre>
<h1 id="ora-12500-tns-jian-ting-cheng-xu-wu-fa-qi-dong-zhuan-yong-fu-wu-qi-jin-cheng">ORA-12500: TNS: 监听程序无法启动专用服务器进程</h1>
<p>没有启动Oracle实例服务。启动实例服务。</p>
<h1 id="ora-12535-tns-cao-zuo-chao-shi">ORA-12535: TNS: 操作超时</h1>
<pre><code class="language-shell">TNS-12154 (ORA-12154)：TNS:could not resolve service name
</code></pre>
<p>检查输入的服务名与配置的服务名是否一致。另外注意生成的本地服务名文件(Linux/Unix下$ORACLE_HOME/network/admin/tnsnames.ora)里每项服务的首行服务名称前不能有空格。</p>
<h1 id="ora-12514-tns-jian-ting-jin-cheng-bu-neng-jie-xi-zai-lian-jie-miao-shu-fu-zhong-gei-chu-de-service-name">ORA-12514: TNS: 监听进程不能解析在连接描述符中给出的 SERVICE_NAME</h1>
<p>检查tnsnames.ora里的服务名输入是否正确。该服务名必须与服务器端监听器配置的全局数据库名一致。</p>
<h1 id="ora-12514-tns-jian-ting-cheng-xu-dang-qian-wu-fa-shi-bie-lian-jie-miao-shu-fu-zhong-qing-qiu-de-fu-wu">ORA-12514:TNS:：监听程序当前无法识别连接描述符中请求的服务</h1>
<p>现象：</p>
<p>（1）在服务端和客户端使用sqlplus user/password@SID均无法连接</p>
<p>（2）在服务端使用sqlplus user/password@SID可以建立连接，客户端使用使用sqlplus user/password@SID无法建立连接。</p>
<p>解决：</p>
<p>（方法1）检查listener.ora以及tnsnames.ora文件。主要是检查文件中的HOST是否为</p>
<p>当前主机名（hostname），如果不是，修改成当前主机名（hostname）或IP地址；</p>
<p>（方法2）在listener.ora文件中添加SID_LIST_LISTENER信息。</p>
<p>创建监听错误</p>
<img class="shadow" src="/img/in-post/oracle-listener-create-error.png" widtgh="1200">
<p>这个问题的解决方法如下：</p>
<p>在ORACLE_HOME/network/admin/listener.ora文件中增加"SID_LIST_LISTENER = "这部分内容。</p>
<pre><code class="language-shell">LISTENER =
  (DESCRIPTION_LIST =
    (DESCRIPTION =
      (ADDRESS = (PROTOCOL = TCP)(HOST=10.164.75.167)(PORT = 1521))
    )
  )
SID_LIST_LISTENER =
    (SID_DESC =
      (GLOBAL_DBNAME = ora11g)       //ora11g是数据库实例名
      (ORACLE_HOME = /opt/oracle/app/product/11.1.0/db_1)    //oracle家目录
      (SID_NAME = ora11g)           
    )
  )
</code></pre>
<p>注：</p>
<p>Oracle System Identifier (SID)</p>
<pre><code class="language-shell">A name that identifies a specific instance of a running pre-release 8.1 Oracle
database. For any database, there is at least one instance referencing the database.
For pre-release 8.1 databases, SID is used to identify the database. The SID is
included in the connect descriptor of a tnsnames.ora file and in the definition of the
listener in the listener.ora file.
</code></pre>
<p>如果SID值不作人为的修改，该值默认为PLSExtProc，且完全可以正常运行（目前141  上的数据库该值就是PLSExtProc）。因此我觉得可能是如果不指定SID值的话，oracle会自动地去搜索运行的实例，然后找出一个匹配的，但是如果直接指定SID，则省去了搜索的步骤，也就加快了连接速度。不过这种猜想目前尚未得到证实，如果大家对这方面了解的话，希望不吝赐教。</p>
<h1 id="qi-dong-jian-ting-shi-chu-cuo-12514">启动监听时出错 – 12514</h1>
<p>正确创建监听后，启动监听时监听启动异常，报12514错误。</p>
<pre><code class="language-shell">oerr ora 12514
12514, 00000, "TNS:listener does not currently know of service requested in connect descriptor"
// *Cause:  The listener received a request to establish a connection to a
// database or other service. The connect descriptor received by the listener
// specified a service name for a service (usually a database service)
// that either has not yet dynamically registered with the listener or has
// not been statically configured for the listener.  This may be a temporary
// condition such as after the listener has started, but before the database
// instance has registered with the listener.
// *Action:
//  - Wait a moment and try to connect a second time.
//  - Check which services are currently known by the listener by executing:
//    lsnrctl services &lt;listener name&gt;
//  - Check that the SERVICE_NAME parameter in the connect descriptor of the
//    net service name used specifies a service known by the listener.
//  - If an easy connect naming connect identifier was used, check that
//    the service name specified is a service known by the listener.
//  - Check for an event in the listener.log file.
</code></pre>
<p>解决方法同上。</p>
<p>如果出现TNS错误时，有可能是因为没有加载数据库实例，加载方法如下：</p>
<p>在SQL/PLUS中输入startup force，强制加载数据库实例。</p>
<h1 id="oracle-shu-ju-ku-jian-ting-qi-dong-shi-bai-bao-00525-12560-deng-cuo-de-jie-jue-fang-fa">oracle数据库监听启动失败，报00525，12560等错的解决方法</h1>
<p>启动数据库监听，报如下警告：</p>
<pre><code class="language-shell">LSNRCTL&gt; start
Starting /opt/oracle/product/11g//bin/tnslsnr: please wait...
TNSLSNR for Linux: Version 11.1.0.7.0 - Production
System parameter file is /opt/oracle/product/11g//network/admin/listener.ora
Log messages written to /opt/oracle/diag/tnslsnr/RAC2/listener/alert/log.xml
Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=RAC2)(PORT=1521)))
Error listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))
TNS-12555: TNS:permission denied
 TNS-12560: TNS:protocol adapter error
  TNS-00525: Insufficient privilege for operation
   Linux Error: 1: Operation not permitted
Listener failed to start. See the error message(s) above...
</code></pre>
<p>原因分析</p>
<p>TCP监听正常，IPC监听失败，由TNS-12555和TNS-12560错误确定是IPC协议出错，由TNS-00525确定是权限不足，查看/tmp/.oracle目录下无内容，可以确定是因为某种原因，oracle不能在该目录下生成IPC监听的KEY值，导致IPC监听失败.</p>
<p>解决方法</p>
<p>将ICP监听取消，将 (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521))这句话注释掉不使用，可以暂时解决该问题。可以使数据库作为客户端来使用</p>
<p>方法二：</p>
<p>修改如下文件夹的权限</p>
<pre><code class="language-shell">/tmp/.oracle的权限 
/var/tmp/.oracle的权限 
</code></pre>
<p>oracle应该有这些目录的权限，用oinstall</p>
<pre><code class="language-shell">chown -R  oracle:oinstall /tmp/.oracle 
chown -R  oracle:oinstall /var/tmp/.oracle 
</code></pre>
<h1 id="aix-xia-jian-ting-wu-fa-ting-zhi">AIX下监听无法停止</h1>
<p>AIX下ORACLE11G（版本：Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production）监听停止、启动失败</p>
<p>表象:</p>
<p>停止监听</p>
<pre><code class="language-shell">% lsnrctl stop
LSNRCTL for IBM/AIX RISC System/6000: Version 11.1.0.6.0 - Production on 17-6月 -2009 19:22:34
Copyright (c) 1991, 2007, Oracle.  All rights reserved.
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=infox2)(PORT=1521)))
TNS-01190: The user is not authorized to execute the requested listener command
</code></pre>
<p>启动监听</p>
<pre><code class="language-shell">% lsnrctl start
LSNRCTL for IBM/AIX RISC System/6000: Version 11.1.0.6.0 - Production on 17-6月 -2009 19:51:21
Copyright (c) 1991, 2007, Oracle.  All rights reserved.
Starting /opt/oracle/app/product/11.1.0/db_1/bin/tnslsnr: please wait...
TNSLSNR for IBM/AIX RISC System/6000: Version 11.1.0.6.0 - Production
System parameter file is /opt/oracle/app/product/11.1.0/db_1/network/admin/listener.ora
Log messages written to /opt/oracle/app/diag/tnslsnr/infox2/listener/alert/log.xml
Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=infox2)(PORT=1521)))
Error listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))
TNS-12555: TNS:permission denied
 TNS-12560: TNS:protocol adapter error
  TNS-00525: Insufficient privilege for operation
   IBM/AIX RISC System/6000 Error: 1: Not owner
Listener failed to start. See the error message(s) above...
</code></pre>
<p>解决方法</p>
<p>修改ORACLE_HOME目录下lintener.ora文件，例如修改为：</p>
<pre><code class="language-shell">LISTENER =
  (DESCRIPTION_LIST =
    (DESCRIPTION =
      (ADDRESS = (PROTOCOL = TCP)(HOST=10.164.75.22)(PORT = 1521))
    )
  )
  
SID_LIST_LISTENER =
    (SID_DESC =
      (GLOBAL_DBNAME = smsgrpt)       //实例名
      (ORACLE_HOME = /opt/oracle/app/product/11.1.0/db_1)   // ORACLE_HOME 目录路径
      (SID_NAME = smsgrpt)           
    )
  )
</code></pre>
<p>注：<br>
oracle版本为Version 11.1.0.6.0的，几乎都会遇见上述监听相关问题，解决方法一般都是增加SID信息。</p>
<h1 id="jie-yu">结语</h1>
<p>当不得已而为之的时候，删除监听，重新建立一个监听。</p>
<p>测试tns的时候，可以通过tnsping 来进行。</p>
<p>在服务器测试，示例如下：</p>
<pre><code class="language-shell">tnsping mmsgdb（这里的mmsgdb是数据库的实例名） 
</code></pre>
<p>客户端测试如下：</p>
<pre><code class="language-shell">tnsping 10.164.75.220/mmsgdb
</code></pre>
<p>以上是Oracle客户端连接服务器端常见的一些问题，当然不能囊括所有的连接异常。解决问题的关键在于方法与思路，而不是每种问题都有固定的答案。</p>
<h1 id="tns-01189-an-li">TNS-01189案例</h1>
<p>表象:</p>
<pre><code class="language-shell">oracle@mmsg01:~/product/11g/network/admin&gt; lsnrctl status

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 31-3?? -2010 18:09:47

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

?y?úá??óμ? (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=mmsg01)(PORT=1521)))
TNS-01189: 监听程序无法验证用户
oracle@mmsg01:~/product/11g/network/admin&gt; lsnrctl stop  

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 31-3?? -2010 18:09:50

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

?y?úá??óμ? (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=mmsg01)(PORT=1521)))
TNS-01189: 监听程序无法验证用户
oracle@mmsg01:~/product/11g/network/admin&gt; lsnrctl start

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 31-3?? -2010 18:09:51

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

TNS-01106: 00106 使用名称LISTENER的监听程序已经启动
oracle@mmsg01:~/product/11g/network/admin&gt;
</code></pre>
<p>原因</p>
<p>解析主机名出错。</p>
<p>主机名为mmsg01，而在/etc/hosts文件中，虽然找到了主机名为mmsg01的记录，但是ifconfig观察之后，发现小网段（192网段）显示的IP信息与/etc/hosts文件中不一致，且/etc/hosts文件中缺少外网段（10网段）的记录。</p>
<p>解决方法</p>
<p>修改/etc/hosts文件，增加小网段和外网段信息，例如：</p>
<pre><code class="language-shell">192.168.100.106 mmsg01
10.164.75.102    mmsg01
</code></pre>
<h1 id="ji-qi-geng-huan-ip-hou-jian-ting-qi-dong-shi-bai">机器更换IP后监听启动失败</h1>
<p>日志</p>
<pre><code class="language-shell">&lt;msg time='2010-04-20T09:56:43.897+08:00' org_id='oracle' comp_id='tnslsnr'
 type='UNKNOWN' level='16' host_id='mmsg'
 host_addr='10.164.74.222'&gt;
 &lt;txt&gt;以 pid=14276 开始
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2010-04-20T09:56:43.898+08:00' org_id='oracle' comp_id='tnslsnr'
 type='UNKNOWN' level='16' host_id='mmsg'
 host_addr='10.164.74.222'&gt;
 &lt;txt&gt;监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.114)(PORT=1521)))
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2010-04-20T09:56:43.898+08:00' org_id='oracle' comp_id='tnslsnr'
 type='UNKNOWN' level='16' host_id='mmsg'
 host_addr='10.164.74.222'&gt;
 &lt;txt&gt;监听: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2010-04-20T09:56:44.011+08:00' org_id='oracle' comp_id='tnslsnr'
 type='UNKNOWN' level='16' host_id='mmsg'
 host_addr='10.164.74.222'&gt;
 &lt;txt&gt;Listener completed notification to CRS on start
 &lt;/txt&gt;
&lt;/msg&gt;
&lt;msg time='2010-04-20T09:56:44.018+08:00' org_id='oracle' comp_id='tnslsnr'
 type='UNKNOWN' level='16' host_id='mmsg'
 host_addr='10.164.74.222'&gt;
 &lt;txt&gt;
TIMESTAMP * CONNECT DATA [* PROTOCOL INFO] * EVENT [* SID] * RETURN CODE
 &lt;/txt&gt;
&lt;/msg&gt;
</code></pre>
<p>原因</p>
<p>机器IP更改，导致监听读取lintener.ora文件中HOST失败</p>
<p>解决</p>
<p>修改lintener.ora中host为当前机器IP地址；</p>
<p>修改/etc/host文件，将该文件中的IP地址更换成当前的IP地址（即变化后的IP地址）；</p>
<p>如上修改后重新启动监听</p>
<h1 id="ting-zhi-jian-ting-bao-tns-01190">停止监听报TNS-01190</h1>
<p>表象</p>
<pre><code class="language-shell">oracle@mmsg1:~&gt; lsnrctl stop

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 11-8月 -2010 08:49:50

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.167)(PORT=1521)))
TNS-01190: 用户无权执行所请求的监听程序命令
</code></pre>
<p>原因</p>
<p>Oracle用户未设置监听密码等信息，导致其他用户停止了oracle的监听，并重新启动了监听。</p>
<pre><code class="language-shell">oracle@mmsg1:~/product/11g/network/admin&gt; ps -ef | grep oracle
oracle   26896 25801  0 Aug10 pts/2    00:00:00 su oracle
oracle   26897 26896  0 Aug10 pts/2    00:00:00 bash
oracle   26915 26897  0 Aug10 pts/2    00:00:00 bash
oracle   26930 26915  0 Aug10 pts/2    00:00:00 -sh
syc      27829     1  0 Aug10 ?        00:00:00 /opt/oracle/product/11g/bin/tnslsnr LISTENER -inherit
root      9623  9622  0 08:48 ?        00:00:00 login -- oracle              
oracle    9624  9623  0 08:48 pts/1    00:00:00 -bash
oracle    9762  9624  0 08:55 pts/1    00:00:00 ps -ef
oracle    9763  9624  0 08:55 pts/1    00:00:00 grep oracle
</code></pre>
<p>解决方法</p>
<p>root用户kill掉相关进程id，oracle用户重新启动linstner，并设置监听密码，防止非oracle用户远程启动、停止监听。</p>
<h1 id="tns-01201-an-li-listener-cannot-find-executable">TNS-01201案例Listener cannot find executable</h1>
<p>表象</p>
<p>启动监听时候，报TNS-01201错</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11g/network/admin&gt; lsnrctl start

LSNRCTL for Linux: Version 11.1.0.6.0 - Production on 08-OCT-2011 15:38:38

Copyright (c) 1991, 2007, Oracle.  All rights reserved.

Starting /opt/oracle/product/11g/bin/tnslsnr: please wait...

TNSLSNR for Linux: Version 11.1.0.6.0 - Production
System parameter file is /opt/oracle/product/11g/network/admin/listener.ora
Log messages written to /opt/oracle/diag/tnslsnr/mmsc101/listener/alert/log.xml
Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.137.73.5)(PORT=1521)))
TNS-01201: Listener cannot find executable /home/oracle/product/11g/bin/oracle for SID sdp

Listener failed to start. See the error message(s) above...
</code></pre>
<p>解决过程</p>
<p>1、查询错误码信息</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11g/network/admin&gt; oerr TNS 01201
01201, 00000, "Listener cannot find executable %s for SID %s"
// *Cause:  The executable for the Oracle dedicated server process cannot be
// found.
// *Action: Check the appropriate SID_DESC in LISTENER.ORA to make sure that
// the ORACLE_HOME component is pointing to a valid location. If this component
// is not set, then check the value of the ORACLE_HOME environment variable.
// *Comment: This error is reported only on UNIX platforms.
oracle@mmsc101:~/product/11g/network/admin&gt; 
</code></pre>
<p>2、确定一下当前ORACLE_HOME目录</p>
<pre><code class="language-shell">oracle@mmsc101:~&gt; echo  $ORACLE_HOME
/opt/oracle/product/11g
</code></pre>
<p>3、 检查下监听配置文件</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11g/bin&gt; more  /opt/oracle/product/11g/network/admin/listener.ora
# listener.ora Network Configuration File: /home/oracle/product/11g/network/admin/listener.ora
# Generated by Oracle configuration tools.

LISTENER =
  (DESCRIPTION_LIST =
    (DESCRIPTION =
      (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.73.5)(PORT = 1521))
    )
  )
SID_LIST_LISTENER =
    (SID_DESC =
      (GLOBAL_DBNAME = sdp)
      (ORACLE_HOME = /home/oracle/product/11g)
      (SID_NAME = sdp)
    )
  )

                      
SID_LIST_LISTENER_RM =
(SID_LIST =
        (SID_DESC =
                (ORACLE_HOME = /opt/oracle/product/11g)
                (SID_NAME= sdp)
                (GLOBAL_DBNAME=sdp)
        )
)

LISTENER_RM =
(
        DESCRIPTION =
          (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.73.5)(PORT = 1523))
)
</code></pre>
<p>发现监听文件中SID_LIST_LISTENER配置ORACLE_HOME为/home/oracle/product/11g，与实际不符，进行修改。</p>
<p>4、修改监听配置文件</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11g/bin&gt; 


oracle@mmsc101:~/product/11g/network/admin&gt; vi listener.ora 

# listener.ora Network Configuration File: /home/oracle/product/11g/network/admin/listener.ora
# Generated by Oracle configuration tools.

LISTENER =
  (DESCRIPTION_LIST =
    (DESCRIPTION =
      (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.73.5)(PORT = 1521))
    )
  )
SID_LIST_LISTENER =
    (SID_DESC =
      (GLOBAL_DBNAME = sdp)
      (ORACLE_HOME = /opt/oracle/product/11g)
      (SID_NAME = sdp)
    )
  )



SID_LIST_LISTENER_RM =
(SID_LIST =
        (SID_DESC =
                (ORACLE_HOME = /opt/oracle/product/11g)
                (SID_NAME= sdp)
                (GLOBAL_DBNAME=sdp)
        )
)

LISTENER_RM =
(
        DESCRIPTION =
          (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.73.5)(PORT = 1523))
)
</code></pre>
<p>5、报错后启动监听</p>
<pre><code class="language-shell">oracle@mmsc101:~/product/11g/network/admin&gt; lsnrctl start

LSNRCTL for Linux: Version 11.1.0.6.0 - Production on 08-OCT-2011 15:42:42

Copyright (c) 1991, 2007, Oracle.  All rights reserved.

Starting /opt/oracle/product/11g/bin/tnslsnr: please wait...

TNSLSNR for Linux: Version 11.1.0.6.0 - Production
System parameter file is /opt/oracle/product/11g/network/admin/listener.ora
Log messages written to /opt/oracle/diag/tnslsnr/mmsc101/listener/alert/log.xml
Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.137.73.5)(PORT=1521)))

Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.73.5)(PORT=1521)))
STATUS of the LISTENER
------------------------
Alias                     LISTENER
Version                   TNSLSNR for Linux: Version 11.1.0.6.0 - Production
Start Date                08-OCT-2011 15:42:42
Uptime                    0 days 0 hr. 0 min. 0 sec
Trace Level               off
Security                  ON: Local OS Authentication
SNMP                      OFF
Listener Parameter File   /opt/oracle/product/11g/network/admin/listener.ora
Listener Log File         /opt/oracle/diag/tnslsnr/mmsc101/listener/alert/log.xml
Listening Endpoints Summary...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.137.73.5)(PORT=1521)))
Services Summary...
Service "sdp" has 1 instance(s).
  Instance "sdp", status UNKNOWN, has 1 handler(s) for this service...
The command completed successfully
oracle@mmsc101:~/product/11g/network/admin&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--错误码之ORA-21561</title>
    <url>/2011/11/07/oracle_troubleshoot_ora_21561/</url>
    <content><![CDATA[<h1 id="ora-21561-oid-generation-failed-an-li">ORA-21561  OID generation failed 案例</h1>
<h2 id="wen-ti">问题</h2>
<p>AIX平台，创建oracle数据库实例时，报ORA-21561 OID创建失败</p>
<h2 id="jie-jue">解决</h2>
<p>修改 <code>/etc/hosts</code> 文件，添加本机IP与机器名。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>修改oracle字符集(汉字显示为乱码)</title>
    <url>/2011/11/20/oracle_modify_lang/</url>
    <content><![CDATA[<h1 id="biao-xiang">表象</h1>
<p>数据库中汉字显示为乱码</p>
<h1 id="yuan-yin">原因</h1>
<p>安装数据库时，如果字符集选择错误，会导致汉字显示为乱码。</p>
<pre><code class="language-shell">SQL&gt; select value$ from props$ where  name='NLS_LANGUAGE' or     name='NLS_TERRITORY' or     name='NLS_CHARACTERSET';

VALUE$
--------------------------------------------------------------------------------
SIMPLIFIED CHINESE
CHINA
WE8MSWIN1252
</code></pre>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>在dbca中以现成的模板General Purpose（一般都是选这个模板）创建的databae，其字符集默认是 WE8ISO8859P1 ，并且在dbca中没有找到修改字符集设置的地方。WE8ISO8859P1是无法显示和处理中文的。</p>
<p>操作如下：</p>
<pre><code class="language-shell">以sqlplus "/as sysdba"登录，执行如下更新：

update sys.props$ set VALUE$='ZHS16GBK' where name='NLS_CHARACTERSET';
</code></pre>
<p>查看更新后的值：</p>
<pre><code class="language-shell">select * from sys.props$ where NAME='NLS_CHARACTERSET';
</code></pre>
<p>此属性重启数据库后生效，如果已经执行了应用脚本，请重新执行应用脚本，这样才不会出现乱码。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--Oracle已启动，dba连接报空闲实例</title>
    <url>/2011/11/25/oracle_troubleshoot_of_idle_instance/</url>
    <content><![CDATA[<h1 id="oracle-yi-qi-dong-dba-lian-jie-bao-kong-xian-shi-li">Oracle已启动，dba连接报空闲实例</h1>
<h2 id="biao-xiang">表象</h2>
<p>Oracle服务的启动是VCS5.1启动的，VCS启动日志中显示数据库已经成功启动，且双机运行正常，但是，使用dba用户连接数据库时，报连接到空闲实例，如下：</p>
<pre><code class="language-shell">oracle@dlsc01:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Fri Nov 25 09:31:17 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.

Connected to an idle instance.

SQL&gt;
</code></pre>
<p>查看oracle进程，进程存在，且正常</p>
<pre><code class="language-shell">oracle@dlsc01:~&gt; ps -ef | grep oracle
oracle     301     1  0 Nov18 ?        00:00:03 ora_dbw0_dlscdb
oracle     305     1  0 Nov18 ?        00:00:09 ora_lgwr_dlscdb
oracle     309     1  0 Nov18 ?        00:00:49 ora_ckpt_dlscdb
oracle     313     1  0 Nov18 ?        00:00:03 ora_smon_dlscdb
oracle     317     1  0 Nov18 ?        00:00:00 ora_reco_dlscdb
oracle     321     1  0 Nov18 ?        00:00:07 ora_mmon_dlscdb
oracle     325     1  0 Nov18 ?        00:00:00 ora_mmnl_dlscdb
oracle     387     1  0 Nov18 ?        00:00:01 ora_arc0_dlscdb
oracle     391     1  0 Nov18 ?        00:00:07 ora_arc1_dlscdb
oracle     395     1  0 Nov18 ?        00:00:01 ora_arc2_dlscdb
oracle     399     1  0 Nov18 ?        00:00:00 ora_arc3_dlscdb
oracle     403     1  0 Nov18 ?        00:00:00 ora_fbda_dlscdb
oracle     411     1  0 Nov18 ?        00:00:00 ora_qmnc_dlscdb
oracle     458     1  0 Nov18 ?        00:00:01 /home/oracle/product/11g/bin/tnslsnr LISTENER -inherit
oracle     465     1  0 Nov18 ?        00:11:44 ora_cjq0_dlscdb
oracle     659     1  0 Nov18 ?        00:00:00 ora_q000_dlscdb
oracle     663     1  0 Nov18 ?        00:00:00 ora_q001_dlscdb
oracle    2045     1  0 Nov18 ?        00:00:00 ora_smco_dlscdb
oracle   17630     1  0 09:25 ?        00:00:00 ora_w000_dlscdb
root     18771 18770  0 09:30 ?        00:00:00 login -- oracle              
oracle   18772 18771  0 09:30 pts/2    00:00:00 -bash
oracle   19150 18772  0 09:31 pts/2    00:00:00 sqlplus   as sysdba
oracle   19153 19150  0 09:31 ?        00:00:00 oracledlscdb (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))
oracle   19242     1  0 09:32 ?        00:00:00 ora_j000_dlscdb
oracle   19370 19150  0 09:32 pts/2    00:00:00 /bin/bash
oracle   19385 19370  0 09:32 pts/2    00:00:00 ps -ef
oracle   19386 19370  0 09:32 pts/2    00:00:00 grep oracle
oracle   32739     1  0 Nov18 ?        00:00:00 ora_pmon_dlscdb
oracle   32743     1  0 Nov18 ?        00:00:00 ora_vktm_dlscdb
oracle   32749     1  0 Nov18 ?        00:00:00 ora_diag_dlscdb
oracle   32753     1  0 Nov18 ?        00:00:00 ora_dbrm_dlscdb
oracle   32757     1  0 Nov18 ?        00:00:00 ora_psp0_dlscdb
oracle   32761     1  0 Nov18 ?        00:00:02 ora_dia0_dlscdb
oracle   32765     1  0 Nov18 ?        00:00:01 ora_mman_dlscdb
</code></pre>
<p>由进程信息，可以看出，数据库的SID为dlscdb，查看环境变量中的sid</p>
<pre><code class="language-shell">oracle@dlsc01:~&gt; echo $ORACLE_SID
dlscdb
</code></pre>
<p>启动的数据库SID与环境变量中的SID一致，数据库为单实例，不存在多实例问题，所以连接异常问题不是SID不一致导致的。</p>
<h2 id="yuan-yin">原因</h2>
<p>Oracle使用的环境变量.profile文件中，设置的ORACLE_HOME中多加了个/</p>
<p><code>export ORACLE_HOME=$ORACLE_BASE/product/11g/ </code></p>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>修改环境变量文件中的.profile文件中的ORACLE_HOM的环境变量，去掉多余的/“”，并source环境变量文件。</p>
<pre><code class="language-shell">oracle@dlsc01:~&gt; source .profile
oracle@dlsc01:~&gt; echo $ORACLE_HOME
/home/oracle/product/11g

oracle@dlsc01:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.7.0 - Production on Fri Nov 25 09:48:07 2011

Copyright (c) 1982, 2008, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.7.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt;
</code></pre>
<p>说明</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>上述现象仅在使用VCS启动数据库时出现，手工启动数据库不出现上述问题。</p>
</li>
<li class="lvl-2">
<p>在oracle环境中，不论资料还是具体的测试环境，对于预设的oracle环境变量，避免在路径末尾加个“/”。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--表空间满，数据库报错(01653,ORA-06512)</title>
    <url>/2011/11/29/oracle_troubleshoot_tablespace_full_ora_01653_ora_06512/</url>
    <content><![CDATA[<h1 id="biao-kong-jian-man-shu-ju-ku-bao-cuo">表空间满，数据库报错</h1>
<h2 id="biao-xiang">表象</h2>
<p>当表空间已经满时，执行数据库操作数据库会报错，例如：</p>
<pre><code class="language-shell">ORA-01653: 表 MMSG.TMP_BASE_RESULT 无法通过 8 (在表空间 MMSG 中) 扩展
ORA-06512: 在 "MMSG.LOG2DB_UTIL", line 92
ORA-06512: 在 line 1
</code></pre>
<h2 id="yuan-yin">原因</h2>
<p>查看错误码信息，如下：</p>
<pre><code class="language-shell">ORA-01653
node1:oracle:mmsgdb &gt; oerr ora 01653
01653, 00000, "unable to extend table %s.%s by %s in tablespace %s"
// *Cause:  Failed to allocate an extent of the required number of blocks for 
//          a table segment in the tablespace indicated.
// *Action: Use ALTER TABLESPACE ADD DATAFILE statement to add one or more
//          files to the tablespace indicated.
node1:oracle:mmsgdb &gt;
</code></pre>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>通过上述错误码给出的原因和解决方法，需要扩展表空间。</p>
<p>扩展操作命令如下：</p>
<pre><code class="language-shell">alter database datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' AUTOEXTEND ON NEXT 50M MAXSIZE UNLIMITED；
</code></pre>
<p>下面的两个命令也可以：</p>
<pre><code class="language-shell">alter tablespace mmsg add datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' size 1024M reuse;
alter database datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' resize 2048M;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--重命名表空间</title>
    <url>/2011/12/05/oracle_troubleshoot_rename_data_files/</url>
    <content><![CDATA[<h1 id="zhong-ming-ming-biao-kong-jian">重命名表空间</h1>
<h2 id="gua-yong-tiao-jian">适用条件</h2>
<p>一般使用于创建表空间时命名随意，后期想使得表空间命名规范化、具有实际意义（读其名而知其意）。</p>
<p><code>alter tablespace old_taplespace_name rename to new_tablespace_name; </code></p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle专有服务器与共享服务器模式</title>
    <url>/2011/12/21/oracle_server_mode/</url>
    <content><![CDATA[<h1 id="ming-ci-jie-shi">名词解释</h1>
<p>专有服务器模式（DEDICATED）：一个客户端连接对应一个服务器进程。</p>
<p>共享服务器模式（SHARE）：多个客户端连接对应一个服务器进程，服务器端存在一个进程调度器来管理。</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>共享服务器模式,必须使用net services.也就是必须配置tns信息（即使客户端与服务端为同一台机器，也要配置TNS,且通过IPC协议进行通讯）。它适合用于高并发，事务量小，如果此时采用了共享模式，可以大大减少由于高度并发对于ORACLE服务器的资源消耗。</p>
</li>
</ul>
<h1 id="mo-shi-shuo-ming">模式说明</h1>
<h2 id="zhuan-you-fu-wu-qi-mo-shi">专有服务器模式</h2>
<p>每次在对Oracle进行访问的时候，Oracle服务器的Listener会得到这个访问请求，然后会为这个访问创建一个新的进程来进行服务。所以说，对于每一个客户端的访问，都会生成一个新的进程进行服务，是一种类似一对一的映射关系。这种连接模式的一个很重要的特点就是UGA（用户全局域）是存储在PGA（进程全局域）中的，这个特性也很好的说明了当前用户的内存空间是按照进程来进行分配的。</p>
<h2 id="gong-xiang-fu-wu-qi-mo-shi">共享服务器模式</h2>
<p>类似一种在程序编写时常用到的连接池（pool）的概念。采用这种模式的话，在数据库的初始化的时候就会创建一批服务器连接的进程，然后把这些连接进程放入一个连接池来进行管理。初始化的池中的进程数量在数据库初始化建立的时候是可以手动设置的。在连接建立的时候，Listener首先接收到客户端的建立连接的请求，然后Listener去生成一个叫做调度器(dipatcher)的进程与客户端进行连接。调度器把客户端的请求放在SGA（系统全局域）的一个请求队列中，然后再共享服务器连接池中查找有无空闲的连接，然后让这个空闲的服务器进行处理。处理完毕以后再把处理结果放在SGA的相应队列中。调度器通过查询相应队列，得到返回结果，再返回给客户端。这种连接模式的优点在于服务器进程的数量可以得到控制，不大可能出现因为连接人数过多而造成服务器内存崩溃。但是由于增加了复杂度以及请求相应队列，性能上有所下降。</p>
<h1 id="you-que-dian-bi-jiao">优缺点比较</h1>
<h2 id="zhuan-you-fu-wu-qi-mo-shi-de-you-que-dian">专有服务器模式的优缺点</h2>
<h3 id="you-dian">优点</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>每个用户都有一个连接，不至于有的应用占着连接造成别的客户的请求给挂起了；</p>
</li>
<li class="lvl-2">
<p>数据库处理性能较高。</p>
</li>
</ul>
<h3 id="que-dian">缺点</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>内存管理上，此种模式随着用户连接数的增加而消耗更多的系统CPU与内存。</p>
</li>
</ul>
<p>因为随着连接数的增加，每增加一个连接，就要分配一份PGA，如果增加10000个连接，那就是10000个PGA要提供，内存很容易吃爆掉,而共享连接方式优点在于连接数.</p>
<h2 id="gong-xiang-fu-wu-qi-mo-shi-you-que-dian">共享服务器模式优缺点</h2>
<h3 id="you-dian-1">优点</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>减少了实例中的进程数</p>
</li>
<li class="lvl-2">
<p>增加了更多并发用户的数量</p>
</li>
<li class="lvl-2">
<p>实现动态负载均衡</p>
</li>
<li class="lvl-2">
<p>减少了空闲服务器进程数量</p>
</li>
<li class="lvl-2">
<p>降低了对内存的使用</p>
</li>
</ul>
<h3 id="que-dian-1">缺点</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>共享服务器的代码路径比专用服务器长，所以它天生就比专用服务器慢；</p>
</li>
<li class="lvl-2">
<p>存在人为死锁的可能，因为它是串行的，只要一个连接阻塞，则该服务器进程上的所有用户都被阻塞，并且极可能死锁；</p>
</li>
<li class="lvl-2">
<p>存在独占事务的可能，因为如果一个会话的事务运行时间过长，它独占共享资源，其它用户只能等待，而专用服务器，每个客户端是一个会话；</p>
</li>
<li class="lvl-2">
<p>共享服务器模式限制了某些数据库特性，例如：不能单独启动和关闭实例，不能进行介质恢复。</p>
</li>
</ul>
<h1 id="gong-xiang-fu-wu-chu-shi-hua-can-shu-de-yi-xie-shuo-ming">共享服务初始化参数的一些说明</h1>
<h2 id="shared-servers">shared_servers</h2>
<p>指定了当instance 启动的时候share_servers启动的数量（可通过shared server process查看），不要将这个参数设置得太大，否者启动数据库instance 的时候就会花更多时间,Oracle启动过后会根据负载来动态调整shared_servers。如果为0，表示数据库没有启动共享服务模式。 这个参数是配置shared server 必须的，而且只有这个参数是必须的。</p>
<p>修改参数：</p>
<pre><code class="language-shell">alter system set shared_servers=1;
</code></pre>
<h2 id="max-shared-servers">max_shared_servers</h2>
<p>ORACLE在同一个时刻最大能够使用的share_servers数量，不要将这个参数设置小于 shared_servers，如果动态修改shared_servers大于max_shared_servers，ORACLE会覆盖max_shared_servers的值，此时你需要修改max_shared_servers，同时也不能大于processes的值。这个参数是为了给占用很大资源操作而设的(批处理)，为了预留一些process 给DBA任务(rman备份)。</p>
<h2 id="shared-server-sesions">shared_server_sesions</h2>
<p>指定了总共允许的的 shared server session 的数量。如果设置了这个参数，那么就不要将这个值超过sessions，如果没有设置这个值，那么只要还有空闲的session,就可以被使用。设置这个值是为专有连接预留 user sessions的。</p>
<h2 id="dispatchers-diao-du-jin-cheng">dispatchers（调度进程</h2>
<p>配置 dispatcher process 。如果不设置这个参数，只要设置了shared_servers，oracle 也会自动设置一个基于tcp协议的dispatcher。还需要查看操作系统支持一个dispatcher能处理多少个connections</p>
<pre><code class="language-shell">SQL&gt; select * from v$dispatcher;
</code></pre>
<h2 id="max-dispatchers">max_dispatchers</h2>
<p>设置同一时刻能够同时运行的最多的dispatchers的数量，必须大于等于 dispatchers ，小于processes。这个参数也会被dispatchers覆盖。</p>
<h1 id="guan-bi-diao-du-jin-cheng">关闭调度进程</h1>
<h2 id="1-shou-xian-yao-cha-xun-dao-dispatchers-de-name">1、首先要查询到DISPATCHERS的NAME：</h2>
<pre><code class="language-shell">SELECT NAME,NETWORK FROM V$DISPATCHER;
</code></pre>
<h2 id="2-ran-hou-guan-bi-diao-du-jin-cheng">2、然后关闭调度进程</h2>
<pre><code class="language-shell">ALTER SYSTEM SHUTDOWN IMMEDIATE 'D000'; 
</code></pre>
<h1 id="guan-bi-gong-xiang-mo-shi">关闭共享模式</h1>
<p>将 shared_servers 参数置为0（alter system set shared_servers=0;），那么所有以共享方式连接到数据库都不能成功，但是未释放的共享连接会继续 保持连接，直到断开。如果将 shared_servers 和 max_shared_servers 都设为0（alter system set max_shared_servers=0;），那么共享连接将被终结。所有的共享方式连接都断开了的话，就可以使用 <code>alter system set dispatcher=''; </code>将dispatcher清除，防止下次启动数据库又打开了共享连接方式。</p>
<h1 id="pan-duan-oracle-shi-gong-xiang-mo-shi-huan-shi-zhuan-yong-mo-shi-de-fang-fa">判断oracle是共享模式还是专用模式的方法</h1>
<h2 id="1-can-shu-cha-xun">1. 参数查询</h2>
<pre><code class="language-shell">show parameter shared_server; (注：8i应为：show parameter mts_servers;)
SQL&gt; show parameter shared_server;

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
max_shared_servers                   integer     0  
shared_server_sessions               integer     
shared_servers                       integer     0  --为0表示专用模式
</code></pre>
<h2 id="2-cha-kan-v-session-shi-tu">2. 查看v$session 视图</h2>
<pre><code class="language-shell">SQL&gt; select username,server,program from v$session where username is not null;

USERNAME     SERVER    PROGRAM
--------- --------- -------------------
GWM            NONE    
SYS            SHARED        plsqldev.exe
SYS            SHARED        plsqldev.exe
SYS            DEDICATED     sqlplus.exe  --专用模式
</code></pre>
<h1 id="3-cha-kan-jian-ting-lsnrctl-service">3. 查看监听： lsnrctl service</h1>
<pre><code class="language-shell">oracle@RAC10:~&gt; lsnrctl service

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 21-12月-2011 17:23:47

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.73.14)(PORT=1521)))
Services Summary...
Service "smsgdb" has 2 instance(s).
  Instance "smsgdb", status UNKNOWN, has 1 handler(s) for this service...
    Handler(s):
      "DEDICATED" established:0 refused:0
         LOCAL SERVER
  Instance "smsgdb", status READY, has 1 handler(s) for this service...
    Handler(s):
      "DEDICATED" established:436931 refused:0 state:ready
         LOCAL SERVER
Service "smsgdb_XPT" has 1 instance(s).
  Instance "smsgdb", status READY, has 1 handler(s) for this service...
    Handler(s):
      "DEDICATED" established:436931 refused:0 state:ready
         LOCAL SERVER
The command completed successfully
</code></pre>
<h2 id="4-cha-kan-tnsnames-ora-wen-jian-ru">4. 查看TNSNAMES.ora 文件。如：</h2>
<pre><code class="language-shell">oracle@RAC10:~/product/11g/db_1/network/admin&gt; more tnsnames.ora
# tnsnames.ora Network Configuration File: /opt/oracle/product/11g/db_1/network/admin/tnsnames.ora
# Generated by Oracle configuration tools.

SMSGDB =
  (DESCRIPTION =
    (ADDRESS = (PROTOCOL = TCP)(HOST = RAC10)(PORT = 1521))
    (ADDRESS = (PROTOCOL = TCP)(HOST = 10.137.73.14)(PORT = 1521))
    (CONNECT_DATA =
      (SERVER = DEDICATED)
      (SERVICE_NAME = smsgdb)
    )
  )
</code></pre>
<p>这里是以DEDICATED 专用模式连接 telemt 实例。写上 (SERVER = SHARED) 则是使用共享服务器模式，但是这时shared_server_process需要打开（即oracle服务器的shared_servers参数要设置为共享模式），要不然会出错连不上oracle(ora-12520:TNS:监听程序无法为请求的服务器类型找到可用的处理程序)。</p>
<p>要是这段放空没写，那么系统会根据服务器模式自动调节，不过根据实测结果，就算服务器是定义成共享服务器模式，shared_server_process没打开的情况下，在v$session中查到的连接依然是SERVER = DEDICATED。所以基本上我们这段话都是可以放空着不写的，但是有时候要连上我们的共享服务器模式的数据库，放空有可能系统认为要用共享服务器方式去连，因此最好声明 SERVER = DEDICATED 采用专用服务器方式去连接。</p>
<p>在数据库启动的时候，如果没有指定shared_servers，但是设置了dispatchers，那么ORACLE就认为启动了shared server ，并且设置shared_servers为1。 在数据库启动的时候，没有设置shared_servers,也没有设置dispatchers，即使以后修改了dispatchers，也不能启动shared server，必须重新启动数据库。</p>
<h1 id="mo-shi-de-xuan-ze">模式的选择</h1>
<p>具体的来说，在以下应用情景下，可以选择采用共享服务器模式。</p>
<h2 id="1-qian-tai-ke-hu-duan-shu-liang-bi-jiao-duo">1. 前台客户端数量比较多</h2>
<p>当大量用户需要连接到数据库并且需要有效的使用可用的系统资源的时候，则需要考虑采用共享服务器模式。具体的来说，像现在采用的一些客户端/服务器端模式的网络应用软件，如ERP系统等等。一方面因为用户人数比较多;另一方面企业由于资金有限，所以购置的是一般的服务器。这些服务器由于硬件方面的一些限制，如数据库系统与前台应用服务器采用统一台服务器。所以往往要求数据库能够充分使用硬件资源，以减少两者之间的冲突。</p>
<p>在这种情况下，往往采用共享式的服务器模式，比较合适。</p>
<h2 id="2-fu-wu-qi-nei-cun-xian-zhi-bi-jiao-da">2. 服务器内存限制比较大</h2>
<p>共享服务器模式下，当连接用户增加时，其内存使用率增加不会很多。因为他们共享一个服务器进程。所以，从这一个角度讲，共享服务器模式可以减少内存的使用。但在专用服务器模式下，内存的使用几乎与用户的数量成比例增加。</p>
<p>所以，用户若在一些老的服务器上部署Oracle数据库的话，因为其主板对内存的升级有所限制，所以，为了得到一个不错的数据库性能，往往采用共享服务器模式。如此，即时同时访问数据库的用户有所增加，其内存也不会有多大的影响。可以大大的降低内存的压力。</p>
<h2 id="3-mou-xie-te-ding-gong-neng-yao-qiu-cai-yong-gong-xiang-fu-wu-qi-mo-shi">3. 某些特定功能要求采用共享服务器模式</h2>
<p>虽然说，共享服务器模式与专用服务器模式在大部分情况下，都是通用的，支持Oracle数据库系统的大部分功能。但是，某一些特定的功能，仍然需要数据库管理员在共享服务器模式下，才能够启用。比较典型的，如Oracle数据库服务器的连接共享、连接集中与负载均衡技术等等。他们必须在共享模式下才能够运行。</p>
<p>负载均衡用来在群集环境下实现多机共享数据库，以保证应用的高可用性。同时可以自动实现并行处理以及均分负载，还能够实现数据库在故障时的容错和无断点恢复。所以，在一些对于性能与稳定性要求比较高的应用场景中，如银行中，往往都会采用负载均衡技术。此时，数据库管理员在配置数据库的时候，就需要考虑采用共享服务器模式。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--表空间--收缩临时表空间</title>
    <url>/2012/01/18/oracle_troubleshoot_shirnk_temp_tablespace/</url>
    <content><![CDATA[<h1 id="shou-suo-lin-shi-biao-kong-jian">收缩临时表空间</h1>
<p>从oracle 11g R1版本开始，新增对历史表空间的shrink操作。目的是：当临时表空间扩展过大时（临时表空间主要用于排序操作，当需要的空间不足时，会自动扩展【前提是允许临时表空间自动扩展】，排完序后，已经扩展的空间不会回缩，这样就会导致临时表空间不断变大），占用磁盘空间，可以适当的对临时表空间进行压缩。</p>
<p>shrink操作只适用于临时表空间，收缩临时表空间有两种方法：</p>
<h2 id="fang-fa-yi-shi-yong-keep-zi-ju">方法一：使用keep子句</h2>
<pre><code class="language-shell">SQL&gt; alter tablespace  MMSG_TMP shrink space keep 20M;

表空间已更改。

SQL&gt;
</code></pre>
<h2 id="fang-fa-er-zi-dong-jiang-lin-shi-biao-kong-jian-ya-suo-zhi-zui-xiao">方法二：自动将临时表空间压缩至最小</h2>
<pre><code class="language-shell">SQL&gt; alter tablespace  YJH_TMP shrink tempfile '/home/yjh/oradata/yjhdata02';
</code></pre>
<p>附：</p>
<p>查询临时表空间名称与大小SQL语句</p>
<pre><code class="language-shell">select t1.file_name,t1.tablespace_name,t2.bytes/1024/1024 from dba_temp_files t1,v$tempfile t2 where t1.file_name=t2.name
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--表空间--表空间使用率为负数</title>
    <url>/2012/02/07/oracle_troubleshoot_tablespace_usage_is_negative/</url>
    <content><![CDATA[<h1 id="oracle-biao-kong-jian-shi-yong-lu-wei-fu">oracle表空间使用率为负</h1>
<h2 id="yin-yan">引言</h2>
<p>oracle的表空间的使用率主要是通过表dba_data_files 和 dba_free_space查询得出的。正常情况下，dba_data_files中bytes字段值应该大于dba_free_space中bytes字段值，否则会出现表空间使用率为负的情况。</p>
<p>本文主要介绍当前彩信网关应用环境中一应用表空间的使用率为是负的一则案例。详细信息如下：</p>
<h2 id="biao-xiang">表像</h2>
<h3 id="cha-xun-gai-biao-kong-jian-shi-yong-qing-kuang-dba-tablespace-usage-metrics">查询该表空间使用情况（dba_tablespace_usage_metrics）</h3>
<pre><code class="language-shell">SQL&gt; run
  1* select * from dba_tablespace_usage_metrics where tablespace_name = 'YJH'

TABLESPACE_NAME                USED_SPACE TABLESPACE_SIZE USED_PERCENT
------------------------------ ---------- --------------- ------------
YJH                                -47312           76800   -61.604167

SQL&gt;
</code></pre>
<p>上述结果展示发现表空间的使用率为负值。</p>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>这个现象几个月前就发现了，迟迟没有解决方法。</p>
</li>
</ul>
<h2 id="qi-ta-fang-shi-cha-xun">其他方式查询</h2>
<h3 id="shi-yong-oem">使用OEM</h3>
<p>Web OEM查询结果如下：</p>
<img class="shadow" src="/img/in-post/oracle-oem.png" width="1200">
<p>上图结果显示表空间YJH的使用率为10.5%</p>
<p>OEM的SQL trace为：</p>
<pre><code class="language-shell">SELECT 
/*+first_rows */ 
 d.tablespace_name,
  NVL(a.bytes / 1024 / 1024, 0),
  DECODE(d.contents,'UNDO',
  NVL(u.bytes, 0)/1024/1024,
  NVL(a.bytes - NVL(f.bytes, 0), 0)/1024/1024), 
  DECODE(d.contents,'UNDO', NVL(u.bytes / a.bytes * 100, 0),
  NVL((a.bytes - NVL(f.bytes, 0)) / a.bytes * 100, 0)),
  DECODE(d.contents,'UNDO', NVL(a.bytes - NVL(u.bytes, 0), 0)/1024/1024,
  NVL(f.bytes, 0) / 1024 / 1024),
  d.status,
  a.count,
  d.contents,
  d.extent_management,
  d.segment_space_management/*, d.encrypted*/ 
  
 FROM 
 sys.dba_tablespaces d, 
( SELECT 
     tablespace_name,
     SUM(bytes) bytes,
     COUNT(file_id) count 
   from dba_data_files 
   GROUP BY tablespace_name
   ) a,
   
   (select 
      tablespace_name,
      sum(bytes) bytes 
    from dba_free_space 
    group by tablespace_name
    ) f,
    
    (
      SELECT 
        tablespace_name,
        SUM(bytes) bytes 
      FROM 
      (
        SELECT 
            tablespace_name,
            sum (bytes) bytes,
            status 
         from dba_undo_extents 
         WHERE status ='ACTIVE' 
         group by tablespace_name,status UNION ALL 
         
           SELECT 
              tablespace_name,
              sum(bytes) bytes,
              status 
           from dba_undo_extents 
           WHERE status ='UNEXPIRED' 
           group by tablespace_name,status 
        )
       group by tablespace_name 
       ) u 
       
     WHERE d.tablespace_name = a.tablespace_name(+)
     AND d.tablespace_name = f.tablespace_name(+)
     AND d.tablespace_name = u.tablespace_name(+)
     AND NOT (d.extent_management = 'LOCAL' 
     AND d.contents = 'TEMPORARY')
     AND d.tablespace_name like 'YJH%' 
     UNION ALL 

SELECT 
     d.tablespace_name,
     NVL(a.bytes / 1024 / 1024, 0),
     NVL(t.bytes, 0)/1024/1024,
     NVL(t.bytes / a.bytes * 100, 0),
     (NVL(a.bytes ,0)/1024/1024 - NVL(t.bytes, 0)/1024/1024),
     d.status,
     a.count,
     d.contents,
     d.extent_management,
     d.segment_space_management/*, d.encrypted*/ 
FROM sys.dba_tablespaces d, 
(
   select 
       tablespace_name,
       sum(bytes) bytes,
       count(file_id) count 
   from dba_temp_files
   group by tablespace_name
 ) a, 

 (
     select  
        ss.tablespace_name ,
        sum((ss.used_blocks*ts.blocksize)) bytes 
     from gv$sort_segment ss, sys.ts$ ts 
     where ss.tablespace_name = ts.name 
     group by ss.tablespace_name) t 
   WHERE d.tablespace_name = a.tablespace_name(+)
   AND d.tablespace_name = t.tablespace_name(+)
   AND d.extent_management = 'LOCAL' 
   AND d.contents = 'TEMPORARY' 
and d.tablespace_name like 'YJH%' ORDER BY 1
</code></pre>
<p>上述command查询结果如下：</p>
<pre><code class="language-shell">TABLESPACE_NAME  NVL(A.BYTES/1024/1024,0) DECODE(D.CONTENTS,'UNDO',NVL(U.BYTES,0)/1024/1024,NVL(A.BYTES-NVL(F.BYTES,0),0)/1024/1024) STATUS     COUNT CONTENTS  EXTENT_MAN SEGMEN
------------------------------ ------------------------ ------------------------------------------------------------------------------------------ --------- ---------- --------- ---------- ------
YJH                                                 600                                                                            63 ONLINE              1 PERMANENT LOCAL      AUTO
YJH_TMP                                              21                                                                             0 ONLINE              1 TEMPORARY LOCAL      MANUAL

SQL&gt;
</code></pre>
<p>该表空间大小为600M，已使用63M，自己计算一下该表空间的使用率为63/600*100%=10.5%</p>
<h3 id="cha-xun-dba-free-space-he-dba-data-files">查询dba_free_space和dba_data_files</h3>
<pre><code class="language-shell">SQL&gt; select sum(bytes) from dba_data_files where tablespace_name = 'YJH';

SUM(BYTES)
----------
 629145600
SQL&gt; select sum(bytes) from dba_free_space where tablespace_name = 'YJH';

SUM(BYTES)
----------
 563085312
</code></pre>
<p>Free的值比总的值要小，也就是该表空间使用了66060288（629145600-563085312）字节，大约使用率在10.5%，而发布的command查询结果却是一个负值，-61.604167%。前后计算值不一。</p>
<h3 id="jie-guo-dui-bi">结果对比</h3>
<p>发现 通过OEM查询结果与手工查表（dba_data_file 和dba_free_space）计算的结果是一致的，都是正数，使用率为10.5%。</p>
<p>这里只能说明一个问题，那就是oracle对于表空间使用率的计算存在缺陷。</p>
<h3 id="wen-ti-hui-xiang">问题回想</h3>
<p>之前表空间名为YJH的使用率达到100%，存在大量XXX_YYYYMMDD表，消耗掉大量的表空间，所以（多次）执行了大量的drop操作（没增加purge参数），以解决有限的表空间资源问题。</p>
<h3 id="yan-zheng">验证</h3>
<p>oracle从10g开始提供回收站功能，从11g提供闪回功能，回收站默认空间为2G。相关信息如下：</p>
<h4 id="bu-zou-yi-hui-shou-zhan-xiang-guan-can-shu">步骤一、回收站相关参数</h4>
<pre><code class="language-shell">SQL&gt; show parameter recyclebin

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
recyclebin                           string      OFF
SQL&gt; show parameter recovery

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_recovery_file_dest                string
db_recovery_file_dest_size           big integer 0
recovery_parallelism                 integer     0
SQL&gt; 
SQL&gt; 
SQL&gt; select * from recyclebin;   #从查询结果来看，回收站没有记录，因为回收站处于关闭状态

no rows selected

SQL&gt;
</code></pre>
<p>上述查询结果显示，recyclebin被关闭（OFF），所以db_recovery_file_dest_size值为0。</p>
<p>如果没有开通回收站功能，默认空间依然为2G，只是删除表、索引等drop记录会被记录在自己的表空间中，用于必要的恢复操作（具体存放的位置或者表中记录，没查询到）。</p>
<h4 id="bu-zou-er-dba-yong-hu-qing-kong-dang-qian-hui-shou-zhan-zhong-suo-you-ji-lu">步骤二、dba用户清空当前回收站中所有记录</h4>
<pre><code class="language-shell">SQL&gt; purge dba_recyclebin;

DBA Recyclebin purged.
</code></pre>
<h4 id="bu-zou-san-zai-ci-cha-xun-biao-kong-jian-shi-yong-lu">步骤三、再次查询表空间使用率</h4>
<pre><code class="language-shell">SQL&gt; select * from dba_tablespace_usage_metrics where tablespace_name = 'YJH';

TABLESPACE_NAME                USED_SPACE TABLESPACE_SIZE USED_PERCENT
------------------------------ ---------- --------------- ------------
YJH                                  8064           76800         10.5

SQL&gt;
</code></pre>
<p>由此可以推测出：</p>
<p>表空间使用率的计算（dba_tablespace_usage_metrics）的缺陷应该是由于回收站机制导致的（只是一种可能，或许还有其他的原因导致表空间使用率为负，本例中是由于回收站机制导致）。</p>
<h3 id="wen-ti-yin-shen">问题引申</h3>
<p>如果表空间的使用率为负，那么，数据库在后续的工作中如何计算表空间的使用情况以及如果处理数据？</p>
<p>按照当前的现象，查询了当前表空间中表的可读写情况：</p>
<pre><code class="language-shell">select 
b.segment_name ,
b.BYTES,b.BLOCKS 
,a.BYTES,
a.USER_BYTES  
from 
dba_data_files a,
dba_extents b 
where a.file_id=b.file_id 
and a.file_name like '/home/yjh/program_files/oradata/y_mmsgdata01';
</code></pre>
<p>发布上述command命令，是有查询结果的，也就是当前虽然表空间使用率为负，但对数据库的操作应该处于一种正常状态，并不影响当前数据库系统的正常运行与使用。</p>
<h3 id="cai-xin-wang-guan-xiang-guan-hua-ti">彩信网关相关话题</h3>
<p>在关闭回收站情况下，建议定期去清理recycle bin中的内容。</p>
<p>目前彩信网关对数据库的备份是定期备份，且关闭回收站以及不启用闪回功能，同时，还有脚本用于定期调用存储过程清除日期表，里面的操作是drop，没增加purge参数。虽然磁阵挂载点给足足够的空间用于MMSG表空间的应用，个人觉得未雨绸缪也不是一件坏事。</p>
<h4 id="zong-shu">综述</h4>
<p>解决彩信可能存在的数据库表空间使用率为负，可参考如下两个方法：</p>
<h5 id="fang-fa-yi-tong-guo-jiao-ben-ding-qi-qing-li-recyclebin">方法一、通过脚本定期清理recyclebin</h5>
<h5 id="fang-fa-er-cun-chu-guo-cheng-shua-ku-jiao-ben-zhong-zeng-jia-purge-can-shu">方法二、存储过程、刷库脚本中增加purge参数</h5>
<p>这个最直接，也最简单。</p>
<p>方法二也是对当前彩信网关 存储过程 的一个优化，以及setdb.sh脚本调用createdb.sql这个脚本中的 drop表操作 的一个优化，都可以通过增加purge参数解决。类似于windows的shift+delete，不经过回收站了。</p>
<h1 id="qi-ta">其他</h1>
<p>表空间使用率为负，从oracle 10g引入（具体版本暂时不知），以前为负的情况时候，OEM的统计表空间的使用率也是负值，该问题应该是修改不完善，导致OEM查询是正确的，而通过表查询是错误的。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle闪回</title>
    <url>/2012/02/19/oracle_flashback/</url>
    <content><![CDATA[<h1 id="te-xing-gai-shu">特性概述</h1>
<p>闪回技术通常用于快速、简单恢复数据库中出现的人为误操作等逻辑错误，即：闪回只对逻辑错误有意义，对数据块损坏和联机日志损坏必须采用介质恢复。</p>
<h1 id="shan-hui-lei-xing">闪回类型</h1>
<p>从闪回的方式可以将闪回分为：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、基于数据库级别闪回</p>
</li>
<li class="lvl-2">
<p>2、表级别闪回</p>
</li>
<li class="lvl-2">
<p>3、事务级别闪回</p>
</li>
</ul>
<p>根据闪回对数据的影响程度又可以分为:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、闪回恢复</p>
</li>
<li class="lvl-2">
<p>2、闪回查询</p>
</li>
</ul>
<p>闪回恢复将修改数据，闪回点之后的数据将全部丢失。而闪回查询则可以查询数据被DML的不同版本，也可以在此基础之上确定是否进行恢复等。</p>
<h1 id="ru-he-qi-yong-shan-hui">如何启用闪回</h1>
<h2 id="qi-yong-shan-hui-qian-jian-cha">启用闪回前检查</h2>
<h3 id="que-ren-shi-fou-qi-yong-shan-hui-gong-neng">确认是否启用闪回功能</h3>
<pre><code class="language-shell">SQL&gt; select flashback_on from v$database;

FLASHBACK_ON
------------------
NO

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>1、flashback_on取值为NO，说明尚未启用闪回功能，取值为YES则表示启用了闪回功能。</p>
</li>
<li class="lvl-3">
<p>2、该参数仅能在数据库mount状态下修改。</p>
</li>
</ul>
<h3 id="que-ren-dang-qian-ri-zhi-gui-dang-mo-shi">确认当前日志归档模式</h3>
<pre><code class="language-shell">SQL&gt; archive log list
Database log mode              Archive Mode
Automatic archival             Enabled
Archive destination            /opt/oracle/product/11g/dbs/arch
Oldest online log sequence     216
Next log sequence to archive   220
Current log sequence           220
SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果非归档模式下，启用闪回失败：</p>
</li>
</ul>
<pre><code class="language-shell">SQL&gt; alter database flashback on;
alter database flashback on
*
ERROR at line 1:
ORA-38706: Cannot turn on FLASHBACK DATABASE logging.
ORA-38707: Media recovery is not enabled.

oracle@mmsc101:~&gt; oerr ora 38706
38706, 00000, "Cannot turn on FLASHBACK DATABASE logging."
// *Cause:  An ALTER DATABASE FLASHBACK ON command failed.
//          Other messages in the alert log describe the problem.
// *Action: Fix the problem and retry.
oracle@mmsc101:~&gt; oerr ora 38707
38707, 00000, "Media recovery is not enabled."
// *Cause: An ALTER DATABASE FLASHBACK ON command failed because media
//         recovery was not enabled.
// *Action: Turn on media recovery with an ALTER DATABASE ARCHIVELOG
//          command and then retry the command.
</code></pre>
<h3 id="jian-cha-xiu-gai-hui-fu-qu-she-zhi">检查/修改恢复区设置</h3>
<pre><code class="language-shell">SQL&gt; show parameter db_recovery_file_dest

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_recovery_file_dest                string
db_recovery_file_dest_size           big integer 0
SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>上述查询结果展示db_recovery_file_dest取值为空，则表示没有配置闪回区域，启用闪回后需要设置该值，string类型的串。</p>
</li>
</ul>
<h3 id="jian-cha-xiu-gai-shan-hui-shi-jian-she-zhi">检查/修改闪回时间设置</h3>
<pre><code class="language-shell">SQL&gt; show parameter db_flashback_retention_target

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_flashback_retention_target        integer     1440
SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、db_flashback_retention_target单位为分钟，表示能恢复数据的时间长短，默认值为1440（24*60）；</p>
</li>
<li class="lvl-2">
<p>2、如果想调整这个参数的取值，可以使用如下语句进行调整：</p>
</li>
</ul>
<pre><code>alter system set db_flashback_retention_target=1440;
</code></pre>
<h3 id="jian-cha-shan-hui-qu-yu-da-xiao">检查闪回区域大小</h3>
<pre><code class="language-shell">SQL&gt; show parameter DB_RECOVERY_FILE_DEST_SIZE

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_recovery_file_dest_size           big integer 0
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>db_recovery_file_dest_size参数单位为G；</p>
</li>
</ul>
<h2 id="qi-yong-shan-hui">启用闪回</h2>
<p>说明：下列步骤为在归档模式下，在没有启用闪回功能前提下启用闪回功能的操作步骤，详细信息如下</p>
<h3 id="bu-zou-1-shou-gong-chuang-jian-shan-hui-shu-ju-cun-fang-lu-jing">步骤1 手工创建闪回数据存放路径</h3>
<p>在/opt/oracle/目录下创建flash_recovery目录。</p>
<h3 id="bu-zou-2-xiu-gai-shan-hui-shu-ju-cun-fang-lu-jing">步骤2 修改闪回数据存放路径</h3>
<pre><code class="language-shell">SQL&gt; alter system set db_recovery_file_dest_size  = 2048M scope=both;

System altered.

SQL&gt;
</code></pre>
<h3 id="bu-zou-3-zhong-xin-qi-dong-shu-ju-ku-dao-mount-zhuang-tai">步骤3 重新启动数据库到Mount状态</h3>
<pre><code class="language-shell">SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
Database mounted.
SQL&gt; startup mount  
ORACLE instance started.

Total System Global Area 8284340224 bytes
Fixed Size                  2145944 bytes
Variable Size            6375342440 bytes
Database Buffers         1879048192 bytes
Redo Buffers               27803648 bytes
Database mounted.
SQL&gt;
</code></pre>
<h3 id="bu-zou-4-qi-dong-flashback-database-xuan-xiang">步骤4 启动flashback database选项</h3>
<pre><code class="language-shell">SQL&gt; alter system set db_recovery_file_dest='/opt/oracle/flash_recovery' scope=both;

System altered.
SQL&gt; alter database flashback on;

Database altered.

SQL&gt; alter database open;

Database altered.

SQL&gt;
</code></pre>
<h3 id="bu-zou-5-jian-cha-shan-hui-jin-cheng-shi-fou-qi-dong">步骤5 检查闪回进程是否启动</h3>
<pre><code class="language-shell">SQL&gt; ho ps -ef | grep rvwr 
oracle   23486     1  0 17:09 ?        00:00:00 ora_rvwr_sdp
oracle    1634 14984  0 17:26 pts/6    00:00:00 /bin/bash -c ps -ef | grep rvwr
oracle    1636  1634  0 17:26 pts/6    00:00:00 grep rvwr

SQL&gt;
</code></pre>
<h1 id="shan-hui-shu-ju-ku-flashback-database-gai-shu">闪回数据库（flashback database）概述</h1>
<h2 id="flashback-database-de-te-xing">flashback database的特性</h2>
<p>flashback data1base闪回到过去的某一时刻，闪回点之后的工作全部丢失。使用resetlogs创建新的场景并打开数据库(一旦resetlogs之后，将不能再flashback至resetlogs之前的时间点)。</p>
<p>常用的场景：truncate table、多表发生意外错误等。</p>
<h2 id="flashback-database-de-zu-cheng">flashback database的组成</h2>
<p>闪回缓冲区：当启用flashback database，则sga中会开辟一块新区域作为闪回缓冲区,大小由系统分配；</p>
<p>启用新的rvwr进程:rvwr进程将闪回缓冲区的内容写入到闪回日志中。</p>
<h2 id="shan-hui-ri-zhi-yu-lian-ji-zhong-zuo-ri-zhi-de-qu-bie">闪回日志与联机重做日志的区别</h2>
<p>闪回日志不同于联机重做日志，闪回日志在联机重做日志基础之上生成，是完整数据块映像的日志。联机日志则是变化的日志。闪回日志不能复用，也不能归档。</p>
<p>闪回日志使用循环写方式,简单的讲，就是：联机日志会记录改变前后的值，而闪回日志只记录改变前的值。</p>
<h2 id="shan-hui-shu-ju-ku-de-shi-xian-ji-li">闪回数据库的实现机理</h2>
<p>buffer cache&lt;–&gt;flashback cache&lt;–&gt;rvwr&lt;–&gt;闪回日志【日志只记录修改前的旧值】</p>
<h1 id="shan-hui-database-de-pei-zhi">闪回database的配置</h1>
<h2 id="cha-kan-shan-hui-shu-ju-liang-shi-jian-deng-xiang-guan-xin-xi">查看闪回数据量、时间等相关信息</h2>
<p>下面查看闪回区分配的大小为大约32M，闪回1440分钟以内的数据则需要46M左右的空间</p>
<pre><code class="language-shell">SQL&gt; select oldest_flashback_scn old_flhbck_scn,oldest_flashback_time old_flhbck_tim,
  2  retention_target rete_trgt,flashback_size/1024/1024 flhbck_siz,
  3  estimated_flashback_size/1024/1024 est_flhbck_size
  4  from v$flashback_database_log;

OLD_FLHBCK_SCN OLD_FLHBCK_TIM       RETE_TRGT FLHBCK_SIZ EST_FLHBCK_SIZE
-------------- ------------------- ---------- ---------- ---------------
       5813199 02/09/2012 17:09:06       1440 32.0078125      46.2890625

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>列oldest_flashback_time说明了允许返回的最早的时间点。</p>
</li>
</ul>
<h2 id="cha-kan-shan-hui">查看闪回</h2>
<pre><code class="language-shell">SQL&gt; set wrap off
SQL&gt; select * from v$flashback_database_stat;
truncating (as requested) before column ESTIMATED_FLASHBACK_SIZE


BEGIN_TIME          END_TIME            FLASHBACK_DATA    DB_DATA  REDO_DATA
------------------- ------------------- -------------- ---------- ----------
02/09/2012 17:09:06 02/09/2012 17:57:12        1351680    1466368     326144

SQL&gt;
</code></pre>
<h2 id="cha-kan-shan-hui-zhong-sga-fen-pei-de-kong-jian-da-xiao">查看闪回中sga分配的空间大小</h2>
<pre><code class="language-shell">SQL&gt; select * from v$sgastat where name like 'flashback%';

POOL         NAME                            BYTES
------------ -------------------------- ----------
shared pool  flashback generation buff    33554432
shared pool  flashback_marker_cache_si        9200

SQL&gt;
</code></pre>
<h2 id="cha-kan-sheng-cheng-de-shan-hui-ri-zhi">查看生成的闪回日志</h2>
<pre><code class="language-shell">SQL&gt; ho ls -hlt $ORACLE_BASE/flash_recovery/SDP/flashback
total 33M
-rw-r----- 1 oracle oinstall 33M 2012-02-09 17:59 o1_mf_7m739k3t_.flb

SQL&gt;
</code></pre>
<h1 id="shi-yong-flashback-shan-hui-shu-ju-ku-shi-jian">使用flashback闪回数据库实践</h1>
<p>前提条件：归档日志可用。</p>
<p>步骤1 关闭数据库</p>
<p>步骤2 启动数据库到mount状态</p>
<p>步骤3 闪回至某个时间点、scn或log sequence number</p>
<p>步骤4 使用resetlogs打开数据库</p>
<h2 id="shi-yong-sqlplus-shan-hui-shu-ju-ku">使用sqlplus闪回数据库</h2>
<h3 id="sqlplus-ji-chong-chang-yong-de-shan-hui-shu-ju-ku-fang-fa">sqlplus几种常用的闪回数据库方法</h3>
<h4 id="ji-yu-scn-shan-hui">基于SCN闪回</h4>
<pre><code class="language-shell">FLASHBACK [STANDBY] DATABASE [&lt;database_name&gt;]  TO [BEFORE] SCN &lt;system_change_number&gt;
</code></pre>
<h4 id="ji-yu-shi-jian-chuo-shan-hui">基于时间戳闪回</h4>
<pre><code class="language-shell">FLASHBACK [STANDBY] DATABASE [&lt;database_name&gt;]  TO [BEFORE] TIMESTMP &lt;system_timestamp_value&gt;
</code></pre>
<h4 id="ji-yu-shi-dian-shan-hui">基于时点闪回</h4>
<pre><code class="language-shell">FLASHBACK [STANDBY] DATABASE [&lt;database_name&gt;]  TO [BEFORE] RESTORE POINT &lt;restore_point_name&gt;
</code></pre>
<p>如下面的示例：</p>
<pre><code class="language-shell">SQL&gt; flashback database to timestamp('2010-10-24 13:04:30','yyyy-mm-dd hh24:mi:ss'); 

SQL&gt; flashback database to scn 5813199;

SQL&gt; flashback database ro restore point wyz_test;
</code></pre>
<h4 id="a-ji-yu-shi-jian-chuo-shan-hui">a.基于时间戳闪回</h4>
<h5 id="bu-zou-1-chuang-jian-ce-shi-biao-bing-cha-ru-shu-ju">步骤1、 创建测试表，并插入数据</h5>
<pre><code class="language-shell">oracle@mmsc101:~&gt; sqlplus mmsg/mmsg@sdp

SQL*Plus: Release 11.1.0.6.0 - Production on Thu Feb 9 18:14:31 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options
SQL&gt; create table scn_test(id int);

Table created.

SQL&gt; insert into scn_test values(1);

1 row created.

SQL&gt; insert into scn_test values(2);

1 row created.

SQL&gt; commit;

Commit complete.

SQL&gt; select count(0) from scn_test;

  COUNT(0)
----------
         2

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>上述测试表中有两个记录。</p>
</li>
</ul>
<h5 id="bu-zou-2-huo-qu-xi-tong-dang-qian-shi-jian">步骤2、获取系统当前时间</h5>
<pre><code class="language-shell">SQL&gt; select to_char(sysdate,'yyyy-mm-dd hh24:mi:ss')  time from dual; 

TIME
---------------------------------------------------------
2012-02-09 18:39:30

SQL&gt;
</code></pre>
<h5 id="bu-zou-3-shan-chu-biao-scn-test">步骤3、删除表scn_test</h5>
<pre><code class="language-shell">SQL&gt; drop table scn_test;

Table dropped.

SQL&gt; commit;

Commit complete.

SQL&gt;
</code></pre>
<h5 id="bu-zou-4-xin-chuang-jian-biao-tmp">步骤4、新创建表tmp</h5>
<pre><code class="language-shell">SQL&gt; create table tmp as select * from modules;

Table created.

SQL&gt; commit;

Commit complete.

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>目的是为了验证闪回后这张表不存在。</p>
</li>
</ul>
<h5 id="bu-zou-5-qi-dong-shu-ju-ku-dao-mount-zhuang-tai">步骤5、启动数据库到mount状态</h5>
<pre><code class="language-shell">oracle@mmsc101:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on Thu Feb 9 18:24:49 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; shutdown immediate
SQL&gt; startup mount
</code></pre>
<h5 id="bu-zou-6-dba-yong-hu-shi-shi-shan-hui">步骤6、dba用户实施闪回</h5>
<pre><code class="language-shell">SQL&gt; flashback database to timestamp to_timestamp('2012-02-09 18:39:30','yyyy-mm-dd hh24:mi:ss');  

Flashback complete.

SQL&gt; alter database open resetlogs;

Database altered.

SQL&gt;
</code></pre>
<h5 id="bu-zou-7-shan-hui-jie-guo-cha-kan">步骤7、闪回结果查看</h5>
<pre><code class="language-shell">SQL&gt; connect mmsg/mmsg@sdp
Connected.
SQL&gt; select count(0) from scn_test;

  COUNT(0)
----------
         2

SQL&gt; select * from tmp;
select * from tmp
              *
ERROR at line 1:
ORA-00942: table or view does not exist


SQL&gt;
</code></pre>
<p>上述查询结果说明表已经闪回恢复，闪回点之后的数据全部丢失。</p>
<h4 id="b-ji-yu-scn-hao-shan-hui">b.基于SCN号闪回</h4>
<h5 id="bu-zou-1-huo-qu-dang-qian-scn">步骤1 获取当前SCN</h5>
<pre><code class="language-shell">SQL&gt; select current_scn from v$database;

CURRENT_SCN
-----------
5815970
</code></pre>
<h5 id="bu-zou-2-shan-chu-mmsg-yong-hu-xia-de-scn-test-biao">步骤2 删除mmsg用户下的scn_test表</h5>
<pre><code class="language-shell">SQL&gt; connect mmsg/mmsg@sdp
Connected.
SQL&gt; drop table scn_test;

Table dropped.

SQL&gt; commit;

Commit complete.
</code></pre>
<h5 id="bu-zou-3-shou-dong-zhi-xing-jian-cha-dian">步骤3 手动执行检查点</h5>
<pre><code class="language-shell">SQL&gt; alter system checkpoint;

System altered.

SQL&gt;
</code></pre>
<h5 id="bu-zou-4-shi-shi-shan-hui">步骤4 实施闪回</h5>
<pre><code class="language-shell">SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; startup mount
ORACLE instance started.

Total System Global Area 8284340224 bytes
Fixed Size                  2145944 bytes
Variable Size            6375342440 bytes
Database Buffers         1879048192 bytes
Redo Buffers               27803648 bytes
Database mounted.
SQL&gt; flashback database to scn 5815970;

Flashback complete.

SQL&gt; alter database open resetlogs;

Database altered.

SQL&gt;
</code></pre>
<h5 id="bu-zou-5-cha-xun-shan-hui-jie-guo">步骤5 查询闪回结果</h5>
<pre><code class="language-shell">SQL&gt; connect mmsg/mmsg@sdp
Connected.
SQL&gt; select count(0) from scn_test;

  COUNT(0)
----------
         2

SQL&gt;
</code></pre>
<h4 id="c-ji-yu-shi-dian-shan-hui">c.基于时点闪回</h4>
<h5 id="bu-zou-1-chuang-jian-ce-shi-biao">步骤1 创建测试表</h5>
<pre><code class="language-shell">SQL&gt; create table test(id int,describe varchar2(20));

Table created.

SQL&gt; insert into test values(1,'ABC');

1 row created.

SQL&gt; insert into test values(2,'DEF');

1 row created.

SQL&gt; commit;

Commit complete.
SQL&gt; select * from test;

        ID DESCRIBE
---------- --------------------
         1 ABC
         2 DEF

SQL&gt;
</code></pre>
<h5 id="bu-zou-2-chuang-jian-shan-hui-dian">步骤2 创建闪回点</h5>
<pre><code class="language-shell">oracle@mmsc101:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on Thu Feb 9 18:54:11 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; create restore point wyz_test;

Restore point created.

SQL&gt;
</code></pre>
<h5 id="bu-zou-3-zai-ci-cha-ru-ji-lu">步骤3 再次插入记录</h5>
<pre><code class="language-shell">SQL&gt; insert into test values(3,'GHI');

1 row created.

SQL&gt; commit;

Commit complete.

SQL&gt; select * from test;

        ID DESCRIBE
---------- --------------------
         1 ABC
         2 DEF
         3 GHI

SQL&gt;
</code></pre>
<h5 id="bu-zou-4-shan-hui-shi-shi">步骤4闪回实施</h5>
<pre><code class="language-shell">SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; startup mount
ORACLE instance started.

Total System Global Area 8284340224 bytes
Fixed Size                  2145944 bytes
Variable Size            6375342440 bytes
Database Buffers         1879048192 bytes
Redo Buffers               27803648 bytes
Database mounted.
SQL&gt; flashback database to restore point wyz_test;

Flashback complete.

SQL&gt; alter database open resetlogs;

Database altered.

SQL&gt;
</code></pre>
<h5 id="bu-zou-5-cha-kan-shan-hui-jie-guo">步骤5 查看闪回结果</h5>
<pre><code class="language-shell">SQL&gt; connect mmsg/mmsg@sdp
Connected.
SQL&gt; select * from test;

        ID DESCRIBE
---------- --------------------
         1 ABC
         2 DEF

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>闪回点是全局的，不区分用户，即在某个point后，不同用户做了不同的操作，只有闪回到该point后，该point后的不同用户的操作都将丢失。</p>
</li>
</ul>
<h2 id="shi-yong-rman-jin-xing-flashback-database">使用RMAN进行flashback database</h2>
<p>使用RMAN进行闪回数据库的几种常用办法</p>
<pre><code class="language-shell">RMAN&gt; flashback database to scn=918987;

RMAN&gt; flashback database to sequence=85  thread=1;
</code></pre>
<h3 id="a-ji-yu-shi-jian-chuo-shan-hui-1">a.基于时间戳闪回</h3>
<h4 id="bu-zou-1-chuang-jian-ce-shi-biao-1">步骤1 创建测试表</h4>
<pre><code class="language-shell">oracle@mmsc101:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on Thu Feb 9 19:02:24 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; create table mmsg.tmp as select * from mmsg.modules;

Table created.

SQL&gt; select count(0) from mmsg.tmp;

  COUNT(0)
----------
        18
</code></pre>
<h4 id="bu-zou-2-huo-qu-shu-ju-ku-dang-qian-shi-jian">步骤2 获取数据库当前时间</h4>
<pre><code class="language-shell">SQL&gt; select to_char(sysdate,'yyyy-mm-dd hh24:mi:ss') tm from dual;

TM
-------------------
2012-02-09 19:03:14
</code></pre>
<h4 id="bu-zou-3-shan-chu-ce-shi-biao">步骤3 删除测试表</h4>
<pre><code class="language-shell">SQL&gt; drop table mmsg.tmp;

Table dropped.

SQL&gt; commit;

Commit complete.
</code></pre>
<h4 id="bu-zou-4-shan-hui-shi-jian">步骤4 闪回实践</h4>
<pre><code class="language-shell">SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; startup mount
ORACLE instance started.

Total System Global Area 8284340224 bytes
Fixed Size                  2145944 bytes
Variable Size            6375342440 bytes
Database Buffers         1879048192 bytes
Redo Buffers               27803648 bytes
Database mounted.
SQL&gt;

oracle@mmsc101:~/product/11g/bin&gt; ./rman target/

Recovery Manager: Release 11.1.0.6.0 - Production on Thu Feb 9 19:05:03 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

connected to target database: SDP (DBID=2998391018, not open)

RMAN&gt; flashback database to time="to_date('2012-02-09 19:03:14','yyyy-mm-dd hh24:mi:ss')";

Starting flashback at 02/09/2012 19:05:09
using target database control file instead of recovery catalog
allocated channel: ORA_DISK_1
channel ORA_DISK_1: SID=1086 device type=DISK


starting media recovery
media recovery complete, elapsed time: 00:00:03

Finished flashback at 02/09/2012 19:05:14

RMAN&gt;


oracle@mmsc101:~&gt; sqlplus / as sysdba

SQL*Plus: Release 11.1.0.6.0 - Production on Thu Feb 9 19:05:36 2012

Copyright (c) 1982, 2007, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.1.0.6.0 - 64bit Production
With the Partitioning, OLAP, Data Mining and Real Application Testing options

SQL&gt; alter database open resetlogs;

Database altered.
</code></pre>
<h4 id="bu-zou-5-cha-kan-shan-hui-jie-guo-1">步骤5 查看闪回结果</h4>
<pre><code class="language-shell">SQL&gt; select count(0) from mmsg.tmp;

  COUNT(0)
----------
        18

SQL&gt;
</code></pre>
<h3 id="b-ji-yu-scn-shan-hui">b.基于SCN闪回</h3>
<h3 id="c-ji-yu-sequence-shan-hui">c.基于sequence闪回</h3>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>RMAN闪回操作和sqlplus闪回类似，命令可参考sqlplus的操作。</p>
</li>
</ul>
<h1 id="shan-hui-biao">闪回表</h1>
<p>就是将表里的数据推回到过去的某个时间点，是利用undo表空间里记录的数据被改变前的值，如果闪回表所需要的undo数据，由于保留的时间超过了初始化参数undo_retention所指定的值，从而导致该undo数据块被其他事务覆盖，就不能恢复到指定的时间点了。</p>
<p>闪回表的局限：当前的时间点到要闪回到的时间点之间不允许有ddl操作，否则闪回无法成功。</p>
<p>示例：</p>
<pre><code class="language-shell">SQL&gt; select count(0) from mmsg.tmp;

  COUNT(0)
----------
        18

SQL&gt; drop table mmsg.tmp;

Table dropped.

SQL&gt; flashback table mmsg.tmp to before drop;

Flashback complete.

SQL&gt; select count(0) from mmsg.tmp;

  COUNT(0)
----------
        18

SQL&gt;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>闪回表，需要在数据库启用回收站条件下才能进行表的闪回，否则报错：</p>
</li>
</ul>
<pre><code class="language-shell">SQL&gt; FLASHBACK TABLE mmsg.TEST TO BEFORE DROP;
FLASHBACK TABLE mmsg.TEST TO BEFORE DROP
*
ERROR at line 1:
ORA-38305: object not in RECYCLE BIN
</code></pre>
<h1 id="shan-hui-ban-ben-cha-xun">闪回版本查询</h1>
<p>所谓版本指的是每次事务所引起的数据行的变化的情况，每一次变化就是一个版本。闪回版本查询使用的undo表空间里记录的undo数据。</p>
<p>示例：</p>
<p>1、创建测试表，并插入数据</p>
<p>2、查询表中数据总量</p>
<p>3、drop 表中某个记录，查询表中总量</p>
<p>4、查看对应的该表中的闪回版本信息</p>
<pre><code class="language-shell">select versions_starttime, versions_endtime, versions_xid,
    versions_operation, moduleid
    from modules versions between timestamp minvalue and maxvalue
    order by VERSIONS_STARTTIME
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>其中modules为测试表的表名称。</p>
</li>
</ul>
<h1 id="shan-hui-shi-wu-cha-xun">闪回事务查询</h1>
<p>闪回事务查询提供的是一个视图，flashback_transaction_query，利用这个视图，可以显示哪些事务引起了数据的变化，并为此提供了撤销事务的SQL语句。</p>
<p>闪回事务查询利用的是undo表空间的undo数据</p>
<p>示例：</p>
<p>1、dba用户登录数据库，查询视图信息；</p>
<p><code>select * from flashback_transaction_query where table_owner='MMSG'；</code></p>
<p>2、查找对应的闪回事务，确定闪回操作时间点，执行UNDO_SQL字段提供的回滚语句进行闪回操作。</p>
<h1 id="shan-hui-cha-xun">闪回查询</h1>
<p>查询过去某个时刻表的数据的情况，一旦确认某个时刻的数据满足我们的需求以后，可以根据这个时间执行闪回表。</p>
<h1 id="fu-lu">附录</h1>
<h2 id="cha-kan-shan-hui-qu-shi-yong-qing-kuang">查看闪回区使用情况</h2>
<pre><code class="language-shell">SQL&gt; select name,space_limit/1024/1024 sp_limt,space_used/1024/1024 sp_usd,
  2  space_reclaimable/1024/1024 sp_recl,
  3  number_of_files num_fils from v$recovery_file_dest;

NAME
--------------------------------------------------------------------------------
   SP_LIMT     SP_USD    SP_RECL   NUM_FILS
---------- ---------- ---------- ----------
/opt/oracle/flash_recovery
      2048  918.15918          0         12


SQL&gt;
</code></pre>
<h2 id="jiang-mou-xie-biao-kong-jian-pai-chu-zai-shan-hui-zhi-wai">将某些表空间排除在闪回之外</h2>
<pre><code class="language-shell">SQL&gt; alter tablespace MMSG flashback off;

SQL&gt; select name,flashback_on from v$tablespace where ts#=4;

        NAME            FLA

        --------------- ---

        MMSG           NO
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果需要对上述表空间启用闪回功能，则需要在mount模式下对该表空间进行开启该功能。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 管理篇之表空间</title>
    <url>/2012/02/28/oracle_manager_tablespace/</url>
    <content><![CDATA[<h1 id="cha-kan-biao-kong-jian">查看表空间</h1>
<p>在做报表性能测试的时候，我们一般都需要去查看表空间。如果表空间已经满了，话单文件就堆积了，无法入库了。</p>
<pre><code class="language-shell">SQL&gt; select * from v$tablespace;

       TS# NAME                           INC BIG FLA ENC
---------- ------------------------------ --- --- --- ---
         0 SYSTEM                         YES NO  YES
         1 SYSAUX                         YES NO  YES
         2 UNDOTBS1                       YES NO  YES
         3 TEMP                           NO  NO  YES
         4 USERS                          YES NO  YES
         5 SMCRPT_HOME                    YES NO  YES
        14 INFOX_WEB_MAIN_DATA            YES NO  YES
         8 GW_IND_SMPP                    YES NO  YES
         7 GW_IN_SMPP                     YES NO  YES
         9 GW_HIS_SMPP                    YES NO  YES
        15 INFOX_WEB_MAIN_INDEX           YES NO  YES

       TS# NAME                           INC BIG FLA ENC
---------- ------------------------------ --- --- --- ---
        11 CDR                            YES NO  YES
        12 CDR_TEMP                       NO  NO  YES
        13 MMSGYK                         YES NO  YES
        26 INFOX_TEMPLFQ                  NO  NO  YES
        17 TB_SCOTT                       YES NO  YES
        18 INFOX_MAIN_DATA                YES NO  YES
        19 INFOX_MAIN_INDEX               YES NO  YES
        20 INFOX_BACKUP_DATA              YES NO  YES
        23 INFOX_RESEND                   YES NO  YES
        24 INFOX_CONGESTION               YES NO  YES
        25 INFOX_TRAFFIC                  YES NO  YES

       TS# NAME                           INC BIG FLA ENC
---------- ------------------------------ --- --- --- ---
        27 INFOX_TEMP_LFQ                 NO  NO  YES
        28 IMUSE01                        YES NO  YES
        29 BILL                            YES NO  YES
        30 IMUSE01_INDEX                  YES NO  YES
        31 IMUSE01_TEMP                   NO  NO  YES

27 rows selected.
</code></pre>
<p>但是上述命令呢，我们依然无法查看各个表空间分配了多大的空间，已经使用了多少空间，还剩余多少空间等信息，而且也不直观。</p>
<h1 id="oem-cha-kan-biao-kong-jian">OEM查看表空间</h1>
<p>现提供另外一种方法来查看各个表空间的信息。</p>
<h2 id="1-qi-dong-oem">1、启动OEM</h2>
<p>oracle用户登录服务器，执行如下命令：</p>
<pre><code class="language-shell">emctl start dbconsole
</code></pre>
<p>如果服务已经起来了，显示信息如下：</p>
<pre><code class="language-shell">oracle@linux:~&gt; emctl start dbconsole
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
        LANGUAGE = (unset),
        LC_ALL = (unset),
        LANG = "AMERICAN_CHINA.ZHS16GBK"
    are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").
Oracle Enterprise Manager 11g Database Control Release 11.1.0.6.0
Copyright (c) 1996, 2007 Oracle Corporation.  All rights reserved.
https://linux:1158/em/console/aboutApplication
Starting Oracle Enterprise Manager 11g Database Control ...... started.
------------------------------------------------------------------
Logs are generated in directory /home/oracle/product/11g/linux_infoxdb/sysman/log
</code></pre>
<p>停止DBCONSOLE服务：</p>
<pre><code class="language-shell">oracle@linux:~&gt; emctl stop dbconsole
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
        LANGUAGE = (unset),
        LC_ALL = (unset),
        LANG = "AMERICAN_CHINA.ZHS16GBK"
    are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").
Oracle Enterprise Manager 11g Database Control Release 11.1.0.6.0
Copyright (c) 1996, 2007 Oracle Corporation.  All rights reserved.
https://linux:1158/em/console/aboutApplication
Stopping Oracle Enterprise Manager 11g Database Control ...

all attemps to stop oc4j failed... now trying to kill 9
--- Failed to shutdown DBConsole Gracefully ---
 ...  Stopped.
</code></pre>
<p>启动失败会出现类似如下信息：</p>
<pre><code class="language-shell">OC4J Configuration issue. /opt/oracle/app/product/11.1.0/db_1/oc4j/j2ee/OC4J_DBConsole_expsmgw_ora11g not found.
</code></pre>
<h2 id="2-ie-deng-lu-fu-wu-qi-a-href-https-serverip-1158-em-https-serverip-1158-em-a">2、IE登录服务器<a href="https://serverip:1158/em">https://serverip:1158/em</a></h2>
<p>（如果IE登录失败，可以在Internet选项中添加可信任站点，将上述服务器的URL地址添加为可信任站点）</p>
<h2 id="3-yi-xi-tong-guan-li-yuan-shen-fen-deng-lu">3、以系统管理员身份登录</h2>
<img class="shadow" src="/img/in-post/oracle_oem.png" width="800">
<p>4、查看表空间信息</p>
<p>主目录 --&gt; 服务器 --&gt; 存储下 表空间</p>
<p>查看各个表空间的详细信息。</p>
<img class="shadow" src="/img/in-post/oracle_oem-1.png" width="800">
<h1 id="qi-ta-fang-fa-cha-kan-biao-kong-jian">其他方法查看表空间</h1>
<pre><code class="language-shell">dba_tablespace_usage_metrics
select tablespace_name,tablespace_size/128 as tablespace_size_Mb from dba_tablespace_usage_metrics;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>dba_tablespace_usage_metrics是表，该表只能查询永久性表空间（同时仅包括系统临时表空间，不含应用级临时表空间）相关信息，该表查询获取的表空间大小并不准确，代码中慎用。</p>
</li>
</ul>
<h2 id="dba-data-files">dba_data_files</h2>
<pre><code class="language-shell">select  tablespace_name,bytes/1024/1024 as tablespace_size_Mb from dba_data_files;
</code></pre>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>dba_data_files是表，该表只能查询永久性表空间相关信息。</p>
</li>
</ul>
<h2 id="dba-temp-files">dba_temp_files</h2>
<pre><code class="language-shell">select  tablespace_name,bytes/1024/1024 as tablespace_size_Mb from  dba_temp_files;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>dba_temp_files是表，该表只能查询临时性表空间相关信息。</p>
</li>
</ul>
<h2 id="dba-free-space">dba_free_space</h2>
<pre><code class="language-shell">select sum(bytes)/1024/1024 from dba_free_space where tablespace_name='WYZ';
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>dba_free_space是视图，该视图只能查询永久性表空间相关信息。</p>
</li>
</ul>
<h2 id="dba-temp-free-space">dba_temp_free_space</h2>
<pre><code class="language-shell">select tablespace_name,tablespace_size/1024/1024 from dba_temp_free_space;
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>dba_temp_free_space是视图，该视图只能查询临时性表空间相关信息。</p>
</li>
</ul>
<h1 id="suse-ping-tai-kuo-zhan-oracle-biao-kong-jian-cao-zuo">Suse平台扩展Oracle表空间操作</h1>
<p>当按照安装规划创建的表空间无法适应于当前性能测试需要时，可以通过如下方法扩大相应逻辑卷，增加空间。</p>
<p>Suse操作系统下扩展Oracle表空间一般情况我们通过扩展裸设备大小的操作，而不是通过增加裸设备个数的操作来实现。因为Suse中的裸设备raw**是需要跟lv文件进行绑定的，该绑定操作需要在系统重启的时候执行。而绑定关系是配置在启动文件中的（该部分可以参考安装指南）。如果增加了裸设备还需要修改绑定关系，为了减少操作，我们一般使用修改lv/裸设备大小的方式进行。</p>
<p>假设临时表空间需要扩展表空间，步骤如下：</p>
<p>扩展lv大小</p>
<p>先找出临时表空间用到哪个裸设备，假设为raw2，然后在安装文档或/etc/raw文件中找到raw2对应绑定的lv的名称，假设为/dev/datavg/lvora_temp1，那么可以将该lv增大2G。</p>
<p><code>lvextend -L +2G /dev/datavg/lvora_temp1 </code></p>
<p>datafile是针对一般表空间</p>
<p>当扩展的是临时表空间时，替换成tmpfile</p>
<h1 id="kuo-zhan-biao-kong-jian">扩展表空间</h1>
<p>当表空间已经满时，执行数据库操作数据库会报错，例如：</p>
<pre><code class="language-shell">ORA-01653: 表 MMSG.TMP_BASE_RESULT 无法通过 8 (在表空间 MMSG 中) 扩展
ORA-06512: 在 "MMSG.LOG2DB_UTIL", line 92
ORA-06512: 在 line 1
需要扩展表空间
ORA－01653
node1:oracle:mmsgdb &gt; oerr ora 01653
01653, 00000, "unable to extend table %s.%s by %s in tablespace %s"
// *Cause:  Failed to allocate an extent of the required number of blocks for 
//          a table segment in the tablespace indicated.
// *Action: Use ALTER TABLESPACE ADD DATAFILE statement to add one or more
//          files to the tablespace indicated.
node1:oracle:mmsgdb &gt;
</code></pre>
<p>扩展操作命令如下：</p>
<pre><code>alter database datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' AUTOEXTEND ON NEXT 50M MAXSIZE UNLIMITED；
</code></pre>
<p>下面的两个命令也可以：</p>
<pre><code class="language-shell">alter tablespace mmsg add datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' size 1024M reuse;
alter database datafile '/opt/oracle/admin/mmsgdb/mmsgdata/mmsgdata01' resize 2048M;
</code></pre>
<p>扩展后重启实例，查看相关表空间是否已经扩展，</p>
<pre><code class="language-shell">select * from dba_tablespace_usage_metrics;
</code></pre>
<h1 id="undo-biao-kong-jian">Undo表空间</h1>
<h2 id="shi-yao-shi-undo">什么是UNDO</h2>
<p>Undo是数据库在撤销、回退或者改变数据所需要的数据库维护信息的一种手段。这里的数据库维护信息主要指的是在数据库提交数据之前的记录的改变等事务信息。</p>
<h2 id="undo-xin-xi-zuo-yong">UNDO信息作用</h2>
<p>1、当系统发布rollback命令时恢复数据库；</p>
<p>2、提供读一致性。</p>
<p>当系统发布rollback命令时，undo通过记录的信息将数据库中数据恢复到commit之前的状态。在数据恢复期间，undo被用来从undo表空间中撤销任何未提交到数据文件的事务。</p>
<p>对于回滚的数据：</p>
<p>delete         回滚段记录整行记录<br>
update         回滚段记录修改了的字段变化前的数据<br>
insert         回滚段记录插入记录的rawid</p>
<p>如果commit，则回滚段中简单标记事务以提交；</p>
<p>如果rollbak</p>
<p>delete         把回滚段整行记录写入数据文件中<br>
update         把回滚段记录修改了的字段变化前的数据写回去<br>
insert         把回滚段记录插入记录的rawid删除掉</p>
<p>当一个用户在访问数据时，Undo记录通过维护访问数据的前镜像数据来保证当有其他用户改变相同数据时数据库的读一致性。</p>
<p>（consisitent reads) Oralce的查询集是根据时间点来判定的。Oracle内部通过系统改变号SC作为相对时间点的标准，任何对数据库的改变都会产生SCN，对数据块的数据改变的时候会把该改变所对应的SCN记录在块中。假设查询开始的时候SCN为T，则在查询所扫描的数据块中，如果数据块的COMMIT SCN小鱼T，则查询接受该数据，如果COMMIT SCN大于T或者说还没有产生COMMIT SCN，则查询会尝试去回滚段中查找数据。这保证了数据的读取时间点的一致性。</p>
<h1 id="xi-tong-hui-gun-duan-he-yan-chi-hui-gun-duan">系统回滚段和延迟回滚段</h1>
<p>SYSTEM回滚段是创建在系统表空间中，主要用于系统级的事务和分配普通事务于其他回滚段上。当手工创建数据后需要创建普通回滚段之前必须首先创建系统回滚段。按oracle文档说，当普通事务异常多的事情可能会使用系统回滚段的情况。正常情况下，系统回滚段主要用于两个方面：一是系统事务，例如针对数据字典的操作的truncate table 和 drop table。如果truncate or drop table的过程中没有成果，则系统会根据系统回滚段中的数据字典操作信息对该DDL操作进行回退。</p>
<p>另一个方面，就是延迟回滚段(Deferred Rollback Segment)。延迟回滚段表示，当我们使一个表空间OFFLINE之后，由于表空间不可用，这个时候若有事务数据位于该空间并执行回滚命令，在client看起来该事务已经回滚，但对于数据块来说回滚并没有真正完成，这个时候数据库将该回滚信息写入系统回滚段（这就是延迟回滚段），等表空间重新ONLINE的时候，数据块从系统回滚段中将回滚信息写入表空间。</p>
<h1 id="xiang-guan-can-shu">相关参数</h1>
<pre><code class="language-shell">SQL&gt; show parameter undo

NAME                            TYPE          VALUE
------------------------------------        -----------       ------------------------------
undo_management                    string        AUTO
undo_retention                        integer      900
undo_tablespace                       string       UNDOTBS1
SQL&gt;
</code></pre>
<h1 id="undo-management">undo_management</h1>
<p>undo管理方式。undo_management设置为AUTO时，系统使用撤销表空间来管理回滚段；</p>
<p>undo_management设置为MENUAL时，系统使用回滚段。</p>
<p>Oracle推荐使用撤销表空间管理回滚段，当undo_management设置为AUTO时，必须指定一个UNDO表空间。UNDO表空间可以在数据库安装时候创建，也可在数据库安装完成后创建。</p>
<p>当数据库启动的时，oracle会自动选择第一个可用的undo表空间或者是rollbak_segment，如果没有可用的undo表空行和rollbak_segment，系统选择system rollback_segment，这种情况是不被推荐使用的。当系统运行在没有undo的情况下，系统产生一条告警信息记录告警日志。</p>
<h1 id="undo-retention">undo_retention</h1>
<p>系统提交后，回滚段的数据保留多长时间，单位是秒。</p>
<h1 id="undo-tablespace">undo_tablespace</h1>
<p>指定数据库使用哪一个撤销表空间。</p>
<h2 id="cha-xun-hui-tui-lu">查询回退率</h2>
<pre><code class="language-shell">SELECT NAME, VALUE FROM v$sysstat WHERE NAME IN ('user commits', 'transaction rollbacks');
</code></pre>
<h1 id="undo-tablespace-1">UNDO TABLESPACE</h1>
<p>UNDO TABLESPACE变的很大，我们不能缩小，这个时候我们需要考虑创建新的UNDO TABLESPACE，然后切换到这个新创建的UNDO表空间。这时即使UNDO表空间有事务也可以切换，只不过不能立即删除该表空间，切换之后等到原来的表空间中所有的事务处理完毕，并且达到undo_retention的时间后，就可以drop原来的UNDO表空间。</p>
<h1 id="biao-kong-jian-sui-pian">表空间碎片</h1>
<p>一个碎片表空间具有很多不连续的自由空间块，碎片会导致性能与空间问题，性能受到影响是因为oracle不得不扫描更多的对象区间，并有可能跨越多个物理磁盘，当数据进行磁盘碎片整理时，对象可以从多个区间压缩为一个区间，减少扫描数据时的内部oracle开销。</p>
<p>相反，一个碎片表空间影响对象存储，具有许多小的自由空间块延伸跨越多个表空间，一些对象可能不会被创建，而如果所有表空间是连续的，空间将足够用于创建该对象。通过表空间磁盘碎片整理，重新组织数据使所有小的自由块形成一个自由块。</p>
<p>当对象如表或索引随表的创建、删除、增大或减小尺寸时，会发生碎片。由于oracle只能在表空间中的、一个连续的自由空间内创建一个区间，会开始出现一些小的自由空间。当删除一个对象时，它的自由空间很有可能处于表空间中分散的地点，只能在那个自由空间中创建另一个相等或小一些的对象。</p>
<p>通过如下命令可以检查表空间的碎片，可以检查在指定的表空间中有多少自由空间段，以及它们的大小。</p>
<pre><code class="language-shell">select A.TABLESPACE_NAME,B.FILE_NAME,A.BYTES
from dba_free_space A,dba_data_files B
where A.TABLESPACE_NAME = '&amp;tablespace_name' and
A.FILE_ID=B.FILE_ID
order by bytes desc;
</code></pre>
<p>当运行这段sql代码，服务器会提示输入表空间名：</p>
<p>输入 tablespace_name 的值:</p>
<p>终端上显示如下：</p>
<img class="shadow" src="/img/in-post/oracle_sql.png" width="600">
<p>PLSQL Developer工具显示如下：</p>
<img class="shadow" src="/img/in-post/oracle_dev.png" width="600">
<p>对每一个不同的file_name，应该各有一条记录。如果没有，表空间就是碎片的。在含有碎片的表空间中表在导入导出过程中会成为用户不可用的，即数据无效。在依赖导入与导入表空间进行表空间碎片整理时，应该输入命令 alter tablespace tablespace_name coalesce。</p>
<p>如果自由空间的两个大块彼此毗邻，这条命令使它们组成一个更大的块，如果这条命令没用，必须使用导入导出以整理表空间碎片。</p>
<p>另一个需要整理表空间的原因是：是否表空间内对象含有多个区间的情况。在大多数情况下，如果对象多于5个区间，应该加以关注，</p>
<p>因为在这点之后，性能受到显著影响。</p>
<p>如下sql代码查询哪些对象具有多于5个区间：</p>
<pre><code class="language-shell">select owner,segment_name, extents from dba_segments
where extents &gt; 5 
and owner not in ('SYS','SYSTEM')
order BY EXTENTS;
</code></pre>
<p>在开始进行碎整理时，先确认已经知会到所有可能受影响的人，因为在这个操作过程中，表空间中的表将不可用。如果可能，计划在没有人使用这些表的情况下进行碎片整理。</p>
<p>使用导入导出整理一个表空间的碎片，遵循的步骤如下：</p>
<p>1、导出表空间下所有表，确认已设置了commpress=y；<br>
2、手工删除表空间中所有的表；<br>
3、合并表空间中的自由空间，使用alter tablespace tablespace_name coalesce命令完成。所有的自由空间被合并成一个块，或者与表空间的数据文件一样多的块，因为表空间中不含有对象。</p>
<h1 id="shuo-shuo-lin-shi-biao-kong-jian-temp-de-yi-chang-zhang-da">说说临时表空间Temp的异常胀大</h1>
<p>笔者接到一个做开发上线的兄弟电话，说正在试运行的系统存储过程突然变慢，而且偶然发现数据库的Temp表空间突然增加到20多G。这位兄弟不知道是不是与存储过程突然变慢有关，而且应该如何处理。----转载</p>
<h2 id="1-cong-temporary-tablespace-tan-qi">1、从Temporary Tablespace谈起</h2>
<p>表空间（Tablespace）、段对象（Segment）、分区（Extent）和数据块（Block）是Oracle逻辑层面上最重要的几个概念。其中，表空间是各个逻辑层面顶层概念，也是与Oracle物理结构文件可以建立关系的重要环节。</p>
<pre><code class="language-shell">SQL&gt; select tablespace_name, contents, logging from dba_tablespaces;

TABLESPACE_NAME               CONTENTS LOGGING
------------------------------ --------- ---------
SYSTEM                        PERMANENT LOGGING
UNDOTBS1                      UNDO     LOGGING
SYSAUX                        PERMANENT LOGGING
TEMP                          TEMPORARY NOLOGGING
USERS                         PERMANENT LOGGING
EXAMPLE                       PERMANENT NOLOGGING

6 rows selected

</code></pre>
<p>表空间从类型上有若干分类的方式，一种是按照“文件file”的大小，区别为small file tablespace和big file tablespace。另一种是按照表空间用途而定的。此种分类方法可以将表空间划分为持久化表空间（Permanent Tablespace）、Undo表空间和临时表空间（Temporary Tablespace）。</p>
<p>Temporary临时表空间是Oracle一种内部空间调控的产物。根据Oracle官方文档中的介绍，Temporary表空间主要是针对session会话自身的操作使用的。</p>
<p>当一个会话通过SQL或者PL/SQL将数据集合获取，进行大面积的sort或者group by操作时，会话会严重的消耗PGA资源。PGA是针对会话自身特有信息的一块内存区域，用于保存会话自身特有、无法与其他会话共享的信息。如果数据集很大，这样对内存PGA的资源消耗就会很大。Oracle在这个时候，就会采用类似操作系统虚拟内存技术的方法，从硬盘上借一块空间给PGA置换使用，缓解PGA的不足。</p>
<p>使用Temporary表空间的时候，是系统自动完成的临时段segment对象创建和销毁。这个过程对用户会话而言是透明的。</p>
<p>临时表空间对应的文件就是临时文件temp file，在Oracle中可以使用dba_temp_files视图进行查询。</p>
<pre><code class="language-shell">SQL&gt; col file_name for a50;
SQL&gt; select file_name, bytes/1024/1024, AUTOEXTENSIBLE from dba_temp_files;
 
FILE_NAME                                         BYTES/1024/1024 AUTOEXTENSIBLE

-------------------------------------------------- ---------------
D:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\TEMP01.DBF              123YES
</code></pre>
<p>通常，在系统创建的时候，Oracle会创建临时表空间Temp作为系统默认临时表空间Temporary Tablespace。而且，通常Temp表空间都是设置为支持自动拓展的。</p>
<h2 id="2-wen-ti-fen-xi">2、问题分析</h2>
<p>回到那位兄弟的问题，简单归纳出来就是“系统中出现批作业缓慢的现象，发现临时表空间暴增”。</p>
<p>从上面我们对于Temp表空间的分析介绍，我们可以初步认为临时表空间的暴增是一个结果，而不是一个原因。或者说，至少是某个原因的结果。</p>
<p>什么意思呢？首先，Oracle文件有自动膨胀autoextend的功能，但是却没有自动缩减的能力。临时表空间容纳的对象，都是系统创建、管理的临时段对象。当会话结束、SQL命令结果返回的时候，临时表空间的内容是可以回收的。所以，Temp表空间的自动膨胀大小结果不是一个累积的效果，而是一个峰值效果。</p>
<p>Temp表空间增加到20G，说明在系统运行的某个阶段，由于会话并发或者其他的原因，引起系统内部排序、分组等PGA高消耗操作剧烈增加，瞬时超过了Temp原有的大小。从而引发Oracle进行Temp表空间的自动拓展，拓展到当前的大小。之后会话操作结束，临时段segment对象被回收，但是文件大小不会重新回收。所以导致了Temp表空间膨胀的事实。</p>
<p>那么，有什么样的原因可能导致出现瞬时Temp空间消耗高峰呢？几种可能的情况如下：</p>
<h3 id="xi-tong-ben-shen-te-dian">系统本身特点</h3>
<p>我们说最大使用Temp表空间的就是sort和group by操作。对一些OLAP、DSS系统而言，无论是进行报表生成还是数据整理汇总析取，都伴随着海量数据的sort或者group by。一般情况下的PGA设置是无法满足如此巨大的空间需求的，必然要消耗相当的Temp表空间。根据笔者的了解，一些数据仓库性质的系统对Temp的消耗达到几十上百G是很常见的；</p>
<h3 id="ying-yong-ben-shen-dui-sql-chu-li-liang-shi-kong">应用本身对SQL处理量失控</h3>
<p>SQL是一种描述性语言，修改一条记录和修改一千万条记录的语句结构可能都是相同的。但是，对系统而言，两者的差异是天壤之别。比如，当我们尝试将获取到数据集合bulk collect到一个数组时候，要关注到可能的数据量规模。如果数据集合较小，一切都好说。但是如果数据集合达到百万级以上，那么瞬时百万条数据全部请求存放在PGA中，进而引起Temp的过量使用；</p>
<h3 id="di-san-fang-gong-ju-de-shi-yong">第三方工具的使用</h3>
<p>很多第三方工具，特别是带有数据分析处理的软件，通过专门的业务实体层封装SQL语句。一些时候，这种封装SQL进行连接、汇总时也会带来大量的Temp消耗。</p>
<h2 id="3-wen-ti-jie-jue">3、问题解决</h2>
<p>经过沟通，确认系统发生的变更情况。在最近一段时间，系统安装了BO相关组件，多用户在反复同时生成报表的时候，可能会出现Temp消耗高峰的情况。</p>
<p>同时，观察应用系统的部分代码，存在SQL处理量未受控的情况，建议开发组根据工作进度情况进行重构处理。</p>
<p>至于说特定SQL执行时间过长，通过诊断（或者AWR、ASH）确定了问题SQL，进行执行计划修正后问题解决。</p>
<p>最后说说对当前系统临时表空间的处理。在使用BO的前提下，临时表空间胀大的情况也许是不可避免的。所以建议开发组从几个方面着手：<br>
1、借助AWR报告，确定究竟是BO造成的临时表空间使用量过高还是应用本身问题；<br>
2、如果确定是BO本身问题，可以确定一个基本的峰值。将临时表空间文件设置一个增长上限，不要关闭autoextend开关；<br>
3、如果是应用本身的问题，也不要轻易关闭autoextend开关。因为如果Temp表空间需要资源而无法分配，那么前端应用会产生异常报错；<br>
4、不断诊断和重构应用代码，加入处理量控制代码，力图做到每次处理的数据量存在可控上限。防止出现瞬时处理量胀大的情况；</p>
<h2 id="4-jie-lun">4、结论</h2>
<p>这个案例，告诉我们两点思考之处：</p>
<h3 id="1-fen-qing-zhu-ci-yin-guo">1、分清主次因果</h3>
<p>数据库诊断调优是一项综合性强的技术。我们看到的大多是问题的表象，甚至是很奇怪的表象。这时候，我们就需要分析问题的根源，理清主次矛盾、孰因孰果，定位到问题的核心；</p>
<h3 id="2-fen-qing-qing-zhong-yuan-jin">2、分清轻重远近</h3>
<p>很多性能问题的根源不是某个或者某几个SQL造成的，而是和开发过程中一些习惯和细节问题日积月累起来。这种情况下，修改重构是一个过程，不可能一蹴而就。所以，调优要从远近轻重的角度制定方案。首先让应用跑起来，支持生产。之后才是将问题一点点的解决。Oracle推出的outline等技术也就是这个含义。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>UID与EUID区别</title>
    <url>/2012/03/22/difference_of_uid_euid/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Linux系统中每个进程都有2个ID，分别为用户ID（UID）和有效用户ID（EUID），UID（实际用户）是一个重要的环境变量，可用于检查当前脚本是以超级用户（root）还是普通用户的身份运行。</p>
<p>UID与EUID，两者之间有什么区别，本文介绍之。</p>
<h1 id="uid-yu-euid-de-qu-bie">UID与EUID的区别</h1>
<h2 id="cong-li-lun-shang-jie-shao-yi-xia-liang-zhe-qu-bie">从理论上介绍一下两者区别</h2>
<p>实际用户(UID)</p>
<p>实际用户ID是指运行这个进程的用户uid。这个用户uid会被设置为父进程的实际用户ID，并且在系统调用中都不会发生改变。一般情况下，登录进程会将用户登录那个shell的实际用户ID设置为 登录用户的uid，并且这个用户所有进程的实际用户ID都会继承这个值。 超级用户可能会把实际用户 ID设置修改为任意值，但是其他用户不可以。</p>
<p>有效用户</p>
<p>有效用户ID是当前进程所使用的用户ID。 权限认证一般是使用这个值。 初始时，这个ID等于实际用户ID。</p>
<h2 id="tong-guo-shi-li-zhan-shi-uid-yu-euid-de-qu-bie">通过实例展示UID与EUID的区别</h2>
<p>先来看一段perl脚本</p>
<pre><code class="language-shell">test01@node77:/home$ cat id.pl 
#!/usr/bin/perl

use warnings;
use strict;

printf "uid: %-20s euid: %-20s\n",$&lt;,$&gt;;
printf "gid: %-20s egid: %-20s\n",$(, $);

test01@node77:/home$ 
</code></pre>
<p>说明:</p>
<p>perl里面的特殊变量$&lt;、$&gt;表示uid euid; $(、$)表示gid egid。只是，$(和$)会存储一个列表，第一位表示的才是gid和egid，这个是perl的设置，不在本文讨论范围。</p>
<p>在root用户下执行，效果如下：</p>
<pre><code class="language-shell">root@node77:/home# perl id.pl 
uid: 0                    euid: 0                   
gid: 0 0                  egid: 0 0                 
root@node77:/home# 
</code></pre>
<p>非root用户下执行，效果如下：</p>
<pre><code class="language-shell">test01@node77:/home$ perl id.pl 
uid: 1000                 euid: 1000                
gid: 1000 1000            egid: 1000 1000           
test01@node77:/home$ 
</code></pre>
<p>说明：</p>
<p>第一次运行的时候，使用的是超级权限(root)，所以uid=0，gid=0；</p>
<p>第二次运行的时候，使用的是普通用户，uid=1000，gid=1000，由于没有使用setgid对gid进行改变，所以uid=gid。</p>
<h1 id="zong-jie">总结</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>有效用户ID(euid)代表它的属主，限制进程的权限</p>
</li>
<li class="lvl-2">
<p>在没有seteuid的情况下，uid=euid，guid同理</p>
</li>
<li class="lvl-2">
<p>当进程以root权限调用setuid()后，root权限会被丢弃，所以root权限下，使用setuid()更加安全</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>UID</tag>
        <tag>EUID</tag>
      </tags>
  </entry>
  <entry>
    <title>who与whoami与who an i与w的区别</title>
    <url>/2012/04/19/difference_of_who_whoami_and_so_on/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍who， w， whoami 和 who am i的区别</p>
<h1 id="shi-ji-shu-chu">实际输出</h1>
<p>当前是root用户：</p>
<pre><code class="language-shell">root@node77:~# w
 18:20:21 up  7:57,  3 users,  load average: 1.06, 1.51, 1.82
USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT
root     pts/0    1.6.72.76        10:28    4.00s  1.89s  0.02s w
root     pts/1    10.10.10.76      15:27    2:30m  0.09s  0.09s -bash
root     pts/2    172.17.74.95     18:13    6:21   0.09s  0.09s -bash
root@node77:~# 
root@node77:~# 
root@node77:~# 
root@node77:~# who
root     pts/0        2012-04-19 10:28 (1.6.72.76)
root     pts/1        2012-04-19 15:27 (10.10.10.76)
root     pts/2        2012-04-19 18:13 (172.17.74.95)
root@node77:~# 
root@node77:~# who am i
root     pts/0        2012-04-19 10:28 (1.6.72.76)
root@node77:~# 
root@node77:~# 
root@node77:~# whoami
root
</code></pre>
<p>切换到test01用户：</p>
<pre><code class="language-shell">root@node77:~# su - test01
test01@node77:~$ who am i
root     pts/0        2012-04-19 10:28 (1.6.72.76)
test01@node77:~$ 
test01@node77:~$ whoami
test01
test01@node77:~$
</code></pre>
<h1 id="ju-ti-qu-bie">具体区别</h1>
<p>w:         Show who is logged on and what they are doing<br>
who:       Show who is logged on<br>
whoami:    Print effective userid(EUID)<br>
who am i： Print effective userid(UID), even use sudo to switch users</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle pfile和spfile</title>
    <url>/2012/05/02/oracle_pfile_and_spfile/</url>
    <content><![CDATA[<h1 id="can-shu-wen-jian-de-ding-yi-zuo-yong">参数文件的定义、作用</h1>
<p>oracle数据库通过一系列参数来对数据库进行配置。这些参数是以键－值对的形式来表 示的，如：</p>
<pre><code class="language-shell">MAXLOGFILES=50
BACKGROUND_DUMP_DEST=C:\DUMP
</code></pre>
<p>其中，等号左边是参数名，右边是对应的参数的值，值的类型有多种，典型的如数字和 字符串.</p>
<p>参数文件就是存储这些参数的地方，oracle在启动时会从参数文件中读取相关的配置。</p>
<h1 id="can-shu-wen-jian-de-fen-lei">参数文件的分类</h1>
<p>在9i之前，参数文件只有一种，它是文本格式的，称为pfile，在9i及以后的版本中，新 增了服务器参数文件,称为spfile,它是二进制格式的。这两种参数文件都是用来存储参 数配置以供oracle读取的，但也有不同点，注意以下几点：</p>
<p>（1）pfile是文本文件，spfile是二进制文件；</p>
<p>（2）对于参数的配置，pfile可以直接以文本编辑器打开手工配置，而spfile不行，必 须在数据库启动后，通过sql命令进行在线修改。</p>
<p>（3）pfile配置改变后，要使用其生效，必须重新启动数据库，spfile的配置生效时限 和作用域可以由修改参数的sql命令指定，可以立即生效，也可以不立即生效。当然有些 参数的修改必须重启数据库才能生效；</p>
<p>（4）可用sql命令由pfile创建spfile,也可以由spfile创建pfile；</p>
<p>（5）如果是手动创建数据库而不是通过DBCA，则开始创建数据库时，你只能定义pfile 。因为它是文本格式的；</p>
<p>（6）oracle数据库只使用一个参数文件，要么是pfile,要么是spfile，即么如何判断 数据库当前使用的是哪一个参数文件呢？一种方法是能过create pfile来鉴别，如果当 前使用的不spfile,则相应格式的create pfile会产生错误。另一种方法是show  parameter  spfile命令，用来显示spfile的位置，如果显示的值为空，则表示使用的是pfile。</p>
<h1 id="can-shu-wen-jian-de-dong-zuo-yuan-li">参数文件的动作原理</h1>
<p>oracle实例在启动时，会去读取参数文件中的配置，这个过程是这样的：</p>
<p>数据库的startup命令中可以指定以哪个pfile来启动，但是请注意，只能指定pfile,不 能指定spfile。</p>
<p>当使用不带pfile 子句的startup 命令时，Oracle 将从平台指定的默认位置上的服务器 参数文件（spfile） 中读取初始化参数。Oracle查找spfile或者创通的init.ora的顺序 是：在平台指定的默认位置上，Oracle首先查找名为spfile$ORACLE_SID.ora的文件，如 果没有就查找spfile.ora文件，还没有的话，就找init$ORACLE_SID.ora文件。</p>
<p>在$ORACLE_BASE\admin\db_name\spfile下，你很可能可以看到一个类似这样init.ora.1 92003215317]名字的文件，这就是初始化参数文件，只是跟上了时间戳。对于Oracle920 ,缺省的就使用spfile启动，但是这个spfile不是凭空而来，而是根据这个文件创建而来 ，你可以去掉这个长后缀，就是标准的pfile文件了。</p>
<p>对于Windows NT 和Windows 2000  ，其位置是：$ORACLE_HOME\database\spfile$ORACLE_SID.ora</p>
<p>对于LINUX，可以通过show parameter spfile。</p>
<pre><code class="language-shell">SQL&gt; show parameter spfile

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
spfile                               string      /opt/oracle/product/11g/dbs/sp
                                                 filemmsgdb.ora
</code></pre>
<p>数据库在启动后，参数的配置值可以通过查询数据字典v$parameter得到。</p>
<h1 id="can-shu-wen-jian-de-xiu-gai-fang-fa">参数文件的修改方法</h1>
<p>分为手动修改和在线修改。</p>
<p>手动修改用于修改pfile，直接用文本编辑打开pfile修改。要使用修改生效，须重启数据库。在线修改是在数据库运行时，用alter system命令进行修改，命令如下：</p>
<pre><code class="language-shell">sql&gt;alter system set job_queue_processed=50 scope=MEMORY;
</code></pre>
<p>注意，scope=MEMORY表示应用范围，取值如下：</p>
<p>SPFILE:修改只对SPFILE有效，不影响当前实例，需要重启数据库才能生效；</p>
<p>MEMORY:修改只对内存有效，即只对当前实例有效，且立即生效，但不会保存到SPFILE, 数据库重启后此配置丢失；</p>
<p>BOTH:顾名思义，包含以上两种，立即生效，且永久生效。</p>
<p>对于ALTER SYSTEM的参数修改命令，请注意以下几点：</p>
<p>（1）如果当前实例使用的是pfile而非spfile,则scope=spfile或scope=both会产生错 误；</p>
<p>（2）如果实例以pfile启动，则scope的默认值为MEMORY,若以spfile启动，则默认值为 BOTH；</p>
<p>（3）可以使用DEFERRED表示所作修改只适用于将来的会话，还可以使用COMMENT写入注 释，如：ALTER SYSTEM SET JOB_QUEUE_PROCESSES=50 SCOPE=BOTH DEFERRED COMMENT=" 注释"</p>
<p>（4）删除参数的方法如下：<code>ALTER SYSTEM SET PARAMETER='';</code></p>
<h1 id="chuang-jian-can-shu-wen-jian">创建参数文件</h1>
<p>对于pfile，你可以用文本编辑器直接手工编辑一个，也可以使用create pfile命令 从spfile创建，如：<code>CREATE PFILE='/opt/oracle/product/11g/dbs/pfilemmsgdb.ora' FROM  SPFILE='/opt/oracle/product/11g/dbs/spfilemmsgdb.ora '</code>,或者从当前实例所使用的spfile创建：<code>create  pfile='/opt/oracle/product/11g/dbs/pfilemmsgdb.ora ' from spfile</code>。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>关闭Oracle用户多次登录失败锁定账户的功能</title>
    <url>/2012/05/24/oracle_lock_account/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>有时候工作环境密码太多，切换不同的环境，难免要输入多次密码，但万一达到尝试上限了，怎么破？ 有的环境只能等待了。。。。。。</p>
<p>本文介绍关闭数据库多次登录失败锁定账户的功能，执行此任务可以设置单个用户连续登录失败的次数为不限制。在Oracle11g默认配置下，如果单个账户如果连续10次登录失败，系统将会锁定账户，只能通过对账户解锁。</p>
<h1 id="ru-he-guan-bi-shu-ju-ku-duo-ci-deng-lu-shi-bai-suo-ding-zhang-hu-de-gong-neng">如何关闭数据库多次登录失败锁定账户的功能</h1>
<p>关闭该功能，具体操作如下：</p>
<p>(1)查询当前允许登录失败次数</p>
<p>以oracle用户登录，连接数据库。</p>
<pre><code class="language-shell">$ sqlplus "/ as sysdba"
</code></pre>
<p>查看系统允许用户登录失败的次数:</p>
<pre><code class="language-shell">SQL&gt; select LIMIT from dba_profiles where PROFILE='DEFAULT' and RESOURCE_NAME='FAILED_LOGIN_ATTEMPTS';
屏幕显示中有如下信息。（仅供参考）
LIMIT
--------------------------------------------------------------------------------
10
</code></pre>
<p>(2)修改允许登录失败次数</p>
<p>修改系统允许用户登录失败的次数为不限制:</p>
<pre><code class="language-shell">SQL&gt; ALTER PROFILE DEFAULT LIMIT FAILED_LOGIN_ATTEMPTS UNLIMITED;
屏幕显示中有如下信息。（仅供参考）
Profile altered.
</code></pre>
<p>(3)确认修改效果</p>
<p>查看修改后的允许用户登录失败的次数。</p>
<pre><code class="language-shell">SQL&gt; select LIMIT from dba_profiles where PROFILE='DEFAULT' and RESOURCE_NAME='FAILED_LOGIN_ATTEMPTS';
屏幕显示中有如下信息。（仅供参考）
LIMIT
--------------------------------------------------------------------------------
UNLIMITED
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle案例--迁移数据库控制文件、数据文件、重做日志文件</title>
    <url>/2012/07/19/oracle_troubleshoot_migrate_database_files/</url>
    <content><![CDATA[<h1 id="qian-yi-shu-ju-ku-kong-zhi-wen-jian-shu-ju-wen-jian-zhong-zuo-ri-zhi-wen-jian">迁移数据库控制文件、数据文件、重做日志文件</h1>
<h2 id="gua-yong-tiao-jian">适用条件</h2>
<p>数据文件、控制文件较大，占用当前磁盘空间，而且当前磁盘剩余空间严重不足。</p>
<h2 id="cao-zuo-bu-zou">操作步骤</h2>
<h3 id="shou-xian-yi-dong-kong-zhi-wen-jian">首先，移动控制文件</h3>
<pre><code class="language-shell">        sqlplus / as sysdba 
        create pfile from spfile;  
        shutdown immdiate 
</code></pre>
<h3 id="jie-zhao-xiu-gai-pfile-wen-jian-zhong-kong-zhi-wen-jian-de-wei-zhi">接着，修改pfile文件中控制文件的位置</h3>
<p>如：原先控制文件在/opt/oracle/oradata/mmsgdb/目录下，修改为/home/oradata/mmsgdb/ (这个目录手工建立，并改变属主)</p>
<p>(1) OS level级去mv 控制文件 到 新的目录下</p>
<p>(2) startup pfile=‘pfile文件路径’</p>
<p>(3) create spfile from pfile</p>
<p>注：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>数据库启动可以指定使用哪个pfile文件，但不能指定使用spfile文件。</p>
</li>
</ul>
<h3 id="qi-ci-shu-ju-wen-jian">其次，数据文件</h3>
<pre><code class="language-shell">         shutdown immediate
         os level 级  mv操作
         startup mount
         alter database rename datafile ‘xxxx01.dbf’,’xxxx02.dbf’ to ‘xxxx03.dbf’,’xxx04.dbf’;
         alter database open;  //如果还需要移动重做日志文件，这里可不启动数据库
</code></pre>
<h3 id="zai-zhe-zhong-zuo-ri-zhi-wen-jian">再者，重做日志文件</h3>
<pre><code class="language-shell">        shutdown immediate
        os level nv重做日志文件
        startup mount
        alter database rename file '/opt/oracle/oradata/mmsgdb/redo01.log' to '/home/oradate/redo01.log‘;
        alter database rename file '/opt/oracle/oradata/mmsgdb/redo02.log' to '/home/oradate/redo02.log‘;
        alter database rename file '/opt/oracle/oradata/mmsgdb/redo03.log' to '/home/oradate/redo03.log‘;
        alter database open;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell和Perl调用sqlplus的几种操作</title>
    <url>/2012/08/19/call_sqlplus_by_shell_perl/</url>
    <content><![CDATA[<h1 id="shell-diao-yong-sqlplus-ge-chong-qing-kuang">Shell调用sqlplus各种情况</h1>
<h2 id="1-zui-jian-dan-de-shell-li-diao-yong-sqlplus">1、最简单的shell里调用sqlplus</h2>
<pre><code class="language-shell">$ vi test1.sh

#!/bin/bash
sqlplus -S /nolog &gt; result.log &lt;&lt;EOF
set heading off feedback off pagesize 0 verify off echo off
conn u_test/iamwangnc
select * from tab;
exit
EOF

$ chmod +x test1.sh
$ ./test1.sh
</code></pre>
<h2 id="2-ba-sqlplus-zhi-xing-jie-guo-chuan-di-gei-shell-fang-fa-yi">2、把sqlplus执行结果传递给shell方法一</h2>
<p>注意sqlplus段使用老板键`了, 赋变量的等号两侧不能有空格.</p>
<pre><code class="language-shell">$ vi test2.sh

#!/bin/bash
VALUE=`sqlplus -S /nolog &lt;&lt;EOF
set heading off feedback off pagesize 0 verify off echo off numwidth 4
conn u_test/iamwangnc
select count(*) from tab;
exit
EOF`
if [ "$VALUE" -gt 0 ]; then
        echo "The number of rows is $VALUE."
        exit 0
else
        echo "There is no row in the table."
fi

$ chmod +x test2.sh
$ ./test2.sh
</code></pre>
<h2 id="3-ba-sqlplus-zhi-xing-jie-guo-chuan-di-gei-shell-fang-fa-er">3、把sqlplus执行结果传递给shell方法二</h2>
<p>注意sqlplus段使用 col … new_value … 定义了变量并带参数exit, 然后自动赋给了shell的$?</p>
<pre><code class="language-shell">$ vi test3.sh

#!/bin/bash
sqlplus -S /nolog &gt; result.log &lt;&lt;EOF
set heading off feedback off pagesize 0 verify off echo off numwidth 4
conn u_test/iamwangnc
col coun new_value v_coun
select count(*) coun from tab;
exit v_coun
EOF
VALUE="$?"
echo "The number of rows is $VALUE."

$ chmod +x test3.sh
$ ./test3.sh
</code></pre>
<h2 id="4-ba-shell-cheng-xu-can-shu-chuan-di-gei-sqlplus">4、把shell程序参数传递给sqlplus</h2>
<p>$1表示第一个参数, sqlplus里可以直接使用, 赋变量的等号两侧不能有空格不能有空格.</p>
<pre><code class="language-shell">$ vi test4.sh

#!/bin/bash
NAME="$1"
sqlplus -S u_test/iamwangnc &lt;&lt;EOF
select * from tab where tname = upper('$NAME');
exit
EOF

$ chmod +x test4.sh
$ ./test4.sh ttt
</code></pre>
<h2 id="5-wei-liao-an-quan-yao-qiu-mei-ci-zhi-xing-shell-du-shou-gong-shu-ru-mi-ma">5、为了安全要求每次执行shell都手工输入密码</h2>
<pre><code class="language-shell">$ vi test5.sh

#!/bin/bash
echo -n "Enter password for u_test:"
read PASSWD
sqlplus -S /nolog &lt;&lt;EOF
conn u_test/$PASSWD
select * from tab;
exit
EOF

$ chmod +x test5.sh
$ ./test5.sh
</code></pre>
<h2 id="6-wei-liao-an-quan-cong-wen-jian-du-qu-mi-ma">6、为了安全从文件读取密码</h2>
<p>对密码文件设置权限, 只有用户自己才能读写.</p>
<pre><code class="language-shell">$ echo 'iamwangnc' &gt; u_test.txt
$ chmod g-rwx,o-rwx u_test.txt
$ vi test6.sh

#!/bin/bash
PASSWD=`cat u_test.txt`
sqlplus -S /nolog &lt;&lt;EOF
conn u_test/$PASSWD
select * from tab;
exit
EOF

$ chmod +x test6.sh
$ ./test6.sh
</code></pre>
<h1 id="perl-diao-yong-sqlplus-ge-chong-qing-kuang">Perl调用sqlplus各种情况</h1>
<h2 id="1-zui-jian-dan-de-perl-diao-yong-sqlplus">1、最简单的perl调用sqlplus</h2>
<pre><code class="language-shell">system(“sqlplus $user/$passwd\@$sid”);
</code></pre>
<h2 id="2-tong-guo-wen-jian-ju-bing">2、通过文件句柄</h2>
<pre><code class="language-shell">    open(SQLPLUS, "|sqlplus -S $USER/$USERPASS\@$SID &gt;/dev/null") || die "Execute sqlplus loging error!\n";
    print SQLPLUS "set feedback off\nset sqlnumber off\n";
    print SQLPLUS "set pagesize 0\n";
    print SQLPLUS "set trimspool off\n";
    print SQLPLUS "set sqlblanklines off\n";
    print SQLPLUS "spool $cur_path/dropjob.txt\n";
    print SQLPLUS "select 'drop job ' || job || ';' from user_jobs;\n";
    print SQLPLUS "spool $cur_path/dropobj.txt\n";    
    print SQLPLUS "select 'drop ' || object_type || ' ' || object_name || ';' from user_objects;\n";
    print SQLPLUS "spool off\n";
    close(SQLPLUS) || die "Execute sqlplus exit error!\n";  
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>手动对CentoOS6 or CentoOS7做网卡绑定</title>
    <url>/2012/08/29/network_bond_by_centos/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>一直使用SUSE，今天切换了一个环境做测试，是Centos6.3，发现不会对Centos做bond了，mark一下操作记录, 本操作在Centos6 和 7 都适用.</p>
<h1 id="cao-zuo-bu-zou">操作步骤</h1>
<h2 id="1-ifconfig-cha-kan-wang-qia-xin-xi">1、ifconfig查看网卡信息</h2>
<pre><code class="language-shell">eth0      Link encap:Ethernet  HWaddr EC:38:8F:79:1B:F0  
          inet addr:172.18.112.11  Bcast:172.18.112.255  Mask:255.255.255.0
          inet6 addr: fe80::ee38:8fff:fe79:1bf0/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:2743 errors:0 dropped:0 overruns:0 frame:0
          TX packets:1958 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:689409 (673.2 KiB)  TX bytes:318047 (310.5 KiB)
          Memory:94d00000-94e00000 

eth1      Link encap:Ethernet  HWaddr EC:38:8F:79:1B:F1  
          inet6 addr: fe80::ee38:8fff:fe79:1bf1/64 Scope:Link
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:38 errors:0 dropped:0 overruns:0 frame:0
          TX packets:6 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:3564 (3.4 KiB)  TX bytes:468 (468.0 b)
          Memory:94c00000-94d00000
</code></pre>
<h2 id="2-bei-fen-yuan-wang-qia-xin-xi">2、备份原网卡信息</h2>
<p>进入 <code>/etc/sysconfig/network-scripts</code>，创建backup目录，并将eth0和eth1网卡配置文件信息拷贝到新创建的backup目录下</p>
<pre><code class="language-shell">mkdir backup
cp ifcfg-eth0 ifcfg-eth1 ./backup
</code></pre>
<h2 id="3-bang-ding-wang-qia">3、绑定网卡</h2>
<p>修改ifcfg-bond1内容</p>
<p><code>/etc/sysconfig/network-scripts </code>目录下，创建ifcfg-bond1文件，并添加如下内容：</p>
<pre><code class="language-shell">DEVICE=bond1
BOOTPROTO=none
ONBOOT=yes
TYPE=Ethernet
IPADDR=172.18.112.11
NETMASK=255.255.255.0
GATEWAY=172.18.112.1
修改ifcfg-eth0和ifcfg-eth1内容
ifcfg-eth0内容
DEVICE=eth0
MASTER=bond1
SLAVE=yes
BOOTPROTO=none
ONBOOT=yes
TYPE=Ethernet
USERCTL=no
</code></pre>
<p>ifcfg-eth1内容</p>
<pre><code class="language-shell">DEVICE=eth1
MASTER=bond1
SLAVE=yes
BOOTPROTO=none
ONBOOT=yes
TYPE=Ethernet
USERCTL=no
</code></pre>
<p>修改dist.conf文件,增加如下内容</p>
<pre><code class="language-shell">vi /etc/modprobe.d/dist.conf
alias bond1 bonding
options bond1 miimon=100 mode=1
</code></pre>
<p>重启网卡服务</p>
<pre><code class="language-shell">/etc/init.d/network restart
</code></pre>
<h1 id="cha-kan-bang-ding-de-wang-qia-xin-xi">查看绑定的网卡信息</h1>
<p>执行ifconfig命令</p>
<p>如果ifconfig查看，并没有发现有bond1网卡信息，可通过如下方法进行解决</p>
<pre><code class="language-shell">service NetworkManager stop
service network restart
ifconfig查看bond信息
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle字符集</title>
    <url>/2012/09/02/oracle_lang/</url>
    <content><![CDATA[<h1 id="oracle-shu-ju-ku-zi-fu-ji">Oracle数据库字符集</h1>
<p>在不同数据库做数据迁移、同其它系统交换数据等，常常因为字符集不同而导致迁移失败或数据库内数据变成乱码。现在将oracle字符集相关的知识做个简单总结。</p>
<h1 id="shi-yao-shi-oracle-zi-fu-ji">什么是oracle字符集</h1>
<p>Oracle字符集是一个字节数据的解释的符号集合,有大小之分,有相互的包容关系。ORACLE 支持国家语言的体系结构允许你使用本地化语言来存储，处理，检索数据。它使数据库工具，错误消息，排序次序，日期，时间，货币，数字，和日历自动适应本地化语言和平台。</p>
<p>影响oracle数据库字符集最重要的参数是NLS_LANG参数。它的格式如下:</p>
<p><code>NLS_LANG = language_territory.charset</code></p>
<p>它有三个组成部分(语言、地域和字符集)，每个成分控制了NLS子集的特性。其中:</p>
<p>(1)Language 指定服务器消息的语言;</p>
<p>(2)territory 指定服务器的日期和数字格式;</p>
<p>(3)charset 指定字符集。如:AMERICAN _ AMERICA. ZHS16GBK</p>
<p>从NLS_LANG的组成我们可以看出，真正影响数据库字符集的其实是第三部分。所以两个数据库之间的字符集只要第三部分一样就可以相互导入导出数据，前面影响的只是提示信息是中文还是英文。</p>
<h1 id="ru-he-cha-xun-oracle-de-zi-fu-ji">如何查询Oracle的字符集</h1>
<p>很多人都碰到过因为字符集不同而使数据导入失败的情况。这涉及三方面的字符集，一是oracel server端的字符集，二是oracle client端的字符集;三是dmp文件的字符集。在做数据导入的时候，需要这三个字符集都一致才能正确导入。</p>
<p>(1)查询oracle server端的字符集</p>
<p>有很多种方法可以查出oracle server端的字符集，比较直观的查询方法是以下这种:</p>
<pre><code class="language-shell">SQL&gt; select userenv('language') from dual;
AMERICAN _ AMERICA. ZHS16GBK
</code></pre>
<p>(2)查询dmp文件的字符集</p>
<p>用oracle的exp工具导出的dmp文件也包含了字符集信息，dmp文件的第2和第3个字节记录了dmp文件的字符集。如果dmp文件不大，比如只有几M或几十M，可以用UltraEdit打开(16进制方式)，看第2第3个字节的内容，如0354，然后用以下SQL查出它对应的字符集:</p>
<pre><code class="language-shell">SQL&gt; select nls_charset_name(to_number('0354','xxxx')) from dual;
ZHS16GBK
</code></pre>
<p>如果dmp文件很大，比如有2G以上(这也是最常见的情况)，用文本编辑器打开很慢或者完全打不开，可以用以下命令(在unix主机上)：</p>
<p><code>cat exp.dmp |od -x|head -1|awk '{print $2 $3}'|cut -c 3-6 </code></p>
<p>修改为：</p>
<p><code>cat exp.dmp | od -h | head -1 | awk '{print substr($2,3,4) substr($3,3,4)}' </code></p>
<p>然后用上述SQL也可以得到它对应的字符集。</p>
<p>(3)查询oracle client端的字符集</p>
<p>在windows平台下，就是注册表里面相应OracleHome的NLS_LANG。还可以在dos窗口里面自己设置，比如：</p>
<p><code>set nls_lang=AMERICAN_AMERICA.ZHS16GBK </code>, 这样就只影响这个窗口里面的环境变量。</p>
<p>在unix平台下，就是环境变量NLS_LANG。</p>
<pre><code class="language-shell">$echo $NLS_LANG
AMERICAN_AMERICA.ZHS16GBK
</code></pre>
<p>如果检查的结果发现server端与client端字符集不一致，请统一修改为同server端相同的字符集。</p>
<h1 id="xiu-gai-oracle-de-zi-fu-ji">修改oracle的字符集</h1>
<p>oracle的字符集有互相的包容关系。如us7ascii就是zhs16gbk的子集,从us7ascii到zhs16gbk不会有数据解释上的问题,不会有数据丢失。在所有的字符集中UTF-8是最大,因为它基于unicode,双字节保存字符(也因此在存储空间上占用更多)。</p>
<p>一旦数据库创建后，数据库的字符集理论上讲是不能改变的。因此，在设计和安装之初考虑使用哪一种字符集十分重要。如下图所示：</p>
<img class="shadow" src="/img/in-post/oracle_lang.png" width="1200">
<p>根据Oracle的官方说明，字符集的转换是从子集到超集受支持,反之不行。如果两种字符集之间根本没有子集和超集的关系，那么字符集的转换是不受oracle支持的。对数据库server而言，错误的修改字符集将会导致很多不可测的后果，可能会严重影响数据库的正常运行，所以在修改之前一定要确认两种字符集是否存在子集和超集的关系。一般来说，除非万不得已，我们不建议修改oracle数据库server端的字符集。特别说明，我们最常用的两种字符集ZHS16GBK和ZHS16CGB231280之间不存在子集和超集关系，因此理论上讲这两种字符集之间的相互转换不受支持。</p>
<p>(1)修改server端字符集(不建议使用)</p>
<p>在oracle 8之前，可以用直接修改数据字典表props$来改变数据库的字符集。但oracle8之后，至少有三张系统表记录了数据库字符集的信息，只改props$表并不完全，可能引起严重的后果。正确的修改方法如下:</p>
<pre><code class="language-shell">　　$sqlplus /nolog
　　SQL&gt;conn / as sysdba;
　　若此时数据库服务器已启动，则先执行SHUTDOWN IMMEDIATE命令关闭数据库服务器，然后执行以下命令:
　　SQL&gt;STARTUP MOUNT;
　　SQL&gt;ALTER SYSTEM ENABLE RESTRICTED SESSION;
　　SQL&gt;ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;
　　SQL&gt;ALTER SYSTEM SET AQ_TM_PROCESSES=0;
　　SQL&gt;ALTER DATABASE OPEN;
　　SQL&gt;ALTER DATABASE CHARACTER SET ZHS16GBK;
　　SQL&gt;ALTER DATABASE national CHARACTER SET ZHS16GBK;
　　SQL&gt;SHUTDOWN IMMEDIATE;
　　SQL&gt;STARTUP
</code></pre>
<p>(2)修改dmp文件字符集</p>
<p>上文说过，dmp文件的第2第3字节记录了字符集信息，因此直接修改dmp文件的第2第3字节的内容就可以‘骗’过oracle的检查。这样做理论上也仅是从子集到超集可以修改，但很多情况下在没有子集和超集关系的情况下也可以修改，我们常用的一些字符集，如US7ASCII，WE8ISO8859P1，ZHS16CGB231280，ZHS16GBK基本都可以改。因为改的只是dmp文件，所以影响不大。</p>
<p>具体的修改方法比较多，最简单的就是直接用UltraEdit修改dmp文件的第2和第3个字节。比如想将dmp文件的字符集改为ZHS16GBK，可以用以下SQL查出该种字符集对应的16进制代码:</p>
<pre><code class="language-shell">SQL&gt; select to_char(nls_charset_id('ZHS16GBK'), 'xxxx') from dual;

TO_CH
-----
  354

SQL&gt;
</code></pre>
<p>然后将dmp文件的2、3字节修改为0354即可。</p>
<p>如果dmp文件很大，用ue无法打开，就需要用程序的方法了，这里不做叙述。</p>
<h1 id="xiao-jie">小结</h1>
<h2 id="zi-fu-ji">字符集</h2>
<p>将特定的符号集编码为计算机能够处理的数值。</p>
<h2 id="zi-fu-ji-jian-de-zhuan-huan">字符集间的转换</h2>
<p>对于在源字符集与目标字符集都存在的符号，理论上转换将不会产生信息丢失；而对于在源字符集中存在而在目标字符集中不存在的符号，理论上转换将会产生信息丢失。</p>
<h2 id="shu-ju-ku-zi-fu-ji">数据库字符集</h2>
<p>选择能够包含所有将要存储的信息符号的字符集。</p>
<h2 id="ke-hu-duan-zi-fu-ji-she-zhi">客户端字符集设置</h2>
<p>指明客户端操作系统缺省使用的字符集。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>消息网关组性能数据收集</title>
    <url>/2012/11/12/gw_performance/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>之前在网关测试组，每个迭代版本都需要进行性能测试，每次测试，除去环境部署外，最大的工作就是性能数据的收集以及分析、绘图了。</p>
<p>做成一个小工具，支持组内所有产品，根据配置文件的设定，自动进行数据的收集，通过excel宏，分析性能数据，并绘制成图在excle中展示。</p>
<h1 id="dai-ma">代码</h1>
<p>具体代码位置，在：</p>
<p><a href="https://github.com/gavin-wang-note/gw_performance.git">https://github.com/gavin-wang-note/gw_performance.git</a></p>
<p>已开源。</p>
<h1 id="excel-shi-yi-tu">excel 示意图</h1>
<img class="shadow" src="/img/in-post/excel_eg.png" width="1200">
]]></content>
      <categories>
        <category>performance</category>
        <category>perl</category>
      </categories>
      <tags>
        <tag>performance</tag>
        <tag>perl</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle补丁</title>
    <url>/2012/12/21/oracle_patch/</url>
    <content><![CDATA[<h1 id="guan-yu-bu-ding">关于补丁</h1>
<p>金无足赤，人无完人，oracle也一样，补丁天天出，打补丁就成了日常工作中常做的事。对于给数据库打补丁，个人建议如下：</p>
<p>1、大补丁（跨版本的补丁）—尽可能在安装oracle软件后，安装database前进行版本升级，实在不可避免，在有database的数据库上进行大补丁的升级操作，往往会破坏数据库的数据字典，详见博主的《Oracle升级碰到的问题》之ORA-01092。</p>
<p>2、小补丁—这个没影响，一般是在也只能在安装有database的数据库上进行升级操作，需要注意一点是：补丁的卸载，由于补丁与补丁之间有相互依赖关系，下载某补丁时，可能顺带卸载了其他的补丁。</p>
<h1 id="bu-ding-an-zhuang">补丁安装</h1>
<p>%vi .cshrc</p>
<p>修改PATH行在该行添加如下内容：</p>
<pre><code class="language-shell">:$ORACLE_HOME/Opatch:
%cd 6650132
%opatch apply
</code></pre>
<h1 id="cha-kan-opatch-ban-ben">查看opatch版本</h1>
<pre><code class="language-shell">oracle@GW_8:~&gt; opatch version
Invoking OPatch 11.1.0.6.2

OPatch Version: 11.1.0.6.2

OPatch succeeded.
</code></pre>
<h1 id="cha-kan-xi-tong-zhong-yi-jing-da-shang-de-one-off-bu-ding">查看系统中已经打上的one-off补丁</h1>
<pre><code class="language-shell">oracle@GW_8:~&gt; opatch lsinventory
Invoking OPatch 11.1.0.6.2

Oracle Interim Patch Installer version 11.1.0.6.2
Copyright (c) 2007, Oracle Corporation.  All rights reserved.


Oracle Home       : /opt/oracle/product/11g
Central Inventory : /opt/oracle/oraInventory
   from           : /etc/oraInst.loc
OPatch version    : 11.1.0.6.2
OUI version       : 11.1.0.7.0
OUI location      : /opt/oracle/product/11g/oui
Log file location : /opt/oracle/product/11g/cfgtoollogs/opatch/opatch2012-12-05_08-47-10AM.log

Lsinventory Output file location : /opt/oracle/product/11g/cfgtoollogs/opatch/lsinv/lsinventory2012-12-05_08-47-10AM.txt

--------------------------------------------------------------------------------
Installed Top-level Products (2): 

Oracle Database 11g                                                  11.1.0.6.0
Oracle Database 11g Patch Set 1                                      11.1.0.7.0
There are 2 products installed in this Oracle Home.


There are no Interim patches installed in this Oracle Home.


--------------------------------------------------------------------------------

OPatch succeeded.
</code></pre>
<p>执行该命令，如果报错</p>
<pre><code class="language-shell">oracle@GW_8:~&gt; opatch lsinventory
-bash: opatcher: command not found
</code></pre>
<p>请oracle操作系统用户环境中做如下配置</p>
<pre><code class="language-shell">export PATH=$ORACLE_HOME/OPatch:$PATH
</code></pre>
<p>source生效后重新执行 <code>opatch lsinventory</code> 命令。</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>清除Oracle数据库中所有表、视图、触发器</title>
    <url>/2013/01/25/clean_all_data_in_db/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在网关组做产品测试的时候，经常要安装环境，部署产品，其中涉及到产品部署刷库，由于组内有多套产品，每套产品所需的表名称皆不仅相同，又互补兼容，在切换到另外一个产品进行测试的时候，不想重做数据库，或者重做表空间来进行数据数据的清理，故而想用一个脚本来清理掉当前数据库环境中的所有的表、视图以及触发器，更换被测产品时，直接先抹掉当前数据，执行下个产品的刷库脚本即可。</p>
<h1 id="qing-li-jiao-ben">清理脚本</h1>
<p>使用<code>perl</code>语言编写（那个时候，组内都用 <code>perl</code>，初学，水平有限，望请海涵。。。）</p>
<p>直接上脚本</p>
<pre><code class="language-shell">#!/usr/bin/perl
use warnings;
use strict;
use Cwd;

################################################################################
#    ######################################################################    #
#   #      说明：   清除当前数据库用户中所有表、视图、存储过程等数据       #   #
#   #      使用：   perl   cls_db.pl                                       #   #
#   #      AUTH：   wangyunzeng                                            #   #
#   #      VER ：   1.0                                                    #   #
#   #      TIME：   2013-01-25   14:52   create                            #   #
#    ######################################################################    #
################################################################################


#说明
$~="CLEAR";
write;
format CLEAR =

--------------------------------------------------------------------------------
说明：
    
    此脚本，清除数据库应用用户下所有资源，包括：表、视图、存储过程、包、包体、

    JOB、Sequence、TRIGGER

--------------------------------------------------------------------------------
.

#当前路径
my $cur_path=getcwd;

#输入数据库用户。口令与SID信息，并校验
my $USER=$ARGV[0];
my $USERPASS=$ARGV[1];
my $SID =$ARGV[2];


#使用方法
if(@ARGV !=3)
{
    print "\n【使用方法】
    
         perl cls_db.pl username  passwd  sid\n\n";
    
    exit;
}
else
{
    #检查下
    &amp;check;
            
    system("which sqlplus&gt;/dev/null");
    if($? eq "0")
    {
        #print '-' x 80,"\n";
        
        #先导出，然后再清理
        print "\n是否需要导出当前用户下数据，[yes/no]?\n\n";
        
        my $response=&lt;STDIN&gt;;
        $response=lc($response);
        chomp($response);
        
        if($response eq "y" || $response eq "yes")
        {
            if(-f "$cur_path/exp_$USER.dmp")
            {
                system("rm -f $cur_path/exp_$USER.dmp");
            }
            print "\n开始导出数据到dmp文件\n";
            system("exp $USER/$USERPASS\@$SID file=$cur_path/exp_$USER.dmp");
        }
        elsif($response eq "n" || $response eq "no")
        {
            print "\n不需要导出当前用户下数据到dmp文件.\n";
        }
        else
        {
            print "\n[yes/no]输入错误，不进行备份操作，直接进行清理.\n\n";
        }
        
        print '-' x 80,"\n";
        
        print "\n开始清理当前数据库下所有对象.......\n";
        
        
        #调用子函数
        &amp;expinfo;
        &amp;dropops;
        
        print '-' x 80,"\n";
    }
    else
    {
       print "\n不支持的数据库类型，程序退出!\n\n";
       print '-' x 60,"\n";
       exit;
    }   
}



####################################定义子函数##################################
##对输入的用户名、口令和SID校验
sub check
{
   if(!$USER || $USER eq "" || $USER eq "sys" || $USER eq "system" || $USER eq "scott" || $USER eq "sysman" || $USER eq "rman")
   {
       print "\n输入数据库用户名有误，不能为空、不能为sys、system、scott、sysman或rman用户，程序退出执行!\n\n";
       exit;
   }
   elsif(!$USERPASS || $USERPASS eq "")
   {
       print "\n输入数据库口令有误，不能为空，程序退出执行!\n\n";
       exit;    
   }
   elsif(!$SID || $SID eq "")
   {
       print "\n输入数据库SID有误，不能为空，程序退出执行!\n\n";
       exit;      
   }
}


##导出当前数据库中表名、视图名等到文件
sub expinfo
{
    open(SQLPLUS, "|sqlplus -S $USER/$USERPASS\@$SID &gt;/dev/null") || die "Execute sqlplus loging error!\n";
    print SQLPLUS "set feedback off\nset sqlnumber off\n";
    print SQLPLUS "set pagesize 0\n";
    print SQLPLUS "set trimspool off\n";
    print SQLPLUS "set sqlblanklines off\n";
    print SQLPLUS "spool $cur_path/dropjob.txt\n";
    print SQLPLUS "select 'drop job ' || job || ';' from user_jobs;\n";
    print SQLPLUS "spool $cur_path/dropobj.txt\n";    
    print SQLPLUS "select 'drop ' || object_type || ' ' || object_name || ';' from user_objects;\n";
    print SQLPLUS "spool off\n";
    close(SQLPLUS) || die "Execute sqlplus exit error!\n";    
}

##执行删除操作
sub dropops
{
    ##判断文件是否存在
    (-f "$cur_path/dropjob.txt") || die "\n File [dropjob.txt] is not eixt,$!\n\n";
    (-f "$cur_path/dropobj.txt") || die "\n File [dropobj.txt] is not eixt,$!\n\n";
    
    system("cat $cur_path/dropjob.txt $cur_path/dropobj.txt &gt; $cur_path/dropinfo.txt");
    
    unlink("$cur_path/dropjob.txt");
    unlink("$cur_path/dropobj.txt");
    
    #执行清理操作
    open(SQLPLUS, "|sqlplus -S $USER/$USERPASS\@$SID &gt;/dev/null") || die "Execute sqlplus loging error!\n";
    print SQLPLUS "\@$cur_path/dropinfo.txt\n";
    close(SQLPLUS) || die "Execute sqlplus exit error!\n";     
}
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
        <category>perl</category>
      </categories>
      <tags>
        <tag>oracle</tag>
        <tag>perl</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle SQL*Plus</title>
    <url>/2013/02/01/oracle_sql_plus/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>Oracle SQL*Plus是连接Oracle常用的工具，本文介绍这个工具的常用命令行。</p>
<h1 id="oracle-de-sql-plus-gong-ju-zhong-qing-ping">Oracle的SQL*Plus工具中清屏</h1>
<p>有时候SQL*Plus工具中输出的信息过多，想清除当前的信息，如同Linux系统的清屏操作。</p>
<p>汇总了oracle的SQL*Plus工具的清屏的几个方法，参考如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>方法一：如果在window窗口下sqlplus 中清屏命令：host cls 或是clear screen 或只是4位 clea scre</p>
</li>
<li class="lvl-2">
<p>方法二：如果是在dos的窗口下进入sql/plus就要用clear SCR。【不区分大小写的】</p>
</li>
<li class="lvl-2">
<p>方法三：在Unix/Linux系统下，使用!clear命令</p>
</li>
</ul>
<p>汇总如下：</p>
<h2 id="windows-ping-tai">Windows平台</h2>
<pre><code class="language-shell">host cls
clear screen
clea scre
clear scr
clea scr
</code></pre>
<h2 id="unix-linux-ping-tai">Unix/Linux平台</h2>
<pre><code class="language-shell">clear screen
clea scre
clear scr
clea scr
!clear
</code></pre>
<h1 id="sql-plus-xi-tong-huan-jing-bian-liang-xin-xi-yi-ji-ru-he-xiu-gai-zhe-xie-bian-liang-xin-xi">SQL*Plus系统环境变量信息以及如何修改这些变量信息</h1>
<pre><code class="language-shell">show和set命令是两条用于维护SQL*Plus系统变量的命令 
      SQL&gt; show all          --查看所有68个系统变量值 
      SQL&gt; show user         --显示当前连接用户 
      SQL&gt; show error　　　　--显示错误 
      SQL&gt; set heading off  --禁止输出列标题，默认值为ON 
      SQL&gt; set feedback off --禁止显示最后一行的计数反馈信息，默认值为"对6个或更多的记录，回送ON" 
      SQL&gt; set timing on      --默认为OFF，设置查询耗时，可用来估计SQL语句的执行时间，测试性能 
      SQL&gt; set sqlprompt "SQL&gt; "    --设置默认提示符，默认值就是"SQL&gt; " 
      SQL&gt; set linesize 1000         --设置屏幕显示行宽，默认100 
      SQL&gt; set autocommit ON         --设置是否自动提交，默认为OFF 
      SQL&gt; set pause on     --默认为OFF，设置暂停，会使屏幕显示停止，等待按下ENTER键，再显示下一页 
      SQL&gt; set arraysize 1  --默认为15 
      SQL&gt; set long 1000     --默认为80 
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>long值默认为80，设置1000是为了显示更多的内容，因为很多数据字典视图中用到了long数据类型，如：</p>
</li>
</ul>
<pre><code class="language-shell">SQL&gt; desc user_views
列名                          可空值否   类型
------------------------------- -------- ----
VIEW_NAME                       NOT NULL VARCHAR2(30)
TEXT_LENGTH                              NUMBER
TEXT                                     LONG
</code></pre>
<h1 id="sql-plus-chang-yong-ming-ling-lie-biao">SQL*PLUS常用命令列表</h1>
<p>命令列表：</p>
<p>假设当前执行命令为：<code>select * from tab; </code></p>
<pre><code class="language-shell">(a)ppend　　　　      添加文本到缓冲区当前行尾　　　　a  order by tname　
结果：select * from tab order by tname;
（注：a后面跟2个空格）
(c)hange/old/new  在当前行用新的文本替换旧的文本　c/*/tname　　　　结果：select tname from tab;
(c)hange/text　　从当前行删除文本　　　　　　　　 c/tab　　　　　　　结果：select tname from;


del　　　　　　　删除当前行
del n　　　　　　删除第n行


(i)nput 文本　　 在当前行之后添加一行
(l)ist　　　　　 显示缓冲区中所有行
(l)ist n　　　　 显示缓冲区中第 n 行

(l)ist m n　　　 显示缓冲区中 m 到 n 行

run　　　　　　　执行当前缓冲区的命令
/　　　　　　　　执行当前缓冲区的命令
r　　　　　　　　执行当前缓冲区的命令


@文件名　　　　　运行调入内存的sql文件，如： 
SQL&gt; edit s&lt;回车&gt;
如果当前目录下不存在s.sql文件，则系统自动生成s.sql文件，
在其中输入“select * from tab;”，存盘退出。 
SQL&gt; @s&lt;回车&gt;
系统会自动查询当前用户下的所有表、视图、同义词。 


@@文件名　　　　 在.sql文件中调用令一个.sql文件时使用 
save 文件名　　　将缓冲区的命令以文件方式存盘，缺省文件扩展名为.sql
get 文件名　　　 调入存盘的sql文件
start 文件名　　 运行调入内存的sql文件 
spool 文件名　　 把这之后的各种操作及执行结果“假脱机”即存盘到磁盘文件上，默认文件扩展名为.lst
spool　　　　　　显示当前的“假脱机”状态
spool off　　　　停止输出
例：
SQL&gt; spool a
SQL&gt; spool
正假脱机到 A.LST
SQL&gt; spool off
SQL&gt; spool
当前无假脱机 

exit　　　　　　  退出SQL*PLUS
desc 表名　　　　 显示表的结构
show user　　　　显示当前连接用户
show error　　　 显示错误
show all　　　　 显示所有68个系统变量值
edit　　　　　　  打开默认编辑器，Windows系统中默认是notepad.exe，把缓冲区中最后一条SQL语句调入afiedt.buf文件中进行编辑
edit 文件名　　　 把当前目录中指定的.sql文件调入编辑器进行编辑 
clear screen　　 清空当前屏幕显示
</code></pre>
<h1 id="tui-chu-sql-jin-ru-os-ming-ling-mo-shi">退出SQL，进入OS命令模式</h1>
<p>使用英文输入法中的感叹号”!”，即可从SQL模式退出到Linux/Unix命令行模式下。</p>
<pre><code class="language-shell">SQL&gt; show parameter processes

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
aq_tm_processes                      integer     0
db_writer_processes                  integer     1
gcs_server_processes                 integer     0
global_txn_processes                 integer     1
job_queue_processes                  integer     1000
log_archive_max_processes            integer     4
processes                            integer     1000
SQL&gt; !
oracle@GW_8:~&gt; exit
exit
</code></pre>
<p>在SQL模式下执行linux/unix命令在linux/unix命令前，增加host命令，即可在不退出SQL模式下执行Linux/Unix命令.</p>
<pre><code class="language-shell">SQL&gt; host ls -l
total 5902
-rw-r--r--  1 oracle oinstall  371339 2012-11-28 15:49 14_45.html
-rw-r--r--  1 oracle oinstall  369040 2012-11-28 15:50 15_00.html
-rw-r--r--  1 oracle oinstall  368320 2012-11-28 15:51 15_15.html
-rw-r--r--  1 oracle oinstall  369926 2012-11-28 16:06 15_30.html
-rw-r--r--  1 oracle oinstall  379080 2012-11-28 16:03 15_45.html
-rw-r--r--  1 oracle oinstall  375061 2012-11-28 16:16 16_00.html
-rw-r--r--  1 oracle oinstall  374294 2012-11-28 16:35 16_15.html
-rw-r--r--  1 oracle oinstall  335887 2012-11-28 17:43 16_30.html
-rw-r--r--  1 oracle oinstall  410141 2012-11-28 14:36 9i.html
-rw-r--r--  1 oracle oinstall  401129 2012-11-28 14:41 9j.html
drwxr-x---  3 oracle oinstall      72 2012-10-11 15:17 admin
-rw-r--r--  1 oracle oinstall   16384 2013-01-08 09:53 a_tab.dmp
-rw-r--r--  1 oracle oinstall 2242560 2012-11-28 16:18 awrlog.tar
drwxr-xr-x  2 oracle oinstall      48 2012-10-11 13:58 bin
drwxr-x---  5 oracle oinstall     120 2012-10-11 15:35 cfgtoollogs
-rw-r--r--  1 oracle oinstall     475 2013-01-05 14:18 createuser.sql
drwxr-xr-x  2 oracle oinstall     208 2012-11-13 14:57 dbscript
drwxr-xr-x  2 oracle oinstall     208 2012-12-03 10:05 dbscript_zzz
drwx------  2 oracle oinstall     256 2012-10-11 14:08 Desktop
drwxrwxr-x 11 oracle oinstall     264 2012-10-11 15:17 diag
drwx------  2 oracle oinstall      80 2012-10-11 13:58 Documents
drwxr-xr-x  4 oracle oinstall     224 2012-10-11 15:01 install
drwxr-xr-x  2 oracle oinstall     216 2012-10-27 10:54 jc
drwxr-xr-x  2 oracle oinstall      48 2012-11-22 17:24 mmsgdpzsscripts
drwxr-xr-x  5 oracle oinstall     120 2013-01-28 19:16 mmsgrptscripts
drwxr-xr-x  2 oracle oinstall     184 2012-11-13 15:15 nss
drwxrwxrwx  3 oracle oinstall     200 2013-01-25 14:25 oradata
drwxr-xr-x  3 oracle oinstall      72 2012-10-24 15:24 oradiag_oracle
drwxrwx---  6 oracle oinstall     224 2012-12-05 08:59 oraInventory
drwxr-xr-x  3 oracle oinstall      72 2012-10-11 15:02 product
drwxr-xr-x  2 oracle oinstall      80 2012-10-11 13:58 public_html
drwxr-xr-x  2 oracle oinstall     248 2012-12-05 14:25 qmg
drwxr-xr-x  2 oracle oinstall     200 2012-10-24 10:54 zhy

SQL&gt;
</code></pre>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle监听</title>
    <url>/2013/02/03/oracle_listener/</url>
    <content><![CDATA[<h1 id="jian-ting-zuo-yong">监听作用</h1>
<p>oracle监听器是Oracle服务器软件的一个组件，它负责管理Oracle数据库和客户端之间的通讯，它在一个特定的网卡端口（默认是TCP 1521端口）上监听连接请求，并将连接转发给数据库，由两个二进制文件组成：tnslsnr和lsnrctl。其中tsnlsnr就是监听器本身，它运行在数据库服务器端，lsnrctl是监听器控制程序，用于在服务器上或远程管理监听器。与监听器相关的还有两个配置文件：sqlnet.ora和listener.ora。tnslsnr启动时就会读取这两个配置文件中的信息，如端口号，数据库服务名。</p>
<p>简而言之，oracle监听主要用来监听客户端向数据库服务器端提出的连接请求，是基于服务器端的服务，那么它也只存在于数据库服务器端，进行监听器的设置也是在数据库服务器端完成的。当conn建立连接以后，listener就没有用了，不会再用到了。</p>
<h1 id="lsnrctl-jian-ting-ming-ling-xiang-jie">lsnrctl监听命令详解</h1>
<p>监听命令是lsnrctl</p>
<p>Oracle用户登陆终端，输入lsnrctl，如下：</p>
<pre><code class="language-shell">oracle@mmsg1:~&gt; lsnrctl

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 11-8月 -2010 10:12:17

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

欢迎来到LSNRCTL, 请键入"help"以获得信息。

LSNRCTL&gt; help
以下操作可用
星号 (*) 表示修改符或扩展命令: 

start                 stop                 status              
services              version             reload              
save_config          trace                spawn               
change_password     quit                 exit                
set*                   show*               
</code></pre>
<h2 id="qi-dong-zhi-ding-de-jian-ting">启动指定的监听</h2>
<pre><code class="language-shell">LSNRCTL&gt;start
</code></pre>
<p>或者</p>
<pre><code class="language-shell">oracle@mmsg1:~&gt; lsnrctl start
</code></pre>
<h2 id="ting-zhi-zhi-ding-de-jian-ting">停止指定的监听</h2>
<pre><code class="language-shell">LSNRCTL&gt;stop
</code></pre>
<p>或者</p>
<pre><code class="language-shell">oracle@mmsg1:~&gt; lsnrctl stop
</code></pre>
<h2 id="cha-kan-jian-ting-zhuang-tai">查看监听状态</h2>
<pre><code class="language-shell">LSNRCTL&gt;status
</code></pre>
<p>或者</p>
<pre><code class="language-shell">oracle@mmsg1:~&gt; lsnrctl status
</code></pre>
<p>显示监听器的状态。Status命令显示监听器是不是活动的，日志与跟踪文件的位置，监听器已经持续运行了多长时间，以及监听器所监听的任务。</p>
<pre><code class="language-shell">LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 11-8月 -2010 10:29:05

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.167)(PORT=1521)))
LISTENER 的 STATUS
------------------------
别名                      LISTENER
版本                      TNSLSNR for Linux: Version 11.1.0.7.0 - Production
启动日期                  11-8月 -2010 08:56:47
正常运行时间              0 天 1 小时 32 分 18 秒
跟踪级别                  err
安全性                    ON: Local OS Authentication
SNMP                      OFF
监听程序参数文件          /opt/oracle/product/11g/network/admin/listener.ora
监听程序日志文件          /opt/oracle/diag/tnslsnr/mmsg1/listener/alert/log.xml
监听程序跟踪文件          /opt/oracle/diag/tnslsnr/mmsg1/listener/trace/ora_9828_47108097237856.trc
监听端点概要...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.137.49.167)(PORT=1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))
服务摘要..
服务 "PLSExtProc" 包含 1 个例程。
  例程 "PLSExtProc", 状态 UNKNOWN, 包含此服务的 1 个处理程序...
服务 "mmsgdb" 包含 1 个例程。
  例程 "mmsgdb", 状态 UNKNOWN, 包含此服务的 1 个处理程序...
命令执行成功
oracle@mmsg1:~&gt;
</code></pre>
<p>列举监听器的服务信息，比如这些服务是否有任何专用的预生成服务器进程或与之相关的调度进程，以及每个服务已有多少连接被接受或拒绝。这种方法用来检查一个监听器是否在监听一个指定服务。</p>
<h2 id="service">service</h2>
<p>列出服务的一个汇总表及为每个协议服务处理程序所建立和拒绝的连接信息个数。</p>
<pre><code class="language-shell">LSNRCTL&gt; service  
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.167)(PORT=1521)))
服务摘要..
服务 "PLSExtProc" 包含 1 个例程。
  例程 "PLSExtProc", 状态 UNKNOWN, 包含此服务的 1 个处理程序...
    处理程序:
      "DEDICATED" 已建立:0 已被拒绝:0
         LOCAL SERVER
服务 "mmsgdb" 包含 1 个例程。
  例程 "mmsgdb", 状态 UNKNOWN, 包含此服务的 1 个处理程序...
    处理程序:
      "DEDICATED" 已建立:0 已被拒绝:0
         LOCAL SERVER
命令执行成功
LSNRCTL&gt;
</code></pre>
<h2 id="version">version</h2>
<p>显示oracle net软件与协议适配器的版本</p>
<pre><code class="language-shell">LSNRCTL&gt; version
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.167)(PORT=1521)))
TNSLSNR for Linux: Version 11.1.0.7.0 - Production
        TNS for Linux: Version 11.1.0.7.0 - Production
        Unix Domain Socket IPC NT Protocol Adaptor for Linux: Version 11.1.0.7.0 - Production
        Oracle Bequeath NT Protocol Adapter for Linux: Version 11.1.0.7.0 - Production
        TCP/IP NT Protocol Adapter for Linux: Version 11.1.0.7.0 - Production,,
命令执行成功
LSNRCTL&gt;
</code></pre>
<h2 id="reload">reload</h2>
<p>重新装入监听器，重新读取listener.ora文件，但不关闭监听器。如果该文件发生了变化，重新刷新监听器。</p>
<h2 id="save-config">save_config</h2>
<p>当从lsnrctl工具中对listener.ora文件进行了修改时，复制一个叫做listener.bak的listener.ora的文件</p>
<h2 id="trace">trace</h2>
<p>打开监听器的跟踪特性</p>
<h2 id="change-password">change_password</h2>
<p>允许用户修改关闭监听器所需要的密码</p>
<h2 id="quit">quit</h2>
<p>退出lsnrctl实用工具</p>
<h2 id="exit">exit</h2>
<p>退出lsnrctl实用工具</p>
<h1 id="set">set*</h1>
<pre><code class="language-shell">SNRCTL&gt; set
The following operations are available after set
An asterisk (*) denotes a modifier or extended command:

password                       rawmode                     
displaymode                    trc_file                    
trc_directory                  trc_level                   
log_file                        log_directory               
log_status                     current_listener            
inbound_connect_timeout     startup_waittime            
save_config_on_stop          dynamic_registration        

LSNRCTL&gt;
</code></pre>
<p><strong>password</strong></p>
<p>指定在lsnrctl命令行工具中执行管理任务所需要的密码</p>
<h2 id="rawmode">rawmode</h2>
<p>指定原始模式，默认为OFF。</p>
<h2 id="displaymode">displaymode</h2>
<p>指定服务显示模式，默认设置为：NORMAL。</p>
<h2 id="trc-file">trc_file</h2>
<p>指定监听器跟踪信息的位置。默认设置是$ORACLE_HOME\network\trace\listener.trc</p>
<h2 id="trc-directory">trc_directory</h2>
<p>指定trace文件路径，默认设置为：$ORALCE_BASE/ diag/tnslsnr/hostname/ listener/trace。</p>
<h2 id="trc-level">trc_level</h2>
<p>跟踪级别 ，OFF - 未启用跟踪功能。OFF 为默认设置。</p>
<p>其中，0和1  ：off<br>
2和3  ：err<br>
4和5  ：user<br>
6~10   ：admin</p>
<p>示例:</p>
<pre><code class="language-shell">LSNRCTL&gt; set trc_level 1
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 off
LSNRCTL&gt; set trc_level 2
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 err
命令执行成功
LSNRCTL&gt; set trc_level 3
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 err
命令执行成功
LSNRCTL&gt; set trc_level 4
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 user
命令执行成功
LSNRCTL&gt; set trc_level 5
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 user
命令执行成功
LSNRCTL&gt; set trc_level 6
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 admin
命令执行成功
LSNRCTL&gt; set trc_level 7
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 admin
命令执行成功
LSNRCTL&gt; set trc_level 8
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 admin
命令执行成功
LSNRCTL&gt; set trc_level 9
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 admin
命令执行成功
LSNRCTL&gt; set trc_level 10
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 admin
命令执行成功
LSNRCTL&gt; set trc_level 0
正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.114)(PORT=1521)))
STRAYEAGLE 参数 "trc_level" 设为 off
命令执行成功
</code></pre>
<h2 id="log-file">log_file</h2>
<p>指定监听日志文件名，默认为：$ORACLE_BASE/ diag/tnslsnr/hostname/ listener/alert/log.xml。</p>
<h2 id="log-directory">log_directory</h2>
<p>指定监听日志文件存放路径，默认为：$ORACLE_BASE/ diag/tnslsnr/hostname/ listener/alert</p>
<h2 id="log-status">log_status</h2>
<p>指定一个监听器将把日志信息写到哪里。这个参数在默认的情况下是ON,并默认为%oracle_home%\network\log\listener.log</p>
<h2 id="current-listener">current_listener</h2>
<p>显示当前监听器名称。</p>
<h2 id="inbound-connect-timeout">inbound_connect_timeout</h2>
<p>定义监听器在一个会话得到启动时将等待的有效响应时间。默认设置为10秒。</p>
<h2 id="startup-waittime">startup_waittime</h2>
<p>定义监听器在响应lsnrctl命令行工具中的一条status命令之前将等待多长时间。</p>
<h2 id="save-config-on-stop">save_config_on_stop</h2>
<p>指定在一个lsnrctl会话期内所发生的修改在退出时是否应该被保存起来。</p>
<h1 id="show">show*</h1>
<pre><code class="language-shell">LSNRCTL&gt; show     
The following operations are available after show
An asterisk (*) denotes a modifier or extended command:

rawmode                     displaymode                 
rules                       trc_file                    
trc_directory               trc_level                   
log_file                    log_directory               
log_status                  current_listener            
inbound_connect_timeout     startup_waittime            
snmp_visible                save_config_on_stop         
dynamic_registration        
</code></pre>
<h2 id="rawmode-1">rawmode</h2>
<p>显示关于status和service的较详细信息（当他们设置成on时）值为ON或OFF</p>
<h2 id="displaymode-1">displaymode</h2>
<p>把lsnrctl工具的显示模式设置成raw、compact、normal或verbose</p>
<p>服务显示模式为NORMAL</p>
<h2 id="rules">rules</h2>
<p>过滤规则</p>
<pre><code class="language-shell">LSNRCTL&gt; show rules
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
No filtering rules currently in effect.
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="trc-file-1">trc_file</h2>
<p>指定监听器跟踪信息的位置。默认设置是$ORACLE_HOME\network\trace\listener.trc</p>
<pre><code class="language-shell">LSNRCTL&gt; show  trc_file   
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "trc_file" set to ora_4825_47881906824032.trc
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="trc-directory-1">trc_directory</h2>
<pre><code class="language-shell">LSNRCTL&gt; show trc_directory
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "trc_directory" set to /opt/oracle/diag/tnslsnr/node1/listener/trace
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="trc-level-1">trc_level</h2>
<pre><code class="language-shell">LSNRCTL&gt; show trc_level
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "trc_level" set to off
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="log-file-1">log_file</h2>
<p>指定一个监听器将把日志信息写到哪里。这个参数在默认的情况下是ON,并默认为%oracle_home%\network\log\listener.log</p>
<pre><code class="language-shell">LSNRCTL&gt; show log_file
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "log_file" set to /opt/oracle/diag/tnslsnr/node1/listener/alert/log.xml
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="log-directory-1">log_directory</h2>
<pre><code class="language-shell">LSNRCTL&gt; show log_directory
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "log_directory" set to /opt/oracle/diag/tnslsnr/node1/listener/alert
The command completed successfully
LSNRCTL&gt; 
log_status
LSNRCTL&gt; show log_status
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "log_status" set to ON
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="current-listener-1">current_listener</h2>
<pre><code class="language-shell">LSNRCTL&gt; show current_listener
Current Listener is LISTENER
LSNRCTL&gt;
</code></pre>
<h2 id="inbound-connect-timeout-1">inbound_connect_timeout</h2>
<p>定义监听器在一个会话得到启动时将等待的有效响应时间。默认设置为60秒。</p>
<pre><code class="language-shell">LSNRCTL&gt; show inbound_connect_timeout
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "inbound_connect_timeout" set to 60
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="startup-waittime-1">startup_waittime</h2>
<p>定义监听器在响应lsnrctl命令行工具中的一条status命令之前将等待多长时间。</p>
<pre><code class="language-shell">LSNRCTL&gt; show startup_waittime
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "startup_waittime" set to 0
The command completed successfully
LSNRCTL&gt;
snmp_visible
LSNRCTL&gt; show snmp_visible
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "snmp_visible" set to OFF
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h2 id="save-config-on-stop-1">save_config_on_stop</h2>
<p>指定在一个lsnrctl会话期内所发生的修改在退出时是否应该被保存起来。</p>
<pre><code class="language-shell">LSNRCTL&gt; show save_config_on_stop
Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.119)(PORT=1521)))
LISTENER parameter "save_config_on_stop" set to OFF
The command completed successfully
LSNRCTL&gt;
</code></pre>
<h1 id="shi-yong-jian-ting-yu-shu-ju-ku-jian-li-lian-jie-de-ling-yi-chong-fang-shi">使用监听与数据库建立连接的另一种方式</h1>
<pre><code class="language-shell">sqlplus mmsg/mmsg@10.137.49.119:1521/mmsgdb 
</code></pre>
<h1 id="ke-hu-duan-ru-he-tong-guo-jian-ting-yu-server-jian-li-lian-jie">客户端如何通过监听与server建立连接</h1>
<p>sqlnet.ora文件内容</p>
<pre><code class="language-shell">NAMES.DIRECTORY_PATH= (TNSNAMES,HOSTNAME)
</code></pre>
<p>当你输入sqlplus mmsg/mmsg@mmsgdb的时候</p>
<p>1． 查询sqlnet.ora看看名称的解析方式，发现是TNSNAME</p>
<p>2． 则查询tnsnames.ora文件，从里边找mmsgdb的记录，并且找到主机名，端口和service_name</p>
<p>3． 如果listener进程没有问题的话，建立与listener进程的连接。</p>
<p>4． 根据不同的服务器模式如专用服务器模式或者共享服务器模式，listener采取接下去的动作。默认是专用服务器模式，没有问题的话客户端就连接上了数据库的server process。</p>
<p>5． 这时候网络连接已经建立，listener进程的历史使命也就完成了。</p>
<h1 id="ji-chong-lian-jie-yong-dao-de-ming-ling-xing-shi">几种连接用到的命令形式</h1>
<p>1.sqlplus / as sysdba 这是典型的操作系统认证，不需要listener进程</p>
<p>2.sqlplus sys/passwd as sysdba 这种连接方式只能连接本机数据库，同样不需要listener进程</p>
<p>3.sqlplus sys/passwd@dbname  as sysdba 这种方式需要listener进程处于可用状态。最普遍的通过网络连接。</p>
<p>以上连接方式使用sys用户或者其他通过密码文件验证的用户都不需要数据库处于可用状态，操作系统认证也不需要数据库可用，普通用户因为是数据库认证，所以数据库必需处于open状态。</p>
<h1 id="jian-ting-zhu-ce">监听注册</h1>
<p>注册就是将数据库作为一个服务注册到监听程序。</p>
<p>客户端不需要知道数据库名和实例名，只需要知道该数据库对外提供的服务名就可以申请连接到数据库。这个服务名可能与实例名一样，也有可能不一样。</p>
<h2 id="dang-jian-ting-de-duan-kou-fei-1521-shi-hou-ru-he-shi-de-jian-ting-jin-xing-dong-tai-zhu-ce">当监听的端口非1521时候，如何使得监听进行动态注册</h2>
<p>通过修改参数local_listener 进行。</p>
<h3 id="fang-fa-yi">方法一</h3>
<p>可以设置local_listener=listener，前提条件是将lsnrctl.ora文件中的listener信息添加到tnsnames.ora文件中，因为pmon进程动态注册监听时会通过读取tnsname.ora文件相关信息</p>
<pre><code class="language-shell">alter system set local_listener=listener;
</code></pre>
<p>添加lsnrctl.ora文件内容到tnsnames.ora文件中。</p>
<h3 id="fang-fa-er">方法二</h3>
<p>可以设置local_listener参数为lister.ora文件中的address和address_list</p>
<pre><code class="language-shell">alter system set local_listener = '(ADDRESS=(PROTOCOL=TCP)(HOST=10.137.49.37)(PORT=1522))';
</code></pre>
<h2 id="ru-he-pan-duan-jian-ting-shi-fou-yi-zhu-ce">如何判断监听是否已注册</h2>
<p>通过查看监听当前状态，根据如下红色加粗部分信息判别：</p>
<pre><code class="language-shell">oracle@GW_8:~&gt; lsnrctl status

LSNRCTL for Linux: Version 11.1.0.7.0 - Production on 01-2月 -2013 11:59:06

Copyright (c) 1991, 2008, Oracle.  All rights reserved.

正在连接到 (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=EXTPROC1521)))
LISTENER 的 STATUS
------------------------
别名                      LISTENER
版本                      TNSLSNR for Linux: Version 11.1.0.7.0 - Production
启动日期                  29-1月 -2013 10:05:29
正常运行时间              3 天 1 小时 53 分 36 秒
跟踪级别                  off
安全性                    ON: Local OS Authentication
SNMP                      OFF
监听程序参数文件          /opt/oracle/product/11g/network/admin/listener.ora
监听程序日志文件          /opt/oracle/diag/tnslsnr/GW_8/listener/alert/log.xml
监听端点概要...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=10.41.16.50)(PORT=1521)))
服务摘要..
服务 "mmsgdb" 包含 1 个例程。
  例程 "mmsgdb", 状态 READY, 包含此服务的 1 个处理程序...
服务 "mmsgdb_XPT" 包含 1 个例程。
  例程 "mmsgdb", 状态 READY, 包含此服务的 1 个处理程序...
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>监听分静态注册与动态注册，注册过程由oracle的PMON进程完成，PMON进程仅默认对1521端口的监听进行注册，非1521端口无法自动注册。</p>
</li>
</ul>
<h1 id="local-listener-yu-remote-listener">local_listener与remote_listener</h1>
<img class="shadow" src="/img/in-post/oracle_listener_remote_listener.png" width="1200">
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle表空间管理</title>
    <url>/2013/03/10/oracle_tablespace/</url>
    <content><![CDATA[<h1 id="yu-biao-kong-jian-xiang-guan-de-shi-tu">与表空间相关的视图</h1>
<table>
<thead>
<tr>
<th>段类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>V$TABLESPACE</td>
<td>控制文件中保存的所有表空间的名称和数量</td>
</tr>
<tr>
<td>DBA_TABLESPACES</td>
<td>所有表空间的描述信息</td>
</tr>
<tr>
<td>USER_TABLESPACES</td>
<td>所有用户可访问表空间的描述信息</td>
</tr>
<tr>
<td>DBA_TABLESPACE_GROUPS</td>
<td>所有表空间组及其所属的表空间信息</td>
</tr>
<tr>
<td>DBA_SEGMENTS</td>
<td>所有表空间中的区间信息</td>
</tr>
<tr>
<td>USER_SEGMENTS</td>
<td>所有用户表空间中的区间信息</td>
</tr>
<tr>
<td>DBA_FREE_SPACE</td>
<td>所有表空间中的空闲区间信息</td>
</tr>
<tr>
<td>USER_FREE_SPACE</td>
<td>所有用户表空间中的空闲区间信息</td>
</tr>
<tr>
<td>V$DATAFILE</td>
<td>所有数据文件信息</td>
</tr>
<tr>
<td>V$TEMPFILE</td>
<td>所有临时文件信息</td>
</tr>
<tr>
<td>DBA_DATA_FILES</td>
<td>显示所有属于表空间的数据文件信息</td>
</tr>
<tr>
<td>DBA_TEMP_FILES</td>
<td>显示所有属于临时表空间的临时文件信息</td>
</tr>
<tr>
<td>V$TABLESPACE</td>
<td>控制文件中保存的所有表空间的名称和数量</td>
</tr>
<tr>
<td>DBA_TABLESPACES</td>
<td>所有表空间的描述信息</td>
</tr>
</tbody>
</table>
<h1 id="chuang-jian-biao-kong-jian">创建表空间</h1>
<pre><code class="language-shell">CREATE TABLESPACE tablespace_name 
DATAFILE  '/path/filename' SIZE integer [K|M] REUSE 
[，'/path/filename' SIZE integer [K|M] REUSE] 
[AUTOEXTEND [ OFF | ON  NEXT integer [ K | M ]  ] [ MAXSIZE [ UNLIMITED | integer [ K | M ] ] ]  ]
[ MINIMUM  EXTENT  integer [ K | M ]  ]
[DEFAULT STORAGE storage ]
[ ONLINE | OFFLINE ]
[ LOGGING | NOLOGGING ]
[ PERMANENT | TEMPORARY ]
[EXTENT MANAGEMENT
[ DICTIONARY | LOCAL [ AUTOALLOCATE | UNIFORM SIZE integer [ K | M ] ]  ]
 ]
</code></pre>
<p>解释：</p>
<p>1、一个表空间可以拥有多个数据文件，create tablespace时，各个数据文件使用英文状态下的逗号分隔；</p>
<p>2、数据文件是否自动扩展，默认off</p>
<p>3、minimum</p>
<p>4、default storeage 设置默认存储</p>
<pre><code class="language-shell">        default storage(
        initial 192K
        next 192K
        minextents 1
        pctincrease 0)
</code></pre>
<p>5、数据文件在线还是脱机，默认online</p>
<p>6、Logging与nologging，区别在于是否忽略日志记录</p>
<p>7、 EXTENT MANAGEMENT，表空间管理方式，分为数据字典管理和本地管理</p>
<h1 id="zi-dian-guan-li-fang-shi-de-biao-kong-jian">字典管理方式的表空间</h1>
<p>表空间中所有存储空间的管理信息都保存在数据字典中，在进行存储空间管理时会产生回退和重做记录</p>
<h1 id="ben-di-guan-li-fang-shi-de-biao-kong-jian">本地管理方式的表空间</h1>
<p>表空间中所有存储空间的管理信息都保存在数据文件头部的位图中</p>
<p>本地管理方式的表空间具有如下优点:</p>
<p>1、在存储分配过程中不需要访问数据库，可以提高存储分配操作的速度</p>
<p>2、能够避免在表空间的存储管理操作中产生的递归现象</p>
<p>3、不会产生重做和撤销记录</p>
<p>4、简化DBA对表空间的管理操作</p>
<p>5、降低用户对数据字典的依赖性</p>
<h1 id="da-wen-jian-biao-kong-jian">大文件表空间</h1>
<p>Bigfile与smallfile文件</p>
<p>这种类型的表空间只能有一个数据文件，且该数据文件允许有4G的数据快，即如果db_block_size=8k的话，最大容量为4G*8K=32T，当然，这个还要看操作系统的限制了。</p>
<p>一般应该不会这样的用的。</p>
<p>理论上的 BFT 可以达到下面所列的值：</p>
<pre><code class="language-shell">数据块大小(单位：K)   BFT 最大值(单位：T) 
         2k                    8T 
         4k                    16T 
         8k                    32T 
         16k                   64T 
         32k                  128T 
</code></pre>
<h1 id="cha-xun-wang-guan-mo-ren-shu-ju-wen-jian-lei-xing">查询网关默认数据文件类型</h1>
<pre><code class="language-shell">select property_name,property_value from database_properties where property_name='DEFAULT_TBS_TYPE';
</code></pre>
<p>修改数据库默认的表空间类型为smallfile,就可以为表空间创建多个数据文件了。</p>
<pre><code class="language-shell">SQL&gt; alter database set default smallfile tablespace;

Database altered
</code></pre>
<p>也可以在创建表空间时，指定表空间类型：create smallfile/bigfile  tablespace …</p>
<h1 id="zhong-ming-ming-biao-kong-jian">重命名表空间</h1>
<pre><code class="language-shell">SQL&gt; select * from v$tablespace;
       TS# NAME                           INC BIG FLA ENC
---------- ------------------------------ --- --- --- ---
         0 SYSTEM                         YES NO  YES
         1 SYSAUX                         YES NO  YES
         2 UNDOTBS1                       YES NO  YES
         3 TEMP                           NO  NO  YES
         4 USERS                          YES NO  YES
         5 MMSG                           YES NO  YES
         6 MMSG_TMP                       NO  NO  YES
         7 YJH                            YES NO  YES
         8 YJH_TMP                        NO  NO  YES
         9 WYZ                            YES NO  YES
        10 WYZ_TMP                        NO  NO  YES
       TS# NAME                           INC BIG FLA ENC
---------- ------------------------------ --- --- --- ---
        11 WYZTEST                        YES NO  YES
        12 WYZTESTTEMP                    NO  NO  YES
已选择13行。
SQL&gt; alter tablespace wyztest rename to wyztest0;
表空间已更改。
SQL&gt; select * from v$tablespace;
       TS# NAME                           INC BIG FLA ENC
---------- ------------------------------ --- --- --- ---
         0 SYSTEM                         YES NO  YES
         1 SYSAUX                         YES NO  YES
         2 UNDOTBS1                       YES NO  YES
         3 TEMP                           NO  NO  YES
         4 USERS                          YES NO  YES
         5 MMSG                           YES NO  YES
         6 MMSG_TMP                       NO  NO  YES
         7 YJH                            YES NO  YES
         8 YJH_TMP                        NO  NO  YES
         9 WYZ                            YES NO  YES
        10 WYZ_TMP                        NO  NO  YES
       TS# NAME                           INC BIG FLA ENC
---------- ------------------------------ --- --- --- ---
        11 WYZTEST0                       YES NO  YES
        12 WYZTESTTEMP                    NO  NO  YES
已选择13行。
SQL&gt; 
</code></pre>
<h1 id="ben-di-guan-li-biao-kong-jian">本地管理表空间</h1>
<p>在ALTER TABLESPACE语句中使用ADD DATAFILE子句，可以在本地管理表空间中增加数据文件，代码如下：</p>
<pre><code class="language-shell">SQL&gt; alter tablespace wyztest 
add datafile '/opt/oracle/oradata/mmsgdb/wyztest01.dbf‘
size 10m
autoextend on next 10m maxsize 100m
表空间已更改。
SQL&gt;
</code></pre>
<h1 id="zhong-zhi-biao-kong-jian-da-xiao">重置表空间大小</h1>
<p>在ALTER database语句中使用resize子句，可以在本地管理表空间中修改数据文件大小，代码如下：</p>
<h2 id="gai-bian-shu-ju-wen-jian-da-xiao">改变数据文件大小</h2>
<pre><code class="language-shell">SQL&gt; alter database datafile '/opt/oracle/oradata/mmsgdb/wyztest01.dbf' resize 15m;
数据库已更改。
</code></pre>
<h1 id="xiu-gai-shu-ju-wen-jian-zeng-chang-fang-shi">修改数据文件增长方式</h1>
<p>在ALTER database语句中使用autoextend子句，可以在本地管理表空间中修改数据文件（不）自动扩展，代码如下：</p>
<h2 id="xiu-gai-shu-ju-wen-jian-de-zeng-chang-fang-shi">修改数据文件的增长方式</h2>
<pre><code class="language-shell">SQL&gt; alter database datafile  '/opt/oracle/oradata/mmsgdb/wyztest.dbf' 
 2  autoextend on next 15m maxsize 150m; 
数据库已更改。
SQL&gt;
</code></pre>
<h2 id="guan-bi-zi-dong-biao-kong-jian-zi-dong-kuo-zhan">关闭自动表空间自动扩展</h2>
<pre><code class="language-shell">SQL&gt; alter database datafile '/opt/oracle/oradata/mmsgdb/wyztest.dbf' 
  2  autoextend off;
数据库已更改。
SQL&gt; 
</code></pre>
<h1 id="gai-bian-shu-ju-wen-jian-de-ming-cheng-he-wei-zhi">改变数据文件的名称和位置</h1>
<h2 id="chang-jing-yi-shu-ju-wen-jian-shu-yu-tong-yi-ge-biao-kong-jian">场景一 数据文件属于同一个表空间</h2>
<p>1；将包含数据文件的表空间置为脱机状态</p>
<pre><code class="language-shell">SQL&gt; alter tablespace wyztest offline normal;
表空间已更改。
</code></pre>
<p>2：os level级重命名表空间下的数据文件名称</p>
<pre><code class="language-shell">oracle@mmsg37:~/oradata/mmsgdb&gt; mv wyztest01.dbf wyztest00.dbf 
</code></pre>
<p>3：在数据库内部修改数据文件的名称或者改变数据文件的位置</p>
<pre><code class="language-shell">alter tablespace tablespace_name 
rename datafile  ‘xxxxx’ to ‘xxxx’;
改变名称
SQL&gt; alter tablespace wyztest 
  2  rename datafile 
  3  '/opt/oracle/oradata/mmsgdb/wyztest01.dbf' to
  4  '/opt/oracle/oradata/mmsgdb/wyztest00.dbf';
alter tablespace wyztest     //这里报错，是因为当初没有执行o slevel的命名操作，必须要执行第二步的重命名操作。
*
第 1 行出现错误:
ORA-01525: 重命名数据文件时出错
ORA-01141: 重命名数据文件 7 时出错 - 未找到新文件
'/opt/oracle/oradata/mmsgdb/wyztest00.dbf'
ORA-01110: 数据文件 7: '/opt/oracle/oradata/mmsgdb/wyztest01.dbf'
ORA-27037: 无法获得文件状态
Linux-x86_64 Error: 2: No such file or directory
Additional information: 3
SQL&gt; /
表空间已更改。
</code></pre>
<p>更改位置</p>
<pre><code class="language-shell"> alter tablespace wyztest 
Rename datafile '/opt/oracle/oradata/mmsgdb/wyztest01.dbf’ to
‘/home/oradata/mmsgdb/wyztest02.dbf’   //前提条件是/home/oradata/mmsgdb/目录存在，且oracle对该目录具有可操作权限
</code></pre>
<p>4：将表空间置为联机状态</p>
<pre><code class="language-shell">SQL&gt; alter tablespace wyztest online;
表空间已更改。
SQL&gt; 
</code></pre>
<p>5：备份控制文件</p>
<h2 id="chang-jing-er-yao-gai-bian-de-shu-ju-wen-jian-shu-yu-duo-ge-biao-kong-jian">场景二 要改变的数据文件属于多个表空间</h2>
<p>1：关闭数据库</p>
<p>2：os level级重命名或者移动数据文件</p>
<p>3：加载数据库到mount状态 startup mount</p>
<p>4：在数据库内部更改数据文件名称或者位置（alter datafile rename datafile ‘xxxxx01  ‘xxxx02’ to ‘yyyy01’ ‘yyyy02’;） //to 之后的文件必须存在，也就是 os level级的操作是必须做的</p>
<p>5：open数据库 alter database open;</p>
<p>6：备份控制文件</p>
<h1 id="she-zhi-zhi-du-biao-kong-jian">设置只读表空间</h1>
<p>ALTER TABLESPACE…READ ONLY语句设置只读表空间</p>
<p>【例】将表空间wyztest设置为只读表空间：</p>
<pre><code class="language-shell">SQL&gt; alter tablespace  wyztest read only;
</code></pre>
<p>ALTER TABLESPACE…READ WRITE语句可以将只读表空间设置为可读写状态</p>
<p>【例】将表空间wyztest设置为可读写状态：</p>
<pre><code class="language-shell">SQL&gt; alter tablespace  wyztest read  write;
</code></pre>
<h1 id="shan-chu-biao-kong-jian">删除表空间</h1>
<p>删除表空间的时候可以清除表空间的内容以及表空间对应的数据文件</p>
<p>适用情况<br>
1：不小心给不需要的表空间增加了数据文件；<br>
2：设置的数据文件较大，想删除后重新创建；</p>
<pre><code class="language-shell">   drop tablesapce tablespacename  including contents;
   drop tablespace tablespacename including contents and datafiles;
</code></pre>
<h2 id="a-suo-zai-biao-kong-jian-zhi-you-yi-ge-shu-ju-wen-jian">A：所在表空间只有一个数据文件</h2>
<p>只要简单地删除表空间即可：</p>
<pre><code class="language-shell">drop tablespace tablespace_name including contents;
</code></pre>
<h2 id="b-ru-guo-biao-kong-jian-you-duo-ge-shu-ju-wen-jian">B：如果表空间有多个数据文件</h2>
<p>1、不再需要表空间中的内容，或者可以很容易重新产生表空间的内容，可以使用</p>
<p><code>drop tablespace tablespace_name including contents;</code> 命令来从Oracle数据字典删除表空间、数据文件和表空间的内容。</p>
<p>Oracle不会再访问该表空间中的任何内容, 然后重新创建表空间并重新导入数据。</p>
<p>2、需要保留该表空间中的其它数据文件中的内容</p>
<p>必须首先export导出该表空间中的所有内容。为了确定表空间中包含哪些内容，运行：</p>
<pre><code class="language-shell">select owner,segment_name,segment_type 
from dba_segments 
where tablespace_name='&lt;name of tablespace&gt;'
</code></pre>
<p>export出你想保留的内容。如果export结束，就可以使用drop tablespace tablespace_name including contents; ，这样永久删除表空间的内容，使用操作系统命令物理删除数据文件，按所需数据文件重新创建表空间，把数据import至表空间。</p>
<p>这里要区别于<code>alter databade datafile ‘/opt/oracle/oradata/mmsgdb/wyztest.dbf’offline drop </code>操作。<br>
Offline drop 将数据文件脱机，而不是删除对应的数据文件，数据库不会再访问这部分数据文件的内容，但它仍然是表空间的一部分。这个数据文件在控制文件中标记为offline状态，在数据库启动时不会将它与控制文件中的SCN比较，跳过对offline 的数据文件的读取操作，这里控制文件保留这个数据文件的入口，方便后续的介质恢复（归档模式下）</p>
]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>绑定与还原网卡配置文件</title>
    <url>/2013/05/08/bakcup_restore_net_interface/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在网关测试组工作期间，产品支持SUSE9/SUSE10/SUSE11平台，每次部署环境，都要进行网卡配置操作，虽然有指导手册，无奈比较懒，不想浪费心力在手动配置上，于是酝酿出这个脚本，实现自动进行网卡的绑定动作，一旦绑定失败，自动还原。</p>
<h1 id="zhi-jie-shang-jiao-ben">直接上脚本</h1>
<pre><code class="language-perl">#!/usr/bin/perl
use warnings;
use strict;
use Sys::Hostname;
use Socket;


################################################################################
#    ######################################################################    #
#   #      说明：   完成网卡文件的备份、绑定、回滚等操作                   #   #
#   #      使用：   perl   network_bond.pl                                 #   #
#   #      AUTH：   wangyunzeng                                            #   #
#   #      VER ：   1.0                                                    #   #
#   #      TIME：   2012-06-11   18:50   create                            #   #
#   #      VER ：   1.1                                                    #   #
#   #      TIME：   2013-05-08   18:05   增加SUSE9/11平台绑定网卡操作      #   #
#    ######################################################################    #
################################################################################

#定义全局变量
chomp(my $OS_Type = $^O);                                                       #操作系统类型
my $cornel;                                                                     #内核版本号,2013-05-08

my $host=hostname();                                                            #修改获取大网IP可能错误问题，2013-05-08
my $IP_A=inet_ntoa(scalar gethostbyname ($host || 'localhost'));
chomp($IP_A);


#判断当前登录用户，非root，退出
my $localuser = getlogin || (getpwuid($&lt;))[0] || die "Can't find a user here!!!\n";

if($localuser ne "root")
{
  print "\n当前登录用户非root，退出！\n\n";
  exit;
}
else
{
   print "\n【说明】
       1、本脚本仅支持SUSE9/SUSE10/SUSE11平台
       
       2、本脚本将Fabric平面网卡绑定成bond0，将Base平面网卡绑定成bond1
       
       3、本脚本备份原网卡配置文件，备份在 /etc/sysconfig 目录下，network_日期.tar.gz
          如果绑定失败，请登录usm，到 /etc/sysconfig 目录下解压后重启网卡既可. \n\n";
       
   
   ##判断操作系统类型
   if($OS_Type =~ /linux/)
   {
      chomp($cornel=`cat /etc/SuSE-release  | head -1`);                        #内核版本号
      
      ##获取系统时间  
      my ($sec,$min,$hour,$day,$month,$year)= localtime(time());
      
      $year+=1900;
      $month=sprintf("%02d",$month+1);
      $day=sprintf("%02d",$day);
      $hour=sprintf("%02d",$hour);
      $min=sprintf("%02d",$min);
      $sec=sprintf("%02d",$sec);
      
      my $daytime = "$year$month$day";
      
      chdir "/etc/sysconfig"; 
      if(! -f "network_ $daytime.tar.gz")
      {
         system("tar zcf network_$daytime.tar.gz network");
      }

      &amp;bak_check;
   }
   else
   {
      print "\n当前仅支持ATAE SUSE平台下网卡绑定操作!\n\n";
      exit;
   }
}


#################################################################################
###                                  定义子例程                               ###
#################################################################################

sub bak_check()
{
  if( -f "/etc/sysconfig/network/ifcfg-bond0")
  {
    print "\n存在网卡绑定文件ifcfg-bond0! \n\n";
    print "\n可能已经绑定网卡，程序退出.\n\n";
    exit;
  }
  
  if( -f "/etc/sysconfig/network/ifcfg-bond1")
  {
    print "\n存在网卡绑定文件ifcfg-bond1! \n\n";
    print "\n可能已经绑定网卡，程序退出.\n\n";
    exit;
  }

  chdir "/etc/sysconfig/network"; 
  
  print "\n开始备份网卡文件.\n\n";
 
  #创建目录
  unless (-d "bak")                                                             #如果目录不存在，创建目录
  {
    mkdir("bak", 0755) || die "Make directory bak error,$!.\n";
  }

  #增加SUSE9和SUSE11平台的支持与判断
  if($cornel=~m/Server 10/i || $cornel=~m/Server 9/i )
  {
    system("cp ifcfg-eth-id-* ./bak/");
  }
  elsif($cornel=~m/Server 11/i)
  {
    system("cp ifcfg-eth[0-9] ./bak/");
  }
  
  
  #判断备份是否成功,成功则继续
  #my $ifcfg_cut=`ls ./bak/ifcfg-eth-id-* | wc -l`;
  my $ifcfg_cut=`ls ./bak/ifcfg-eth* | wc -l`;                                  #SUSE11 文件名称发生变化,2013-05-08
  chomp($ifcfg_cut);

  if($ifcfg_cut &gt;= 1)
  {
    print "\n备份网卡文件成功\n\n";
    
    #绑定网卡
    &amp;bond;
    
    #清理文件
    &amp;clear;
    
    #重启网卡
    print "\n重启网卡......\n\n";
    system("rcnetwork restart");
    
    #打印绑定后的网卡信息
    print "\n绑定后的网卡信息如下:\n\n";
    system("ifconfig -a");
  
    
    print "\n完成网卡的绑定.\n\n";
   
  }
  else
  {
    print "\n备份网卡文件失败,退出!\n\n";
    exit;
  }
}


sub bond()
{
   system("/var/adm/autoinstall/scripts/eth_alias.sh  | grep -v Update | grep -v PMC  &gt; eth.tmp");
   system("ifconfig -a | grep -v RX | grep -v dropped | grep -v UP | grep -v collisions | grep -v Interrupt | grep -v \"127.0.0.1\" &gt; ifconfig.txt");
   
   ##网卡名
   my $eth_A= `cat eth.tmp | grep Fabric1 |  awk \-F \" \" \'\{print \$1\}\'`;
   my $eth_B= `cat eth.tmp | grep Fabric2 |  awk \-F \" \" \'\{print \$1\}\'`;
   my $eth_C= `cat eth.tmp | grep Base1 |  awk \-F \" \" \'\{print \$1\}\'`;
   my $eth_D= `cat eth.tmp | grep Base2 |  awk \-F \" \" \'\{print \$1\}\'`;
   
   chomp($eth_A);
   chomp($eth_B);
   chomp($eth_C);
   chomp($eth_D);
   
   
   ##总线
   my $Fabric1_A1=` more eth.tmp | grep Fabric1 | awk -F \" \" \'\{print \$2\}\' | awk \-F \"\,\" \'\{print \$1\}\' `;
   my $Fabric1_A2=` more eth.tmp | grep Fabric1 | awk -F \" \" \'\{print \$2\}\' | awk \-F \"\,\" \'\{print \$2\}\' `;
   my $Base1_A1=` more eth.tmp | grep Base1 | awk -F \" \" \'\{print \$2\}\' | awk \-F \"\,\" \'\{print \$1\}\' `;
   my $Base1_A2=` more eth.tmp | grep Base1 | awk -F \" \" \'\{print \$2\}\' | awk \-F \"\,\" \'\{print \$2\}\' `;
   
   chomp($Fabric1_A1);
   chomp($Fabric1_A2);
   chomp($Base1_A1);
   chomp($Base1_A2);
   
   ##10转16进制
   my $Fabric_ZX_1=`echo "obase=16;$Fabric1_A1"|bc`;
   my $Fabric_ZX_2=`echo "obase=16;$Fabric1_A2"|bc`;
   my $Base_ZX_1=`echo "obase=16;$Base1_A1"|bc`;    
   my $Base_ZX_2=`echo "obase=16;$Base1_A2"|bc`;
   
   ##全部转换成小写 add by wangyunzeng  2012-11-06
   ##-----begin-----##
   $Fabric_ZX_1=lc($Fabric_ZX_1);
   $Fabric_ZX_2=lc($Fabric_ZX_2);
   $Base_ZX_1=lc($Base_ZX_1);
   $Base_ZX_2=lc($Base_ZX_2);
   ##------end------##
      
   chomp($Fabric_ZX_1);
   chomp($Fabric_ZX_2);
   chomp($Base_ZX_1);
   chomp($Base_ZX_2);
   
   
   ## 拼接
   my $Fabric_ZX0="0$Fabric_ZX_1:0$Fabric_ZX_2.0";
   my $Fabric_ZX1="0$Fabric_ZX_1:0$Fabric_ZX_2.1";
   my $Base_ZX0="0$Base_ZX_1:0$Fabric_ZX_2.0";
   my $Base_ZX1="0$Base_ZX_1:0$Fabric_ZX_2.1";

   
   ##MAC
   my $eth_A_MAC=`cat ifconfig.txt | grep $eth_A | head -1 | awk \-F \" \" \'\{print \$5\}\'`;
   my $eth_B_MAC=`cat ifconfig.txt | grep $eth_B | head -1 | awk \-F \" \" \'\{print \$5\}\'`;
   my $eth_C_MAC=`cat ifconfig.txt | grep $eth_C | head -1 | awk \-F \" \" \'\{print \$5\}\'`;
   my $eth_D_MAC=`cat ifconfig.txt | grep $eth_D | head -1 | awk \-F \" \" \'\{print \$5\}\'`;
   
   chomp($eth_A_MAC);
   chomp($eth_B_MAC);
   chomp($eth_C_MAC);
   chomp($eth_D_MAC);
   
   ##IP地址,修改SUSE11平台ifconfig显示大网地址在小网地址后，获取大网地址错误问题，注释掉原cat和chomp操作，2013-05-08
   #my $IP_A=`cat ifconfig.txt | grep "inet addr" | head -1  | awk -F \" \" \'\{print \$2\}\' | sed \'s\/addr\:\/\/\'`;
   my $IP_C=`cat ifconfig.txt | grep "inet addr" | sort -r | head -1  | awk -F \" \" \'\{print \$2\}\' | sed \'s\/addr\:\/\/\'`;
   #chomp($IP_A);
   chomp($IP_C);
   
   #print "\n$IP_A\n";
   #print "\n$IP_C\n";
   
   ##写bind文件
   open(BOND0,"&gt;ifcfg-bond0") || die "\nOpen file failed:$!\n\n";
      print BOND0 "BOOTPROTO='static'\n";
      print BOND0 "STARTMODE='onboot'\n";
      print BOND0 "WIRELESS='no'\n";
      print BOND0 "device='bond0'\n";
      print BOND0 "IPADDR='$IP_A'\n";
      print BOND0 "NETMASK='255.255.254.0'\n";
      print BOND0 "REMOTE_IPADDR=''\n";
      print BOND0 "BONDING_MASTER='yes'\n";
      print BOND0 "BONDING_MODULE_OPTS='mode=1 miimon=200'\n";
      
      #增加SUSE11平台网卡绑定操作
      if($cornel=~m/Server 10/i  || $cornel=~m/Server 9/i )
      {
        print BOND0 "BONDING_SLAVE0=' bus-pci-0000:$Fabric_ZX0'\n";
        print BOND0 "BONDING_SLAVE1=' bus-pci-0000:$Fabric_ZX1'\n";
      }
      elsif($cornel=~m/Server 11/i)
      {
        print BOND0 "BONDING_SLAVE0='$eth_A'\n";
        print BOND0 "BONDING_SLAVE1='$eth_B'\n";  
      }

   close(BOND0);


   
   
   open(BOND1,"&gt;ifcfg-bond1") || die "\nOpen file failed:$!\n\n";
      print BOND1 "BOOTPROTO='static'\n";
      print BOND1 "STARTMODE='onboot'\n";
      print BOND1 "WIRELESS='no'\n";
      print BOND1 "device='bond1'\n";
      print BOND1 "IPADDR='$IP_C'\n";
      print BOND1 "NETMASK='255.255.255.0'\n";
      print BOND1 "REMOTE_IPADDR=''\n";
      print BOND1 "BONDING_MASTER='yes'\n";
      print BOND1 "BONDING_MODULE_OPTS='mode=1 miimon=200'\n";
      
      #增加SUSE11平台网卡绑定操作
      if($cornel=~m/Server 10/i  || $cornel=~m/Server 9/i )
      {
        print BOND1 "BONDING_SLAVE0=' bus-pci-0000:$Base_ZX0'\n";
        print BOND1 "BONDING_SLAVE1=' bus-pci-0000:$Base_ZX1'\n"; 
      }
      elsif($cornel=~m/Server 11/i)
      {
        print BOND1 "BONDING_SLAVE0='$eth_C'\n";
        print BOND1 "BONDING_SLAVE1='$eth_D'\n";  
      }

   close(BOND1);
   
   
   ##写网卡文件
   #增加SUSE11平台支持,2013-05-08
   if($cornel=~m/Server 10/i  || $cornel=~m/Server 9/i )
   {
    open(ETHA,"&gt;ifcfg-$eth_A-id-$eth_A_MAC") || die "\nOpen file failed:$! \n\n";
   }
   elsif($cornel=~m/Server 11/i)
   {
    open(ETHA,"&gt;ifcfg-$eth_A") || die "\nOpen file ifcfg-$eth_A failed:$! \n\n";
   }
   #open(ETHA,"&gt;ifcfg-$eth_A-id-$eth_A_MAC") || die "\nOpen file failed:$! \n\n";
       print ETHA "DEVICE='$eth_A'\n";
       print ETHA "BOOTPROTO='static'\n"; 
       print ETHA "STARTMODE='onboot'\n";
   close(ETHA);
   
  if($cornel=~m/Server 10/i  || $cornel=~m/Server 9/i )
   {
    open(ETHB,"&gt;ifcfg-$eth_B-id-$eth_B_MAC") || die "\nOpen file failed:$! \n\n";
   }
   elsif($cornel=~m/Server 11/i)
   {
    open(ETHB,"&gt;ifcfg-$eth_B") || die "\nOpen file failed:$! \n\n";
   }
   #open(ETHB,"&gt;ifcfg-$eth_B-id-$eth_B_MAC") || die "\nOpen file failed:$! \n\n";
       print ETHB "DEVICE='$eth_B'\n";
       print ETHB "BOOTPROTO='static'\n";                                                 
       print ETHB "STARTMODE='onboot'\n";
   close(ETHB);
   
  if($cornel=~m/Server 10/i  || $cornel=~m/Server 9/i )
   {
    open(ETHC,"&gt;ifcfg-$eth_C-id-$eth_C_MAC") || die "\nOpen file failed:$! \n\n";
   }
   elsif($cornel=~m/Server 11/i)
   {
    open(ETHC,"&gt;ifcfg-$eth_C") || die "\nOpen file failed:$! \n\n";
   }   
   #open(ETHC,"&gt;ifcfg-$eth_C-id-$eth_C_MAC") || die "\nOpen file failed:$! \n\n";
       print ETHC "DEVICE='$eth_C'\n";
       print ETHC "BOOTPROTO='static'\n";                                                 
       print ETHC "STARTMODE='onboot'\n";
   close(ETHC);
   
  if($cornel=~m/Server 10/i  || $cornel=~m/Server 9/i )
   {
    open(ETHD,"&gt;ifcfg-$eth_D-id-$eth_D_MAC") || die "\nOpen file failed:$! \n\n";
   }
   elsif($cornel=~m/Server 11/i)
   {
    open(ETHD,"&gt;ifcfg-$eth_D") || die "\nOpen file failed:$! \n\n";
   }   
   #open(ETHD,"&gt;ifcfg-$eth_D-id-$eth_D_MAC") || die "\nOpen file failed:$! \n\n";
       print ETHD "DEVICE='$eth_D'\n";
       print ETHD "BOOTPROTO='static'\n";                                                 
       print ETHD "STARTMODE='onboot'\n";
   close(ETHD);
}

#文件清理
sub clear
{
  if($cornel=~m/Server 10/i  || $cornel=~m/Server 9/i )
  {
    ##删除原网卡配置文件
    system("rm  -f ifcfg-eth-id-*");
  }
  #elsif($cornel=~m/Server 11/i)
  #{
  #  ##删除原网卡配置文件
  #  system("rm  -f ifcfg-eth[0-9]");
  #}
  #else
  #{
  #  print "\n不支持的操作系统类型，程序退出!\n";
  #  exit
  #}

  ##清理其他文件
  unlink("eth.tmp");
  unlink("ifconfig.txt");
}
</code></pre>
]]></content>
      <categories>
        <category>perl</category>
      </categories>
      <tags>
        <tag>perl</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux录屏与回放</title>
    <url>/2013/05/21/linux_script_replay/</url>
    <content><![CDATA[<h1 id="lu-zhi-yu-hui-fang-zhong-duan-hui-hua">录制与回放终端会话</h1>
<p>当你需要为别人在终端上演示某些操作，或者是需要准备一个命令行教程时，通常要一边手动输入命令一边进行演示，或者录制一段演示视频进行播放。如果我们将输入命令后发生的一切，安装一定的先后顺序记录下来，再进行回访，从而使得观众好像身临其境一样，这个想法听起来如何？命令的输出会显示在终端上，一直到回访内容播放完毕，所有的这些，都可以使用script和scriptreplay命令来实现。</p>
<h1 id="yu-bei-zhi-shi">预备知识</h1>
<p>script 和 scriptreplay命令在绝大多数GNU/Linux发行版本上都可以找到。把终端会话记录到一个文件，可以通过录制终端会话来制作命令行技巧视频，也可以与他人分享会话记录文件，共同研究如何使用这些命令行完成某项任务。</p>
<h1 id="shi-zhan-yan-lian">实战演练</h1>
<h2 id="script-chang-yong-xuan-xiang">script常用选项</h2>
<p>更详细的说明可以man script来查看</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-a, - -append</td>
<td>输出录制的文件，在现有内容上追加新的内容</td>
</tr>
<tr>
<td>-c, - -command</td>
<td>直接执行命令，而非是交互式的shell</td>
</tr>
<tr>
<td>-r, - -return</td>
<td>返回子shell的退出码</td>
</tr>
<tr>
<td>-f, - -flush</td>
<td>每次操作后都立即刷新缓存。 如果不设置这个选项，则不会实时写入文件</td>
</tr>
<tr>
<td>-q, - -quiet</td>
<td>可以使script命令以静默模式运行，不显示script启动和exit的命令，用户可以完全察觉不到在录屏</td>
</tr>
<tr>
<td>-t, - -timing[=<file>]</file></td>
<td>输出录制的时间数据，输出到屏幕或者存到指定文件中，回放的时候用到</td>
</tr>
<tr>
<td>-V, - -version</td>
<td>显示版本并退出</td>
</tr>
<tr>
<td>-h, - -help</td>
<td>显示使用说明并退出</td>
</tr>
</tbody>
</table>
<h2 id="scriptreplay">scriptreplay</h2>
<table>
<thead>
<tr>
<th>选项</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>-t, - -timing file</td>
<td>包含记录时序的文件</td>
</tr>
<tr>
<td>-s, - -typescript file</td>
<td>包含脚本终端输出的文件</td>
</tr>
<tr>
<td>-d, –divisor number</td>
<td>加速播放速度倍数（可以是小数：放慢）</td>
</tr>
<tr>
<td>-V, - -version</td>
<td>显示版本并退出</td>
</tr>
<tr>
<td>-h, - -help</td>
<td>显示使用说明并退出</td>
</tr>
</tbody>
</table>
<p>开始录制终端会话：</p>
<pre><code class="language-shell">root@host245:~/tmp# script -t 2&gt; timeing.log -a output.session
Script started, file is output.session
root@host245:~/tmp# ls -l
total 4
-rw-r--r-- 1 root root  0 Nov 26 11:38 output.session
-rw-r--r-- 1 root root 78 Nov 26 11:38 timeing.log
root@host245:~/tmp# cd
root@host245:~# cd -
/root/tmp
root@host245:~/tmp# exit
exit
Script done, file is output.session
</code></pre>
<p>两个文件（timeing.log 和 output.session）被当做script命令的参数，其中timeing.log用于存储时序信息，描述每一个指令在何时运行；另外一个文件output.session用于存储命令输出。</p>
<p>-t选项用于将时序数据导入stderr； 2&gt;则用于将stedrr重定向到timing.log文件。</p>
<p>借助这两个文件：timeing.log（存储时序信息） 和 output.session（存储命令输入信息），我们可以按照下面的方法回放命令的执行过程：</p>
<pre><code class="language-shell">root@host245:~/tmp# scriptreplay timeing.log output.session 
</code></pre>
<h1 id="gong-zuo-yuan-li">工作原理</h1>
<p>通常我们会录制桌面环境视频来作为教程使用，不过要注意的是，视频需要更大的存储空间，而终端脚本文件仅仅是文本文件，大小不过KB级别。</p>
<p>script命令同样可以用于建立可在多个用户之间进行广播的视频会话，这是件很有意思的事情，来看看它是如何实现的吧。</p>
<p>打开两个终端，Terminal1 和 Terminal2</p>
<p>在Terminal1中输入如下命令：</p>
<pre><code class="language-shell">root@host244:~# mkfifo scriptfifo

</code></pre>
<p>在Terminal2中输入如下命令：</p>
<pre><code class="language-shell">root@host244:~# cat scriptfifo
</code></pre>
<p>返回Terminal1，输入以下命令：</p>
<pre><code class="language-shell">root@host244:~# script -f scriptfifo
root@host244:~# some other linux command, such as ls, cd, mkdir and so on
</code></pre>
<p>如果需要结束会话，输入exit并按回车，会得到如下信息：</p>
<p><code>Script done, file is scriptfifo </code></p>
<p>现在，Terminal1就成了广播员，Terminal2则成为了听众。不管你在Terminal1中输入什么内容，都会在Terminal2或者使用了下列命令的任何终端中实时播放：</p>
<p><code>cat scriptfifo</code></p>
<p>当你需要为计算机实验室或者Internet上的用户群演示教程时，不妨考虑这个方法，它在节省带宽的同时，也提供了实体试验。</p>
<h1 id="ling-wai-yi-ge-gong-xiang-ping-mu-de-fang-fa">另外一个共享屏幕的方法</h1>
<p>可以使用tmux，将tmux的session id告知大家，所有人都在Terminal中切换到这个tmux session，一个人的任何输入输出操作， 其他在这个会话中的人都可以看到。缺点是：在这个tmux session的人，都有执行命令的权限。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>彩信网关数据库自动升级与比对（QCC）</title>
    <url>/2013/07/05/auto_upgrade_commpare/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>原始文件是个ppt，大约是在2013年在网关测试组测试时，写了一个QCC，获奖了哦~~</p>
<p>现在把PPT截图放出来，做了关键信息的屏蔽处理，望见谅~</p>
<h1 id="mmsg-qcc-auto-upgrade-ping-shen-xiao-pian">MMSG QCC auto upgrade 评审胶片</h1>
<img class="shadow" src="/img/in-post/qcc_1.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_2.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_3.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_4.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_5.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_6.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_7.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_8.png" width="1200">
<p>说明：</p>
<p>测试环境准备：包括但不限制于：测试环境准备、产品部署、数据导入等操作</p>
<img class="shadow" src="/img/in-post/qcc_9.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_10.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_11.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_12.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_13.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_14.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_15.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_16.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_17.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_18.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_19.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_20.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_21.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_22.png" width="1200">
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>cfg：存放产品的配置文件信息，方便产品安装与部署</p>
</li>
<li class="lvl-2">
<p>cls_db.pl：用于清理数据库中对象，包括表、视图、存储过程、package等对象</p>
</li>
<li class="lvl-2">
<p><a href="http://compare.pl">compare.pl</a>：用于数据的比对，并将结果保存到文件</p>
</li>
<li class="lvl-2">
<p>config：存放配置文件信息</p>
</li>
<li class="lvl-2">
<p>data：存放现网数据，即dmp文件</p>
</li>
<li class="lvl-2">
<p>exp_date.pl：导出数据</p>
</li>
<li class="lvl-2">
<p>exp_parameter.pl：导出参数数据</p>
</li>
<li class="lvl-2">
<p>imp_data.pl：导入现网数据</p>
</li>
<li class="lvl-2">
<p><a href="http://main.pl">main.pl</a>：调用其他的所有的pl脚本</p>
</li>
<li class="lvl-2">
<p>m_manager：存放XXC的相关升级脚本</p>
</li>
<li class="lvl-2">
<p>mmsg：存放XXA的相关升级脚本</p>
</li>
<li class="lvl-2">
<p>package：存放安装包，无需解压的gz或Z包</p>
</li>
<li class="lvl-2">
<p>sms：存放XXB的相关升级脚本</p>
</li>
<li class="lvl-2">
<p>syslib：Perl模块，解决AIX平台未安装Config模块无法从配置文件获取信息问题</p>
</li>
</ul>
<img class="shadow" src="/img/in-post/qcc_23.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_24.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_25.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_26.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_27.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_28.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_29.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_30.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_31.png" width="1200">
<img class="shadow" src="/img/in-post/qcc_32.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
      </categories>
      <tags>
        <tag>Automation</tag>
      </tags>
  </entry>
  <entry>
    <title>根据文件列求和</title>
    <url>/2014/01/21/file_column_summation/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>工作中，常常会用到对某个测试结果进行数据汇总，就需要求和，比如求IOPS，或者带宽值，总不能拷贝出来，贴到excel中去求和、求平均值吧。。。</p>
<h1 id="dui-wen-jian-zhong-mou-yi-lie-jin-xing-shu-zhi-qiu-he">对文件中某一列进行数值求和</h1>
<p>示例:</p>
<pre><code class="language-shell">198 MMSGSUSE11 [wyz] :/home/wyz/perl/testcase&gt;more tmp.txt
testAddCountryCode.AddCountryCode 5 0 0 796.28
testChcekSAGipNormal.ChcekSAGIPNormalTest 3 0 0 418.28
testCheckInfoNormal.CheckInfoNormalTest 3 0 0 748.26
testCheckSAGIPNormal.StageInteractiveNormalTest 3 0 0 804.79
testCheckSPinfo.CheckSPinfoTest 12 0 0 1736.24
testConsumModify.ConsumModify 8 0 0 2628.19
testCountryCodeAbnormalCase.CountryCodeAbnormalTest 3 0 0 899.41
testDelCountryCode.DelCountryCodeTest 5 0 0 1512.43
testEmigratedInteractive.EmigratedInteractiveTest 1 0 0 401.68
testGeneralOndemand.OndemandTest 10 0 0 2835.79
testGeneralOndemandAbnormal.OnDemandAbnormal 4 0 0 1029.27
testGiveOndemandAbnormal.GiveOndemandAbnormal 2 0 0 115.75
</code></pre>
<p>求和操作：</p>
<pre><code class="language-shell">200 MMSGSUSE11 [wyz] :/home/wyz/perl/testcase&gt;awk '{m+=$2} END{print m}' tmp.txt
59
</code></pre>
<h1 id="dui-duo-lie-qiu-he">对多列求和</h1>
<p>示例：</p>
<pre><code class="language-shell">201 MMSGSUSE11 [wyz] :/home/wyz/perl/testcase&gt;more t.txt
00|M00a|0A|a00|0.00|15.00
00|M00a|0A|a00|0.00|15.00
00|M0Z1|0B|my|10.00|0.00
00|M0Z1|0A|a00|10.00|0.00
00|M005|0A|a00|0.00|1.48
00|M005|0A|a00|2.96|0.00
00|M005|0A|a00|2.96|0.00
</code></pre>
<p>求和操作：</p>
<pre><code class="language-shell">202 MMSGSUSE11 [wyz] :/home/wyz/perl/testcase&gt;awk -F '|' '{m+=$5;n+=$6} END {print m,n}' t.txt
25.92 31.48
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>awk</tag>
        <tag>sum</tag>
      </tags>
  </entry>
  <entry>
    <title>替换文件中空格</title>
    <url>/2014/06/06/delete_space_in_files/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>有时候一些目录下的文件有一些空格，想对这些文件中的空格进行批量删除，该如何做呢？主要使用awk, tr，sed之类的命令，进行替换操作。</p>
<h1 id="mu-lu-xia-wen-jian-de-zheng-ti-qu-chu-kong-ge">目录下文件的整体去除空格</h1>
<p>使用shell脚本进行批量处理，示例如下：</p>
<pre><code class="language-shell">#!/usr/bin/bash

ls|while read i;do  

    mv "$i" $(echo $i|tr -d ' ') 2&gt;/dev/null  

done 
</code></pre>
<h1 id="dan-ge-wen-jian-de-kong-ge-chu-li-shan-chu-suo-you-kong-ge">单个文件的空格处理–删除所有空格</h1>
<p>方法1：<br>
<code>sed 's/\s//g' input.txt | tr -d '\n' </code></p>
<p>方法2：Perl一行命令</p>
<p><code>perl -CS -pe 's/\p{Space}//g' &lt; input &gt; output </code></p>
<p>方法3：<br>
<code>tr -d ' \t\n\r\f' &lt;inputFile &gt;outputFile </code></p>
<p>方法4:<br>
<code>sed 's/\s//g'|tr -d '\n' </code></p>
<p>方法5：<br>
<code>sed s/[[:space:]]//g </code></p>
<p>示例：</p>
<p>比如下面的文件a.txt，内容如下：</p>
<pre><code class="language-shell">root@cvm02:~/test# cat a.txt 
1

2
3  4
5
6
7  8
9
</code></pre>
<p><code>root@cvm02:~/test# tr -d ' ' &lt;a.txt  &gt;b.txt</code></p>
<p>查看替换后的效果：</p>
<pre><code class="language-shell">root@cvm02:~/test# cat b.txt 
1

2
34
5
6
78
9
</code></pre>
<h1 id="shan-chu-xing-shou-kong-ge">删除行首空格</h1>
<p>代码如下:</p>
<pre><code class="language-shell">sed 's/^[ \t]*//g'
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>第一个/的左边是s表示替换，即将空格替换为空</p>
<ul class="lvl-2">
<li class="lvl-4">第一个/的右边是表示后面的以xx开头</li>
<li class="lvl-4">中括号表示“或”，空格或tab中的任意一种。这是正则表达式的规范</li>
<li class="lvl-4">中括号右边是*，表示一个或多个</li>
</ul>
</li>
<li class="lvl-2">
<p>第二个和第三个\中间没有东西，表示空</p>
</li>
<li class="lvl-2">
<p>g表示替换原来buffer（缓冲区）中的，sed在处理字符串的时候并不对源文件进行直接处理，先创建一个buffer，但是加g表示对原buffer进行替换</p>
</li>
<li class="lvl-2">
<p>整体的意思是：用空字符去替换一个或多个用空格或tab开头的本体字符串</p>
</li>
</ul>
<h1 id="shan-chu-xing-mo-kong-ge">删除行末空格</h1>
<p>代码如下:</p>
<pre><code class="language-shell">sed 's/[ \t]*$//g'
</code></pre>
<p>和上面稍微有些不同是前面删除了^符，在后面加上了美元符，这表示以xx结尾的字符串为对象。</p>
<h1 id="awk-qu-chu-kong-ge">awk去除空格</h1>
<p>代码如下:</p>
<pre><code class="language-shell">awk '{gsub(/^ +| +$/,"",$0);printf $0}'
</code></pre>
<p>效果：</p>
<pre><code class="language-shell">root@cvm02:~/test# cat a.txt | awk '{gsub(/^ +| +$/,"",$0);printf $0}'
123  4567  89root@cvm02:~/test# 
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>awk</tag>
        <tag>sed</tag>
        <tag>tr</tag>
      </tags>
  </entry>
  <entry>
    <title>替换文件中空行</title>
    <url>/2014/06/07/delete_line_in_file/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文主要描述，如果在Linux下，使用命令行方式，对文本文件中的空行进行替换操作</p>
<h1 id="vi-mo-shi">vi模式</h1>
<p>真正删除空行，可以使用vim</p>
<p>通过命令模式删除空行。vim在命令模式下(在vim里输入英文字符:进入命令模式)输入： %s/^n//g 。意思是全局替换所有以回车开头的字符，替换为空。如果有多个连续的空行，想保留一行。则只需在命令行模式输入下行即可：%s/^n$//g</p>
<h1 id="linux-pipline-fang-shi">Linux pipline方式</h1>
<p>主要是删除方法，使用grep，awk，sed，tr，xargs等命令进行处理</p>
<h2 id="grep">grep</h2>
<p><code>grep -v '^$' filename </code></p>
<p>或</p>
<p><code>grep -vE "^[[:blank:]]*$" filename </code></p>
<h2 id="sed">sed</h2>
<p><code>sed '/^$/d'  filename </code></p>
<p>或</p>
<p><code>sed -n '/./p' filename </code></p>
<p>或</p>
<p><code>sed '/^[[:blank:]]*$/d' filename </code></p>
<h2 id="awk">awk</h2>
<p>$0表示一行</p>
<p><code>awk '/./ {print}' filename </code></p>
<p>或</p>
<p><code>awk '!/^[[:blank:]]*$/{print $0}' filename </code></p>
<p>或</p>
<p><code>awk '{if($0!="") print}' </code></p>
<h2 id="tr">tr</h2>
<p><code>tr -s "\n" </code></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>awk</tag>
        <tag>sed</tag>
        <tag>tr</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title>Perl常用代码汇总</title>
    <url>/2014/06/13/perl_script_summary/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>初学perl，汇总了一下，在工作中使用perl写测试脚本常用到的一些代码块信息。</p>
<h1 id="xiang-guan-dai-ma-an-li">相关代码案例</h1>
<h2 id="wen-jian-cao-zuo">文件操作</h2>
<h3 id="cha-zhao-zhi-ding-mu-lu-xia-wen-jian-jia">查找指定目录下文件夹</h3>
<pre><code class="language-perl">use File::Find;
my @files;

sub want
{
#push @files,$_ if -d $_;
push @files,$_ if -d $_ and !/^\.{1,2}/;
}

find(\&amp;want,'/home/wyz/');
print "\nfiles:@files\n";
</code></pre>
<h3 id="zhao-chu-mu-lu-xia-suo-you-wen-jian">找出目录下所有文件</h3>
<pre><code class="language-perl">my @file_names=grep {-f and -T} glob '*';
print "\nfile_names:@file_names\n";
</code></pre>
<h3 id="huo-qu-zhi-ding-mu-lu-xia-suo-you-wen-jian">获取指定目录下所有文件</h3>
<pre><code class="language-perl">#!/usr/bin/perl
use warnings;
use strict;
use File::Find;

my $dir = shift || die "Please input a directory!!!";

find (\&amp;handle,$dir);

sub handle
{
    print $File::Find::name,"\n" if -f $_;
}
</code></pre>
<h2 id="huo-qu-jiao-ben-dang-qian-lu-jing">获取脚本当前路径</h2>
<pre><code class="language-perl">use File::Basename;
my $dir = File::Basename::dirname($0);
print $dir;
</code></pre>
<h2 id="chuang-jian-mu-lu">创建目录</h2>
<pre><code class="language-perl">  #文件存放路径
  unless (-d "$USER.load")
  {
      mkdir("$USER.load", 0755) || die "Make directory $USER.load error.\n";
  }
  chdir "$USER.load";
</code></pre>
<h2 id="wen-jian-ju-bing">文件句柄</h2>
<p>​</p>
<pre><code class="language-perl"> for(my $i=1; $i&lt;=$scalar;$i++)
         {                                                                                              
            open(SQLPLUS, "|sqlplus -S $USER/$USERPASS\@$SID &gt;/dev/null") || die "Execute sqlplus error!\n";
            print SQLPLUS "set feedback off\nset sqlnumber off\n";
            print SQLPLUS "set pagesize 0\n";
            print SQLPLUS "set trimspool off\n";
            print SQLPLUS "set sqlblanklines off\n";
            print SQLPLUS "spool $array[$i].wyz_tmp\n";
            print SQLPLUS "desc $array[$i]\n";
            print SQLPLUS "spool off\n";
            close(SQLPLUS) || die "Execute sql error!\n";
         }
</code></pre>
<h2 id="cong-pei-zhi-wen-jian-huo-qu-shu-ju">从配置文件获取数据</h2>
<pre><code class="language-perl">use FindBin qw ($Bin);                                                          #解决AIX未安装Config::IniFiles模块问题
use lib "$Bin/syslib";
use Config::IniFiles;

#从配置文件中获取信息
my $cfg = Config::IniFiles-&gt;new( -file =&gt; "$cur_path/config/init.cfg" );

my $DB_USER=$cfg-&gt;val('COMPARE_DATA','DB_USER') || '';                          #连接数据库的用户名
my $DB_PASS=$cfg-&gt;val('COMPARE_DATA','DB_PASS') || '';                          #连接数据库的用户名对应的口令
my $DB_IDENTIFIED=$cfg-&gt;val('COMPARE_DATA','DB_IDENTIFIED') || '';              #连接数据库的标识
my $PROC_TYPE=$cfg-&gt;val('COMPARE_DATA','PROC_TYPE') || '';                      #产品类型
my $IS_SCENE=$cfg-&gt;val('COMPARE_DATA','IS_SCENE') || '';                        #是否使用现网数据
my $BEFORE_AFTER_VERSION=$cfg-&gt;val('COMPARE_DATA','BEFORE_AFTER_VERSION') || '';#升级前版本号
my $UPDATE_TO_VERSION=$cfg-&gt;val('COMPARE_DATA','UPDATE_TO_VERSION') || '';      #升级后版本号
</code></pre>
<h2 id="ding-yi-ri-zhi">定义日志</h2>
<pre><code class="language-perl">my $start_date = ostime(time);                                                  #时间，日志内容中使用，年月日时分秒
my $logtime=shortTimeString(time);                                              #时间，日志文件命名使用,年月日时分
my $script_log="$script_dir/update_db_$logtime.log";                            #定义脚本执行过程中日志记录信息


</code></pre>
<h2 id="nian-yue-ri-xiao-shi-fen-miao-yong-yu-ri-zhi-wen-jian-nei-rong-zhong-ji-lu-de-shi-jian">年月日小时分秒，用于日志文件内容中记录的时间</h2>
<pre><code class="language-perl">sub ostime 
{
 my ($tm) = @_;
 my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) = localtime($tm);
 return sprintf("%04d-%02d-%02d %02d:%02d:%02d", $year+1900, $mon+1, $mday, $hour, $min, $sec);
}
</code></pre>
<h2 id="nian-yue-ri-xiao-shi-fen-yong-yu-ri-zhi-wen-jian-ming-ming">年月日小时分，用于日志文件命名</h2>
<pre><code class="language-perl">sub shortTimeString 
{
 my ($tm) = @_;
 my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) = localtime($tm);
 return sprintf("%04d_%02d_%02d_%02d_%02d", $year+1900, $mon+1, $mday, $hour, $min);
}
</code></pre>
<h2 id="ji-lu-ri-zhi">记录日志</h2>
<pre><code class="language-perl">sub LOG {
 my ($text) = @_;
 my $time = ostime time;
 print "\n[$time] $text\n";

 open(UPDATELOG,"&gt;&gt;$script_log") or die("打开日志文件[$script_log]出错: $!");
 print UPDATELOG "\n[$time] $text\n";
 close UPDATELOG;
}
</code></pre>
<h2 id="wen-jian-shu-xing-xin-xi">文件属性信息</h2>
<pre><code class="language-perl">use warnings;
use strict;

die "请输入文件名称\n" unless(@ARGV&gt;=1);

print "\n检测文件信息:\n";

foreach my $file(@ARGV)
{
    if(-e $file)
    {
        print "\n存在文件:$file\n";
        

    if(-f $file)
    {
        print "可读\n" if(-r $file);
        print "可写\n" if(-w $file);
        print "可执行\n" if(-x $file);
        
        print "文件大小是:", -s $file,"Bytes\n";
        
        my @time=timeconv(-A $file);
        print "\n距离上次访问文件 $file 时间是 $time[0] 天 $time[1] 小时 $time[2] 分 $time[3] 秒.\n";
        
        @time=timeconv(-M $file);
        print "\n距离上次修改文件 $file 时间是 $time[0] 天 $time[1] 小时 $time[2] 分 $time[3] 秒.\n";          
    }
}
elsif(-d $file)
{
    print "\n$file 是个目录\n";
}
else
{
    print "\n$file 不存在\n";
}

}


sub timeconv
{
    my $time=shift;
    my $days=int($time);
    $time=($time-$days)*24;
    

    my $hours=int($time);
    $time=($time-$hours)*60;
    
    my $minutes=int($time);
    $time=($time-$minutes)*60;
    
    my $seconds=int($time);
    return ($days,$hours,$minutes,$seconds);    

}
</code></pre>
<h1 id="cao-zuo-xi-tong-xiang-guan">操作系统相关</h1>
<h2 id="huo-qu-cao-zuo-xi-tong-ming-cheng">获取操作系统名称</h2>
<pre><code class="language-perl">use Sys::Hostname;
print hostname,"\n";
</code></pre>
<h3 id="cao-zuo-xi-tong-lei-xing">操作系统类型</h3>
<pre><code class="language-perl">chomp(my $OS_Type = $^O);
</code></pre>
<p>$OS_Type打印结果为：<code>linux/MSWin32/SUNOS</code>等</p>
<h2 id="zi-dong-guan-ji">自动关机</h2>
<pre><code class="language-perl">use Win32;

my $machine = Win32::NodeName();
my $timeout = 3600;
if($ARGV[0])
{
    $timeout = $ARGV[0];
}

my $message = Win32::MsgBox("即将在 $timeout 秒后自动关机.
如想取消，请进入dos界面执行 shutdown -a 操作.");
Win32::InitiateSystemShutdown($machine,$message,$timeout,1,1);
</code></pre>
<p>说明：</p>
<pre><code class="language-perl">  Win32::InitiateSystemShutdown
   (MACHINE, MESSAGE, TIMEOUT, FORCECLOSE, REBOOT)

   Shutsdown the specified MACHINE, notifying users with the supplied
   MESSAGE, within the specified TIMEOUT interval. Forces closing of
   all documents without prompting the user if FORCECLOSE is true, and
   reboots the machine if REBOOT is true. This function works only on WinNT.
</code></pre>
<h2 id="sheng-cheng-sui-ji-mi-ma">生成随机密码</h2>
<h3 id="chan-sheng-sui-ji-mi-ma">产生随机密码</h3>
<pre><code class="language-perl">my @input=(1..9,'a'..'z');
my $passwd= join '',map {$input[int rand @input]} 0..7;
print "\n随机密码为:$passwd\n";
</code></pre>
<p>这里的 0…7，约束了密码的长度，输出长度为8，rand后面的@input是个标量，即长度。</p>
<h1 id="usage">Usage</h1>
<h2 id="fang-fa-1">方法1</h2>
<pre><code class="language-perl">#!/usr/bin/perl
use warnings;
use strict;

die "\n\tUsage: perl $0 parameter1 parameter2 parameter3\n\n" unless(@ARGV==3);   

print "\ntest\n\n";
</code></pre>
<h2 id="fang-fa-2">方法2</h2>
<pre><code class="language-perl">my $file = $ARGV[0] or die "\n  [ERROR]   请脚本名称后面携带CSV文件!\n\n";
</code></pre>
<h1 id="pan-duan-jiao-ben-shi-fou-yi-jing-you-zai-yun-xing">判断脚本是否已经有在运行</h1>
<pre><code class="language-perl">exit if 2 == grep { /perl/ }  qx{ ps aux|grep $0 };
</code></pre>
<p>具体示例如下述</p>
<pre><code class="language-perl">print "程序已运行，退出!\n" and exit if 2==grep {/$0/i} `ps -ef | grep $0 | grep -v grep`;
</code></pre>
<h1 id="shu-zu">数组</h1>
<h2 id="wen-jian-nei-rong-fang-ru-shu-zu">文件内容放入数组</h2>
<pre><code class="language-perl">my $FH;
my @bug_array;

open($FH,"tmp.csv") or die "\nOpen file faild,$!\n\n";
{
    @bug_array=&lt;$FH&gt;;
    @bug_array=sort @bug_array;
}
close($FH);


redo
my $response;

{
   print "\n是否继续:[yes/no]\n";
   chomp($response=&lt;STDIN&gt;);
   $response=lc($response);

   $response eq "yes" or $response eq "y" or $response eq "n" or $response eq "no" or
   print "\n只能输入y/yes/n/no中的一个，请重新输入:\n" and redo;
}

print "\n你选择了 $response\n"
</code></pre>
]]></content>
      <categories>
        <category>perl</category>
      </categories>
      <tags>
        <tag>perl</tag>
      </tags>
  </entry>
  <entry>
    <title>手机整机测试</title>
    <url>/2014/07/21/mobile_phone_testing/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>做了一段时间的手机整机测试工作，虽然没有全面的去做，毕竟手机整机测试涉及的方方面面非常的广泛，我只负责其中的一小部分，比如功耗和Appium Automation部分，当然也设计Monkey相关工具的使用。</p>
<p>现简单汇总一下手机整机测试的一些信息点，比较粗略的记录一下主要测试点/方向。</p>
<h1 id="gai-shu">概述</h1>
<p>手机的整机测试（也称为手机全面测试或手机集成测试）是确保手机在各个方面都符合预期性能和质量标准的过程。这通常包括硬件、软件和用户界面的测试。</p>
<h1 id="x-mind-si-wei-dao-tu">XMind思维导图</h1>
<img class="shadow" src="/img/in-post/手机整机测试.png" width="800">
]]></content>
      <categories>
        <category>Phone</category>
      </categories>
      <tags>
        <tag>Phone</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis入门</title>
    <url>/2014/08/17/introduction_to_redis/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Gikoo的产品后端使用的数据库是Redis，本文介绍Redis的入门。</p>
<h1 id="redis-gai-nian">Redis概念</h1>
<img class="shadow" src="/img/in-post/redis/overview_of_various_databases.png" width="1200">
<p>Redis是一款高性能的NOSQL系列的非关系型数据库。</p>
<h2 id="1-1-shi-yao-shi-nosql">1.1、什么是NOSQL</h2>
<p>NOSQL（NOSQL = Not Only SQL），意即“不仅仅是SQL”，是一项全新的数据库理念，泛指非关系型的数据库。随着互联网Web2.0网站的兴起，传统的关系型数据库在应付Web2.0网站，特别是超大规模和高并发的SNS类型的Web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NOSQL数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题。</p>
<h3 id="1-1-1-nosql-he-guan-xi-xing-shu-ju-ku-bi-jiao">1.1.1、NOSQL和关系型数据库比较</h3>
<p>优点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>成本：NOSQL数据库简单易部署，基本都是开源软件，不需要像使用oracle那样花费大量成本购买使用，相比关系型数据库价格便宜。</p>
</li>
<li class="lvl-2">
<p>查询速度：NOSQL数据库将数据存储于缓存之中，关系型数据库将数据存储在硬盘中，自然查询速度远不及NOSQL数据库。</p>
</li>
<li class="lvl-2">
<p>查询数据的格式：NOSQL的存储格式是key，value形式、文档形式、图片形式等等，所以可以存储基础类型以及对象或者是集合等各种格式，而数据库则只支持基础类型。</p>
</li>
<li class="lvl-2">
<p>扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。</p>
</li>
</ul>
<p>缺点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>维护的工具和资料有限，因为NOSQL是属于新的技术，不能和关系型数据库十几年的技术同日而语。</p>
</li>
<li class="lvl-2">
<p>不提供对SQL的支持，如果不支持SQL这样的工页标准，将产生一定用户的学习和使用成本。</p>
</li>
<li class="lvl-2">
<p>不提供关系型数据库对事务的处理。</p>
</li>
</ul>
<h3 id="1-1-2-fei-guan-xi-xing-shu-ju-ku-de-you-shi">1.1.2、非关系型数据库的优势</h3>
<p>性能NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。</p>
<p>可扩展性同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。</p>
<h3 id="1-1-3-guan-xi-xing-shu-ju-ku-de-you-shi">1.1.3、关系型数据库的优势</h3>
<p>复杂查询可以用SQL语句方便地在一个表以及多个表之间做非常复杂的数据查询。</p>
<p>事务支持使得对于安全性能很高的数据访问要求得以实现。对于这两类数据库，对方的优势就是就是自己的弱势，反之亦然。</p>
<h3 id="1-1-4-zong-jie">1.1.4、总结</h3>
<p>关系型数据库与NOSQL数据库并非对立而是互补的关系，即通常情况下使用关系型数据库，在适合使用NOSQL的时候使用NOSQL数据库，让NOSQL数据库对关系型数据库的不足进行弥补。一般会将数据存储在关系型数据库中，在NOSQL数据库中备份存储关系型数据库的数据。</p>
<h2 id="1-2-zhu-liu-de-nosql-chan-pin">1.2、主流的NOSQL产品</h2>
<h3 id="1-2-1-jian-zhi-key-value-cun-chu-shu-ju-ku">1.2.1、键值（Key-Value）存储数据库</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>相关产品：Tokyo Cabinet/Tyrant、Redis、Voldemort、Berkeley DB。</p>
</li>
<li class="lvl-2">
<p>典型应用：内容缓存，主要用于处理大量数据的高访问负载。</p>
</li>
<li class="lvl-2">
<p>数据模型：一系列键值对。</p>
</li>
<li class="lvl-2">
<p>优势：快速查询。</p>
</li>
<li class="lvl-2">
<p>劣势：存储的数据缺少结构化。</p>
</li>
</ul>
<h3 id="1-2-2-lie-cun-chu-shu-ju-ku">1.2.2、列存储数据库</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>相关产品：Cassandra、HBase、Riak。</p>
</li>
<li class="lvl-2">
<p>典型应用：分布式的文件系统。</p>
</li>
<li class="lvl-2">
<p>数据模型：以列簇式存储，将同一列数据存在一起。</p>
</li>
<li class="lvl-2">
<p>优势：查找速度快，可扩展性强，更容易进行分布式扩展。</p>
</li>
<li class="lvl-2">
<p>劣势：功能相对局限。</p>
</li>
</ul>
<h3 id="1-2-3-wen-dang-xing-shu-ju-ku">1.2.3、文档型数据库</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>相关产品：CouchDB、MongoDB。</p>
</li>
<li class="lvl-2">
<p>典型应用：Web应用（与Key-Value类似，Value是结构化的）。</p>
</li>
<li class="lvl-2">
<p>数据模型：一系列键值对。</p>
</li>
<li class="lvl-2">
<p>优势：数据结构要求不严格。</p>
</li>
<li class="lvl-2">
<p>劣势：查询性能不高，而且缺乏统一的查询语法。</p>
</li>
</ul>
<h3 id="1-2-4-tu-xing-graph-shu-ju-ku">1.2.4、图形（Graph）数据库</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>相关数据库：Neo4J、InfoGrid、Infinite Graph。</p>
</li>
<li class="lvl-2">
<p>典型应用：社交网络。</p>
</li>
<li class="lvl-2">
<p>数据模型：图结构。</p>
</li>
<li class="lvl-2">
<p>优势：利用图结构相关算法。</p>
</li>
<li class="lvl-2">
<p>劣势：需要对整个图做计算才能得出结果，不容易做分布式的集群方案。</p>
</li>
</ul>
<h2 id="1-3-shi-yao-shi-redis">1.3、什么是Redis</h2>
<p>Redis使用C语言开发的一个开源的高性能键值对（Key-Value）数据库，官方提供测试数据，50个并发执行的100000个请求，读的速度是110000次/s，写的速度是81000次/s，且Redis通过提供多种键值数据类型来适应不同场景下的存储需求，摸钱为止Redis支持的键值数据类型如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>字符串类型：string</p>
</li>
<li class="lvl-2">
<p>哈希类型：hash</p>
</li>
<li class="lvl-2">
<p>列表类型：list</p>
</li>
<li class="lvl-2">
<p>集合类型：set</p>
</li>
<li class="lvl-2">
<p>有序集合类型：sortedset</p>
</li>
</ul>
<h3 id="1-3-1-redis-de-ying-yong-chang-jing">1.3.1、Redis的应用场景</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>缓存（数据查询、短连接、新闻内容、商品内容等等）；</p>
</li>
<li class="lvl-2">
<p>聊天室的在线好友列表；</p>
</li>
<li class="lvl-2">
<p>任务队列（秒杀、抢购、12306等等）；</p>
</li>
<li class="lvl-2">
<p>应用排行榜；</p>
</li>
<li class="lvl-2">
<p>网站访问统计；</p>
</li>
<li class="lvl-2">
<p>数据过期处理（可以精确到毫秒）；</p>
</li>
<li class="lvl-2">
<p>分布式集群架构中的session分离。</p>
</li>
</ul>
<h1 id="2-xia-zai-an-zhuang">2、下载安装</h1>
<p>1、官网：<a href="https://redis.io">https://redis.io</a></p>
<p>2、中文网：<a href="http://www.redis.net.cn/download/">www.redis.net.cn/download/</a></p>
<p>3、解压直接可以使用：</p>
<pre><code class="language-shell">redis.windows.conf：配置文件
redis-cli.exe：redis的客户端
redis-server.exe：redis的服务器端
</code></pre>
<h1 id="3-ming-ling-cao-zuo">3、命令操作</h1>
<h2 id="3-1-redis-de-shu-ju-jie-gou">3. 1、Redis的数据结构</h2>
<img class="shadow" src="/img/in-post/redis/redis-struct.png" width="1200">
<pre><code class="language-shell">redis存储的是key-value格式的数据，其中key都是字符串，value有5种不同的数据结构。

value 的数据结构：
    1）字符串类型 string
    2）哈希类型 hash ： map格式
    3）列表类型 list ： linkedlist格式
    4）集合类型 set ： （与list相比不允许重复元素）
    5）有序集合类型 sortedset ： 不允许重复元素，且元素有顺序
</code></pre>
<h2 id="3-2-zi-fu-chuan-lei-xing-string">3.2、字符串类型 string</h2>
<pre><code class="language-shell">1、存储：set key value
2、获取：get key
3、删除：del key
</code></pre>
<h2 id="3-3-ha-xi-lei-xing-hash">3.3、哈希类型 hash</h2>
<pre><code class="language-shell">1、存储：hset key field value
2、获取：
    hget key field：获取指定的field对应的value
    hgetall key：获取所有的field和value
3、删除：hdel key field
</code></pre>
<h2 id="3-4-lie-biao-lei-xing-list">3.4、列表类型 list</h2>
<p>列表类型list：可以添加一个元素到列表的头部（左边）或者尾部（右边）。</p>
<pre><code class="language-shell">1、存储：
    lpush key value：将元素加入列表左边。
    rpush key value：将元素加入列表右边。
2、获取：get key
    lrange key start end：范围获取
3、删除：del key
    lpop key：删除列表最左边的元素，并将元素返回。
    rpop key：删除列表最右边的元素，并将元素返回。
</code></pre>
<h2 id="3-5-ji-he-lei-xing-set">3.5、集合类型 set</h2>
<p>集合类型set：不允许重复元素。</p>
<pre><code class="language-shell">1、存储：sadd key value
2、获取：smembers key：获取set集合中所有元素
3、删除：srem key value：删除set集合中的某个元素
</code></pre>
<h2 id="3-6-you-xu-ji-he-lei-xing">3.6、有序集合类型</h2>
<p>有序集合类型sortedset：不允许重复元素，且元素有顺序。</p>
<pre><code class="language-shell">1、存储：zadd key score value
2、获取：zrange key start end
3、删除：zrem key value
</code></pre>
<h2 id="3-7-tong-yong-ming-ling">3.7、通用命令</h2>
<pre><code class="language-shell">1、keys * ：查询所有的键
2、type key：获取键对应的value的类型
3、del key：删除指定的key value
</code></pre>
<h1 id="4-chi-jiu-hua-cao-zuo">4、持久化操作</h1>
<p>1、Redis是一个内存数据库，当Redis服务器重启，或者电脑重启，数据会丢失，我们可以将Redis内存中的数据持久化保存到硬盘中的文件中。</p>
<p>2、Redis的持久化机制：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>RDB：默认方式，不需要进行配置，默认就是用这种机制。在一定的间隔时间中，检测key的变化情况，然后持久化数据。</p>
<pre><code class="language-shell">使用步骤：
1、编辑redis.windows.conf文件；
    # after 900 sec (15 min) if at least 1 key changed
    save 900 1
    # after 300 sec (5 min) if at least 10 key changed
    save 300 10
    # after 60 sec (15 min) if at least 10000 key changed
    save 60 10000

2、重新启动redis服务器，并指定配置文件名称。
    D:\redis-2.8.9|redis-server.exe redis.windows.conf
</code></pre>
</li>
<li class="lvl-2">
<p>AOF：日志记录的方式，记录每一条命令的操作。可以每一次命令操作后，持久化数据。</p>
<pre><code class="language-shell">使用步骤：
1、编辑redis.windows.conf文件
    appendonly on （关闭aof） --&gt; appendonly yes （开启aof）

    # appendfsync always ：每一次操作都进行持久化
    appendfsync everysec ：每隔一秒进行一次持久化
    # appendfsync no ：不进行持久化
</code></pre>
</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>pylot安装与使用</title>
    <url>/2014/09/06/pylot_use_guide/</url>
    <content><![CDATA[<h2 id="strong-gai-shu-strong"><strong>概述</strong></h2>
<p>Pylot是一个免费的开源工具，用于测试Web服务的性能和可扩展性。它运行HTTP负载测试，这是有用的容量规划，基准，分析和系统调整。pylot使用比较简单。而且测试结果相对稳定，不像Apache的ab工具，同样的url，测试结果飘忽不定。</p>
<p>Pylot产生并发负载（HTTP请求），验证服务器的响应，并制作报告的度量。测试套件的执行和监测，从一个GUI或shell /控制台。</p>
<p>Pylot基于Python开发，和著名的Apache压力测试工具ab一样，默认在命令行运行，也可以通过参数触发GUI界面，当然前提是安装了wxPython的。</p>
<h2 id="strong-chang-shi-strong"><strong>尝试</strong></h2>
<p>在尝试了python2.7.5、python2.6.2版本后，发现这两个版本均存在问题：</p>
<p>1、pylot不支持python2.7，仅支持python2.5或2.6（pylot工具2009年停止更新，然pylot相应的其他插件一直在更新中）</p>
<p>pylot-1.26\pylot_1.26\ui\console\win目录下，cpos.py文件部分内容如下：</p>
<pre><code class="language-python">import sys
 
is_25 = sys.version.startswith('2.5')
is_26 = sys.version.startswith('2.6')

 
if is_25:
  import _consolepos25 as _consolepos
elif is_26:
  import _consolepos26 as _consolepos

getpos = _consolepos.getpos
gotoxy = _consolepos.gotoxy
</code></pre>
<p>2、python2.6出现另外一个问题，tk不支持多线程</p>
<pre><code class="language-python">Generating Results...
Generating Graphs...
ERROR: Unable to generate graphs with Matplotlib

Done generating results. You can view your test at:
results/results_2014.09.06_21.59.10/results.html
Done.

Error in atexit._run_exitfuncs:
Traceback (most recent call last):
 File "C:\Python26\lib\atexit.py", line 24, in _run_exitfuncs
  func(*targs, **kargs)
 File "C:\Python26\lib\site-packages\matplotlib\_pylab_helpers.py", line 89, in
 destroy_all
  manager.destroy()
 File "C:\Python26\lib\site-packages\matplotlib\backends\backend_tkagg.py", lin
e 590, in destroy
  self.window.destroy()
 File "C:\Python26\lib\lib-tk\Tkinter.py", line 1685, in destroy
  for c in self.children.values(): c.destroy()
 File "C:\Python26\lib\lib-tk\Tkinter.py", line 1938, in destroy
  self.tk.call('destroy', self._w)
TclError: out of stack space (infinite loop?)
Error in sys.exitfunc:
Traceback (most recent call last):
 File "C:\Python26\lib\atexit.py", line 24, in _run_exitfuncs
  func(*targs, **kargs)
 File "C:\Python26\lib\site-packages\matplotlib\_pylab_helpers.py", line 89, in
 destroy_all
  manager.destroy()
 File "C:\Python26\lib\site-packages\matplotlib\backends\backend_tkagg.py", lin
e 590, in destroy
  self.window.destroy()
 File "C:\Python26\lib\lib-tk\Tkinter.py", line 1685, in destroy
  for c in self.children.values(): c.destroy()
 File "C:\Python26\lib\lib-tk\Tkinter.py", line 1938, in destroy
  self.tk.call('destroy', self._w)
_tkinter.TclError: out of stack space (infinite loop?)
</code></pre>
<p>综上所述，本文以python2.5为示例，介绍pylot的安装与简单使用。</p>
<h2 id="strong-ruan-jian-lie-biao-strong"><strong>软件列表</strong></h2>
<table>
<thead>
<tr>
<th><strong>软件名称</strong></th>
<th><strong>作用</strong></th>
<th><strong>下载地址</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>pylot</strong></td>
<td>python的一个功能插件，进行网站压力测试</td>
<td><a href="http://www.oschina.net/p/pylot-bug-fix">http://www.oschina.net/p/pylot-bug-fix</a></td>
</tr>
<tr>
<td><strong>Python</strong></td>
<td>Pylot编译环境（必选）</td>
<td></td>
</tr>
<tr>
<td><strong>Wxpython</strong></td>
<td>Python语言的一套优秀的GUI图形库，用于GUI图形化界面展示（可选）</td>
<td></td>
</tr>
<tr>
<td><strong>numpy</strong></td>
<td>可选 - 用于报告以图表</td>
<td></td>
</tr>
<tr>
<td><strong>matplotlib</strong></td>
<td>可选 - 用于报告以图表</td>
<td></td>
</tr>
<tr>
<td><strong>six</strong></td>
<td>Matplotlib 的require lib</td>
<td></td>
</tr>
<tr>
<td><strong>dateutil</strong></td>
<td>Matplotlib 的require lib</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>说明：</strong></p>
<p><strong>从Python(不含)以下部分为可选安装软件</strong></p>
<h2 id="strong-an-zhuang-fang-fa-strong"><strong>安装方法</strong></h2>
<h3 id="bu-zou-1-xia-zai-pylot">步骤1、下载pylot</h3>
<p>登录到开源中国社区，下载pylot修复版即可。</p>
<p><a href="http://www.oschina.net/p/pylot-bug-fix">http://www.oschina.net/p/pylot-bug-fix</a></p>
<p>下载后解压到某个目录下，注意，目录/路径中不要含有空格、中文字符，如：G:\pylot-master</p>
<h3 id="bu-zou-2-xia-zai-ji-pei-zhi-python-yi-ji-qi-ta-cha-jian">步骤2、下载及配置Python以及其他插件</h3>
<p>详见下文。</p>
<h2 id="an-zhuang-python">安装python</h2>
<h3 id="bu-zou-1-xia-zai-bing-an-zhuang-python-2-5">步骤1、下载并安装python2.5</h3>
<p>安装，略。</p>
<h3 id="bu-zou-2-she-zhi-python-huan-jing-bian-liang">步骤2、设置python环境变量</h3>
<p>变量名：<strong>Path</strong></p>
<p>变量值：<strong>C:\Python25</strong></p>
<img class="shadow" src="/img/in-post/pylot_python_path.png" width="1200">
<h3 id="bu-zou-3-an-zhuang-qi-ta-bao">步骤3、安装其他包</h3>
<p>不用numpy和matplotlib，单独使用pylot+python也可以进行压力测试，但是这样测试生成的报表文件里是不包含曲线图的。为了能够图形化展示数据，这里介绍其他依赖包的安装。</p>
<p>Numpy下载地址：</p>
<p><a href="http://sourceforge.net/projects/numpy/files/NumPy/1.4.1/numpy-1.4.1-win32-superpack-python2.5.exe/download?use_mirror=jaist">http://sourceforge.net/projects/numpy/files/NumPy/1.4.1/numpy-1.4.1-win32-superpack-python2.5.exe/download?use_mirror=jaist</a></p>
<p>wxPython下载地址：</p>
<p><a href="http://sourceforge.net/projects/wxpython/files/wxPython/2.9.1.1/">http://sourceforge.net/projects/wxpython/files/wxPython/2.9.1.1/</a></p>
<p>选择wxPython2.9-win32-2.9.1.1-py25</p>
<p>Six下载地址：</p>
<p><a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#six">http://www.lfd.uci.edu/~gohlke/pythonlibs/#six</a></p>
<p>下载six-1.7.3.win32-py2.6，否则在生成报告过程中会出现如下错误信息：</p>
<img class="shadow" src="/img/in-post/pylot_six_error.png" width="1200">
<p>Dateutil下载地址：</p>
<p><a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#python-dateutil">http://www.lfd.uci.edu/~gohlke/pythonlibs/#python-dateutil</a></p>
<p>如果没有这个lib，则在生成报告过程中出现如下提示信息：</p>
<img class="shadow" src="/img/in-post/pylot_lib_error.png" width="1200">
<p><strong>说明：</strong></p>
<p><strong>如果在使用过程中，遇到需要安装的一些依赖包，你可以到这里查找：</strong></p>
<p><strong><a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/">http://www.lfd.uci.edu/~gohlke/pythonlibs/</a></strong></p>
<h2 id="strong-shi-yong-pylot-strong"><strong>使用pylot</strong></h2>
<p>1、下载完pylot之后，解压到一个目录下，例如：C:\pylot，无需安装。</p>
<p>2、配置testcases.xml</p>
<p>在pylot文件夹里，会看到一个testcases.xml的文件，我们需要更改一下这个文件，用记事本打开它，把需要测试的网页地址添加进去。</p>
<pre><code class="language-shell">&lt;testcases&gt;
  &lt;case&gt;
    &lt;url&gt;http://midh.mlpplus.gikoo.cn/e-learning/index-test.html&lt;/url&gt;
        &lt;method&gt;GET&lt;/method&gt;
  &lt;/case&gt;
&lt;/testcases&gt;
</code></pre>
<p>上面代码中，<a href="http://midh.mlpplus.gikoo.cn/e-learning/index-test.html%E4%B8%BA%E8%A6%81%E6%B5%8B%E8%AF%95%E7%9A%84%E7%BD%91%E5%9D%80%EF%BC%8C%E7%84%B6%E5%90%8E%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6%E3%80%82">http://midh.mlpplus.gikoo.cn/e-learning/index-test.html为要测试的网址，然后保存文件。</a></p>
<p>3、执行压力测试</p>
<p><strong>命令行模式：</strong></p>
<p>启动cmd，进入pylot所在目录，执行如下命令即可启动压力测试:</p>
<img class="shadow" src="/img/in-post/pylot_performance.png" width="1200">
<p>看到类似以上信息，就表示测试结束了。（如果一直没有出现上图的信息，那可能是并发数太多了，把并发数改少点试试，例如只并发20，不要一下子就并发1000）</p>
<p><strong>GUI****模式：</strong></p>
<img class="shadow" src="/img/in-post/pylot_gui.png" width="1200">
<p>​    测试结束后，会在pylot的文件目录里生成一个“results”的文件夹，还生成一个results.html的文件，这个文件记录了详细的测试数据。我们可以进入results的目录，打开这个文件，看看我的测试结果：</p>
<img class="shadow" src="/img/in-post/pylot_result_files.png" width="1200">
<p>点击目录中的results文件，即可打开测试结果：</p>
<img class="shadow" src="/img/in-post/pylot_result_html.png" width="1200">
<h2 id="strong-can-shu-xiang-xi-shuo-ming-strong"><strong>参数详细说明</strong></h2>
<p>Pylot有很多参数，介绍一下：</p>
<table>
<thead>
<tr>
<th>-a, --agents=NUM_AGENTS</th>
<th>设置同时访问用户数量</th>
</tr>
</thead>
<tbody>
<tr>
<td>-d, --duration=DURATION</td>
<td>设置总测试时间（秒）</td>
</tr>
<tr>
<td>-r, --rampup=RAMPUP</td>
<td>设置提升量（秒）</td>
</tr>
<tr>
<td>-i, --interval=INTERVAL</td>
<td>设置访问间隔（毫秒）</td>
</tr>
<tr>
<td>-x, --xmlfile=TEST_CASE_XML</td>
<td>设置要使用的xml文件，默认testcase.xml</td>
</tr>
<tr>
<td>-o, --output_dir=PATH</td>
<td>设置输出文件路径</td>
</tr>
<tr>
<td>-n, --name=TESTNAME</td>
<td>设置测试名称</td>
</tr>
<tr>
<td>-l, --log_msgs</td>
<td>设置是否需要日志信息</td>
</tr>
<tr>
<td>-b, --blocking</td>
<td>设置是否开启锁定模式，如果开启会锁定输出直到测试结束</td>
</tr>
<tr>
<td>-g, --gui</td>
<td>设置是否使用图形界面</td>
</tr>
<tr>
<td>-p, --port=PORT</td>
<td>设置xml-rpc监听的端口</td>
</tr>
</tbody>
</table>
<h2 id="strong-can-kao-wen-dang-strong"><strong>参考文档</strong></h2>
<p><a href="http://www.webkaka.com/blog/archives/windows-pylot-matplotlib-webstress-test.html">http://www.webkaka.com/blog/archives/windows-pylot-matplotlib-webstress-test.html</a></p>
]]></content>
      <categories>
        <category>performance</category>
        <category>pylot</category>
      </categories>
      <tags>
        <tag>performance</tag>
        <tag>pylot</tag>
      </tags>
  </entry>
  <entry>
    <title>adb logcat获取日常日志</title>
    <url>/2014/10/09/capture_exception_log_with_adb_logcat/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在日常测试APP过程中，总有机会碰到APP崩溃问题，为了能够及时的获取到崩溃日志，特意写了一个script，方便自己抓取。</p>
<h1 id="dai-ma-shi-li">代码示例</h1>
<pre><code class="language-python">#!/usr/bin/env python
#-*- coding:UTF-8 -*-

#######################################
##  作用：   调用adb logcat获取日志     ##
##  Create:  2014-10-09              ##
##  version: V1.0                    ##
#######################################

import sys,os,time
import re

class getAppLog():
    '''  定义基类  :
                        判断andriod_home是否存在，继而判断adb命令是否存在
                        判断device是否在线，如果在线，获取devices信息
                        判断adb logcat是否可用
                        清空缓存日志
                        调用adb logcat捕获日志，并重定向到指定文件
                        如果日志文件超过20M，备份原日志文件
    '''
    
    def def_log_file(self,log_name=None):
        ''' 定义 日志文件   '''
        PATH = lambda p: os.path.abspath(os.path.join(os.path.dirname(__file__), p))    
        log_name = 'test_logcat.txt' if log_name == None else log_name
        file_path = PATH(log_name)
        return file_path
            
    def envCheck(self): 
        '''  校验 andriod sdk '''
        if "ANDROID_HOME" in os.environ: 
            rootDir = os.path.join(os.environ["ANDROID_HOME"], "platform-tools") 
            for path, subdir, files in os.walk(rootDir): 
                if "adb.exe" in files: 
                    return os.path.join(path, "adb.exe") 
                else: 
                    print '\nadb.exe does not exist!\n',
                    time.sleep(3)
        else:
            print "\nANDROID_HOME not exist! Please setup andriod SDK and set the environment variable ANDROID_HOME. \n",
            time.sleep(3)



    def get_device_id(self): 
        '''  获取 deviceId，并作容错校验       ''' 
        #尝试停止、启动adb-server，方便调用adb获取信息
        os.popen('adb kill-server')
        time.sleep(3)
        os.popen('adb start-server')
        time.sleep(5)
        out = os.popen("adb devices").read()
                 
        if out == '':
            print '\n[ERROR]  Terminal device has a problem, the program exits, replace the terminal equipment!\n'
            time.sleep(3)
            exit() 
        elif out.startswith('error'):
            print '\n[ERROR]  Get devices error,program exits!\n'
            time.sleep(3)
            exit() 
        elif out.split('\n')[1].strip().endswith('unauthorized') and str(out).count('device') == 1:
            print '\n[ERROR]  Device unauthorized,program exits!\n'
            time.sleep(3)
            exit()            
        elif out.split('\n')[0].strip().endswith('attached') and str(out).count('device') == 1 and len(out.split('\n')) &lt;= 3:
            print '\n[ERROR]  Not get list of devices,program exits!\n'
            time.sleep(3)
            exit() 
        else:
            deviceId = out.split('\n')[1].split('\t')[0]
            return deviceId
    
    def check_log_is_enable(self):
        ''' 校验手机设备是否支持logcat命令   '''
        log_cat = os.popen("adb logcat -g 20").read()
        
        match = re.search(r'''Unable to open log device '/dev/log/main': No such file or directory''',log_cat)
        if match:
            print '\n[ERROR]  ' + log_cat + ' \n'
            time.sleep(3)
            sys.exit()
     
    def get_log_to_file(self,deviceid,file_path):
        ''' 调用logcat获取日志到文件  
            adb -s deviceid logcat -c （清除LOGCAT的缓存）
            adb -d -s deviceid logcat *:W &gt;test_logcat.txt
        '''
        
        if deviceid != '':
            clear_buffer = 'adb -s '+ deviceid  +' logcat -c '
            get_log = 'adb -d -s ' +  deviceid + ' logcat -v time -s *:W &gt;&gt;' + file_path
            
            if ' ' in file_path:
                print '\n ' + file_path + ': The path contains spaces,program exits!\n'
                time.sleep(3)
                sys.exit()
            
            #执行具体的命令
            os.system(clear_buffer)
            time.sleep(1)
            os.system(get_log)
        else:
            print '\ndeviceid not exist!\n'
            time.sleep(3)
            sys.exit()
    
    def log_file_size(self,file_path):
        ''' 如果log文件过大，备份并重新启用一个日志进行记录   '''
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
    
            file_name = file_path.split("/")[-1].split('.')[0] 
            file_Suffix =file_path.split("/")[-1].split('.')[-1] 
            
            timeStamp =  time.strftime('%Y_%m_%d_%H_%M_%S')
            new_name = file_name+'_'+ timeStamp + file_Suffix
            if file_size &gt;= 20971520:
                os.rename(file_path, new_name)



if __name__ == '__main__':
    print '-' * 75 

    log = getAppLog()
    
    log_file = log.def_log_file()
    
    log.log_file_size(log_file)
    
    log.envCheck()
     
    device_id = log.get_device_id()
    
    log.check_log_is_enable()
    
    log.get_log_to_file(device_id,log_file)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>MPS接口自动化测试指南</title>
    <url>/2014/11/15/mps_automation_guide/</url>
    <content><![CDATA[<h1 id="xu-qiu-miao-shu">需求描述</h1>
<h2 id="ji-ben-yao-qiu">基本要求</h2>
<p>对服务后台一系列的HTTP接口功能测试，主要涉及POST、PUT、GET、DELETE等类型；用例与用例之间保持独立，即低耦合。</p>
<p>输入：</p>
<p>根据各接口描述，构造不同的参数输入值，模拟客户端请求。</p>
<p>输出：</p>
<p>服务端响应（HTTP状态码/具体响应数据）。</p>
<p>检验：</p>
<p>用例执行过程中增加断言，判断用例执行成功/失败与否。</p>
<p>结果：</p>
<p>可视化的HTML/XML测试报告；</p>
<p>用例执行过程中日志信息记录。</p>
<p>CI：与jenkins结合，完成持续构建、自动部署、自动执行，并将结果发送到相关人。</p>
<h2 id="shi-xian-fang-fa">实现方法</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>采用python脚本来驱动测试,使用Unittest框架</p>
</li>
<li class="lvl-2">
<p>调用HTTP接口，采用python封装好的API</p>
</li>
<li class="lvl-2">
<p>测试需要的HTTP，组装字符转处理</p>
</li>
<li class="lvl-2">
<p>测试数据以随机数传递到各接口对应参数，确保用例独立性</p>
</li>
<li class="lvl-2">
<p>设置1个/多个检查点，校验响应消息中的返回值（通过解析响应消息得到）</p>
</li>
<li class="lvl-2">
<p>首次执行需根据实际测试环境，修改下配置文件autotest.config（注：不是每次测试都需要修改这个配置文件，只有在变更测试环境情况下才需要修改）</p>
</li>
</ul>
<h1 id="ce-shi-kuang-jia">测试框架</h1>
<p>设计图：</p>
<img class="shadow" src="/img/in-post/mps_automation_design.png" width="1200">
<p>用例执行过程示意图：</p>
<img class="shadow" src="/img/in-post/mps_case_run_process.png" width="1200">
<h1 id="zi-dong-hua-shi-yong-zhi-nan">自动化使用指南</h1>
<h2 id="zi-dong-hua-gai-shu">自动化概述</h2>
<p>目前使用python的urllib、urllib2模块，封装http请求消息，完成发送json报文到后台，后台处理后，根据http response或其他，并增加断言，以判断用例执行结果是成功还是失败。</p>
<p>同时组织了用例生成的报告，以及与jenkins结合，实现持续集成，自动执行用例，并将结果以HTML Report方式发送到相关邮箱，及时知道构建结果。</p>
<h2 id="ce-shi-zhun-bei">测试准备</h2>
<h3 id="pei-zhi-wen-jian">配置文件</h3>
<p>只需保证自动化配置文件内容正确即可。配置文件存放在src/common/config/目录下，名称是：autotest.config。配置文件各参数介绍，请参考下图：</p>
<img class="shadow" src="/img/in-post/mps_config.png" width="1200">
<h3 id="di-san-fang-mo-kuai-de-an-zhuang">第三方模块的安装</h3>
<table>
<thead>
<tr>
<th>模块名称</th>
<th>安装命令</th>
<th>模块说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>progressbar</td>
<td>pip install progressbar</td>
<td>进度条</td>
</tr>
<tr>
<td>configobj</td>
<td>pip install configobj</td>
<td>读取配置文件</td>
</tr>
<tr>
<td>matplotlib</td>
<td>pip install matplotlib</td>
<td>绘图使用</td>
</tr>
<tr>
<td>dateuti</td>
<td>pip install python-dateutil</td>
<td>绘图使用</td>
</tr>
<tr>
<td>numpy</td>
<td>pip install numpy</td>
<td>绘图使用</td>
</tr>
<tr>
<td>pyparsing</td>
<td>pip install pyparsing</td>
<td>解析xml文件使用</td>
</tr>
</tbody>
</table>
<h3 id="zhang-hao-zi-ding-yi-shu-xing-xin-xi-bu-neng-wei-bi-tian-xiang">账号自定义属性信息不能为必填项</h3>
<img class="shadow" src="/img/in-post/mps_account.png" width="1200">
<p>不能存在“自定义账号属性”；存在也可以，但是属性要求是可选的，不能是必填的（因为每个测试环境不同，无法满足每个测试环境创建账号需要的自定义的属性信息）:</p>
<img class="shadow" src="/img/in-post/mps_account2.png" width="1200">
<h3 id="cun-zai-ke-yong-de-ce-shi-fen-zu">存在可用的测试分组</h3>
<p>测试环境中需要存在“自动化测试组”这个分组信息。</p>
<p>说明：目前第3、第4点，已经在测试用例执行入口脚本(<a href="http://interfaceRunner.py">interfaceRunner.py</a>)中增加了检测机制，如果检测不通过，则用例退出执行，并给出为何退出原因，方便使用者进行测试环境的调整。</p>
<h2 id="ce-shi-yong-li-de-bian-xie">测试用例的编写</h2>
<p>1、所有用例的编写，放在对应功能目录下testcase目录下，且必须以test开头；</p>
<p>2、每一个函数就是一个测试用例，函数名的命名尽量要有意义，能根据函数名称而知道用例是做哪方面的功能测试；</p>
<p>3、用例要保证独立性，互相不依赖。</p>
<p>示例如下：成功登录测试用例</p>
<img class="shadow" src="/img/in-post/mps_success_login.png" width="1200">
<p>异常登录测试用例</p>
<img class="shadow" src="/img/in-post/mps_failed_login.png" width="1200">
<p>创建一个通知测试用例</p>
<img class="shadow" src="/img/in-post/mps_notification.png" width="1200">
<h2 id="ce-shi-yong-li-de-zhi-xing">测试用例的执行</h2>
<p>有两种执行方式方式1、通过IDE执行</p>
<p>比如在eclipse中打开某个用例，右击选择Run As Python unit-test：</p>
<img class="shadow" src="/img/in-post/mps_run_by_ide.png" width="1200">
<p>方式2、通过入口脚本执行入口脚本存放在src目录下，名称：<a href="http://interfaceRunner.py">interfaceRunner.py</a>，双击即可执行所有的测试用例：</p>
<img class="shadow" src="/img/in-post/mps_run.png" width="1200">
<p>说明：选择性的执行用例，可在后期增加，目前只有执行全部用例函数，无选择性执行用例函数。</p>
<h2 id="yong-li-zhi-xing-jin-du-cha-kan">用例执行进度查看</h2>
<p><a href="http://xn--srcprocessBar-r40u917bt6gp48c102f.py">双击src目录下processBar.py</a>，即可查看用例执行进度：</p>
<img class="shadow" src="/img/in-post/mps_progress.png" width="1200">
<p>在网络或server端响应较慢情况下，用例执行耗时非常长（有一次是79个用例耗时47分钟37秒）；经过测试，这79个测试用例，在公网环境正常状态下，只需88秒即可完成。由此也证实了，网络不好的情况下，并不影响自动化测试用例的正常执行。</p>
<h2 id="li-shi-ce-shi-ji-lu-shu-ju-zhan-shi">历史测试记录数据展示</h2>
<p>每次执行用例（通过执行interfaceRunner.py完成），将测试结果（report目录下Interface_TestReport.xml文件）解析、入库到SQLite  report_history表中，通过统计脚本(<a href="http://statInfoInfo.py">statInfoInfo.py</a>)读取数据库中历史记录，以曲线图形展示用例执行成功率。</p>
<img class="shadow" src="/img/in-post/mps_summary.png" width="1200">
<img class="shadow" src="/img/in-post/mps_case_overall_statistic.png" width="1200">
<h2 id="chuang-jian-sqlite-biao-xiang-guan-yu-ju">创建sqlite表相关语句</h2>
<pre><code class="language-ini">CREATE TABLE [report_history] (
  [begintime] DATETIME NOT NULL, 
  [endtime] DATETIME NOT NULL, 
  [total] INT NOT NULL, 
  [passed] INT NOT NULL, 
  [failed] INT NOT NULL, 
  [error] INT NOT NULL,
  PRIMARY KEY (begintime));
</code></pre>
<h2 id="ce-shi-bao-gao-cha-kan">测试报告查看</h2>
<p>测试报告在report目录下Interface_TestReport.html文件，部分截图如下：</p>
<img class="shadow" src="/img/in-post/mps_report.png" width="1200">
<h2 id="pei-zhi-wen-jian-shuo-ming">配置文件说明</h2>
<p>配置文件在src/common/config目录下，名称为：autotest.config，详细内容与解释，请参考本文附件章节中的“配置文件说明”excel文档。</p>
<h2 id="you-que-dian">优缺点</h2>
<h3 id="you-dian">优点</h3>
<p>1、直接使用JSON构造报文构造的消息体，直接使用json表示。因为后台使用的是JSON，拿到接口文档后就可直接构造报文了，不需要转换成其他类型的报文（如果使用pyresettest，需要将json转成yaml）。</p>
<p>2、参数化所有测试用例中的host、账号隶属于的组织结构的id、接口的URL地址、接口中需要的参数/tooken等信息，都可以从配置文件/基类中获取；</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>变更测试环境，无需对测试用例进行修改，仅需修改config目录下配置文件即可</p>
</li>
<li class="lvl-2">
<p>cookie是动态变化的，直接从login response中获取，并传递下去，不需要手工干预，不会出现会话过期失效问题</p>
</li>
<li class="lvl-2">
<p>参数化的另外一个好处是，可以多样化构造报文中字段各式各样的值，测试/验证后台能否正常处理</p>
</li>
<li class="lvl-2">
<p>扩展性强：接口变更后（比如携带的参数调整），直接修改对应基类中构造json报文代码即可。</p>
</li>
</ul>
<p>3、测试记录跟踪、测试结果可视化</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>记录用例运行过程中的日志;</p>
</li>
<li class="lvl-3">
<p>可生成HTML和XML格式测试报告，界面直观，数据一目了然</p>
</li>
</ul>
<p>4、用例统一管理用例执行有一个统一的入口，可执行所有的用例（如果有需要，将来可增加选择性执行用例）</p>
<p>5、成功与jenkins结合，做CI(持续集成)测试目前已成功完成与jenkins结合，进行自动构建，并将测试结果（自动化运行日志、测试报告和jenkins构建日志）发送到邮箱，如下图所示：</p>
<img class="shadow" src="/img/in-post/mps_email.png" width="1200">
<h3 id="que-dian">缺点</h3>
<p>​    1、用例管理、维护成本稍高一点；</p>
<p>​    2、每个测试用例都是一个函数，用例的编写方面，需要会一点python；​         对测试而言，有机会去了解后台代码，可以更好的熟悉业务逻辑、对产品进行更深入的测试，暂时的缺点也会变成后期的优点吧</p>
<p>​    3、用例编写无GUI​         还是归根到用例的编写上，目前提供的日志与测试用例执行结果（用例中增加了断言），在一定程度上是有助于定位用例执行失败的原因。</p>
<h1 id="da-jian-jenkins-chi-xu-ji-cheng-huan-jing">搭建Jenkins持续集成环境</h1>
<h2 id="jenkins-de-xia-zai-yu-an-zhuang">Jenkins的下载与安装</h2>
<p>度娘吧。</p>
<h2 id="cha-jian-de-an-zhuang">插件的安装</h2>
<p>涉及到的插件，主要有GIt Plugin、Email Extension Plugin和 HTML Publisher plugin3个插件。GIt Plugin用于从github上下载代码；Email Extension Plugin用于持续构建过程后发送邮件；HTML Publisher plugin用于生成邮件中的html报告。本文以安装git plugin为例进行插件安装的介绍。</p>
<h2 id="git-plugin-de-an-zhuang">Git Plugin的安装</h2>
<p>Jenkins缺省支持CVS，Subversion，Maven和SSH。依次进入"系统管理"–&gt;“插件管理”–&gt;“可选插件”.这里列出了目前可以获得的所有的插件。</p>
<img class="shadow" src="/img/in-post/mps_jenkisn_all_plugs.png" width="1200">
<p>选择"Git plugin"，点击下方的"直接安装":</p>
<img class="shadow" src="/img/in-post/mps_update_plugs.png" width="1200">
<p>插件安装已经完成，需要重启jenkins，新插件才能生效。</p>
<h2 id="huan-jing-pei-zhi">环境配置</h2>
<p>依次进入"系统管理"–&gt;“系统设置”，设置Jenkins相关参数。</p>
<h3 id="she-zhi-git-lu-jing">设置git路径</h3>
<p>设置获取路径、代码用户名，如下图所示:</p>
<img class="shadow" src="/img/in-post/mps_git.png" width="1200">
<h3 id="she-zhi-chao-shi-shi-jian">设置超时时间</h3>
<p>源码管理  高级  添加“Additional Behaviours”，设置down代码超时时间：</p>
<img class="shadow" src="/img/in-post/mps_timeout.png" width="1200">
<h3 id="gou-jian-hong-fa-qi">构建触发器</h3>
<p>如下图所示：</p>
<img class="shadow" src="/img/in-post/mps_trigger.png" width="1200">
<p>表示每周一至周五的23点自动运行。</p>
<h3 id="zeng-jia-gou-jian-bu-zou">增加构建步骤</h3>
<p>执行bat命令，运行接口用例入口脚本，执行所有测试用例，如下图所示：</p>
<img class="shadow" src="/img/in-post/mps_before_build.png" width="1200">
<p>bat命令行代码如下：</p>
<pre><code class="language-shell">@echo off
cd C:\Jenkins\workspace\interfaceAutotest\Testing\autotest\intefaceTest\src
python interfaceRunner.py
</code></pre>
<h3 id="gou-jian-hou-cao-zuo">构建后操作</h3>
<p>如下图所示，增加构建后操作。示例中展示的是将测试报告、测试日志、构建日志发送到指定邮箱。</p>
<img class="shadow" src="/img/in-post/mps_send_email_conf.png" width="1200">
<p>Editable Email Notification中Default Content，内容信息如下：</p>
<pre><code class="language-shell">&lt;html&gt;

    &lt;head&gt;
        &lt;title&gt;&lt;/title&gt;
    &lt;/head&gt;

    &lt;body&gt;
        Hi All,捷库接口自动化测试结果 &lt;br&gt;
        &lt;font color="#0B610B" size="4"&gt;  请点击红色链接，检查控制台输出，查看本次持续集成构建结果：&lt;/font&gt; &lt;a href="${BUILD_URL}console"&gt;&lt;b&gt;&lt;font color="#DF0101" size="5"&gt; ${ENV, var="JOB_NAME"}&lt;/font&gt;&lt;/b&gt;&lt;/a&gt;

        &lt;table width="95%" cellpadding="0" cellspacing="0" style="font-size:11pt; font-family:Tahoma, Arial, Helvetica, sans-serif"&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;h2&gt;
                        &lt;font color="#0000FF"  size="4"&gt;构建结果 -- ${BUILD_STATUS}&lt;/font&gt;
                    &lt;/h2&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;br&gt;
                    &lt;b&gt;&lt;font color="#0B610B"&gt;构建信息:&lt;/font&gt;&lt;/b&gt;
                    &lt;hr size="2" width="100%" align="center"&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;ul&gt;
                        &lt;li&gt;项目名称 - ${PROJECT_NAME}&lt;/li&gt;
                        &lt;li&gt;构建编号 ： 第${BUILD_NUMBER}次构建&lt;/li&gt; 
                        &lt;li&gt;触发原因： ${CAUSE}&lt;/li&gt;  
                        &lt;li&gt;构建结果(For xxx) -- &lt;a href="${PROJECT_URL}ws"&gt;${PROJECT_URL}ws&lt;/a&gt; &lt;/li&gt;
                        &lt;li&gt;项目 Url -- &lt;a href="${PROJECT_URL}"&gt;${PROJECT_URL}&lt;/a&gt;&lt;/li&gt;
                        &lt;li&gt;构建 Url -- &lt;a href="${BUILD_URL}"&gt;${BUILD_URL}&lt;/a&gt;&lt;/li&gt;
                        &lt;li&gt;SVN 版本 -- ${SVN_REVISION} &lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;b&gt;&lt;font color="#0B610B"&gt;自最后一次构建成功后的变 化:&lt;/font&gt;&lt;/b&gt;
                    &lt;hr size="2" width="100%" align="center"&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;ul&gt;
                        &lt;li&gt;在此查看历史变化记录: -- &lt;a href="${PROJECT_URL}changes"&gt;${PROJECT_URL}changes&lt;/a&gt;
                        &lt;/li&gt;
                    &lt;/ul&gt;${CHANGES_SINCE_LAST_SUCCESS, reverse=true, format="Changes for Build #%n:&lt;br&gt;%c&lt;br&gt;", showPaths=true, changesFormat="&lt;pre&gt;[%a]&lt;br&gt;%m&lt;/pre&gt;", pathFormat="&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;%p"}
                &lt;/td&gt;
            &lt;/tr&gt;        

            &lt;tr&gt;
               &lt;td&gt;
                   &lt;br&gt;
               &lt;/td&gt;
            &lt;/tr&gt;
            
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;b&gt;&lt;font color="#0B610B"&gt;失败的测试结果：&lt;/font&gt;&lt;/b&gt;
                    &lt;hr size="2" width="100%" align="center"&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;pre style="font-size:11pt; font-family:Tahoma, Arial, Helvetica, sans-serif"&gt;

$FAILED_TESTS
&lt;/pre&gt;&lt;br&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;b&gt;&lt;font color="#0B610B"&gt;构建日志 (最后 100 行):&lt;/font&gt;&lt;/b&gt;
                    &lt;hr size="2" width="100%" align="center"&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    测试日志 (如果有运行测试): &lt;a href="${PROJECT_URL}ws/Testing/autotest/intefaceTest/report/interface_autotest.log"&gt;${PROJECT_URL}ws/Testing/autotest/intefaceTest/report/interface_autotest.log&lt;/a&gt;&lt;br&gt;
                    &lt;br&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;
                    &lt;textarea cols="80" rows="30" readonly="readonly" style="font-family: Courier New"&gt;
${BUILD_LOG, maxLines=100}
&lt;/textarea&gt;
                &lt;/td&gt;
            &lt;/tr&gt;
        &lt;/table&gt;

&lt;hr size="2" width="100%" align="center" /&gt;  

（说明：本邮件由系统自动生成，请勿回复！）
            &lt;tr&gt; &lt;td&gt;
                   &lt;br&gt;
               &lt;/td&gt;
            &lt;/tr&gt;
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="shi-jian-jie-guo">实践结果</h3>
<p>如下为邮件发送后，在Foxmail邮箱中的展示：</p>
<img class="shadow" src="/img/in-post/msp_send_email_show.png" width="1200">
<h1 id="jenkins-zhan-shi-luan-ma-wen-ti">Jenkins展示乱码问题</h1>
<h2 id="wen-ti-1-kong-zhi-tai-shu-chu-zhong-wen-zhan-shi-shi-luan-ma">问题1、控制台输出中文展示是乱码</h2>
<p>如下图所示：</p>
<img class="shadow" src="/img/in-post/mps_console.png" width="1200">
<h2 id="wen-ti-2-you-jian-zhong-github-bian-hua-xin-xi-luan-ma">问题2、邮件中github变化信息乱码</h2>
<img class="shadow" src="/img/in-post/mps_github.png" width="1200">
<h2 id="wen-ti-3-you-jian-zhong-zui-hou-100-xing-ji-lu-luan-ma">问题3、邮件中最后100行记录乱码</h2>
<img class="shadow" src="/img/in-post/mps_last_100.png" width="1200">
<p>解决方法<br>
Jenkins中Git仓库变更集中文注释显示乱码问题</p>
<p>C:\Jenkins\jenkins.xml 新增蓝色粗体标记参数(-Dfile.encoding=utf-8)，然后重启Jenkins服务，完毕！</p>
<pre><code class="language-shell">  &lt;executable&gt;%BASE%\jre\bin\java&lt;/executable&gt;
  &lt;arguments&gt;-Xrs -Xmx256m  -Dfile.encoding=utf-8 -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle -jar "%BASE%\jenkins.war" --httpPort=8080&lt;/arguments&gt;
</code></pre>
<p>原因：</p>
<p>为什么Jenkins 使用 SVN 仓库不会出现非 ANSI 字符乱码，因为 Git 插件获取变更集时保存的不是 XML格式文档（虽然后缀都是.xml），这就导致了显示的时候不知道以什么编码方式来显示，就使用了系统默认编码，中文的也就是GBK。 而 GIT Commit 注释默认是 UTF-8。</p>
<h2 id="wen-ti-4-jie-kou-jenkins-kong-zhi-tai-zhong-wen-luan-ma-wen-ti">问题4、接口jenkins控制台中文乱码问题</h2>
<p>系统管理–系统设置，增加全局属性，设置LANG=zh_CN.UTF-8，如下图所示：</p>
<img class="shadow" src="/img/in-post/mps_system_conf1.png" width="1200">
<p>如上设置后，重启jenkins服务，进入系统设置 系统信息，查看环境变量，如下图所示：</p>
<img class="shadow" src="/img/in-post/mps_system_conf2.png" width="1200">
<p>再次执行构建，控制台输出如下：</p>
<img class="shadow" src="/img/in-post/mps_console_output.png" width="1200">
<h1 id="guan-li-zhu-ce-yong-hu">管理注册用户</h1>
<p>详细文档，请参考：</p>
<p><a href="http://blog.csdn.net/wangmuming/article/details/22926025">http://blog.csdn.net/wangmuming/article/details/22926025</a></p>
<h1 id="you-xiang-ce-shi-shi-bai-503-cuo-wu-ma">邮箱测试失败（503错误码）</h1>
<p>如果在系统管理系统设置中“邮件通知”测试邮箱发邮件失败，请确保“使用SMTP认证”中用户名和密码是正确的：</p>
<img class="shadow" src="/img/in-post/mps_email_503.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
        <category>python</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>interface</tag>
        <tag>Unittest</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>MPS测试用例数统计脚本</title>
    <url>/2014/11/19/mps_test_case_count_script/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>上周写了一篇关于MPS 后端接口自动化用例设计与用例的编写，虽然有一个可视化的报告，但还缺少接口自动化测试用例分布统计信息，这次补上。当然可以集成到HTML report中，设置是CI/CD中，这样展示会更直观。</p>
<h1 id="html-ge-shi-de-tong-ji">HTML格式的统计</h1>
<p>代码片段：</p>
<pre><code class="language-python">#!/usr/bin/env python
#-*- coding:UTF-8 -*-

######################################
##  作用：    测试用例数统计脚本        ##
##  日期：      2014-11-09            ##
##  版本：      V1.0                  ##
##  作者：      Strayeagle            ##
##  日期：      2015-04-01            ##
##  版本：      V1.1                  ##
######################################


import os
import sys
import re
import time
from pylab import *  
import decimal
from common.stub.DataStub import DataStub
from common.util.PathUtil import getReportPath


#要处理的文件后缀名称，存入一个list中
exts = ['.py']



#所有测试用例文件列表
def all_case_files():
    test_case_files = []
    
    for root,dirs,files in os.walk(os.getcwd()):
        for fileName in files:
            #检查子目录
            if fileName.endswith('.py') and not fileName.endswith('__.py'):
                ##完整的文件路径（绝对路径）,并取lower
                fname = (root + os.sep + fileName).lower()
                test_case_files.append(fname)
                
    return  test_case_files


    
#读取文件，获取:4个空格开头， + def + 空格 + '(self):' 结尾的行记录的数量
def test_case_count(fname):
    count = 0
    for file_line in open(fname).xreadlines():
        m = re.match(r'^(\s{4})def(\s+)(test*)', file_line)
        if m is not None:
            count += 1
    return count




#所有测试用例总数
def all_case_counts(dir_tpye=None):
    count=0
    for root,dirs,files in os.walk(os.getcwd()):
        for fileName in files:
            #检查子目录
            ##完整的文件路径（绝对路径）,并取lower
            fname = (root + os.sep + fileName).lower()
            
            #测试用例的总数
            ext = fileName[fileName.rindex('.'):]
            if dir_tpye == 'all':
                try:
                    if(exts.index(ext) == 0):
                        c = test_case_count(fname)
                        count += c
                except:
                    pass
            elif dir_tpye == 'manager':
                if '_01_manager' in fname:
                    try:
                        if(exts.index(ext) == 0):
                            c = test_case_count(fname)
                            count += c
                    except:
                        pass
            elif dir_tpye == 'app':
                if '_02_app' in fname:
                    try:
                        if(exts.index(ext) == 0):
                            c = test_case_count(fname)
                            count += c
                    except:
                        pass
    return count

#获取各个用例分目录下对应的测试用例数，返回值为dict
def get_each_dir_case_count(dirList,test_case_files):
    
    case_count_dict = {}
    case_count_dict.clear()
    
    for each_case_file in test_case_files:
        for each_dir in dirList:
            if each_dir in each_case_file:
                count = test_case_count(each_case_file)
                if case_count_dict.has_key(each_dir):
                    cur_count = case_count_dict[each_dir] + count
                    after_dict = {each_dir:cur_count}
                    case_count_dict.update(after_dict)
                else:
                    case_count_dict[each_dir]=count
    
    return case_count_dict



def graph_pie(case_count_dict, pie_type=None):
    '''  绘制饼图  '''
    # make a square figure and axes   
    figure(1, figsize=(6,6))  
    labels = list(case_count_dict.keys())
    fracs = case_count_dict.values()
    
    if  pie_type == 'all':
        explode=(0, 0) 
        colors  = ["orange","green"]
        pie(fracs, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True)
        title('All TestCase', bbox={'facecolor':'0.8', 'pad':5})  
        savefig(getReportPath() + os.sep +'all_pie.png') 
        #plt.show()
        
    if  pie_type == 'manager':
        explode=(0, 0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) 
        colors  = ["pink","coral","yellow","orange","red","green","white"]
        # Pie Plot
        # autopct: format of "percent" string;
        pie(fracs, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',pctdistance=0.8, shadow=True)
        title('Manager TestCase', bbox={'facecolor':'0.8', 'pad':5})
        savefig(getReportPath() + os.sep +'manager_pie.png')
        plt.cla()
        plt.clf()
        #plt.show()
        
    if  pie_type == 'app':
        explode=(0, 0, 0, 0)
        colors  = ["pink","coral","yellow","orange","red","green","white"]
        pie(fracs, explode=explode, labels=labels,  colors=colors, autopct='%1.1f%%', shadow=True)
        title('APP TestCase', bbox={'facecolor':'0.8', 'pad':5})  
        savefig(getReportPath() + os.sep +'app_pie.png')
        #plt.show()
        plt.cla()
        plt.clf()

def get_data():
    data = {}
    
    sql = 'select begintime,passed,total from report_history'
    select_data = DataStub().executeQuery(sql, bindParams=None)
    
    for each_data in select_data:
        rate_tmp = decimal.Decimal(each_data[1])/decimal.Decimal(each_data[-1])*100
        rate = '{0:.4}'.format(rate_tmp)
        data[each_data[0]] = rate
        
    return data


def line_draw(data):
    try:
        if len(data) &lt;1:
            print u'SQLite查无数据，程序退出!'
            time.sleep(4)
            sys.exit()
    except:
        pass
    
    x = [i for i in range(len(data.values()))]
    y=list(data.values())
    
    # trick to get the axes
    #fig,ax = plt.subplots()
    fig = figure(figsize=(8, 4))  # image dimensions  
    ax = fig.add_subplot(111)
    ax.grid(True, color='#666666')
    xticks(size='x-small')
    yticks(size='x-small')
    axis(xmin=0)
        
    xticklabels = list(sorted(data.keys()))
    
    # plot data
    ax.plot(x,y)
    
    # set ticks and tick labels
    ax.set_xticks(x)
    
    ax.set_xticklabels(xticklabels,rotation=15)
    
    #主刻度间距设置
    if len(data) &gt; 15 and len(data) &lt; 60 :
        ax.xaxis.set_major_locator( MultipleLocator(3) )
    elif len(data) &gt; 60:
        ax.xaxis.set_major_locator( MultipleLocator(5) )
        
    # 设置图的底边距
    plt.subplots_adjust(bottom = 0.15)
    
    #开启网格
    plt.grid(True)
    
    plt.xlabel('Time')
    plt.ylabel("Rate(%)")
    
    #自动调整label显示方式，如果太挤则倾斜显示
    fig.autofmt_xdate()
    
    #title('success rate', bbox={'facecolor':'0.8', 'pad':0})  
    title('success rate') 
    plt.savefig(getReportPath() + os.sep + 'rate_line.png')
    
    # show the figure
    #plt.show()
    plt.cla()
    plt.clf()

##---------------------  写报告    ------------------  ##
def write_starting_content(handle):
    handle.write('&lt;h1&gt;MPS - Statistical information automation&lt;/h1&gt;\n')
    
    
def write_images(handle):
    #总用例分布，饼图
#     handle.write('&lt;h2&gt;The overall distribution of automated test cases&lt;/h2&gt;\n')
#     handle.write('&lt;img src="../report/all_pie.png" width="500px" height="500px alt="all testcase distribution graph"&gt;\n')
#     #web 后台用例分布，饼图
#     handle.write('&lt;h2&gt;The server automated test case distribution&lt;/h2&gt;\n')
#     handle.write('&lt;img src="../report/manager_pie.png" width="500px" height="500px alt="server testcase graph"&gt;\n')
#     #APP端用例分布，饼图
#     handle.write('&lt;h2&gt;APP automation test case distribution&lt;/h2&gt;\n')
#     handle.write('&lt;img src="../report/app_pie.png" width="500px" height="500px alt="app testcase graph"&gt;\n')    
#     #成功率曲线图
#     handle.write('&lt;h2&gt;Test case execution success ratio diagram of curves&lt;/h2&gt;\n')
#     handle.write('&lt;img src="../report/rate_line.png"  width="700px" height="400px alt="testcase execution rate graph"&gt;\n')




    handle.write('&lt;div style=" float:left"&gt;&lt;h2&gt;Overall distribution of testcases&lt;/h2&gt;&lt;img src="../report/all_pie.png" width="500px" height="500px alt="all testcase distribution graph"&gt;&lt;/div&gt;')
    handle.write('&lt;div style=" float:middle"&gt;&lt;h2&gt;Server testcase distribution&lt;/h2&gt;&lt;img src="../report/manager_pie.png" width="500px" height="500px alt="server testcase graph"&gt;&lt;/div&gt;')
    handle.write('&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;')
    handle.write('&lt;div style=" float:left"&gt;&lt;h2&gt;APP testcase distribution&lt;/h2&gt;&lt;img src="../report/app_pie.png" width="500px" height="500px alt="app testcase graph"&gt;&lt;/div&gt;')
    handle.write('&lt;div style=" float:middle"&gt;&lt;h2&gt;Testcase execution success ratio diagram of curves&lt;/h2&gt;&lt;img src="../report/rate_line.png" width="700px" height="400px alt="testcase execution rate graph"&gt;&lt;/div&gt;')


def write_summary_results(handle,total_testcase,manager_testcase,app_testcase):
    handle.write('&lt;b&gt;%s:&lt;/b&gt; &amp;nbsp;%s&lt;br /&gt;\n' % ('report generated', time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))))
    handle.write('&lt;h2&gt;Results Summary&lt;/h2&gt;')
    handle.write('&lt;table&gt;\n')
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('total testcases', total_testcase))
    handle.write('&lt;/table&gt;\n')
    
    handle.write('&lt;table&gt;\n')
    handle.write('&lt;tr&gt;&lt;td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('- manager testcases', manager_testcase))
    handle.write('&lt;/table&gt;\n')


    handle.write('&lt;table&gt;\n')
    handle.write('&lt;tr&gt;&lt;td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;&lt;td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('- app testcases', app_testcase))
    handle.write('&lt;/table&gt;\n') 

def write_stats_tables(handle, manager_distribution_dict,app_distribution_dict):
    handle.write('&lt;p&gt;&lt;br /&gt;&lt;/p&gt;')
    handle.write('&lt;table&gt;\n')
    handle.write('&lt;th&gt;Manager testcase (Number)&lt;/th&gt;&lt;th&gt;APP testcase (Number)&lt;/th&gt;\n')
    handle.write('&lt;tr&gt;\n')
    handle.write('&lt;td&gt;\n')   
    handle.write('&lt;table&gt;\n')
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('login', manager_distribution_dict['_login']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('account', manager_distribution_dict['_account']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('group', manager_distribution_dict['_group']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('course', manager_distribution_dict['_course']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('exam', manager_distribution_dict['_exam']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('notice', manager_distribution_dict['_notice']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('survey', manager_distribution_dict['_survey']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('registertion', manager_distribution_dict['_registration']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('classroom', manager_distribution_dict['_classroom']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('forum', manager_distribution_dict['_forum']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('news', manager_distribution_dict['_news']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('mission', manager_distribution_dict['_mission']))            
    handle.write('&lt;/table&gt;\n')
    handle.write('&lt;/td&gt;\n')
    handle.write('&lt;td&gt;\n')
    handle.write('&lt;table&gt;\n')
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('quick_push', app_distribution_dict['_01_quick_push']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('members', app_distribution_dict['_02_members']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('content', app_distribution_dict['_03_content']))
    handle.write('&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%d&lt;/td&gt;&lt;/tr&gt;\n' % ('news', app_distribution_dict['_02_news']))
    handle.write('&lt;/table&gt;\n')
    handle.write('&lt;/td&gt;\n')
    handle.write('&lt;/tr&gt;\n')
    handle.write('&lt;/table&gt;\n')
    
        
def write_head_html(handle):
    handle.write("""\
&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;
&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"&gt;
&lt;head&gt;
    &lt;title&gt;MPS Automated test case statistics - Results&lt;/title&gt;
    &lt;meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" /&gt;
    &lt;meta http-equiv="Content-Language" content="en" /&gt;
    &lt;style type="text/css"&gt;
        body {
            background-color: #FFFFFF;
            color: #000000;
            font-family: Trebuchet MS, Verdana, sans-serif;
            font-size: 11px;
            padding: 10px;
        }
        h1 {
            font-size: 25px;
            margin-bottom: 0.5em;
            background: #FF9933;
            padding-left: 5px;
            padding-top: 2px;
        }
        h2 {
            font-size: 20px;
            background: #C0C0C0;
            padding-left: 5px;
            margin-top: 2em;
            margin-bottom: .75em;
        }
        h3 {
            font-size: 11px;
            margin-bottom: 0.5em;
        }
        h4 {
            font-size: 11px;
            margin-bottom: 0.5em;
        }
        p {
            margin: 0;
            padding: 0;
        }
        table {
            margin-left: 30px;
        }
        td {
            text-align: right;
            color: #000000;
            background: #FFFFFF;
            padding-left: 10px;
            padding-right: 8px;
            padding-bottom: 0px;
        }
        th {
            text-align: center;
            font-size: 12px;
            padding-right: 30px;
            padding-left: 30px;
            color: #000000;
            background: #C0C0C0;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
""")
  


def write_closing_html(handle):
    handle.write("""\
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/body&gt;
&lt;/html&gt;
""")



if __name__ == '__main__':
    
    test_case_files = all_case_files()
    
    all_dir_list = ['_01_manager','_02_app']
    manager_dir_list = ['_survey', '_account', '_course', '_classroom', '_forum', '_mission', '_login', '_notice', '_group', '_exam', '_registration', '_news'] 
    app_dir_list = ['_01_quick_push','_02_members','_03_content','_02_news']
    
    all_each_counts = get_each_dir_case_count(all_dir_list,test_case_files)
    manager_each_counts = get_each_dir_case_count(manager_dir_list,test_case_files)
    app_each_counts = get_each_dir_case_count(app_dir_list,test_case_files)
    
    #pie
    graph_pie(manager_each_counts,pie_type='manager')     # manager type pie
    graph_pie(app_each_counts,pie_type='app')             # app type pie
    graph_pie(all_each_counts,pie_type='all')             # all type pie
    #line
    data = get_data()
    line_draw(data)
    
    # write html report
    fh = open(getReportPath() + os.sep + 'Interface_Stat_Results.html', 'w')
    write_head_html(fh)
    write_starting_content(fh)
    write_summary_results(fh,all_case_counts('all'),all_case_counts('manager'),all_case_counts('app'))
    write_stats_tables(fh,manager_each_counts,app_each_counts)
    write_images(fh)
    fh.close()
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>sysbench使用介绍</title>
    <url>/2015/01/01/sysbench/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>PS:<br>
Happy new year.</p>
<p><code>sysbench</code> 是一款开源的多线程的系统基准测试工具，广泛用于评估Linux操作系统下不同系统参数下的数据库负载情况，尤其是MySQL和PostgreSQL。除了数据库，Sysbench也可以对系统的文件I/O性能、CPU性能、内存分配及传输速率等硬件参数进行测试。由于其灵活性和扩展性，Sysbench是系统管理员和数据库管理员常用的性能测试工具。</p>
<p>主要特性：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>多线程: Sysbench可以生成多个线程同步执行测试，模拟多用户的操作环境。</p>
</li>
<li class="lvl-2">
<p>高度可定制: 可以指定许多测试参数，如线程数、测试时长、数据库表的大小、读写比例等。</p>
</li>
<li class="lvl-2">
<p>多种测试类型: 支持多种测试，如CPU性能测试、磁盘I/O性能测试、数据库性能测试等。</p>
</li>
<li class="lvl-2">
<p>脚本支持: 支持Lua脚本，可以编写定制化的测试场景。</p>
</li>
</ul>
<h1 id="sysbench-xiang-jie">sysbench 详解</h1>
<h2 id="an-zhuang">安装</h2>
<p>Sysbench可以从源代码编译安装，也可以通过包管理系统安装。例如，在Ubuntu上可以使用以下命令进行安装：</p>
<pre><code class="language-bash">sudo apt-get update
sudo apt-get install sysbench
</code></pre>
<h2 id="ce-shi-lei-xing">测试类型</h2>
<p><code>sysbench</code> 提供了多种测试类型，包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>CPU 测试：评估 CPU 性能</p>
</li>
<li class="lvl-2">
<p>内存测试：包括内存速度测试和内存泄漏测试</p>
</li>
<li class="lvl-2">
<p>磁盘 I/O 测试：评估磁盘读写性能</p>
</li>
<li class="lvl-2">
<p>网络测试：评估网络吞吐量和延迟</p>
</li>
<li class="lvl-2">
<p>数据库测试：模拟数据库操作，评估数据库性能</p>
</li>
</ul>
<h2 id="pei-zhi-wen-jian">配置文件</h2>
<p><code>sysbench</code> 允许使用配置文件来定义测试参数。配置文件通常以 .lua 扩展名保存，可以使用 --config-file 参数加载。</p>
<h3 id="shi-yong-shi-li">使用示例</h3>
<h4 id="cpu-ce-shi">CPU 测试</h4>
<p>要进行 CPU 测试，可以使用以下命令：</p>
<pre><code class="language-bash">sysbench --test=cpu --cpu-max-prime=20000 run
</code></pre>
<p>这里 <code>--test=cpu</code> 指定了测试类型，<code>--cpu-max-prime</code> 是一个可选参数，用于设置 CPU 测试中的最大素数，这里–cpu-max-prime=20000表示计算到第20000个素数。</p>
<h4 id="nei-cun-ce-shi">内存测试</h4>
<p>进行内存速度测试的命令如下：</p>
<pre><code class="language-bash">sysbench --test=memory --memory-block-size=1M --memory-total-size=10G --num-threads=10 run
</code></pre>
<p>这里 --memory-block-size 和 --memory-total-size 分别定义了内存块的大小和总大小，–num-threads 定义了测试中的线程数。</p>
<h4 id="ci-pan-i-o-ce-shi">磁盘 I/O 测试</h4>
<p>进行磁盘 I/O 测试的命令如下：</p>
<pre><code class="language-bash">sysbench --test=disk --disk-block-size=16K --disk-max-ops=10000 --disk-max-time=10 --disk-test-mode=rndrd --disk-rw-mode=rnd run
</code></pre>
<p>这里 --disk-block-size 定义了块大小，–disk-max-ops 设置了最大操作数，–disk-max-time 设置了最大测试时间，–disk-test-mode 和 --disk-rw-mode 分别定义了测试模式和读写模式。</p>
<h4 id="shu-ju-ku-ce-shi">数据库测试</h4>
<p>Sysbench可以用来评估数据库的OLTP(在线事务处理)性能，在进行测试前需要准备数据：</p>
<pre><code class="language-bash">sysbench oltp_read_write --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=yourusername --mysql-password=yourpassword --mysql-db=dbname --tables=10 --table-size=10000 prepare
</code></pre>
<p>执行测试：</p>
<pre><code class="language-bash">sysbench oltp_read_write --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=yourusername --mysql-password=yourpassword --mysql-db=dbname --tables=10 --table-size=10000 --time=60 --threads=8 --report-interval=10 run
</code></pre>
<p>清理数据：</p>
<pre><code class="language-bash">sysbench oltp_read_write --mysql-host=127.0.0.1 --mysql-port=3306 --mysql-user=yourusername --mysql-password=yourpassword --mysql-db=dbname --tables=10 --table-size=10000 cleanup
</code></pre>
<p>在上述命令中，需要替换yourusername、yourpassword和dbname到实际的数据库用户、密码和数据库名。–tables=10表示创建10个测试表，–table-size=10000表示每个表中有10000行数据。–time=60表示测试时长为60秒，–threads=8定义了8个线程。</p>
<h3 id="jie-guo-fen-xi">结果分析</h3>
<p><code>sysbench</code> 会在测试完成后输出详细的性能报告，包括每秒事务数、每秒查询数、平均响应时间等关键指标。这些数据可以帮助用户了解系统在不同负载下的性能表现，并为系统优化提供依据。</p>
<h1 id="overall">Overall</h1>
<p><code>sysbench</code> 是一个功能强大的基准测试工具，适用于开发人员、系统管理员和性能工程师。通过合理配置和使用，可以有效地评估和优化系统性能。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>sysbench</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>sysbench</tag>
      </tags>
  </entry>
  <entry>
    <title>bc介绍</title>
    <url>/2015/02/26/linux_bc/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>bc（Basic Calculator）是一个在多种UNIX和类UNIX系统中广泛可用的命令行计算器。它支持任意精度的数字和程序语言风格的语法，能够执行简单到复杂的算术、逻辑运算，并且可以定义自己的函数。这些特性使得bc成为一个强大且灵活的数学工具，特别适合处理科学计算、财务分析等需要高精度计算的场景。</p>
<h1 id="te-dian">特点</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>任意精度：bc可以处理非常大的数字，包括小数和非常大的整数。</p>
</li>
<li class="lvl-2">
<p>互动模式：bc提供了一个互动shell，用户可以在其中输入表达式并立即看到结果。</p>
</li>
<li class="lvl-2">
<p>可编程：具有类似于C语言的程序设计元素，包括变量赋值、条件判断、循环等。</p>
</li>
<li class="lvl-2">
<p>函数定义：用户可以定义和调用自己的函数，提升计算的灵活性和重复利用性。</p>
</li>
</ul>
<h1 id="shi-yong-chang-jing">使用场景</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>科学计算：任意精度的特性让bc非常适合大数或高精度要求的科学领域计算。</p>
</li>
<li class="lvl-2">
<p>财务分析：可以编写复杂的财务模型，比如复利计算、投资收益率分析等。</p>
</li>
<li class="lvl-2">
<p>教育用途：作为教学工具，演示算术和数学概念。</p>
</li>
<li class="lvl-2">
<p>脚本编程中的数学操作：在Shell脚本中嵌入数学计算时，bc是一个理想的工具，它可以返回处理后的数值结果给脚本变量。</p>
</li>
</ul>
<h1 id="an-zhuang">安装</h1>
<p>大多数UNIX和类UNIX系统中都自带有bc命令。如果系统中没有，可以通过包管理器安装：</p>
<p>对于Debian/Ubuntu系统：</p>
<pre><code class="language-shell">sudo apt-get install bc
</code></pre>
<p>对于CentOS/Fedora系统：</p>
<pre><code class="language-bash">sudo yum install bc
</code></pre>
<h1 id="ji-ben-yu-fa">基本语法</h1>
<p>bc 的基本语法如下：</p>
<pre><code class="language-shell">bc -l [选项] [文件]

    -l 选项表示使用数学库。
    [文件] 是包含 bc 程序的文件名。
</code></pre>
<h1 id="chang-jian-yong-fa">常见用法</h1>
<h2 id="ji-chu-suan-zhu-yun-suan">基础算术运算</h2>
<p>启动bc：</p>
<pre><code class="language-shell">bc
</code></pre>
<p>然后你可以在出现的提示符下输入算术表达式，如：</p>
<pre><code class="language-shell">5 + 3
</code></pre>
<h2 id="shi-yong-bian-liang">使用变量</h2>
<pre><code class="language-shell">echo "define pi 3.14159
a = 5
b = a * pi
print b" | bc
</code></pre>
<p>这将定义一个变量 pi 并计算 5 * pi 的值。</p>
<h2 id="xun-huan">循环</h2>
<pre><code class="language-shell">echo "define sum(x) {
  i = 1
  sum = 0
  while (i &lt;= x) {
    sum = sum + i
    i = i + 1
  }
  return sum
}
print sum(100)" | bc
</code></pre>
<p>这个脚本定义了一个函数 sum，计算从 1 到 x 的所有整数之和，并输出 sum(100) 的结果。</p>
<h2 id="tiao-jian-yu-ju">条件语句</h2>
<pre><code class="language-shell">echo "define is_prime(n) {
  if (n &lt;= 1) {
    return 0
  }
  for (i = 2; i &lt;= n / 2; i++) {
    if (n % i == 0) {
      return 0
    }
  }
  return 1
}
print is_prime(29)" | bc
</code></pre>
<p>这个脚本定义了一个函数 is_prime，用于检查一个数是否为素数，并输出 is_prime(29) 的结果。</p>
<h2 id="shi-yong-gao-ji-gong-neng">使用高级功能</h2>
<p>启动bc时带上-l选项，可以访问标准数学库，这提供了对高级函数如正弦（sin）、余弦（cos）等的支持：</p>
<pre><code class="language-shell">bc -l
</code></pre>
<p>然后你可以进行如下计算：</p>
<pre><code class="language-shell">s(3.14159265)  # 计算 sin(π), 接近 0
</code></pre>
<h2 id="ding-yi-bing-shi-yong-han-shu">定义并使用函数</h2>
<p>bc也支持用户自定义函数。例如，定义一个计算平方的函数：</p>
<pre><code class="language-shell">define square(x) {
    return x * x
}
square(4)  # 输出16
</code></pre>
<h2 id="zhi-xing-jiao-ben">执行脚本</h2>
<p>bc可以执行存储在文件中的脚本。例如，将上面定义的square函数和调用代码保存到calculations.bc文件中，然后执行：</p>
<pre><code class="language-shell">bc -l calculations.bc
</code></pre>
<h1 id="xiao-tie-shi">小贴士</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用scale变量来设置小数点后的精确位数。例如，scale=5确定了结果保留到小数点后五位。</p>
</li>
<li class="lvl-2">
<p>利用if, while, for等控制结构来增强计算的逻辑能力。</p>
</li>
<li class="lvl-2">
<p>使用quit或Ctrl+D来退出bc。</p>
</li>
</ul>
<h1 id="zong-jie">总结</h1>
<p><code>bc</code>命令是一个功能强大的计算器，它填补了简单计算器功能不足的空白。无论是进行简单的算术操作，还是需要复杂的数学函数计算，甚至编写完整的数学计算脚本，bc都能够有效地满足需求，是每个涉及数学计算的行业专业人士必备的工具。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>bc</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>bc</tag>
      </tags>
  </entry>
  <entry>
    <title>令人惊艳的Linux工具</title>
    <url>/2015/03/09/amazing_linux_commands/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Linux 拥有丰富多彩的命令行工具集，很多工具都具有强大的功能和独特的魅力。本文推荐一些比较有趣且实用的 Linux 命令或工具，它们绝对能够给你的日常工作带来些许惊艳：</p>
<p><strong>tmux</strong><br>
tmux 是一个终端复用器，允许用户在单个终端窗口中打开多个会话，你可以在会话之间轻松切换，甚至在不同的物理位置接入同一个会话。</p>
<p><strong>atop</strong><br>
相较于传统的 top 命令，atop 以更加直观的方式显示系统进程和资源占用情况，提供交互式操作，并支持自动颜色标识、垂直、水平滚动和搜索匹配。</p>
<p><strong>ncdu (NCurses Disk Usage)</strong><br>
ncdu 是一个基于文本的磁盘用量分析器，使用 Ncurses 库进行可视化显示，比 du 命令更易用，可以轻松找到占用磁盘空间的文件和目录。</p>
<p><strong>fzf (Fuzzy Finder)</strong><br>
fzf 是一个命令行的模糊查找器，它可以被绑定到任何列表数据上，如文件、命令历史等，支持模糊匹配，使得查找效率大大提升。</p>
<p><strong>Glances</strong><br>
Glances 是一个跨平台的系统监控工具，它提供了负载、进程、磁盘、网络等全方位的视图，还可以运行在 Web 模式，通过浏览器远程查看状态。</p>
<p><strong>tldr (Too Long; Didn’t Read)</strong><br>
tldr 提供了简化版的 man 页面，它用更少的词汇和更多实用示例来描述命令的使用方法，对于快速查找命令用法非常便捷。</p>
<p><strong>The Silver Searcher (ag)</strong><br>
ag 是一个类似于 grep 的文本搜索工具，但它是专门为代码搜索优化的，速度更快，并默认忽略 .git 或其他版本控制系统的目录。</p>
<p><strong>neofetch</strong><br>
neofetch 是一个轻量级的系统信息工具，它以图形化的方式显示关于你的系统和硬件的信息，辅以漂亮的ASCII艺术。</p>
<p><strong>jq</strong><br>
jq 是一个轻量级且灵活的命令行 JSON 处理器，允许你对 JSON 数据进行切分、过滤、映射和转换等操作，对于处理 JSON 格式日志或 API 响应尤其有用。</p>
<p><strong>nmap</strong><br>
nmap 是一个强大的网络探测和安全审核工具，能够发现网络上的设备，并确定设备上运行的服务和对应的端口，同时它还具有端口扫描、版本检测、网络发现等功能。</p>
<p><strong>bat</strong><br>
bat 是 cat 命令的一个克隆版本，但附加了很多有用的特性，比如语法高亮显示、Git 集成和自动分页等。</p>
<h1 id="ge-gong-ju-jie-shao">各工具介绍</h1>
<h2 id="tmux">tmux</h2>
<h3 id="shi-yao-shi-tmux">什么是 tmux？</h3>
<p>tmux（Terminal Multiplexer）是一个开源的工具，用于在一个终端窗口内管理多个终端会话。通过使用 tmux，用户可以在一个窗口内创建、切换和断开连接到多个终端会话，尽情享受它所带来的强大功能。</p>
<h3 id="tmux-de-guan-jian-te-xing">tmux 的关键特性</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>会话管理：tmux 允许你从多个会话中选择，可以在本地或远程服务器上运行。这意味着你可以在本地机器上启动一个会话，在远程服务器上切换到该会话，并持续不间断地工作。</p>
</li>
<li class="lvl-2">
<p>窗口分割：tmux 提供了分割窗格的功能，使你可以在一个终端窗口中查看和操作多个窗口，类似于 Vim 和 Emacs 的缓冲区和窗口管理。</p>
</li>
<li class="lvl-2">
<p>可定制性：tmux 提供了丰富的键盘快捷键和可配置选项，可以根据个人喜好和需求进行个性化定制。</p>
</li>
<li class="lvl-2">
<p>持久性：即使终端断开连接或系统重启，tmux 会话仍然可以被恢复。这对于长时间运行的任务和批处理作业尤为重要。</p>
</li>
<li class="lvl-2">
<p>易于安装：tmux 跨平台兼容，几乎可在所有类 Unix 系统上安装。在大多数 Linux 发行版中，你可以直接使用包管理器安装 tmux。</p>
</li>
</ul>
<h3 id="ru-he-kai-shi-shi-yong-tmux">如何开始使用 tmux？</h3>
<p>首先，确保在你的系统上安装了 tmux。在大多数 Linux 发行版中，可以使用以下命令安装 tmux：</p>
<pre><code class="language-shell">apt-get install tmux  # 对于 Debian/Ubuntu 系统
yum install tmux      # 对于 CentOS/RedHat 系统
pacman -S tmux        # 对于 Arch Linux 系统
</code></pre>
<p>安装完成后，只需在终端中输入 tmux 即可启动一个新的 tmux 会话。你可以使用 tmux new -s <session-name> 创建一个带有特定名称的新会话。</session-name></p>
<h3 id="tmux-ji-ben-shi-yong">tmux 基本使用</h3>
<h4 id="chuang-jian-xin-hui-hua">创建新会话</h4>
<pre><code class="language-shell">tmux new -s my-session
</code></pre>
<h4 id="fu-jia-dao-yi-cun-zai-de-hui-hua">附加到已存在的会话</h4>
<pre><code class="language-shell">tmux attach -t my-session
</code></pre>
<h4 id="lie-chu-suo-you-hui-hua">列出所有会话</h4>
<pre><code class="language-shell">tmux ls
</code></pre>
<h4 id="zai-hui-hua-jian-qie-huan">在会话间切换</h4>
<p>使用 Ctrl+b 后跟数字键（例如，Ctrl+b 1）可以在不同窗格或会话间切换。</p>
<p>分割窗格：</p>
<pre><code>水平分割窗格：

Ctrl+b %


垂直分割窗格：

Ctrl+b "
</code></pre>
<p>导航窗格：</p>
<pre><code>在窗格间切换：

    Ctrl+b 方向键


关闭当前窗格：

    Ctrl+b x
</code></pre>
<h3 id="gao-ji-tmux-shi-yong-ji-qiao">高级 tmux 使用技巧</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>自定义快捷键：编辑 ~/.tmux.conf 文件，可以添加或更改 tmux 快捷键的配置。例如，你可以将预览窗格的快捷键从 Ctrl+b w 改为 Ctrl+b Tab。</p>
</li>
<li class="lvl-2">
<p>复制和粘贴： 在 tmux 中，使用 Ctrl+b [ 进入复制模式，使用方向键移动光标选择文本，并按 Space 来开始选择。退出复制模式后，可以使用 Ctrl+b ] 粘贴文本。</p>
</li>
<li class="lvl-2">
<p>会话持久性：设置 set -g attach-session-tiled yes 使会话在附加到现有会话时保持平铺模式。</p>
</li>
<li class="lvl-2">
<p>面板和窗口命名：你可以为面板和窗口设置名字，以便更容易地区分和管理。编辑 ~/.tmux.conf 文件，添加以下行：<br>
<code>set -g status-left "#[fg=green]#H #[fg=white]#(whoami)#[fg=green]#(basename "$PWD")#[fg=white]"</code></p>
</li>
<li class="lvl-2">
<p>使用 tmux 与 Vim 协同工作：tmux 配合 Vim 可以实现一些强大的编辑功能，如代码折叠、快速导航等。</p>
</li>
</ul>
<p>tmux 是一个功能丰富的工具，这些只是它的冰山一角。通过深入了解和掌握 tmux，你的终端操作将会变得无比流畅和高效。对于那些多任务、长时间运行的作业和项目，tmux 无疑是一个宝贵的资产。</p>
<h2 id="atop">atop</h2>
<p>公司产品一直内嵌此程序，非常好用，额外介绍了。</p>
<h2 id="ncdu">ncdu</h2>
<p>ncdu（NCurses Disk Usage）是一个用于查看磁盘用量并以交互方式找到占用空间最多的文件和目录的工具。</p>
<h3 id="an-zhuang-ncdu">安装 ncdu</h3>
<p>首先，你需要在你的系统上安装 ncdu。不同的 Linux 发行版会提供不同的包管理器，以下是一些常用发行版的安装命令：</p>
<p>对于基于 Debian 和 Ubuntu 的系统：</p>
<pre><code class="language-shell">apt-get update
apt-get install ncdu
</code></pre>
<p>对于基于 Fedora 的系统：</p>
<pre><code class="language-shell">dnf install ncdu
</code></pre>
<p>对于基于 Arch 的系统：</p>
<pre><code class="language-shell">pacman -S ncdu
</code></pre>
<p>安装完成后，你可以开始使用 ncdu。</p>
<h3 id="shi-yong-ncdu">使用 ncdu</h3>
<p>要使用 ncdu，打开终端并运行以下命令：</p>
<pre><code class="language-shell">ncdu
</code></pre>
<p>默认情况下，此命令会扫描当前工作目录及其所有子目录，并且显示它们占用的磁盘空间。要扫描整个系统，你可以运行：</p>
<pre><code class="language-shell">ncdu /
</code></pre>
<p>这将以超级用户权限开始扫描整个根文件系统。</p>
<p>ncdu 扫描完成后，你会看到类似这样的界面，列出所有文件和文件夹及其大小：</p>
<pre><code class="language-shell">--- /path/to/directory ----------------------------------------------
    4.6 GiB [##########] /usr
    1.4 GiB [###       ] /var
  720.3 MiB [#         ] /lib
  256.7 MiB [          ] /home
  106.7 MiB [          ] /boot
</code></pre>
<p>操作指南</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用键盘上的箭头键 ↑ 和 ↓ 来浏览文件列表。</p>
</li>
<li class="lvl-2">
<p>进入目录请按 → 或 Enter，返回上级目录请按 ←。</p>
</li>
<li class="lvl-2">
<p>要删除一个文件或目录（请非常谨慎操作），你可以将光标移动到该项上并按 d 键。</p>
</li>
<li class="lvl-2">
<p>按q退出 ncdu。</p>
</li>
</ul>
<p>ncdu 提供了一种简洁而直观的方式来查看哪些文件和目录占用了大量空间，允许你直接在界面中浏览到它们，并取得关于每个项目大小的直观感受。通过它，你可以快速识别并处理占用空间过多的项。</p>
<h2 id="fzf">fzf</h2>
<p>fzf 是一个命令行模糊查找器，具有以下几个特点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>速度快: fzf 通过使用 Go 语言编写而获得了极其快的执行速度。</p>
</li>
<li class="lvl-2">
<p>模糊匹配: 您可以输入任意位置的字符序列，fzf 将会模糊匹配相关的结果。</p>
</li>
<li class="lvl-2">
<p>终端集成: 它可以在任何使用了标准输入（stdin）的命令中使用，使其十分灵活。</p>
</li>
<li class="lvl-2">
<p>排序: 匹配的结果会根据相关性排序，最相关的结果排在前面。</p>
</li>
<li class="lvl-2">
<p>可自定义: 可以自定义快捷键、颜色、窗口大小等。</p>
</li>
<li class="lvl-2">
<p>可扩展性: 它可以与其他命令结合使用，例如 ls, cat, find, git log。</p>
</li>
<li class="lvl-2">
<p>跨平台: 可以在大多数 Unix 系统上使用，包括 macOS、Linux 和 BSD。</p>
</li>
<li class="lvl-2">
<p>插件: 对于像 vim 和 bash 这样的应用，有现成的插件，可以在您喜欢的外壳或编辑器中使用 fzf。</p>
</li>
</ul>
<h3 id="an-zhuang-fzf">安装 fzf</h3>
<p>可以通过包管理器进行安装，例如，在 Ubuntu 上：</p>
<pre><code class="language-shell">apt install fzf
</code></pre>
<p>或者使用 git 克隆仓库并运行安装脚本：</p>
<pre><code class="language-shell">git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf
~/.fzf/install
</code></pre>
<h3 id="shi-yong-shi-li">使用示例</h3>
<h4 id="jian-dan-de-cha-zhao">简单的查找</h4>
<p>可以通过管道将任何列表传递到 fzf 中：</p>
<pre><code class="language-shell">   cat list.txt | fzf
</code></pre>
<h4 id="zai-vim-zhong-cha-zhao-wen-jian-bing-da-kai">在 vim 中查找文件并打开</h4>
<p>如果你使用的是 vim，并且已经安装了 fzf 的 vim 插件：</p>
<pre><code class="language-shell">   :Files
</code></pre>
<h4 id="li-shi-ming-ling-cha-xun">历史命令查询</h4>
<p>使用 fzf 查询命令行历史：</p>
<pre><code class="language-shell">   history | fzf
</code></pre>
<h4 id="jin-cheng-cha-zhao-bing-kill">进程查找并 kill</h4>
<p>使用 fzf 结合 ps 来选择一个进程并 kill 掉它：</p>
<pre><code class="language-shell">   ps -ef | fzf | awk '{print $2}' | xargs kill
</code></pre>
<h4 id="cha-zhao-wen-jian">查找文件</h4>
<p>几乎在任何需要文件查找的地方，都可以使用 find 和 fzf 的组合：</p>
<pre><code class="language-shell">   find path/to/search -type f | fzf
</code></pre>
<h4 id="pei-he-git-shi-yong">配合 git 使用</h4>
<p>查找 git 分支：</p>
<pre><code class="language-shell">   git branch | fzf
</code></pre>
<h3 id="gao-ji-zi-ding-yi">高级自定义</h3>
<p>fzf 允许用户进行很多自定义，例如绑定键位、更改查找算法、自定义颜色等：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>设置 FZF_DEFAULT_OPTS 环境变量来更改默认选项</p>
</li>
</ul>
<p>如：</p>
<pre><code class="language-shell">   export FZF_DEFAULT_OPTS='--height=40% --reverse --border'
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>在启动 fzf 时通过命令行参数调整行为</p>
</li>
</ul>
<p>比如使用 --reverse 选项来颠倒列表顺序。</p>
<h3 id="ji-cheng-qi-ta-gong-ju">集成其他工具</h3>
<p>fzf 提供了一些有用的示例和配方，展示了如何将它与 ripgrep、ag 或其他命令结合来提升文件搜索的体验。它通常配合 tmux, bash, zsh, fish 等 shell 环境和 vim 等文本编辑器使用，通过各种 shell 脚本和函数加以实际应用。</p>
<p>这只是 fzf 功能和用法的冰山一角，随着对命令行的理解加深，你会发现 fzf 可以提升你的工作流程到一个全新的水平。</p>
<h2 id="glances">Glances</h2>
<p>Glances 是一个跨平台的监控工具，它运行在终端中，提供了一个实时的、整合了多项功能的视图来观察你的系统资源利用情况，包括 CPU、内存、负载、磁盘 I/O、网络 I/O、磁盘使用、传感器（温度、风扇）、进程等信息。Glances 使用 Python 编写，基于一个库叫 psutil，这使得 Glances 能够在许多不同的平台上运行。</p>
<p>主要特点包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>全面的监控视图: Glances 以紧凑的格式展示您的系统信息，便于一眼看到所有关键性能指标。</p>
</li>
<li class="lvl-2">
<p>插件架构: Glances 可以通过插件来扩展其监控功能，用户可以开发自己的插件来定制 Glances 的行为。</p>
</li>
<li class="lvl-2">
<p>Web服务器模式: Glances 可以在 Web 服务器模式下运行。只需启动它，并通过浏览器访问提供的 URL 便可以监控系统。这在远程监控情况下非常有用。</p>
</li>
<li class="lvl-2">
<p>REST API: Glances 提供了一个 RESTful API，你可以通过这个 API 查询系统的实时信息，并且可以轻松集成到其他应用中。</p>
</li>
<li class="lvl-2">
<p>警告和阈值: Glances 允许用户设置各种资源的阈值（如高/严重/危险），当系统资源使用情况超过预定阈值时，相关的指标会变色（黄/红色）以提醒用户。</p>
</li>
<li class="lvl-2">
<p>跨平台: 它适用于 Linux、Windows 和 macOS，以及任何能够运行 Python 的操作系统。</p>
</li>
<li class="lvl-2">
<p>易于安装: Glances 可以通过 Python 的包管理工具 pip 进行安装。</p>
</li>
<li class="lvl-2">
<p>多种输出形式: 除了标准的终端输出之外，Glances 还能够以 CSV、JSON、XML 等格式导出数据。</p>
</li>
<li class="lvl-2">
<p>互动式界面: 在 Glances 中，用户可以使用键盘命令与界面互动，例如排序进程列表或改变显示的度量。</p>
</li>
</ul>
<h3 id="an-zhuang-glances">安装 Glances</h3>
<p>可以使用 pip 来安装 Glances：</p>
<pre><code class="language-shell">pip install glances
</code></pre>
<p>在一些发行版中，Glances 也可能包含在官方的软件仓库中，可以使用包管理器安装。例如在 Ubuntu 系统中：</p>
<pre><code class="language-shell">apt-get update
apt-get install glances
</code></pre>
<h3 id="shi-yong-glances">使用 Glances</h3>
<p>要启动 Glances，只需在终端中键入 glances：</p>
<pre><code class="language-shell">glances
</code></pre>
<p>在 Glances 运行的时候，你可以使用键盘快捷键来进行不同的操作，例如：</p>
<pre><code>h: 显示帮助屏幕
c: 通过 CPU 使用率对进程排序
m: 通过内存使用率对进程排序
p: 通过磁盘 I/O 排序进程
n: 通过网络 I/O 排序进程
g: 切换网络 I/O 显示速率和总计数
w: 切换到 web 服务器模式
q: 退出 Glances
</code></pre>
<h4 id="web-fu-wu-qi-mo-shi">Web 服务器模式</h4>
<p>要在 web 服务器模式下启动 Glances，请使用以下命令：</p>
<pre><code class="language-shell">glances -w
</code></pre>
<p>此时 Glances 将启动一个内置的 web 服务器，你可以在任意设备的 web 浏览器中输入主机的 IP 地址和默认端口 61208（例如 <a href="http://127.0.0.1:61280">http://127.0.0.1:61280</a>)</p>
<h4 id="jian-pan-kuai-jie-jian">键盘快捷键</h4>
<p>在 Glances 的终端界面中，你可以使用以下快捷键：</p>
<pre><code>↑ 和 ↓：上下滚动列表。
h：显示帮助菜单。
1：切换CPU视图（全局/每核）。
b：切换字节/bit 模式（对于网络速率显示）。
w：切换到 I/O 速率重新计算模式。
q 或 Ctrl+C：退出 Glances。
</code></pre>
<p>更多快捷键和功能可以通过 h 快捷键在 Glances 中查看。</p>
<h3 id="ji-cheng-yu-kuo-zhan">集成与扩展</h3>
<p>Glances 可以集成到其他监控解决方案中，例如可以将数据输出到 InfluxDB、Grafana，以获得更美观，功能更全面的监控视图。</p>
<p>此外，Glances 的 GitHub 页面有着详细的文档来帮助用户配置和使用该工具，地址为：<a href="https://github.com/nicolargo/glances%E3%80%82">https://github.com/nicolargo/glances。</a></p>
<h2 id="tldr-too-long-didnt-read">tldr (Too Long; Didn’t Read)</h2>
<h2 id="the-silver-searcher-ag">The Silver Searcher (ag)</h2>
<p>The Silver Searcher (ag)：高效的代码搜索利器</p>
<p>随着软件开发的复杂性日益增加，开发人员经常需要在大量代码库中查找特定的函数、变量或者任何其他文本模式。传统的 grep 工具虽然强大，但在处理大型文件或需要更智能搜索时，可能会显得力不从心。在这种背景下，The Silver Searcher（ag）应运而生，它以其卓越的性能和丰富的特性，成为了开发者搜索代码时的首选工具。</p>
<h3 id="shi-yao-shi-the-silver-searcher-ag">什么是 The Silver Searcher (ag)？</h3>
<p>The Silver Searcher，简称 ag，是一个基于 Vim 文件型录工具 ack 的代码搜索工具。它非常快速，可以轻松地在大型文件和庞大的代码库中搜索文本、字符串、正则表达式等。ag 使用多进程来并行搜索文件，这使得它在处理大量数据时比 grep 更加高效。</p>
<h3 id="ag-de-he-xin-te-xing">ag 的核心特性</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>快速搜索：ag 利用多进程快速并行地搜索文件，尤其在处理大型文件和深层次的目录结构时，相较于传统工具具有显著的速度优势。</p>
</li>
<li class="lvl-2">
<p>智能匹配：ag 默认情况下会忽略大小写，并且能够智能地匹配整行或单词边界，以减少误报。</p>
</li>
<li class="lvl-2">
<p>丰富的查询语法：ag 支持正则表达式和 Perl 兼容的正则表达式（PCRE），为用户提供了强大的搜索语法和灵活的查询能力。</p>
</li>
<li class="lvl-2">
<p>可视化输出：ag 可以用高亮显示搜索到的匹配项，使结果更易于阅读和分析。</p>
</li>
<li class="lvl-2">
<p>集成与兼容性：ag 几乎是跨平台的，它支持 Linux、macOS、Windows 等操作系统。此外，ag 可以很方便地与文本编辑器和集成开发环境（IDE）集成，例如 Vim、Emacs、Sublime Text、Visual Studio Code 等。</p>
</li>
</ul>
<h3 id="ru-he-an-zhuang-the-silver-searcher-ag">如何安装 The Silver Searcher (ag)？</h3>
<p>在大多数 Linux 发行版和 macOS 上，可以使用包管理器轻松安装 ag。以下是在不同系统上安装 ag 的命令：</p>
<p>对于 Debian/Ubuntu 系统：</p>
<pre><code class="language-shell">apt-get install silversearcher-ag
</code></pre>
<p>对于 macOS 用户（使用 Homebrew）：</p>
<pre><code class="language-shell">brew install silversearcher-ag
</code></pre>
<p>对于 Windows 用户，可以使用预编译的二进制文件或通过包管理器（如 Chocolatey）安装。</p>
<h3 id="ji-ben-shi-yong-he-ming-ling">基本使用和命令</h3>
<p>安装完成后，你可以在终端中输入 ag 加上你的搜索词来开始搜索。例如：</p>
<pre><code class="language-shell">ag "function_name"
</code></pre>
<p>如果你想在整个项目目录中搜索，可以使用 -l（递归地遍历目录）或 --follow（递归地搜索并读取包含符号链接的文件）选项：</p>
<pre><code class="language-shell">ag -l "function_name"
</code></pre>
<h3 id="gao-ji-ji-qiao">高级技巧</h3>
<h4 id="pai-chu-te-ding-wen-jian-huo-mu-lu">排除特定文件或目录</h4>
<p>使用 -忽略 选项排除特定的文件或目录。例如，忽略所有 .log 文件和 node_modules 目录：</p>
<pre><code class="language-shell">ag "search_pattern" --ignore "*.log" --ignore "node_modules"
</code></pre>
<h4 id="shi-yong-dai-li-wen-jian">使用代理文件</h4>
<p>创建一个代理文件（例如 .agignore），在其中列出要忽略的文件模式。ag 会自动读取这个文件来排除匹配的文件和目录。</p>
<h4 id="zi-ding-yi-gao-liang-xian-shi">自定义高亮显示</h4>
<p>ag 允许你通过 --color 选项来自定义搜索结果的高亮显示。例如，只为搜索到的行的匹配部分高亮：</p>
<pre><code class="language-shell">ag "search_pattern" --color "match"
</code></pre>
<h4 id="di-gui-sou-suo-mu-lu">递归搜索目录</h4>
<p>使用 --cpp 选项让 ag 以 C++ 程序员的方式递归搜索目录，这在搜索嵌套目录时非常实用。</p>
<h4 id="yu-git-ji-cheng">与 Git 集成</h4>
<p>ag 可以和 Git 集成，只在你的工作目录（即未暂存的更改）中搜索，使用 --vcs 选项即可。</p>
<p>The Silver Searcher (ag) 以其无与伦比的速度和功能，已经成为了现代程序员的标准工具之一。无论你是在查找代码中的某个函数、解决依赖冲突，还是仅仅在尝试理解一个新项目的架构，ag 都会让你的工作流程更加高效和愉悦。</p>
<h2 id="neofetch">neofetch</h2>
<p>在命令行用户中，展示系统信息和美化终端输出的工具一直备受欢迎。neofetch 是一款流行的命令行系统信息工具，因其提供美观、可定制的输出而变得非常流行。它结合了 fancy-weather、mo都会有问题多 以 install xul-ext-dark-okiraq 等工具的功能，为用户展示了丰富的系统信息，同时保持了视觉上的吸引力。</p>
<h3 id="shi-yao-shi-neofetch">什么是 Neofetch？</h3>
<p>Neofetch 是 neofetch 项目的分支，专为美观和功能而设计。它在 geany 光主题的基础上，引入了大量的改进，并添加了新的功能和选项。neofetch 旨在提供一种简明的方式来展示系统信息，同时允许用户通过自定义选项和额外的组件扩展其功能。</p>
<h3 id="wei-shi-yao-shi-yong-neofetch">为什么使用 Neofetch？</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>美观的输出：neofetch 提供了清晰、美观的输出样式，可以轻松地识别各种系统信息。</p>
</li>
<li class="lvl-2">
<p>丰富的信息：neofetch 为用户提供了系统信息的丰盛大餐，包括但不限于内核版本、操作系统、CPU 型号、内存使用率、电池状态等。</p>
</li>
<li class="lvl-2">
<p>可定制性：用户可以根据自己的喜好，通过各种选项和主题来定制 neofetch 的输出样式。</p>
</li>
<li class="lvl-2">
<p>易于使用：neofetch 的使用十分简单，同时还提供了许多有用的选项以便用户详细地查看系统信息。</p>
</li>
<li class="lvl-2">
<p>实时更新：某些系统信息，如 CPU 和内存使用情况，可以通过 watch 命令实时查看，便于用户监控系统状态。</p>
</li>
</ul>
<h3 id="ru-he-an-zhuang-neofetch">如何安装 Neofetch？</h3>
<p>neofetch 支持多种操作系统。在大多数 Linux 发行版中，你可以通过包管理器进行安装。以下是在不同系统上安装 neofetch 的命令：</p>
<p>对于基于 Debian 的系统（如 Ubuntu）：</p>
<pre><code class="language-shell">apt-get install neofetch
</code></pre>
<p>对于基于 RPM 的系统（如 Fedora）：</p>
<pre><code class="language-shell">dnf install neofetch
</code></pre>
<p>对于 Arch Linux 用户：</p>
<pre><code class="language-shell">pacman -S neofetch
</code></pre>
<h3 id="shi-yong-neofetch">使用 Neofetch</h3>
<p>安装完成后，只需在终端中输入 neofetch 命令，即可看到系统信息的美观展示。默认情况下，neofetch 会使用 suru 主题。</p>
<p>你也可以使用其他主题，只需将主题文件夹放置在 ~/.config/neofetch/ 目录下，并通过 --theme 选项指定主题：</p>
<pre><code class="language-shell">neofetch --theme &lt;主题名&gt;
</code></pre>
<p>neofetch 还支持许多配置选项，你可以通过创建或编辑配置文件 ~/.config/neofetch/config.conf 来自定义其行为。</p>
<h3 id="gao-ji-yong-fa">高级用法</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>自定义输出：你可以配置 neofetch 显示或隐藏特定的信息模块，如 cpu、memory 等。</p>
</li>
</ul>
<pre><code class="language-shell">neofetch --no-memory
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>CPU 使用率：neofetch 可以实时显示 CPU 使用率。要使用此功能，请运行：</p>
</li>
</ul>
<pre><code class="language-shell">watch -n 1 neofetch
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>添加额外组件：neofetch 支持添加额外的组件，如字体、图标等，以增强其视觉效果。</p>
</li>
<li class="lvl-2">
<p>更新和升级：neofetch 经常更新以修复问题和添加新功能。确保定期检查更新，以保持软件的最新状态。</p>
</li>
<li class="lvl-2">
<p>社区支持：如果遇到问题或需要灵感，neofetch 社区非常活跃，你可以在 GitHub、Reddit 或其他论坛上寻求帮助或分享你的配置。</p>
</li>
</ul>
<h2 id="jq">jq</h2>
<p>在现代软件开发中，JSON（JavaScript Object Notation）作为一种轻量级的数据交换格式，已经被广泛应用在各种场景中。然而，处理JSON数据并不是件轻松的事情，特别是在命令行环境中。幸运的是，jq这个工具应运而生，它是一个轻量级且功能强大的命令行JSON处理器，专门用于解析、生成和处理JSON数据。</p>
<h3 id="shi-yao-shi-jq">什么是jq？</h3>
<p>jq是一个命令行工具，用于处理JSON格式的数据。它的出现极大地简化了与JSON数据的交云，并提供了丰富的功能，如数据提取、过滤、排序和转换。jq使用了类似Bash的文本处理理念，但针对JSON对象和数组的数据结构。</p>
<h3 id="jq-de-he-xin-te-xing">jq的核心特性</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>解析和打印JSON：jq能够将JSON数据格式化为易读的格式，帮助用户更好地理解数据结构。</p>
</li>
</ul>
<pre><code class="language-shell">    jq . &lt; jsonfile
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>过滤和查询：jq支持使用JSON路径表达式（类似XPATH）进行过滤和查询。</p>
</li>
</ul>
<pre><code class="language-shell">    jq '.users | map(select(.name == "jq-dev"))' &lt; jsonfile
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>修改和创建JSON：你可以使用jq来修改现有JSON结构或创建新的JSON对象。</p>
</li>
</ul>
<pre><code class="language-shell">    jq '.name="John Doe"' &lt; jsonfile &gt; newfile
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>颜色输出：jq可以根据JSON数据的层次结构进行智能颜色打印，使结果更加直观。</p>
</li>
</ul>
<pre><code class="language-shell">    jq --color-input --pretty-print &lt; jsonfile
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>强大的表达式：jq支持算术、逻辑、文本处理等多种表达式，还支持递归调用。</p>
</li>
</ul>
<h3 id="ru-he-an-zhuang-jq">如何安装jq？</h3>
<p>jq几乎可以在所有主流操作系统上安装。在大多数Linux发行版中，你可以使用包管理器进行安装。</p>
<p>对于基于Debian的系统（如Ubuntu）：</p>
<pre><code class="language-shell">    apt-get install jq
</code></pre>
<p>对于基于RPM的系统（如Fedora）：</p>
<pre><code class="language-shell">    dnf install jq
</code></pre>
<p>对于macOS用户（使用Homebrew）：</p>
<pre><code class="language-shell">    brew install jq
</code></pre>
<h3 id="shi-yong-jq-jin-xing-json-chu-li">使用jq进行JSON处理</h3>
<p>获取JSON中的值：</p>
<pre><code class="language-shell">    jq '.key' &lt; jsonfile
</code></pre>
<p>这将返回名为key的JSON字段的值。</p>
<p>修改JSON中的值：</p>
<pre><code class="language-shell">    jq '.key = "newValue"' jsonfile &gt; newfile
</code></pre>
<p>这将设置名为key的字段值为newValue，并将结果输出到newfile。</p>
<p>从多个JSON文件中提取数据：</p>
<pre><code class="language-shell">    jq '.key' json1.json json2.json
</code></pre>
<p>这将从所有指定的JSON文件中提取名为key的字段的值。</p>
<p>排序JSON数组：</p>
<pre><code class="language-shell">    jq '.sort_by(.value)' &lt; jsonfile
</code></pre>
<p>这将按数组中的值进行升序排序。</p>
<p>条件过滤JSON数据：</p>
<pre><code class="language-shell">    jq '.filter_by("disk", "vin")' &lt; jsonfile
</code></pre>
<p>这将过滤出所有“disk”字段等于“vin”的JSON对象。</p>
<h3 id="gao-ji-jq-ji-qiao">高级jq技巧</h3>
<p>合并多个JSON对象：</p>
<pre><code class="language-shell">    jq --slurp 'reduce .[] { . * $item }' *.json
</code></pre>
<p>这将合并当前目录下所有的JSON文件。</p>
<p>从远程JSON服务提取数据：</p>
<pre><code class="language-shell">    curl -s http://myapi.com/data | jq '.key'
</code></pre>
<p>这将首先使用curl命令从远程服务获取JSON数据，然后用jq处理它。</p>
<p>创建复杂的新JSON结构：</p>
<pre><code class="language-shell">    jq -n '{"newkey": [1, 2, 3]}'
</code></pre>
<p>这将创建一个新的JSON对象，包含一个名为newkey的数组字段。</p>
<p>与Shell脚本结合：</p>
<pre><code class="language-shell">    users=$(jq '.users[].name' &lt; users.json)
</code></pre>
<p>这将在Shell脚本中使用，将用户名称提取到Shell变量中。</p>
<h2 id="nmap">nmap</h2>
<p>网络管理员和安全专家每天都会面临许多网络管理和安全挑战。为了解决这些问题，他们需要了解自己的网络中的设备和系统，以及这些设备的配置和漏洞。这时，Nmap（网络映射器）就发挥了重要作用。作为一款强大的网络扫描工具，Nmap可以检测网络上的主机、识别运行在这些主机上的服务和版本信息，从而帮助用户了解网络状况、评估系统安全性。这篇文章将详细介绍Nmap的功能、安装和使用方法。</p>
<h3 id="nmap-de-gong-neng">Nmap的功能</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>主机发现：Nmap能够快速扫描网络，确定哪些主机是活动的，并收集关于它们的信息。</p>
</li>
<li class="lvl-2">
<p>端口扫描：Nmap可以检测目标主机上开放的端口以及运行在这些端口上的服务。</p>
</li>
<li class="lvl-2">
<p>版本检测：通过识别服务的版本信息，Nmap帮助你了解网络中的潜在漏洞和安全风险。</p>
</li>
<li class="lvl-2">
<p>操作系统检测：Nmap可以识别目标系统的操作系统类型和版本，从而为安全审计和维护提供有用的信息。</p>
</li>
<li class="lvl-2">
<p>脚本扫描：Nmap支持使用 Lua 脚本进行自定义扫描，这使得用户可以根据自己的需求编写扫描脚本。</p>
</li>
<li class="lvl-2">
<p>性能监测：Nmap可以帮助评估网络的性能，如带宽和响应时间。</p>
</li>
</ul>
<h3 id="nmap-de-an-zhuang">Nmap的安装</h3>
<p>Nmap可以在多种操作系统上安装。以下是在不同系统上安装Nmap的方法：</p>
<p>Debian/Ubuntu：</p>
<pre><code class="language-shell">    apt-get update
    apt-get install nmap
</code></pre>
<p>Red Hat/CentOS：</p>
<pre><code class="language-shell">    yum install nmap
</code></pre>
<p>macOS（使用Homebrew）：</p>
<pre><code class="language-shell">    brew install nmap
</code></pre>
<p>Windows：</p>
<p>你可以从Nmap官方网站下载适用于Windows的安装包：<a href="https://nmap.org/download.html">https://nmap.org/download.html</a></p>
<h3 id="nmap-ji-ben-shi-yong">Nmap基本使用</h3>
<p>扫描单个IP：</p>
<pre><code class="language-shell">    nmap 192.168.1.1
</code></pre>
<p>扫描IP范围：</p>
<pre><code class="language-shell">    nmap 192.168.1.1-254
</code></pre>
<p>扫描子网：</p>
<pre><code class="language-shell">    nmap 192.168.1.0/24
</code></pre>
<p>扫描指定端口：</p>
<pre><code class="language-shell">    nmap -p 80,443 192.168.1.1
</code></pre>
<p>扫描所有端口：</p>
<pre><code class="language-shell">    nmap -p- 192.168.1.1
</code></pre>
<p>使用SYN扫描：</p>
<pre><code class="language-shell">    nmap -sS 192.168.1.1
</code></pre>
<p>操作系统检测：</p>
<pre><code class="language-shell">    nmap -O 192.168.1.1
</code></pre>
<h3 id="nmap-jin-jie-shi-yong">Nmap进阶使用</h3>
<p>版本检测：</p>
<pre><code class="language-shell">    nmap -sV 192.168.1.1
</code></pre>
<p>脚本扫描：</p>
<pre><code class="language-shell">    nmap --script "banner,ssl-enum-ciphers" -p 80,443 192.168.1.1
</code></pre>
<p>隐蔽扫描：</p>
<pre><code class="language-shell">    nmap -sS -T4 192.168.1.1
</code></pre>
<p>输出结果到文件：</p>
<pre><code class="language-shell">    nmap -oN output.txt 192.168.1.1
</code></pre>
<p>从文件中读取目标：</p>
<pre><code class="language-shell">    nmap -iL target_list.txt
</code></pre>
<p>结合Nping：</p>
<p>Nping 是 Nmap 工具包的一部分，专门用于网络探测和性能测试。</p>
<pre><code class="language-shell">    nping --tcp -p80 192.168.1.1
</code></pre>
<p>定制自己的脚本：</p>
<p>Nmap 支持 Lua 脚本，您可以编写自己的扫描脚本来满足特定的需求。</p>
<h2 id="bat">bat</h2>
<p>在Linux系统中，处理文本数据是常见的任务。尽管传统的文本处理工具如sed和awk在很多场景下都非常实用，但有时它们可能过于复杂。为了解决这个问题，我们需要一个既有功能强大又易于使用的文本处理工具。幸运的是，有一种名为bat的命令行工具，它旨在为Linux用户提供简单、快速且高效的文本处理解决方案。</p>
<h3 id="shi-yao-shi-bat-ming-ling">什么是bat命令？</h3>
<p>bat是一个跨平台的命令行工具，它以cat、sed、awk、grep等传统文本处理工具为基础，进行了优化与改进。它旨在提供更好的用户体验，同时保证高效的性能。bat的目标是成为一个通用的命令行文本处理工具。</p>
<h3 id="bat-de-he-xin-te-xing">bat的核心特性</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>语法高亮：bat能够自动为不同的编程语言和格式进行语法高亮，让代码更易读。</p>
</li>
<li class="lvl-2">
<p>并行处理：bat支持多核心处理，可显著提高文件处理速度。</p>
</li>
<li class="lvl-2">
<p>低内存占用：bat在处理大型文件时占用内存较低，比其他文本处理工具更高效。</p>
</li>
<li class="lvl-2">
<p>跨平台：bat支持Linux、macOS和Windows等多个操作系统。</p>
</li>
<li class="lvl-2">
<p>自动泵：bat无需额外配置即可自动读取和写入压缩文件，如.gz、.bz2等。</p>
</li>
</ul>
<h3 id="ru-he-an-zhuang-bat-ming-ling">如何安装bat命令？</h3>
<p>在大多数Linux发行版中，你可以使用包管理器轻松安装bat。</p>
<p>对于基于Debian的系统（如Ubuntu）：</p>
<pre><code class="language-shell">    apt-get update
    apt-get install bat
</code></pre>
<p>对于基于RPM的系统（如Fedora）：</p>
<pre><code class="language-shell">    dnf install bat
</code></pre>
<p>对于Arch Linux用户：</p>
<pre><code class="language-shell">    pacman -S bat
</code></pre>
<h3 id="shi-yong-bat-ming-ling-jin-xing-wen-ben-chu-li">使用bat命令进行文本处理</h3>
<p>查看文件内容：</p>
<pre><code class="language-shell">    bat &lt;filename&gt;
</code></pre>
<p>语法高亮：</p>
<pre><code class="language-shell">    bat --style=friendly &lt;filename&gt;
</code></pre>
<p>搜索文件内容：</p>
<pre><code class="language-shell">    bat --search="searchterm" &lt;filename&gt;
</code></pre>
<p>并行处理：</p>
<pre><code class="language-shell">    bat --flowlog=/path/to/combined.log &lt;directory&gt;/*.log
</code></pre>
<p>处理压缩文件：</p>
<pre><code class="language-shell">    bat &lt; /path/to/file.gz
</code></pre>
<p>复制文件到剪贴板：</p>
<pre><code class="language-shell">    bat --style=numbers &lt;filename&gt; | xclip -selection clipboard
</code></pre>
<p>分页查看文件：</p>
<pre><code class="language-shell">    bat --pages=to-cn &lt;filename&gt;
</code></pre>
<p>在GUI中查看文件：</p>
<pre><code class="language-shell">    bat -.gui &lt;filename&gt;
</code></pre>
<h3 id="bat-yu-git-de-ji-cheng">bat与git的集成</h3>
<p>除了在命令行中使用bat外，它还可以与git进行集成，这样你可以直接在git仓库中查看文件的语法高亮。要实现这一点，请将下面的内容添加到你的~/.gitconfig文件：</p>
<pre><code class="language-shell">[core]
pager = bat
</code></pre>
<p>现在，当你运行git diff、git show或者git log时，文件内容将通过bat以语法高亮的方式展示出来。</p>
<h3 id="xiao-jie">小结</h3>
<p>bat是一个非常高效且实用的文本处理工具。通过其简单易用的界面和丰富的特性，bat为用户提供了一种全新的处理和管理文本文件的方法。如果你经常需要处理文本数据，不妨试试bat，它可能会成为你的新宠。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下一次性任务(at和batch命令)</title>
    <url>/2015/04/06/linux_at_command/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>我们知道，在Linux中可以使用cron实现周期性任务，但如果我有一个一次性任务，该如何做呢？</p>
<p>也许你会说，可以使用nohup或者tmux里执行类似这样的指令达到预期目的：</p>
<pre><code class="language-shell">sleep 7200; ./do_st.sh
</code></pre>
<p>即根据当前时间，计算一下预期需要等到多久，再执行具体命令。</p>
<p>Hmm，太trick了…</p>
<p>今天介绍另外一种方式，使用<code>at</code>命令。</p>
<h1 id="code-at-code-jie-shao"><code>at</code> 介绍</h1>
<p>在 Linux 中，你可以使用 <code>at</code> 命令来安排一次性的定时任务。<code>at</code> 命令允许你在将来的某个时间点执行一个命令或一组命令。</p>
<h2 id="an-zhuang">安装</h2>
<p>对于基于 <code>Debian</code> 的系统（如 <code>Ubuntu</code>）：</p>
<pre><code class="language-shell">sudo apt-get update
sudo apt-get install at
</code></pre>
<p>对于基于 <code>Red Hat</code> 的系统（如 <code>CentOS</code> 或 <code>Fedora</code>）：</p>
<pre><code class="language-shell">sudo yum install at
···

或者，如果你使用的是 dnf：

```shell
sudo dnf install at
···

## 使用 `at` 命令安排任务

假设你想在 5 分钟后运行以下命令：
       
```shell
echo "Hello, World!" &gt; /tmp/hello.txt
</code></pre>
<p>你可以这样做：</p>
<pre><code class="language-shell">echo "echo 'Hello, World!' &gt; /tmp/hello.txt" | at now + 5 minutes
</code></pre>
<p>这里，<code>echo</code> 命令用于将待执行的命令传递给 <code>at</code>, <code>now + 5 minutes</code> 指定了任务的执行时间。</p>
<h2 id="cha-kan-yi-an-pai-de-ren-wu">查看已安排的任务</h2>
<p>使用 <code>atq</code> 命令查看已安排的任务及其作业号：</p>
<pre><code class="language-shell">atq
</code></pre>
<p>输出可能如下所示：</p>
<pre><code class="language-shell">Job 1 at 2015-04-06 15:00
</code></pre>
<h2 id="qu-xiao-yi-an-pai-de-ren-wu">取消已安排的任务</h2>
<p>如果你想取消一个已安排的任务，可以使用 <code>atrm</code> 命令，后面跟上作业号：</p>
<pre><code class="language-shell">atrm 1
</code></pre>
<p>这里，1 是你想取消的任务的作业号。</p>
<h2 id="shi-yong-code-at-code-de-jiao-hu-mo-shi">使用 <code>at</code> 的交互模式</h2>
<p>我们还可以将 <code>at</code> 命令与 <code>-t</code> 选项一起使用，以指定确切的日期和时间：</p>
<pre><code class="language-shell">at -t 2015-04-06 15:00
</code></pre>
<p>然后，你会进入一个提示符，可以输入要安排的命令。输入完成后，按 <code>Ctrl + D</code> 保存并退出。</p>
<h2 id="shi-yong-batch-ming-ling">使用 batch 命令</h2>
<p><code>batch</code>命令是 <code>at</code> 的一个变体，它会在系统负载较低时运行任务。这可以用于不紧急的任务：</p>
<pre><code class="language-shell">echo "echo 'Hello, World!' &gt; /tmp/hello.txt" | batch
</code></pre>
<p>或者，使用交互模式：</p>
<pre><code class="language-shell">batch
</code></pre>
<p>然后输入命令，完成后按 <code>Ctrl + D</code> 保存并退出。</p>
<h1 id="ying-yong-chang-jing-shi-li">应用场景示例</h1>
<h2 id="shi-yong-at-de-chang-jing-he-shi-li">使用at的场景和示例</h2>
<h3 id="an-pai-yi-ci-xing-ren-wu">安排一次性任务</h3>
<p>你想在明天的某个特定时间运行一个脚本:</p>
<pre><code class="language-shell">at 9:00 PM tomorrow &lt;&lt;END
/path/to/your/script.sh
END
</code></pre>
<h3 id="fa-song-ti-xing-you-jian">发送提醒邮件</h3>
<p>你想要在一周后的今天发送一封提醒邮件给自己:</p>
<pre><code class="language-shell">echo "This is a reminder for the meeting next week." | at now + 1 week
</code></pre>
<h3 id="xi-tong-wei-hu">系统维护</h3>
<p>你需要在夜间执行系统维护任务，比如运行 <code>apt-get update</code> 和 <code>apt-get upgrade</code>。</p>
<pre><code class="language-shell">echo "sudo apt-get update &amp;&amp; sudo apt-get upgrade -y" | at 2:00 AM
</code></pre>
<h3 id="ding-shi-bei-fen">定时备份</h3>
<p>你想要每天凌晨2点自动运行备份脚本:</p>
<pre><code class="language-shell">echo "/path/to/backup.sh" | at 2:00 AM
</code></pre>
<h3 id="ding-shi-guan-ji">定时关机</h3>
<p>你需要在特定时间自动关闭系统:</p>
<pre><code class="language-shell">echo "sudo shutdown -h now" | at 5:00 PM
</code></pre>
<h2 id="shi-yong-batch-de-chang-jing-he-shi-li">使用 batch 的场景和示例</h2>
<h3 id="di-you-xian-ji-shu-ju-chu-li">低优先级数据处理</h3>
<p>你有一项数据处理任务，不需要立即完成，可以在系统负载较低时运行:</p>
<pre><code class="language-shell">echo "/path/to/data_processing.sh" | batch
</code></pre>
<h3 id="ye-jian-yun-xing-de-di-you-xian-ji-ren-wu">夜间运行的低优先级任务</h3>
<p>你想要在夜间系统负载较低时运行一个长时间的计算任务:</p>
<pre><code class="language-shell">echo "/path/to/long_computation.sh" | batch -t 23:00
</code></pre>
<h3 id="xi-tong-qing-li-ren-wu">系统清理任务</h3>
<p>你需要定期清理日志文件和临时文件，这可以在夜间进行，以减少对系统性能的影响:</p>
<pre><code class="language-shell">echo "/path/to/system_cleanup.sh" | batch
</code></pre>
<h3 id="ding-qi-shu-ju-ku-wei-hu">定期数据库维护</h3>
<p>数据库需要定期维护，比如每周日的凌晨1点运行数据库清理脚本:</p>
<pre><code class="language-shell">echo "/path/to/db_maintenance.sh" | batch -t 01:00
</code></pre>
<h3 id="fei-jin-ji-de-wen-jian-chuan-shu">非紧急的文件传输</h3>
<p>你需要在网络负载较低时进行文件传输，比如在夜间:</p>
<pre><code class="language-shell">echo "rsync -avz /source/ /destination/" | batch
</code></pre>
<p><strong>注意</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>at</code> 和 <code>batch</code> 命令通常在后台运行，不会显示命令的输出。如果你想查看输出，可以将输出重定向到文件中，如上例所示。</p>
</li>
<li class="lvl-2">
<p><code>at</code> 和 <code>batch</code> 命令的具体行为可能会因系统和配置的不同而有所差异。在使用这些命令时，你应该检查你的系统文档以了解它们的具体用法和选项。此外，出于安全考虑，确保你了解这些命令的权限和潜在风险。</p>
</li>
</ul>
<h1 id="overall">Overall</h1>
<p>使用 <code>at</code> 命令安排一次性定时任务是一种简单而有效的方法，适用于需要在将来某个时间点执行的任务。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>APP性能数据收集操作指南</title>
    <url>/2015/07/19/app_performance/</url>
    <content><![CDATA[<h1 id="gong-neng-miao-shu">功能描述</h1>
<p>集成monkey功能， android测试工作中常用测试脚本，以及在手工测试app端功能时，自动收集相关数据，并生成HTML报告。</p>
<p><code>需要源码的，请发我163邮箱</code></p>
<p><strong>monkey稳定性测试：</strong></p>
<p>（1）monkey各参数从配置文件中读取，基本涵盖monkey所有参数，可随时调整/修改配置项值；</p>
<p>（2）获取logcat、traces、monkey日志，出现问题时可通知日志进行问题初步分析；</p>
<p>（3）捕获JAVA异常日志，提取异常日志写入error文件，并统计异常日志</p>
<p><strong>performance</strong> <strong>数据收集：</strong></p>
<p>（1）获取终端设备硬件信息（Results Summary）</p>
<p>（2）app平均启动时间</p>
<p>（3）获取cpu、cpu load、memory、flow上下行（WIFI）信息</p>
<p>（4）处理获取数据，写入文本文件，同时入库（SQLIte）</p>
<p>（5）绘曲线图，并生成HTML测试报告</p>
<p><strong>其他脚本：</strong></p>
<p>（1）批量备份/安装/卸载APP；</p>
<p>（2）kill 5037进程</p>
<p>（3）获取全局cpu、mem信息并绘曲线图</p>
<p>（4）获取当前activity</p>
<p>（5）获取安装包名称（package_name）</p>
<p>（6）获取安装包详细信息</p>
<p>（7）截屏，传到本地PC</p>
<p>（8）屏幕操作过程录制（要求sdk version&gt;=19）</p>
<h1 id="shi-xian-fang-fa">实现方法</h1>
<p>1、采用python脚本来驱动测试；</p>
<p>2、调用android SDK adb与monkey命令，进行数据采集和稳定性测试；</p>
<p>3、采集数据写入文件和数据库；</p>
<p>4、附带android其他小脚本，便于测试过程中使用；</p>
<p>5、根据实际情况修改配置文件后进行数据采集，生成静态HTML报告，数据一目了然</p>
<h1 id="mu-lu-jie-gou">目录结构</h1>
<p>代码目录结构：</p>
<img class="shadow" src="/img/in-post/app_performance_code_tree.png" width="400">
<h1 id="xing-neng-shu-ju-shou-ji-shi-yong-zhi-nan">性能数据收集使用指南</h1>
<h2 id="ce-shi-zhun-bei">测试准备</h2>
<h3 id="1-pei-zhi-wen-jian">1、配置文件</h3>
<p>只需保证配置文件内容正确即可。</p>
<p>配置文件存放在src/config/目录下，名称是：config.ini。配置文件各参数介绍，请参考下图：</p>
<img class="shadow" src="/img/in-post/config_ini.png" width="1200">
<h3 id="2-sql-ite-shu-ju-ku-biao-she-ji-shuo-ming">2、SQLIte数据库表设计说明</h3>
<img class="shadow" src="/img/in-post/table_desc.png" width="1200">
<h3 id="3-chuang-jian-biao-sql-yu-ju">3、创建表SQL语句</h3>
<img class="shadow" src="/img/in-post/sqlite_create_tab.png" width="1200">
<h3 id="4-she-ji-de-di-san-fang-mo-kuai">4、涉及的第三方模块</h3>
<table>
<thead>
<tr>
<th>模块名称</th>
<th>安装命令</th>
<th>模块说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>progressbar</td>
<td>pip  install progressbar</td>
<td>进度条</td>
</tr>
<tr>
<td>configobj</td>
<td>pip install configobj</td>
<td>读取配置文件</td>
</tr>
<tr>
<td>matplotlib</td>
<td>pip  install matplotlib</td>
<td>绘图使用</td>
</tr>
<tr>
<td>dateuti</td>
<td>pip install python-dateutil</td>
<td>绘图使用</td>
</tr>
<tr>
<td>numpy</td>
<td>pip  install numpy</td>
<td>绘图使用</td>
</tr>
</tbody>
</table>
<h2 id="xing-neng-shu-ju-shou-ji-dai-ma-zhi-xing">性能数据收集代码执行</h2>
<p>执行src目录下run_performance.py，即可进行性能数据的收集工作，在数据收集期间，请手工进行app端的功能测试，这样的数据采集才具有意义。</p>
<h2 id="monkey-wen-ding-xing-ce-shi">Monkey稳定性测试</h2>
<p>src目录下，执行run_monkey.py，可调用monkey命令进行稳定性测试，产生的日志信息记录在report目录下。</p>
<p><strong>说明：</strong></p>
<p>可在进行monkey稳定性过程中，进行性能数据收集操作，这样采集的数据为monkey稳定性测试期间被测app的性能数据。</p>
<h2 id="ce-shi-bao-gao-cha-kan">测试报告查看</h2>
<p>测试报告在report目录下Performance_Results.html文件，部分截图如下：</p>
<img class="shadow" src="/img/in-post/app_performance_html_view.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
      </categories>
      <tags>
        <tag>performance</tag>
        <tag>Automation</tag>
        <tag>APP</tag>
      </tags>
  </entry>
  <entry>
    <title>Appium+python自动化安装指南</title>
    <url>/2015/07/23/appium_python_automaion_guide/</url>
    <content><![CDATA[<p>说明：</p>
<p>如果作为服务端，请参考软件安装和Python与python开发环境配置章节；</p>
<p>如果仅作为Client，请参考client安装章节。</p>
<h1 id="ruan-jian-an-zhuang">软件安装</h1>
<h2 id="an-zhuang-nodejs">安装Nodejs</h2>
<h3 id="bu-zou-1-xia-zai-bing-an-zhuang-nodejs">步骤1、下载并安装nodejs</h3>
<p>下载nodejs安装包（<a href="http://nodejs.org/download/%EF%BC%89%E5%B9%B6%E8%BF%9B%E8%A1%8C%E5%AE%89%E8%A3%85%EF%BC%8C**%E5%AE%89%E8%A3%85%E7%9A%84%E6%97%B6%E5%80%99%E6%9C%89%E9%80%89%E9%A1%B9%EF%BC%8C%E8%AE%B0%E5%BE%97%E6%8A%8A%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E6%B7%BB%E5%8A%A0%E5%88%B0path%E8%B7%AF%E5%BE%84**%E3%80%82">http://nodejs.org/download/）并进行安装，**安装的时候有选项，记得把环境变量添加到path路径**。</a></p>
<p>下图红框中表示要下载的版本：</p>
<img class="shadow" src="/img/in-post/current_version.png" width="1200">
<h3 id="bu-zou-2-ce-shi-nodejs-an-zhuang-shi-fou-cheng-gong">步骤2、测试nodejs安装是否成功</h3>
<p>在cmd中输入node –v，如果出现如下结果，则表明安装成功</p>
<img class="shadow" src="/img/in-post/node_success.png" width="1200">
<h2 id="strong-an-zhuang-android-de-skd-strong"><strong>安装android的SKD</strong></h2>
<h3 id="bu-zou-1-xia-zai-skd-bao">步骤1、下载SKD包</h3>
<p>安装android的sdk包，(<a href="http://developer.android.com/sdk/index.html">http://developer.android.com/sdk/index.html</a>),运行依赖 sdk中的 'android’工具，并确保你安装了Level17或以上的版本 api。</p>
<h3 id="bu-zou-2-she-zhi-huan-jing-bian-liang">步骤2、设置环境变量</h3>
<p>（1）解压压缩包到某个目录，如<strong>C:\adt-bundle-windows</strong></p>
<p>（2）配置系统环境变量</p>
<p>变量名：<strong>ANDROID_HOME</strong></p>
<p>变量值：<strong>C:\adt-bundle-windows\sdk</strong></p>
<img class="shadow" src="/img/in-post/ad_home.png" width="1200">
<p>（3）添加系统path路径</p>
<p>变量名：<strong>Path</strong></p>
<p>变量值：<strong>%ANDROID_HOME%\tools;%ANDROID_HOME%\platform-tools;</strong></p>
<img class="shadow" src="/img/in-post/plat_path.png" width="1200">
<h3 id="bu-zou-3-sdk-bao-geng-xin">步骤3、SDK包更新</h3>
<p>由于谷歌服务器连接不是很稳定， SDK更新或安装其他工具时候会出现无法连接、连接超时、无法下载等问题，针对这个问题，可通过如下方法进行解决：</p>
<p>（1）启动 Android SDK Manager ，打开主界面，依次选择「Tools」、「Options…」，弹出『Android SDK Manager - Settings』窗口；</p>
<p>（2）在『Android SDK Manager - Settings』窗口中，在「HTTP Proxy Server」和「HTTP Proxy Port」输入框内填入mirrors.neusoft.edu.cn和80，并且选中「Force https://… sources to be fetched using http://…」复选框。</p>
<p>（3）设置完成后单击「Close」按钮，关闭『Android SDK Manager - Settings』窗口返回到主界面；依次选择「Packages」、「Reload」。</p>
<h2 id="jdk-an-zhuang">JDK安装</h2>
<h3 id="bu-zou-1-xia-zai-bing-an-zhuang-jdk">步骤1、下载并安装JDK</h3>
<p>安装oracle的JDK，本文以jdk1.7为示例，下载地址：</p>
<p><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html</a></p>
<h3 id="bu-zou-2-she-zhi-java-home">步骤2、设置JAVA_HOME</h3>
<p>成功下载并安装后，设置环境变量JAVA_HOME：</p>
<p>变量名：<strong>JAVA_HOME</strong></p>
<p>变量值：<strong>C:\Program Files\Java\jdk1.7.0_13</strong></p>
<img class="shadow" src="/img/in-post/java_home.png" width="1200">
<h3 id="bu-zou-3-yan-zheng-jdk-shi-fou-an-zhuang-cheng-gong">步骤3、验证jdk是否安装成功</h3>
<p>在<strong>cmd</strong>中输入<strong>java -version</strong>，如果出现下图结果，表明jdk1.7安装成功。</p>
<img class="shadow" src="/img/in-post/jdk_success.png" width="1200">
<h2 id="strong-an-zhuang-apache-strong-strong-ant-strong"><strong>安装Apache</strong> <strong>Ant</strong></h2>
<h3 id="bu-zou-1-xia-zai-apache-ant">步骤1、下载Apache Ant</h3>
<p>下载地址：<a href="http://ant.apache.org/bindownload.cgi%EF%BC%89">http://ant.apache.org/bindownload.cgi）</a></p>
<p>说明：</p>
<p>​    如果不使用jenkins进行CI操作，则不需要安装它。</p>
<h3 id="bu-zou-2-she-zhi-huan-jing-bian-liang-1">步骤2、设置环境变量</h3>
<p>到C盘，创建apache文件夹，并将下载后的ant解压后，拷贝到此目录下（C:\apache\apache-ant-1.9.4）</p>
<p>然后设置环境变量：</p>
<p>​     变量名： <strong>ANT_HOME</strong></p>
<p>​     变量值： 你刚解压到的路径： <strong>C:\apache\apache-ant-1.9.4</strong></p>
<img class="shadow" src="/img/in-post/ant_home.png" width="1200">
<p>设置Path:</p>
<p>变量名：<strong>Path</strong></p>
<p>变量值：<strong>%ANT_HOME%\bin</strong></p>
<img class="shadow" src="/img/in-post/ant_bin.png" width="1200">
<h3 id="bu-zou-3-ce-shi-ant-huan-jing-an-zhuang-cheng-gong">步骤3、测试ant环境安装成功</h3>
<p>运行cmd，输入ant，如果没有指定build.xml就会输出：</p>
<img class="shadow" src="/img/in-post/ant_success.png" width="1200">
<p>查看ant版本</p>
<img class="shadow" src="/img/in-post/ant_version.png" width="1200">
<p>如上信息表明ant已经成功安装。</p>
<h2 id="strong-a-href-http-xn-49-sq-66-h-net-an-zhuang-net-a-framework-zu-jian-strong"><strong><a href="http://xn--49sq66h.net">安装.net</a> framework组件</strong></h2>
<h3 id="bu-zou-1-a-href-http-xn-ghq-880-n-net-xia-zai-net-a-framework">步骤1、<a href="http://xn--ghq880n.net">下载.net</a> framework</h3>
<p>说明：</p>
<p>如果不安装，在进行下一步安装appium时，会报如下错误信息：</p>
<img class="shadow" src="/img/in-post/start_error_appium.png" width="1200">
<p>由于Microsoft Windows Studio 2008和Windows SDK for Windows Server 2008 and .NET Framework 3.5都比较大，很多东西用不到，以及考虑到后期appium更新后对更高版本的邀请，这里选择安装Microsoft .NET Framework 4.5。</p>
<p>Microsoft .NET Framework 4.5 下载地址：<a href="http://www.microsoft.com/en-us/download/details.aspx?id=30653">http://www.microsoft.com/en-us/download/details.aspx?id=30653</a></p>
<h3 id="bu-zou-2-a-href-http-xn-49-sq-66-h-net-an-zhuang-net-a-framework-4-5">步骤2、<a href="http://xn--49sq66h.NET">安装.NET</a> Framework 4.5</h3>
<p>步骤略。</p>
<h2 id="strong-an-zhuang-appium-strong"><strong>安装appium</strong></h2>
<h3 id="bu-zou-1-an-zhuang-appium">步骤1、安装appium</h3>
<p>使用npm安装appium，在cmd中使用命令<strong>npm install  -g appium</strong> 下载appium（整个过程稍慢，请耐心等待）。</p>
<p><strong>说明：</strong></p>
<p>如果安装过程中报如下错：</p>
<img class="shadow" src="/img/in-post/install_appium_error.png" width="1200">
<p>请到“C:\Users\Administrator\AppData\Roaming”目录下，创建npm目录，然后再运行“npm install -g appium”命令即可。</p>
<h3 id="bu-zou-2-xiao-yan-appium-shi-fou-an-zhuang-cheng-gong">步骤2、校验appium是否安装成功</h3>
<p>安装成功后，在cmd输入<strong>appium</strong>出现以下信息表明安装成功：</p>
<img class="shadow" src="/img/in-post/install_appium_success.png" width="1200">
<h2 id="strong-an-zhuang-wd-strong"><strong>安装wd</strong></h2>
<p>启动cmd，在窗口输入npm install wd命令，继续wd的安装：</p>
<img class="shadow" src="/img/in-post/wd.png" width="1200">
<h1 id="huan-jing-jian-ce">环境检测</h1>
<p>运行cmd， 输入<strong>appium-doctor</strong>检查你的环境是不是都配置好了。 如图：</p>
<img class="shadow" src="/img/in-post/env_check_success.png" width="1200">
<p>整体的环境变量已经配置完毕，接下来要进行 python和selenium的安装、配置。</p>
<h1 id="python-he-selenium-de-an-zhuang-pei-zhi">Python和selenium的安装配置</h1>
<h2 id="an-zhuang-python">安装python</h2>
<h3 id="bu-zou-1-xia-zai-bing-an-zhuang-python-2-7-5">步骤1、下载并安装python2.7.5</h3>
<p>链接地址：<a href="https://www.python.org/download/releases/2.7.5/">https://www.python.org/download/releases/2.7.5/</a></p>
<p><strong>说明</strong>：</p>
<p>本文选择python版本为2.7.5，该版本较其他版本比较稳定。</p>
<h3 id="bu-zou-2-she-zhi-python-huan-jing-bian-liang">步骤2、设置python环境变量</h3>
<p>变量名：<strong>Path</strong></p>
<p>变量值：<strong>C:\Python27</strong></p>
<img class="shadow" src="/img/in-post/python_path.png" width="1200">
<h2 id="strong-an-zhuang-setuptools-strong"><strong>安装setuptools</strong></h2>
<h3 id="bu-zou-1-xia-zai-ez-setup-py">步骤1、下载ez_setup.py</h3>
<p>参考地址如下：</p>
<p><a href="https://pypi.python.org/pypi/setuptools#windows-7-or-graphical-install">https://pypi.python.org/pypi/setuptools#windows-7-or-graphical-install</a></p>
<p>在链接页面中，找到<strong>ez_setup.py</strong>，入下图所示：</p>
<img class="shadow" src="/img/in-post/ez_setup1.png" width="1200">
<p><strong>右击下载<strong><strong>ez_setup.py</strong></strong>文件到本地</strong>：</p>
<img class="shadow" src="/img/in-post/ez_setup2.png" width="1200">
<p><strong>注意：</strong></p>
<p><strong>ez_setup.py文件要存放在不包含中文以及空格目录中！</strong></p>
<h3 id="bu-zou-2-an-zhuang-setuptools">步骤2、安装setuptools</h3>
<p>（1）启动cmd，进入ez_setup.py所在目录</p>
<p>（2）执行python ez_setup.py install进行下载安装setuptools：</p>
<img class="shadow" src="/img/in-post/download_setup.png" width="1200">
<p>然后就会在python的安装目录中生成scripts目录，其中有easy_install.exe</p>
<img class="shadow" src="/img/in-post/easy_install_package.png" width="1200">
<p>步骤3、设置环境变量</p>
<p>将C:\Python27\Scripts 设置到系统环境变量中：</p>
<img class="shadow" src="/img/in-post/python_path.png" width="1200">
<h2 id="strong-an-zhuang-pip-strong"><strong>安装pip</strong></h2>
<p>启动cmd进入命令行，把目录切换到python的安装目录下的Script文件夹下，运行 <strong>easy_inatall pip</strong>命令进行pip在线安装，如下图所示：</p>
<img class="shadow" src="/img/in-post/install_pip.png" width="1200">
<h2 id="strong-an-zhuang-python-yi-lai-bao-strong"><strong>安装python依赖包</strong></h2>
<p>依赖包，如下：</p>
<p>nose</p>
<p>selenium</p>
<p>Appium-Python-Client</p>
<p>启动cmd，分别输入</p>
<p>pip install nose</p>
<p>pip install selenium</p>
<p>pip install Appium-Python-Client</p>
<p>进行安装操作, 如下图所示：</p>
<img class="shadow" src="/img/in-post/appium_client_setup.png" width="1200">
<p>如果系统中已经安装过了，再次进行安装时，会出现类似如下界面所展示的信息：</p>
<img class="shadow" src="/img/in-post/install_nose.png" width="1200">
<p>其他依赖包的安装</p>
<table>
<thead>
<tr>
<th><strong>包名</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>mysqldb</strong></td>
<td>用于Mysql操作使用</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>详见目录; pythond.3rd.lib中可执行文件，双击安装即可。</p>
<h1 id="eclipse-yu-python-kai-fa-huan-jing-pei-zhi">Eclipse与python开发环境配置</h1>
<h2 id="strong-eclipse-xia-zai-yu-an-zhuang-strong"><strong>Eclipse下载与安装</strong></h2>
<h3 id="bu-zou-1-xia-zai-eclipse">步骤1、下载eclipse</h3>
<p>链接地址：</p>
<p><a href="http://www.eclipse.org/downloads/">http://www.eclipse.org/downloads/</a></p>
<h3 id="bu-zou-2-an-zhuang-eclipse">步骤2、安装eclipse</h3>
<p>下载下来是个压缩包，比如：eclipse-standard-luna-R-win32.zip，无需安装，直接解压即可。</p>
<p><strong>注意：</strong></p>
<p><strong>Eclipse解压后所在目录不能含有中文、空格。</strong></p>
<h2 id="strong-pydev-cha-jian-an-zhuang-strong"><strong>Pydev插件安装</strong></h2>
<h3 id="bu-zou-1-da-kai-eclipse-gong-ju">步骤1、打开Eclipse工具</h3>
<h3 id="bu-zou-2-shi-chang-zhong-an-zhuang-pydev">步骤2、市场中安装pydev</h3>
<p><strong>在eclipse</strong>工具，点击Help，选择Eclipse Marketplace，如下图所示：</p>
<img class="shadow" src="/img/in-post/market.png" width="1200">
<p>在弹出界面中Find出，输入pydev，点击GO进行搜索：</p>
<img class="shadow" src="/img/in-post/go.png" width="1200">
<p>说明：</p>
<p>上图表明我已经安装过了，所以是Uninstall状态，未安装状态应该是install。</p>
<p>点击“install“进行pydev插件的安装。</p>
<h3 id="bu-zou-3-pei-zhi-pydev">步骤3、配置pydev</h3>
<p>在Window --&gt; Preferences中，点击”Quick Atuo-Config”，并点击OK即可，如下图所示步骤操作：</p>
<img class="shadow" src="/img/in-post/auto_config.png" width="1200">
<h2 id="strong-jian-li-python-gong-cheng-strong"><strong>建立python工程</strong></h2>
<h3 id="bu-zou-1-chuang-jian-py-dev-project">步骤1、创建PyDev Project</h3>
<p>选择PyDev Project，直接点击Next：</p>
<img class="shadow" src="/img/in-post/project_next.png" width="1200">
<p>命名工程名称（如mpsAutotest），并点击finish，出现提示框后，点击“yes“：</p>
<img class="shadow" src="/img/in-post/next_ok.png" width="1200">
<h3 id="bu-zou-2-zai-gong-cheng-zhong-xin-jian-yi-ge-python-package">步骤2、在工程中新建一个Python Package</h3>
<p>右键点击src, New&gt;Pydev Package，选择源文件路径及输入包名：</p>
<img class="shadow" src="/img/in-post/pvdev_package.png" width="1200">
<h3 id="bu-zou-3-ce-shi-gong-cheng-shi-fou-chuang-jian-zheng-chang">步骤3、测试工程是否创建正常</h3>
<p>在testCase目录下新创建个test.py文件，输入脚本内容：</p>
<pre><code class="language-python">#/usr/bin/env python
#-*- coding:UTF-8 -*-

import os,sys

def nameInfo(name=None):
    return name


if __name__ == "__main__":
    name = nameInfo('Gikoo')
    print name
    print sys.platform
    print os.path.sep
</code></pre>
<p>按F9即可看到输出结果：</p>
<img class="shadow" src="/img/in-post/example.png" width="1200">
<p>如上图所示，说明开发环境安装成功</p>
<h1 id="appium-qi-dong-pian">appium启动篇</h1>
<h2 id="strong-qi-dong-appium-strong"><strong>启动appium</strong></h2>
<h3 id="bu-zou-1-qi-dong-cmd-chuang-kou">步骤1、启动cmd窗口</h3>
<h3 id="bu-zou-2-zhi-xing-appium-a-127-0-0-1-p-4723-ming-ling">步骤2、执行appium -a 127.0.0.1 -p 4723命令</h3>
<p>在cmd中输入 appium -a 127.0.0.1 -p 4723 (-a表示ip，-p表示端口， 可以通过appium -h查看更多命令)，启动appium服务。</p>
<p>如果如下图所示 就表示 appium服务启动成功了：</p>
<img class="shadow" src="/img/in-post/start_appium_success.png" width="1200">
<p><strong>注意：</strong></p>
<p>这个窗口不要关闭 因为这是appium的服务，关了就相当于关了服务，后面过程无法执行，而且这个窗口也是 日志输出的窗口，用于排错。</p>
<h1 id="client-an-zhuang">client安装</h1>
<h2 id="ke-hu-duan-an-zhuang-bu-zou-ru-xia">客户端安装步骤如下：</h2>
<h3 id="an-zhuang-python-bing-she-zhi-python-huan-jing-bian-liang">安装python并设置python环境变量</h3>
<p>详请参考Python和selenium的安装配置章节中安装python与设置环境变量操作</p>
<h3 id="an-zhuang-setuptools">安装setuptools</h3>
<p>详请参考Python和selenium的安装配置章节中安装setuptools操作</p>
<h3 id="an-zhuang-pip-hou">安装pip后</h3>
<p>详请参考Python和selenium的安装配置章节中安装pip操作</p>
<h3 id="an-zhuang-client">安装client</h3>
<p>启动cmd，分别输入</p>
<p>pip install Appium-Python-Client</p>
<p>pip install selenium</p>
<p>安装selenium ide</p>
<p>安装selenium ide，是为了通过ide录制web界面操作，并通过导出转换为需要的语言代码，进而修改以节约web界面用例开发时间。</p>
<h2 id="strong-xia-zai-ide-wen-jian-strong"><strong>下载ide文件</strong></h2>
<p>打开火狐浏览器，输入如下网址</p>
<p><a href="http://release.seleniumhq.org/selenium-ide/2.0.0/selenium-ide-2.0.0.xpi">http://release.seleniumhq.org/selenium-ide/2.0.0/selenium-ide-2.0.0.xpi</a></p>
<h2 id="strong-an-zhuang-xpi-wen-jian-strong"><strong>安装xpi文件</strong></h2>
<p>火狐浏览器会自动下载xpi文件，成功安装后弹出类似如下提示：</p>
<img class="shadow" src="/img/in-post/firefox_noty1.png" width="1200">
<h2 id="strong-zhong-qi-firefox-strong"><strong>重启firefox</strong></h2>
<p>点击“立即安装”即可进行安装操作。</p>
<img class="shadow" src="/img/in-post/after_restart_firefox.png" width="1200">
<p>点击“立即重启”，以加载新安装的ide插件。</p>
<h2 id="strong-que-ren-an-zhuang-shi-fou-cheng-gong-strong"><strong>确认安装是否成功</strong></h2>
<img class="shadow" src="/img/in-post/ide_plug.png" width="1200">
<p>至此，appium iede安装完毕。</p>
<p>其他插件，比如firebug、firepath等，直接将下载的文件拖入firefox进行安装即可。或者直接在组建中搜索，然后点击安装即可。</p>
<h1 id="can-kao-wen-dang">参考文档</h1>
<p>示例参考：<a href="http://testerhome.com/topics/153">http://testerhome.com/topics/153</a></p>
]]></content>
      <categories>
        <category>Automation</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>APP</tag>
        <tag>Appium</tag>
      </tags>
  </entry>
  <entry>
    <title>Fiddler使用总结</title>
    <url>/2015/08/20/fiddler_user_guide/</url>
    <content><![CDATA[<h1 id="fiddler-ming-ling-xing">Fiddler命令行</h1>
<h2 id="kuai-jie-jian">快捷键</h2>
<h3 id="alt-q-kuai-su-jiang-jiao-dian-she-zhi-dao-ming-ling-xing-zhong">Alt+Q 快速将焦点设置到命令行中</h3>
<img class="shadow" src="/img/in-post/fiddler_alter_q.png" width="1200">
<h3 id="ctrl-i-jiang-dang-qian-xuan-zhong-de-session-zhong-de-url-cha-ru-dao-ming-ling-xing-zhong">Ctrl+I 将当前选中的session中的URL插入到命令行中</h3>
<img class="shadow" src="/img/in-post/fiddler_ctrl_i.png" width="1200">
<h3 id="alt-ctrl-f-ji-huo-yi-yun-xing-de-fiddler-chuang-kou">Alt+Ctrl+F 激活已运行的fiddler窗口</h3>
<p>Fiddler处于后台运行中，使用如上键，可最大化fiddler窗口</p>
<h2 id="ming-ling-xing">命令行</h2>
<h3 id="sometext">?sometext</h3>
<p>功能说明：在已有的session中，将URL中包含sometext的session项高亮</p>
<h3 id="gt-size-huo-lt-size">&gt;size 或 &lt;size</h3>
<p>功能说明：在当前session中，高亮选择response的body大小大于或小于size指定的值，单位为byte</p>
<p>示例：</p>
<p>&gt;3000，将response中body值大于1000bytes的sessions高亮</p>
<p>&lt;2K，将response的body值小于2K的sessions高亮</p>
<h3 id="status">=status</h3>
<p>功能说明：在当前所有的sessions中，将result列中等于status值的session项高亮，即将与status值相同的http状态码高亮</p>
<p>示例：</p>
<p>=401，即将http状态码为401的sessions高亮</p>
<h3 id="method">=method</h3>
<p>功能说明：在当前所有的sessions中，将request请求中的http method与命令行中method值相同的session项高亮</p>
<p>示例：</p>
<p>=post，即将method为POST的session项高亮</p>
<h3 id="host">@host</h3>
<p>功能说明：在当前所有的sessions中，将request请求中host项中包含命令行@内容的session项高亮</p>
<p>示例：</p>
<p>@baidu.com，<a href="http://xn--app-xy9du2rl0o.baidu.com">即会将app.baidu.com</a>、<a href="http://www.baidu.xn--combaike-hm3g.baidu.xn--comsessions-e612a">www.baidu.com、baike.baidu.com等sessions</a>项高亮</p>
<h3 id="boldsometext">boldsometext</h3>
<p>功能说明：将新记录的sessions，如果URL中包含sometext内容，就将该sessions的字体加粗。如果要取消加粗，直接输入bold即可。</p>
<p>示例：</p>
<p>bold <a href="http://baidu.com">baidu.com</a>，即将新记录的sessions中URL内容包含有baidu.com的字样的session字体加粗</p>
<h3 id="bpaftersometext">bpaftersometext</h3>
<p>功能说明：在URL中包含sometext内容的sessions的response位置设置断点，即该sessions的After Response位置。使用这个命令后，会将之前设置的策略清楚。取消该拦截项，直接输入bpafter即可.</p>
<p>示例：</p>
<p>bpafter /q，拦截所有URL中包含有/q内容的response返回值</p>
<h3 id="bpssometext">bpssometext</h3>
<p>功能说明：拦截所有状态码与sometext值相同的sessions的Response返回值。使用这个命令后，会将之前设置的策略清除。取消该拦截策略，直接输入bps即可。</p>
<p>示例：</p>
<p>bps 404，将所有返回404请求的response全部拦截</p>
<h3 id="bpvsometext-huo-bpmsometext">bpvsometext 或 bpmsometext</h3>
<p>功能说明：拦截所有发送的http method与sometext内容相同的sessions网络请求。使用这个命令后，会将之前设置的策略清除。取消拦截策略，直接输入bpv或bpm即可。</p>
<p>示例：</p>
<p>bpv POST，会拦截所有以POST方法发送的网络请求。</p>
<h3 id="bpusometext">bpusometext</h3>
<p>功能说明：在URL中包含sometext内容的sessions的Request位置设置断点，即该sessions的before request位置。使用这个命令后，会将之前设置的策略清除。取消该拦截策略，直接输入bpu即可。</p>
<p>示例：</p>
<p>bpu /a.sext，拦截所有URL中包含 /a.sext内容的Request请求。</p>
<h3 id="cls-huo-clear">cls 或clear</h3>
<p>功能说明：清除列表中所有的session，功能与Ctrl+X相同</p>
<p>示例：</p>
<img class="shadow" src="/img/in-post/fiddler_cls.png" width="1200">
<h3 id="dump">dump</h3>
<p>功能说明：将当期获取到的所有的sessions保存成zip文件，并保存到系统我的文档中的\Fiddler2\Captures文件夹中，命名为dump.saz</p>
<h3 id="g-huo-go">g 或 go</h3>
<p>功能说明：回复所有被设置断点的session</p>
<h3 id="help">help</h3>
<p>功能说明：打开QuickExec的帮助页面，该页面详细介绍Fiddler的使用</p>
<h3 id="hid">hid</h3>
<p>功能说明：将Fiddler隐藏到系统状态栏中</p>
<h3 id="urlreplace">urlreplace</h3>
<p>功能说明：自动将任意URL中的内容sometext1替换成sometext2.使用这个命令后，会清除之前设置的策略。取消该拦截策略，直接输入urlreplace即可。</p>
<p>示例：</p>
<p>urlreplacebaidugoogle，即如果发生的网络请求为<a href="http://www.baidu.com">www.baidu.com</a>，通过该策略会自动更改为<a href="http://www.gogle.cn">www.gogle.cn</a>，并发送出去。</p>
<h3 id="start">start</h3>
<p>功能说明：将Fiddler设置为系统代理</p>
<h3 id="stop">stop</h3>
<p>功能说明：取消Fiddler为系统代理</p>
<h3 id="show">show</h3>
<p>功能说明：可以将已被隐藏的Fiddler置前。执行该命令需要使用到ExecAction.exe这个程序，该程序的位置为Fiddler的安装目录</p>
<p>示例：</p>
<p>ExecAction.exe show</p>
<h3 id="selectsometext">selectsometext</h3>
<p>功能说明：在当前所有sessions中，将header的Contetnt-Type字段包含sometext内容的sessions高亮、可用于选择文件格式等。</p>
<p>示例：</p>
<p>slectcss，即将所有网络请求中Content-Type字段包含css的sessions高亮</p>
<h3 id="select-header-or-flagsometext">selectHeaderOrFlagsometext</h3>
<p>功能说明：高亮SessionFlag或header中包含指定sometext内容的session</p>
<p>示例：</p>
<p>例1、select text abc，即在名为text的SessionFlag中，高亮内容为abc的session</p>
<p>例2、select @Response.Set-Cookie <a href="http://baidu.com">baidu.com</a>，即在所有session的Response中，查找name为Set-Cookie值为baidu.com的Session，并高亮</p>
<p>例3、select @Request.X-Requested-With XMLHttpRequest中，即在所有的session的Request中，查找name为.X-Requested-With值为XMLHttpRequest的Session，并高亮</p>
<p>例4、select @Request.X-Requested-With *，即在所有session的Request中，查找name为X-Requested-With且值为任意值的session，并高亮。</p>
<h3 id="allbutsometext-huo-keeponlysometext">allbutsometext或 keeponlysometext</h3>
<p>功能说明：隐藏所有除Content-Type内容包含sometext的session</p>
<p>示例：</p>
<p>allbut xml，隐藏所有Content-Type为非xml的session，即只展示Content-Type为xml的session，其他session被隐藏</p>
<h3 id="quit">quit</h3>
<p>功能说明：关闭Fiddler</p>
<h3 id="dnssometext-huo-nsloolupsometext">!dnssometext 或 !nsloolupsometext</h3>
<p>功能说明：进行目录域名为sometext的DNS查找，并在LOG选项卡上将结果输出</p>
<p>示例：</p>
<p>!<a href="http://dnswww.baidu.com">dnswww.baidu.com</a>，即将www.baidu.com对应的IP地址解析并输出</p>
<h3 id="listen-port-certhostname">!listen PORT [CERTHOSTNAME]</h3>
<p>功能说明：在另外一个端口增设一个监听器，可选安全的HTTPS证</p>
<p>示例：</p>
<p>!listen 8080，即可以同时截获通过8080端口的网络请求。</p>
<h1 id="fiddler-shi-jian">Fiddler实践</h1>
<h2 id="wen-ti-1-jie-mian-zeng-jia-ip-di-zhi">问题1、界面增加IP地址</h2>
<p>测试过程中发现访问的数据不正确，怀疑是修改的host没有生效导致的。但无法查看手机端访问该数据页面的IP，所以一直无法确认该问题</p>
<ol>
<li class="lvl-3">
<p>运行fiddler，菜单，Rules-&gt;Customize Rules…或者点击右侧tab</p>
</li>
</ol>
<p>“FiddlerScript”</p>
<ol start="2">
<li class="lvl-3">
<p>Ctrl+F查找“static function Main()”字符串，然后添加下面这行代码：</p>
</li>
</ol>
<p>FiddlerObject.UI.lvSessions.AddBoundColumn(“ServerIP”, 120, “X-HostIP”);</p>
<ol start="3">
<li class="lvl-3">
<p>保存CustomRules.js或者点击“Save Script”按钮，如下所示：</p>
</li>
</ol>
<pre><code class="language-shell">static function Main() {

var today: Date = new Date();

FiddlerObject.StatusText = " CustomRules.js was loaded at: " + today;

FiddlerObject.UI.lvSessions.AddBoundColumn("ServerIP", 120, "X-HostIP");
</code></pre>
<ol start="4">
<li class="lvl-3">
<p>查看fiddler，此时IP会添加到所有数据的最后一列，拖到滚动条，即可看到，如下所示：</p>
</li>
</ol>
<img class="shadow" src="/img/in-post/fiddler_ip.png" width="1200">
<h2 id="wen-ti-2-xiu-gai-duan-kou">问题2、修改端口</h2>
<p>测试过程中，手机借来借去是常有的事，也行你刚在一台手机上将自己的IP添加上，过一会这台手机就被某某某拿走了，不一会儿，你的Fiddler上面多了很多会话，不巧其中有个URL的参数id为空。Bug？！然而，重复操作N遍都没法重现。仔细查看请求后发现不是自己使用的手机。如何摆脱曾经的小尾巴，请看下文</p>
<p>在Toolsà Fiddler options --&gt; Connections，如下图所示：</p>
<img class="shadow" src="/img/in-post/fiddler_options.png" width="1200">
<p>Fiddler默认端口号是8888，为了避免这种情况对自己的干扰，在找不到北某某某的拿走的手机时，可以将这个端口修改为其他的，例如：8889，重启Fiddler，再在自己使用的手机上做相应的修改即可。</p>
<h2 id="wen-ti-3-fiddler-de-guo-lu-gong-neng">问题3、Fiddler的过滤功能</h2>
<p>在PC上打开Fiddler用于查看手机端的请求，但总是被PC上来来往往的请求所干扰。如何只查看android上的请求，而不被干扰呢？</p>
<p>Fiddler有强大的filter，通过filter能够只查看自己关注的请求。但是呢，有一些去服务器下载的请求，由于服务器有好多，添加过滤器有可能过滤掉本来想看的内容，例如：某个banner展示成功的前提是：图片资源下载成功。当我们在测试过程中看到banner图显示不出来，到底是banner图的功能有问题呢？还是服务器的问题呢？因此，作为一名认真、负责任的测试同学，我们想要准确定位bug的原因，就需要关注这个过程中发生了什么，而不能简单的跟开发同学说:banner图显示不出来了。</p>
<p>So，这种过滤如何实现呢？正确的处理方式是：</p>
<p>点击Fiddler左下角的Capturing，可以控制是否把Fiddler注册为PC代理，当左下角出现”Capturing”时，Capture Traffic是打开的，此时的IE的Internet选项连接局域网（LAN）设置中的代理服务器是勾选的；否则不勾选，如下图所示：</p>
<img class="shadow" src="/img/in-post/fiddler_internet_set.png" width="1200">
<h2 id="wen-ti-4-sheng-xiao-xiu-gai-de-hosts-wen-jian">问题4、生效修改的hosts文件</h2>
<p>测试过程中需要访问测试服务器，打开Fiddler，在PC的etc目录下修改了hosts文件却不能不生效，为什么呢？</p>
<p>当Fiddler已经建立会话时，任何修改hosts的行为都不会被Fiddler注意到。可以通过Fiddler的Tools à HOSTS 导入本地的hosts文件。需要指定测试服务器的时候，勾选“Enable remapping of request for one host to a different host or IP, overredding DNS”，否则去掉勾选。</p>
<h2 id="wen-ti-5-ce-shi-guo-cheng-zhong-ru-he-mo-ni-duo-yong-hu-wang-luo-chang-jing">问题5、测试过程中如何模拟多用户网络场景</h2>
<p>这里介绍下模拟低速网络情况。</p>
<p>Fiddler是一个代理，它提供了客户端请求和服务器响应前的回调接口，我们可以在这些接口里自定义一些逻辑。Fiddler的模拟限速就是在客户端请求前来定义限速的逻辑，此逻辑是通过延迟发送数据或接收的数据的时间来限制网络的下载速度和上传速度，从而达到限速的效果。</p>
<p>Fiddler提供了一个功能，可以方便的模拟低速网络环境。方法：Rules à Performances à Simulate Modem Speeds，如图所示：</p>
<img class="shadow" src="/img/in-post/fiddler_rule.png" width="1200">
<p>也可自定义低速网络：</p>
<p>（1）打开Fiddler，Rules --&gt; Customize Rules…，或者在Fiddler中使用Ctrl+R快捷键</p>
<p>（2）搜索关键字“m_SimulateModem”</p>
<p>（3）然后根据自己需要，修改上传与下载速度</p>
<img class="shadow" src="/img/in-post/fiddler_speed.png" width="1200">
<p>说明如下：</p>
<p>oSession[“request-trickle-delay”] = “300”;</p>
<p>#每上传1K，延迟300ms</p>
<p>oSession[“response-trickle-delay”] = “150”;</p>
<p>#没下载1K，延迟150ms</p>
<p>（4）保存修改后，勾选之前的 Simulate Modem Speed 选项。</p>
<h2 id="wen-ti-6-fiddler-bao-cun-hui-hua-de-response-nei-rong-wei-luan-ma">问题6、Fiddler保存会话的response内容为乱码</h2>
<p>右键点击会话选择“save à Response à Response Body”，保存的文件打开后里面出现乱码。</p>
<p>这是因为Fiddler为了提高性能，将会话的response压缩后进行了传输，查看Transformer的选项卡，如下图所示：</p>
<img class="shadow" src="/img/in-post/fiddler_transfer.png" width="1200">
<p>是否可看到GZIP Encoding处于选中状态？想要正常查看被压缩的数据，需要选择成No Compression，但是出现乱码的情况下，该处是不能点击的，如何解决呢？</p>
<p>方法1:</p>
<p>如果想在会话处理过程中进行Decode，点击Fiddler界面上Decode 按钮，如下图所示：</p>
<img class="shadow" src="/img/in-post/fiddler_decode.png" width="1200">
<p>则会对所有的会话进行decode，这样保存的response就能正常显示了，需要注意：点击“Decode”之后，需要重启Fiddler才能生效。</p>
<p>方法2</p>
<p>如果想对所有会话处理之后再进行No Compression（解压缩），可以选择多个会话，右键选择“Decode Selected Sessions”，另外，在会话的response区域看到的却是乱码，上面有黄条提示“Response is encoded and require decoding before inspection.Click here to transform”,杜继英的Transform勾选情况如下图所示：</p>
<img class="shadow" src="/img/in-post/fiddler_garbled.png" width="1200">
<p>处理方法：这种情况下，只要按照提示，点击黄条即可对当前的会话进行decode，但是这样处理只针对当前的会话，是一次性的效果，如果不担心传输性能的话，可以直接使用方法1。</p>
<h2 id="wen-ti-7-mo-ni-http-qing-qiu">问题7、模拟http请求</h2>
<h2 id="mo-ni-http-post-qing-qiu">模拟http POST请求</h2>
<p>对于post请求，需要输入Reuqest Body。而Request Body 默认情况是隐藏起来的。按下面步骤点击显示出Reuqest Body。</p>
<p>1、点击Options</p>
<img class="shadow" src="/img/in-post/fiddler_composer.png" width="1200">
<p>2、点击Tear off，如下图</p>
<img class="shadow" src="/img/in-post/fiddler_tearoff.png" width="1200">
<p>点击执行，就可以模拟post请求了。</p>
<p>上图中的消息头，可从别的地方拷贝过来，如下图所示：</p>
<img class="shadow" src="/img/in-post/fiddler_inspectors.png" width="1200">
<h2 id="mo-ni-http-get-cao-zuo">模拟http get操作</h2>
<p>下拉框中选择GET，输入请求的地址，输入Request Headers。Request Headers是键值对的格式，用：隔开。点击执行。</p>
<img class="shadow" src="/img/in-post/fiddler_composer2.png" width="1200">
<p>查看get操作获取到的结果：</p>
<img class="shadow" src="/img/in-post/fiddler_get_result.png" width="1200">
]]></content>
      <categories>
        <category>Fiddler</category>
      </categories>
      <tags>
        <tag>Fiddler</tag>
      </tags>
  </entry>
  <entry>
    <title>Monkey Tool 介绍</title>
    <url>/2015/08/21/introducing_monkey_tool_for_app/</url>
    <content><![CDATA[<h1 id="monkey-shi-shi-yao">Monkey 是什么？</h1>
<pre><code class="language-shell">Monkey 就是SDK中附带的一个工具。
</code></pre>
<h1 id="monkey-ce-shi-de-mu-de">Monkey 测试的目的？</h1>
<p>该工具用于进行压力测试。 然后开发人员结合monkey 打印的日志 和系统打印的日志，结局测试中出现的问题。</p>
<h1 id="monkey-ce-shi-de-te-dian">Monkey 测试的特点？</h1>
<pre><code class="language-shell">Monkey 测试,所有的事件都是随机产生的，不带任何人的主观性。
</code></pre>
<h1 id="monkey-ming-ling-xiang-jie">Monkey 命令详解</h1>
<h2 id="biao-zhun-de-monkey-ming-ling">标准的monkey 命令</h2>
<pre><code class="language-shell">[adb shell] monkey [options] &lt;eventcount&gt; 
</code></pre>
<p>例如：</p>
<pre><code class="language-shell">adb shell monkey -v 500    --------产生500次随机事件，作用在系统中所有activity（其实也不是所有的activity，而是包含  Intent.CATEGORY_LAUNCHER 或Intent.CATEGORY_MONKEY 的activity）。
</code></pre>
<p>上面只是一个简单的例子，实际情况中通常会有很多的options 选项。</p>
<h2 id="si-da-lei-chang-yong-xuan-xiang-shi-jian-xuan-xiang-yue-shu-xuan-xiang-diao-shi-xuan-xiang">四大类—— 常用选项 、 事件选项 、 约束选项 、 调试选项</h2>
<h3 id="chang-yong-xuan-xiang">常用选项</h3>
<p>–help：打印帮助信息<br>
-v：指定打印信息的详细级别，一个 -v增加一个级别 ， 默认级别为 0 。</p>
<h3 id="shi-jian-xuan-xiang">事件选项</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>-s：指定产生随机事件种子值，相同的种子值产生相同的事件序列。如： -s 200</p>
</li>
<li class="lvl-2">
<p>–throttle：每个事件结束后的间隔时间——降低系统的压力（如不指定，系统会尽快的发送事件序列）。如：–throttle 100</p>
</li>
<li class="lvl-2">
<p>–pct-touch：指定触摸事件的百分比，如：–pct-touch 5% ， 相关的还有以下option：</p>
<ul class="lvl-2">
<li class="lvl-5">
<p>–pct-motion <percent> （滑动事件）</percent></p>
</li>
<li class="lvl-4">
<p>–pct-trackball <percent> （轨迹球事件）</percent></p>
</li>
<li class="lvl-4">
<p>–pct-nav <percent> （导航事件 up/down/left/right）</percent></p>
</li>
<li class="lvl-4">
<p>–pct-majornav <percent> (主要导航事件 back key 、 menu key)</percent></p>
</li>
<li class="lvl-4">
<p>–pct-syskeys <percent> (系统按键事件 Home 、Back 、startCall 、 endCall、 volumeControl)</percent></p>
</li>
<li class="lvl-4">
<p>–pct-appswitch <percent> （activity之间的切换）</percent></p>
</li>
<li class="lvl-4">
<p>–pct-anyevent <percent>（任意事件）</percent></p>
</li>
</ul>
</li>
</ul>
<h3 id="yue-shu-xuan-xiang">约束选项</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>-p：指定有效的package（如不指定，则对系统中所有package有效），一个-p 对应一个有效package， 如：-p com.ckt -p com.ckt.asura</p>
</li>
<li class="lvl-2">
<p>-c：activity必须至少包含一个指定的category，才能被启动，否则启动不了</p>
</li>
</ul>
<h3 id="diao-shi-xuan-xiang">调试选项</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>–dbg-no-events：初始化启动的activity，但是不产生任何事件</p>
</li>
<li class="lvl-2">
<p>–hprof：指定该项后在事件序列发送前后会立即生成分析报告  —— 一般建议指定该项</p>
</li>
<li class="lvl-2">
<p>–ignore-crashes：忽略崩溃</p>
</li>
<li class="lvl-2">
<p>–ignore-timeouts：忽略超时</p>
</li>
<li class="lvl-2">
<p>–ignore-security-exceptions：忽略安全异常</p>
</li>
<li class="lvl-2">
<p>–kill-process-after-error：发生错误后直接杀掉进程</p>
</li>
<li class="lvl-2">
<p>–monitor-native-crashes：跟踪本地方法的崩溃问题</p>
</li>
<li class="lvl-2">
<p>–wait-dbg：知道连接了调试器才执行monkey测试。</p>
</li>
</ul>
<h1 id="yi-ge-jian-dan-de-monkey-ming-ling">一个简单的monkey命令</h1>
<pre><code class="language-shell">adb shell monkey -p com.xy.android.junit -s 500 -v 10000
</code></pre>
<p>但是，工作中为了保证测试数量的完整进行，我们一般不会在发生错误时立刻退出压力测试。</p>
<p>monkey 测试命令如下：</p>
<pre><code class="language-shell">adb shell monkey -p com.xy.android.junit -s 500 --ignore-crashes --ignore-timeouts --monitor-native-crashes -v -v 10000 &gt; E:\monkey_log\java_monkey_log.txt
</code></pre>
<h1 id="monkey-zuo-yong-de-bao-com-ckt-android-junit">monkey作用的包：com.ckt.android.junit</h1>
<p>产生时间序列的种子值：500</p>
<p>忽略程序崩溃 、 忽略超时 、 监视本地程序崩溃 、 详细信息级别为2 ， 产生 10000个事件 。</p>
]]></content>
      <categories>
        <category>Monkey</category>
      </categories>
      <tags>
        <tag>Monkey</tag>
      </tags>
  </entry>
  <entry>
    <title>Monkey详解</title>
    <url>/2015/08/21/app_mokey_help_details/</url>
    <content><![CDATA[<h1 id="monkey-shi-shi-yao">Monkey 是什么？</h1>
<p>Monkey 就是SDK中附带的一个工具。</p>
<h1 id="monkey-ce-shi-de-mu-de">Monkey 测试的目的？</h1>
<p>该工具用于进行压力测试。 然后开发人员结合monkey 打印的日志 和系统打印的日志，结局测试中出现的问题。</p>
<h1 id="monkey-ce-shi-de-te-dian">Monkey 测试的特点？</h1>
<p>Monkey 测试,所有的事件都是随机产生的，不带任何人的主观性。</p>
<h1 id="monkey-ming-ling-xiang-jie">Monkey 命令详解</h1>
<h2 id="biao-zhun-de-monkey-ming-ling">标准的monkey 命令</h2>
<p><code>[adb shell] monkey [options] &lt;eventcount&gt; </code></p>
<p>例如：</p>
<p><code>adb shell monkey -v 500 </code></p>
<p>产生500次随机事件，作用在系统中所有activity（其实也不是所有的activity，而是包含  Intent.CATEGORY_LAUNCHER 或Intent.CATEGORY_MONKEY 的activity）。上面只是一个简单的例子，实际情况中通常会有很多的options 选项</p>
<h2 id="si-da-lei-chang-yong-xuan-xiang-shi-jian-xuan-xiang-yue-shu-xuan-xiang-diao-shi-xuan-xiang">四大类 – 常用选项 、 事件选项 、 约束选项 、 调试选项</h2>
<h3 id="chang-yong-xuan-xiang">常用选项</h3>
<p>–help：打印帮助信息</p>
<p>-v：指定打印信息的详细级别，一个 -v增加一个级别 ， 默认级别为 0 。</p>
<h3 id="shi-jian-xuan-xiang">事件选项</h3>
<p>-s：指定产生随机事件种子值，相同的种子值产生相同的事件序列。如： -s 200</p>
<p>–throttle：每个事件结束后的间隔时间——降低系统的压力（如不指定，系统会尽快的发送事件序列）。如：–throttle 100</p>
<p>–pct-touch：指定触摸事件的百分比，如：–pct-touch 5% ， 相关的还有以下option：</p>
<p>–pct-motion <percent> （滑动事件）、 --pct-trackball <percent> （轨迹球事件） 、 --pct-nav <percent> （导航事件 up/down/left/right）、 --pct-majornav <percent> (主要导航事件 back key 、 menu key)、 --pct-syskeys <percent> (系统按键事件 Home 、Back 、startCall 、 endCall 、 volumeControl)、 --pct-appswitch <percent> （activity之间的切换）、 --pct-anyevent <percent>（任意事件）</percent></percent></percent></percent></percent></percent></percent></p>
<h3 id="yue-shu-xuan-xiang">约束选项</h3>
<p>-p：指定有效的package（如不指定，则对系统中所有package有效），一个-p 对应一个有效package， 如：-p com.ckt -p com.ckt.asura；</p>
<p>-c：activity必须至少包含一个指定的category，才能被启动，否则启动不了；</p>
<h3 id="diao-shi-xuan-xiang">调试选项</h3>
<p>–dbg-no-events：初始化启动的activity，但是不产生任何事件。</p>
<p>–hprof：指定该项后在事件序列发送前后会立即生成分析报告  —— 一般建议指定该项。</p>
<p>–ignore-crashes：忽略崩溃</p>
<p>–ignore-timeouts：忽略超时</p>
<p>–ignore-security-exceptions：忽略安全异常</p>
<p>–kill-process-after-error：发生错误后直接杀掉进程</p>
<p>–monitor-native-crashes：跟踪本地方法的崩溃问题</p>
<p>–wait-dbg：知道连接了调试器才执行monkey测试。</p>
<h1 id="yi-ge-jian-dan-de-monkey-ming-ling">一个简单的monkey命令：</h1>
<p><code>adb shell monkey -p com.xy.android.junit -s 500 -v 10000 </code></p>
<p>但是，工作中为了保证测试数量的完整进行，我们一般不会在发生错误时立刻退出压力测试。</p>
<p>monkey 测试命令如下：</p>
<p><code>adb shell monkey -p com.xy.android.junit -s 500 --ignore-crashes --ignore-timeouts --monitor-native-crashes -v -v 10000 &gt; E:\monkey_log\java_monkey_log.txt</code></p>
<h1 id="monkey-zuo-yong-de-bao-com-ckt-android-junit">monkey作用的包：com.ckt.android.junit</h1>
<p>产生时间序列的种子值：500<br>
忽略程序崩溃 、 忽略超时 、 监视本地程序崩溃 、 详细信息级别为2 ， 产生 10000个事件 。</p>
]]></content>
      <categories>
        <category>Monkey</category>
      </categories>
      <tags>
        <tag>Monkey</tag>
      </tags>
  </entry>
  <entry>
    <title>Netconsole ：输出kernel log到远端机器</title>
    <url>/2015/09/10/config_netconsole/</url>
    <content><![CDATA[<h1 id="wei-shi-yao-xu-yao-netconsole">为什么需要netconsole</h1>
<p>很多时候，很难抓到kernel panic，因为不知道如何复现。 更惨的是，一旦系统重启，系统的log中因为内核异常可能没有记录下有用的信息。这时候netconsole就可以跳出来帮忙了。</p>
<p>比如出现CPU soft lockup的问题，重启之后，从kernel.log中并未找到明显的线索，使用netconsole，让kernel log输出到另一台机器上，这样的话，如果本地不能写磁盘文件，kernel的printk还可以通过网络，将打印的内容记录在另一台机器上。</p>
<p>netconsole是一个内核模块，我们存储的内核将netconsole以module的形式编进了内核，允许将其作为模块加</p>
<p><code>root@node-191:~# grep NETCONSOLE /boot/config-3.14.35-server CONFIGNETCONSOLE=m CONFIGNETCONSOLE_DYNAMIC=y </code></p>
<p>Ubuntu的wiki给出了一个很好的页面，介绍netconsole介绍的很详细：<code>https://wiki.ubuntu.com/Kernel/Netconsole </code></p>
<h1 id="linux-server-duan-yun-xing-shi-pei-zhi">Linux server端运行时配置</h1>
<p>Netconsole can be loaded as one of?kernel modules? manually after boot or auto during boot depending on this module config. See?kernel modules?for configuring it to load at boot. For loading manually any time after boot:</p>
<pre><code class="language-shell"># set log level for kernel messages
dmesg -n 7
modprobe configfs
modprobe netconsole
mount none -t configfs /sys/kernel/config
# 'netconsole' dir is auto created if the module is loaded 
mkdir /sys/kernel/config/netconsole/target1
cd /sys/kernel/config/netconsole/target1
# set local IP address
echo 192.168.0.111 &gt; local_ip
# set destination IP address
echo 192.168.0.17 &gt; remote_ip
# find destination MAC address
arping `cat remote_ip` -f |grep -o ..:..:..:..:..:.. &gt; remote_mac
echo 1 &gt; enabled

</code></pre>
<h1 id="to-verify">To verify</h1>
<p>netconsole should now be configured. To verify, run <code>dmesg |tail</code> and you should see “netconsole: network logging started”. Check available log levels by running <code>dmesg -h</code>.</p>
<h1 id="jie-shou-duan-pei-zhi-ke-yi-xuan-ze-yi-tai-xu-ni-ji">接收端配置（可以选择一台虚拟机）</h1>
<pre><code class="language-shell">nc -u -l 6666
or
nc -u -l -p 6666
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>说明：</p>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">Ubuntu 14.4按照上面的设置无效, 具体设置，参考：<br>
<code>http://blog.51cto.com/7938217/1662524 </code></li>
</ul>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">shell脚本运行在被测试节点，kern log信息会被sync到有设置conf的节点（该节点重启rsyslog服务）</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>netconsole</tag>
      </tags>
  </entry>
  <entry>
    <title>使用shell实现节点间ssh互信</title>
    <url>/2015/09/22/shell_implements_ssh_key_mutual_trust_between_hosts/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>说假设有一个100台节点的Hadoop集群，要配置节点之间的SSH免密码登录，该如何用shell脚本实现？</p>
<h1 id="shi-xian-guo-cheng">实现过程</h1>
<h2 id="fang-an-1-jiao-ben-shi-xian">方案1：脚本实现</h2>
<pre><code class="language-shell">#!/bin/expect
#循环100台机器的IP地址，生成密钥文件authorized_keys

for ip in {cat ip.list}
do
  ssh user@$ip ssh-keygen -t rsa  &amp;&gt;/dev/null
  expect{
        "yes/no" { send "yes\r";exp_continue}
        "password:"{send "$passwd\r";exp_continue}
       }

  cat ~/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keys &amp;&gt; /dev/null  
  exit

  if [ !-f ~/.ssh/authorized_keys ];&lt;br&gt;   then
    touch ~/.ssh/authorized_keys&lt;br&gt;   fi
  ssh user@$ip cat ~/.ssh/authorized_keys &gt;&gt; ~/.ssh/authorized_keys  &amp;&gt; /dev/null
  expect{
        "yes/no" { send "yes\r";exp_continue}
        "password:"{send "$passwd\r";exp_continue}
       }  
done

 
#scp authorized_keys 文件到各台机器上面。
for ip in {cat ip.list}
do
  scp ~/.ssh/authorized_keys user@$ip:~/.ssh/ 
  expect{
        "yes/no" { send "yes\r";exp_continue}
        "password:"{send "$passwd\r";exp_continue}
       }  
done
</code></pre>
<h2 id="fang-an-2-suo-you-node-shi-yong-xiang-tong-key">方案2：所有node使用相同key</h2>
<p>将第一个node上生成的dsa public key（一般是/root/.ssh/id_dsa.pub），scp到其他节点的/root/.ssh/目录下，即所有节点的dsa public key都一样，自然就实现ssh的互信了。</p>
<p>这里介绍个快速传递ssh key的命令，ssh-copy-id ：</p>
<p>ssh-copy-id 将本机的公钥复制到远程机器的authorized_keys文件中，ssh-copy-id也能让你到远程机器的home, ~./ssh , 和 ~/.ssh/authorized_keys的权利。</p>
<p>语法格式如下：</p>
<pre><code class="language-shell"> ssh-copy-id 将key写到远程机器的 ~/ .ssh/authorized_key.文件中 
</code></pre>
<p>示例：</p>
<pre><code class="language-shell"> ssh-copy-id -i .ssh/id_rsa.pub 用户名字@192.168.x.xxx
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>检查URL是否可达</title>
    <url>/2015/11/29/checking_if_the_url_is_reachable/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天查看某公众号发现一篇shell脚本，用来侦测网络URl是否可达，直接抄袭过来备用。</p>
<h1 id="dai-ma">代码</h1>
<pre><code class="language-shell">#!/usr/bin/env bash 

# Description: Web check with curl

#定义颜色
red='\e[0;31m'
RED='\e[1;31m'
green='\e[0;32m'
GREEN='\e[1;32m'
blue='\e[0;34m'
BLUE='\e[1;34m'
cyan='\e[0;36m'
CYAN='\e[1;36m'
NC='\e[0m'

date=`date +%Y-%m-%d' '%H:%M:%S` 

# 定义User Agent
ua="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.9 Safari/537.36"
pass_count=0
fail_count=0

# 需要检测的url
urls=(
    "http://www.bing.com"
)

function request(){
    status=$(curl -sk -o /dev/null --retry 1 --connect-timeout 1 -w '%{http_code}' --user-agent "$ua" $1)
    if [ $status -eq '200' -o $status -eq '301' \
                           -o $status -eq '302' ]; then
        echo -e "[${GREEN} Passed ${NC}] =&gt; $1"
  ((pass_count ++))
    else
        echo -e "[${RED} Failed ${NC}] =&gt; $1"
  ((fail_count ++))
    fi
}

function main(){
    echo "Start checking ..."
    for((i=0;i&lt;${#urls[*]};i++)) 
        do 
        request ${urls[i]};
        done
    # 输出检测通过和失败的记录
    echo -e "======================== Summary ======================== "
    echo -e "Total: ${cyan} $((pass_count + fail_count))${NC}  Passed: ${green}${pass_count}${NC}  Failed: ${red}${fail_count}${NC} Time: $date"
       
}

main $*
</code></pre>
<p>测试效果：</p>
<pre><code class="language-shell">[ wyz@node2 ~]$ bash check_url.sh 
Start checking ...
[ Passed ] =&gt; http://www.bing.com
======================== Summary ======================== 
Total:  1  Passed: 1  Failed: 0 Time: 2023-11-29 18:11:57
[ wyz@node2 ~]$ 
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>查看dd进度</title>
    <url>/2016/03/09/view_dd_progress/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>dd是一个神奇的命令，可以将硬盘驱动器复制到另一个硬盘驱动器，完全归零硬盘驱动器等。但是，一旦启动 dd 命令，就没法显示它的进度，只是坐在光标处，直到命令最终完成。那么如何监控dd的进展呢？本文以ubuntu环境为例进行阐述。</p>
<h1 id="cha-kan-dd-jin-du">查看dd进度</h1>
<p>新status选项添加到dd（GNU Coreutils 8.24+）<br>
dd在GNU Coreutils 8.24+（Ubuntu 16.04及更高版本）中，有一个新status选项可以显示进度：</p>
<p>示例：</p>
<p><code>dd if=/dev/urandom of=/dev/null status=progress </code></p>
<p>输出信息：</p>
<pre><code class="language-shell">462858752 bytes (463 MB, 441 MiB) copied, 38 s, 12,2 MB/s
</code></pre>
<h1 id="shi-yong-kill-huo-qu-jin-du">使用kill获取进度</h1>
<p><code>dd if=/dev/zero of=/tmp/zero.img bs=10M count=100000 </code></p>
<p>想要查看上面的dd命令的执行进度，可以使用下面几种方法：</p>
<p>比如：每5秒输出dd的进度</p>
<p>方法一：</p>
<p><code>watch -n 5 pkill -USR1 ^dd$ </code></p>
<p>方法二：</p>
<p><code>watch -n 5 killall -USR1 dd </code></p>
<p>方法三：</p>
<p><code>while killall -USR1 dd; do sleep 5; done </code></p>
<p>方法四：</p>
<p><code>while (ps auxww |grep " dd " |grep -v grep |awk '{print $2}' |while read pid; do kill -USR1 $pid; done) ; do sleep 5; done </code></p>
<p>方法五：</p>
<p><code>dd if=/path/to/bigimage of=/path/to/newimage conv=sparse bs=262144 &amp; bgid=$!; while true; do sleep 1; kill -USR1 $bgid || break; sleep 4; done </code></p>
<p>上面这个命令，糅合了具体的dd命令，然后kill它来显示进度</p>
<img class="shadow" src="/img/in-post/dd_output_progress.png" width="1200">
<h1 id="pv-xian-shi-jin-du">pv显示进度</h1>
<p>题外话：</p>
<p>pv不仅仅有显示进度的功能，还有结合dd来限制dd读写速度， e.g:</p>
<p><code>pv --rate-limit 2M -q -cN source &lt; /dev/zero |dd of=off_file bs=1M count=1024 iflag=fullblock</code></p>
<p>非本文要阐述的内容，有兴趣的可以man pv查看使用手册。</p>
<p>如果没有pv，执行下列命令进行安装</p>
<p><code>apt-get install pv </code></p>
<h2 id="chuang-jian-bash-bao-zhuang-qi-shi-yong-pv-lai-xian-shi-jin-du">创建bash包装器，使用pv来显示进度</h2>
<p>在.bashrc中增加包装器,将下面内容放入.bashrc文件</p>
<pre><code class="language-shell">dd()
{
    local dd=$(which dd); [ "$dd" ] || {
        echo "'dd' is not installed!" &gt;&amp;2
        return 1
    }

    local pv=$(which pv); [ "$pv" ] || {
        echo "'pv' is not installed!" &gt;&amp;2
        "$dd" "$@"
        return $?
    }

    local arg arg2 infile
    local -a args
    for arg in "$@"
    do
        arg2=${arg#if=}
        if [ "$arg2" != "$arg" ]
        then
            infile=$arg2
        else
            args[${#args[@]}]=$arg
        fi
    done

    "$pv" -tpreb "$infile" | "$dd" "${args[@]}"
}
</code></pre>
<p>source一下.bashrc</p>
<p>之后再来使用dd命令，就可以看到进度了~</p>
<h2 id="zhi-jie-ming-ling-xing-yong-pv-xian-shi-jin-du">直接命令行用pv显示进度</h2>
<p>示例：</p>
<p><code>dd if=/dev/urandom | pv | dd of=/dev/null </code></p>
<p>输出：</p>
<p><code>44.2MB 0:00:04 [11.4MB/s] [         &lt;=&gt;                                ] </code></p>
<p>如果想要时间估算，可以使用 --size 指定近似大小：</p>
<p><code>dd if=/dev/urandom | pv -s 2G| dd of=/dev/null </code></p>
<img class="shadow" src="/img/in-post/pv_size.png" width="1200">
<p>示例：</p>
<p>写一个文件，并显示进度：</p>
<p><code>pv -cN source &lt; /dev/zero | dd of=1g bs=100k count=10240 </code></p>
<p>输出如下：</p>
<pre><code class="language-shell">root@host245:~/tmp# pv -cN source &lt; /dev/zero | dd of=1g bs=100k count=10240
   source:  960MB 0:00:01 [ 627MB/s] [         &lt;=&gt;                                                                                                                                                                                                                           ]
7680+2560 records in
7680+2560 records out
1006632960 bytes (1.0 GB) copied, 4.18198 s, 241 MB/s
root@host245:~/tmp# 
</code></pre>
<h2 id="shi-yong-pv-pei-he-dialog-huan-ke-yi-xian-shi-jin-du-tiao-dui-hua-kuang">使用pv配合dialog还可以显示进度条对话框：</h2>
<p>需要事先安装dialog</p>
<p><code>apt-get install dialog </code></p>
<p><code>(pv -n /dev/sda | dd of=/dev/zero bs=128M) 2&gt;&amp;1 | dialog --gauge "dd process bar" 10 70 0 </code></p>
<img class="shadow" src="/img/in-post/pv_dialog.png" width="1200">
<p>示例：</p>
<p>克隆磁盘驱动器：</p>
<p><code>(pv -n /dev/sda | dd of=/dev/sdh bs=128M conv=notrunc,noerror) 2&gt;&amp;1 | dialog --gauge "Running dd command (cloning), please wait..." 10 70 0 </code></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>dd</tag>
        <tag>pv</tag>
      </tags>
  </entry>
  <entry>
    <title>linux 下批量删除文件中空格</title>
    <url>/2016/01/18/linux_delete_space_for_files/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Linux下如何快速、批量删除文件中的空格？</p>
<h1 id="shell-shi-li-dai-ma">shell示例代码</h1>
<pre><code class="language-shell">#!/usr/bin/bash

ls|while read i;do &nbsp;
&nbsp; &nbsp; mv "$i" $(echo $i|tr -d ' ') 2&gt;/dev/null &nbsp;

done&nbsp;
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>查看网卡对应网口是否已使用</title>
    <url>/2016/03/22/check_nic_used_or_not/</url>
    <content><![CDATA[<h1 id="ying-yong-chang-jing">应用场景</h1>
<p>在安装完操作系统进行网卡配置IP地址时，往往不知道操作系统哪几个网卡口插了网线，在不去查看具体设备情况下，可通过本文确认哪个网卡口上插了网线。</p>
<p>如下图所示，存在4个网卡，在配置IP地址时，需要事先确认要去配置哪个网卡。</p>
<img class="shadow" src="/img/in-post/net_info.png" width="600">
<h1 id="cha-kan-guo-cheng">查看过程</h1>
<h2 id="cha-kan-suo-you-wang-qia-xin-xi">查看所有网卡信息</h2>
<pre><code class="language-shell">root@host181:~# ifconfig -a
eth0      Link encap:Ethernet  HWaddr 0c:c4:7a:47:44:a4  
          BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
          Interrupt:16 Memory:df600000-df620000 

eth1      Link encap:Ethernet  HWaddr 00:e0:ed:43:8c:4e  
          inet addr:10.16.17.181  Bcast:10.16.17.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:464590 errors:651 dropped:689 overruns:0 frame:651
          TX packets:68621 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:44648440 (44.6 MB)  TX bytes:47221831 (47.2 MB)

eth2      Link encap:Ethernet  HWaddr 0c:c4:7a:47:44:a5  
          BROADCAST MULTICAST  MTU:1500  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
          Interrupt:17 Memory:df500000-df520000 

eth3      Link encap:Ethernet  HWaddr 00:e0:ed:43:8c:4f  
          inet addr:10.10.10.181  Bcast:10.10.10.255  Mask:255.255.255.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:63671255 errors:651 dropped:4061 overruns:0 frame:651
          TX packets:79242899 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000 
          RX bytes:49119827886 (49.1 GB)  TX bytes:47106704400 (47.1 GB)

lo        Link encap:Local Loopback  
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:30775317 errors:0 dropped:0 overruns:0 frame:0
          TX packets:30775317 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:17379972836 (17.3 GB)  TX bytes:17379972836 (17.3 GB)
</code></pre>
<h2 id="cha-kan-ge-ge-wang-qia-de-link-detected-xin-xi">查看各个网卡的Link detected信息</h2>
<pre><code class="language-shell">root@host181:~# ethtool eth0 | grep 'Link detected'
	Link detected: no
root@host181:~# ethtool eth1 | grep 'Link detected'
	Link detected: yes
root@host181:~# ethtool eth2 | grep 'Link detected'
	Link detected: no
root@host181:~# ethtool eth3 | grep 'Link detected'
	Link detected: yes
root@host181:~#
</code></pre>
<p>如上所示，Link detected值为yes的，表示该网卡有连接线，被启用，据此可以去进行eth0和eth3网卡的IP配置。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Robot Framework做VirtualStore的自动化</title>
    <url>/2016/04/11/virtualstore_robotframework_automation_guide/</url>
    <content><![CDATA[<h2 id="env">ENV</h2>
<table>
<thead>
<tr>
<th><strong>Type</strong></th>
<th><strong>Version</strong></th>
<th><strong>Desc</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OS</strong></td>
<td>Ubuntu 16.04</td>
<td>Need lib higher  libc lib/python/apache, out storage ISO not match</td>
</tr>
<tr>
<td><strong>Jenkins</strong></td>
<td>2.32.3</td>
<td>Jenkins</td>
</tr>
<tr>
<td><strong>RF</strong></td>
<td>3.0.2 (Python  2.7.12 on linux2)</td>
<td>Robot framework,  used for running RF testcases</td>
</tr>
</tbody>
</table>
<h2 id="install-jenkins">Install Jenkins</h2>
<h3 id="install-jenkins-1">install Jenkins</h3>
<pre><code class="language-shell">jenkins@jenkins:~$ wget -q -O - https://jenkins-ci.org/debian/jenkins-ci.org.key | sudo apt-key add -
OK
jenkins@jenkins:~$ sudo sh -c 'echo deb http://pkg.jenkins-ci.org/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list'
jenkins@jenkins:~$
sudo apt-get update 
sudo apt-get install jenkins 
</code></pre>
<h3 id="check-jenkins-service-status">Check Jenkins service status</h3>
<pre><code class="language-shell">jenkins@jenkins:~$ sudo service jenkins status

● jenkins.service - LSB: Start Jenkins at boot time
  Loaded: loaded (/etc/init.d/jenkins; bad; vendor preset: enabled)
  Active: active (exited) since 五 2017-03-03 18:03:06 CST; 46s ago
   Docs: man:systemd-sysv-generator(8)

3月 03 18:03:05 jenkins systemd[1]: Starting LSB: Start Jenkins at boot time...
3月 03 18:03:05 jenkins jenkins[5041]: * Starting Jenkins Continuous Integration Server jenkins
3月 03 18:03:05 jenkins su[5059]: Successful su for jenkins by root
3月 03 18:03:05 jenkins su[5059]: + ??? root:jenkins
3月 03 18:03:05 jenkins su[5059]: pam_unix(su:session): session opened for user jenkins by (uid=0)
3月 03 18:03:06 jenkins jenkins[5041]:  ...done.
3月 03 18:03:06 jenkins systemd[1]: Started LSB: Start Jenkins at boot time.
</code></pre>
<h3 id="jenkins-path">jenkins path</h3>
<pre><code class="language-shell">Access path：http://localhost:8080 
Installed path：/var/lib/jenkins 
Log path：/var/log/jenkins
Create a project directory in Jenkins installation directory of the jobs.
</code></pre>
<h3 id="first-login-jenkins-ui">First login Jenkins UI</h3>
<h6 id="getting-started">Getting Started</h6>
<img class="shadow" src="/img/in-post/rf/clip_image002.jpg" width="1200">
<h6 id="after-input-administrator-password">after input Administrator password</h6>
<img class="shadow" src="/img/in-post/rf/clip_image004.jpg" width="1200">
<h6 id="select-install-suggested-plugins">Select “Install suggested plugins”</h6>
<img class="shadow" src="/img/in-post/rf/clip_image006.jpg" width="1200">
<h6 id="create-first-admin-user">Create First Admin User</h6>
<img class="shadow" src="/img/in-post/rf/clip_image008.jpg" width="1200">
<img class="shadow" src="/img/in-post/rf/clip_image010.jpg" width="1200">
<h6 id="save-and-finish">Save and Finish</h6>
<img class="shadow" src="/img/in-post/rf/clip_image012.jpg" width="1200">
<p>Login Jenkins UI</p>
<img class="shadow" src="/img/in-post/rf/clip_image014.jpg" width="1200">
<img class="shadow" src="/img/in-post/rf/clip_image016.jpg" width="1200">
<h2 id="install-rf-and-third-library">install RF and Third library</h2>
<h3 id="install-robotframework">Install Robotframework</h3>
<h5 id="install-rf">install RF</h5>
<pre><code class="language-shell">sudo apt-get install python-pip
sudo pip install --upgrade pip
sudo pip install robotframework
</code></pre>
<h5 id="install-rf-library">install RF library</h5>
<pre><code class="language-shell">sudo apt-get install python-wxgtk*
sudo pip install robotframework-ride
sudo pip install --upgrade robotframework-httplibrary
sudo apt-get install build-essential libssl-dev libffi-dev python-dev
#此步骤如果不执行，会出现安装cryptography失败，具体错误参考“setup cryptography failed”章节的内容。
sudo pip install --upgrade robotframework-SSHLibrary
</code></pre>
<h5 id="other-package">other package</h5>
<pre><code class="language-shell">sudo apt-get install sshpass
sudo apt-get install open-iscsi
sudo apt-get install fio
</code></pre>
<h5 id="problems-encountered">Problems encountered</h5>
<h6 id="setup-cryptography-failed">setup cryptography failed</h6>
<pre><code class="language-shell">  writing top-level names to src/cryptography.egg-info/top_level.txt
  writing dependency_links to src/cryptography.egg-info/dependency_links.txt
  writing entry points to src/cryptography.egg-info/entry_points.txt
  reading manifest file 'src/cryptography.egg-info/SOURCES.txt'
  reading manifest template 'MANIFEST.in'
  no previously-included directories found matching 'docs/_build'
  warning: no previously-included files matching '*' found under directory 'vectors'
  writing manifest file 'src/cryptography.egg-info/SOURCES.txt'
  running build_ext
  generating cffi module 'build/temp.linux-x86_64-2.7/_padding.c'
  creating build/temp.linux-x86_64-2.7
  generating cffi module 'build/temp.linux-x86_64-2.7/_constant_time.c'
  generating cffi module 'build/temp.linux-x86_64-2.7/_openssl.c'
  building '_openssl' extension
  creating build/temp.linux-x86_64-2.7/build
  creating build/temp.linux-x86_64-2.7/build/temp.linux-x86_64-2.7
  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fstack-protector-strong -Wformat -Werror=format-security -fPIC -I/usr/include/python2.7 -c build/temp.linux-x86_64-2.7/_openssl.c -o build/temp.linux-x86_64-2.7/build/temp.linux-x86_64-2.7/_openssl.o
  build/temp.linux-x86_64-2.7/_openssl.c:434:30: fatal error: openssl/opensslv.h: No such file or directory
  compilation terminated.
  **error: command 'x86_64-linux-gnu-gcc' failed with exit status 1**
  

 ----------------------------------------
Command "/usr/bin/python -u -c "import setuptools, tokenize;__file__='/tmp/pip-build-CbMI0T/cryptography/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))" install --record /tmp/pip-T5kRVj-record/install-record.txt --single-version-externally-managed --compile" failed with error code 1 in /tmp/pip-build-CbMI0T/cryptography/

Reference resources：
  https://cryptography.io/en/latest/installation/#building-cryptography-on-linux

</code></pre>
<h3 id="modify-http-library-code">Modify HttpLibrary code</h3>
<h5 id="linux">Linux</h5>
<pre><code class="language-shell">vi /usr/local/lib/python2.7/dist-packages/HttpLibrary/__init__.py

Increase the following records, global cancelled certificate verification：

import ssl

ssl._create_default_https_context = ssl._create_unverified_context
</code></pre>
<h5 id="windows">Windows</h5>
<pre><code class="language-shell">  Modify file of C:\Python27\Lib\site-packages\HttpLibrary\__init__.py, increase the following records, global cancelled certificate verification：

import ssl

ssl._create_default_https_context = ssl._create_unverified_context
</code></pre>
<h2 id="running-rf-test-cases">Running RF test cases</h2>
<h3 id="case-execution-condition">Case execution condition</h3>
<pre><code class="language-shell">
1. 3 nodes cluster, each node of disk space is greater than 8G

2. Each node disk/vdisk numbers shall not be less than 4 (&gt; = 4)
</code></pre>
<p>instructions:</p>
<pre><code class="language-shell"> This part of the inspection is in test case of rf-automation\testcase\01_Create_Cluster\Prepare Cluster.robot\01_ENV_Check
</code></pre>
<h3 id="problems-encountered-1">Problems encountered</h3>
<h6 id="ssl-certificate-verify-failed">SSL certificate verify failed</h6>
<p>When running RF test case, occur SSLcertificate verify failed issue:</p>
<img class="shadow" src="/img/in-post/rf/clip_image018.jpg" width="1200">
<p>The solution：</p>
<p>Refer to the “Modify HttpLibrary code” section. Here only capture the record, if don’t modify this problem will appear.</p>
<h6 id="wait-until-keyword-succeeds-occur-cannot-send-request">Wait Until Keyword Succeeds occur CannotSendRequest</h6>
<img class="shadow" src="/img/in-post/rf/clip_image020.jpg" width="1200">
<pre><code class="language-shell">20160516 13:55:43.636 : INFO : ${osd_state} = OFFLINE

20160516 13:55:43.637 : INFO : 

Argument types are:

&lt;type 'str'&gt;

&lt;type 'unicode'&gt;

20160516 13:55:43.637 : FAIL : OFFLINE != ONLINE

20160516 13:55:48.649 : FAIL : BadStatusLine: ''

20160516 13:55:53.656 : FAIL : CannotSendRequest

20160516 13:55:58.674 : FAIL : CannotSendRequest

20160516 13:56:03.679 : FAIL : CannotSendRequest

20160516 13:56:08.685 : FAIL : CannotSendRequest

20160516 13:56:13.695 : FAIL : CannotSendRequest

20160516 13:56:18.704 : FAIL : CannotSendRequest

20160516 13:56:23.718 : FAIL : CannotSendRequest

20160516 13:56:28.726 : FAIL : CannotSendRequest

20160516 13:56:33.742 : FAIL : CannotSendRequest

20160516 13:56:38.762 : FAIL : CannotSendRequest

20160516 13:56:43.780 : FAIL : CannotSendRequest

20160516 13:56:48.799 : FAIL : CannotSendRequest

20160516 13:56:53.817 : FAIL : CannotSendRequest

20160516 13:56:58.836 : FAIL : CannotSendRequest

20160516 13:57:03.852 : FAIL : CannotSendRequest

20160516 13:57:08.867 : FAIL : CannotSendRequest

20160516 13:57:13.881 : FAIL : CannotSendRequest

20160516 13:57:18.890 : FAIL : CannotSendRequest

20160516 13:57:23.898 : FAIL : CannotSendRequest

20160516 13:57:28.912 : FAIL : CannotSendRequest

20160516 13:57:33.921 : FAIL : CannotSendRequest

20160516 13:57:38.936 : FAIL : CannotSendRequest

20160516 13:57:43.952 : FAIL : CannotSendRequest

20160516 13:57:43.958 : FAIL : Keyword 'Get OSD State' failed after retrying for 2 minutes. The last error was: CannotSendRequest

Ending test:  interfaceAuto.Testcase.02 Host Configuration.Add storage volume.Single partition
</code></pre>
<p>The solution：</p>
<pre><code class="language-shell">root@host1:/# vi /etc/apache2/apache2.conf

modify 

   KeepAliveTimeout 5 

to 

   KeepAliveTimeout 100

Units are seconds, then restart apache2 service。
</code></pre>
<p>instructions：</p>
<p>This is united into the robot file of rf-automation\testcase\01_Create_Cluster\Prepare Cluster.robot. If still appear, please check whether the apache conf was successfully modified, or to check the test case in file of Prepare Cluster.robot execute success or not.</p>
<h6 id="forbidden-root-login">Forbidden root login</h6>
<p>The RF test case exceutor is Jenkins, sometimes need root user to perform or switch to root user(e.g: ssh 127.0.0.1), because of user of root was banned to login, so some test case will fail.</p>
<p>The solution：</p>
<p>Allow root login：</p>
<pre><code class="language-shell">1. modify /etc/ssh/sshd_config

vi /etc/ssh/sshd_config

 

2、allow root login

search “#PermitRootLogin no”， 

delete "#", and set "No" to "Yes", then save the file. Like this:

# PermitRootLogin prohibit-password

PermitRootLogin yes

 

At last, restart ssh service.
</code></pre>
<h6 id="client-mount-nfs-return-32">Client mount nfs return 32</h6>
<p>The bellow is test case of “Create NFS share folder”:</p>
<img class="shadow" src="/img/in-post/rf/clip_image022.jpg" width="1200">
<p>when client mount nfs, the output is:</p>
<pre><code class="language-shell">Failed to restart nfs-kernel-server.service: Unit nfs-kernel-server.service not found.

root@jenkins:~# mount -t nfs 10.10.0.127:/vol/nas01 /mnt/nfs

mount: wrong fs type, bad option, bad superblock on 10.10.0.127:/vol/nas01,

​    missing codepage or helper program, or other error

​    (for several filesystems (e.g. nfs, cifs) you might

​    need a /sbin/mount.&lt;type&gt; helper program)

 

​    In some cases useful info is found in syslog - try

​    dmesg | tail or so.
</code></pre>
<p>The solution：</p>
<pre><code class="language-shell">Install nfs-common and cifs-utils
apt-get install nfs-common
apt-get install cifs-utils
</code></pre>
<p>Then, file of mount.nfs and mount.cifs created in dir of /sbin.</p>
<h2 id="create-jenkins-porject">Create Jenkins Porject</h2>
<h3 id="enter-an-item-name">Enter an item name</h3>
<img class="shadow" src="/img/in-post/rf/clip_image024.jpg" width="1200">
<p>Click “OK”</p>
<h3 id="source-code-management">Source Code Management</h3>
<img class="shadow" src="/img/in-post/rf/clip_image026.jpg" width="1200">
<h3 id="build-triggers">Build Triggers</h3>
<img class="shadow" src="/img/in-post/rf/clip_image028.jpg" width="1200">
<h3 id="build-environment">Build Environment</h3>
<img class="shadow" src="/img/in-post/rf/clip_image030.jpg" width="1200">
<h3 id="build">Build</h3>
<img class="shadow" src="/img/in-post/rf/clip_image032.jpg" width="1200">
<p>set properties file path to get ISO_NAME and RF running times. Before setting, should install this plug, search keyword is “inject”.</p>
<img class="shadow" src="/img/in-post/rf/clip_image034.jpg" width="1200">
<h3 id="post-build-actions">Post-build Actions</h3>
<h6 id="install-robot-framework-plug">Install robot framework plug</h6>
<p>install robot framework plug to get total test cases/success test cases/failed test cases/ignore test cases and so on.</p>
<img class="shadow" src="/img/in-post/rf/clip_image036.jpg" width="1200">
<h6 id="editable-email-notification">Editable Email Notification</h6>
<p>Input follow content in “Default Content”:</p>
<pre><code class="language-shell">&lt;html&gt;
  &lt;head&gt;
​    &lt;title&gt;&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
​    Hi All, &lt;br&gt;
​      This is the SEG Robot Framework Interface Automation Test Results. &lt;br&gt;
​    &lt;font color="#0B610B" size="3"&gt; Please click on the red link, check the console output, and check the continuous integration build results:&lt;/font&gt; &lt;a href="${BUILD_URL}console"&gt;&lt;b&gt;&lt;font color="#DF0101" size="3"&gt; ${ENV, var="JOB_NAME"}&lt;/font&gt;&lt;/b&gt;&lt;/a&gt;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;table width="95%" cellpadding="0" cellspacing="0" style="font-size:11pt; font-family:Tahoma, Arial, Helvetica, sans-serif"&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;h2&gt;
​            &lt;font color="#0000FF" size="4"&gt;Result: Passing rate - ${TEST_COUNTS,var="PASS"}&amp;#47;${TEST_COUNTS}&lt;/font&gt;
​          &lt;/h2&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;br&gt;
​          &lt;b&gt;&lt;font color="#0B610B"&gt;Build information:&lt;/font&gt;&lt;/b&gt;
​          &lt;hr size="2" width="100%" align="center"&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;ul&gt;
​            &lt;li&gt;Project Name    -- ${PROJECT_NAME}&lt;/li&gt;
​            &lt;li&gt;Run ISO Version   -- ${ISO_NAME} &lt;/li&gt;
​            &lt;li&gt;RF Start/End Time  -- From ${START_TIME} To ${END_TIME}&lt;/li&gt;
​            &lt;li&gt;Build Serial Number -- The ${BUILD_NUMBER} times build&lt;/li&gt;
​            &lt;li&gt;Trigger Reason   -- ${CAUSE}&lt;/li&gt; 
​             &lt;li&gt;Build Result    -- &lt;a href="${PROJECT_URL}${BUILD_NUMBER}/robot/"&gt;${PROJECT_URL}${BUILD_NUMBER}/robot/&lt;/a&gt; &lt;/li&gt;
​            &lt;li&gt;Project URL     -- &lt;a href="${PROJECT_URL}"&gt;${PROJECT_URL}&lt;/a&gt;&lt;/li&gt;
​            &lt;li&gt;Build URL      -- &lt;a href="${BUILD_URL}"&gt;${BUILD_URL}&lt;/a&gt;&lt;/li&gt;
​            &lt;li&gt;Total cases     -- $TEST_COUNTS&lt;/li&gt;
​            &lt;li&gt;Pass cases      -- ${TEST_COUNTS,var="pass"}&lt;/li&gt;
​            &lt;li&gt;Fail cases      -- ${TEST_COUNTS,var="fail"}&lt;/li&gt;
​            &lt;li&gt;Skip cases     -- ${TEST_COUNTS,var="skip"}&lt;/li&gt;
​            &lt;li&gt;Git Version     -- ${GIT_REVISION,length=8} &lt;/li&gt;
​          &lt;/ul&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;b&gt;&lt;font color="#0B610B"&gt;Since the last success build of the change&lt;/font&gt;&lt;/b&gt;
​          &lt;hr size="2" width="100%" align="center"&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;ul&gt;
​            &lt;li&gt;In this view the historical change: -- &lt;a href="${PROJECT_URL}changes"&gt;${PROJECT_URL}changes&lt;/a&gt;
​            &lt;/li&gt;
​          &lt;/ul&gt;${CHANGES_SINCE_LAST_SUCCESS, reverse=true, format="Changes for Build #%n:&lt;br&gt;%c&lt;br&gt;", showPaths=true, changesFormat="&lt;pre&gt;[%a]&lt;br&gt;%m&lt;/pre&gt;", pathFormat="&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;%p"}
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;br&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;b&gt;&lt;font color="#0B610B"&gt;Failure of the test results:&lt;/font&gt;&lt;/b&gt;
​          &lt;hr size="2" width="100%" align="center"&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;pre style="font-size:11pt; font-family:Tahoma, Arial, Helvetica, sans-serif"&gt;

$FAILED_TESTS

&lt;/pre&gt;&lt;br&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          &lt;b&gt;&lt;font color="#0B610B"&gt;Build log (The last 100 rows record):&lt;/font&gt;&lt;/b&gt;
​          &lt;hr size="2" width="100%" align="center"&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
​      &lt;tr&gt;
​        &lt;td&gt;
​          The test log (if run the test): &lt;a href="${PROJECT_URL}${BUILD_NUMBER}/console"&gt;${PROJECT_URL}${BUILD_NUMBER}/console&lt;/a&gt;&lt;br&gt;
​          &lt;br&gt;
​        &lt;/td&gt;
​       &lt;/tr&gt;
​    &lt;/table&gt;

&lt;hr size="2" width="100%" align="center" /&gt; 
(Note: This E-mail generated by system automatically, please do not reply!)

​      &lt;tr&gt; &lt;td&gt;
​          &lt;br&gt;
​        &lt;/td&gt;
​      &lt;/tr&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h6 id="add-publish-robot-framework-test-results">Add publish robot framework test results</h6>
<img class="shadow" src="/img/in-post/rf/clip_image038.jpg" width="1200">
<p>Then, save it.</p>
<h3 id="jenkins-system-config">Jenkins System Config</h3>
<h6 id="config-system">Config System</h6>
<img class="shadow" src="/img/in-post/rf/clip_image040.jpg" width="1200">
<h6 id="set-system-admin-e-mail-address">Set System Admin e-mail address</h6>
<img class="shadow" src="/img/in-post/rf/clip_image042.jpg" width="1200">
<h6 id="extended-e-mail-notification">Extended E-mail Notification</h6>
<img class="shadow" src="/img/in-post/rf/clip_image044.jpg" width="1200">
<h6 id="e-mail-notification">E-mail Notification</h6>
<img class="shadow" src="/img/in-post/rf/clip_image046.jpg" width="1200">
<p>project的详细配置，请参考Nanking lab 172.16.146.234的设置。</p>
<h3 id="e-mail-over-view">E-mail Over View</h3>
<p>The below is the received email, e.g:</p>
<img class="shadow" src="/img/in-post/rf/clip_image048.jpg" width="1200">
<h3 id="open-report-html-failed">Open report.html failed</h3>
<p>just like this:</p>
<img class="shadow" src="/img/in-post/rf/clip_image050.jpg" width="1200">
<p>This is a bug of Jenkins, the work around is:</p>
<p><a href="https://issues.jenkins-ci.org/browse/JENKINS-32118">https://issues.jenkins-ci.org/browse/JENKINS-32118</a></p>
<p>Run the command in Script Console:</p>
<pre><code class="language-shell">system.setProperty("hudson.model.DirectoryBrowserSupport.CSP","sandbox allow-scripts; default-src 'none'; img-src 'self' data: ; style-src 'self' 'unsafe-inline' data: ; script-src 'self' 'unsafe-inline' 'unsafe-eval' ;")
</code></pre>
<p>That’s all.</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>Robot Framework</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Robot Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>Slow to open CIFS</title>
    <url>/2016/04/21/monitify_cifs_open_time/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>I encountered a scenario where the client feedback that the client side is slow to open CIFS, write a script to verify it.</p>
<h1 id="script-of-monitor-cifs-open-time-py">Script of monitor_cifs_open_time.py</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8  -*-

import time
import subprocess
from datetime import datetime


def cost_time():

    start_time = time.time()
    p = subprocess.Popen('ls -l /mnt/windows_cifs', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)

    for line in p.stdout.readlines():

        if 'total' in line:
            #print line
            end_time= time.time()
            cost_time = end_time - start_time
            print '[{}] cost_time {}'.format(datetime.now(), cost_time)

            break

    time.sleep(10)


if __name__ == '__main__':
    for i in xrange(1000):
        cost_time()
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>自动关闭ssh会话</title>
    <url>/2016/05/29/auto_close_ssh_session/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>有时候需要远程登录到客户现场环境，通过<code>xshell</code>之类的终端工具访问后台，由于客户现场有安全方面的严格要求，不得持续保留ssh会话，即：当问题摸清之后，需要退出远程，关闭ssh连接。但难免百密一疏导致遗漏，引发客户埋怨。如何来解决这个问题呢？</p>
<h1 id="shi-jian">实践</h1>
<p>以<code>xshell ssh</code>登录<code>linux</code>后台，在一定时间内没有任何操作，自动中断这个会话。</p>
<p>解决方法：</p>
<h3 id="step-1-vi-etc-profile">step 1、vi /etc/profile</h3>
<p>增加 <code>TMOUT=60</code></p>
<p>这里表示60秒内无操作，自动终止<code>ssh session</code>。</p>
<h3 id="step-2-source-etc-profile">step 2、source /etc/profile</h3>
<h3 id="step-3-echo-tmout">step 3、echo $TMOUT</h3>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>获取Apache请求处理时间</title>
    <url>/2016/06/01/elapsed_time_of_apache/</url>
    <content><![CDATA[<h1 id="yin-yan">引言</h1>
<p>客户经常指责我们某些CGI请求处理的时间过长，我们需要一种快速的方法获取apache 对每一个请求处理的时间。事实上apache 可以打印出每一个请求的处理时间。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>/etc/apache2/apache2.conf中，在</p>
<p><code>LogFormat "%h %l %u %t \"%r\" %&gt;s %O \"%{Referer}i\" \"%{User-Agent}i\"" combined </code></p>
<p>在这一行中增加 <code>%T.%D</code> 就可以打印每一个请求的处理时间。</p>
<p>修改后，conf 内容如下：</p>
<pre><code class="language-shell">LogFormat "%v:%p %h %l %u %t \"%r\" %&gt;s %O \"%{Referer}i\" \"%{User-Agent}i\"" vhost_combined
LogFormat "%h %l %u %t \"%r\" %&gt;s %O %T.%D \"%{Referer}i\" \"%{User-Agent}i\"" combined
LogFormat "%h %l %u %t \"%r\" %&gt;s %O" common
LogFormat "%{Referer}i -&gt; %U" referer
LogFormat "%{User-agent}i" agent
</code></pre>
<p>看下//var/log/apache2/access.log中的输出：</p>
<pre><code class="language-shell"> 10.16.17.43 - - [01/Jun/2016:13:41:51 +0800] "GET /cgi-bin/ezs3/json/list_shared_folder?gateway_group=virStorage&amp;_=1464745951979 HTTP/1.1" 200 1322 0.932141 "https://10.16.17.11:8080/" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:46.0) Gecko/20100101 Firefox/46.0"
</code></pre>
<h1 id="qi-ta">其他</h1>
<p>其他相关的参数和含义如下,可以前往 <a href="https://httpd.apache.org/docs/2.2/mod/modlogconfig.html">https://httpd.apache.org/docs/2.2/mod/modlogconfig.html</a> 去学习。</p>
]]></content>
      <categories>
        <category>Apache</category>
      </categories>
      <tags>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title>Curl调用CGI完成UI操作</title>
    <url>/2016/06/24/use_curl_call_api/</url>
    <content><![CDATA[<h1 id="yin-yan">引言</h1>
<p>Web UI上的所有操作都对应一个CGI(大多是一个HTTP GET请求)，因此如果想快速地进行大量UI操作，可以直接call CGI去完成想要的工作。对于发送一个HTTP请求，绝大多数编程语言都可以做到。如果是自动化测试开发，可能会选择python等比较全面的工具，但如果只是偶尔用之，一个小小的curl，一两行命令就可以满足要求。</p>
<h1 id="shi-li">示例</h1>
<h2 id="step-1-ji-lu-xia-cookie-wen-jian-test-cookie">Step1、记录下cookie文件test.cookie</h2>
<p>–cookie-jar可简化做-c，仅需要登录一次，除非会话过期</p>
<pre><code class="language-shell">curl --cookie-jar test.cookie --insecure "https://10.16.17.191:8080/cgi-bin/ezs3/json/login?user_id=admin&amp;password=1"
</code></pre>
<h2 id="step-2-diao-yong-dui-ying-de-api">Step2、调用对应的API</h2>
<p>–cookie可简化做-b，该示例是创建一个叫pool01的pool</p>
<pre><code class="language-shell">curl --cookie ezstor.cookie --insecure "https://10.16.17.191:8080/cgi-bin/ezs3/json/poolcreate?poolname=pool01"
</code></pre>
<h1 id="kuo-zhan">扩展</h1>
<p>如何抓取API?</p>
<p>可以借助浏览器，F12，就可以抓取自己care的API了</p>
<h1 id="wan-zheng-jiao-ben-shi-li">完整脚本示例</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>说明:</p>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">本示例，用于创建集群</li>
</ul>
</li>
</ul>
<pre><code class="language-shell">#!/bin/bash

public_ip=(
172.17.59.101
172.17.59.102
172.17.59.103
)
storage_ip=(
192.168.100.101
192.168.100.102
192.168.100.103
)
license_info=(
CLAWCT-PTWAV4-4K66F0-C3RH9O-8ATUKF-YDO14G-11WI568
CLB2LB-GF94W0-2O11R5-NA4E9L-5B5XRM-9DFK0V-72438U
CLB8TT-70LYWW-5ZYPBB-H0AAR4-126WJ0-VC8END-1H4H309
)
osd_device=sdb

public_iface=eth0
cluster_iface=eth1
root_passwd=1
cluster_name=automation
ui_account=admin
ui_account_passwd=1
rep_no=2
ntp_server_ip=202.120.2.101
enable_timeout=480


function check_network()
{
    # public_interface network status check
    echo "@1.Start to check network."
    echo -e "  [Public interface]:"
    for(( i=0; i&lt;${#public_ip[@]}; i++ ))
    do
        public_network_status=`ping -c 4 ${public_ip[i]} | grep "packet loss" | awk -F " " '{print $6}'`
        if [[ x"${public_network_status}" == x"0%" ]]; then
            echo -e "    ${public_ip[i]}  --&gt;  OK"
        else
            echo -e "    ${public_ip[i]}  --&gt;  OK"
            return 1
        fi
    done
    
    # storage_interface network status check
    echo -e "  [Storeage interfae]:"
    for(( i=0;i&lt;${#storage_ip[@]}; i++ ))
    do
        storage_network_status=`ping -c 4 ${storage_ip[i]} | grep "packet loss" | awk -F " " '{print $6}'`
        if [[ x"${storage_network_status}" == x"0%" ]]; then
            echo -e "    ${storage_ip[i]}  --&gt;  OK"
        else
            echo -e "    ${storage_ip[i]}  --&gt;  OK"
            return 1
        fi
    done
    return 0
}

function check_apache()
{ 
    # network is bad, do not start apache
    ret=`echo $?`
    if [[ ${ret} -eq 1 ]]; then
        echo -e "[ERROR]  network check finish, network is bad."
        return 1
    else
        echo -e "[Success]  network check finish, network is ok."
    fi
    
    echo -e "\n@2.Start to check apache service."
    for(( i=0; i&lt;${#public_ip[@]}; i++ ))
    do
        for(( i=0; i&lt;3; i++ ))
        do
            ret_code=$(curl -I -m 10 -o /dev/null -s -w %{http_code} --insecure --cookie-jar cookie.jar "https://${public_ip[i]}:8080/cgi-bin/ezs3/json/login?user_id=root&amp;password=${root_passwd}")
            if [[ x"${ret_code}" != x"200" ]]; then
                echo -e "[ERROR]  Apache's service is bad on ${public_ip[i]}, error code is ${ret_code}"
                return 1
            else
                echo -e "  Apache service on ${public_ip[i]}  --&gt;  OK"
            fi
        done
    done

    echo -e "[Success] Check Apache service finished, all apache's service are OK."
    return 0

:&lt;&lt;!
    # add host to sshpass known list
    for(( i=0; i&lt;${#public_ip[@]}; i++ ))
    do
        #echo ${apache_status}
        sshpass -p p@ssw0rd ssh -o StrictHostKeyChecking=no root@${public_ip[i]} pidof apache2
        #apache_status="sshpass -p p@ssw0rd ssh -o StrictHostKeyChecking=no root@${public_ip[i]} pidof apache2"
        #echo ${apache_status}
    done
    
    # check apache whether or not start
    for(( i=0; i&lt;${#public_ip[@]}; i++ ))
    do
        apache_status="sshpass -p p@ssw0rd ssh -o StrictHostKeyChecking=no root@${public_ip[i]} pidof apache2"
        if [[ x"${apache_status}" == x"" ]]; then
            echo "apache not started @${public_ip[i]}."
            return 1
        else
            echo "apache started ${public_ip[i]}."
        fi
    done
    return 0
!
}

function check_license()
{
   license_array_len=${#license_info[@]}
   storage_ip_len=${#storage_ip[@]}

   if [[ x"${license_array_len}" -ne x"${storage_ip_len}" ]]; then
      echo -e "    [ERROR] Licesne number should same as the number of nodes\n"
      return 1 
   fi
}


function create_cluster()
{
    for(( i=0;i&lt;${#storage_ip[@]};i++))
    do
        if [[ ${i} -eq 0 ]]; then 
            cluster_ip+=${storage_ip[i]}
        else
            cluster_ip+=+${storage_ip[i]}
        fi
    done

    echo -e "Login with root account, then create the cluster\n"
    curl --insecure --cookie-jar cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/login?user_id=root&amp;password=${root_passwd}"
    
    curl --insecure --cookie cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/create_cluster?admin_account=${ui_account}&amp;admin_passwd=${ui_account_passwd}&amp;cluster_name=${cluster_name}&amp;license_key=&amp;mons=${cluster_ip#*+}&amp;nodes=${cluster_ip}&amp;ntp_server_list=${ntp_server_ip}&amp;rack_id=0&amp;rep_no=2&amp;use_rack_aware=false"
 
    echo -e "Account of root logout\n"
    curl --insecure --cookie cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/logout"
    
    echo -e "Remove cookie.jar\n"
    rm -rf cookie.jar
    echo -e "Sleep 100s, to wait root session timeout\n"
    sleep 100
    
    echo -e "Login UI with ${ui_account}, then input license/create OSD/enable GW\n"
    curl --insecure  --cookie-jar ui-cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/login?user_id=${ui_account}&amp;password=${ui_account_passwd}"
}


function input_license()
{
    for(( i=0;i&lt;${#storage_ip[@]};i++))
    do 
        echo -e "    Input lincesne ${license_info[i]} on ${storage_ip[i]}\n"
        curl --insecure --cookie ui-cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/license_set?ip=${storage_ip[i]}&amp;key=${license_info[i]}"
        sleep 1
    done
}

function create_and_enable_osd()
{
    for(( i=0;i&lt;${#storage_ip[@]};i++))
    do 
        echo -e "    Create OSD on node ${storage_ip[i]}\n"
        curl --insecure --cookie ui-cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/storage_volume_add" --data "host=${storage_ip[i]}&amp;name=osd&amp;sv_type=0&amp;data_devs=%5B%22%2Fdev%2F${osd_device}%22%5D&amp;journal_dev=data&amp;cache_dev=&amp;spare_devs=%5B%5D&amp;dedup=false&amp;compress=false&amp;memory_conserve=false&amp;enable_osd=true&amp;ip=${storage_ip[i]}&amp;cluster_iface=${cluster_iface}&amp;public_iface=${public_iface}&amp;pool_to_join=default&amp;add_metadata_pool=true"
        echo -e "    Enable  OSD on node ${storage_ip[i]}\n"
        curl --insecure --cookie ui-cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/node_role_enable_osd?ip=${storage_ip[i]}&amp;sv_list=osd&amp;cluster_iface=${cluster_iface}&amp;public_iface=${public_iface}"
        echo -e "    Check OSD up/down status on node ${storage_ip[i]}\n"
        j=1
        while [[ ${j} -le ${enable_timeout} ]]
        do
           osd_up_nums=`ceph osd tree | grep -A 2 default_${storage_ip[i]} | grep -i up| wc -l 2&gt;&amp;1`
           if [[ ${osd_up_nums} -ge 1 ]]; then
               echo -e "        [SUCCESS] OSD is up on node ${storage_ip[i]}\n"
               break
           else
               echo -e "        Node ${storage_ip[i]}, the $j time(s) check OSD up status, total check times is ${enable_timeout}\n"
           fi
           let j++
           sleep 1
        done
    done
}


function enable_gw()
{
    for(( i=0;i&lt;${#storage_ip[@]};i++))
    do
        echo -e "    Enable Gateway on node ${storage_ip[i]}\n"
        curl --insecure --cookie ui-cookie.jar "https://${public_ip[0]}:8080/cgi-bin/ezs3/json/gateway_role_enable?ip=${storage_ip[i]}&amp;public_iface=${public_iface}"
        echo -e "    Check GW enabled status on node ${storage_ip[i]}\n"
        j=1
        while [[ ${j} -le ${enable_timeout} ]]
        do
           ctdb_status=`ctdb status | grep ${storage_ip[i]} | awk '{print $3}'| sed 's/ //g' 2&gt;&amp;1`
           if [[ x"${ctdb_status}" == x"OK" ]]; then
               echo -e "        [SUCCESS] GW is enabled\n"
               break
           else
               echo -e "        Node ${storage_ip[i]}, the $j time(s) to check ctdb status, total check times is ${enable_timeout}\n"
           fi
           let j++
           sleep 1
        done
    done
}

function cluster_health()
{
    echo -e "Check cluster health status\n"
    health_status=`ceph -s | grep -i health | awk '{print $NF}' | sed 's/ //g' 2&gt;&amp;1`
    i=1
    while [[ $i -le ${enable_timeout} ]]
    do
        if [[ x"${health_status}" != x"HEALTH_OK" ]]; then
            echo -e "  The $i time(s) to check cluster health, total check times is ${enable_timeout}\n"
            let i++
            sleep 1
        else
            echo -e "  [Success] Cluster health is OK\n"
            break
        fi
    done
}

function clean_env()
{
    echo -e "Clean current env\n"
    rm ui-cookie.jar
}

#curl -I -o /dev/null -s -w %{http_code} --insecure --cookie-jar cookie.jar "https://172.16.146.130:8080/cgi-bin/ezs3/json/login?user_id=root&amp;password=${root_passwd}"
#code_status=$(curl -I -o /dev/null -s -w %{http_code} --insecure --cookie-jar cookie.jar "https://172.16.146.130:8080/cgi-bin/ezs3/json/login?user_id=root&amp;password=${root_passwd}")
#echo "status: ${code_status}"
#echo "http_code: ${http_code}"

check_network
check_apache
echo -e "Do some general checks\n"
check_license
echo -e "    Check whether the licesne number is the same as the number of nodes    [Success]\n"

create_cluster
input_license
create_and_enable_osd
enable_gw
cluster_health
clean_env

</code></pre>
]]></content>
      <categories>
        <category>curl</category>
      </categories>
      <tags>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title>磁盘加入RAID组</title>
    <url>/2016/08/28/join_disk_to_raid/</url>
    <content><![CDATA[<h1 id="bei-jing">背景</h1>
<p>测试场景中含有容灾测试，其中涉及到拔盘测试，本文以该场景为例，指导如何恢复RAID组到正常状态。</p>
<h1 id="xin-pan-jia-ru">新盘加入</h1>
<p>从RAID组中拔掉一块硬盘，重新插入一块新盘，无需执行任何megacli命令，新盘会自动加入RAID组，并处于rebuild状态，直至rebuild完成后，RAID组恢复正常。</p>
<h1 id="jiu-pan-jia-ru">旧盘加入</h1>
<p>从RAID组中拔掉一块硬盘，再重新插入这块被拔下来的磁盘，RAID组的校验机制检测到这块盘曾经是RAID组成员，之前叛变了，现在又先回归组织，需要进行身份验证，所以这块旧盘会被标记成unconfig（good）状态，需要做两个动作，来完成再加入RAID，分别是：</p>
<p>1、标记硬盘状态为config(good)</p>
<p>2、导入到RAID组</p>
<h2 id="ju-ti-cao-zuo-bu-zou-ru-xia">具体操作步骤如下：</h2>
<p>（1）获取被加入RAID组磁盘的Enclosure Device ID 和Slot Number</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -LdPdInfo -aALL</code></p>
<img class="shadow" src="/img/in-post/hdd_join_raid.png" width="800">
<p>（2）标记磁盘为unconfig（good）状态</p>
<p>如上图所示，坏了的磁盘，状态应该是unconfig（good），这里截图仅供参考。</p>
<p>假如Enclosure Device ID 为8，Slot Number为2的磁盘坏了的话，执行如下命令：</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDMakeGood -PhysDrv[8:2] -a0</code></p>
<p>将磁盘设置为good状态。</p>
<p>（3）导入RAID组</p>
<p>执行</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -CfgForeign -import -a0</code></p>
<p>命令，将步骤2中标记的盘导入raid组。</p>
<h2 id="cha-kan-raid-zu-rebuild-jin-du">查看RAID组rebuild进度</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -pdrbld -showprog -physdrv[8:2] -aALL</code></p>
]]></content>
      <categories>
        <category>RAID</category>
      </categories>
      <tags>
        <tag>RAID</tag>
      </tags>
  </entry>
  <entry>
    <title>ping test</title>
    <url>/2016/10/26/ping/</url>
    <content><![CDATA[<h1 id="overvicw">Overvicw</h1>
<p>ping the node under test to confirm whether the network can communicate properly.</p>
<h1 id="script-of-ping-test-sh">Script of ping_test.sh</h1>
<pre><code class="language-shell">#!/bin/bash

node_ip="10.10.128.2"
cmd=`ping -i 1 ${node_ip} -w 1 | grep "icmp_req=1"`

#while true
#do
#    date_time=`date +"%Y-%m-%d %H:%M:%S"`
#    echo "[${date_time}]  ${cmd}" &gt;&gt;/home/ping.log
#    sleep 1
#done

i=0


while [ ${i} -le  172800 ]
do 
    date_time=`date +"%Y-%m-%d %H:%M:%S"`
    echo "[${date_time}]  ${cmd}" &gt;&gt;/home/ping_node2.log
    sleep 1
    i=$((${i}+1))
    echo ${i}
done
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>显示ctdb VIP与物理IP映射关系</title>
    <url>/2016/11/14/show_ctdb_vip_map/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>产品UI支持存储网关上设置VIP，UI上并不会展示出这个/些VIP与物理IP之间的mapping关系。</p>
<p>故而先提供一个脚本，展示客户想知道当前VIP与物理IP间的映射关系。</p>
<h1 id="jiao-ben-nei-rong">脚本内容</h1>
<pre><code class="language-shell">#!/usr/bash

ctdb_status=`ctdb status  |grep pnn |tr -d pnn:  |awk '{print $1,$2}'|sort -nk 1  &gt; /tmp/ctdb_status.out 2&gt;&amp;1`
ctdb_ip=`ctdb ip |grep -v IP |sort -nk 2  &gt; /tmp/ctdb_ip.out 2&gt;&amp;1`

ctdb_ip_map=`join -1 1 -2 2 /tmp/ctdb_status.out /tmp/ctdb_ip.out 2&gt;&amp;1`

echo "pnn   storage ip  virtual ip"
echo "${ctdb_ip_map}\n"

</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>iSCSI自动挂载</title>
    <url>/2016/06/12/auto_mount_iscsi/</url>
    <content><![CDATA[<h1 id="gai-yao">概要</h1>
<p>本篇介绍了iscsiadm常见命令和iSCSI自动挂载的方法。</p>
<p>iscsiadm工具用于Linux连接以太网上的iSCSI设备，我们的系统中内置本工具，如果是其他OS，可能需要先安装相应包。</p>
<h1 id="an-zhuang">安装</h1>
<p>Ubuntu</p>
<pre><code class="language-shell">apt-get install open-iscsi
apt-get install open-iscsi-utils
</code></pre>
<p>CentOS</p>
<pre><code class="language-shell">yum install iscsi-initiator-utils
</code></pre>
<p>安装完成后应该会自动启动，如果没有使用service iscsi start</p>
<h1 id="shi-yong">使用</h1>
<p>常见步骤如下：</p>
<pre><code class="language-shell">iscsiadm -m discovery -t sendtargets -p {ip_address:port}
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>发现给定IP的target，port可不加，默认是3260，sendtargets可简写为st</p>
</li>
</ul>
<pre><code class="language-shell">iscsiadm -m node -T { target-name } -p { ip_address:port } -l
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>挂载iSCSI 设备</p>
</li>
</ul>
<pre><code class="language-shell">iscsiadm -m node -T { target-name } -p { ip_address:port } -u
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>卸载iSCSI 设备</p>
</li>
</ul>
<p>其他常见命令：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>查看iSCSI状态</p>
</li>
</ul>
<pre><code class="language-shell">iscsiadm -m session # 查看当前登录的session，可以带参数-P 3查看到详细信息，包括target和sdX的对应关系！
iscsiadm -m node # 查看当前已经discovery到的target
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>删除iSCSI设备</p>
</li>
</ul>
<pre><code class="language-shell">iscsiadm -m node -o delete -T { target-name } -p { ip_address:port }
</code></pre>
<p>​    可以灵活选用-p和-T，比如iscsiadm -m node -T <a href="http://iqn.2016-12.bigtera.com">iqn.2016-12.bigtera.com</a>:test -l表示挂载当前discovery到的名字是iqn.2016-12.bigtera.com:test的target，所有的IP都会被挂载到；同理，如果是iscsiadm -m node -p 192.168.1.1 -u，表示卸载192.168.1.1上的所有target；如果既没有-p，也没有-T，表示挂载/卸载所有session。</p>
<h1 id="kai-ji-zi-dong-gua-zai">开机自动挂载</h1>
<h2 id="step-1-xiu-gai-etc-iscsi-iscsid-conf">Step1、修改 “/etc/iscsi/iscsid.conf”</h2>
<p>把 node.startup 改成 automatic。(如果已经discovery了的话需要先删除target，如上述命令"删除iSCSI设备")</p>
<h2 id="step-2-zhong-xin-fa-xian">Step2、重新发现</h2>
<pre><code class="language-shell">iscsiadm -m discovery -t sendtargets -p ip
</code></pre>
<h2 id="step-3-pei-zhi-wen-jian-jian-cha">Step3、配置文件检查</h2>
<p>检查类似如下config中的startup是否是automatic，对于不同的release版本位置有所不同，举例：</p>
<h3 id="for-ubuntu">For Ubuntu</h3>
<pre><code class="language-shell">/etc/iscsi/nodes/iqnname/192.168.0.1:servername.iscsiTargetName/default
</code></pre>
<h3 id="for-centos">For Centos</h3>
<pre><code class="language-shell">/var/lib/iscsi/nodes/iqn.2001-06.com.test:storage/192.168.0.14,3260,1/default 
</code></pre>
<p>可以针对不同的session设置不同的startup策略(manual/automatic)。</p>
]]></content>
      <categories>
        <category>iSCSI</category>
      </categories>
      <tags>
        <tag>iSCSI</tag>
      </tags>
  </entry>
  <entry>
    <title>History命令打印时间</title>
    <url>/2017/01/18/history_time/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>排查问题的时候，可能需要追踪出现问题的原因，尤其是怀疑有误操作或者受到攻击的时候，history命令只会展示出命令本身。</p>
<h1 id="fang-fa">方法</h1>
<p>vim /etc/bash.bashrc 添加如下信息：</p>
<p><code>HISTTIMEFORMAT="%Y-%m-%d-%H:%M:%S: " </code></p>
<p>重新登录后，执行history结果如下：</p>
<pre><code class="language-shell">  409  2017-01-18-11:50:55: cp b c
  410  2017-01-18-11:50:55: ceph df
  411  2017-01-18-11:51:01: history
  412  2017-01-18-11:52:24: strace -e trace=file history
  413  2017-01-18-11:53:02: which history
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>EXT4修复FS error</title>
    <url>/2017/02/06/ext4_fs_fix/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>早起产品因为没有很多的控制cache flush策略，导致服务器掉电后，有比较高的概率出现EXT4 FS error，本文介绍借助 e2fsck 如何修复这部分错误。</p>
<h1 id="xiu-fu-bu-zou">修复步骤</h1>
<img class="shadow" src="/img/in-post/ext4-fs-error-fix.png" width="1200">
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Disable core dump</title>
    <url>/2017/02/17/disable_core_dump/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>有时候测试环境比较弱，资源开销比较大，一旦产生core dump file，期间会消耗CPU、memory和disk空间。为了暂时规避此问题，需要禁止产生core dump。</p>
<h1 id="cao-zuo-bu-zou">操作步骤</h1>
<h2 id="to-disable-core-dumps-for-all-users">To disable core dumps for all users</h2>
<p>open /etc/security/limits.conf, enter:</p>
<pre><code class="language-shell"># vi /etc/security/limits.conf
</code></pre>
<h2 id="make-sure-the-following-config-directive-exists">Make sure the following config directive exists</h2>
<pre><code class="language-shell">* soft core 0
* hard core 0
</code></pre>
<h2 id="save-and-close-the-file">Save and close the file</h2>
<p>Once a hard limit is set in /etc/security/limits.conf, the user cannot increase that limit within his own session. Add fs.suid_dumpable = 0 to /etc/sysctl.conf file:</p>
<pre><code class="language-shell"># echo 'fs.suid_dumpable = 0' &gt;&gt; /etc/sysctl.conf
# sysctl -p
</code></pre>
<p>This will make sure that core dumps can never be made by setuid programs.</p>
<h2 id="set-soft-limit">Set soft limit</h2>
<p>Finally, add the following to /etc/profile to set a soft limit to stop the creation of core dump files for all users (which is default and must be disabled):</p>
<pre><code class="language-shell"># echo 'ulimit -S -c 0 &gt; /dev/null 2&gt;&amp;1' &gt;&gt; /etc/profile
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>EXT3/4 FS 长度</title>
    <url>/2017/04/20/ext_fs_length/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍如何测试出EXT3/4 文件系统的长度上限。</p>
<h1 id="jiao-ben">脚本</h1>
<pre><code class="language-shell">LENTH=`for i in {1..255};do for x in a;do echo -n $x;done;done`
touch $LENTH
</code></pre>
<p>当增加到256时，touch报错，File name too long</p>
<p>linux系统下ext3文件系统内给文件/目录命名，最长只能支持127个中文字符，英文则可以支持255个字符</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Upload and download S3 Big metadata</title>
    <url>/2017/04/24/s3_big_metadata_upload_download/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>因应标，要求支持64M大小的<code>metadata</code>，所以南京Office测试一下，如何给<code>ceph S3 Object</code>上传一个比较大的<code>metadata</code>。</p>
<h1 id="jiao-ben-nei-rong">脚本内容</h1>
<p><code>s3_big_meta_data_upload_download.py</code></p>
<pre><code class="language-python">#-*-coding:UTF-8-*-

import io
import boto
import glob

import boto.s3.connection
import os
from boto.s3.key import Key
access_key ='VZRCDG5Y7JZTJLCYDZ5T'
secret_key = '8Wl8tyqSY2Url88umtlJ6zkfk5nu6tts+8GDVAx3'

META_SIZE_THREASHOLD = 2500

def upload_file_with_meta(objfile, xml_file, bucket_handle):
    ##debug print "begin upload_file with meta func,,objfile:{},xml_file:{},key:{},".format(objfile,xml_file)

    content = ""
    try:
        with io.open(xml_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        return False

    k = bucket_handle.new_key(objfile)
    ##debug print "begin upload key_name {}".format(key)
    print "length content is {}".format(len(content) )
    if len(content) &lt; META_SIZE_THREASHOLD:
        ##debug print "xml as metadata:"

        k.set_metadata("descriptions", content)
        k.set_contents_from_filename(objfile)
        print "upload finish"
    else:                                                                      
        #创建属性对象（属性对象key命名为*.MP4.meta），将xml 文件存入对象  
        external_meta = u"{}.meta".format(objfile)     
        k.set_metadata("meta1", external_meta)                                                        
        k.set_contents_from_filename(objfile)      
                                                   
        meta_k = bucket_handle.new_key(external_meta)     
        meta_k.set_contents_from_filename(xml_file)
        print "upload mp4 and xml object finish"


def download_file_with_meta(bucket_handle, key_name):
    try:
        key= bucket_handle.get_key(key_name)
        if 'descriptions' in key.metadata.keys():
            xml_content=key.metadata['descriptions']
            key.get_contents_to_filename(key.name)
            
            xml_file=key_name[:-4]+'.xml'
            with io.open(xml_file, 'w', encoding='utf-8') as f:
                f.write(xml_content)
            print "download finish"
                
        else:
            #下载对象                                           
            print key.get_contents_to_filename(key.name)
            key.get_contents_to_filename(key.name)              
                                                            
            #下载对象的属性                                        
            external_meta=key.metadata['meta1']               
            meta_key=bucket_handle.get_key(external_meta)   
            
            #属性对象下载为xml 文件，名称为xml_name                      
            xml_name=meta_key.name[:-9]+'.xml'              
            ##debug print xml_name                                  
            meta_key.get_contents_to_filename(xml_name)     
            print "download mp4 and xml object finish"
    except Exception as e:
        print str(e)

#建立连接
print "createt connection BEGIN \n"
conn = boto.connect_s3(
        aws_access_key_id = access_key,
        aws_secret_access_key = secret_key,
        host = '10.10.0.127',
        is_secure=False,    #uncomment if you are not using ssl
        calling_format = boto.s3.connection.OrdinaryCallingFormat(),
        )
print conn

print "createt connection  END\n"

bucket_name = "material"
bucket = conn.lookup(bucket_name)
if bucket == None :
    print "bucket {} is not exists".format(bucket_name)
    # 创建bucket 
    bucket = conn.create_bucket(bucket_name)
    # 再次列出所有的bucket，查看是否存在新建的bucket
    for bucket in conn.get_all_buckets():
        print "{name}\t{created}".format(
                name = bucket.name,
                created = bucket.creation_date,
                )

#查看bucket中的所有对象
print "list all the OBJECTS in bucket, empty of course"
bucket = conn.lookup(bucket_name)
for key in bucket.list():
    print "{name}\t{size}\t{modified}".format(
                name = key.name,
                size = key.size,
                modified =
                key.last_modified,
           )
print "list all the OBJECTS in bucket END\n"
   

# 上传对象的同时，设置对象的元数据信息

filelist = glob.glob("/var/share/ezfs/shareroot/material/*.mp4")
for fi in filelist:
    f_xml = fi[:-4] + ".xml"
    key = os.path.basename(fi) 
    upload_file_with_meta(fi,f_xml,bucket)
print "end filelist"


# download object
for fi in filelist:
    # key = os.path.basename(fi) 
    key = os.path.abspath(fi)
    download_file_with_meta(bucket, key)
print "enc to download object" 

</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>ESXi remount VMFS</title>
    <url>/2017/06/06/esxi_mount_vmfs/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>The ESXi product has a bug that when the cluster is restarted, the cluster is not yet in a healthy state, during which the ESXi side scans early and hangs on VMFS, but it no longer fills up after a certain number of durations; and after the cluster is restored to health, ESXi does not initiate scanning actions anymore.</p>
<p>Write a script, put it on the ESXi side, set a timed task, and initiate a scan.</p>
<h1 id="script-of-vmware-scan-remount-sh">Script of vmware_scan_remount.sh</h1>
<pre><code class="language-shell">#!/bin/sh

# add by bigtera wyz for remout vmfs at 2017-06-06 15:10
remount_log="/vmfs/volumes/datastore1 (1)/bigtera-cron/remount_vmfs.log"

echo "rescan all adapter"  &gt;&gt; ${remount_log}

for i in {1..50}
do
    echo "`date '+%Y-%m-%d %H:%M:%S'`  $i times to rescan" &gt;&gt; ${remount_log}
    esxcli storage core adapter rescan --all
    sleep 10
done

vmfs_uuid=`esxcli storage vmfs snapshot list | grep -i "vmfs uuid" | awk -F ":"
if [ ${vmfs_uuid} != "" ];then
    echo "`date '+%Y-%m-%d %H:%M:%S'`  need remount vmfs, vmfs uuid is ${vmfs_uu
    esxcli storage vmfs snapshot mount -u ${vmfs_uuid}
else
    echo "`date '+%Y-%m-%d %H:%M:%S'`  not found needed remount vmfs, skip remou
fi




min=1
max=50
while [ $min -le $max ]
do
    echo $min
    min=`expr $min + 1`
done  
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>ESXi</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>ESXi</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统空间预留</title>
    <url>/2017/06/07/os_reserved_space/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在执行df命令查看空间时，发现已使用空间与剩余空间之和，小于总空间，如下图所示：</p>
<img class="shadow" src="/img/in-post/df_space.png" width="600">
<p>图上显示，可用空间81G，已使用8G，加起来是89G，但总空间是94G，少了5G?</p>
<p>这是什么原因呢？</p>
<h1 id="mkfs-kong-jian-yu-liu">mkfs 空间预留</h1>
<p>原来mkfs的时候，默认携带 -m 参数，即默认预留5%的空间, 94G * 0.05 = 4.7G，大约是5G，与上面的计算吻合（在磁盘换算过程中由于使用的单位不同，这个有约0.02左右的误差是可能的）。</p>
<img class="shadow" src="/img/in-post/dumpe2fs.png" width="600">
<h1 id="yi-tu">意图</h1>
<p>看一下man手册：</p>
<pre><code class="language-shell">-m reserved-blocks-percentage
Specify the percentage of the filesystem blocks reserved for the
super-user.   This  avoids  fragmentation, and allows root-owned
daemons, such as syslogd(8), to continue to  function  correctly
after non-privileged processes are prevented from writing to the
filesystem.  The default percentage is 5%.
</code></pre>
<p>也就是说，ext文件系统，包括ext2、ext3、ext4都会默认预留5%的磁盘空间，留给root用户维护系统或者记录系统关键日志的时候使用(比如磁盘使用空间已经100%的情况下的处理)，这也就是导致普通用户无法使用部分磁盘空间的原因了。</p>
<h1 id="ru-he-guan-bi-yu-liu-kong-jian">如何关闭预留空间</h1>
<p>对于操作系统，这个预留是有意义的，但对于存储（比如ceph-osd ext4 data空间），如果还有5%的预留，空间就浪费了，如何关闭这个预留空间呢？ 以另外一套环境为例：</p>
<p>通过tune2fs 可以关闭文件系统空间的预留</p>
<p>关闭前：</p>
<pre><code class="language-shell">root@host244:/# df -PH
Filesystem                                Size  Used Avail Use% Mounted on
/dev/sdc3                                  99G  2.2G   92G   3% /
udev                                       34G   13k   34G   1% /dev
tmpfs                                     6.8G  5.5M  6.8G   1% /run
none                                      5.3M     0  5.3M   0% /run/lock
none                                       34G   37k   34G   1% /run/shm
</code></pre>
<p>关闭后：</p>
<pre><code class="language-shell">root@host244:/# tune2fs -h 
tune2fs 1.42 (29-Nov-2011)
tune2fs: invalid option -- 'h'
Usage: tune2fs [-c max_mounts_count] [-e errors_behavior] [-g group]
	[-i interval[d|m|w]] [-j] [-J journal_options] [-l]
	[-m reserved_blocks_percent] [-o [^]mount_options[,...]] [-p mmp_update_interval]
	[-r reserved_blocks_count] [-u user] [-C mount_count] [-L volume_label]
	[-M last_mounted_dir] [-O [^]feature[,...]]
	[-E extended-option[,...]] [-T last_check_time] [-U UUID]
	[ -I new_inode_size ] device
root@host244:/# tune2fs -m 0 /dev/sdc3 
tune2fs 1.42 (29-Nov-2011)
Setting reserved blocks percentage to 0% (0 blocks)
root@host244:/# df -PH
Filesystem                                Size  Used Avail Use% Mounted on
/dev/sdc3                                  99G  2.2G   97G   3% /
udev                                       34G   13k   34G   1% /dev
tmpfs                                     6.8G  5.5M  6.8G   1% /run
none                                      5.3M     0  5.3M   0% /run/lock
none                                       34G   37k   34G   1% /run/shm
root@host244:/# 
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Put 1Million S3 objects to bucket</title>
    <url>/2017/06/30/s3_put_100_million_objects/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>NanKing Office，test ceph S3 objects, needs to upload more than 100 million objects into the bucket,so, write a script to help me to upload the objects.</p>
<h1 id="script">Script</h1>
<p><a href="http://S3-100million-testing.py">S3-100million-testing.py</a></p>
<pre><code class="language-python">import boto
import boto.s3.connection

access_key='JZKZIF7XY46DXA71ZWJZ'
secret_key='PAMM0M1lW2UhollmLOhTIsPUspYtys8acczxa9QS'

if __name__ == "__main__":
    conn = boto.connect_s3(
           aws_access_key_id=access_key,
           aws_secret_access_key=secret_key,
           host="172.16.146.184",
           calling_format = boto.s3.connection.OrdinaryCallingFormat(),
          )
    bucket = conn.get_bucket("my-bucket")
    print bucket.name
    
    for i in range(0,10000):
        for j in range(1,101):
            key_name=str(i* 100 + j) + '.txt'
            key = bucket.new_key(key_name)
            key.set_contents_from_string(key_name)
        print "put %d objects done"%((i+1)*100)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>修复memcache 未授权访问漏洞</title>
    <url>/2017/07/30/memcache_port_limit/</url>
    <content><![CDATA[<h1 id="bei-jing-shuo-ming">背景说明</h1>
<p><code>memcache</code> 未授权访问漏洞修复，修复方法是通过系统的防火墙来禁止其他ip访问</p>
<h1 id="patch-bu-zou">patch步骤</h1>
<h2 id="1-jian-cha">1. 检查</h2>
<p>客户端确认端口访问情况，可以看到 11211 可以访问</p>
<pre><code class="language-shell">root@wyz-node2:~# telnet 10.10.10.134 11211
Trying 10.10.10.134...
Connected to 10.10.10.134.
Escape character is '^]'.
dd^H^H^H^H^C^C^C^C^C^C^C^C
</code></pre>
<h2 id="2-cun-chu-jie-dian-zeng-jia-iptable-mei-ge-jie-dian-du-yao-zuo">2. 存储节点增加iptable（每个节点都要做）</h2>
<p>注意其中ip 需要根据实际情况替换</p>
<pre><code class="language-shell">iptables -I INPUT -p tcp --dport 11211 -j DROP
iptables -I INPUT -s 127.0.0.1 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.17.73.134 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.17.73.135 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.17.73.136 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 10.10.10.134 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 10.10.10.135 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 10.10.10.136 -p tcp --dport 11211 -j ACCEPT
root@wyz:~/docker-file/first# telnet 172.17.73.134 11211
</code></pre>
<h2 id="3-xiao-guo-yan-zheng">3. 效果验证</h2>
<p>每个节点做完后，通过 客户端 telnet 11211端口，验证是否可以访问。可以看到已经无法访问了</p>
<pre><code class="language-shell">root@wyz:~/docker-file/first# telnet 172.17.73.134 11211

Trying 172.17.73.134...
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>memchche</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>memchche</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title>FTP需求汇总</title>
    <url>/2017/10/12/ftp_feature/</url>
    <content><![CDATA[<h1 id="yin-yan">引言</h1>
<p><strong>vsftpd(very secure FTP daemon)</strong>，如果你想在你的Linux/Unix服务器上搭建一个安全、高性能、稳定性好的FTP服务器，那么vsftpd可能是你的首选应用。我们的客户对FTP有需求，目前只能通过手动部署、配置的方式来实现客户的要求，工作往往重复。为了规范化FTP配置流程，本文整理一下FTP的需求，以供RD参考。</p>
<h1 id="ji-ben-pei-zhi">基本配置</h1>
<p>默认如下拥有配置项：</p>
<h2 id="1-ftp-port">(1)ftp port</h2>
<p>支持默认与非默认的修改,针对对安全有特殊要求的用户</p>
<pre><code class="language-shell">    listen_port=&lt;port&gt; :设置控制连接的监听端口号，默认为21
    connect_from_port_20=&lt;YES/NO&gt; :若为YES，则强迫FTP－DATA的数据传送使用port 20，默认YES
</code></pre>
<h2 id="2-listen-yes">(2)Listen=yes</h2>
<p>独立的VSFTPD服务器</p>
<h2 id="3-ji-lu-vsftpd-de-log">(3)记录vsftpd的log</h2>
<pre><code class="language-shell">    log_ftp_protocol=YES (all FTP requests and responses are logged)
    xferlog_enable=yes  （激活上传和下传的日志）
    xferlog_std_format=yes (使用标准的日志格式)  
</code></pre>
<h2 id="4-anon-root">(4)anon_root</h2>
<pre><code class="language-shell">    This option represents a directory  which  vsftpd  will  try  to change  into  after  an  anonymous  login.  Failure  is silently ignored.
    Default: (none)
    留给匿名账号使用。
</code></pre>
<h2 id="5-local-umask">(5)local_umask</h2>
<pre><code class="language-shell">default 022
</code></pre>
<p>建议设置成002</p>
<h2 id="6-qi-ta-mo-ren-pei-zhi-xiang">(6) 其他默认配置项</h2>
<pre><code class="language-shell">    dirmessage_enable=YES
    use_localtime=YES
    secure_chroot_dir=/var/run/vsftpd/empty
    pam_service_name=ftp
    rsa_cert_file=/etc/ssl/private/vsftpd.pem  （这项可有可无，虚拟用户访问FTP Server、PAM认证时使用）
</code></pre>
<h1 id="xu-qiu">需求</h1>
<h2 id="ni-ming-fang-wen">匿名访问</h2>
<p>说明：</p>
<p>基于安全考虑，禁止匿名用户启用SSL，即：<code>allow_anon_ssl=NO</code></p>
<h3 id="chang-jing-1-jin-you-shang-chuan-quan-xian">场景1、仅有上传权限</h3>
<h4 id="vsftpd-conf-xu-yao-xiu-gai-de-nei-rong-ru-xia">vsftpd.conf需要修改的内容如下</h4>
<pre><code class="language-shell">    anon_upload_enable=YES (开放上传权限)
    anon_mkdir_write_enable=YES（可创建目录的同时可以在此目录中上传文件）
    anon_other_write_enable=NO (匿名帐号可以有删除的权限，基于安全考虑，建议设置为NO)
    anon_root=/var/share/ezfs/shareroot/gz/ （设定匿名用户的base_home，要与/etc/passwd 中ftp用户保持一致）
    anon_umask=002
    hide_ids=YES
    no_anon_password=YES （是否询问匿名访问时输入密码）
    write_enable=yes (开放本地用户写的权限)
</code></pre>
<h4 id="ce-shi">测试</h4>
<h5 id="ftp-de-ni-ming-deng-lu-yi-ban-you-san-chong">FTP的匿名登录一般有三种：</h5>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、用户名：anonymous 密码：Email或者为空</p>
</li>
<li class="lvl-2">
<p>2、用户名：FTP 密码：FTP或者为空</p>
</li>
<li class="lvl-2">
<p>3、用户名：USER 密码：pass</p>
</li>
</ul>
<h5 id="chu-xian-ru-xia-cuo-wu">出现如下错误</h5>
<pre><code class="language-shell">    500 OOPS: vsftpd: refusing to run with writable root inside chroot()
</code></pre>
<h5 id="jie-jue-fang-fa">解决方法</h5>
<p>Bean 修改了vsftpd的source code，将vsftpd 校验根目录的写权限这部分code注释掉，从而规避这个问题。 记得patch 新的vsftpd deb。</p>
<h3 id="chang-jing-2-jin-you-xia-zai-quan-xian">场景2、仅有下载权限</h3>
<p>vsftpd.conf内容变更如下：</p>
<pre><code class="language-shell">    anonymous_enable=YES
    anon_world_readable_only=YES
    anon_root=/var/share/ezfs/shareroot/gz/
    hide_ids=YES
    no_anon_password=YES
    local_enable=YES
</code></pre>
<p>说明：</p>
<p>要注意文件夹的属性，匿名帐户是其它（other）用户来开启它的读写执行的权限</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>（R）读 – 下载</p>
</li>
<li class="lvl-2">
<p>（W）写 – 上传</p>
</li>
<li class="lvl-2">
<p>（X）执行 – 如果不开FTP的目录都进不去</p>
</li>
</ul>
<h3 id="chang-jing-3-shang-chuan-xia-zai-quan-xian-du-you">场景3、上传、下载权限都有</h3>
<p>vsftpd.conf内容变更如下：</p>
<pre><code class="language-shell">    anonymous_enable=YES
    anon_umask=002
    anon_upload_enable=YES
    anon_mkdir_write_enable=YES
    anon_other_write_enable=NO
    anon_world_readable_only=YES
    anon_root=/var/share/ezfs/shareroot/gz/
    hide_ids=YES
    no_anon_password=YES
    local_enable=YES
    write_enable=YES
</code></pre>
<h3 id="chang-jing-4-yue-shu-chuan-shu-su-lu">场景4、约束传输速率</h3>
<pre><code class="language-shell">    anon_max_rate=51200  （匿名用户的传输比率，单位b/s）
</code></pre>
<p>作为场景1、2、3的附属配置。</p>
<h3 id="chang-jing-5-geng-gai-wen-jian-shang-chuan-shu-zhu">场景5、更改文件上传属主</h3>
<p>这个作为场景3的附属配置，一旦设置了属主，文件的umask始终是600，这样，ftp用户只有上传权限，无法下载。</p>
<pre><code class="language-shell">    chown_uploads=YES
    chown_username=指定一个账号
</code></pre>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>chown_uploads=YES 情况下，anon_umask 的设置失效，上传的文件的权限始终是600</p>
</li>
<li class="lvl-2">
<p>chown_uploads=YES</p>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">这种情况下需要设置chown_username，但是你不设置也不会报错，因为系统默认给你设置了个root用户，上传上去的文件所有会是root:ftp。无论你是否设置anon_umask，上传的文件都会是600权限，很恶心，自己能上传但是不能下载。</li>
</ul>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">这种情况可用于公司开发文件上传，只要上传了你就不能修改。</li>
</ul>
</li>
<li class="lvl-2">
<p>chown_uploads=NO</p>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">这种情况下，通过修改anon_umask文件来控制匿名用户上传文件的权限，不过上传的文件所有者会变为ftp:ftp，也就是说这种情况下匿名用户总是可以修改自己上传的文件的，即使anon_umask=777，也是有权限的。</li>
</ul>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">无论在哪种情况下，上传的文件是不会拥有X，即执行权限。</li>
</ul>
</li>
</ul>
<h1 id="pu-tong-ftp-yong-hu-de-shang-chuan">普通ftp用户的上传</h1>
<h2 id="zhi-neng-shang-chuan-wu-fa-xia-zai">只能上传，无法下载</h2>
<p>vsftpd.conf内容变更如下：</p>
<pre><code class="language-shell">    anonymous_enable=NO
    local_enable=YES
    write_enable=YES
    download_enable=NO
    log_ftp_protocol=YES
    use_sendfile=NO
    local_umask=002
</code></pre>
<h2 id="pu-tong-ftp-yong-hu-de-xia-zai">普通ftp用户的下载</h2>
<p>vsftpd.conf内容变更如下：</p>
<pre><code class="language-shell">    anonymous_enable=NO
    local_enable=YES
    write_enable=NO
    download_enable=YES
    log_ftp_protocol=YES
    use_sendfile=NO
    local_umask=002
</code></pre>
<h2 id="pu-tong-ftp-yong-hu-de-shang-chuan-xia-zai">普通ftp用户的上传、下载</h2>
<p>vsftpd.conf内容变更如下：</p>
<pre><code class="language-shell">    anonymous_enable=NO
    local_enable=YES
    write_enable=YES
    log_ftp_protocol=YES
    use_sendfile=NO
    local_umask=002
</code></pre>
<h2 id="dong-jie-ftp-zhang-hao">冻结FTP账号</h2>
<p>vsftpd.conf内容增加如下配置项：</p>
<pre><code class="language-shell">    userlist_enable=YES
    userlist_deny=YES
    userlist_file=xxxPATH
</code></pre>
<p>同时，要将被冻结账号信息加入到userlist_file中</p>
<h3 id="ce-shi-1">测试</h3>
<h4 id="vsftpd-conf-zhong-zeng-jia">vsftpd.conf中增加</h4>
<pre><code class="language-shell">    userlist_enable=YES
    userlist_deny=YES
    userlist_file=/etc/vsftpd.deny_list 
</code></pre>
<h4 id="ran-hou-zeng-jia-bei-xian-zhi-zhang-hao-dao-userlist-file-zhong">然后，增加被限制账号到userlist_file中</h4>
<pre><code class="language-shell">    echo -n "guizhou" &gt; vsftpd.deny_list
</code></pre>
<h4 id="zui-hou-restart-vsftp-shi-yong-client-fang-wen-ftp-server">最后，restart vsftp，使用client 访问FTP server</h4>
<pre><code class="language-shell">    root@631:~# ftp 172.17.59.5
    Connected to 172.17.59.5.
    220 (vsFTPd 2.3.5)
    Name (172.17.59.5:root): guizhou
    530 Permission denied.
    Login failed.
    ftp&gt;
</code></pre>
<h2 id="yue-shu-ftp-yong-hu-fang-wen-mu-lu-fan-wei">约束ftp用户访问目录范围</h2>
<h3 id="yuan-yin">原因</h3>
<p>如果不约束住ftp用户的访问目录范围，任其可以访问非base_home下文件，这是非常危险的。</p>
<h3 id="yue-shu-pei-zhi">约束配置</h3>
<p>如果设置为：</p>
<pre><code class="language-shell">    chroot_local_user＝YES
    chroot_list_enable=YES(这行可以没有, 也可以有)
    chroot_list_file=/etc/vsftpd.chroot_list
</code></pre>
<p>那么, 凡是加在文件vsftpd.chroot_list中的用户都是不受限止的用户</p>
<p>即, 可以浏览其主目录的上级目录.</p>
<p>所以, 如果不希望某用户能够浏览其主目录上级目录中的内容,可以如上设置, 然后在文件vsftpd.chroot_list中不添加该用户即可(此时, 在该文件中的用户都是可以浏览其主目录之外的目录的).</p>
<p>或者, 设置如下：</p>
<pre><code class="language-shell">    chroot_local_user＝NO
    chroot_list_enable=YES(这行必须要有, 否则文件
    vsftpd.chroot_list不会起作用)
    chroot_list_file=/etc/vsftpd.chroot_list
</code></pre>
<p>然后把所有不希望有这种浏览其主目录之上的各目录权限的用户添加到文件vsftpd.chroot_list(此时, 在该文件中的用户都是不可以浏览其主目录之外的目录的)</p>
<p>中即可(一行一个用户名).</p>
<p>下图，为这两个参数的详细解释：<br>
<img class="shadow" src="/img/in-post/ftp_parameter_desc.png" width="1200"></p>
<h4 id="ce-shi-2">测试</h4>
<p>按照上面的配置，在限制住用户只能访问bash_home情况下，会出现FTP 500错误码：</p>
<pre><code class="language-shell">    root@scaler01:/var/share/ezfs/shareroot# ftp 172.17.59.5
    Connected to 172.17.59.5.
    220 (vsFTPd 2.3.5)
    Name (172.17.59.5:root): guizhou
    331 Please specify the password.
    Password:
    500 OOPS: vsftpd: refusing to run with writable root inside chroot()
    Login failed.
    ftp&gt; 
</code></pre>
<p>但如果注销掉这三个参数，则会限制住目录，一切OK。</p>
<h2 id="xian-zhi-ftp-chuan-shu-su-lu">限制ftp 传输速率</h2>
<pre><code class="language-shell">local_max_rate=5120000 （本地用户的传输比率，单位b/s ）
</code></pre>
<h2 id="xian-zhi-ip">限制IP</h2>
<p>要求：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>支持具体的IP、IP段、域名</p>
</li>
</ul>
<p>调整的内容：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>vsftpd.conf中增加：</p>
</li>
</ul>
<pre><code class="language-shell">    tcp_wrappers=YES
</code></pre>
<p>同时，要修改/etc/hosts.deny  和 /etc/hosts.allow两个文件</p>
<p>/etc/hosts.deny 中增加如下内容：</p>
<pre><code class="language-shell">    #vsftpd
    vsftpd:ALL

/etc/hosts.allow
    #vsftpd
    vsftpd:172.17.59.
</code></pre>
<h3 id="ce-shi-3">测试</h3>
<p>在/etc/hosts.deny 中增加如下内容：</p>
<pre><code class="language-shell">    #vsftpd
    vsftpd:ALL
</code></pre>
<p>在/etc/hosts.allow中增加如下内容：</p>
<pre><code class="language-shell">    #vsftpd
    vsftpd:172.19.5.
</code></pre>
<p>client访问ftp server：</p>
<pre><code class="language-shell">    root@631:~# ftp 172.17.59.5
    Connected to 172.17.59.5.
    421 Service not available.
    ftp&gt; 
</code></pre>
<p>vsftpd的log显示：</p>
<pre><code class="language-shell">    Thu Oct 12 14:46:44 2017 [pid 2] CONNECT: Client "172.17.59.8", "Connection refused: tcp_wrappers denial."
    Thu Oct 12 14:46:44 2017 [pid 2] FTP response: Client "172.17.59.8", "421 Service not available."
</code></pre>
<p>说明：</p>
<p>/etc/hosts.allow 内容格式与要求，示例如下：</p>
<pre><code class="language-shell">    vsftpd:.hype.com
    vsftpd:172.17.59.
    vsftpd:172.17.0.0/255.255.254.0
</code></pre>
<p>第一行表示，只有hype.com这个域里的主机允许访问vsftpd服务，注意hype.com前面的那个点(.)；</p>
<p>第二行表示，只有172.17.59这个网段的用户允许访问vsftpd服务，注意0后面的点(.)；</p>
<p>第三行表示，只有172.17.0这个网段的用户允许访问vsftpd服务，注意这里不能写为172.17.0.0/24。</p>
<h2 id="ftp-tls-jia-mi-chuan-shu">ftp TLS加密传输</h2>
<h3 id="wei-jia-mi-chuan-shu-qing-kuang-xia-zhi-jie-zhua-bao">未加密传输情况下，直接抓包：</h3>
<pre><code class="language-shell">    1146	7.562069	172.17.59.8	172.17.59.5	FTP	74	Request: PASS 1
</code></pre>
<img class="shadow" src="/img/in-post/ftp_tcpdump.png" widtgh="1200">
<p>上面一行为抓包到的内容，可以明确的看出，密码为1，明文的，风险系数较高</p>
<h3 id="xian-que-ren-vsftpd-shi-fou-zhi-chi-ssl-ren-zheng">先确认，vsftpd是否支持SSL认证：</h3>
<pre><code class="language-shell">    root@scaler01:/etc# ldd /usr/sbin/vsftpd |grep libssl
	libssl.so.1.0.0 =&gt; /lib/x86_64-linux-gnu/libssl.so.1.0.0 (0x00007fc154eb4000)
</code></pre>
<p>出现类似如上信息，表明支持SSL。</p>
<h3 id="sheng-cheng-vsftpd-pem-zheng-shu">生成vsftpd.pem 证书</h3>
<pre><code class="language-shell">    root@scaler01:/etc/ssl/private# openssl req -x509 -nodes -days 365 -newkey rsa:1024 \-keyout /etc/ssl/private/vsftpd.pem \-out /etc/ssl/private/vsftpd.pem
    Generating a 1024 bit RSA private key
    ................++++++
    .............................++++++
    writing new private key to '/etc/ssl/private/vsftpd.pem'
    -----
    You are about to be asked to enter information that will be incorporated
    into your certificate request.
    What you are about to enter is what is called a Distinguished Name or a DN.
    There are quite a few fields but you can leave some blank
    For some fields there will be a default value,
    If you enter '.', the field will be left blank.
    -----
    Country Name (2 letter code) [AU]:CN
    State or Province Name (full name) [Some-State]:shanghai
    Locality Name (eg, city) []:nanjing
    Organization Name (eg, company) [Internet Widgits Pty Ltd]:bigtera
    Organizational Unit Name (eg, section) []:bigtera
    Common Name (e.g. server FQDN or YOUR name) []:virtualstor
    Email Address []:virtualstor@bigtera.com.cn

</code></pre>
<p>vsftpd.conf的设置</p>
<pre><code class="language-shell">    ssl_enable=YES
    allow_anon_ssl=NO
    force_local_data_ssl=YES
    force_local_logins_ssl=YES
    ssl_tlsv1=YES
    ssl_sslv2=NO
    ssl_sslv3=NO
    rsa_cert_file=/etc/ssl/private/vsftpd.pem
</code></pre>
<h3 id="ce-shi-4">测试</h3>
<pre><code class="language-shell">    root@631:~# ftp 172.17.59.5
    Connected to 172.17.59.5.
    220 (vsFTPd 2.3.5)
    Name (172.17.59.5:root): guizhou
    530 Non-anonymous sessions must use encryption.
    Login failed.
    421 Service not available, remote server has closed connection
    ftp&gt; 
</code></pre>
<p>说明已经启用了认证，client无法访问FTP server。</p>
<p>这里，可以下载flashftp工具，测试一下。<br>
<img class="shadow" src="/img/in-post/ftp_Accept_key.png" widtgh="1200"></p>
<p>在开启SSL认证情况下抓包：<br>
<img class="shadow" src="/img/in-post/ftp_tcp_desc.png" widtgh="1200"></p>
<h1 id="can-kao-wen-dang">参考文档</h1>
<p><a href="http://manpages.ubuntu.com/manpages/trusty/man5/vsftpd.conf.5.html">http://manpages.ubuntu.com/manpages/trusty/man5/vsftpd.conf.5.html</a></p>
<p><a href="http://os.51cto.com/art/201008/221842_all.htm">http://os.51cto.com/art/201008/221842_all.htm</a></p>
<p><a href="http://viong.blog.51cto.com/844766/261354">http://viong.blog.51cto.com/844766/261354</a></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>FTP</category>
      </categories>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title>IOPS计算</title>
    <url>/2017/09/13/calc_iops/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文概述如何根据硬盘，来推算IOPS。</p>
<h1 id="ji-jie-ying-pan">机械硬盘</h1>
<pre><code class="language-shell">7200硬盘IOPS = 1000/(3 + 1000*(7200/60)/2) = 140
10k硬盘IOPS = 1000/(3 + 60000/10000/2) = 167
15k硬盘IOPS = 1000/(3 + 60000/15000/2) = 200
</code></pre>
<p>其中3为寻道延迟，7200/10k/15k为转速（rpm），1000*(7200/60)/2为旋转延迟（旋转延迟一般用转一圈所需时间的1/2表示），结果为理论峰值，实际还会有系统延迟导致测得IOPS一般低于此值。</p>
<h1 id="raid-zu">RAID组</h1>
<p>由于RAID组需要校验以提供恢复功能，所以会存在一定写惩罚（一个业务写操作对应实际硬盘的I/O操作，可以参考<a href="https://community.emc.com/docs/DOC-26624%EF%BC%89%EF%BC%8C%E8%BF%99%E4%B8%AA%E7%B3%BB%E6%95%B0%E5%A6%82%E4%B8%8B%EF%BC%9A">https://community.emc.com/docs/DOC-26624），这个系数如下：</a></p>
<pre><code class="language-shell">RAID0: 1
RAID1: 2
RAID5: 4
RAID6: 6
RAID1-0: 2
</code></pre>
<p>所以RAID组IOPS = 硬盘写IOPS<em>硬盘数量</em>写操作百分比/写惩罚系数 + 硬盘读IOPS<em>硬盘数量</em>读操作百分比。</p>
<p>以4块IOPS为180的SAS硬盘组RAID 6然后百分百随机写操作为例：</p>
<p><code>IOPS = 180*4/6 = 120 </code></p>
<p>为方便大家，笔者在此提供一个网站供大家参考使用，里面包括RAID、备份、虚拟化、IP等多种计算工具，<a href="http://wintelguy.com/raidperf.pl%E3%80%82">http://wintelguy.com/raidperf.pl。</a></p>
<p>Ceph的IOPS经验公式</p>
<p>由于Ceph存储结构不同于物理硬件，所以影响其IOPS的因素主要有网络、副本数量、日志、OSD（硬盘）数量、OSD服务器数量、OSD IOPS等，这里给出一个来自Mirantis的经验公式：</p>
<p>IOPS = 硬盘IOPS * 硬盘数量 * 0.88 / 副本数量</p>
<p>其中0.88为4-8k随机读操作占比（88%），如果OSD不是以硬盘为单位而是RAID组，则替换公式中对应参数。</p>
<p>关于Ceph的IOPS计算仅供参考，计算结果可能会跟物理环境实测有较大偏差。</p>
]]></content>
      <categories>
        <category>RAID</category>
        <category>Disk</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>RAID</tag>
      </tags>
  </entry>
  <entry>
    <title>gdisk分区</title>
    <url>/2017/11/13/gdisk_partition_disk_device/</url>
    <content><![CDATA[<h1 id="yin-yan">引言</h1>
<p>对磁盘分区除了使用parted，还可以使用gdisk工具，不过gdisk只支持GPT格式的分区表，不过目前来说已经很少用到MBR了（由于其有2T的size限制）。</p>
<h1 id="cao-zuo-shi-li">操作示例</h1>
<p>需求1： 将sdb分成三个区，第一个分区是32G，第二个分区也是32G，剩下的是第三个分区</p>
<p>步骤：</p>
<pre><code class="language-shell">  gdisk /dev/sdb
  &gt; o (y)     # 重建GPT分区表
  &gt; n         # 分第一个分区，分区序号都使用默认即可，选择合适的开始扇区和结束扇区，这里结束扇区用+{offset}表示
  &gt; &lt;Enter&gt;
  &gt; 1M
  &gt; +32G
  &gt; &lt;Enter&gt;
  &gt; n         # 分第二个分区，在选择起始扇区时默认是紧接着上个分区
  &gt; &lt;Enter&gt;
  &gt; &lt;Enter&gt;
  &gt; +32G
  &gt; &lt;Enter&gt;
  &gt; n         # 分第三个分区时都使用默认即可
  &gt; &lt;Enter&gt;
  &gt; &lt;Enter&gt;
  &gt; &lt;Enter&gt;
  &gt; &lt;Enter&gt;
  &gt; w (y)     # 最后别忘了要写入才能生效
</code></pre>
<p>需求2： 删除第二个分区，将第三个分区的分区名改为osd-data</p>
<p>步骤：</p>
<pre><code class="language-shell">gdisk /dev/sdb
&gt; d         # 删除分区
&gt; 2
&gt; c         # 修改分区名
&gt; 3
&gt; osd-data
&gt; w (y)
</code></pre>
<h1 id="fei-jiao-hu-shi">非交互式</h1>
<p>顺便介绍另一个工具sgdisk，相较于gdisk，它不需要交互式配置，只需要把所有参数一次给齐，因此更适合脚本使用。</p>
<p>比如上述示例如果用sgdisk，只需要如下两行代码：</p>
<pre><code class="language-shell">sgdisk -Z /dev/sdb # 清空分区表 
sgdisk /dev/sdb -n 1:1M:+32G -n 2:0:+32G -N 3
</code></pre>
<p>提示</p>
<p>对于MPIO的场景，使用parted分区会和multipath有冲突，有可能导致OSD建立失败，因此墙裂建议使用GPT分区。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>gdisk</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>gdisk</tag>
      </tags>
  </entry>
  <entry>
    <title>使用s3cmd操作对象</title>
    <url>/2017/12/30/use_s3cmd_access_s3_object/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>ceph 天然支持对象存储，经常使用XShell访问server，习惯了在console里做一些操作，那么，如何</p>
<h1 id="huo-qu-s-3-key">获取S3 key</h1>
<p>ceph提供radosg-admin命令，方便查询S3账号的属性信息，诸如ACL，quota，AKEY，SKEY等等一些信息，如下所示：</p>
<pre><code class="language-shell">root@auto-70-1:~# radosgw-admin --uid=user01 user info
{
    "user_id": "user01",
    "display_name": "user01",
    "email": "user01@126.com",
    "suspended": 0,
    "max_buckets": 1000,
    "auid": 0,
    "subusers": [
        {
            "id": "user01:user01",
            "permissions": "full-control"
        }
    ],
    "keys": [
        {
            "user": "user01",
            "access_key": "4B2DT6E0B9C5R6MJ8OEA",
            "secret_key": "XI5ZxYejXiZXUJWtzLDEs4OXiGOYVDuoXVhBYtIa"
        }
    ],
    "swift_keys": [
        {
            "user": "user01",
            "secret_key": "1"
        },
        {
            "user": "user01:user01",
            "secret_key": "1"
        }
    ],
    "caps": [],
    "op_mask": "read, write, delete",
    "default_placement": "",
    "placement_tags": [],
    "bucket_quota": {
        "enabled": false,
        "max_size_kb": -1,
        "max_objects": -1
    },
    "user_quota": {
        "enabled": false,
        "max_size_kb": -1,
        "max_objects": -1
    },
    "temp_url_keys": []
}

root@auto-70-1:~# 
</code></pre>
<h1 id="pei-zhi-s-3-cmd-config">配置s3cmd config</h1>
<p>通过上面获取到的AKEY和SKEY，就可以进行s3cmd的配置操作了。</p>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd --configure

Enter new values or accept defaults in brackets with Enter.
Refer to user manual for detailed description of all options.

Access key and Secret key are your identifiers for Amazon S3
Access Key: 4B2DT6E0B9C5R6MJ8OEA
Secret Key: XI5ZxYejXiZXUJWtzLDEs4OXiGOYVDuoXVhBYtIa

Encryption password is used to protect your files from reading
by unauthorized persons while in transfer to S3
Encryption password: 
Path to GPG program [/usr/bin/gpg]: 

When using secure HTTPS protocol all communication with Amazon S3
servers is protected from 3rd party eavesdropping. This method is
slower than plain HTTP and can't be used if you're behind a proxy
Use HTTPS protocol [No]: 

On some networks all internet access must go through a HTTP proxy.
Try setting it here if you can't conect to S3 directly
HTTP Proxy server name: 

New settings:
  Access Key: 4B2DT6E0B9C5R6MJ8OEA
  Secret Key: XI5ZxYejXiZXUJWtzLDEs4OXiGOYVDuoXVhBYtIa
  Encryption password: 
  Path to GPG program: /usr/bin/gpg
  Use HTTPS protocol: False
  HTTP Proxy server name: 
  HTTP Proxy server port: 0

Test access with supplied credentials? [Y/n] n

Save settings? [y/N] y
Configuration saved to '/root/.s3cfg'
root@auto-70-1:~#
</code></pre>
<h1 id="xiu-gai-s-3-conf">修改.s3conf</h1>
<p>从上面可以看出，会生成用户的配置文件/root/.s3cfg,但是标准的s3是amazon提供的，因此：</p>
<pre><code class="language-shell">host_base = s3.amazonaws.com
host_bucket = %(bucket)s.s3.amazonaws.com
</code></pre>
<p>显然，如果不修改配置文件，就会访问官方正式的amazon s3 服务，而ceph提供的是兼容服务，比如让web service请求发送到ceph集群中的某个主机，或者ceph 集群提供的域名。</p>
<p>因此将上面两行中的s3.amazonaws.com改成集群中的IP或者集群提供的域名.</p>
<p><code>:%s/s3.amazonaws.com/192.168.7.105/g </code></p>
<p>至此，就可以通过s3cmd正常访问对象存储了。</p>
<h1 id="cao-zuo-bucket">操作bucket</h1>
<h2 id="chuang-jian-bucket">创建Bucket</h2>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd mb s3://bench
Bucket 's3://bench/' created
root@auto-70-1:~#
</code></pre>
<h2 id="cha-kan-dang-qian-s-3-zhang-hao-xia-you-na-xie-bucket">查看当前S3账号下有哪些bucket</h2>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd ls
2017-12-30 06:54  s3://bench
</code></pre>
<h2 id="shang-chuan-dui-xiang">上传对象</h2>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd put /var/log/syslog s3://bench
/var/log/syslog -&gt; s3://bench/syslog  [1 of 1]
 732743 of 732743   100% in    0s    10.42 MB/s  done
</code></pre>
<h2 id="lie-chu-bucket-xia-you-na-xie-dui-xiang">列出bucket下有哪些对象</h2>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd ls s3://bench
2017-12-30 08:09    732743   s3://bench/syslog
</code></pre>
<h2 id="xia-zai-dui-xiang">下载对象</h2>
<pre><code class="language-shell">root@auto-70-1:~# mkdir download
root@auto-70-1:~# cd download
root@auto-70-1:~/download# s3cmd get s3://bench/syslog
s3://bench/syslog -&gt; ./syslog  [1 of 1]
 732743 of 732743   100% in    0s    31.35 MB/s  done
root@auto-70-1:~/download# ls -l
total 716
-rw-r--r-- 1 root root 732743 Dec 30 16:11 syslog
root@auto-70-1:~/download# md5sum syslog 
07e6f89c26d60ec499a203366ba24d55  syslog
root@auto-70-1:~/download# s3cmd info s3://bench/syslog
s3://bench/syslog (object):
   File size: 732743
   Last mod:  Mon, 30 Dec 2017 08:09:39 GMT
   MIME type: binary/octet-stream
   MD5 sum:   07e6f89c26d60ec499a203366ba24d55
   ACL:       user01: FULL_CONTROL
root@auto-70-1:~/download#
</code></pre>
<h2 id="huo-qu-bucket-kong-jian">获取bucket空间</h2>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd du s3://bench
336277063 s3://bench/
root@auto-70-1:~# 
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>单位是byte，336277063大约是330M</p>
</li>
</ul>
<h2 id="huo-qu-bucket-huo-zhe-dui-xiang-de-stat-xin-xi">获取bucket或者对象的stat信息</h2>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd info s3://bench/syslog
s3://bench/syslog (object):
   File size: 732743
   Last mod:  Mon, 30 Dec 2017 08:09:39 GMT
   MIME type: binary/octet-stream
   MD5 sum:   07e6f89c26d60ec499a203366ba24d55
   ACL:       user01: FULL_CONTROL
root@auto-70-1:~# 
</code></pre>
<h2 id="kao-bei-huo-zhe-move-shu-ju">拷贝或者move数据</h2>
<h3 id="copy-object">copy object</h3>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd del s3://bench/benchmark_data_auto-70-1_839993_object9
File s3://bench/benchmark_data_auto-70-1_839993_object9 deleted
root@auto-70-1:~# 
</code></pre>
<h3 id="move-object">move object</h3>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd ls s3://bucket01;s3cmd mv s3://bench/benchmark_data_auto-70-1_839993_object8 s3://bucket01; s3cmd ls s3://bench | grep *839993_object8
2017-12-30 08:21    732743   s3://bucket01/syslog
File s3://bench/benchmark_data_auto-70-1_839993_object8 moved to s3://bucket01/benchmark_data_auto-70-1_839993_object8
root@auto-70-1:~# 
</code></pre>
<h2 id="shan-chu-s-3-object">删除S3 object</h2>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd mb s3://bucket01
Bucket 's3://bucket01/' created
root@auto-70-1:~# s3cmd cp s3://bench/syslog s3://bucket01
File s3://bench/syslog copied to s3://bucket01/syslog
root@auto-70-1:~# s3cmd ls s3://bucket01
2017-12-30 08:21    732743   s3://bucket01/syslog
root@auto-70-1:~# 
</code></pre>
<h1 id="geng-xiang-xi-de-xin-xi-yu-cao-zuo-ke-can-kan-s-3-cmd-cao-zuo-shou-ce">更详细的信息与操作，可参看s3cmd操作手册</h1>
<pre><code class="language-shell">root@auto-70-1:~# s3cmd -h
Usage: s3cmd [options] COMMAND [parameters]

S3cmd is a tool for managing objects in Amazon S3 storage. It allows for
making and removing "buckets" and uploading, downloading and removing
"objects" from these buckets.

Options:
  -h, --help            show this help message and exit
  --configure           Invoke interactive (re)configuration tool.
  -c FILE, --config=FILE
                        Config file name. Defaults to /root/.s3cfg
  --dump-config         Dump current configuration after parsing config files
                        and command line options and exit.
  -n, --dry-run         Only show what should be uploaded or downloaded but
                        don't actually do it. May still perform S3 requests to
                        get bucket listings and other information though (only
                        for file transfer commands)
  -e, --encrypt         Encrypt files before uploading to S3.
  --no-encrypt          Don't encrypt files.
  -f, --force           Force overwrite and other dangerous operations.
  --continue            Continue getting a partially downloaded file (only for
                        [get] command).
  --skip-existing       Skip over files that exist at the destination (only
                        for [get] and [sync] commands).
  -r, --recursive       Recursive upload, download or removal.
  -P, --acl-public      Store objects with ACL allowing read for anyone.
  --acl-private         Store objects with default ACL allowing access for you
                        only.
  --delete-removed      Delete remote objects with no corresponding local file
                        [sync]
  --no-delete-removed   Don't delete remote objects.
  -p, --preserve        Preserve filesystem attributes (mode, ownership,
                        timestamps). Default for [sync] command.
  --no-preserve         Don't store FS attributes
  --exclude=GLOB        Filenames and paths matching GLOB will be excluded
                        from sync
  --exclude-from=FILE   Read --exclude GLOBs from FILE
  --rexclude=REGEXP     Filenames and paths matching REGEXP (regular
                        expression) will be excluded from sync
  --rexclude-from=FILE  Read --rexclude REGEXPs from FILE
  --include=GLOB        Filenames and paths matching GLOB will be included
                        even if previously excluded by one of
                        --(r)exclude(-from) patterns
  --include-from=FILE   Read --include GLOBs from FILE
  --rinclude=REGEXP     Same as --include but uses REGEXP (regular expression)
                        instead of GLOB
  --rinclude-from=FILE  Read --rinclude REGEXPs from FILE
  --bucket-location=BUCKET_LOCATION
                        Datacentre to create bucket in. Either EU or US
                        (default)
  -m MIME/TYPE, --mime-type=MIME/TYPE
                        Default MIME-type to be set for objects stored.
  -M, --guess-mime-type
                        Guess MIME-type of files by their extension. Falls
                        back to default MIME-Type as specified by --mime-type
                        option
  --add-header=NAME:VALUE
                        Add a given HTTP header to the upload request. Can be
                        used multiple times. For instance set 'Expires' or
                        'Cache-Control' headers (or both) using this options
                        if you like.
  --encoding=ENCODING   Override autodetected terminal and filesystem encoding
                        (character set). Autodetected: UTF-8
  --verbatim            Use the S3 name as given on the command line. No pre-
                        processing, encoding, etc. Use with caution!
  --list-md5            Include MD5 sums in bucket listings (only for 'ls'
                        command).
  -H, --human-readable-sizes
                        Print sizes in human readable form (eg 1kB instead of
                        1234).
  --progress            Display progress meter (default on TTY).
  --no-progress         Don't display progress meter (default on non-TTY).
  --enable              Enable given CloudFront distribution (only for
                        [cfmodify] command)
  --disable             Enable given CloudFront distribution (only for
                        [cfmodify] command)
  --cf-add-cname=CNAME  Add given CNAME to a CloudFront distribution (only for
                        [cfcreate] and [cfmodify] commands)
  --cf-remove-cname=CNAME
                        Remove given CNAME from a CloudFront distribution
                        (only for [cfmodify] command)
  --cf-comment=COMMENT  Set COMMENT for a given CloudFront distribution (only
                        for [cfcreate] and [cfmodify] commands)
  -v, --verbose         Enable verbose output.
  -d, --debug           Enable debug output.
  --version             Show s3cmd version (0.9.9.91) and exit.

Commands:
  Make bucket
      s3cmd mb s3://BUCKET
  Remove bucket
      s3cmd rb s3://BUCKET
  List objects or buckets
      s3cmd ls [s3://BUCKET[/PREFIX]]
  List all object in all buckets
      s3cmd la 
  Put file into bucket
      s3cmd put FILE [FILE...] s3://BUCKET[/PREFIX]
  Get file from bucket
      s3cmd get s3://BUCKET/OBJECT LOCAL_FILE
  Delete file from bucket
      s3cmd del s3://BUCKET/OBJECT
  Synchronize a directory tree to S3
      s3cmd sync LOCAL_DIR s3://BUCKET[/PREFIX] or s3://BUCKET[/PREFIX] LOCAL_DIR
  Disk usage by buckets
      s3cmd du [s3://BUCKET[/PREFIX]]
  Get various information about Buckets or Files
      s3cmd info s3://BUCKET[/OBJECT]
  Copy object
      s3cmd cp s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]
  Move object
      s3cmd mv s3://BUCKET1/OBJECT1 s3://BUCKET2[/OBJECT2]
  Modify Access control list for Bucket or Files
      s3cmd setacl s3://BUCKET[/OBJECT]
  Sign arbitrary string using the secret key
      s3cmd sign STRING-TO-SIGN
  Fix invalid file names in a bucket
      s3cmd fixbucket s3://BUCKET[/PREFIX]
  List CloudFront distribution points
      s3cmd cflist 
  Display CloudFront distribution point parameters
      s3cmd cfinfo [cf://DIST_ID]
  Create CloudFront distribution point
      s3cmd cfcreate s3://BUCKET
  Delete CloudFront distribution point
      s3cmd cfdelete cf://DIST_ID
  Change CloudFront distribution point parameters
      s3cmd cfmodify cf://DIST_ID

See program homepage for more information at
http://s3tools.org

root@auto-70-1:~# 
</code></pre>
]]></content>
      <categories>
        <category>ceph</category>
        <category>S3</category>
      </categories>
      <tags>
        <tag>s3cmd</tag>
        <tag>S3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python文件操作：&#39;with open()&#39;与&#39;open()&#39;的区别</title>
    <url>/2018/01/29/python_open_with_open/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在Python中，文件操作是非常常见的任务，Python提供了<code>open()</code>函数和<code>with</code>语句。<code>with open()</code>与<code>open()</code>在文件操作中有什么区别呢？</p>
<h1 id="code-open-code-han-shu"><code>open()</code>函数</h1>
<p><code>open()</code>函数是Python内置的用于打开文件的函数。它接受两个参数：文件名和模式。模式可以是<code>'r'</code>（只读，默认值），<code>'w'</code>（写入，如果文件存在则清空内容），<code>'a'</code>（追加，如果文件存在则在末尾追加内容）或<code>'x'</code>（创建，如果文件存在则返回错误）。</p>
<p>详细模式信息如下：</p>
<table>
<thead>
<tr>
<th>模式</th>
<th>可做操作</th>
<th>若文件不存在</th>
<th>是否覆盖</th>
</tr>
</thead>
<tbody>
<tr>
<td>r</td>
<td>只读</td>
<td>error</td>
<td>-</td>
</tr>
<tr>
<td>r+</td>
<td>读写</td>
<td>error</td>
<td>是</td>
</tr>
<tr>
<td>w</td>
<td>只写</td>
<td>create</td>
<td>是</td>
</tr>
<tr>
<td>w+</td>
<td>读写</td>
<td>create</td>
<td>是</td>
</tr>
<tr>
<td>a</td>
<td>只写</td>
<td>create，尾部追加写</td>
<td></td>
</tr>
<tr>
<td>a+</td>
<td>读写</td>
<td>create</td>
<td>否，尾部追加写</td>
</tr>
<tr>
<td>wb</td>
<td>只写二进制字符串，写入bytes</td>
<td>create</td>
<td>是</td>
</tr>
<tr>
<td>rb</td>
<td>只读二进制字符串，返回bytes</td>
<td>error</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>使用<code>open()</code>函数打开文件后，你可以使用文件对象的<code>read()</code>、<code>write()</code>、<code>close()</code>等方法进行文件操作。</p>
<p>示例：</p>
<pre><code class="language-python">file = open('example.txt', 'r')
content = file.read()
file.close()
</code></pre>
<h1 id="code-with-open-code-yu-ju"><code>with open()</code>语句</h1>
<p><code>with open</code>语句是Python中一种简洁的文件操作方式。它使用<code>with</code>关键字和<code>open()</code>函数，可以简化文件操作的代码。<code>with open</code>语句会在执行完文件操作后自动关闭文件，避免了手动关闭文件的操作。</p>
<p>使用<code>with open</code>语句时，不需要指定文件名和模式，只需将文件名和模式作为<code>open()</code>函数的参数即可。</p>
<p>示例：</p>
<pre><code class="language-python">with open('example.txt', 'r') as file:
    content = file.read()
</code></pre>
<p>上述示例代码，与如下代码效果同样：</p>
<pre><code class="language-python">try:
    file = open('example.txt', 'r')
    file.read()
finally:
    if file:
        file.close()
</code></pre>
<p>一对比，<code>with open</code>更简洁。</p>
<h1 id="code-with-open-code-yu-code-open-code-de-qu-bie"><code>with open()</code>与<code>open()</code>的区别</h1>
<p><code>with open</code>语句与<code>open()</code>函数在文件操作上有很多相似之处，但它们之间有几个重要的区别：</p>
<ol>
<li class="lvl-3">
<p>自动关闭：<code>with open</code>语句会在退出<code>with</code>块时自动关闭文件，而<code>open()</code>函数需要手动调用<code>close()</code>方法关闭文件。</p>
</li>
<li class="lvl-3">
<p>上下文管理：<code>with open</code>语句使用了上下文管理器，可以更好地处理异常和资源管理。在<code>with</code>块中发生的异常会被传递到<code>with</code>语句之外，而<code>open()</code>函数的异常则需要在文件操作中处理。</p>
</li>
<li class="lvl-3">
<p>代码可读性：<code>with open</code>语句使代码更简洁，可读性更强。它避免了手动关闭文件和处理异常的繁琐操作。</p>
</li>
</ol>
<p>摘抄自网络上的解释：</p>
<pre><code class="language-shell">Unlike `open()` where you have to close the file with the `close()` method, the `with` statement closes the file for you without you telling it to.

This is because the `with` statement calls 2 built-in methods behind the scene – `__enter()__` and `__exit()__`.

The `__exit()__` method closes the file when the operation you specify is done.
</code></pre>
<h1 id="guan-yu-shang-xia-wen">关于上下文</h1>
<p>在Python中，<code>__exit__()</code>和<code>__entry__()</code>是面向对象的编程语言特性，称为“特殊方法”。它们主要用于定义对象在进入和退出上下文管理器（如<code>with</code>语句）时的行为。</p>
<p><code>__exit__()</code>方法在对象离开上下文管理器时被调用，而<code>__entry__()</code>方法在对象进入上下文管理器时被调用。这两个方法可以用于执行资源清理、状态管理或其他需要在进入和退出上下文管理器时执行的操作。</p>
<p>以下是一个简单的例子，说明如何在Python中使用<code>__exit__()</code>和<code>__entry__()</code>方法：</p>
<pre><code class="language-python">class MyContext:
    def __init__(self):
        self.count = 0

    def __entry__(self):
        print("Entering context")

    def __exit__(self, exc_type, exc_val, exc_tb):
        print("Exiting context")
        self.count += 1
        return False  # 返回False表示异常应该被继续传播

# 使用with语句
with MyContext() as ctx:
    print("Inside with block")
    raise ValueError("An error occurred")

print("After with block")
</code></pre>
<p>输出：</p>
<pre><code class="language-shell">Entering context
Inside with block
Exiting context
1
After with block
</code></pre>
<p>在这个例子中，定义了一个名为<code>MyContext</code>的类，该类具有<code>__entry__()</code>和<code>__exit__()</code>方法。当我们使用<code>with</code>语句创建一个<code>MyContext</code>对象的上下文管理器时，<code>__entry__()</code>方法会在进入上下文管理器时被调用，而<code>__exit__()</code>方法会在离开上下文管理器时被调用。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python文件操作：大文件的读</title>
    <url>/2018/02/06/python_open_big_file/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>上一篇介绍了文件的open与 with open的区别，此篇介绍下如何读取大文件，避免MemoryError之类的错误（比如说VM内存4G，读取10GiB大小的文件）。</p>
<h1 id="wen-jian-du-qu-fang-shi">文件读取方式</h1>
<table>
<thead>
<tr>
<th>method</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>read()</td>
<td>一次性<strong>读取整个文件内容</strong>。推荐使用read(size)方法，size越大运行时间越长</td>
</tr>
<tr>
<td>readline()</td>
<td>每次<strong>读取一行</strong>内容。内存不够时使用，一般不太用</td>
</tr>
<tr>
<td>readlines()</td>
<td>一次性<strong>读取整个文件内容</strong>，并按行返回到list，方便我们遍历</td>
</tr>
</tbody>
</table>
<p>从介绍的几种method来看，read() 与  readlines() 都是读取文件的全部内容，遇到大文件不能按常规方法直接使用。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="du-qu-da-wen-jian">读取大文件</h2>
<p>准备了一个大小为2067MiB的大文件进行测试：</p>
<pre><code class="language-shell">root@scaler80:/mnt/code# du -m ./big_file.txt 
2067	./big_file.txt
</code></pre>
<p>测试脚本如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import os
import time
import psutil

# from memory_profiler import profile

def time_diff(func):
    def wrapper():
        start_time = time.time()
        func()
        end_time = time.time()
        time_diff= end_time - start_time
        print("Time diff : {}".format('%.4f s' % (time_diff)))

    return wrapper


def get_memory_usage(func):
    def wrapper():
        before_used = float(psutil.swap_memory().free) / 1024 / 1024 / 1024
        func()
        after_used = float(psutil.swap_memory().free) / 1024 / 1024 / 1024
        print("Memory diff : {}".format('%.4f GB' % (after_used - before_used)))
    return wrapper

@time_diff
@get_memory_usage
def open_file_test():
    file_name = r"D:\big_file.txt"
    with open(file_name, "r") as f:
        f.read()


if __name__ == "__main__":
    open_file_test()
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">root@scaler80:/mnt/code# python time_diff.py
Memory diff : 1.0151 GB
Time diff : 6.3894 s

root@scaler80:/mnt/code# 
</code></pre>
<p>从测试效果看，整个读取过程，文件占用了1.0151 GB的内存，耗时6.3894秒。</p>
<p>优化一下看看效果：</p>
<pre><code class="language-python">@time_diff
@get_memory_usage
def open_file_test():
    chunk_size = 1024 * 1024
    file_name = r"D:\big_file.txt"
    with open(file_name, "r") as f:
        f.read(chunk_size)
</code></pre>
<p>执行效果：</p>
<pre><code class="language-shell">root@scaler80:/mnt/code# python time_diff.py
Memory diff : 0.0000 GB
Time diff : 0.1323 s
</code></pre>
<p>再次优化:</p>
<pre><code class="language-python">def chunked_file_reader(file, block_size=1024 * 1024):
    for chunk in iter(partial(file.read, block_size), ''):
        yield chunk


@time_diff
@get_memory_usage
def open_file_test():
    file_name = r"D:\big_file.txt"
    with open(file_name, "r") as f:
        chunked_file_reader(f)
</code></pre>
<p>效果如下：</p>
<pre><code class="language-shell">root@scaler80:/mnt/code# python time_diff.py
Memory diff : 0.0000 GB
Time diff : 0.1168 s

root@scaler80:/mnt/code# 
</code></pre>
<p>最后两个优化基本上没差。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次memcache安全漏洞修复记录</title>
    <url>/2018/03/02/security_of_memcache/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>分布式高速缓存系统Memcache存在高危安全漏洞，攻击者可利用该漏洞实施分布式反射拒绝服务（DRDoS）攻击。恶意攻击者向网络服务器发送大量伪造源IP地址的UDP协议数据包，这些源IP地址即为被攻击目标地址。服务器根据Memcache协议内容向源IP地址回复大量数据内容，从而造成被攻击目标网络拥堵进而无法对外提供服务。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="jie-jue-fang-fa">解决方法</h2>
<p>增加<code>iptables</code>过滤</p>
<h2 id="cao-zuo-bu-zou">操作步骤</h2>
<pre><code class="language-shell">在/etc/rc.local中增加如下内容：
iptables -I INPUT -p tcp --dport 11211 -j DROP
iptables -I INPUT -s 127.0.0.1 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.20.3.61 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.20.3.62 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 172.20.3.63 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.20.3.64 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.18.12.105 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.18.12.106 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.18.12.107 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 172.18.12.108 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 172.18.12.109 -p tcp --dport 11211 -j ACCEPT
iptables -I INPUT -s 10.10.128.1 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.2 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.3 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.4 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.5 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.6 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.7 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.8 -p tcp --dport 11211 -j Accept
iptables -I INPUT -s 10.10.128.9 -p tcp --dport 11211 -j Accept
</code></pre>
<h2 id="cha-kan-shi-fou-sheng-xiao">查看是否生效</h2>
<p><code>iptables -L -n -v </code></p>
<p>清空上面的规则，命令：</p>
<p><code>iptables -F </code></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title>List 3 object from Bucket</title>
    <url>/2018/04/28/get_objects_from_bucket/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>因为要调测<code>ceph S3</code>相关参数，观察参数调整对<code>list S3 Objects</code>的 影响，因此写了如下脚本辅助测试。</p>
<h1 id="script">Script</h1>
<pre><code class="language-python">#!/usr/bin/python
# coding: utf8

from boto.s3.connection import S3Connection, OrdinaryCallingFormat
from boto.s3.bucket import Bucket
from boto.s3.key import Key
import time

ACCESS_KEY = "85P6XN20EO05YX88ID9E"
SECRET_ACCESS_KEY = "zzYU77LbdRGOCndXDFhQKw6a949p1Xj5qBjgjRgh"
HOST = "172.17.59.45"
BUCKET_NAME = "account0bucket0" 
PREFIX = "NODE98-1952364"

# create s3 connection
def s3_con(ACCESS_KEY, SECRET_ACCESS_KEY, host, port=80):
    conn = S3Connection(ACCESS_KEY,
        SECRET_ACCESS_KEY,
        host = host,
        port = 80,
        calling_format = OrdinaryCallingFormat(),
        is_secure = False
    )

    return conn


def list_objects(conn, bucket_name, prefix, loop_times=None):
    # List all objects with a prefix under a bucket
    loop_times = 100 if loop_times is None else loop_times

    bucket = conn.get_bucket(bucket_name)

    cost_time_list = []
    for i in xrange(loop_times):
        start_time = time.time()
        match_objs = []
        for obj in bucket.list(prefix=prefix):
            match_objs.append(obj)
    
        match_counts = len(match_objs)
        end_time = time.time()

        time_stamp = end_time - start_time
        cost_time_list.append(time_stamp)
        print "match counts: %d  cost time(s) : %.2f" %(match_counts, time_stamp)


    return cost_time_list


def Get_Max(list):
    return max(list)


def Get_Min(list):
    return min(list)


def Get_Average(list):
    sum = 0
    for item in list:
        sum += item
    return sum/len(list)



def run_app():
    conn = s3_con(ACCESS_KEY, SECRET_ACCESS_KEY, HOST)
    
    cost_time_list = list_objects(conn, BUCKET_NAME, PREFIX, loop_times=100)

    max_time = Get_Max(cost_time_list)
    mix_time = Get_Min(cost_time_list)
    avg_time = Get_Average(cost_time_list)

    print "max: {}  min: {}  avg: {}".format(max_time, mix_time, avg_time)


if __name__ == "__main__":
    run_app()

</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Email发送HTML测试报告模板</title>
    <url>/2018/05/01/jenkins_html_report/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近打算使用nose framework写产品自动化用例，需要与jenkins集成做CI，将测试结果以Email形式广播给大家，于是尝试搞一个html模板，将HTML测试结果以附件方式发送出去。</p>
<h1 id="shi-ce-xiao-guo">实测效果</h1>
<h2 id="jenkins-she-zhi-inject-enviromment-variables">Jenkins设置’Inject enviromment variables’</h2>
<p>这里需要在Jenkins中设置环境变量，写入到这个变量文件中，有一个shell脚本，从这个变量文件中读取需要的信息，传递给HTML模板，从而能够构成一个完整的HTML数据，发送出去.<br>
Jenkins上设置变量信息如下图所示:</p>
<img class="shadow" src="/img/in-post/inject_env_variables.png" width="1200">
<h2 id="du-qu-bian-liang-wen-jian-de-jiao-ben">读取变量文件的脚本</h2>
<pre><code class="language-shell">#!/bin/bash

scriptrootpath=/work/automation-test/nose_7.0/nose_framework
if [ ! -d ${scriptrootpath} ]; then
    mkdir ${scriptrootpath}
    chown -R jenkins.jenkins ${scriptrootpath}
fi


# Get automation start and end time for jenkins report'
time_file="$scriptrootpath/report/time.txt"
START_TIME=`cat ${time_file} | head -n 1`
echo START_TIME=${START_TIME} &gt; $scriptrootpath/build.properties
END_TIME=`tac ${time_file} | head -n 1`
echo END_TIME=${END_TIME} &gt;&gt; $scriptrootpath/build.properties

# Record version
version_file="$scriptrootpath/report/version.txt"
PRODUCT_VERSION=`cat ${version_file}`
echo PRODUCT_VERSION=${PRODUCT_VERSION} &gt;&gt; $scriptrootpath/build.properties

#parse result.txt
report_file="$scriptrootpath/report/all_test_cases.html"
if [ ! -f ${report_file} ]; then
    echo "[ERROR]  Not exist ${report_file}, exit!"
    exit
fi


result_file="$scriptrootpath/report/result.txt"
`cat ${report_file} | grep -A5 "&lt;td&gt;&lt;strong&gt;Total&lt;/strong&gt;&lt;/td&gt;" | grep -v strong | awk -F "td" '{{print $2}}' | sed 's/&gt;//g' | sed 's/&lt;\///g' &gt; ${result_file}` 


test_counts=`awk 'NR==5, NR==5 {print $1}' ${result_file}`
test_pass=`awk 'NR==4, NR==4 {print $1}' ${result_file}`
test_fail=`awk 'NR==1, NR==1 {print $1}' ${result_file}`
test_skip=`awk 'NR==3, NR==3 {print $1}' ${result_file}`
test_error=`awk 'NR==2, NR==2 {print $1}' ${result_file}`

echo TEST_COUNTS=${test_counts} &gt;&gt; $scriptrootpath/build.properties
echo TEST_PASS=${test_pass} &gt;&gt; $scriptrootpath/build.properties
echo TEST_FAIL=${test_fail} &gt;&gt; $scriptrootpath/build.properties
echo TEST_SKIP=${test_skip} &gt;&gt; $scriptrootpath/build.properties
echo TEST_ERROR=${test_error} &gt;&gt; $scriptrootpath/build.properties
</code></pre>
<h2 id="html-mo-ban-dai-ma">html模板代码</h2>
<pre><code class="language-shell">&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;h2 style="color: #5e9ca0; text-align: center;"&gt;
            Note:(This email generated by system automatically, please do not reply!)
        &lt;/h2&gt;
        &lt;table class="editorDemoTable" style="height: 549px; width: 811px;"&gt;
            &lt;thead&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #3498db; text-align: center; width: 801px;" colspan="2" nowrap="nowrap"&gt;
                        &lt;h2&gt;
                            &lt;span style="color: #000000;"&gt;NOSE Automation Test Result&lt;/span&gt;
                        &lt;/h2&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #3498db; width: 801px; text-align: left;" colspan="2" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Information&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
            &lt;/thead&gt;
            &lt;tbody&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Test Result&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;&amp;nbsp;&lt;/span&gt;
                        &lt;ul&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Total Cases:&amp;nbsp; &amp;nbsp; ${TEST_COUNTS}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #008000;"&gt;Pass&amp;nbsp; Cases:&amp;nbsp; &amp;nbsp; ${TEST_PASS}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #ffff00;"&gt;Fail&amp;nbsp; &amp;nbsp;Cases:&amp;nbsp; &amp;nbsp; ${TEST_FAIL}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #3366ff;"&gt;Skip&amp;nbsp; Cases:&amp;nbsp; &amp;nbsp; ${TEST_SKIP}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #ff0000;"&gt;Error Cases:&amp;nbsp; &amp;nbsp; ${TEST_ERROR}&lt;/span&gt;
                            &lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Product Version&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$PRODUCT_VERSION&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        Time Consuming
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;From ($START_TIME) To ($END_TIME)&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Project Name&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$PROJECT_NAME&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Number&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$BUILD_NUMBER&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Status&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$BUILD_STATUS&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Trigger Reason&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;${CAUSE}&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #3498db; width: 801px; text-align: left;" colspan="2" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Test Information&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build&amp;nbsp;Result&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;&lt;a style="color: #000000;" title="Build Result" href="${BUILD_URL}console"&gt;${BUILD_URL}&lt;/a&gt;&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Log&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;&lt;a style="color: #000000;" title="Build Log" href="${BUILD_URL}console"&gt;${BUILD_URL}console&lt;/a&gt;&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Log&amp;amp;Report&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 643px;" nowrap="nowrap"&gt;
                        &lt;br&gt;
                        &lt;ul&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Test Report:&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;a style="color: #000000;" title="Test Report" href="${BUILD_URL}testReport"&gt;${BUILD_URL}testReport&lt;/a&gt;&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Pylint Violations Report:&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &lt;a style="color: #000000;" title="Pylint Violations Report" href="${BUILD_URL}violations"&gt;${BUILD_URL}violations&lt;/a&gt;&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Cobertura Coverage Report:&amp;nbsp;&amp;nbsp; &lt;a style="color: #000000;" title="Cobertura Coverage Report" href="${BUILD_URL}cobertura"&gt;${BUILD_URL}cobertura&lt;/a&gt;&lt;/span&gt;
                            &lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
            &lt;/tbody&gt;
        &lt;/table&gt;
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h2 id="email-zhong-html-xiao-guo">Email中html效果</h2>
<img class="shadow" src="/img/in-post/email_html.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu kdump dump core files</title>
    <url>/2018/05/27/auto_dump_core/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>kdump 是一种先进的基于 kexec 的内核崩溃转储机制。当系统崩溃时，kdump 使用 kexec 启动到第二个内核。</p>
<p>第二个内核通常叫做捕获内核，以很小内存启动以捕获转储镜像。第一个内核保留了内存的一部分给第二内核启动 用。由于 kdump 利用 kexec 启动捕获内核，绕过了 BIOS，所以第一个内核的内存得以保留。这是内核崩溃转储的本质。</p>
<p>现在整理下在Ubuntu 14.04上的部署方法。</p>
<h1 id="bu-shu">部署</h1>
<p>第一步是通过如下指令安装：</p>
<p><code>root@46:~# sudo apt-get install linux-crashdump</code></p>
<p>安装过程中，会弹出选择框：</p>
<img class="shadow" src="/img/in-post/ubuntu_kdump-1.png" width="1200">
<p>注意:<br>
选择YES。选择完成后，安装过程完毕，该安装会自动修改grub.cfg:</p>
<pre><code class="language-shell">linux   /boot/vmlinuz-4.1.49-server root=UUID=cfb17230-a084-4117-a9b8-38bcd48f7c07 ro video=VGA-1:800x600 quiet 915.modeset=0 nomodeset net.ifnames=1 biosdevname=0 nomdmonddf nomdmonisw crashkernel=384M-:128M
</code></pre>
<p>后面新增 crashkernel=384M -:128M 了部分。 安装好了之后，执行kdump-conﬁg show会发现，该功能尚未启用。</p>
<pre><code class="language-shell">root@46:~# kdump-config show
Usage: /usr/sbin/kdump-config {help|test|show|status|load|unload|savecore} root@46:~# kdump-config show
 * /etc/default/kdump-tools: USE_KDUMP is not set or zero
 * no crashkernel= parameter in the kernel cmdline
DUMP_MODE:        kdump
USE_KDUMP:        0
KDUMP_SYSCTL:     kernel.panic_on_oops=1 KDUMP_COREDIR:    /var/crash
crashkernel addr:
current state:    Not ready to kdump

kexec command:
  no kexec command recorded
</code></pre>
<p>第二步是要启用kdump，方法是修改/etc/default/kdump-tools 中的USE_KDUMP</p>
<pre><code class="language-shell"># kdump-tools configuration
# ---------------------------------------------------------------------------# USE_KDUMP - controls kdump will be configured
#     0 - kdump kernel will not be loaded
#     1 - kdump kernel will be loaded and kdump is configured
# KDUMP_SYSCTL - controls when a panic occurs, using the sysctl
#     interface.  The contents of this variable should be the
#     "variable=value ..." portion of the 'sysctl -w ' command.
#     If not set, the default value "kernel.panic_on_oops=1" will
#     be used.  Disable this feature by setting KDUMP_SYSCTL=" "
#     Example - also panic on oom:
#         KDUMP_SYSCTL="kernel.panic_on_oops=1 vm.panic_on_oom=1"
#
USE_KDUMP=0 
#KDUMP_SYSCTL="kernel.panic_on_oops=1"
</code></pre>
<p>将USE_KDUMP=0改成 USE_KDUMP=1。 修改之后，需要重启机器，方能生效。</p>
<p>第三步重启机器，然后检查 kdump-conﬁg show： (换了一台机器展示)</p>
<pre><code class="language-shell">root@44:~# kdump-config show
DUMP_MODE:        kdump
USE_KDUMP:        1
KDUMP_SYSCTL:     kernel.panic_on_oops=1 
KDUMP_COREDIR:    /var/crash
crashkernel addr: 0x2d000000
current state:    ready to kdump

kexec command:
  /sbin/kexec -p --command-line="BOOT_IMAGE=/boot/vmlinuz-4.1.49-server root=UUID=3cc9983b-3d4d-413a-a9a5-6edc9e785c3e ro video=VGA-1:800x600 quiet 915.modeset=0 nomodeset net.ifnames=1 biosdevname=0 nomdmonddf nomdmonisw irqpoll maxcpus=1 nousb" --initrd=/boot/initrd.img-4.1.49-server /boot/vmlinuz-4.1.49-server
</code></pre>
<h1 id="ce-shi-pei-zhi-shi-fou-you-xiao">测试配置是否有效</h1>
<p>如何触发crash，验证能否产生crash文件： 手动触发的话，比较简单：</p>
<p><code>echo c&gt; /proc/sysrq-trigger </code></p>
<p>就会触发crash，搜集资料，机器启动之后会看到如下内容:</p>
<pre><code class="language-shell">root@44:/var/crash/201808021451# crash  /usr/lib/debug/lib/modules/4.1.49-server/vmlinux dump.201808021451

crash 7.0.3
Copyright (C) 2002-2013  Red Hat, Inc.
Copyright (C) 2004, 2005, 2006, 2010  IBM Corporation
Copyright (C) 1999-2006  Hewlett-Packard Co
Copyright (C) 2005, 2006, 2011, 2012  Fujitsu Limited
Copyright (C) 2006, 2007  VA Linux Systems Japan K.K.
Copyright (C) 2005, 2011  NEC Corporation
Copyright (C) 1999, 2002, 2007  Silicon Graphics, Inc.
Copyright (C) 1999, 2000, 2001, 2002  Mission Critical Linux, Inc.
This program is free software, covered by the GNU General Public License, 
and you are welcome to change it and/or distribute copies of it under 
certain conditions.  Enter "help copying" to see the conditions.
This program has absolutely no warranty.  Enter "help warranty" for details.

GNU gdb (GDB) 7.6
Copyright (C) 2013 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; 
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-unknown-linux-gnu"...

      KERNEL: /usr/lib/debug/lib/modules/4.1.49-server/vmlinux 
    DUMPFILE: dump.201808021451  [PARTIAL DUMP]
        CPUS: 32
        DATE: Thu Jan  1 08:00:00 1970
      UPTIME: 00:01:35
LOAD AVERAGE: 5.72, 2.41, 0.89
       TASKS: 2109
    NODENAME: 44
     RELEASE: 4.1.49-server
     VERSION: #2 SMP Wed Aug 1 14:31:39 CST 2018
     MACHINE: x86_64  (2099 Mhz)
      MEMORY: 127.9 GB
       PANIC: "Oops: 0002 [#1] SMP " (check log for details) 
         PID: 5191
     COMMAND: "bash"
        TASK: ffff8810249be500  [THREAD_INFO: ffff880fd8144000] 
         CPU: 1
       STATE: TASK_RUNNING (PANIC)

crash&gt; bt
PID: 5191   TASK: ffff8810249be500  CPU: 1   COMMAND: "bash" 
 #0 [ffff880fd8147ab0] machine_kexec at ffffffff81042cef
 #1 [ffff880fd8147b00] crash_kexec at ffffffff810e7a33
#2 [ffff880fd8147bd0] oops_end at ffffffff810076c8
 #3 [ffff880fd8147c00] no_context at ffffffff8173cf5f
 #4 [ffff880fd8147c60] __bad_area_nosemaphore at ffffffff8173d01e
 #5 [ffff880fd8147cb0] bad_area_nosemaphore at ffffffff8173d18a
 #6 [ffff880fd8147cc0] __do_page_fault at ffffffff8104ce25
 #7 [ffff880fd8147d30] do_page_fault at ffffffff8104d331
 #8 [ffff880fd8147d60] page_fault at ffffffff8174aa62
    [exception RIP: sysrq_handle_crash+22]
    RIP: ffffffff8145e156  RSP: ffff880fd8147e18  RFLAGS: 00010292 
    RAX: 000000000000000f  RBX: ffffffff81caa660  RCX: 0000000000000000 
    RDX: 0000000000000001  RSI: ffff88103fa4d678  RDI: 0000000000000063 
    RBP: ffff880fd8147e18   R8: 00000000000000c2   R9: ffffffff81eafe9c 
    R10: 000000000000064a  R11: 0000000000000649  R12: 0000000000000063 
    R13: 0000000000000000  R14: 0000000000000003  R15: 0000000000000000 
    ORIG_RAX: ffffffffffffffff  CS: 0010  SS: 0018
 #9 [ffff880fd8147e20] __handle_sysrq at ffffffff8145e927
#10 [ffff880fd8147e50] write_sysrq_trigger at ffffffff8145edd3
#11 [ffff880fd8147e70] proc_reg_write at ffffffff8123107d
#12 [ffff880fd8147ea0] __vfs_write at ffffffff811ca688
#13 [ffff880fd8147eb0] vfs_write at ffffffff811cacd9
#14 [ffff880fd8147f00] sys_write at ffffffff811cbaa6
#15 [ffff880fd8147f50] system_call_fastpath at ffffffff81748f5b
    RIP: 00007f9b22df2390  RSP: 00007fff9441ffd8  RFLAGS: 00000246 
    RAX: ffffffffffffffda  RBX: 0000000000000003  RCX: 00007f9b22df2390 
    RDX: 0000000000000002  RSI: 0000000001d27408  RDI: 0000000000000001 
    RBP: 000000000000000a   R8: 000000000000000a   R9: 00007f9b2370c740 
    R10: 00007f9b230c46a0  R11: 0000000000000246  R12: 00000000004b8a97 
    R13: 0000000000000073  R14: 0000000000000030  R15: 0000000001efdb40 
    ORIG_RAX: 0000000000000001  CS: 0033  SS: 002b
crash&gt;
</code></pre>
<p>凑巧的时，我们产品恰好发生了crash：</p>
<img class="shadow" src="/img/in-post/ubuntu_kdump-2.png" width="1200">
<p>当搜集信息完成之后，会自动重启，重启之后，可以在/var/crash下看到对应的信息：</p>
<pre><code class="language-shell">root@44:~# ll /var/crash
total 56
drwxrwxrwt  4 root root  4096 Aug  2 15:53 ./
drwxr-xr-x 16 root root  4096 Aug  2 14:43 ../
drwxr-xr-x  2 root root  4096 Aug  2 14:54 201808021451/
drwxr-xr-x  2 root root  4096 Aug  2 15:56 201808021553/
-rw-r--r--  1 root root   313 Aug  2 15:58 kexec_cmd
-rw-r-----  1 root root 36332 Aug  2 14:56 linux-image-4.1.49-server-201808021451.crash

root@44:/var/crash/201808021553# ll
total 1434560
drwxr-xr-x 2 root root       4096 Aug  2 15:56 ./
drwxrwxrwt 4 root root       4096 Aug  2 15:53 ../
-rw------- 1 root root     240194 Aug  2 15:56 dmesg.201808021553 
-rw------- 1 root root 1468733533 Aug  2 15:56 dump.201808021553
</code></pre>
<h1 id="fen-xi-crash">分析crash</h1>
<p>要分析crash文件，需要安装内核符号表：</p>
<pre><code class="language-shell">root@44:~# dpkg -l |grep linux-image
ii  linux-image-4.1.49-server            201808011426~cf7c219                 amd64        Linux kernel binary image for version 4.1.49-server
ii  linux-image-4.1.49-server-dbg        201808011426~cf7c219                 amd64        Linux kernel debug image for version 4.1.49-server
</code></pre>
<p>安装后，使用如下指令开始分析crash</p>
<pre><code class="language-shell">crash  /usr/lib/debug/lib/modules/4.1.49-server/vmlinux dump.201808021553
</code></pre>
<p>对于本次的crash，可以查出是由于scst引起的，如下所示：</p>
<pre><code class="language-shell">root@44:/var/crash/201808021553# crash  /usr/lib/debug/lib/modules/4.1.49-server/vmlinux dump.201808021553

crash 7.0.3
Copyright (C) 2002-2013  Red Hat, Inc.
Copyright (C) 2004, 2005, 2006, 2010  IBM Corporation
Copyright (C) 1999-2006  Hewlett-Packard Co
Copyright (C) 2005, 2006, 2011, 2012  Fujitsu Limited
Copyright (C) 2006, 2007  VA Linux Systems Japan K.K.
Copyright (C) 2005, 2011  NEC Corporation
Copyright (C) 1999, 2002, 2007  Silicon Graphics, Inc.
Copyright (C) 1999, 2000, 2001, 2002  Mission Critical Linux, Inc.
This program is free software, covered by the GNU General Public License, 
and you are welcome to change it and/or distribute copies of it under 
certain conditions.  Enter "help copying" to see the conditions.
This program has absolutely no warranty.  Enter "help warranty" for details.

GNU gdb (GDB) 7.6
Copyright (C) 2013 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; 
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-unknown-linux-gnu"...

      KERNEL: /usr/lib/debug/lib/modules/4.1.49-server/vmlinux 
    DUMPFILE: dump.201808021553  [PARTIAL DUMP]
        CPUS: 32
        DATE: Thu Jan  1 08:00:00 1970
      UPTIME: 00:55:56
LOAD AVERAGE: 23.89, 6.95, 4.06
       TASKS: 2485
    NODENAME: 44
     RELEASE: 4.1.49-server
     VERSION: #2 SMP Wed Aug 1 14:31:39 CST 2018
     MACHINE: x86_64  (2099 Mhz)
      MEMORY: 127.9 GB
       PANIC: "Oops: 0000 [#1] SMP " (check log for details) 
         PID: 133396
     COMMAND: "scstd30"
        TASK: ffff882036574bc0  [THREAD_INFO: ffff881c1253c000] 
         CPU: 14
       STATE: TASK_RUNNING (PANIC)

crash&gt;
crash&gt; bt
PID: 133396  TASK: ffff882036574bc0  CPU: 14  COMMAND: "scstd30"
 #0 [ffff881c1253f970] machine_kexec at ffffffff81042cef
 #1 [ffff881c1253f9c0] crash_kexec at ffffffff810e7a33
 #2 [ffff881c1253fa90] oops_end at ffffffff810076c8
 #3 [ffff881c1253fac0] no_context at ffffffff8173cf5f
 #4 [ffff881c1253fb20] __bad_area_nosemaphore at ffffffff8173d01e
 #5 [ffff881c1253fb70] bad_area_nosemaphore at ffffffff8173d18a
 #6 [ffff881c1253fb80] __do_page_fault at ffffffff8104ce25
 #7 [ffff881c1253fbf0] do_page_fault at ffffffff8104d331
 #8 [ffff881c1253fc20] page_fault at ffffffff8174aa62
    [exception RIP: scst_update_lat_stats+224]
    RIP: ffffffffa0c2d4f0  RSP: ffff881c1253fcd8  RFLAGS: 00010206 
    RAX: 0000000000000048  RBX: ffff881cf3ed0000  RCX: 0000000000000010 
    RDX: 0000000000000000  RSI: 0000000000000000  RDI: 0000000000000000 
    RBP: ffff881c1253fd58   R8: 0000000000000000   R9: 0000000000000092 
    R10: 0000000000000000  R11: 0000000000000010  R12: 0000000000000000 
    R13: ffff881db84e7640  R14: ffff881cf3ed0490  R15: 0000000000000092 
    ORIG_RAX: ffffffffffffffff  CS: 0010  SS: 0018
 #9 [ffff881c1253fd60] scst_finish_cmd at ffffffffa0c0bc68 [scst]
#10 [ffff881c1253fdb0] scst_process_active_cmd at ffffffffa0c0e415 [scst] #11 [ffff881c1253fdf0] scst_do_job_active at ffffffffa0c0fe10 [scst]
#12 [ffff881c1253fe40] scst_cmd_thread at ffffffffa0c100cf [scst]
#13 [ffff881c1253fec0] kthread at ffffffff8107c749
#14 [ffff881c1253ff50] ret_from_fork at ffffffff81749362
crash&gt;
</code></pre>
<p>通过反编译 scst.ko文件：</p>
<p><code>objdump -S scst.ko |tee /tmp/scst.ko.obj</code></p>
<p>我们打开该反编译的文件:</p>
<pre><code class="language-shell">0000000000034410 &lt;scst_update_lat_stats&gt;:

void scst_update_lat_stats(struct scst_cmd *cmd)
{
   34410:       e8 00 00 00 00          callq  34415 &lt;scst_update_lat_stats+0x5&gt; 
   34415:       55                      push   %rbp
   34416:       48 89 e5                mov    %rsp,%rbp
   34419:       41 57                   push   %r15
   3441b:       41 56                   push   %r14
   3441d:       41 55                   push   %r13
   3441f:       49 89 fd                mov    %rdi,%r13
   34422:       41 54                   push   %r12 
   34424:       53                      push   %rbx 
   34425:       48 83 ec 58             sub    $0x58,%rsp
        uint64_t finish, scst_time, tgt_time, dev_time, total_time; 
        struct scst_session *sess = cmd-&gt;sess;
</code></pre>
<p>注意这一行:</p>
<p><code>[exception RIP: scst_update_lat_stats+224] </code></p>
<p>我们可以计算crash的代码位置：</p>
<p><code>0x0000000000034410 + 224(十进制) = 344F0 </code></p>
<p>去反编译的文件中寻找对应的未知:</p>
<pre><code class="language-shell">#ifdef CONFIG_SCST_MEASURE_LATENCY
        if (cmd-&gt;dev-&gt;vdev_update_lat_stats) {
   344f0:       4c 8b 97 40 02 00 00    mov    0x240(%rdi),%r10 
        else
                dev_latency_stat = NULL;
</code></pre>
<p>原因是：cmd-&gt;dev在更新统计新的时候已经变成了NULL，这和之前的分析对应。</p>
<pre><code class="language-shell">10925 #ifdef CONFIG_SCST_MEASURE_LATENCY
10926         if (cmd-&gt;dev-&gt;vdev_update_lat_stats) {
10927                 cmd-&gt;dev-&gt;vdev_update_lat_stats(cmd-&gt;dev, cmd-&gt;data_direction, 10928                                                 total_time);
10929         }
10930 #endif
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>测试中常用的Linux命令汇总</title>
    <url>/2017/10/26/linux_command_summary/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在日常测试工作中，产品是部署在Ubuntu上的，本文罗列一些在测试过程中，常用到的一些指令。</p>
<h1 id="pi-liang-sheng-cheng-wen-jian">批量生成文件</h1>
<p>方法1：</p>
<p><code>seq 1 10  | xargs -i{} -P 10 touch file_{}  </code></p>
<p>10个并发来touch file</p>
<p>方法2：</p>
<p><code>for i in {1..100}; do dd if=/dev/zero of=file_$i bs=1M count=1; done </code></p>
<p>这个没有并发哦~</p>
<p>方法3：</p>
<p><code>touch file{0..9}.txt </code></p>
<p>相应的，创建目录、删除目录/文件（夹），都可以以此类推：</p>
<p><code>rm -rf file{0..9} </code></p>
<p><code>mkdir dir{0..9} </code></p>
<p><code>rm -rf dir{0..9} </code></p>
<h1 id="cha-zhao-jiang-shi-jin-cheng">查找僵尸进程</h1>
<p><code>ps -A -ostat,ppid,pid,cmd | grep -e '^[zZ]' </code></p>
<h1 id="cha-kan-jin-cheng-yun-xing-shi-jian">查看进程运行时间</h1>
<p><code>ps -A -opid,stime,etime,args | grep XXX </code></p>
<h1 id="cha-kan-mou-jin-cheng-shi-yao-shi-hou-qi-dong-yun-xing-shi-jian">查看某进程什么时候启动、运行时间</h1>
<h2 id="qi-dong-shi-jian">启动时间</h2>
<p><code>ps -eo lstart </code></p>
<h2 id="yun-xing-duo-chang-shi-jian">运行多长时间</h2>
<p><code>ps -eo etime&nbsp;</code></p>
<p>示例:</p>
<p><code>ps -eo pid,lstart,etime | grep 5176</code></p>
<p>或者</p>
<p><code>ps -p `pidof ceph-mon` -o etime,pid,cmd </code></p>
<h1 id="cha-kan-wang-qia-du-xie-xin-xi">查看网卡读写信息</h1>
<p>方法1：</p>
<p><code>nfsiostat 2 </code></p>
<p>方法2：</p>
<p><code>iftop </code></p>
<p>或者：</p>
<p><code>iftop -I ethX </code></p>
<p>方法3：</p>
<p><code>sar -n DEV 2 </code></p>
<h1 id="cha-kan-cpu-xin-xi">查看cpu信息</h1>
<h2 id="cha-kan-wu-li-cpu-de-ge-shu">查看物理CPU的个数</h2>
<p><code>cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l</code></p>
<h2 id="cha-kan-luo-ji-cpu-de-ge-shu">查看逻辑CPU的个数</h2>
<p><code>cat /proc/cpuinfo |grep "processor"|wc -l</code></p>
<p>或者使用nproc命令查看:</p>
<pre><code class="language-shell">root@host245:~# nproc
32
</code></pre>
<h2 id="cha-kan-cpu-shi-ji-he">查看CPU是几核</h2>
<p><code>cat /proc/cpuinfo |grep "cores"|uniq</code></p>
<h2 id="cha-kan-cpu-de-zhu-pin">查看CPU的主频</h2>
<p><code>cat /proc/cpuinfo |grep MHz|uniq</code></p>
<h2 id="cha-kan-nei-cun-de-cha-cao-shu-yi-jing-shi-yong-duo-shao-cha-cao-mei-tiao-nei-cun-duo-da-yi-shi-yong-nei-cun-duo-da">查看内存的插槽数，已经使用多少插槽。每条内存多大，已使用内存多大</h2>
<p><code>dmidecode|grep -P -A5 "Memory\s+Device"|grep Size|grep -v Range</code></p>
<h2 id="cha-kan-nei-cun-zhi-chi-de-zui-da-nei-cun-rong-liang">查看内存支持的最大内存容量</h2>
<p><code>dmidecode|grep -P 'Maximum\s+Capacity'</code></p>
<h2 id="cha-kan-nei-cun-de-pin-lu">查看内存的频率</h2>
<p><code>dmidecode|grep -A16 "Memory Device"</code></p>
<p><code>dmidecode|grep -A16 "Memory Device"|grep 'Speed'</code></p>
<h1 id="vm-re-jia-pan">VM热加盘</h1>
<p>虚拟机添加硬盘，无需重启，识别新硬盘</p>
<p><code>echo '- - -' &gt; /sys/class/scsi_host/host*/scan </code></p>
<h1 id="cha-kan-sector-size">查看sector size</h1>
<p><code>cat /sys/block/sdX/queue/*block_size</code></p>
<h1 id="ru-he-que-ding-pan-shi-ssd-lei-xing-de-ci-pan">如何确定盘是SSD类型的磁盘</h1>
<p>方法1：</p>
<p><code>cat /sys/block/sdX/queue/rotational</code></p>
<p>方法2：</p>
<p><code>lsblk -d -o name,rota</code></p>
<p>输出示例如下：</p>
<pre><code class="language-shell">root@host245:~/tmp# lsblk -d -o name,rota
NAME ROTA
sda     0
sdb     0
sdc     1
sdd     1
sde     1
sdf     1
sdg     1
sdh     1
sdi     1
sdj     1
sdk     1
sdl     1
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>0 表示是SSD</p>
</li>
<li class="lvl-2">
<p>1 表示是HDD或者SAS盘</p>
</li>
<li class="lvl-2">
<p>如SSD是在RAID卡上，此方法不适用，需要借助Megacli(e.g:<code>MegaCli ldpdinfo aall</code>)来确认</p>
</li>
</ul>
<h1 id="cha-kan-fen-qu-de-uuid-xin-xi">查看分区的uuid信息</h1>
<pre><code class="language-shell">[root@nwos ~]# blkid  /dev/sdb1
/dev/sdb1: UUID="9d7790c6-4fd9-47db-ad16-24d1025d4518" TYPE="ext4" 
</code></pre>
<p>或者直接使用blkid指令列出所有分区的uuid</p>
<img class="shadow" src="/img/in-post/blkid.png" width="1200">
<h1 id="kuai-su-chuang-jian-da-wen-jian">快速创建大文件</h1>
<p><code>fallocate -l 10G bigfile</code></p>
<p>上面这个，只能骗过ls -s, du和df</p>
<p><code>truncate -s 10G bigfile </code></p>
<p>上面这个，只能骗过ls -l</p>
<p><code>dd of=bigfile bs=1 seek=10G count=0</code></p>
<p>上面这个，只能骗过ls -l</p>
<h1 id="diao-chu-hou-tai-yun-xing-de-ming-ling">调出后台运行的命令</h1>
<p>比如vi 一个文件，ctrl+z之后，进入后台, 或者在vi期间，session中断了（没有tmux）</p>
<pre><code class="language-shell">root@node01:/home/stability_testing/src/testCase/_03_ctdb/testcasebase# vi ctdbManagerTestcaseBase.py 

[1]+  Stopped  

</code></pre>
<p>ps查看：</p>
<pre><code class="language-shell">root@node01:/home/stability_testing/src/testCase/_03_ctdb/testcasebase# ps -ef | grep -i vii
root      393866  399030  0 11:35 pts/2    00:00:00 grep --color=auto -i vii
root@node01:/home/stability_testing/src/testCase/_03_ctdb/testcasebase# ps -ef | grep -i vi
root        1085       2  0 Jun21 ?        00:00:00 [dbu_evict]
root        1111       2  0 Jun21 ?        00:00:12 [arc_user_evicts]
root      394119  399030  0 11:35 pts/2    00:00:00 grep --color=auto -i vi
root      412813  399030  0 10:58 pts/2    00:00:02 vi ctdbManagerTestcaseBase.py
</code></pre>
<p>如何调出这个vi命令，继续进行vi编辑？</p>
<h2 id="step-1-shi-yong-jobs-ming-ling">Step1、使用jobs命令</h2>
<p>`</p>
<pre><code class="language-shell">root@node01:/home/stability_testing/src/testCase/_03_ctdb/testcasebase# jobs
[1]+  Stopped                 vi ctdbManagerTestcaseBase.py
</code></pre>
<p>这里看到[1]+，如果有多个后台运行，展示类似如下：</p>
<pre><code class="language-shell">[root@pcmxexweb&nbsp;etc]#&nbsp;jobs

[1]-&nbsp;&nbsp;Stopped&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;find&nbsp;/&nbsp;-name&nbsp;xml

[2]+&nbsp;&nbsp;Stopped&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;vi&nbsp;/etc/hosts
</code></pre>
<h2 id="step-2-zhi-xing-fs-x-diao-chu-lai">Step2、执行fs X，调出来</h2>
<p>X表示中括号里的数值，比如：</p>
<p><code>fg 1</code></p>
<p>则调出find命令</p>
<h1 id="cha-kan-suo-you-wang-kou-de-link-detected-zhuang-tai">查看所有网口的Link Detected 状态</h1>
<p><code>ifconfig -a | grep 'Link encap:' | grep -v lo | awk '{{print $1}}' | xargs -I{} -t ethtool {} | grep 'Link detected' </code></p>
<p>输出示例：</p>
<pre><code class="language-shell">ethtool bond0 
	Link detected: yes
ethtool bond1 
	Link detected: yes
ethtool enp129s0f0 
	Link detected: yes
ethtool enp129s0f1 
	Link detected: no
ethtool enp130s0f0 
	Link detected: yes
ethtool enp130s0f1 
	Link detected: no
ethtool eth0 
	Link detected: yes
ethtool eth1 
	Link detected: no
</code></pre>
<h1 id="ge-shi-hua-dui-qi-shu-chu">格式化对齐输出</h1>
<p>对于cat的一些内容，显示总是不对齐</p>
<p>解决方法</p>
<p>使用|column -t， 如：</p>
<p><code>cat dev | column - </code></p>
<p>输出示例：</p>
<img class="shadow" src="/img/in-post/cat_format.png" width="1200">
<h1 id="cha-kan-top-10-cpu-nei-cun-de-zhan-yong">查看top 10 CPU、内存的占用</h1>
<h2 id="cpu-zhan-yong-zui-duo-de-qian-10-ge-jin-cheng">CPU占用最多的前10个进程：</h2>
<p><code>ps auxw|head -1;ps auxw|sort -rn -k3|head -10 </code></p>
<h2 id="nei-cun-xiao-hao-zui-duo-de-qian-10-ge-jin-cheng">内存消耗最多的前10个进程</h2>
<p><code>ps auxw|head -1;ps auxw|sort -rn -k4|head -10 </code></p>
<h2 id="xu-ni-nei-cun-shi-yong-zui-duo-de-qian-10-ge-jin-cheng">虚拟内存使用最多的前10个进程</h2>
<p><code>ps auxw|head -1;ps auxw|sort -rn -k5|head -10 </code></p>
<h1 id="tong-ji-dai-ma-xing-shu">统计代码行数</h1>
<h2 id="find-jia-wc">find 加 wc</h2>
<p><code>find . -type f -iname "*.py" -print0 | xargs -0 wc -l</code></p>
<p>这个指令比较原始，会含有注释、空格等的总计行数.</p>
<h2 id="shi-yong-cloc-jin-xing-tong-ji">使用cloc进行统计</h2>
<p>示例如下：</p>
<p><code>cloc /bigtera/nose_framework/src/</code></p>
<img class="shadow" src="/img/in-post/code_colc.png" width="1200">
<h2 id="pylint">pylint</h2>
<p><code>pylint /home/xxx/src</code></p>
<img class="shadow" src="/img/in-post/code_pylint.png" width="1200">
<h1 id="lie-chu-mu-lu-de-4-chong-fang-fa">列出目录的4种方法</h1>
<p>方法1：</p>
<p><code>ls -d */</code></p>
<p>方法2：</p>
<p><code>ls -F | grep '/$'</code></p>
<p>方法3：</p>
<p><code>ls -l | grep '^d'</code></p>
<p>方法4：</p>
<p><code>find . -type d -maxdepth 1 -print</code></p>
<h1 id="cha-kan-shi-qu">查看时区</h1>
<p>方法1 date</p>
<p>输出示例:</p>
<pre><code class="language-shell">root@host245:~/tmp# date +"%Z %z"
CST +0800
</code></pre>
<p>或者 date -R</p>
<pre><code class="language-shell">root@host245:~/tmp# date -R
Wed, 27 Nov 2019 16:59:38 +0800
root@host245:~/tmp# 
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>重点在+0800，表示时区是东八区</p>
</li>
</ul>
<p>方法2 timedatectl</p>
<p>输出示例:</p>
<pre><code class="language-shell">root@host245:~/tmp# timedatectl | grep 'Timezone'
        Timezone: Asia/Shanghai (CST, +0800)
</code></pre>
<h1 id="xiu-gai-shi-qu">修改时区</h1>
<p>当系统安装好后，发现系统时区不对，如何修改呢？</p>
<p>方法1</p>
<p><code>tzselect </code></p>
<p>方法2</p>
<p><code>timeconfig </code></p>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>仅限于RedHat Linux 和 CentOS</p>
</li>
</ul>
<p>方法3</p>
<p><code>dpkg-reconfigure tzdata </code></p>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>适用于Debian</p>
</li>
</ul>
<p>根据提示，选择不同的时区信息，设置成功后，需要复制文件：</p>
<p><code>cp /usr/share/zoneinfo/Asia/Shanghai  /etc/localtime</code></p>
<h1 id="qing-kong-cache">清空cache</h1>
<p>在跑fio进行读测试之前，一定要进行一次cache的清空，否则会影响fio性能测试结果的。<br>
cache分3种：<br>
1： pagecache； 2：dentries 和 inodes； 3：所有cache</p>
<h2 id="qing-kong-nei-cun-huan-cun">清空内存缓存</h2>
<pre><code class="language-shell">echo 1 &gt; /proc/sys/vm/drop_caches
</code></pre>
<h2 id="qing-kong-pagecache">清空 pagecache</h2>
<pre><code class="language-shell">sync
echo 1 &gt; /proc/sys/vm/drop_caches
</code></pre>
<p>或者</p>
<pre><code class="language-shell">sync
sysctl -w vm.drop_caches=1
</code></pre>
<h2 id="qing-kong-dentries-he-inodes">清空 dentries 和 inodes</h2>
<pre><code class="language-shell">sync
echo 2 &gt; /proc/sys/vm/drop_caches
</code></pre>
<p>或者</p>
<pre><code class="language-shell">sync
sysctl -w vm.drop_caches=2
</code></pre>
<h2 id="qing-kong-suo-you-huan-cun-pagecache-dentries-he-inodes">清空所有缓存（pagecache、dentries 和 inodes）</h2>
<pre><code class="language-shell">sync
echo 3 &gt; /proc/sys/vm/drop_caches
</code></pre>
<p>或者</p>
<pre><code class="language-shell">sync
sysctl -w vm.drop_caches=3
</code></pre>
<h1 id="qing-kong-arp-biao">清空arp表</h1>
<p><code>arp -n|awk '/^[1-9]/{print "arp -d " $1}'|sh -x </code></p>
<p>然后 off  和 on 对应的网卡</p>
<pre><code class="language-shell">[root@localhost sbull]# ip link set arp off dev eth0
[root@localhost sbull]# ip link set arp on dev eth0
</code></pre>
<p>最后再查看下arp表信息</p>
<pre><code class="language-shell">[root@localhost sbull]# arp -n
</code></pre>
<h1 id="cha-kan-dang-qian-zhu-ji-shi-wu-li-ji-huan-shi-xu-ni-ji">查看当前主机是物理机还是虚拟机</h1>
<p><code>dmidecode -s system-product-name </code></p>
<p>示例：</p>
<p>物理服务器</p>
<pre><code class="language-shell">[root@JX-P-L-KVM-231 ~]# dmidecode -s system-product-name
# SMBIOS implementations newer than version 2.7 are not
# fully supported by this version of dmidecode.
PowerEdge R930
</code></pre>
<p>KVM 虚拟主机</p>
<pre><code class="language-shell">[root@JX-V-L-PHP-237 ~]# dmidecode -s system-product-name
KVM
</code></pre>
<p>VMware vSphere 虚拟主机</p>
<pre><code class="language-shell">[root@ZE-T1 ~]# dmidecode -s system-product-name
VMware Virtual Platform
</code></pre>
<p>阿里云主机</p>
<pre><code class="language-shell">[root@zdc ~]# dmidecode -s system-product-name
HVM domU
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>给nose写一个类似Robot Framework的Wait Until Keyword Succeeds</title>
    <url>/2018/06/18/nose_smart_check/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>由于产品是异步请求，往往一个request下去，只是将某些信息写入到了KVStore中，之后由daemon读取KVStore进行判断是否有发生变化，如果有变化，daemon才采取行动。这里在写自动化校验设置是否apply下去，以及apply下去后是否有生效，就不能靠time.sleep来做了，主要问题是：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>不确定要等待多久，等待久了，感觉是浪费时间，尤其用例很多的情况下，严重影响了用例的整体执行时间；等待短了，又没有成功的apply下去，或者apply下去了但还没有具体生效</p>
</li>
</ul>
<p>鉴于此，就需要有一个类似于Robot Framework的<code>Wait Until Keyword Succeeds </code>功能.</p>
<h1 id="shi-jian">实践</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-


from __future__ import unicode_literals

import time

from common.config import GetConfig as config

retry_interval = config.retry_interval
retry_timeout = config.retry_timeout


def assert_check(func):
    """
    :param func, string, a function name
    """
    @wraps(func)
    def inner(param, *args, **kwargs):
        """
        :param param, string, a parameter
        """
        for i in xrange(int(retry_timeout)):
            try:
                func(param, *args, **kwargs)
                break
            except Exception as ex:
                logging.warn("[WARN]  Not match, %s time(s) to retry, "
                             "exception is : (%s) : (%s)", (i + 1), ex.__str__, unicode(ex))
                logging.warn("[WARN]  In file (%s) of function (%s), "
                             "at line (%s)", func.func_code.co_filename,
                             func.func_name,
                             func.func_code.co_firstlineno)
                time.sleep(int(retry_interval))
                continue
        else:
            logging.info("[ERROR]  Retry timeout or AssertionError")
            # raise AssertionError('[RetryTimeOut] Failure expected, retry timeout')
            # Deliberately doing this, this will mark the use case status as failed,
            # otherwise it will affect the normal output of the html report (the entire html content is empty)
            eq_(1, 2, "[RetryTimeOut] Failure expected, retry timeout")

    return inner

</code></pre>
<p>这里是一个示例的片段，通过装饰器，在调用check函数之前，引用这个装饰器，从而达到间隔一定时间（retry_timeout）、执行一定次数（retry_interval）来实现类似RF<code>Wait Until Keyword Succeeds </code>的功能</p>
<p>对应测试用例基类的检查操作示例如下：</p>
<pre><code class="language-python">    @assert_check
    def check_snapshot(self, gateway_group, target_id, iscsi_id, snap_name, op_type):
        """
        Check snapshot created or delete result
        :param gateway_group, string, a gateway group name
        :param target_id, string, a target name
        :param iscsi_id, string, a volume name
        :param snap_name, string, a snapshot name for a iSCSI volume
        :param op_type, string, del or add
        """

        if op_type == 'add':
            logging.info("[Check]    Check snapshot created result")
        elif op_type == 'del':
            logging.info("[Check]    Check snapshot deleted result")

        info = get_volume_info(gateway_group, target_id, iscsi_id, translate_pool_id=True)
        pool = info['pool']
        image_name = info['rbd_img']

        rbd_res = do_cmd("rbd -p {} snap ls {}".format(pool, image_name), 30, True).strip()
        if op_type == 'add':
            assert_in(snap_name, rbd_res, "[ERROR]  Not found : ({}) in "
                                          "rbd_res : ({})".format(snap_name, rbd_res))
            logging.info("[Success]  Create snapshot : (%s) success", snap_name)
        elif op_type == 'del':
            assert_not_in(snap_name, rbd_res, "[ERROR]  Still found : ({}) in "
                                              "rbd_res : ({})".format(snap_name, rbd_res))
            logging.info("[Success]  Delete snapshot : (%s) success", snap_name)

</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>nose</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>nose</tag>
      </tags>
  </entry>
  <entry>
    <title>网络时延--Linux模拟复杂网络环境下的传输（netem和tc）</title>
    <url>/2018/07/10/bond_package_lost/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在进行网络服务的测试时，有时需要模拟一些异常的网络情况，例如网络延时长、丢包、网络地址连接不通等。在Linux下，可以通过tc工具来模拟各种网络情况；通过iptables禁止访问某个网络地址。</p>
<h1 id="netem-yu-tc-jie-shao">netem与tc介绍</h1>
<p>netem 是 Linux 2.6 及以上内核版本提供的一个网络模拟功能模块。该功能模块可以用来在性能良好的局域网中，模拟出复杂的互联网传输性能，诸如低带宽、传输延迟、丢包等等情况。</p>
<p>使用 Linux 2.6 (或以上) 版本内核的很多发行版 Linux 都开启了该内核功能，比如Fedora、Ubuntu、Redhat、OpenSuse、CentOS、Debian等等。</p>
<p>tc 是 Linux 系统中的一个工具，全名为traffic control（流量控制）。tc 可以用来控制 netem 的工作模式，也就是说，想要使用 netem ，则需要内核开启了 netem，而且安装了 tc工具。</p>
<p>tc控制的是发包动作，不能控制收包动作。它直接对物理接口生效，如果控制了物理的eth0，那么逻辑网卡（比如eth0:1）也会受到影响，反之则不行，控制逻辑网卡是无效的。</p>
<h1 id="mo-ni-yan-chi-chuan-shu">模拟延迟传输</h1>
<p>将 eth0 网卡的传输设置为延迟100毫秒发送</p>
<pre><code class="language-shell">$ tc  qdisc  add  dev  eth0  root  netem  delay  100ms  
</code></pre>
<p>如果设置出现：</p>
<pre><code class="language-shell">root@auto-70-2:~#  tc qdisc add dev bond0 root netem
RTNETLINK answers: File exists
</code></pre>
<p>说明之前设置过，解决方法：</p>
<pre><code class="language-shell">ip addr flush dev bond0
</code></pre>
<p>真实的情况下，延迟值不会这么精确，会有一定的波动，下面命令模拟带有波动性的延迟值：</p>
<pre><code class="language-shell"> $ tc  qdisc  add  dev  eth0  root  netem  delay  100ms  10ms
</code></pre>
<p>该命令将 eth0 网卡的传输设置为延迟 100ms ± 10ms （90 ~ 110 ms 之间的任意值）发送。</p>
<p>由于各个包的延迟值不通，也会在一定程度上打乱发包的次序。</p>
<p>还可以更进一步加强这种波动的随机性，将 eth0 网卡的传输设置为 100ms ，同时，大约有30%的包会延迟 ± 10ms 发送：</p>
<pre><code class="language-shell"> $ tc  qdisc  add  dev  eth0  root  netem  delay  100ms  10ms  30%
</code></pre>
<h1 id="mo-ni-wang-luo-diu-bao">模拟网络丢包</h1>
<p>将 eth0 网卡的传输设置为随机丢掉 1% 的数据包。</p>
<pre><code class="language-shell"> $ tc  qdisc  add  dev  eth0  root  netem  loss  1%  
</code></pre>
<p>也可以设置丢包的成功率，将 eth0 网卡的传输设置为随机丢掉 1% 的数据包，成功率为30% ：</p>
<pre><code class="language-shell"> $ tc  qdisc  add  dev  eth0  root  netem  loss  1%  30%
</code></pre>
<h1 id="mo-ni-bao-zhong-fu">模拟包重复</h1>
<p>将 eth0 网卡的传输设置为随机产生 1% 的重复数据包。</p>
<pre><code class="language-shell"> $ tc  qdisc  add  dev  eth0  root  netem  duplicate 1% 
</code></pre>
<h1 id="mo-ni-shu-ju-bao-sun-pi">模拟数据包损坏</h1>
<p>将 eth0 网卡的传输设置为随机产生 0.2% 的损坏的数据包。 (内核版本需在2.6.16以上）</p>
<pre><code class="language-shell"> $ tc  qdisc  add  dev  eth0  root  netem  corrupt  0.2% 
</code></pre>
<h1 id="mo-ni-shu-ju-bao-luan-xu">模拟数据包乱序</h1>
<p>将 eth0 网卡的传输设置为:有25%的数据包（50%相关）会被立即发送，其他的延迟10秒。</p>
<pre><code class="language-shell"> $ tc  qdisc  change  dev  eth0  root  netem  delay  10ms   reorder  25%  50%
</code></pre>
<h1 id="shi-li">示例</h1>
<p>step1：使用ifconfig命令查看你的网卡信息，如:eth0</p>
<p>step2：将网卡加入监控列表</p>
<pre><code class="language-shell">$ sudo tc qdisc add dev eth0 root netem
</code></pre>
<p>step3：设置丢包率</p>
<pre><code class="language-shell">$ sudo tc qdisc change dev eth0 root netem loss 0.5%
</code></pre>
<p>设置重发</p>
<pre><code class="language-shell">$ sudo tc qdisc change dev eth0 root netem duplicate 1%
</code></pre>
<p>设置发乱序包</p>
<pre><code class="language-shell">$ sudo tc qdisc change dev eth0 root netem gap 5 delay 10ms
</code></pre>
<p>如果想让网络恢复正常，只需要删除监控，或将设置的值相应归0即可。</p>
<p>例如，设置延时</p>
<pre><code class="language-shell">$ sudo tc qdisc add dev eth0 root netem delay 4s
</code></pre>
<p>取消延时</p>
<pre><code class="language-shell">$ sudo tc qdisc del dev eth0 root netem delay 4s
</code></pre>
<h1 id="jin-zhi-fang-wen-yi-ge-ip">禁止访问一个IP</h1>
<p>如果要禁止访问一个IP，不使用tc，而是用iptables。iptalbes可以简单理解为linux下的防火墙，控制网络访问。</p>
<p>1、禁止访问10.237.0.1</p>
<pre><code class="language-shell">$ iptables -A OUTPUT -d 10.237.0.1 -j REJECT
</code></pre>
<p>2、查看规则</p>
<pre><code class="language-shell">$ iptables -L OUTPUT -n
Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
REJECT     all  --  0.0.0.0/0            10.237.0.1        reject-with icmp-port-unreachable
</code></pre>
<p>3、查看规则号</p>
<pre><code class="language-shell">$ iptables -L OUTPUT -n --line-numbers
Chain OUTPUT (policy ACCEPT)
num  target     prot opt source               destination         
1    REJECT     all  --  0.0.0.0/0            10.237.0.1        reject-with icmp-port-unreachable
</code></pre>
<p>4、删除规则</p>
<pre><code class="language-shell">$ iptables -D OUTPUT 1
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>nose测试用例可指定循环次数</title>
    <url>/2018/07/09/nose_loop_run/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>编写nose 自动化测试用例时，有些场景需要重复循环运行，才有可能踩到Bug，为了让nose 用例能够支持循环运行，特意写了一个装饰器，能够指定nose测试用例的循环次数。</p>
<h1 id="dai-ma">代码</h1>
<pre><code class="language-python">def loop_run():
    """  
    loop run a test case
    """
    from testconfig import config as cf

    def wrap(func):
        """
        :param func, string, a function name
        """
        @wraps(func)
        def wrapper(object):
            """
            :param object, object, a object name
            """
            for num in xrange(int(cf.get('runs', 1))):
                logging.info("[loop run] The current number of loop operations is: (%s), "
                             "test case name is : (%s)", num+1, func.func_name)
                func(object)

        return wrapper
    return wrap
</code></pre>
<h1 id="ce-shi-yong-li-shi-li">测试用例示例</h1>
<pre><code class="language-python">    @loop_run()
    def test_435_create_enable_folder(self):
        """  Sc-435:Enable share folder  """
        folder_name = 'nose-' + rand_low_ascii(6)
        self.create_share_folder(folder_name, nfs='true', smb='true', op_type='add')
        self.disable_folder(folder_name, nfs='true', smb='true', op_type='disable')
        self.enable_folder(folder_name, nfs='true', smb='true', op_type='enable')
        self.delete_folder(folder_name, op_type='del')
</code></pre>
<h1 id="yong-li-zhi-xing-shi-li">用例执行示例</h1>
<pre><code class="language-shell">root@nose-70-97:/home/nose_framework/src# nosetests -v --with-progressive --with-html --html-report=../report/nas.html testcase/Function_Test/case_4_Virtual_Storages/NAS/ --tc=runs:10
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这里的loop_run就是执行10次，即<code>testcase/Function_Test/case_4_Virtual_Storages/NAS/ </code>目录下的所有测试用例，都会被执行10次</p>
</li>
<li class="lvl-2">
<p>loop_run 函数，需要配合nose的nose-testconfig使用</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Automation</category>
        <category>nose</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>nose</tag>
      </tags>
  </entry>
  <entry>
    <title>vim无法黏贴</title>
    <url>/2018/08/15/vim_copy/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>有时候会碰到OS的默认设置，禁止vim中选择文本、复制文本。本文介绍如何规避之。</p>
<h1 id="jiao-ben">脚本</h1>
<p>vim ~/.vimrc，添加如下内容：</p>
<pre><code class="language-shell">set mouse=c
syntax on
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD在不同控制器下不同文件系统类型性能</title>
    <url>/2018/08/19/ssd_performance_with_different_fs/</url>
    <content><![CDATA[<h1 id="ssd-zai-bu-tong-kong-zhi-qi-xia-bu-tong-wen-jian-xi-tong-lei-xing-xia-de-xing-neng">SSD 在不同控制器下不同文件系统类型下的性能</h1>
<img class="shadow" src="/img/in-post/SSD_Performance_with_different_Controller_FS.png" width="1200">
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SSD</tag>
      </tags>
  </entry>
  <entry>
    <title>Monitor tools of sysdig</title>
    <url>/2018/10/04/sysdig/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Sysdig 是一款强大的系统分析工具，能够监控和捕捉到大量的系统状态信息。它可以用来监控包括但不限于以下状态：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>CPU 使用率：可以监控整体系统或者特定进程的CPU使用情况。</p>
</li>
<li class="lvl-2">
<p>内存使用：能够检查系统的内存使用率，包括物理内存、交换分区等。</p>
</li>
<li class="lvl-2">
<p>I/O 活动：监控磁盘I/O活动，如读写操作和I/O等待时间，可以用于诊断性能瓶颈。</p>
</li>
<li class="lvl-2">
<p>文件操作：捕捉对文件的打开、读写、关闭等操作，用于分析文件使用情况或未授权访问。</p>
</li>
<li class="lvl-2">
<p>网络活动：监听所有网络活动，包括连接的建立与断开、数据包的传输等。</p>
</li>
<li class="lvl-2">
<p>进程活动：跟踪进程的创建、执行和终止，查看系统中进程的活跃情况。</p>
</li>
<li class="lvl-2">
<p>用户活动：记录用户登录、执行命令及其他活动，对于安全监控尤其重要。</p>
</li>
<li class="lvl-2">
<p>系统调用：跟踪系统调用（syscalls），可以用于检查系统的安全性和程序行为。</p>
</li>
<li class="lvl-2">
<p>容器活动：特别对于Docker等容器化技术，sysdig可以监控容器的使用情况，如CPU、内存、网络和文件系统活动。</p>
</li>
<li class="lvl-2">
<p>错误和异常：查看系统产生的错误及异常，帮助定位问题所在。</p>
</li>
<li class="lvl-2">
<p>系统事件：所有用户空间和内核空间的事件都可以通过sysdig进行跟踪，这对于分析系统行为非常有用。</p>
</li>
</ul>
<p>Sysdig 通过提供强大的过滤器，使用户可以根据需要选择性地监控上述状态的任何组合。此外，sysdig 还有一个名为 csysdig 的图形界面版本，该程序可以让用户以交云方式浏览和过滤事件数据。正因为 sysdig 提供了如此详细的系统洞察，它被广泛用于底层的问题诊断、性能分析和安全监控中。不过，使用者应当注意，sysdig 的高级监控功能可能对系统性能有一定的影响，故在生产环境中应斟酌使用。</p>
<h1 id="sysdig-an-zhuang">Sysdig 安装</h1>
<p>Sysdig 是一个开源的系统监控和故障排查工具，适用于Linux。它提供了丰富的系统事件数据，便于深入分析。</p>
<h2 id="an-zhuang-yi-lai-xiang">安装依赖项</h2>
<p>首先，确保已安装必须的依赖项。大多数Linux发行版都可以通过包管理器安装。对于基于Debian的系统（如Ubuntu），运行：</p>
<pre><code class="language-shell">apt-get update
apt-get install -y software-properties-common
</code></pre>
<p>对于基于RPM的系统（如CentOS），运行：</p>
<pre><code class="language-shell">yum update
yum groupinstall -y 'Development Tools'
yum install -y kernel-devel
</code></pre>
<h2 id="tong-guo-bao-guan-li-qi-an-zhuang-sysdig">通过包管理器安装Sysdig</h2>
<p>接着，可以通过系统的包管理器直接安装Sysdig。对于Ubuntu或Debian系统，运行：</p>
<pre><code class="language-shell">curl -s https://s3.amazonaws.com/download.draios.com/stable/install-sysdig | ```shell
</code></pre>
<p>对于CentOS，运行：</p>
<pre><code class="language-shell">rpm --import https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public
curl -s -o /etc/yum.repos.d/draios.repo https://s3.amazonaws.com/download.draios.com/stable/rpm/draios.repo
yum install -y sysdig
</code></pre>
<h2 id="bian-yi-an-zhuang">编译安装</h2>
<p>如果您喜欢从源代码安装，可以按照以下步骤操作：</p>
<pre><code class="language-shell">git clone https://github.com/draios/sysdig.git
cd sysdig
mkdir build
cd build
cmake ..
make
make install
</code></pre>
<h1 id="sysdig-shi-yong-chang-jing-he-shi-li">Sysdig 使用场景和示例</h1>
<h2 id="cha-kan-suo-you-xi-tong-shi-jian">查看所有系统事件</h2>
<p>运行以下命令可以查看所有捕获的事件：</p>
<pre><code class="language-shell">sysdig
</code></pre>
<h2 id="shai-xuan-jin-cheng-chuang-jian-he-tui-chu-shi-jian">筛选进程创建和退出事件</h2>
<p>仅查看与进程创建和退出相关的事件：</p>
<pre><code class="language-shell">sysdig evt.type=execve or evt.type=exit
</code></pre>
<h2 id="an-zhao-jin-cheng-ming-cheng-shai-xuan">按照进程名称筛选</h2>
<p>通过进程名称来筛选事件：</p>
<pre><code class="language-shell">sysdig proc.name=httpd
</code></pre>
<h2 id="cha-kan-te-ding-yong-hu-de-huo-dong">查看特定用户的活动</h2>
<p>查看特定用户（假设用户ID为1001）的所有系统活动：</p>
<pre><code class="language-shell">sysdig user.uid=1001
</code></pre>
<h2 id="cha-kan-wen-jian-i-o">查看文件I/O</h2>
<p>捕获特定文件（例如/var/log/messages）的所有读写事件：</p>
<pre><code class="language-shell">sysdig fd.name=/var/log/messages
</code></pre>
<h2 id="jian-kong-wang-luo-lian-jie">监控网络连接</h2>
<p>监控所有进出网络连接：</p>
<pre><code class="language-shell">sysdig evt.type=connect or evt.type=accept
</code></pre>
<h2 id="shi-shi-biao-shi-mou-ge-mu-lu-xia-de-wen-jian-cao-zuo">实时表示某个目录下的文件操作</h2>
<p>监控对/etc目录的所有文件操作：</p>
<pre><code class="language-shell">sysdig fd.directory=/etc
</code></pre>
<h2 id="jiang-bu-huo-de-shi-jian-shu-chu-dao-wen-jian">将捕获的事件输出到文件</h2>
<p>将事件输出到 capture.scap 文件以备后续分析：</p>
<pre><code class="language-shell">sysdig -w capture.scap
</code></pre>
<h2 id="cong-wen-jian-zhong-du-qu-shi-jian">从文件中读取事件</h2>
<p>从scap文件中读取并分析事件：</p>
<pre><code class="language-shell">sysdig -r capture.scap
</code></pre>
<p>建议在操作中加以尝试以更好地理解每个命令的使用场景。Sysdig 的官方文档提供了更多高级用法和示例，可以访问 Sysdig Documentation 来获取详细信息。</p>
<h1 id="sysdig-shi-ji-ying-yong-chang-jing-jie-shao">sysdig实际应用场景介绍</h1>
<p>除了前面提到的基础用法，sysdig 还能适用于更复杂的实战场景，下面是一些进阶的使用示例：</p>
<h2 id="fen-xi-te-ding-ying-yong-cheng-xu-de-xing-neng">分析特定应用程序的性能</h2>
<p>如果要监控特定应用程序的系统调用以分析性能问题，可以使用类似以下命令：</p>
<pre><code class="language-shell">sysdig -p "%proc.name %evt.num %evt.type" proc.name=httpd
</code></pre>
<p>这个命令会显示进程名为httpd的所有事件类型及其事件序号，有助于识别可能导致性能下降的系统调用。</p>
<h2 id="gu-zhang-pai-cha-he-shi-shi-jian-kong">故障排查和实时监控</h2>
<p>Sysdig 可以用来监控实时系统的状态，比如实时监控CPU利用率较高的进程：</p>
<pre><code class="language-shell">sysdig -c topprocs_cpu
</code></pre>
<p>这将会列出消耗CPU最多的进程。</p>
<h2 id="jian-cha-wen-jian-xi-tong-de-huo-dong">检查文件系统的活动</h2>
<p>如果需要监控文件系统的变化，例如谁删除了某个文件或者哪些文件被最频繁地修改，可以使用：</p>
<pre><code class="language-shell">sysdig -A -c echo_fds fd.type=file and evt.failed=false and evt.type=write
</code></pre>
<p>这个命令捕获并显示所有文件写入事件，并排除了失败的事件。</p>
<h2 id="jian-kong-wang-luo-huo-dong">监控网络活动</h2>
<p>监控并记录从特定IP地址传入或传出的网络活动，可以帮助排查网络问题：</p>
<pre><code class="language-shell">sysdig -c spy_ip 192.168.1.101
</code></pre>
<p>如果是需要详细输出特定端口的网络请求，可以使用：</p>
<pre><code class="language-shell">sysdig "evt.type=recvfrom and fd.port=80"
</code></pre>
<h2 id="rong-qi-jian-kong">容器监控</h2>
<p>Sysdig 也是个容器监控的好工具。如果你使用Docker，可以通过以下命令查看所有Docker事件：</p>
<pre><code class="language-shell">sysdig -c spy_users
</code></pre>
<p>或者查看特定容器的活动：</p>
<pre><code class="language-shell">sysdig -pc container.id=&lt;container_id&gt;
</code></pre>
<p>用容器ID替换 &lt;container_id&gt; 以监控该容器。</p>
<h2 id="pai-cha-xi-tong-an-quan-wen-ti">排查系统安全问题</h2>
<p>如果怀疑系统被未经授权的用户访问，可以用 sysdig 搜集证据：</p>
<pre><code class="language-shell">sysdig -c spy_users
</code></pre>
<p>该命令会监控所有用户活动，包括终端输入输出。</p>
<h2 id="bao-cun-he-hui-fang-hui-hua">保存和回放会话</h2>
<p>如果想要记录下发生异常时的系统状态用于事后分析，可以将sysdig输出保存到文件:</p>
<pre><code class="language-shell">sysdig -w session.scap
</code></pre>
<p>然后可以回放这次会话：</p>
<pre><code class="language-shell">sysdig -r session.scap
</code></pre>
<h1 id="sysdig-de-chisels-du-you-na-xie-chang-yong-de-gong-neng">sysdig的Chisels都有哪些常用的功能？</h1>
<p>sysdig 的 Chisels 是预先编写的脚本，用来提供易懂的输出，并针对特定的监控任务。以下是一些常用的 sysdig Chisels 以及它们的功能：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>topprocs_cpu: 显示 CPU 使用率最高的进程。</p>
</li>
<li class="lvl-2">
<p>topprocs_mem: 显示内存使用率最高的进程。</p>
</li>
<li class="lvl-2">
<p>topfiles_bytes: 列出读取和写入最多字节的文件。</p>
</li>
<li class="lvl-2">
<p>topconns: 显示网络连接数最多的端点。</p>
</li>
<li class="lvl-2">
<p>iobytes: 按照 I/O 字节显示进程排行。</p>
</li>
<li class="lvl-2">
<p>nettop: 实时网络活动统计，类似于网络版的 top 命令。</p>
</li>
<li class="lvl-2">
<p>spy_users: 显示用户输入的命令（例如在 shell 中输入的）。</p>
</li>
<li class="lvl-2">
<p>listens: 显示监听端口的服务器。</p>
</li>
<li class="lvl-2">
<p>spy_file: 监控对指定文件的所有读写活动。</p>
</li>
<li class="lvl-2">
<p>fileslower: 显示磁盘 I/O 操作中响应时间超过一定阈值的事件。</p>
</li>
<li class="lvl-2">
<p>stderr / stdout: 分别捕获和显示进程的标准错误或标准输出流。</p>
</li>
<li class="lvl-2">
<p>connections: 罗列系统中的网络连接。</p>
</li>
<li class="lvl-2">
<p>echo_fds: 以人类可读的格式捕捉文件描述符的活动。</p>
</li>
<li class="lvl-2">
<p>memcachetop: 显示 memcached 服务器上的 top 请求。</p>
</li>
<li class="lvl-2">
<p>httptop: 显示 HTTP 请求排行。</p>
</li>
</ul>
<p>这些是一些基本的 Chisels，sysdig 根据使用频率和需要进行了优化。你可以通过运行 sysdig -cl 来列出所有可用的 Chisels。记住每个 Chisel 都有其参数和过滤选项，用以精细控制输出内容。</p>
<p>使用 Chisel 的时候，通常我们会输入如 sysdig -c ChiselName 的命令，并可以加上过滤条件来更精准地捕捉所需的数据。</p>
<h1 id="wo-gai-ru-he-shi-yong-chisels-lai-jian-kong-te-ding-jin-cheng-de-wang-luo-lian-jie-shu">我该如何使用Chisels来监控特定进程的网络连接数？</h1>
<p>要监控某个特定进程的网络连接数，你可以使用 sysdig 的 topconns Chisel。topconns Chisel 用于显示网络连接数最多的进程及其对应的IP地址和端口号。如果你想针对某个特定进程进行监控，你需要结合使用 Chisel 和一个合适的过滤器。假设你要监控进程名称为 myapp 的应用程序的网络连接数，可以按照以下步骤操作：</p>
<p>打开终端，输入以下命令，其中 proc.name=myapp 是一个过滤器，用于指定进程名称：</p>
<pre><code class="language-shell">sysdig -c topconns "proc.name=myapp"
</code></pre>
<p>如果你知道进程的PID，也可以使用类似的命令：</p>
<pre><code class="language-shell">sysdig -c topconns "proc.pid=1234"
</code></pre>
<p>这里的 1234 应替换为实际要监控的进程的PID。</p>
<p>运行此命令，sysdig 将会实时显示与 myapp 应用程序相关的网络连接信息，包括远程IP地址、端口号和连接数等。</p>
<p>如果你只对特定类型的网络连接感兴趣（例如TCP或UDP连接），你还可以进一步细化过滤器。例如，只监控TCP连接：</p>
<pre><code class="language-shell">sysdig -c topconns "proc.name=myapp and evt.type=connect and fd.type=ipv4 and fd.l4proto=tcp"
</code></pre>
<p>使用Chisels监控网络连接数有助于识别潜在的网络瓶颈问题、不正常的连接模式或者检查服务的使用情况等。记得，始终根据你的需求来调整过滤器，以获取最相关的数据。</p>
<h1 id="wo-ru-he-zai-sysdig-zhong-jian-kong-duo-ge-te-ding-jin-cheng-de-wang-luo-lian-jie-shu">我如何在sysdig中监控多个特定进程的网络连接数？</h1>
<p>要在sysdig中监控多个特定进程的网络连接数，你可以构建一个过滤器，该过滤器结合了所有你需要监控的进程。过滤器可以使用逻辑运算符（如or）来匹配多个条件。例如，如果你需要同时监控名为 httpd 和 mysqld 的两个进程的网络连接数，可以这样做：</p>
<p>打开一个终端，输入以下命令：</p>
<pre><code class="language-shell">sysdig -c topconns "proc.name=httpd or proc.name=mysqld"
</code></pre>
<p>这个命令将显示 httpd 和 mysqld 进程的网络连接数。topconns chisel会针对这些过滤器列出连接最多的端点。同样地，如果你有这些进程的PID，也可以像这样使用它们：</p>
<pre><code class="language-shell">sysdig -c topconns "proc.pid=123 or proc.pid=456"
</code></pre>
<p>其中的 123 和 456 应该替换为你想要监控的实际进程的PID。</p>
<p>请注意，在监控多个不同的进程时，要准确无误地指定进程名称或者PID，以确保sysdig为每个特定进程提供准确的网络连接数据。</p>
<p>如果你想要指定更多的进程，只需在过滤器中继续添加更多的条件，使用 or 运算符连接它们即可。这样可以让你轻松地同时监控多个进程的网络连接状况。如果有必要，也可以添加更多详细的过滤选项，比如过滤特定的端口号或网络协议。</p>
<h1 id="wo-ke-yi-shi-yong-sysdig-de-chisels-lai-jian-kong-udp-lian-jie-shu-ma">我可以使用sysdig的Chisels来监控UDP连接数吗？</h1>
<p>是的，你可以使用sysdig的Chisels监控UDP连接数。不过，需要注意的是UDP（用户数据报协议）是无连接的协议，意味着它本身并不维持持久的连接状态。因此，对于UDP通信，通常是监控发送和接收到的UDP包的数量。要监控UDP通信，你可以使用topconns Chisel，结合一个过滤器来专注于UDP协议。例如，以下命令展示了所有UDP通信：</p>
<pre><code class="language-shell">sysdig -c topconns "fd.l4proto=udp"
</code></pre>
<p>如果想针对特定的进程，你可以再进一步添加过滤条件：</p>
<pre><code class="language-shell">sysdig -c topconns "proc.name=dnsmasq and fd.l4proto=udp"
</code></pre>
<p>在这个示例中，我们用proc.name=dnsmasq指定了进程名为dnsmasq的进程，同时指定了fd.l4proto=udp来过滤仅对应于UDP协议的数据。这样，sysdig就会展示dnsmasq进程的UDP通信情况。</p>
<p>类似地，如果你有进程的PID，可以使用下面的命令来监控该进程的UDP通信：</p>
<pre><code class="language-shell">sysdig -c topconns "proc.pid=1234 and fd.l4proto=udp"
</code></pre>
<p>在这里，1234是你希望监控的进程的进程ID（PID）。记得替换为真实的进程PID。</p>
<p>请注意，由于UDP是无连接的，所以“连接数”这一术语在这里指的是UDP数据包的流量量级。Chisel会根据你的过滤条件来显示活动最多的UDP会话。</p>
<h1 id="ru-he-zai-sysdig-zhong-jian-kong-udp-bao-de-shu-liang">如何在sysdig中监控UDP包的数量？</h1>
<p>监控UDP包的数量可以通过使用 sysdig 的 pktcount Chisel 实现，它能统计在一段时间内经过网络接口的数据包总数。如果你只对 UDP 数据包感兴趣，你需要添加一个过滤器来专注于 UDP 流量。</p>
<p>下面是如何使用 sysdig 监控 UDP 包数量的具体命令：</p>
<pre><code class="language-shell">sysdig -c pktcount "evt.type=recvfrom and fd.l4proto=udp"
</code></pre>
<p>这个命令结合了 pktcount Chisel 和一个过滤器，后者只考虑接收到的、使用 UDP 协议的网络数据包（基于事件类型 recvfrom）。这样就可以得到实时统计的 UDP 接收数据包数。</p>
<p>如果需要监控发送的 UDP 数据包数，可以修改事件类型为 sendto：</p>
<pre><code class="language-shell">sysdig -c pktcount "evt.type=sendto and fd.l4proto=udp"
</code></pre>
<p>若要更具体地监控某个进程的接收到的 UDP 数据包，可以添加进程名称或进程 ID 来进一步过滤：</p>
<pre><code class="language-shell">sysdig -c pktcount "evt.type=recvfrom and proc.name=dnsdist and fd.l4proto=udp"
</code></pre>
<p>在上述命令中，我们以 dnsdist 进程为例，在过滤器中指定了 <a href="http://proc.name">proc.name</a> 这个字段。这个命令将仅统计 dnsdist 进程接收到的 UDP 数据包数量。</p>
<p>请记得将 dnsdist 替换为你想要监控的具体进程名称，如果你已知进程的 PID，你可以使用 proc.pid 字段替换掉 proc.name=dnsdist：</p>
<pre><code class="language-shell">sysdig -c pktcount "evt.type=recvfrom and proc.pid=12345 and fd.l4proto=udp"
</code></pre>
<p>在这里，12345 应替换为你希望监控的进程的实际 PID。通过这样的命令，你可以定位到特定进程的 UDP 包数量，无论是接收还是发送。</p>
<h1 id="wo-ru-he-zai-sysdig-zhong-jian-kong-te-ding-wang-luo-jie-kou-de-udp-bao-shu-liang">我如何在sysdig中监控特定网络接口的UDP包数量？</h1>
<p>要在 sysdig 中监控特定网络接口上的 UDP 数据包数量，你首先需要知道接口的名称，如 eth0 或 wlan0。接着，可以使用 sysdig 的过滤语句来专门监控那个接口上的 UDP 交互。以下是监控指定网络接口上 UDP 包数量的一个例子：</p>
<pre><code class="language-shell">sysdig -c pktcount "evt.type=recvfrom and fd.l4proto=udp and fd.dev=eth0"
</code></pre>
<p>在这个命令中：<br>
-c pktcount 是指使用 pktcount Chisel 来统计数据包。<br>
evt.type=recvfrom 指明捕获接收事件。<br>
fd.l4proto=udp 用于过滤 UDP 协议的数据包。<br>
fd.dev=eth0 用于限定只监控名为 eth0 的网络接口。</p>
<p>确保将 eth0 替换成你实际想监控的网络接口名称。如果你想监控所有发送和接收的 UDP 包，可以省略 evt.type 过滤器，或者将其改成同时监控 recvfrom 和 sendto：</p>
<pre><code class="language-shell">sysdig -c pktcount "fd.l4proto=udp and fd.dev=eth0"
</code></pre>
<p>或者，要同时监控接收和发送的UDP包：</p>
<pre><code class="language-shell">sysdig -c pktcount "(evt.type=recvfrom or evt.type=sendto) and fd.l4proto=udp and fd.dev=eth0"
</code></pre>
<p>如上命令将监控特定网络接口 eth0 上的所有 UDP 发送和接收活动。</p>
<p>记得你可以通过运行 ifconfig 或 ip addr 命令来查看你系统上所有网络接口的列表及其状态。这有助于确保你使用正确的网络接口名称在 sysdig 命令中。</p>
<h1 id="ru-he-shi-yong-sysdig-jian-kong-te-ding-jin-cheng-de-cpu-shi-yong-qing-kuang">如何使用sysdig监控特定进程的CPU使用情况？</h1>
<p>要监控特定进程的CPU使用情况，你可以使用sysdig的内置的Chisel（即sysdig命令行版本的一种交互式的脚本）。Chisels 是一系列用于处理和格式化sysdig的输出数据的脚本。Sysdig 带有一些预定义的Chisels，可以直接使用。</p>
<p>监控特定进程的CPU使用情况的步骤：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>确定你想要监控的进程名称或者进程ID（PID）。例如，如果你想要监控名为httpd的进程。</p>
</li>
<li class="lvl-4">
<p>使用sysdig的topprocs_cpu Chisel，这个Chisel会显示消耗CPU最多的进程。</p>
</li>
</ul>
<p>启动监控的具体命令如下：</p>
<p>如果使用进程名称进行监控：</p>
<pre><code class="language-shell">sysdig -c topprocs_cpu "proc.name=httpd"
</code></pre>
<p>如果是使用PID进行监控，则需要用到proc.pid过滤条件：</p>
<pre><code class="language-shell">sysdig -c topprocs_cpu "proc.pid=1234"
</code></pre>
<p>请将 “httpd” 和 “1234” 替换为你需要监控的实际进程名称或PID。</p>
<p>默认系统会输出CPU占用率最高的几个进程，但如果你使用上面的过滤条件，输出将会被限制在特定的进程。</p>
<p>topprocs_cpu 是实时运行的，它会不断刷新并显示当前消耗CPU最多的进程。你可以通过 Ctrl + C 来停止监控过程。</p>
<p>友情提示：</p>
<p>在低性能或者高负载的系统上使用sysdig时，尽量使用特定的过滤条件来减少性能开销。过度的监控可能会进一步拖慢系统。</p>
<h1 id="wo-zen-yang-cai-neng-jian-kong-suo-you-zheng-zai-jin-xing-de-udp-tong-xin">我怎样才能监控所有正在进行的UDP通信？</h1>
<p>若要使用sysdig来监控系统中所有正在进行的UDP通信，你不需要指定特定的进程或网络接口，你可以设置通用的过滤器来捕获所有的UDP事件。以下是监控系统中所有UDP通信的命令：</p>
<pre><code class="language-shell">sysdig "fd.l4proto=udp"
</code></pre>
<p>这个简单的过滤器只要求捕获协议为UDP的网络事件。不过，这样会显示所有相关的事件，包括recvfrom和sendto，并可能会产生大量的输出。如果你想定制输出让它更有用，可以设置Chisel输出更可读的格式。例如，使用echo_fds Chisel会显示详细的I/O活动：</p>
<pre><code class="language-shell">sysdig -c echo_fds "fd.l4proto=udp"
</code></pre>
<p>这会以人类可读的格式输出UDP通信的细节，包括哪个进程正在发送或接收数据。若想仅监控接收（入站）的UDP包，可以使用以下命令：</p>
<pre><code class="language-shell">sysdig "evt.type=recvfrom and fd.l4proto=udp"
</code></pre>
<p>对于发送（出站）的UDP包，可以用：</p>
<pre><code class="language-shell">sysdig "evt.type=sendto and fd.l4proto=udp"
</code></pre>
<p>要获得关于每一条UDP通信的统计信息，可以使用topconns Chisel：</p>
<pre><code class="language-shell">sysdig -c topconns "fd.l4proto=udp"
</code></pre>
<p>这会列出活跃的UDP连接（实际上是流），包括远程的IP地址和端口，以及它们的活动排序。</p>
<p>如果输出信息太多，你可能想要将输出重定向到文件中或者使用grep等工具进行过滤，以更好地分析数据。</p>
<h1 id="wo-ke-yi-tong-guo-sysdig-jian-kong-xi-tong-zhong-de-suo-you-tcp-tong-xin-ma">我可以通过sysdig监控系统中的所有TCP通信吗？</h1>
<p>是的，您可以使用 sysdig 来监控系统中的所有 TCP 通信。TCP（传输控制协议）是一种可靠的、面向连接的协议，用于建立网络应用之间稳定的双向通信。通过合适的过滤器，您可以捕获和显示所有与 TCP 相关的网络活动。</p>
<p>要监控所有TCP通信，您可以运行如下命令：</p>
<pre><code class="language-shell">sysdig "fd.l4proto=tcp"
</code></pre>
<p>这个命令应用了一个简单的过滤器 fd.l4proto=tcp 来选择所有 TCP 协议的事件。这将会列出所有TCP网络事件，包括连接的建立、数据的发送和接收以及连接的关闭。</p>
<p>如果要以格式化的方式显示TCP通信的详细信息，您可以使用Chisels，例如 echo_fds：</p>
<pre><code class="language-shell">sysdig -c echo_fds "fd.l4proto=tcp"
</code></pre>
<p>echo_fds Chisel 以可读的格式显示文件描述符的活动，包括网络套接字的创建和使用。对于TCP通信，这将包括连接建立和数据传输的详细内容。</p>
<p>对于更细粒度的分析，Sysdig 允许您使用各种过滤条件来控制您想要监控的TCP通信的具体类型。比如，如果您只想看到建立的TCP连接，您可以使用以下命令：</p>
<pre><code class="language-shell">sysdig "evt.type=connect and fd.l4proto=tcp"
</code></pre>
<p>反之，如果您想监控TCP连接关闭事件，可以使用：</p>
<pre><code class="language-shell">sysdig "evt.type=close and fd.l4proto=tcp"
</code></pre>
<p>或者，您可能想要监控在指定端口(例如 HTTP 标准端口 80)上的TCP通信：</p>
<pre><code class="language-shell">sysdig "fd.l4proto=tcp and fd.sport=80 or fd.dport=80"
</code></pre>
<p>对于高级监控，您甚至可以结合 sysdig 的输出与其他命令行工具如 grep、awk 或 sed 进行数据处理和分析，或者通过将输出重定向到文件中来进行后续处理。</p>
<p>请记住，在使用 sysdig 对网络通信进行监控时，根据监控的数据量和系统的性能，可能会对系统性能产生一定的影响，所以请确保按需合理使用监控命令。</p>
<h1 id="wo-ke-yi-shi-yong-sysdig-lai-jian-kong-te-ding-duan-kou-shang-de-tcp-tong-xin-ma">我可以使用sysdig来监控特定端口上的TCP通信吗？</h1>
<p>当然可以，使用sysdig监控特定端口上的TCP通信相对简单。你只需要在过滤器中指定你感兴趣的端口。例如，如果你想监控本地端口 80 （通常被HTTP服务器使用）上的TCP通信，你可以使用以下命令：</p>
<pre><code class="language-shell">sysdig "fd.l4proto=tcp and (fd.sport=80 or fd.dport=80)"
</code></pre>
<p>在这个命令中：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>fd.l4proto=tcp 表示过滤器将仅匹配TCP协议的网络活动。</p>
</li>
<li class="lvl-4">
<p>fd.sport=80 表示源端口号为80。</p>
</li>
<li class="lvl-4">
<p>fd.dport=80 表示目的端口号为80。</p>
</li>
<li class="lvl-4">
<p>使用 or 逻辑运算符是因为TCP通信可以是进入端口80或从端口80出去的。</p>
</li>
</ul>
<p>这将捕获所有涉及端口80的TCP包，不论它们是发送到这个端口还是从这个端口发送出去的。</p>
<p>如果你想要针对远程端口进行过滤（例如，你只关心连接到你服务器端口80的外部端口），你可以修改过滤器来做这种监控：</p>
<pre><code class="language-shell">sysdig "fd.l4proto=tcp and fd.dport=80"
</code></pre>
<p>这将只捕获向本地端口80发送的TCP数据包。</p>
<p>你也可以结合使用sysdig的Chisels功能来格式化这些信息，例如，使用netstat Chisel，它提供一个网络连接统计视图，用以下命令查看端口80相关的连接：</p>
<pre><code class="language-shell">sysdig -c netstat "fd.l4proto=tcp and (fd.sport=80 or fd.dport=80)"
</code></pre>
<p>Sysdig Chisels可以为你提供更友好或者更详细的输出，并可以按照需要进行多方面的定制。</p>
<p>如果你想实时查看关于特定端口TCP流量的详细统计数据，用topconns Chisel也非常有用：</p>
<pre><code class="language-shell">sysdig -c topconns "fd.l4proto=tcp and (fd.sport=80 or fd.dport=80)"
</code></pre>
<p>上述命令将会按网络连接数量列出源端口或目的端口为80的TCP连接。记得将80替换成你想要监控的特定端口号。</p>
<h1 id="wo-ke-yi-shi-yong-sysdig-lai-jian-kong-te-ding-wang-luo-jie-kou-shang-de-icmp-bao-shu-liang-ma">我可以使用sysdig来监控特定网络接口上的ICMP包数量吗？</h1>
<p>是的，Sysdig 允许你监控特定网络接口上的 ICMP（Internet Control Message Protocol，因特网控制消息协议）包数量。ICMP 通常用于发送错误消息和操作信息，例如当一个数据包无法到达目的地时。</p>
<p>要在 Sysdig 中监控特定网络接口的 ICMP 包，你可以使用相似的过滤器语法，这次关注 icmp 协议。以下是一条具体的命令示例：</p>
<pre><code class="language-shell">sysdig -c pktcount "icmp and fd.dev=eth0"
</code></pre>
<p>在这个命令中：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>-c pktcount 是指使用 pktcount Chisel 来统计数据包。</p>
</li>
<li class="lvl-4">
<p>icmp 是指过滤协议为 ICMP 的数据包，它在 Sysdig 中代表所有与 ICMP 相关的事件。</p>
</li>
<li class="lvl-4">
<p>fd.dev=eth0 是限定只监控名为 eth0 的网络接口。</p>
</li>
</ul>
<p>你需要把 eth0 更换为你想要监控的实际网络接口。如果你想要记录接收到的 ICMP 包，使用 evt.type 过滤器和 fd.l4proto 字段来进一步细化：</p>
<pre><code class="language-shell">sysdig -c pktcount "evt.type=recvfrom and fd.l4proto=icmp and fd.dev=eth0"
</code></pre>
<p>如上所示，修改后的命令通过 evt.type=recvfrom 来指定我们只对接收到的数据包感兴趣。</p>
<p>对于发送出去的 ICMP 包，可以这样过滤：</p>
<pre><code class="language-shell">sysdig -c pktcount "evt.type=sendto and fd.l4proto=icmp and fd.dev=eth0"
</code></pre>
<p>请确保将 eth0 替换为你的网络接口的正确名称。</p>
<h1 id="jie-yu">结语</h1>
<p>Sysdig 的功能十分强大，学习和掌握它能够大大提高Linux系统管理和故障排查的效率。以上的案例只展示了Sysdig 的一部分功能，它还有许多高级的用法。建议详细阅读其官方文档或社区贡献的使用案例，实践中会发现更多有用的技能。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>sysdig</category>
      </categories>
      <tags>
        <tag>sysdig</tag>
      </tags>
  </entry>
  <entry>
    <title>nose-html-reporting plugin HTML报告排序</title>
    <url>/2018/12/26/nose_html_report_sort/</url>
    <content><![CDATA[<h1 id="can-kao-zi-liao">参考资料</h1>
<p><code>https://pypi.org/project/nose-html-reporting/ </code></p>
<h1 id="gai-shu">概述</h1>
<p>在Ubuntu 14.04.5 LTS系统使用nose生成测试报告时，使用了nose-html-reporting这个插件,但这个插件，对产生的测试报告是不排序的，比较乱，鉴于此，调整一下源码，使得测试结果能够排序。</p>
<p>为什么要排序？</p>
<p>排序后，能够方便QA排查失败用例是最初哪一个用例失败导致的，解耦用例间关系，尽可能的确保每个测试用例的独立性。</p>
<p>安装命令：</p>
<p><code>pip install nose-html-reporting </code></p>
<p>在apt archive目录（/var/cache/apt/archives/）看到，使用的是 nose-html-reporting-0.2.3.tar.gz</p>
<h1 id="shi-jian">实践</h1>
<p>默认HTML report用例未排序：</p>
<img class="shadow" src="/img/in-post/nose_report_not_sort.png" width="800">
<p>如上图所示，HTML report展示的用例文件名称，并没有顺序排序，现修改了report2.jinja2内容，将下列内容：</p>
<img class="shadow" src="/img/in-post/nose_html_before.png" width="800">
<p>调整成:</p>
<img class="shadow" src="/img/in-post/nose_html_after.png" width="800">
<p>展示的HTML效果如下图所示：</p>
<img class="shadow" src="/img/in-post/nose_html_report_sort.png" width="800">
]]></content>
      <categories>
        <category>Automation</category>
        <category>nose</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>nose</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 14.04 上部署LDAP&amp;DNS Server</title>
    <url>/2018/09/21/install_ldap_on_ubuntu14.04/</url>
    <content><![CDATA[<h1 id="an-zhuang-ldap">安装LDAP</h1>
<h2 id="an-zhuang-ruan-jian">安装软件</h2>
<p><code>sudo apt-get install slapd ldap-utils </code></p>
<p>安装过程中会提示输入设置LDAP管理员账号密码：<br>
<img class="shadow" src="/img/in-post/ldap_password.png" width="1200"></p>
<p>这里输入了12345678。</p>
<p>再次确认密码<br>
<img class="shadow" src="/img/in-post/ldap_confirm_passwd.png" width="1200"></p>
<h1 id="pei-zhi-ldap">配置LDAP</h1>
<p>打开’/etc/ldap/ldap.conf’文件按照以下内容配置修改:</p>
<pre><code class="language-shell">sudo vi /etc/ldap/ldap.conf
#
# LDAP Defaults
#

# See ldap.conf(5) for details
# This file should be world readable but not world writable.

#BASE   dc=example,dc=com
#URI    ldap://ldap.example.com ldap://ldap-master.example.com:666
BASE    dc=bigtera-os,dc=com
URI     ldap://172.16.146.134

#SIZELIMIT      12
#TIMELIMIT      15
#DEREF          never

# TLS certificates (needed for GnuTLS)
TLS_CACERT      /etc/ssl/certs/ca-certificates.crt
</code></pre>
<p>执行以下命令配置：</p>
<p><code>sudo dpkg-reconfigure slapd </code></p>
<p>以下界面选择“NO”后按Enter继续<br>
<img class="shadow" src="/img/in-post/ldap_ dpkg_reconfigure_slapd.png" width="1200"></p>
<p>输入DNS domain 名称。<a href="http://xn--bigtera-os-uy5pu07g.com">例如bigtera-os.com</a></p>
<p>输入组织名称，例如bigtera-os<br>
<img class="shadow" src="/img/in-post/ldap_doamin.png" width="1200"></p>
<p>输入LDAP管理员的密码<br>
<img class="shadow" src="/img/in-post/ldap_input_passwd.png" width="1200"></p>
<p>再次确认输入LDAP管理员密码<br>
<img class="shadow" src="/img/in-post/ldap_input_confirm_passwd.png" width="1200"></p>
<p>选择HDB数据库<br>
<img class="shadow" src="/img/in-post/ldap_select_db.png" width="1200"></p>
<p>选择删除LDAP服务时自动删除数据库<br>
<img class="shadow" src="/img/in-post/ldap_remove_db1.png" width="1200"></p>
<p>选择删除之前的数据库<br>
<img class="shadow" src="/img/in-post/ldap_remove_db2.png" width="1200"></p>
<p>选择No后，LDAP服务配置且启动<br>
<img class="shadow" src="/img/in-post/ldap_config_auto_start.png" width="1200"></p>
<h1 id="ce-shi-ldap-fu-wu">测试LDAP服务</h1>
<p>输入"ldapsearch -x"，会看到类似以下输出:</p>
<pre><code class="language-shell">wyz@LDAP:~$ ldapsearch -x
# extended LDIF
#
# LDAPv3
# base &lt;dc=bigtera-os,dc=com&gt; (default) with scope subtree
# filter: (objectclass=*)
# requesting: ALL
#

# bigtera-os.com
dn: dc=bigtera-os,dc=com
objectClass: top
objectClass: dcObject
objectClass: organization
o: bigtera-os
dc: bigtera-os

# admin, bigtera-os.com
dn: cn=admin,dc=bigtera-os,dc=com
objectClass: simpleSecurityObject
objectClass: organizationalRole
cn: admin
description: LDAP administrator

# search result
search: 2
result: 0 Success

# numResponses: 3
# numEntries: 2
wyz@LDAP:~$
</code></pre>
<h2 id="cha-kan-ldap-ban-ben">查看LDAP版本</h2>
<pre><code class="language-shell">root@LDAP:~# slapd -V
@(#) $OpenLDAP: slapd  (Ubuntu) (May 31 2017 21:52:16) $
	buildd@lgw01-30:/build/openldap-tnOaja/openldap-2.4.31/debian/build/servers/slapd
</code></pre>
<h1 id="ldap-fu-wu-qi-guan-li">LDAP服务器管理</h1>
<p>在命令行模式下管理LDAP服务器是相当困难的，所以在这里我使用了一个更简单的GUI管理工具“phpldapadmin”。</p>
<h2 id="an-zhuang-phpldapadmin">安装phpldapadmin</h2>
<p>执行以下命令安装:<br>
<code>sudo apt-get install phpldapadmin </code></p>
<h2 id="gei-phpldapadmin-mu-lu-chuang-jian-link-mu-lu">给phpldapadmin目录创建link目录</h2>
<p><code>sudo ln -s /usr/share/phpldapadmin/  /var/www/phpldapadmin </code></p>
<h2 id="xiu-gai-config-phhp-wen-jian">修改config.phhp文件</h2>
<p>打开‘/etc/phpldapadmin/config.phhp’文件，替换配置的名称。按照以下显示修改：建议先备份一下，防止修改错误。</p>
<p><code>sudo cp /etc/phpldapadmin/config.php /etc/phpldapadmin/bak_config.php </code></p>
<pre><code class="language-shell">$servers = new Datastore();
$servers-&gt;newServer('ldap_pla');
$servers-&gt;setValue('server','host','172.16.146.134');
$servers-&gt;setValue('server','base',array('dc=bigtera-os,dc=com'));
$servers-&gt;setValue('login','auth_type','session');
$servers-&gt;setValue('login','bind_id','cn=admin,dc=bigtera-os,dc=com');
</code></pre>
<h2 id="zhong-qi-ldap-fu-wu">重启LDAP服务</h2>
<p><code>sudo /etc/init.d/apache2 restart </code></p>
<h2 id="da-kai-xi-tong-80-389-duan-kou">打开系统80,389端口</h2>
<pre><code class="language-shell">wyz@LDAP:~$ sudo ufw allow 80
Rules updated
Rules updated (v6)
wyz@LDAP:~$ sudo ufw allow 389
Rules updated
Rules updated (v6)
</code></pre>
<h2 id="deng-lu-ldap-fu-wu-duan">登陆LDAP服务端</h2>
<p>通过浏览器访问 <code>http://IP/phpldapadmin </code><br>
<img class="shadow" src="/img/in-post/ldap_login_page.png" width="1200"></p>
<p>点击登陆按钮进入登陆界面<br>
<img class="shadow" src="/img/in-post/lsap_auth_page.png" width="1200"></p>
<p>输入密码后点击“认证”进入系统会看到下面的界面<br>
<img class="shadow" src="/img/in-post/ldap_login_success.png" width="1200"></p>
<p>至此LDAP的管理服务phpldapadmin算是搭建完成了。</p>
<h1 id="ldap-jian-cheng-dui-ying">LDAP简称对应</h1>
<pre><code class="language-shell">o --  organization（组织-公司）
ou -- organization unit（组织单元/部门）
c --  countryName（国家）
dc -- domainComponent（域名组件）
sn -- suer name（真实名称）
cn -- common name（常用名称）
dn -- distinguished name（专有名称）
</code></pre>
<h1 id="ldap-cao-zuo">LDAP 操作</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>本文简化操作，只以创建用户组和普通用户来进行文档的整理。</p>
</li>
</ul>
<h2 id="chuang-jian-ou">创建OU</h2>
<h3 id="create-new-entry-here">Create new entry here</h3>
<p>如下图所示，点击“Create new entry here”，创建一个新条目：</p>
<img class="shadow" src="/img/in-post/ldap_create_new_entry.png" width="1200">
<h3 id="create-object">Create Object</h3>
<p>如下图所示，选择“Generic： Organisational Unit”</p>
<img class="shadow" src="/img/in-post/ldap_create_object.png" width="1200">
<h3 id="xuan-ze-ou-hou-ru-xia-tu-suo-shi">选择OU后，如下图所示：</h3>
<img class="shadow" src="/img/in-post/ldap_select_ou.png" width="1200">
<h3 id="create-ldap-entry">Create LDAP Entry</h3>
<p>输入OU名称，例如“IT”：<br>
<img class="shadow" src="/img/in-post/ldap_create_ou_entry.png" width="1200"></p>
<h3 id="save-the-created-entry">Save the created Entry</h3>
<p>点击“Commit”按钮：<br>
<img class="shadow" src="/img/in-post/ldap_save_ou_entry.png" width="1200"></p>
<h1 id="chuang-jian-cn">创建CN</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>用phpldapadmin 时，不能添加UID号 和 GID 号，这是phpldapadmin的bug。解决办法是要先用ldapadd，添加用户的uidNumber，gidNumber如：</p>
</li>
</ul>
<pre><code class="language-shell">root@LDAP:~# vi lduser1.ldif 
# lduser1, IT, bigtera-os.com
dn: uid=lduser1,ou=IT,dc=bigtera-os,dc=com
uid: lduser1
cn: lduser1
objectClass: account
objectClass: posixAccount
objectClass: top
objectClass: shadowAccount
userPassword: 1
shadowLastChange: 14323
shadowMax: 99999
shadowWarning: 7
loginShell: /bin/bash
uidNumber: 1105
gidNumber: 1105
homeDirectory: /home/lduser1
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这里添加了一个普通账号，账号名称为lduser1.</p>
</li>
</ul>
<p>使用命令添加：</p>
<pre><code class="language-shell">root@LDAP:~# ldapadd -x -D "cn=admin,dc=bigtera-os,dc=com" -W  -f  lduser1.ldif
Enter LDAP Password: 
adding new entry "uid=lduser1,ou=IT,dc=bigtera-os,dc=com"
</code></pre>
<p>查看：</p>
<pre><code class="language-shell">root@LDAP:~# ldapsearch -x  -b "dc=bigtera-os,dc=com"
# extended LDIF
#
# LDAPv3
# base &lt;dc=bigtera-os,dc=com&gt; with scope subtree
# filter: (objectclass=*)
# requesting: ALL
#

# bigtera-os.com
dn: dc=bigtera-os,dc=com
objectClass: top
objectClass: dcObject
objectClass: organization
o: bigtera-os
dc: bigtera-os

# admin, bigtera-os.com
dn: cn=admin,dc=bigtera-os,dc=com
objectClass: simpleSecurityObject
objectClass: organizationalRole
cn: admin
description: LDAP administrator

# IT, bigtera-os.com
dn: ou=IT,dc=bigtera-os,dc=com
objectClass: organizationalUnit
objectClass: top
ou: IT

# lduser1, IT, bigtera-os.com
dn: uid=lduser1,ou=IT,dc=bigtera-os,dc=com
uid: lduser1
cn: lduser1
objectClass: account
objectClass: posixAccount
objectClass: top
objectClass: shadowAccount
shadowMax: 99999
shadowWarning: 7
loginShell: /bin/bash
uidNumber: 1105
gidNumber: 1105
homeDirectory: /home/lduser1

# search result
search: 2
result: 0 Success

# numResponses: 5
# numEntries: 4
root@LDAP:~#
</code></pre>
<p>账号创建好后，如下图所示：</p>
<img class="shadow" src="/img/in-post/ldap_show_account.png" width="1200">
<p>至此，就可以正常使用phpldapadmin添加用户和用户组了！</p>
<h1 id="chuang-jian-posix-group">创建Posix Group</h1>
<h2 id="create-a-child-entry">Create a child entry</h2>
<p>如下图所示，选择cn=admin，对其创建子条目：<br>
<img class="shadow" src="/img/in-post/ldap_create_a_child_entry.png" width="1200"></p>
<h2 id="create-object-1">Create Object</h2>
<p>选择“Generic： Posix Group”，如下图所示：<br>
<img class="shadow" src="/img/in-post/ldap_select_posix_group.png" width="1200"></p>
<p>输入组名称，如group1：<br>
<img class="shadow" src="/img/in-post/ldap_create_group.png" width="1200"></p>
<p>注意：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>不要选择已经存在的账号！</p>
</li>
</ul>
<h2 id="create-ldap-entry-1">Create LDAP Entry</h2>
<img class="shadow" src="/img/in-post/ldap_create_ldap_entry.png" width="1200">
<h2 id="save-the-entry">Save the entry</h2>
<p>点击“Commit”按钮，如下图所示：</p>
<img class="shadow" src="/img/in-post/ldap_save_entry.png" width="1200">
<h2 id="xin-zeng-zhang-hao">新增账号</h2>
<p>Create a child entry<br>
选择新创建的OU，创建子条目，如下图所示：<br>
<img class="shadow" src="/img/in-post/ldap_create_new_account.png" width="1200"></p>
<h2 id="create-object-2">Create Object</h2>
<p>输入账号名称信息，比如test01。说明：<br>
password加密算法，选择crypt.</p>
<img class="shadow" src="/img/in-post/ldap_crypt.png" width="1200">
<h2 id="create-ldap-entry-2">Create LDAP Entry</h2>
<img class="shadow" src="/img/in-post/ldap_create_crypt_user.png" width="1200">
<h2 id="save-entry">Save entry</h2>
<img class="shadow" src="/img/in-post/ldap_save_ou_user.png" width="400">
<h1 id="rename-user">Rename user</h1>
<p>选择新创建的账号，对其进行修改操作<br>
<img class="shadow" src="/img/in-post/ldap_rename01.png" width="1200"></p>
<p>将cn=test01 修改为 uid=test01<br>
<img class="shadow" src="/img/in-post/ldap_rename02.png" width="1200"></p>
<p>点击“Rename”后：<br>
<img class="shadow" src="/img/in-post/ldap_rename03.png" width="1200"></p>
<p>修改loginShell，将/bin/sh修改为 /bin/bash：<br>
<img class="shadow" src="/img/in-post/ldap_shell.png" width="1200"></p>
<p>点击“Upgrade Object”后，账号信息发送了变化：<br>
<img class="shadow" src="/img/in-post/ldap_show_update.png" width="1200"></p>
<h2 id="add-attribute">Add attribute</h2>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>LDAP的 user, 要加上 displayName 和 mail，因为没有这些attribute， search出来的结果会被filter掉。 标准的LDAP账号，应该是具有这些属性信息的。</p>
</li>
</ul>
<h3 id="add-new-attribute">Add new attribute</h3>
<img class="shadow" src="/img/in-post/ldap_attribute01.png" width="1200">
<p>Add DisplayName attribute</p>
<img class="shadow" src="/img/in-post/ldap_attribute02.png" width="1200">
<p>Add email attribute</p>
<img class="shadow" src="/img/in-post/ldap_attribute03.png" width="1200">
<p>其他账号的创建，请参考“新增账号”章节。</p>
<h1 id="phpldapadmin-cun-zai-de-wen-ti">phpldapadmin存在的问题</h1>
<h2 id="cant-create-a-new-entry">Can’t create a new entry</h2>
<p>现象</p>
<p>创建新实体的时候，UI右方会显示Error, trying to get a non-existant value(appearance, password_hash)</p>
<img class="shadow" src="/img/in-post/ldap_issue1.png" width="1200">
<p>解决方法</p>
<p>将password_hash在/usr/share/phpldapadmin/lib/TemplateRender.php(第2469行)更改为password_hash_custom。</p>
<h2 id="chuang-jian-zhang-hao-de-shi-hou-wu-fa-xuan-ze-gid">创建账号的时候，无法选择gid</h2>
<p>现象</p>
<p>本文在创建CN章节有提到，操作方法请参考本文“创建CN”这章节内容。</p>
<p>解决方法</p>
<p>后台创建账号，再在phpldapadmin web界面创建group 和 账号。</p>
<h2 id="virtual-stor-ldap-zhang-hao-dao-ru-ce-shi">Virtual Stor LDAP 账号导入测试</h2>
<img class="shadow" src="/img/in-post/ldap_issue2.png" width="1200">
<img class="shadow" src="/img/in-post/ldap_issue3.png" width="1200">
<img class="shadow" src="/img/in-post/ldap_issue4.png" width="1200">
<h1 id="zong-jie">总结</h1>
<p>搭建的步骤按照文章的内容一步一步来操作，看似很简单，但是希望在看本教程的时候，看懂每一步再下手，不要盲目的去重复上面的事情，只有这样才能事半功倍。</p>
<h1 id="can-kao-wen-dang">参考文档</h1>
<pre><code class="language-shell">    https://my.oschina.net/u/2496664/blog/801996
    https://my.oschina.net/guol/blog/338362
    https://www.zhukun.net/archives/7980
    http://www.topjishu.com/8781.html
</code></pre>
<h1 id="fu-lu">附录</h1>
<h2 id="da-jian-dns-server">搭建DNS Server</h2>
<h3 id="can-kao-wen-dang-1">参考文档</h3>
<p><a href="https://help.ubuntu.com/14.04/serverguide/dns.html">https://help.ubuntu.com/14.04/serverguide/dns.html</a></p>
<p>这里简单记录一下内容。</p>
<h3 id="caching-nameserver">Caching Nameserver</h3>
<pre><code class="language-shell">root@LDAP:~# cat /etc/bind/named.conf.options
options {
	directory "/var/cache/bind";

	// If there is a firewall between you and nameservers you want
	// to talk to, you may need to fix the firewall to allow multiple
	// ports to talk.  See http://www.kb.cert.org/vuls/id/800113

	// If your ISP provided one or more IP addresses for stable 
	// nameservers, you probably want to use them as forwarders.  
	// Uncomment the following block, and insert the addresses replacing 
	// the all-0's placeholder.

	// forwarders {
	// 	0.0.0.0;
	// };

       forwarders {
                8.8.8.8;
                172.16.146.134;
           };
	//========================================================================
	// If BIND logs error messages about the root key being expired,
	// you will need to update your keys.  See https://www.isc.org/bind-keys
	//========================================================================
	dnssec-validation auto;

	auth-nxdomain no;    # conform to RFC1035
	listen-on-v6 { any; };
};
</code></pre>
<h3 id="primary-master">Primary Master</h3>
<pre><code class="language-shell">root@LDAP:~# cat /etc/bind/named.conf.local
//
// Do any local configuration here
//

// Consider adding the 1918 zones here, if they are not used in your
// organization
//include "/etc/bind/zones.rfc1918";


zone "bigtera-os.com" {
	type master;
        file "/etc/bind/db.bigtera-os.com";
};

zone "146.16.172.in-addr.arpa" {
        type master;
        file "/etc/bind/db.172";
};
root@LDAP:~#
</code></pre>
<pre><code class="language-shell">root@LDAP:~# cat /etc/bind/db.bigtera-os.com 
;
; BIND data file for local loopback interface
;
$TTL	604800
@	IN	SOA	bigtera-os.com. root.bigtera-os.com. (
			      2		; Serial
			 604800		; Refresh
			  86400		; Retry
			2419200		; Expire
			 604800 )	; Negative Cache TTL
	IN	A	172.16.146.134
;
@	IN	NS	ns.bigtera-os.com.
@	IN	A	172.16.146.134
@	IN	AAAA	::1
ns	IN	A	172.16.146.134
www	IN	A	172.16.146.134
root@LDAP:~#
</code></pre>
<pre><code class="language-shell">root@LDAP:~# cat  /etc/bind/named.conf.local 
//
// Do any local configuration here
//

// Consider adding the 1918 zones here, if they are not used in your
// organization
//include "/etc/bind/zones.rfc1918";


zone "bigtera-os.com" {
	type master;
        file "/etc/bind/db.bigtera-os.com";
};

zone "146.16.172.in-addr.arpa" {
        type master;
        file "/etc/bind/db.172";
};
root@LDAP:~#
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>LDAP</tag>
      </tags>
  </entry>
  <entry>
    <title>S3 boto set content from filename</title>
    <url>/2019/02/22/s3_boto_set_content_from_filename/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>自动化测试ceph S3 object时，需要上传不同的文件到不同的目录 与子目录下，并展示目录以及目录下子文件是否正确，为此先写了一个调试脚本，调试完毕后再集成到自动化测试框架中。</p>
<h1 id="jiao-ben">脚本</h1>
<p><code>s3_boto_set_content_from_filename.py</code></p>
<pre><code class="language-python">root@node244:~# cat s3_boto_set_content_from_filename.py 
import os
import boto
import shutil
from boto.s3.key import Key
from boto.s3.connection import S3Connection, OrdinaryCallingFormat

import boto.s3.connection


from ezs3.command import do_cmd

filenames = ['sample.txt', 'notes/2019/January/sample.txt', 'notes/2019/February/sample2.txt',
             'notes/2019/February/sample3.txt', 'notes/2019/February/sample4.txt',
             'notes/2019/sample5.txt', 'nose/delete/delete_object.txt']

# create s3 connection
def s3_con(access_key, secret_access_key, host=None, port=80):
    """
    connect to S3
    :param access_key, string, access_key
    :param secret_access_key, string, secret_access_key
    :param host, string, S3 server IP address
    :param port, string, S3 port
    """

    host = '172.17.73.244'

    conn = S3Connection(access_key,
                        secret_access_key,
                        host=host,
                        port=port,
                        calling_format=OrdinaryCallingFormat(),
                        is_secure=False)

    return conn


def upload_dir(conn, bucket_name, upload_path=None):
    upload_path = "/tmp/nose_up" if upload_path is None else upload_path

    bucket = conn.get_bucket(bucket_name)

    for root, dirs, files in os.walk(upload_path):
        for name in files:
            path = root.split(os.path.sep)[1:]
            path.append(name)
            # key_id = os.path.join(*path)
            key_id = os.path.join(*path) + '/'
            k = Key(bucket)
            k.key = key_id
            k.set_contents_from_filename(os.path.join(root, name))

def upload_file_into_bucket(conn, bucket_name, upload_path=None):
    """
    Upload some objects into bucket
    :param conn, a instance, s3 connection
    :param bucket_name, string, a bucket name
    :param upload_path, string, upload file path
    """

    upload_path = "/tmp/nose_up" if upload_path is None else upload_path
    destDir = ''

    print('[Action]   Upload files to bucket , '
                 'set contents of object ) from filenames', bucket_name, filenames)

    if os.path.exists(upload_path):
        shutil.rmtree(upload_path)
        os.mkdir(upload_path, 0755)
 
    if not os.path.exists(upload_path):
        os.mkdir(upload_path, 0755)
 
    for each_file in filenames:
        # dir_path = upload_path + os.sep + os.path.dirname(each_file)
        dir_path = os.path.join(upload_path, os.path.dirname(each_file))
        file_name = os.path.basename(each_file)
        print("--  dir_path is : , file_name is : ", dir_path, file_name)
        if not os.path.exists(dir_path):
            if dir_path != '':
                os.makedirs(dir_path, 0755)
            # print("--  echo content to : ", dir_path + os.sep + file_name)
            do_cmd("echo {} &gt; {}".format(file_name, dir_path + os.sep + file_name), 30)
        elif not os.path.exists(each_file):
            full_name = dir_path + os.sep + file_name
            print("--  full_name is : ", full_name)
            do_cmd("echo {} &gt; {}".format(file_name, dir_path + os.sep + file_name), 30)

    try:
        bucket = conn.get_bucket(bucket_name)
        for each_file in filenames:
            key = Key(bucket, each_file)
            key.set_contents_from_filename(upload_path + os.sep + each_file)
#            full_key_name = os.path.join(upload_path, each_file)
#            print("----- full_key_name is : ", full_key_name)
#            k = bucket.new_key(full_key_name)
#            k.set_contents_from_filename(full_key_name)
#            # k.set_contents_from_filename(each_file)

#         for root, dirs, files in os.walk(upload_path):
#             for each_file in files:
#                 key = Key(bucket, each_file)
#                 key.set_contents_from_filename(upload_path + os.sep + each_file)
#        for each_file in filenames:
#            sourcepath = os.path.join(upload_path + '/' + each_file)
#            destpath = os.path.join(destDir + '/' + each_file)
#            k = boto.s3.key.Key(bucket)
#            k.key = destpath
#            k.set_contents_from_filename(sourcepath)
    except Exception as e:
        print("[ERROR]  Upload s3 object to bucket : ({}) failed, "
              "backend return : ({})".format(bucket_name, str(e)))
        return str(e)


def list_object_in_bucket(conn, bucket_name, prefix=None):
    """
    List all objects with a prefix under a bucket
    :param conn, instance, S3 connection
    :param bucket_name, string, a bucket name
    :param prefix, string, a object prefix name
    """

    print("[Action]   Start to list object in bucket : (%s)", bucket_name)
    prefix = '' if prefix is None else prefix

    match_objs = []

    try:
        bucket = conn.get_bucket(bucket_name)

        for obj in bucket.list(prefix=prefix):
            match_objs.append(obj.key)

        len_mat_objects = len(match_objs)
        if int(len_mat_objects) &gt; 0:
            print("[Success]  List object : (%s) from bucket : (%s) success.", match_objs, bucket_name)
    except Exception as e:
        print("[ERROR]  Upload a single S3 object to bucket : ({}) failed, "
                      "backend return : ({})".format(bucket_name, str(e)))

    return match_objs



if __name__ == '__main__':
    access_key = '62HVFE4XEYSSA9C3C7U0'
    secret_access_key = 'gHlpbsR6E9nQ4EaLBcmrlNxwQ96NfeCpYq1kfMSq'
    bucket_name = 'bucket01'
    conn = s3_con(access_key, secret_access_key)
    # upload_dir(conn, bucket_name)
    upload_file_into_bucket(conn, bucket_name)
    list_object_in_bucket(conn, bucket_name)

</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>重置ESXi root密码</title>
    <url>/2019/04/29/reset_esxi_password/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>其他人创建的环境，碰到ESXi root密码无人记得了，上面又有蛮多重要的VM，如何重置ESXi root密码，成为本文介绍的话题。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="shi-yong-dan-yong-hu-mo-shi-geng-gai-mi-ma">使用单用户模式更改密码</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>(1) 用Linux光盘启动，如：RHEL5，进入到系统的救援模式。</p>
</li>
<li class="lvl-2">
<p>(2) 在命令提示符界面下，运行mount /dev/sda5 /mnt/test  #这里的test目录是自己创建的，用于挂载用</p>
</li>
<li class="lvl-2">
<p>(3) sh-3.2# cp  /mnt/sda5/state.tgz /tmp/</p>
</li>
<li class="lvl-2">
<p>(4) 进入到/tmp 目录下，依次解压state.tgz local.tgz</p>
</li>
</ul>
<pre><code class="language-shell">sh-3.2# tar xvfz state.tgz
sh-3.2# tar xvfz local.tgz
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>(5) 修改存放用户密码的配置文件，将root用户的密码清除掉（即通过MD5加密的长串字符）</p>
</li>
</ul>
<pre><code class="language-shell">sh-3.2# vi etc/shadow
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>(6) 重要的步骤：</p>
</li>
</ul>
<pre><code class="language-shell">sh-3.2# rm -rf state.tgz local.tgz
sh-3.2# tar czvf local.tgz etc
sh-3.2# tar czvf state.tgz local.tgz
sh-3.2# cp statge.tgz /mnt/test
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>(7) 重启ESXi主机即可</p>
</li>
</ul>
]]></content>
      <categories>
        <category>ESXi</category>
      </categories>
      <tags>
        <tag>ESXi</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title>iSCSI 相关操作介绍</title>
    <url>/2019/05/02/iscsi_option/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文主要介绍作为initiator端时，如何访问存储端IP_SAN device。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="cha-kan-cun-chu-scst-de-yi-xie-xin-xi">查看存储scst的一些信息：</h2>
<p><code>/sys/kernel/scst_tgt/devices/tgtX_X</code></p>
<h2 id="gua-zai-iscsi-juan">挂载iscsi卷</h2>
<p><code>iscsiadm -m discovery -t st -p 10.16.17.191 -l </code> 或者</p>
<p><code>iscsiadm -m node -l </code></p>
<p>或者指定target进行挂载：<code>iscsiadm -m node -T iqn.2016-01.11test:storage  -p 10.16.17.11 -l</code></p>
<h2 id="cha-zhao-i-scsi-targets-zhu-ji-de-target-name">查找iSCSI targets主机的target name</h2>
<p><code>iscsiadm --mode discovery --type sendtargets --portal 192.168.0.9</code></p>
<p>注：假设target主机ip为192.168.0.9</p>
<h2 id="login-target">login target</h2>
<p><code>iscsiadm --mode node --targetname iqn.renyuannetdisk --portal 192.168.0.9:3260 --login</code></p>
<p>注：假设target name为iqn.renyuannetdisk，3260为iSCSI服务默认端口</p>
<h2 id="i-scsi-target-duan-she-zhi">iSCSI target端设置</h2>
<p>initiator客户端执行login命令后，在target服务器端可以发现新通道。把要分配给initiator客户端的卷通过该通道映射给initiator。</p>
<h2 id="zhong-qi-ke-hu-duan-iscsi-initiator-fu-wu">重启客户端iscsi initiator 服务</h2>
<p><code>/etc/init.d/open-iscsi restart</code></p>
<h2 id="cha-kan-iscsi-targets-ying-she-guo-lai-de-juan">查看iscsi targets映射过来的卷</h2>
<p><code>fdisk -l </code></p>
<p>或 用dmesg 或tail -f /var/log/messages 命令查看</p>
<h2 id="chuang-jian-fen-qu">创建分区</h2>
<p><code>fdisk /dev/sdb</code></p>
<p>在提示行后输入m查看fdisk命令，输入n新建分区。</p>
<p>注：假设映射过来的卷设备名为sdb</p>
<h2 id="ge-shi-hua-fen-qu">格式化分区</h2>
<p><code>mkfs.ext3 /dev/sdb1</code></p>
<h2 id="gua-zai-wen-jian-xi-tong">挂载文件系统</h2>
<pre><code class="language-shell">mkdir /mnt/iscsi

mount /dev/sdb1 /mnt/iscsi
</code></pre>
<h2 id="zhu-xiao-i-scsi-initiator-deng-lu">注销iSCSI initiator登录</h2>
<p>不需要时可以注销iSCSI initiator登录，先umount文件系统，再把第四步命令的login参数改成logout执行即可：</p>
<pre><code class="language-shell">umount /mnt/iscsi

iscsiadm --mode node --targetname iqn.renyuannetdisk --portal 192.168.0.9:3260 --logout
</code></pre>
<h2 id="shan-chu-zhi-ding-target">删除指定Target</h2>
<p>用logout只是暂时登出，发现的target信息会保存在数据库中，下次重启iscsi服务时(service iscsi restart)，仍会找回该Target卷。如果想从数据库中删除该Target，需用以下命令：</p>
<p>查询数据库中Target内容：</p>
<p><code>iscsiadm -m node</code></p>
<h2 id="shan-chu-zhi-ding-de-target">删除指定的Target：</h2>
<p><code>iscsiadm -m node -o delete </code></p>
<p>or</p>
<p><code>iscsiadm --mode node -o delete --targetname iqn.renyuannetdisk --portal 192.168.0.9:3260 </code></p>
<p>or</p>
<p><code>iscsiadm -m node -o delete -T TARGET -p IP:port</code></p>
<h1 id="initiator-name-ge-shi-shuo-ming">Initiator name 格式说明：</h1>
<p><a href="https://www.ietf.org/rfc/rfc3721.txt">https://www.ietf.org/rfc/rfc3721.txt</a> 参考 : 1.1.  Constructing iSCSI names using the iqn. Format</p>
<h1 id="ke-hu-duan-fa-xian-i-scsi-diao-ce">客户端发现iSCSI 调测</h1>
<p>当客户端尝试登录iSCSI target时，发起discovery and login命令，如果命令执行结果出错，可以通过如下方式来调测：</p>
<p><code>strace -f -s 1024 iscsiadm -m discovery -t iqn.2018-08.nose:target-acl2 -p 172.17.75.98</code></p>
<p>那server端，是谁在负责处理客户端的连接请求呢？</p>
<p>iscsi-scstd 这个用户态进程负责处理</p>
<pre><code class="language-shell">root@node248:~# ps -ef |grep iscsi-scstd | grep -v grep
root      293083       1  0 Sep22 ?        00:00:04 iscsi-scstd
root@node248:~# 

strace -f -p 293083
</code></pre>
<p>上面的这个指令，在客户端发起连接请求时候，会跟踪出详细连接信息</p>
]]></content>
      <categories>
        <category>iSCSI</category>
      </categories>
      <tags>
        <tag>iSCSI</tag>
      </tags>
  </entry>
  <entry>
    <title>ESXi常用命令</title>
    <url>/2019/04/30/exsi_commands/</url>
    <content><![CDATA[<h3 id="gai-shu">概述</h3>
<p>本文摘抄ESXi的一些基本命令范例， mark下来备用。</p>
<h3 id="kan-ni-de-esx-ban-ben">看你的esx版本</h3>
<pre><code class="language-shell">vmware -v                      #  看你的esx版本
VMware ESXi 5.0.0 build-469512
</code></pre>
<pre><code class="language-shell">esxcfg-info -a                 #  显示所有ESX相关信息
esxcfg-info -w                 #  显示esx上硬件信息
service mgmt-vmware restart    #  重新启动vmware服务
esxcfg-vmknic -l               #  查看宿主机IP地址
 
esxcli hardware cpu list       #  cpu信息 Brand，Core Speed，
esxcli hardware cpu global get #  cpu信息 （CPU Cores）
esxcli hardware memory get     #  内存信息 内存 Physical Memory
esxcli hardware platform get   #  硬件型号，供应商等信息,主机型号,Product Name 供应商,Vendor Name
esxcli hardware clock get      #  当前时间
 
esxcli system version get                           # 查看ESXi主机版本号和build号
esxcli system maintenanceMode set --enable yes      # 将ESXi主机进入到维护模式
esxcli system maintenanceMode set --enable no       # 将ESXi主机退出维护模式
esxcli system settings advanced list -d             # 列出ESXi主机上被改动过的高级设定选项
esxcli system settings kernel list -d               # 列出ESXi主机上被变动过的kernel设定部分
esxcli system snmp get | hash | set | test          # 列出、测试和更改SNMP设定
 
esxcli vm process list                              # 利用esxcli列出ESXi服务器上VMs的World I(运行状态的)
esxcli vm process kill -t soft -w WorldI           # 利用esxcli命令杀掉VM
 
vim-cmd hostsvc/hostsummary          # 查看宿主机摘要信息
vim-cmd vmsvc/get.datastores         # 查看宿主存储空间信息
vim-cmd vmsvc/getallvms              # 列出所有虚拟机
 
vim-cmd vmsvc/power.getstate VMI    # 查看指定VMI虚拟状态
vim-cmd vmsvc/power.shutdown VMI    # 关闭虚拟机
vim-cmd vmsvc/power.off VMI         # 如果虚拟机没有关闭，使用poweroff命令
vim-cmd vmsvc/get.config VMI        # 查看虚拟机配置信息
 
esxcli software vib install -d /vmfs/volumes/datastore/patches/xxx.zip  # 为ESXi主机安装更新补丁和驱动
 
esxcli network nic list         # 列出当前ESXi主机上所有NICs的状态
esxcli network vm list          # 列出虚拟机的网路信息
esxcli storage nmp device list  # 理出当前NMP管理下的设备satp和psp信息
esxcli storage core device vaai status get # 列出注册到PS设备的VI状态
 
esxcli storage nmp satp set --default-psp VMW_PSP_RR --satp xxxx # 利用esxcli命令将缺省psp改成Round Robin
</code></pre>
<p>查看FC WWN號信息：</p>
<pre><code class="language-shell">CLI ( SSH, vMA, vCLI)
esxcfg-mpath -b |grep WWNN | sed 's/.*fc //;s/Target.*$//'
</code></pre>
]]></content>
      <categories>
        <category>ESXi</category>
      </categories>
      <tags>
        <tag>ESXi</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title>perf检查ceph-osd CPU使用率高问题</title>
    <url>/2019/05/06/perf_check_osd_cpu_high/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>今天早晨 QA 发现 LAB里的一套集群环境里，124~128集群里面，128节点ceph-osd cpu load重，CPU使用率是 200%~400% 之间。</p>
<img class="shadow" src="/img/in-post/perf-1.png" width="1200">
<p>我用strace 粗略地看了下，没看出什么端倪。只能上perf了。</p>
<h1 id="pai-cha">排查</h1>
<h2 id="perf-top">perf top</h2>
<p>首先用perf top查看下：</p>
<img class="shadow" src="/img/in-post/perf-2.png" width="1200">
<p>CPU消耗大户是ceph-osd，其中用户态的operator&lt;&lt; 操作罪魁祸首，其中operator&lt;&lt;看起来是运算符重载，应该是和日志打印相关。</p>
<h2 id="perf-record">perf record</h2>
<p>找到ceph-osd的进程ID 4966， 用如下指令采集下：</p>
<pre><code class="language-shell">perf record -e cpu-clock -g -p 4966
</code></pre>
<pre><code class="language-shell">-g 选项是告诉perf record额外记录函数的调用关系
-e cpu-clock 指perf record监控的指标为cpu周期
-p 指定需要record的进程pid
</code></pre>
<p>我们观测的对象是ceph-osd。运行10秒中左右，ctrl+C中断掉perf record:</p>
<pre><code class="language-shell">root@converger-128:~# perf record -e cpu-clock -g -p 4966
^C[ perf record: Woken up 7 times to write data ]
[ perf record: Captured and wrote 5.058 MB perf.data (17667 samples) ]
root@converger-128:~#
</code></pre>
<p>在root目录下会产生出来 perf.data文件。</p>
<h2 id="perf-report">perf report</h2>
<p>用如下指令查看dump 出来的perf.data</p>
<pre><code class="language-shell">perf report -i perf.data
</code></pre>
<p>输出如下：</p>
<img class="shadow" src="/img/in-post/perf-3.png" width="1200">
<p>我们把operator&lt;&lt;展开：</p>
<img class="shadow" src="/img/in-post/perf-4.png" width="1200">
<p>我们看到，大部分operator&lt;&lt;的调用是由gen_preﬁx函数产生的。</p>
<h1 id="fen-xi">分析</h1>
<p>这部分代码代码在：</p>
<pre><code class="language-shell">osd/ReplicatedBackend.cc
------------------------------
#define dout_subsys ceph_subsys_osd
#define DOUT_PREFIX_ARGS this
#undef dout_prefix
#define dout_prefix _prefix(_dout, this)
static ostream&amp; _prefix(std::ostream *_dout, ReplicatedBackend *pgb) {
 &nbsp;return *_dout &lt;&lt; pgb-&gt;get_parent()-&gt;gen_dbg_prefix(); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
}
</code></pre>
<p>原因是128集群之前有人分析ceph-osd.4，ceph.conf 里面debug osd = 0/20, 尽管不会往磁盘里面打印日志，但是因为OSD crash的时候，需要dump 级别为20 的debug log，因此，大量的osd debug log会暂存在内存的环形buﬀer 中，因此，gen_preﬁx函数被大量的调用，消耗了太多的CPU资源实时修改ceph-osd debug_osd的级别，并修改ceph.conf 永久生效，发现ceph-osd CPU使用正常。</p>
<pre><code class="language-shell">root@converger-128:/etc/ceph# ceph daemon osd.5 config set debug_osd 0
{
 &nbsp; &nbsp;"success": ""
}
root@converger-128:/etc/ceph# ceph daemon osd.4 config set debug_osd 0
{
 &nbsp; &nbsp;"success": ""
}
</code></pre>
<img class="shadow" src="/img/in-post/perf-5.png" width="1200">
<h1 id="qi-ta">其他</h1>
<p>perf工具我们产品并不自带，如果大家需要的话，需要自行编译。我们buildman上面，进入linux-kernel</p>
<pre><code class="language-shell">jenkins@buildman-trusty:~/jobs/virtualstor_scaler_7.0/workspace/linux-kernel/tools/perf$
</code></pre>
<p>执行make，即可得到perf 可执行文件。（当然了，之所以这么顺利，是因为我们的buildman 已经编译出了内核。）</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>perf</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>S3 placement to create bucket</title>
    <url>/2019/07/01/s3_placement_create_bucket/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近存储产品开始支持多个S3 Placement了，即上传S3 Object，默认存放到Default S3 Placement，如果有其他S3 Placement的存在，需要指定具体的S3 Placement名称，为此写了一测试脚本方便测试验证此功能。</p>
<h1 id="jiao-ben">脚本</h1>
<p><code>s3_placement_create_bucket.py</code></p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import sys
import json
import boto
import boto.s3.connection

from ezs3.command import do_cmd


def connect_s3(access_key, secret_key, host):
    print("Connection to S3")
    conn = boto.connect_s3(
           aws_access_key_id=access_key,
           aws_secret_access_key=secret_key,
           host=host,
           calling_format = boto.s3.connection.OrdinaryCallingFormat(),
          )

    return conn


def check_s3_placement(s3_placement):
    s3_placement_set = set()

    res = do_cmd("radosgw-admin zone get --rgw-zone=default").strip()
    res = json.loads(res)

    for each_key in res['placement_pools']:
        s3_placement_set.add(each_key['key'])

    if s3_placement not in s3_placement_set:
        print("[ERROR]  Not exist this S3 placement, please create it first.")
        sys.exit(1)

def create_bucket(conn, bucket_name, s3_placement):
    print("Start to create bucket :({}) in S3 placement : ({})".format(bucket_name, s3_placement))
    try:
        bucket = conn.create_bucket(bucket_name, location=':{}'.format(s3_placement))
    except:
        bucket = conn.get_bucket(bucket_name)

    return bucket

if __name__ == "__main__":
    access_key ='7T0GOCXVGOJXFI4IQJH2'
    secret_key = 'uLqJD5hrkMqtgg0lNQWTWLGod7415L0mB5BIxZEX'
    host = '172.17.75.97'
    bucket_name = 'seg_bucket_test'
    s3_placement = 'new_s3_placement'


    conn = connect_s3(access_key, secret_key, host)
    check_s3_placement(s3_placement)
    create_bucket(conn, bucket_name, s3_placement)

</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>开启kernel debug</title>
    <url>/2019/07/04/debug_kernel/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>有时候需要查看更详细的kernel堆栈信息，本文介绍如何开启kernel debug。</p>
<h1 id="shi-jian">实践</h1>
<pre><code class="language-shell">echo 'module ceph +p' &gt; /sys/kernel/debug/dynamic_debug/control
echo 'module libceph +p' &gt; /sys/kernel/debug/dynamic_debug/control
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Summary of S3 Sample</title>
    <url>/2019/08/08/s3_sample/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>When verifying some features of S3, you often need to use some basic operations, for this reason, record these contents, easy to find at a later stage.</p>
<h1 id="script">Script</h1>
<p><code>s3_sample.py</code></p>
<pre><code class="language-python"># -*-coding:UTF-8-*-

import boto

import boto.s3.connection
import os
from boto.s3.key import Key


access_key = 'WJ1ID9FHBAR71C1TTQ0I'
secret_key = 'NTK5DNbFSYYItB6kyvkYgJ3wA3tEDe4RxJhUcKcU'


# 建立连接
print "createt connection BEGIN \n"
conn = boto.connect_s3(
        aws_access_key_id = access_key,
        aws_secret_access_key = secret_key,
        host = '172.17.59.8',
        is_secure=False,    #uncomment if you are not using ssl
        calling_format = boto.s3.connection.OrdinaryCallingFormat(),
        )
print conn

print "createt connection  END\n"

#列出所有已有的bucket，以及创建时间
print "list all the bucket in this account, empty of course"
for bucket in conn.get_all_buckets():
    print "{name}\t{created}".format(
            name = bucket.name,
            created = bucket.creation_date,
            )
print "list all buckets finished\n"

# 查找bucket是否存在
print "create bucket and list all bucket BEGIN"
bucket_name = "my-bucket"
bucket = conn.lookup(bucket_name)
if bucket == None :
    print "bucket {} is not exists".format(bucket_name)
    # 创建bucket
    bucket = conn.create_bucket(bucket_name)
    # 再次列出所有的bucket，查看是否存在新建的bucket
    for bucket in conn.get_all_buckets():
        print "{name}\t{created}".format(
                name = bucket.name,
                created = bucket.creation_date,
                )
    print "create bucket and list all bucket END\n"

#查看bucket中的所有对象
print "list all the OBJECTS in bucket, empty of course"
bucket = conn.lookup(bucket_name)
for key in bucket.list():
    print "{name}\t{size}\t{modified}".format(
                name = key.name,
                size = key.size,
                modified =
                key.last_modified,
           )
print "list all the OBJECTS in bucket END\n"

# 上传对象，对象的内容来自字符串
key_name = "my-object"

print "upload object from string ,and list it "
key = bucket.lookup(key_name)
if key == None:
    print "key {} is not exists in bucket {}".format(key_name,bucket_name)
    k = Key(bucket)
    k.key = key_name
    k.set_contents_from_string("this object is generated by string")
    for key in bucket.list():
        print "{name}\t{size}\t{modified}".format(
                    name = key.name,
                    size = key.size,
                    modified =
                    key.last_modified,
               )

print "upload object from string ,and list it END\n "

# 上传对象，对象的内容来自文件
key_name = "my-object-from-file"

print "upload object from filename ,and list it "
filename_need_upload = "/var/log/kern.log"
key = bucket.lookup(key_name)
if key == None:
    print "key {} is not exists in bucket {}".format(key_name,bucket_name)
    k = Key(bucket)
    k.key = key_name
    k.set_contents_from_filename(filename_need_upload)

    #上传完毕后，列出所有的对象，查看新上传的文件是否存在。
    for key in bucket.list():
        print "{name}\t{size}\t{modified}".format(
                    name = key.name,
                    size = key.size,
                    modified =
                    key.last_modified,
               )

# 上传对象的同时，设置对象的元数据信息
key_name = "my-object-with-meta"
filename_need_upload = "/var/log/kern.log"
key = bucket.lookup(key_name)
if key == None:
    print "key {} is not exists in bucket {}".format(key_name,bucket_name)
    k = Key(bucket)
    k.key = key_name
    k.metadata = { 'name':'xyz', 'meta2':'value2'}
    k.set_contents_from_filename(filename_need_upload)

    for key in bucket.list():
        print "{name}\t{size}\t{modified}".format(
                    name = key.name,
                    size = key.size,
                    modified =
                    key.last_modified,
               )

# 获取对象的元数据信息
key_name = "my-object-with-meta"
k = bucket.get_key(key_name)
print "name {} \nmeta {}".format(key_name, k.metadata)

# 更新已有对象的元数据信息：
# key_name = "my-object"
# k = bucket.get_key(key_name)
# meta_add = {'meta-key':'meta data is updated afterward', 'meta2':'meta data 2'}
# set_remote_metadata第一个参数为添加的元数据信息，第二个参数为要删除的属性
# k.set_remote_metadata(meta_add, {}, True)


k = bucket.get_key(key_name)
print "name {} \nmeta {}".format(key_name, k.metadata)


print "upload object from file ,and list it END\n"
# 下载刚刚上传的对象
key_name = "my-object-from-file"
filename_of_download = "/tmp/kern.log.bak"


print "download object to file string ,and check file "
key = bucket.get_key(key_name)
key.get_contents_to_filename(filename_of_download)

if os.path.isfile(filename_of_download):
    print "{} is file ,download successfully".format(filename_of_download)

print "download object to file string ,and check file END\n "


# 设置ACL
print "set acl"
bucket_name = "my-bucket"
bucket = conn.lookup(bucket_name)
print "set my-bucket's acl to private"
access_control_policy = 'private'
bucket.set_acl(access_control_policy)
print "set one object's acl to public-read"
access_control_policy = 'public-read'
key = list(bucket.list())[0]
key.set_acl(access_control_policy)

print "set acl END\n"


# 获取ACL
print "get acl"
acp = bucket.get_acl()
for grant in acp.acl.grants:
    print grant.permission, grant.display_name, grant.email_address, grant.id

acp = key.get_acl()
for grant in acp.acl.grants:
    print grant.permission, grant.display_name, grant.email_address, grant.id
print "get acl END\n"


# 删除bucket中的某个对象

key_name = "my-object-from-file"
bucket.delete_key(key_name)

# 删除之后查看对应的key 是否存在
for key in bucket.list():
    print "{name}\t{size}\t{modified}".format(
                name = key.name,
                size = key.size,
                modified =
                key.last_modified,
           )

# 删除bucket中所有的objcet
for key in bucket.list():
    bucket.delete_key(key.name)

# 删除bucket
bucket_name = "my-bucket"
conn.delete_bucket(bucket_name)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>ceph</category>
        <category>S3</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>消除pylint warn/error</title>
    <url>/2019/08/23/fix_pylint_warn_error/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在写pytest用例期间，使用pylint检查代码质量，出现了一些这样或者那样的pylint warn/error，如何消灭这些warn/error，本文介绍一个unexpected-keyword-arg warn的消除方法。</p>
<h1 id="xian-xiang">现象</h1>
<p>以下文代码为示例：</p>
<img class="shadow" src="/img/in-post/code_example.png" width="1200">
<p>这里有一行 <code>md_dev = md.get_md_dev(md_info, _host=src_gw) </code></p>
<p>由于传递的参数 _host，这个参数是remote call（@callable）使用的，即可以在本机执行其他机器的指令，所以_host就是其他机器的IP地址，这里一旦带上 _host参数，执行pylint就会出现unexpected-keyword-arg，如何解决呢？</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>在对应出现error/warn的代码行后面，增加disable具体的error/warn即可：</p>
<pre><code class="language-shell">md_dev = md.get_md_dev(md_info, _host=src_gw) # pylint: disable=unexpected-keyword-arg
</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pylint</tag>
      </tags>
  </entry>
  <entry>
    <title>谁在使用Linux SWAP</title>
    <url>/2019/09/09/linux_swap/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文概述Linux SWAP 有哪些进程在使用，以及如何关闭/开启SWAP。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="cha-kan-na-xie-jin-cheng-zhan-yong-swap-fen-qu">查看哪些进程占用swap分区</h2>
<p>参考链接： <code>https://blog.csdn.net/m0_37886429/article/details/73826868</code></p>
<pre><code class="language-shell">for i in $(ls /proc | grep "^[0-9]" | awk '$0&gt;100'); do awk '/Swap:/{a=a+$2}END{print '"$i"',a/1024"M"}' /proc/$i/smaps;done| sort -k2nr | head
</code></pre>
<p>然后根据ps aux | grep pid进行查看是哪个服务占用了swap</p>
<p>一个更详细的命令如下：</p>
<pre><code class="language-shell">#!/bin/bash  
# Get current swap usage for all running processes  
# writted by xly  

function getswap {

   SUM=0
   OVERALL=0
   for DIR in `find /proc/ -maxdepth 1 -type d | egrep "^/proc/[0-9]"` ; do
       PID=`echo $DIR | cut -d / -f 3`
           PROGNAME=`ps -p $PID -o comm --no-headers`
           for SWAP in `grep Swap $DIR/smaps 2&gt;/dev/null| awk '{ print $2 }'`
               do
                   let SUM=$SUM+$SWAP
               done
               echo "PID=$PID - Swap used: $SUM - ($PROGNAME )"
               let OVERALL=$OVERALL+$SUM
               SUM=0
    done
    echo "Overall swap used: $OVERALL"
}  

getswap
#getswap|egrep -v "Swap used: 0" 
</code></pre>
<h1 id="ying-shi-fang-swap-kong-jian">硬释放swap空间</h1>
<pre><code class="language-shell">（1）执行sync
（2）echo 3 &gt; /proc/sys/vm/drop_caches
 (3) swapoff -a
 (4) swapon -a
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>将megaraid卡磁盘改为JBOD模式</title>
    <url>/2019/09/29/enable_jbod/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>目前lab里HDD基本上都是通过LSI RAID卡做RAID来使用，但有些时候也想测试单盘，但不想做RAID0，于是需要启用JBOD模式来识别每一块单盘。</p>
<p>megaraid 卡使用 JBOD 模式，磁盘可以直接被系统识别，使用 smartctl 查看 SMART 信息（<code>smartcl -d megaraid,N &lt;device&gt; </code>参数查看做过RAID磁盘的 SMART 信息）和 直连 SAS 卡一样。</p>
<p>如果 LSI megaraid 卡没有启用JBOD模式，磁盘必须做RAID操作，才能被系统识别到 。</p>
<p>没有启动JBOD模式，没法使用megacli设置磁盘为JBOD 。</p>
<h1 id="cha-kan-jbod-shi-fou-qi-yong">查看 JBOD 是否启用</h1>
<pre><code class="language-shell">root@node244:~# /opt/MegaRAID/MegaCli/MegaCli64 -AdpGetProp -enablejbod -aALL
                                     
Adapter 0: JBOD: Enabled

Exit Code: 0x00
root@node244:~# 
</code></pre>
<p><code>Enabled </code> 表明已经启用了JBOD模式；如果没有开启，先启用该特性：</p>
<pre><code class="language-shell">root@node244:~# /opt/MegaRAID/MegaCli/MegaCli64 -h
......
......
MegaCli -AdpSetProp -EnableJBOD -val -aN|-a0,1,2|-aALL 
       val - 0=Disable JBOD mode. 
             1=Enable JBOD mode.

root@node244:~# /opt/MegaRAID/MegaCli/MegaCli64 -AdpSetProp -EnableJBOD -1 -aALL
                                     
Adapter 0: Set JBOD to Enable success.

Exit Code: 0x00
root@node244:~# 

</code></pre>
<h1 id="jiang-dui-ying-pan-she-zhi-wei-jbod">将对应盘设置为JBOD</h1>
<pre><code class="language-shell">root@node244:~# /opt/MegaRAID/MegaCli/MegaCli64 -PDMakeJBOD -PhysDrv[E:S] -aALL
</code></pre>
<p>如果想批量设置，类似如下：</p>
<pre><code class="language-shell">for i in {0..11}; do /opt/MegaRAID/MegaCli/MegaCli64 -PDMakeJBOD -PhysDrv[E:${i}] -aALL; done
</code></pre>
<p>注意要替换掉E，这里的E就是 <code>Enclosure Device ID</code>；0…11是值disk的Slot Number</p>
<p>对于<code>Enclosure Device ID</code> 和 <code>Slot Number </code>,可以通过<code>/opt/MegaRAID/MegaCli/MegaCli64 pdlist aall </code>进行获取:</p>
<pre><code class="language-shell">root@node244:~# /opt/MegaRAID/MegaCli/MegaCli64 pdlist aall | grep -Ei "Enclosure Device ID|Slot Number"
Enclosure Device ID: 9
Slot Number: 0
Enclosure Device ID: 9
Slot Number: 1
Enclosure Device ID: 9
Slot Number: 2
Enclosure Device ID: 9
Slot Number: 3
Enclosure Device ID: 9
Slot Number: 4
Enclosure Device ID: 9
Slot Number: 5
Enclosure Device ID: 9
Slot Number: 6
Enclosure Device ID: 9
Slot Number: 7
Enclosure Device ID: 9
Slot Number: 8
Enclosure Device ID: 9
Slot Number: 9
Enclosure Device ID: 9
Slot Number: 10
Enclosure Device ID: 9
Slot Number: 11
root@node244:~# 
</code></pre>
<h1 id="cha-kan-pan-shi-fou-bei-she-zhi-wei-jbod-mo-shi">查看盘是否被设置为JBOD模式</h1>
<pre><code class="language-shell">root@node244:~# /opt/MegaRAID/MegaCli/MegaCli64 -PDList -aALL -Nolog|grep '^Firm'
Firmware state: Online, Spun Up
Firmware state: JBOD
Firmware state: JBOD
Firmware state: Online, Spun Up
Firmware state: Unconfigured(bad)
Firmware state: Online, Spun Up
Firmware state: Online, Spun Up
Firmware state: Online, Spun Up
Firmware state: Online, Spun Up
Firmware state: Online, Spun Up
Firmware state: Online, Spun Up
Firmware state: Online, Spun Up
root@node244:~# 
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Unconfigured(bad) 是一块坏盘</p>
</li>
<li class="lvl-2">
<p>Online, Spun Up 的是RAID组成员，做了RAID，因为当前环境是先创建了RAID5，然后对剩下的盘做的JBOD模式</p>
</li>
</ul>
]]></content>
      <categories>
        <category>MegaRAID</category>
      </categories>
      <tags>
        <tag>JBOD</tag>
      </tags>
  </entry>
  <entry>
    <title>nose进度条中展示执行用例数与总数</title>
    <url>/2019/11/20/nose_progress_bar/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在使用nose 插件时，发现这个插件只能显示进度（nose-progressive），并不知道当前执行多少个用例，执行到哪个了，如下图所示：</p>
<img class="shadow" src="/img/in-post/before_progress_bar.png" width="1200">
<h1 id="qi-dai-xiao-guo">期待效果</h1>
<p>这里源码有个问题，同时使用高亮（nose的  colorama  和  walkingnine-colorunit）和进度，会导致高亮和进度在用例执行结果信息输出时，两部分信息展示混杂在一起，已经修改源码解决，安装后无需做任何调整。</p>
<p>由于只能看到一个进度条，无法知道当前要执行多少个用例，以及执行到了第几个用例，再次修改之。在进度条前面，显示已执行用例数（包含当前正在执行的用例）与总共要执行的用例数,于是对源码（nose-progressive-master/noseprogressive/bar.py）做了如下调整：</p>
<pre><code class="language-python">    def update(self, test_path, number):
        """Draw an updated progress bar.
    
        At the moment, the graph takes a fixed width, and the test identifier
        takes the rest of the row, truncated from the left to fit.
    
        test_path -- the selector of the test being run
        number -- how many tests have been run so far, including this one
    
        """
        # TODO: Play nicely with absurdly narrow terminals. (OS X's won't even
        # go small enough to hurt us.)
    
        # Figure out graph:
        GRAPH_WIDTH = 14
        # min() is in case we somehow get the total test count wrong. It's tricky.
        num_filled = int(round(min(1.0, float(number) / self.max) * GRAPH_WIDTH))
        graph = ''.join([self._fill_cap(' ' * num_filled),
                         self._empty_cap(self._empty_char * (GRAPH_WIDTH - num_filled))])
    
        # Figure out the test identifier portion:
        # Avoid causing progress bar wraps due to more test cases when 
        # show number of runned/total test cases, modify it by wangyunzeng 2019-01-30
        # cols_for_path = self.cols - GRAPH_WIDTH - 2  # 2 spaces between path &amp; graph
        cols_for_path = self.cols - GRAPH_WIDTH - 13  # 13 spaces between path &amp; graph
        if len(test_path) &gt; cols_for_path:
            test_path = test_path[len(test_path) - cols_for_path:]
        else:
            test_path += ' ' * (cols_for_path - len(test_path))
    
        # Put them together, and let simmer:
        # Show number of runned/total test cases, modify it by wangyunzeng 2019-01-30
        # self.last = self._term.bold(test_path) + '  ' + graph
        self.last = self._term.bold(test_path) + '  ' + str(number) + '/' + str(self.max) + '  ' + graph
        with self._at_last_line():
            self.stream.write(self.last)
        self.stream.flush()
</code></pre>
<p>再次执行，效果图如下：</p>
<img class="shadow" src="/img/in-post/after_progress_bar.png" width="1200">
<p>是不是清爽很多了~</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>nose</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>nose</tag>
        <tag>Progress bar</tag>
      </tags>
  </entry>
  <entry>
    <title>Ununtu14.04 安装Jekyll及Github部署流程</title>
    <url>/2019/11/22/install_jekyll_with_github/</url>
    <content><![CDATA[<h1 id="jekyll-ben-di-da-jian-kai-fa-huan-jing-yi-ji-github-bu-shu-liu-cheng">Jekyll本地搭建开发环境以及Github部署流程</h1>
<h2 id="ben-di-da-jian-jekyll">本地搭建Jekyll</h2>
<p>本文以ubuntu14.04为例。</p>
<p>根据最新版本的要求， Jekyll 3 要求 Ruby 2.0.0 及以上的版本。但 Ubuntu 14.04 apt-get 默认提供的版本较低（1.9），所以需要从其他地方安装最新的版本。</p>
<h3 id="an-zhuang-rbenv">安装 rbenv</h3>
<p>从 Github 上 clone, 再添加路径 :</p>
<pre><code class="language-shell">git clone git://github.com/sstephenson/rbenv.git ~/.rbenv

echo 'export PATH="$HOME/.rbenv/bin:$PATH"' &gt;&gt; ~/.bashrc

echo 'eval "$(rbenv init -)"' &gt;&gt; ~/.bashrc

source ~/.bashrc
</code></pre>
<p>然后我们需要一个 rbenv 插件 ruby-build 来编译并安装 Ruby .</p>
<pre><code class="language-shell">git clone git://github.com/sstephenson/ruby-build.git ~/.rbenv/plugins/ruby-build

echo 'export PATH="$HOME/.rbenv/plugins/ruby-build/bin:$PATH"' &gt;&gt; ~/.bashrc

source ~/.bashrc
</code></pre>
<p>安装 rbenv-gem-rehash . 当使用 gem 安装或卸载 Ruby package 时，这个插件自动调用 rbenv rehash .</p>
<pre><code class="language-shell">git clone https://github.com/sstephenson/rbenv-gem-rehash.git ~/.rbenv/plugins/rbenv-gem-rehash
</code></pre>
<h3 id="an-zhuang-node-js">安装Node.js</h3>
<p>官网提供的方法是：</p>
<pre><code class="language-shell">curl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -

apt-get install -y nodejs
</code></pre>
<p>npm 也会被安装.</p>
<h3 id="an-zhuang-gem">安装gem</h3>
<p>说明：</p>
<p><strong>先跳过安装，如果没有gem，再来安装与设置环境变量</strong></p>
<pre><code class="language-shell">apt-get install gem
</code></pre>
<p>设置gem环境变量</p>
<pre><code class="language-shell">echo '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.zshrc

echo 'export GEM_HOME="$HOME/gems"' &gt;&gt; ~/.zshrc

echo 'export PATH="$HOME/gems/bin:$PATH"' &gt;&gt; ~/.zshrc

source ~/.zshrc
</code></pre>
<h3 id="an-zhuang-ruby-2-x-he-jekyll-4-0">安装 Ruby 2.x 和 Jekyll 4.0</h3>
<p>首先确定相关的依赖已经安装.</p>
<pre><code class="language-shell">apt-get update

apt-get install build-essential libssl-dev libreadline-dev libyaml-dev libxml2-dev libxslt1-dev libffi-dev python-software-properties
</code></pre>
<p>然后运行下面的语句：</p>
<pre><code class="language-shell">rbenv install 2.4.0

rbenv global 2.4.0
</code></pre>
<p>由于jekyll requires RubyGems version &gt;= 2.7.0，需要更新gem</p>
<pre><code class="language-shell">gem update --system
</code></pre>
<p>如果上面的命令不行，需要执行下面的命令：</p>
<pre><code class="language-shell">gem install rubygems-update

update_rubygems
</code></pre>
<p>成功更新后，查看gem版本</p>
<pre><code class="language-shell">root@code80:~# gem -v
3.0.6
</code></pre>
<h4 id="kai-shi-an-zhuang-jekyll">开始安装jekyll</h4>
<pre><code class="language-shell">gem install bundle

gem install jekyll
</code></pre>
<img class="shadow" src="/img/in-post/install_jekyll_1.jpg" width="1200">
<img class="shadow" src="/img/in-post/install_jekyll_2.jpg" width="1200">
<p>通过下面的方法检查安装是否成功.</p>
<pre><code class="language-shell">root@code80:~# jekyll -v
jekyll 4.0.0
</code></pre>
<h4 id="shi-yong-jekyll-chuang-jian-ni-de-bo-ke-zhan-dian">使用Jekyll创建你的博客站点</h4>
<pre><code class="language-shell">jekyll new blog
</code></pre>
<p>说明：</p>
<p>执行“jekyll new blog”会卡住很久，耐心等待一下（或者tmux里执行），成功后会看到：</p>
<img class="shadow" src="/img/in-post/jeky_new_blog.jpg" width="1200">
<h4 id="qi-dong-jekyll-fu-wu">启动jekyll服务</h4>
<pre><code class="language-shell">cd blog

jekyll serve
</code></pre>
<p>会看到如下效果：</p>
<pre><code class="language-shell">root@code80:~/blog# jekyll serve
Configuration file: /root/blog/_config.yml
            Source: /root/blog
       Destination: /root/blog/_site
 Incremental build: disabled. Enable with --incremental
      Generating... 
       Jekyll Feed: Generating feed for posts
                    done in 0.624 seconds.
 Auto-regeneration: enabled for '/root/blog'
    Server address: http://127.0.0.1:4000/
  Server running... press ctrl-c to stop.
</code></pre>
<h4 id="chang-shi-web-fang-wen">尝试web访问</h4>
<p>由于jekyll将地址绑定到了127.0.0.1，导致局域网的其它机器并不能访问它的服务。但实际上只要改变运行jekyll的参数就可以了。</p>
<pre><code class="language-shell"> root@code80:~/blog# jekyll serve -w --host=172.17.73.80
Configuration file: /root/blog/_config.yml
            Source: /root/blog
       Destination: /root/blog/_site
 Incremental build: disabled. Enable with --incremental
      Generating... 
       Jekyll Feed: Generating feed for posts
                    done in 0.49 seconds.
 Auto-regeneration: enabled for '/root/blog'
    Server address: http://172.17.73.80:4000/
  Server running... press ctrl-c to stop.
</code></pre>
<p>通过172.17.73.80这个地址，访问web：</p>
<img class="shadow" src="/img/in-post/default_ui.jpg" width="1200">
<p>至此，jekyll安装好了。</p>
<h2 id="shi-yong-jekyll-xie-bo-wen">使用Jekyll写博文</h2>
<h3 id="bo-wen-jie-gou">博文结构</h3>
<p>我们进入blog目录后，会发现Jekyl的结构如下：</p>
<img class="shadow" src="/img/in-post/default_tree.jpg" width="1200">
<h3 id="bo-wen-fa-bu-ce-shi">博文发布测试</h3>
<p>我们进入_post目录，撰写的markdown语法的博文都放在这里。默认会有一篇测试文章：2019-11-21-welcome-to-jekyll.markdown.</p>
<p>现在写两个新的md文档</p>
<pre><code class="language-shell">-rw-r--r-- 1 root root 3319 Nov 21 21:20 2019-11-20-nose-progress-bar.md

-rw-r--r-- 1 root root 5018 Nov 21 21:20 2019-11-21-write-nose-test-case-role.md
</code></pre>
<p>然后刷新一下浏览器、发现页面并没有变化.因为我们还没有通过Jekyll build去生成。</p>
<h3 id="jekyll-build">jekyll build</h3>
<p>默认情况下，服务会以前台的方式挂起，如果希望用后台进程运行服务，我们可以使用 --detach参数，缩写参数为-B(应该是Background的首字母)</p>
<pre><code class="language-shell">jekyll serve build --detach -w --host=172.17.73.80
</code></pre>
<p>或者</p>
<pre><code class="language-shell">jekyll serve build -B -w --host=172.17.73.80
</code></pre>
<p>注意：</p>
<p>如果用vagrant虚拟机去安装jekyll，那么启动服务时还需要加上-H参数，指定访问主机号为0.0.0.0，即jekyll serve build -B -H 0.0.0.0,否则vagrant下可能启动失败</p>
<p>再查看首页，发现已经有三篇文章了！</p>
<img class="shadow" src="/img/in-post/3_test_file.jpg" width="1200">
<h3 id="bo-wen-tou-xin-xi">博文头信息</h3>
<p>打开一个markdown,可以看见开头有如下几个东东。</p>
<pre><code class="language-shell">---

layout: post

title: "Welcome to Jekyll!"

date:  2019-11-21 20:52:45 +0800

categories: jekyll update

---
</code></pre>
<p>layout表示使用的是post布局，title是文章标题，date是自动生成的日期，categories是该文章生成html文件后存放的目录，可以去_site/jekyll/update下找到对应日期下面的html文档。当然你也可以只设置jekyll单一的目录，甚至是更多级别的目录，用空格分开即可。头信息设置完成后就可以书写正文了。</p>
<p>如果每次都输入这些头信息，还要去整理格式，那么一定很烦躁，这种重复性的东西我们就把它自动化，通过Rakefile去解决，它类似shell这样的脚本，可以使用交互模式。以下是我的Rakefile,可以复制后命名为Rakefile，放在站点根目录直接使用，也可以修改为适合自己的Rakefile：</p>
<pre><code class="language-shell">task :default =&gt; :new

require 'fileutils'

desc "创建新 post"

task :new do

 puts "请输入要创建的 post URL："

  @url = STDIN.gets.chomp

  puts "请输入 post 标题："

  @name = STDIN.gets.chomp

  puts "请输入 post 子标题："

  @subtitle = STDIN.gets.chomp

  puts "请输入 post 分类，以空格分隔："

  @categories = STDIN.gets.chomp

  puts "请输入 post 标签："

  @tag = STDIN.gets.chomp

  @slug = "#{@url}"

  @slug = @slug.downcase.strip.gsub(' ', '-')

  @date = Time.now.strftime("%F")

  @post_name = "_posts/#{@date}-#{@slug}.md"

  if File.exist?(@post_name)

​      abort("文件名已经存在！创建失败")

  end

  FileUtils.touch(@post_name)

  open(@post_name, 'a') do |file|

​      file.puts "---"

​      file.puts "layout: post"

​      file.puts "title: #{@name}"

​      file.puts "subtitle: #{@subtitle}"

​      file.puts "author: Gavin"

​      file.puts "date: #{Time.now}"

​      file.puts "categories: #{@categories}"

​      file.puts "tag: #{@tag}"

​      file.puts "---"

  end

  exec "vi #{@post_name}"

end
</code></pre>
<h3 id="ru-he-shi-yong-rake">如何使用Rake</h3>
<p>输入一下命令：</p>
<pre><code class="language-shell">rake new
</code></pre>
<p>rake会启动交互模式，让你依次输入title，subtitle，author，categories，tag等信息，并为你创建好具有头信息的markdown文件。如下一样:</p>
<pre><code class="language-shell">请输入要创建的 post URL：

testurl

请输入 post 标题：

testpost

请输入 post 子标题：

subtitle  

请输入 post 分类，以空格分隔：

jekyll

请输入 post 标签：

技术
</code></pre>
<p>我们查看_post目录，发现已经有一篇2019-11-21-testurl.md文章，打开看下</p>
<pre><code class="language-shell">---

layout: post

title: testpost

subtitle: subtitle

author: gavin

date: 2019-11-21 21:39:27 +0800

categories: jekyll

tag: 技术

---
</code></pre>
<h2 id="shi-yong-github-pages-fu-wu-sheng-cheng-ge-ren-bo-ke">使用Github pages服务生成个人博客</h2>
<h3 id="chuang-jian-wo-men-de-cang-ku">创建我们的仓库</h3>
<img class="shadow" src="/img/in-post/my_pro.jpg" width="1200">
<p>如此，我们已经可以通过浏览器输入 <a href="https://link.jianshu.com/?t=http://username.github.io">http://username.github.io</a>访问博客主页。那么我就访问<a href="https://gavin-wang-note.github.io/">https://gavin-wang-note.github.io/</a></p>
<p>如下图所示，就是我的默认博客首页：</p>
<img class="shadow" src="/img/in-post/my_default_blog_ui.jpg" width="1200">
<p>这里我使用了他人的pro，更换了一些图片，代替上面默认的风格，展示如下：</p>
<img class="shadow" src="/img/in-post/my_new_pro.jpg" width="1200">
<h3 id="jiang-ben-di-jekyll-dai-ma-bu-shu-dao-github-shang-de-cang-ku">将本地jekyll代码部署到Github上的仓库</h3>
<p>前面我们已经详细地说明如何搭建Jekyll，我们可以在本地开发测试，推送代码到仓库，发布到线上。</p>
<h3 id="ke-long-cang-ku-dao-ben-di">克隆仓库到本地</h3>
<p>请确保本地安装了git客户端，克隆你的username.github.com仓库到本地。</p>
<pre><code class="language-shell">git clone https://github.com/username/username.github.com.git
</code></pre>
<h3 id="kao-bei-ben-di-de-jekyll-mu-lu-dao-ban-ben-ku">拷贝本地的jekyll目录到版本库</h3>
<p>删除username.github.com下面的示例文件(<a href="http://README.md">README.md</a>,不要删除，绑定域名会用到):</p>
<pre><code class="language-shell">rm -rf _site index.html _config.yml
</code></pre>
<p>拷贝本地blog(这个是前面本地搭建的blog，后续等同，不再说明)<a href="http://xn--username-t39lz9evvos2etr9b1siwlmn0f3y0futb.github.com">下的所有目录及文件到username.github.com</a></p>
<pre><code class="language-shell">cp -r /root/blog/* username.github.com
</code></pre>
<p>此时你会看见当前存在username.github.com这个目录，我们启动jekyll服务（启动前确保其他目录下没有jekyll服务，可以<code>ps aux|grep jekyll</code>查看进程,有的话,用<code>kill -9 进程号</code>杀掉）:</p>
<pre><code class="language-shell">cd username.github.com

jekyll serve -B -w --host=172.17.73.80
</code></pre>
<p>现在我们打开 ‘<a href="http://172.17.73.80:4000">http://172.17.73.80:4000</a>’, 即可看见我们在Github上创建的主页，理论上和 ‘<a href="http://username.github.com">http://username.github.com</a>’ 访问的应该是一模一样的。</p>
<h3 id="ben-di-jekyll-zhan-dian-bu-shu-dao-github-pages-shang-xiang-dang-yu-xian-shang-huan-jing">本地Jekyll站点部署到Github Pages上（相当于线上环境）</h3>
<pre><code class="language-shell">git add --all       #添加到暂存区 

git commit -m "提交jekyll默认页面" #提交到本地仓库

git push origin master     #线上的站点是部署在master下面的

</code></pre>
<p>稍等10分钟左右，Github Pages有一定时间缓存,我们刷新username.github.io看看,已经ok了！</p>
<h2 id="wen-ti">问题</h2>
<h3 id="jekyll-yin-missing-dependency-exception-qi-dong-shi-bai">Jekyll因MissingDependencyException启动失败</h3>
<img class="shadow" src="/img/in-post/jekyll_start_failed.jpg" width="1200">
<p>主要是这一句：</p>
<pre><code class="language-shell">The jekyll-theme-cayman theme could not be found
</code></pre>
<p>那就使用gem去安装它</p>
<pre><code class="language-shell">gem install jekyll-theme-cayman
</code></pre>
<img class="shadow" src="/img/in-post/install_jekyll-theme-cayman.jpg" width="1200">
<p>成功安装后，再次启动Jekyll</p>
<img class="shadow" src="/img/in-post/start_jekyll_again.jpg" width="1200">
<p>后续如果缺失其他模块，可根据trace信息，使用gem进行安装。</p>
<h1 id="can-kao-wen-dang">参考文档</h1>
<p><a href="https://jekyllrb.com/docs/installation/ubuntu/">https://jekyllrb.com/docs/installation/ubuntu/</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-install-ruby-on-rails-with-rbenv-on-ubuntu-14-04">https://www.digitalocean.com/community/tutorials/how-to-install-ruby-on-rails-with-rbenv-on-ubuntu-14-04</a></p>
<p><a href="https://blog.csdn.net/sinat_34439107/article/details/78440836">https://blog.csdn.net/sinat_34439107/article/details/78440836</a></p>
<p><a href="https://www.jianshu.com/p/f37a96f83d51">https://www.jianshu.com/p/f37a96f83d51</a></p>
]]></content>
      <categories>
        <category>Jekyll</category>
      </categories>
      <tags>
        <tag>Jekyll</tag>
      </tags>
  </entry>
  <entry>
    <title>魔法键重启Linux机器</title>
    <url>/2019/11/27/reboot_host/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>啥？ 重启Linux机器，无非通过下列几种常见命令：</p>
<p><code>reboot </code></p>
<p><code>reboot -f </code></p>
<p><code>poweroff </code></p>
<p>说明：</p>
<p>如果上面的指令，在机器重启、关机期间卡住了，怎么办？看下面ipmi指令。</p>
<h1 id="ipmi-zhi-ling">IPMI指令</h1>
<p>说明：</p>
<p>需要安装ipmitool工具, 这个也不是本文重点哦。</p>
<h2 id="ying-guan-ji-zhi-jie-qie-duan-dian-yuan">硬关机，直接切断电源</h2>
<p><code>ipmitool -I lan -H 192.168.1.2 -U IPMI的管理员账号 -P 密码 power off </code></p>
<h2 id="ruan-guan-ji">软关机</h2>
<p>即如同轻按一下开机扭，对于linux，服务器将halt，power status 为off</p>
<p><code>ipmitool -I lan -H 192.168.1.2 -U IPMI的管理员账号 -P 密码 power soft </code></p>
<h2 id="ying-kai-ji">硬开机</h2>
<p><code>ipmitool -I lan -H 192.168.1.2 -U IPMI的管理员账号 -P 密码 power on </code></p>
<h2 id="ying-zhong-qi">硬重启</h2>
<p><code>ipmitool -I lan -H 192.168.1.2 -U IPMI的管理员账号 -P 密码 power reset </code></p>
<h1 id="mo-fa-jian">魔法键</h1>
<p>重点来了~~~</p>
<p>上面的指令大家都知道，本文要讲的，是一个Magic key，可以做到强制重启哦，非常的神奇，一切卡死都不是事~~</p>
<p>命令如下：</p>
<p><code>echo "b" &gt; /proc/sysrq-trigger </code></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>统计cosbench每个任务的IOPS和耗时</title>
    <url>/2019/11/30/calc_cosbench_task_iops_elapsed_time/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>近期针对前方客户提出的具体S3测试要求，测试了一下S3性能，使用的是cosbench工具。在测试过程中，排除客户的要求外，我们自身也想知道，当前硬件条件下，每间隔1,000,00,00个object，IOPS和耗时是多久，比如：1到1千万，1千万到2千万，。。。1亿到1.1亿个object, and so on。由于测试场景比较多，而且测试时长也会很久，所有写了这个脚本，统计一下不同level object数据下的IOPS和耗时（当然，cosbench的任务是每间隔1千万提交一次，即一个xml里写1千万个object，直到数据量过亿,所以cosbench提交的是多个任务来完成数据过亿的测试）。</p>
<h1 id="jiao-ben-nei-rong">脚本内容</h1>
<pre><code class="language-python">root@fireware:~# cat calc_cosbench_task_time.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import os
import sys
from datetime import datetime

from ezs3.command import do_cmd


def get_start_end_time():
    all_work_dict = {}

    all_csv_file = do_cmd("find {} -iname *WRITEJOB.csv -print".format(archive_home), 30).strip()
    for each_csv in all_csv_file.split('\n'):
        work_id = each_csv.split('/')[-2].split('-')[0]
        start_time = do_cmd("cat '{}' | awk -F ',' '{{print $1}}' | grep -v 'Timestamp' |  sed '/^$/d' | head -n 1".format(each_csv), 30).strip()
        end_time = do_cmd("tac '{}' | awk -F ',' '{{print $1}}' | grep -v 'Timestamp' | head -n 1".format(each_csv), 30).strip() 
        all_work_dict[work_id] = [start_time, end_time]

    sorted(all_work_dict.items(), lambda x, y: cmp(x[0], y[0]))
    return all_work_dict


# def calc_elapsed_time(all_work_dict):
#     elapsed_time_dict = {}
# 
#     for each_key in all_work_dict.items():
#         start_at = each_key[1][0]
#         stop_at = each_key[1][1]
# 
#         if start_at and stop_at:
#             start = datetime.strptime(start_at, '%H:%M:%S')
#             end = datetime.strptime(stop_at, '%H:%M:%S')
#             elapsed_time = (end-start).seconds
# 
#             elapsed_time_dict[each_key[0]] = elapsed_time
#         else:
#             elapsed_time_dict[each_key[0]] = 0
# 
#     sorted(elapsed_time_dict.items(), lambda x, y: cmp(x[0], y[0]))
#     return elapsed_time_dict
# 
# 
# def calc_ops():
#     ops_dict = {}
#     all_csv_file = do_cmd("find {} -iname *W.csv -print".format(archive_home), 30).strip()
# 
#     for each_csv in all_csv_file.split('\n'):
#         cur_work_op_list = []
#         work_id = each_csv.split('/')[-2].split('-')[0]
#         ops_info = do_cmd("cat '{}' | awk '{{print $1}}' | awk -F ',' '{{print $14}}' | grep -v Throughput".format(each_csv), 30).strip() 
#         ops_dict[work_id] = sum(map(float, ops_info.split("\n")))
# 
#     return ops_dict


def calc_elapsed_time_ops(all_work_dict):
    elapsed_time_ops_dict = {}
    ops_dict = {}
    all_csv_file = do_cmd("find {} -iname *W.csv -print".format(archive_home), 30).strip()

    for each_csv in all_csv_file.split('\n'):
        cur_work_op_list = []
        work_id = each_csv.split('/')[-2].split('-')[0]
        ops_info = do_cmd("cat '{}' | awk '{{print $1}}' | awk -F ',' '{{print $14}}' | grep -v Throughput".format(each_csv), 30).strip() 
        sum_ops = sum(map(float, ops_info.split("\n")))
        
        ops_dict[work_id] = sum(map(float, ops_info.split("\n")))

        for each_key in all_work_dict.items():
            start_at = each_key[1][0]
            stop_at = each_key[1][1]
            if start_at and stop_at:
                start = datetime.strptime(start_at, '%H:%M:%S')
                end = datetime.strptime(stop_at, '%H:%M:%S')
                elapsed_time = (end-start).seconds
            else:
                elapsed_time_dict[each_key[0]] = 0

            if each_key[0] == work_id:
                time_and_ops = '{}/{}'.format(sum_ops, elapsed_time)
                elapsed_time_ops_dict[work_id] = time_and_ops
    sorted(elapsed_time_ops_dict.items(), lambda x, y: cmp(x[0], y[0]))
    return elapsed_time_ops_dict



if __name__ == '__main__':
    archive_home = "/root//0.4.2.c4/archive/"
    ls_info = do_cmd("ls -l {}".format(archive_home), 30, True).split('\n')

    if not os.path.exists(archive_home):
        print "\n    [ERROR]  Not find cosbench archive path, exit!\n"
        sys.exit(0)
    elif 'total 0' in ls_info:
        print "\n    [ERROR]  Not find cosbench archive files, exit!\n"
        sys.exit(0)

    all_work_dict = get_start_end_time()
    # elapsed_time_dict = calc_elapsed_time(all_work_dict)
    # ops = calc_ops()

    time_and_ops = calc_elapsed_time_ops(all_work_dict)
    # print("All work dict is : ({})\n".format(all_work_dict))
    # print("Elapsed time is : ({})\n".format(elapsed_time_dict))
    # print("OPS is : ({})\n".format(ops))
    print("OPS and elapsed time is : ({})\n".format(time_and_ops))
</code></pre>
<h1 id="shu-chu-xin-xi">输出信息</h1>
<pre><code class="language-shell">root@fireware:~# python calc_cosbench_task_time.py 
OPS and elapsed time is : ({'w11': '2504.92/4070', 'w10': '2514.82/4060', 'w7': '2519.07/4050', 'w6': '2579.88/3960', 'w5': '2593.13/3940', 'w4': '2606.27/3910', 'w3': '2636.37/3870', 'w2': '2623.56/3890', 'w1': '5387.47/1890', 'w9': '2540.3/4010', 'w8': '2524.32/4050'})

root@fireware:~#
</code></pre>
<p>说明：<br>
*吐出的信息中，以“‘w11’: ‘2504.92/4070’”为示例：</p>
<ul class="lvl-0">
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">w11，表示的是cosbench的w11这个任务</li>
</ul>
</li>
<li class="lvl-2">
<ul class="lvl-2">
<li class="lvl-4">2504.92/4070, 表示这个任务的IOPS是2504.92，耗时了4070秒</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>ceph</category>
        <category>S3</category>
        <category>cosbench</category>
      </categories>
      <tags>
        <tag>S3</tag>
        <tag>cosbench</tag>
      </tags>
  </entry>
  <entry>
    <title>iSCSI多路径配置</title>
    <url>/2019/12/27/iscsi_modify_multipath_mode/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>配置iSCSI多路径，可以增加HA（高可用性）</p>
<p>本文以Ubuntu 14.04为示例，在安装了multipath-tools工具后，以此节点作为client去挂载iSCSI设备，将multipath默认active-standy修改为rond-robing</p>
<h1 id="i-scsi-duo-lu-jing-pei-zhi-client-duan">iSCSI多路径配置（client端）</h1>
<h2 id="wei-she-zhi-duo-lu-jing-zhi-qian">未设置多路径之前</h2>
<pre><code class="language-shell">root@host245:~# multipath -ll
2ea63c7c4f3aa5c5d dm-0 Bigtera ,VirtualStor_Scal
size=10T features='0' hwhandler='0' wp=rw
|-+- policy='round-robin 0' prio=1 status=active
| `- 11:0:0:0 sdd 8:48  active ready running
|-+- policy='round-robin 0' prio=1 status=enabled
| `- 14:0:0:0 sdg 8:96  active ready running
|-+- policy='round-robin 0' prio=1 status=enabled
| `- 15:0:0:0 sdh 8:112 active ready running
|-+- policy='round-robin 0' prio=1 status=enabled
| `- 13:0:0:0 sdf 8:80  active ready running
`-+- policy='round-robin 0' prio=1 status=enabled
  `- 12:0:0:0 sde 8:64  active ready running
</code></pre>
<h2 id="xiu-gai-multipath-conf">修改multipath.conf</h2>
<pre><code class="language-shell">root@host245:~# cat /etc/multipath.conf 
blacklist {
        devnode "^(rbd)[0-9]*"
        devnode "^zd[0-0]*"
#       devnode "*"
}

defaults {
        getuid_callout  "/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/%n"
        path_grouping_policy  multibus
        path_selector         "round-robin 0"
        failback               immediate
        rr_min_io_req          32
}
root@host245:~# 
</code></pre>
<p>说明：</p>
<p>从path_grouping_policy开始，之后的4行为新增内容</p>
<h2 id="zhong-qi-multipath-tool">重启multipath-tool</h2>
<pre><code class="language-shell">root@host245:~# /etc/init.d/multipath-tools restart
</code></pre>
<h2 id="cha-kan-she-zhi-hou-xiao-guo">查看设置后效果</h2>
<pre><code class="language-shell">root@host245:~# multipath -ll
2ea63c7c4f3aa5c5d dm-0 Bigtera ,VirtualStor_Scal
size=10T features='0' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=1 status=active
  |- 11:0:0:0 sdd 8:48  active ready running
  |- 12:0:0:0 sde 8:64  active ready running
  |- 13:0:0:0 sdf 8:80  active ready running
  |- 14:0:0:0 sdg 8:96  active ready running
  `- 15:0:0:0 sdh 8:112 active ready running
root@host245:~# 
</code></pre>
<h2 id="que-ren-sd-x-yu-i-scsi-target-guan-xi">确认sdX与iSCSI target关系</h2>
<p>现在是多路径了，如何分别出sdX对应哪个iSCSI target呢？</p>
<p>比如下面的sdf</p>
<pre><code class="language-shell">root@host243:~# lsblk
NAME                       MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT
sda                          8:0    0  14.6T  0 disk  
├─sda1                       8:1    0     8G  0 part  
└─sda2                       8:2    0  14.6T  0 part  /data/osd.2
sdb                          8:16   0 278.9G  0 disk  
├─sdb1                       8:17   0   7.5M  0 part  
├─sdb2                       8:18   0  95.4G  0 part  /
├─sdb3                       8:19   0  26.7G  0 part  [SWAP]
└─sdb4                       8:20   0 156.8G  0 part  
sdc                          8:32   0  10.9T  0 disk  
└─sdc1                       8:33   0  10.9T  0 part  
sdd                          8:48   0     5T  0 disk  
└─26a53c128cb536936 (dm-0) 252:0    0     5T  0 mpath 
sde                          8:64   0     5T  0 disk  
└─26a53c128cb536936 (dm-0) 252:0    0     5T  0 mpath 
sdf                          8:80   0     5T  0 disk  
└─26a53c128cb536936 (dm-0) 252:0    0     5T  0 mpath 
sdg                          8:96   0     5T  0 disk  
└─26a53c128cb536936 (dm-0) 252:0    0     5T  0 mpath 
sdh                          8:112  0     5T  0 disk  
└─26a53c128cb536936 (dm-0) 252:0    0     5T  0 mpath
</code></pre>
<p>方法如下：</p>
<p>step1、先获取 Host Number</p>
<pre><code class="language-shell">root@host243:~# multipath -ll
26a53c128cb536936 dm-0 Bigtera ,VirtualStor_Scal
size=5.0T features='0' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=1 status=active
  |- 39:0:0:0 sdf 8:80  active ready running
  |- 38:0:0:0 sdh 8:112 active ready running
  |- 40:0:0:0 sdg 8:96  active ready running
  |- 37:0:0:0 sde 8:64  active ready running
  `- 36:0:0:0 sdd 8:48  active ready running
</code></pre>
<p>如上文所示， <code>39:0:0:0</code>， 这里的39，就是Host Number， 同理，下面的38,40,37,36都是Host Number，分别对应不同的sdX分区</p>
<p>step2、根据Host Number，确认连接到哪个target</p>
<pre><code class="language-shell">root@host243:~# iscsiadm -m session -P 3
iSCSI Transport Class version 2.0-870
version 2.0-873
Target: iqn.2019-12.com:lenove
	Current Portal: 10.16.172.109:3260,1
	Persistent Portal: 10.16.172.109:3260,1
		**********
		Interface:
		**********
		Iface Name: default
		Iface Transport: tcp
		Iface Initiatorname: iqn.1993-08.org.debian:01:f077d70d498
		Iface IPaddress: 10.16.172.243
		Iface HWaddress: &lt;empty&gt;
		Iface Netdev: &lt;empty&gt;
		SID: 10
		iSCSI Connection State: LOGGED IN
		iSCSI Session State: LOGGED_IN
		Internal iscsid Session State: NO CHANGE
		*********
		Timeouts:
		*********
		Recovery Timeout: 120
		Target Reset Timeout: 30
		LUN Reset Timeout: 30
		Abort Timeout: 15
		*****
		CHAP:
		*****
		username: &lt;empty&gt;
		password: ********
		username_in: &lt;empty&gt;
		password_in: ********
		************************
		Negotiated iSCSI params:
		************************
		HeaderDigest: None
		DataDigest: None
		MaxRecvDataSegmentLength: 262144
		MaxXmitDataSegmentLength: 1048576
		FirstBurstLength: 262144
		MaxBurstLength: 1048576
		ImmediateData: Yes
		InitialR2T: No
		MaxOutstandingR2T: 1
		************************
		Attached SCSI devices:
		************************
		Host Number: 40	State: running
		scsi40 Channel 00 Id 0 Lun: 0
			Attached scsi disk sdg		State: running
	Current Portal: 10.16.172.105:3260,1
	Persistent Portal: 10.16.172.105:3260,1
		**********
		Interface:
		**********
		Iface Name: default
		Iface Transport: tcp
		Iface Initiatorname: iqn.1993-08.org.debian:01:f077d70d498
		Iface IPaddress: 10.16.172.243
		Iface HWaddress: &lt;empty&gt;
		Iface Netdev: &lt;empty&gt;
		SID: 6
		iSCSI Connection State: LOGGED IN
		iSCSI Session State: LOGGED_IN
		Internal iscsid Session State: NO CHANGE
		*********
		Timeouts:
		*********
		Recovery Timeout: 120
		Target Reset Timeout: 30
		LUN Reset Timeout: 30
		Abort Timeout: 15
		*****
		CHAP:
		*****
		username: &lt;empty&gt;
		password: ********
		username_in: &lt;empty&gt;
		password_in: ********
		************************
		Negotiated iSCSI params:
		************************
		HeaderDigest: None
		DataDigest: None
		MaxRecvDataSegmentLength: 262144
		MaxXmitDataSegmentLength: 1048576
		FirstBurstLength: 262144
		MaxBurstLength: 1048576
		ImmediateData: Yes
		InitialR2T: No
		MaxOutstandingR2T: 1
		************************
		Attached SCSI devices:
		************************
		Host Number: 36	State: running
		scsi36 Channel 00 Id 0 Lun: 0
			Attached scsi disk sdd		State: running
	Current Portal: 10.16.172.107:3260,1
	Persistent Portal: 10.16.172.107:3260,1
		**********
		Interface:
		**********
		Iface Name: default
		Iface Transport: tcp
		Iface Initiatorname: iqn.1993-08.org.debian:01:f077d70d498
		Iface IPaddress: 10.16.172.243
		Iface HWaddress: &lt;empty&gt;
		Iface Netdev: &lt;empty&gt;
		SID: 7
		iSCSI Connection State: LOGGED IN
		iSCSI Session State: LOGGED_IN
		Internal iscsid Session State: NO CHANGE
		*********
		Timeouts:
		*********
		Recovery Timeout: 120
		Target Reset Timeout: 30
		LUN Reset Timeout: 30
		Abort Timeout: 15
		*****
		CHAP:
		*****
		username: &lt;empty&gt;
		password: ********
		username_in: &lt;empty&gt;
		password_in: ********
		************************
		Negotiated iSCSI params:
		************************
		HeaderDigest: None
		DataDigest: None
		MaxRecvDataSegmentLength: 262144
		MaxXmitDataSegmentLength: 1048576
		FirstBurstLength: 262144
		MaxBurstLength: 1048576
		ImmediateData: Yes
		InitialR2T: No
		MaxOutstandingR2T: 1
		************************
		Attached SCSI devices:
		************************
		Host Number: 37	State: running
		scsi37 Channel 00 Id 0 Lun: 0
			Attached scsi disk sde		State: running
	Current Portal: 10.16.172.108:3260,1
	Persistent Portal: 10.16.172.108:3260,1
		**********
		Interface:
		**********
		Iface Name: default
		Iface Transport: tcp
		Iface Initiatorname: iqn.1993-08.org.debian:01:f077d70d498
		Iface IPaddress: 10.16.172.243
		Iface HWaddress: &lt;empty&gt;
		Iface Netdev: &lt;empty&gt;
		SID: 8
		iSCSI Connection State: LOGGED IN
		iSCSI Session State: LOGGED_IN
		Internal iscsid Session State: NO CHANGE
		*********
		Timeouts:
		*********
		Recovery Timeout: 120
		Target Reset Timeout: 30
		LUN Reset Timeout: 30
		Abort Timeout: 15
		*****
		CHAP:
		*****
		username: &lt;empty&gt;
		password: ********
		username_in: &lt;empty&gt;
		password_in: ********
		************************
		Negotiated iSCSI params:
		************************
		HeaderDigest: None
		DataDigest: None
		MaxRecvDataSegmentLength: 262144
		MaxXmitDataSegmentLength: 1048576
		FirstBurstLength: 262144
		MaxBurstLength: 1048576
		ImmediateData: Yes
		InitialR2T: No
		MaxOutstandingR2T: 1
		************************
		Attached SCSI devices:
		************************
		Host Number: 38	State: running
		scsi38 Channel 00 Id 0 Lun: 0
			Attached scsi disk sdh		State: running
	Current Portal: 10.16.172.106:3260,1
	Persistent Portal: 10.16.172.106:3260,1
		**********
		Interface:
		**********
		Iface Name: default
		Iface Transport: tcp
		Iface Initiatorname: iqn.1993-08.org.debian:01:f077d70d498
		Iface IPaddress: 10.16.172.243
		Iface HWaddress: &lt;empty&gt;
		Iface Netdev: &lt;empty&gt;
		SID: 9
		iSCSI Connection State: LOGGED IN
		iSCSI Session State: LOGGED_IN
		Internal iscsid Session State: NO CHANGE
		*********
		Timeouts:
		*********
		Recovery Timeout: 120
		Target Reset Timeout: 30
		LUN Reset Timeout: 30
		Abort Timeout: 15
		*****
		CHAP:
		*****
		username: &lt;empty&gt;
		password: ********
		username_in: &lt;empty&gt;
		password_in: ********
		************************
		Negotiated iSCSI params:
		************************
		HeaderDigest: None
		DataDigest: None
		MaxRecvDataSegmentLength: 262144
		MaxXmitDataSegmentLength: 1048576
		FirstBurstLength: 262144
		MaxBurstLength: 1048576
		ImmediateData: Yes
		InitialR2T: No
		MaxOutstandingR2T: 1
		************************
		Attached SCSI devices:
		************************
		Host Number: 39	State: running
		scsi39 Channel 00 Id 0 Lun: 0
			Attached scsi disk sdf		State: running
</code></pre>
<p>比如上文中的 <code>Persistent Portal: 10.16.172.106:3260,1 </code>，对应的Host Number是39(<code>Host Number: 39 State: running </code>)，对应的分区信息是sdf(<code>Attached scsi disk sdf          State: running </code>)，说明访问sdf这个device，是通过10.16.172.106 这个IP进行访问的。</p>
]]></content>
      <categories>
        <category>iSCSI</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>iSCSI</tag>
      </tags>
  </entry>
  <entry>
    <title>解决因RAID卡提示VD有cache而无法创建RAID问题</title>
    <url>/2019/12/30/controller_has_data_in_cache_for_offline_or_missing_virtual_disks/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>单盘组的RAID0做的OSD，设备上直接把这块盘拔掉，然后重新插回去，本想看看重做RAID0后，UI rescan or reformat OSD是否OK的，结果在重做RAID0期间碰到了本文的问题，记录一下。</p>
<h1 id="xian-xiang">现象</h1>
<p>单盘RAID0被拔掉后，这块SATA盘的“Firmware State” 是 “Unconfigured(bad), Spun Up”，于是尝试make good it:</p>
<pre><code class="language-shell">root@node247:~# /opt/MegaRAID/MegaCli/MegaCli64 -PDMakeGood -PhysDrv[0:5] -a0
                                     
Adapter: 0: EnclId-0 SlotId-5 state changed to Unconfigured-Good.

Exit Code: 0x00
</code></pre>
<p>尝试对它重建建RAID0，结果失败，RAID卡event log显示：</p>
<p>导出的RAID卡的event log：</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpEventLog -GetEvents -f event.log -A0 </code></p>
<pre><code class="language-shell">seqNum: 0x000153dc
Time: Mon Dec 30 10:12:20 2019

Code: 0x000000da
Class: 0
Locale: 0x40
Event Description: Foreign Configuration Detected
Event Data:
===========
None
</code></pre>
<p>直接Display event log：</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -FwTermLog -Dsply -aALL </code></p>
<pre><code class="language-shell">12/30/19 10:13:10: C0:EVT#87008-12/30/19 10:13:10: 218=Foreign Configuration Detected
12/30/19 10:13:11: C0:pii addBvdInfo rsvd2=1 &lt;- bvd ld=0
12/30/19 10:13:11: C0:createMegaraidCfg: cfg:4422ac20 forCfg=441cd7e0 merge:0 import:0 other_pinned_vds:c02e1240 
12/30/19 10:13:11: C0:**** PinnedCacheDataStructures-&gt;pinned_cache_present
12/30/19 10:13:11: C0:0x00000002
12/30/19 10:13:11: C0:sscPinnedWindowInfo.ssd_window_pinned 0 
12/30/19 10:13:11: C0:createMegaraidCfg - V ld 0  targetId 1  LdMapTargetIdToLd fe totLd:1 
12/30/19 10:13:11: C0:createMegaraidCfg - VI number_pinned_vds_found_during_import 1 targetId 1 
12/30/19 10:13:11: C0:createMegaraidCfg - pii createMR1 rsvd2=1 &lt;- forcfg ld=0 import:0 OldTargetId:1 merge:0 cfg-&gt;logDrvCount:0 ldCount:7 
12/30/19 10:13:11: C0:NumberOfVdsWithPinnedCache: number_of_pinned_vds = 1
</code></pre>
<p>均提示，侦测到PD Foreign 状态 <code>Foreign Configuration Detected </code></p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>清理Foreign状态</p>
<pre><code class="language-shell">root@node247:~# /opt/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -a0
                                     
Failed to clear Foreign configuration 0 on controller 0.

FW error description: 
 The current operation is not allowed because the controller has data in cache for offline or missing virtual disks.  

Exit Code: 0x54
root@node247:~# 
</code></pre>
<p>很遗憾，报错了，究其原因，是VD直接被拔掉，VD对应的PD里还有一些cache，这些cache需要先清理掉。</p>
<p>再次解决之：</p>
<pre><code class="language-shell">root@node247:~# /opt/MegaRAID/MegaCli/MegaCli64  -DiscardPreservedCache -L1 -a0 
                                     
Adapter #0

Virtual Drive(Target ID 01): Preserved Cache Data Cleared.

Exit Code: 0x00
root@node247:~# /opt/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -aALL
                                     
Foreign configuration 0 is cleared on controller 0.

Exit Code: 0x00
root@node247:~# 
</code></pre>
<p>这里成功清理了对应VD的cache（虽然VD已经不存在了，但要记住这个RAID0在损坏前的VD id，这里是1），之后就可以成功创建RAID0了</p>
]]></content>
      <categories>
        <category>RAID</category>
        <category>Megacli</category>
      </categories>
      <tags>
        <tag>RAID</tag>
        <tag>Megacli</tag>
      </tags>
  </entry>
  <entry>
    <title>如何快速知道S3存储性能</title>
    <url>/2019/12/30/s3_radosgw_performance/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>当ceph S3集群搭建成功后，想知道当前存储的RGW性能如何， 如何快速评估呢？</p>
<p>本文介绍3种方法：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>s3cmd并发</p>
</li>
<li class="lvl-2">
<p>rest-bench</p>
</li>
<li class="lvl-2">
<p>cosbench</p>
</li>
</ul>
<h1 id="s-3-cmd-kuai-su-ping-gu">s3cmd 快速评估</h1>
<p>详请参考我同事Bean的blog：</p>
<p><code>https://bean-li.github.io/s3cmd-put-to-slow/ </code></p>
<h1 id="step-1-rest-bench">Step1. rest-bench</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>rest-bench这个工具，年久失修，在ceph的早期版本开发的（ceph version 0.80.11），运行到最后会crash，好在crash之前，很多的结果已经吐出来的，将就用吧，不用care CORE dump问题</p>
</li>
</ul>
<h2 id="an-zhuang-rest-bench">安装rest-bench</h2>
<pre><code class="language-shell">apt-get update
apt-get install rest-bench
</code></pre>
<h2 id="step-2-chuang-jian-bucket">Step2. 创建Bucket</h2>
<p>本文以s3cmd来创建bucket，当然，也可以通过其他可视化工具（S3 Browser 或者 CloudBerry Explorer for Amazon S3 Freeware）进行Bucket的创建， 如下操作，是在获知S3账号的AKEY和SKEY情况下进行的。</p>
<h3 id="zhun-bei-ce-shi-jiao-ben">准备测试脚本</h3>
<pre><code class="language-shell">export RGW=localhost:7480
export SECS=10
export SIZE=$((1&lt;&lt;22)) # 4MB object size
export BUCKET=bench
export CONCURRENCY=16
export KEY="4B2DT6E0B9C5R6MJ8OEA"
export SECRET="XI5ZxYejXiZXUJWtzLDEs4OXiGOYVDuoXVhBYtIa"

rest-bench -t $CONCURRENCY -b $SIZE --seconds=$SECS --api-host=$RGW --bucket=$BUCKET --access-key=$KEY --secret=$SECRET --no-cleanup write host=localhost:7480
</code></pre>
<p>如上脚本，可以放在一个shell script里，也可以直接在ssh console里执行</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>下列结果，为VM的测试结果，仅做示例</p>
</li>
</ul>
<pre><code class="language-shell"> Maintaining 16 concurrent writes of 4194304 bytes for up to 10 seconds or 0 objects
 Object prefix: benchmark_data_auto-70-1_839993
   sec Cur ops   started  finished  avg MB/s  cur MB/s  last lat   avg lat
     0       5         5         0         0         0         -         0
     1      16        20         4   15.9971        16   0.32558  0.209102
     2      16        32        16   31.9936        48  0.805092  0.811289
     3      16        41        25   33.3274        36  0.959682   1.12456
     4      16        42        26   25.9957         4   2.53238    1.1787
     5      16        44        28   22.3966         8   3.08912   1.31648
     6      16        48        32   21.3301        16   3.36158   1.63555
     7      16        57        41   23.4252        36   4.75692   2.15025
     8      16        67        51   25.4964        40   1.14588   2.20246
     9      16        74        58   25.7691        28   1.81314   2.15862
    10      16        79        63   25.1919        20   1.45566   2.13518
    11      16        80        64   23.2657         4   3.54682   2.15723
    12      15        80        65   21.6604         4   3.15252   2.17254
 Total time run:         12.499256
Total writes made:      80
Write size:             4194304
Bandwidth (MB/sec):     25.602 

Stddev Bandwidth:       16.0831
Max bandwidth (MB/sec): 48
Min bandwidth (MB/sec): 0
Average Latency:        2.48922
Stddev Latency:         1.42932
Max latency:            6.14039
Min latency:            0.088134
</code></pre>
<h1 id="cosbench">cosbench</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这个工具是Intel 开源的工具，业内也非常认可它，很多厂商都使用它进行S3的性能测试。</p>
</li>
<li class="lvl-2">
<p>本文以6节点做配置示例</p>
</li>
</ul>
<h2 id="controller-ce-controller-conf-nei-rong">controller侧controller.conf内容</h2>
<pre><code class="language-shell">[controller]
drivers = 6
log_level = INFO
log_file = log/system.log
archive_dir = archive

[driver1]
name = driver1
url = http://10.0.26.91:18088/driver

[driver2]
name = driver2
url = http://10.0.26.92:18088/driver

[driver3]
name = driver3
url = http://10.0.26.93:18088/driver

[driver4]
name = driver4
url = http://10.0.26.94:18088/driver

[driver5]
name = driver5
url = http://10.0.26.95:18088/driver

[driver6]
name = driver6
url = http://10.0.26.96:18088/driver
</code></pre>
<h2 id="driver-ce-driver-conf-nei-rong">driver侧driver.conf内容</h2>
<p>driver1的driver.conf内容：</p>
<pre><code class="language-shell">[driver]
log_level = DEBUG
name = driver1
url = http://10.0.26.91:18088/driver
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>其他node的driver.conf，只是name后面的driver名称（需要与controller.conf匹配）和URL地址的变化，其他没什么变化</p>
</li>
</ul>
<h2 id="workload-shi-li">workload示例</h2>
<h3 id="shi-li-1-36-threads-yun-xing-900-miao">示例1： 36Threads,运行900秒</h3>
<pre><code class="language-shell">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;workload name="Bigtera BT-H4400 HCI 1VM 36Threads" description="1GB tests. include writes, reads, mix tests"&gt;
&lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161" /&gt;

  &lt;workflow&gt;

		&lt;!-- ******************************* --&gt;
  	&lt;!-- 1mch 24wrks 36threads write job --&gt;
		&lt;!-- ******************************* --&gt;

    &lt;workstage name="1mch-23wrks-36threads-write-init"&gt;
        &lt;work name="1mch-24wrks-36threads-write-init" type="init" workers="1" interval="10" division="container" runtime="0" rampup="0" rampdown="0" driver="driver1"  config="cprefix=bigterahci;containers=r(1,48)" /&gt;
    &lt;/workstage&gt;
    
    &lt;workstage name="1mch-24wrks-36threads-write-WRITEJOB"&gt;
        &lt;work name="write1-11_7070" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1" &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(1,2);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-11_7071" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(3);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-11_7072" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(4,5);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-11_7073" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(7,8);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
		
        &lt;work name="write2-11_7070" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(9,10);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-11_7071" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(11,12);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-14_7072" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(13,14);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-14_7073" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(15,16);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
		
        &lt;work name="write1-12_7070" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(17,18);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-12_7071" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(19,20);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-12_7072" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(21,22);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-12_7073" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(23,24);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;

        &lt;work name="write2-12_7070" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(25,26);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-12_7071" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(27,28);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-14_7072" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(29,30);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-14_7073" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(31,32);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;

        &lt;work name="write1-13_7070" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(33,34);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-13_7071" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(35,36);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-13_7072" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(37,38);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-13_7073" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(39,40);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;

        &lt;work name="write2-13_7070" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(41,42);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-13_7071" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(43,44);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-14_7072" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(45,46);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-14_7073" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(47,48);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
    &lt;/workstage&gt;
		
    &lt;workstage name="1mch-24wrks-36threads-write-cleanup"&gt;
          &lt;work type="cleanup" workers="1" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(1,48);objects=r(1,10)" /&gt;
    &lt;/workstage&gt;
    &lt;workstage name="1mch-24wrks-36threads-write-dispose"&gt;
          &lt;work type="dispose" workers="1" driver="driver1" config="cprefix=bigterahci;containers=r(1,48)" /&gt;
    &lt;/workstage&gt;

		&lt;!-- ****************************** --&gt;
  	&lt;!-- 1mch 24wrks 36threads read job --&gt;
		&lt;!-- ****************************** --&gt;

    &lt;workstage name="1mch-24wrks-36threads-read-init"&gt;
        &lt;work name="1mch-24wrks-36threads-read-init" type="init" workers="1" interval="10" division="container" runtime="0" rampup="0" rampdown="0" driver="driver1"  config="cprefix=bigterahci;containers=r(1,48)" /&gt;
    &lt;/workstage&gt;
    
    &lt;workstage name="1mch-24wrks-36threads-read-prepare"&gt;
        &lt;work type="prepare" workers="48" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(1,48);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
    &lt;/workstage&gt;
    
    &lt;workstage name="1mch-24wrks-36threads-read-READJOB"&gt;
          &lt;work name="read1-11-7070" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(1,2);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-11-7071" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(3,4);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-11-7072" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(5,6);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-11-7073" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(7,8);objects=u(1,10)" /&gt;
          &lt;/work&gt;

          &lt;work name="read2-11-7070" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(9,10);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-11-7071" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(11,12);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-14-7072" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(13,14);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-14-7073" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(15,16);objects=u(1,10)" /&gt;
          &lt;/work&gt;
		  
          &lt;work name="read1-12-7070" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(17,18);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-12-7071" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(19,20);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-12-7072" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(21,22);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-12-7073" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(23,24);objects=u(1,10)" /&gt;
          &lt;/work&gt;

          &lt;work name="read2-12-7070" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(25,26);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-12-7071" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(27,28);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-14-7072" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(29,30);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-14-7073" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(31,32);objects=u(1,10)" /&gt;
          &lt;/work&gt;
		  
          &lt;work name="read1-13-7070" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(33,34);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-13-7071" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(35,36);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-13-7072" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(37,38);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read1-13-7073" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(39,40);objects=u(1,10)" /&gt;
          &lt;/work&gt;

          &lt;work name="read2-13-7070" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(41,42);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-13-7071" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(43,44);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-14-7072" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(45,46);objects=u(1,10)" /&gt;
          &lt;/work&gt;
          &lt;work name="read2-14-7073" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                  &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                  &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(47,48);objects=u(1,10)" /&gt;
          &lt;/work&gt;

    &lt;/workstage&gt;
    
    &lt;workstage name="1mch-24wrks-36threads-read-cleanup"&gt;
          &lt;work type="cleanup" workers="1" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(1,48);objects=r(1,10)" /&gt;
    &lt;/workstage&gt;
    &lt;workstage name="1mch-24wrks-36threads-read-dispose"&gt;
          &lt;work type="dispose" workers="1" driver="driver1" config="cprefix=bigterahci;containers=r(1,48)" /&gt;
    &lt;/workstage&gt;

		&lt;!-- ***************************** --&gt;
  	&lt;!-- 1mch 24wrks 36threads mix job --&gt;
		&lt;!-- ***************************** --&gt;

    &lt;workstage name="1mch-24wrks-36threads-mix-init"&gt;
        &lt;work name="1mch-24wrks-36threads-mix-init" type="init" workers="1" interval="10" division="container" runtime="0" rampup="0" rampdown="0" driver="driver1"  config="cprefix=bigterahci;containers=r(1,48)" /&gt;
    &lt;/workstage&gt;
    
    &lt;workstage name="1mch-24wrks-36threads-mix-prepare"&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(1,2);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(3,4);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(5,6);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(7,8);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(9,10);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(11,12);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
	    &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(13,14);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(15,16);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(17,18);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
		&lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(19,20);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(21,22);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
        &lt;work type="prepare" workers="8" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(23,24);objects=r(1,10);content=zero;sizes=c(1)GB" /&gt;
    &lt;/workstage&gt;

    &lt;workstage name="1mch-24wrks-36threads-mix-MIXJOB"&gt;
        &lt;work name="mix1-14_7070" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(25,26);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-11_7071" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(27,28);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-11-7072" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(1,2);objects=u(1,10)" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-14-7073" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(3,4);objects=u(1,10)" /&gt;
        &lt;/work&gt;
		
        &lt;work name="mix2-11_7070" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(29,30);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-11_7071" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(31,32);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-11-7072" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(5,6);objects=u(1,10)" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-11-7073" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.161"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(7,8);objects=u(1,10)" /&gt;
        &lt;/work&gt;
		
        &lt;work name="mix1-12_7070" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(33,34);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-14_7071" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(35,36);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-14-7072" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(9,10);objects=u(1,10)" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-12-7073" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(11,12);objects=u(1,10)" /&gt;
        &lt;/work&gt;

        &lt;work name="mix2-12_7070" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(37,38);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-12_7071" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(39,40);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-12-7072" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(13,14);objects=u(1,10)" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-12-7073" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.162"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(15,16);objects=u(1,10)" /&gt;
        &lt;/work&gt;

        &lt;work name="mix1-14_7070" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(41,42);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-13_7071" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(43,44);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-13-7072" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(17,18);objects=u(1,10)" /&gt;
        &lt;/work&gt;
        &lt;work name="mix1-14-7073" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.164"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(19,20);objects=u(1,10)" /&gt;
        &lt;/work&gt;

        &lt;work name="mix2-13_7070" type="write" workers="1" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(45,46);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-13_7071" type="write" workers="2" interval="10" division="object" runtime="900" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigterahci;oprefix=1GB_;containers=u(47,48);objects=u(1,10);sizes=c(1)GB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-13-7072" workers="1" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(21,22);objects=u(1,10)" /&gt;
        &lt;/work&gt;
        &lt;work name="mix2-13-7073" workers="2" runtime="900" rampup="10" rampdown="0" interval="10" driver="driver1" &gt;
                &lt;storage type="s3" config="accesskey=EIP2ZTZO4EHL6A50I8FT;secretkey=GFLTkbyVUaisUuSF0g9QgkZUmkGEyp3hOt7W2tpT;endpoint=http://10.0.26.163"/&gt;
                &lt;operation type="read" ratio="100" config="cprefix=bigterahci;oprefix=1GB_;containers=u(23,24);objects=u(1,10)" /&gt;
        &lt;/work&gt;
    &lt;/workstage&gt;
		
    &lt;workstage name="1mch-24wrks-36threads-mix-cleanup"&gt;
          &lt;work type="cleanup" workers="1" driver="driver1" config="cprefix=bigterahci;oprefix=1GB_;containers=r(1,48);objects=r(1,10)" /&gt;
    &lt;/workstage&gt;
    &lt;workstage name="1mch-24wrks-36threads-mix-dispose"&gt;
          &lt;work type="dispose" workers="1" driver="driver1" config="cprefix=bigterahci;containers=r(1,48)" /&gt;
    &lt;/workstage&gt;

	&lt;/workflow&gt;
&lt;/workload&gt;
</code></pre>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果只考虑运行多长时间，则xml中需要定义 <code>runtime="900" </code>，表示运行900秒</p>
</li>
<li class="lvl-2">
<p>如果要考虑在对应bucket里生成一定数量的object，则需要改成 <code>totalOps="500000" </code>，这里的500000表示50万个object</p>
</li>
</ul>
<h3 id="shi-li-2-60-threads-shun-xu-xie-gu-ding-shu-liang-de-object">示例2： 60Threads,顺序写固定数量的object</h3>
<pre><code class="language-shell">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;workload name="SEG_phyical_round1_60threads_ONLY_W" description="1VM 60threads w24work WR"&gt;
&lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63" /&gt;

  &lt;workflow&gt;
		&lt;!-- ******************************* --&gt;
  	&lt;!-- 1mch 20wrks 60threads write job --&gt;
		&lt;!-- ******************************* --&gt;

    &lt;workstage name="1mch-20wrks-60threads-write-init"&gt;
        &lt;work name="1mch-20wrks-60threads-write-init" type="init" workers="1" interval="10" division="container" runtime="0" rampup="0" rampdown="0" driver="driver1"  config="cprefix=seg;containers=r(1,1)" /&gt;
    &lt;/workstage&gt;

    &lt;workstage name="1mch-20wrks-60threads-write-WRITEJOB"&gt;
        &lt;work name="write1-11_7070" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1" &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(1,500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-11_7071" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(500001,1000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-11_7072" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(1000001,1500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-11_7073" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(1500001,2000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-11_7070" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(2000001,2500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-11_7071" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(2500001,3000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-11_7072" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.63"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(3000001,3500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-11_7073" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.64"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(3500001,4000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-12_7070" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.64"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(4000001,4500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-12_7071" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.64"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(4500001,5000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-12_7072" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.64"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(5000001,5500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-12_7073" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.64"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(5500001,6000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-12_7070" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.64"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(6000001,6500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-12_7071" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.64"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(6500001,7000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-12_7072" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.65"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(7000001,7500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-12_7073" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.65"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(7500001,8000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-13_7070" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.65"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(8000001,8500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-13_7071" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.65"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(8500001,9000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write1-13_7072" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.65"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(9000001,9500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2-13_7072" type="write" workers="8" interval="10" division="object" totalOps="500000" rampup="0" rampdown="0" driver="driver1"  &gt;
            &lt;auth type="none" config=""/&gt;
            &lt;storage type="s3" config="accesskey=DJL9ZF20DDPEGYCCY902;secretkey=K7DMecYvlsfU9jf6K6bDTc3afnPwwnWmbQyZ1aK8;endpoint=http://10.10.172.65"/&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=seg;oprefix=1_10KB_;containers=s(1,1);objects=r(9500001,10000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
    &lt;/workstage&gt;

&lt;!--
    &lt;workstage name="1mch-20wrks-60threads-write-cleanup"&gt;
          &lt;work type="cleanup" workers="1" driver="driver1" config="cprefix=seg;oprefix=1_10KB_;containers=r(1,1);objects=r(1,10)" /&gt;
    &lt;/workstage&gt;
    &lt;workstage name="1mch-20wrks-60threads-write-dispose"&gt;
          &lt;work type="dispose" workers="1" driver="driver1" config="cprefix=seg;containers=r(1,1)" /&gt;
    &lt;/workstage&gt;
--&gt;

	&lt;/workflow&gt;
&lt;/workload&gt;
</code></pre>
<h2 id="cosbench-de-bu-chong-shuo-ming">cosbench的补充说明</h2>
<p>container selector用 “s”, object selector用 “r”, 然后container数量跟object的"数量"要"互质"</p>
<p>示例:</p>
<pre><code class="language-shell">&lt;operation type="write" ratio="100" division="object" config="cprefix=tmo;oprefix=round2_10KB_;containers=s(8,10);objects=r(25001,50000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
</code></pre>
<p>10-8+1 = 3<br>
50000-25001+1 = 25000<br>
3跟25000数量</p>
<p>然后如果是设置timeout就要保证Dataset够大，不会写到重复的</p>
<p>如果是设置totalOps那設定的值照这个示例就是 3 * 25000 = 75000</p>
<p>如果contrainers和objects用range/sequential的selector时，最终生成的object个数为他们的最小公倍数，比如containers=s(1,10);objects=s(1,20)，这样最后的object个数时20，而不是200，所以要灌全200个object，有两个方法：</p>
<ul class="lvl-0">
<li class="lvl-2">
<ol>
<li class="lvl-5">在prepare workstage里会每个object都写到（不管使用的是何种division），因此利用prepare workstage来灌object</li>
</ol>
</li>
<li class="lvl-2">
<ol start="2">
<li class="lvl-5">如果是normal workstage的话，需要contrainers和objects的个数互为质数(relatively-prime)</li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>ceph</category>
        <category>S3</category>
      </categories>
      <tags>
        <tag>S3</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Nose Framework做分布式存储产品自动化</title>
    <url>/2019/12/31/seg_team_nose_automation_documentation/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>自2018-05-01提交第一个commit以来，在不影响正常测试工作release版本情况下，断断续续的持续了1年8个月的自动化开发在今天(2019-12-31)收尾了，总测试用例数为1310个，一路走来深有感慨。。。。。。</p>
<p>虽然收尾了，但后期版本功能发生变化，或者用例开发过程中有一些bug未考虑到导致用例执行失败的，还是需要对用例进行修改、优化，总之，一个产品自动化的完善，需要一个循序渐进的过程，持之以恒，总会渐变渐好！</p>
<p>本文记录了在开发产品自动化期间(Base on Ubuntu12.04)，所需要的一些条件、碰到的问题、注意事项等，如果想了解Nose framework的具体使用，请参考Nose官网吧，官网有详细的guide。</p>
<h1 id="bi-yao-de-an-zhuang-sheng-ji-xiu-gai">必要的安装/升级/修改</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>在线安装，所以存储节点要配置 dns server；</p>
</li>
<li class="lvl-2">
<p>本章节的如下操作，无需手动安装，只需要执行 <a href="http://run.py">run.py</a>，自动完成本章节的所有安装动作。本章节仅为了记录要安装哪些模块、插件、修改等信息。</p>
</li>
</ul>
<h2 id="1-fei-chan-pin-os-zuo-wei-ke-hu-duan-xu-yao-an-zhuang-de-ruan-jian">1、非产品OS 作为客户端需要安装的软件</h2>
<p>本章节以 ubuntu 为例，其他类型的 OS，不做考虑，且 OS 并不是我们的产品。</p>
<p>需要安装 multipath-tools， fio，openssh-server（支持 ssh 指令）， open-iscsi（支持 iscsiadm指令）， NFS  和 CIFS。 上述软件安装指令如下：</p>
<pre><code class="language-shell">apt-get install open-iscsi
apt-get install openssh-server apt-get install multipath-tools apt-get install fio
apt-get install cifs-utils
apt-get install nfs-kernel-server
</code></pre>
<p>如果客户端是官方的Ubuntu，那肯定是没有安装 NFS 和 CIFS 的，mount NFS/CIFS 会出问题：</p>
<pre><code class="language-shell">root@nose-ubuntu:/mnt# mount -t nfs 10.16.172.246:/vol/nose_nas /mnt/test mount: wrong fs type, bad option, bad superblock on 10.16.172.246:/vol/nose_nas,
missing codepage or helper program, or other error (for several filesystems (e.g. nfs, cifs) you might need a /sbin/mount.&lt;type&gt; helper program)

In some cases useful info is found in syslog - try dmesg | tail or so.


root@nose-ubuntu:/mnt# mount -t cifs //10.16.172.246/nose_nas_src /mnt/test/ mount: wrong fs type, bad option, bad superblock on //10.16.172.246/nose_nas_src,
missing codepage or helper program, or other error (for several filesystems (e.g. nfs, cifs) you might
need a /sbin/mount.&lt;type&gt; helper program)

In some cases useful info is found in syslog - try dmesg | tail or so.

root@nose-ubuntu:/mnt# dmesg | tail
[  141.523611] device-mapper: multipath: Failing path 65:0. [ 141.638465] device-mapper: multipath: Failing path 65:32. [ 141.638545] device-mapper: multipath: Failing path 65:112. [ 141.687588] device-mapper: multipath: Failing path 65:112. 
[846862.989111] FS-Cache: Loaded
[846862.997304] RPC: Registered named UNIX socket transport module. [846862.997307] RPC: Registered udp transport module. [846862.997308] RPC: Registered tcp transport module.
[846862.997309] RPC: Registered tcp NFSv4.1 backchannel transport module.
[846863.007999] FS-Cache: Netfs 'nfs' registered for caching

</code></pre>
<p>所以需要进行安装，成功安装后，内容如下：</p>
<pre><code class="language-shell">root@nose:~# dpkg -l | grep nfs
ii  libnfs4:amd64                        1.10.0-7.0+854+6b837f908                   amd64        NFS client library (shared library)
ii  libnfsidmap2:amd64                   0.25-5                                     amd64        NFS idmapping library
ii  nfs-common                           1:1.2.8-6ubuntu1.2                         amd64        NFS support files common to client and server
ii  nfs-kernel-server                    1:1.2.8-6ubuntu1.2                         amd64        support for NFS kernel server
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>目前 <a href="http://run.py">run.py</a> 有做检查，但不进行安装，具体安装操作，尚需手动执行。</p>
</li>
</ul>
<h2 id="2-an-zhuang-python-pip">2、安装python-pip</h2>
<pre><code class="language-shell">apt-get install python-pip
</code></pre>
<h2 id="3-sheng-ji-requests-mo-kuai">3、升级requests模块</h2>
<pre><code class="language-shell">pip install --upgrade --ignore-installed requests --index-url=https://pypi.python.org/simple

root@44:/var/cache/apt/archives# pip install --upgrade --ignore-installed requests --index-url=https://pypi.python.org/simple
Downloading/unpacking requests
  Downloading requests-2.18.4.tar.gz (126Kb): 126Kb downloaded
  Running setup.py egg_info for package requests
    
    warning: no files found matching 'NOTICE'
Downloading/unpacking chardet&gt;=3.0.2,&lt;3.1.0 (from requests)
  Downloading chardet-3.0.4.tar.gz (1.9Mb): 1.9Mb downloaded
  Running setup.py egg_info for package chardet
    
    warning: no files found matching 'requirements.txt'
Downloading/unpacking idna&gt;=2.5,&lt;2.7 (from requests)
  Downloading idna-2.6.tar.gz (135Kb): 135Kb downloaded
  Running setup.py egg_info for package idna
    
    warning: no previously-included files matching '*.pyc' found under directory 'tools'
    warning: no previously-included files matching '*.pyc' found under directory 'tests'
Downloading/unpacking urllib3&gt;=1.21.1,&lt;1.23 (from requests)
  Downloading urllib3-1.22.tar.gz (226Kb): 226Kb downloaded
  Running setup.py egg_info for package urllib3
    
    warning: no previously-included files matching '*' found under directory 'docs/_build'
Downloading/unpacking certifi&gt;=2017.4.17 (from requests)
  Downloading certifi-2018.4.16.tar.gz (149Kb): 149Kb downloaded
  Running setup.py egg_info for package certifi
    
Installing collected packages: requests, chardet, idna, urllib3, certifi
  Found existing installation: requests 1.2.3
    Uninstalling requests:
      Successfully uninstalled requests
  Running setup.py install for requests
    
    warning: no files found matching 'NOTICE'
  Found existing installation: chardet 2.0.1
    Uninstalling chardet:
      Successfully uninstalled chardet
  Running setup.py install for chardet
    
    warning: no files found matching 'requirements.txt'
    Installing chardetect script to /usr/local/bin
  Running setup.py install for idna
    
    warning: no previously-included files matching '*.pyc' found under directory 'tools'
    warning: no previously-included files matching '*.pyc' found under directory 'tests'
  Found existing installation: urllib3 1.6
    Uninstalling urllib3:
      Successfully uninstalled urllib3
  Running setup.py install for urllib3
    
    warning: no previously-included files matching '*' found under directory 'docs/_build'
  Running setup.py install for certifi
    
Successfully installed requests chardet idna urllib3 certifi
Cleaning up...
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>request模块，目前仅有wechat告警有使用到，升级不会对存储节点中python lib带来额外影响。</p>
</li>
</ul>
<h2 id="4-an-zhuang-configobj-mo-kuai">4、安装configobj模块</h2>
<pre><code class="language-shell">pip install configobj
</code></pre>
<h2 id="5-shi-yong-html-bao-gao">5、使用html 报告</h2>
<p>参考资料: <code>https://pypi.org/project/nose-html-reporting/ </code></p>
<p>安装命令：</p>
<pre><code class="language-shell">pip install nose-html-reporting
</code></pre>
<h2 id="6-an-zhuang-nose">6、安装nose</h2>
<p>存储节点系统安装好后自带nose，无需安装、升级。</p>
<h2 id="7-xiu-gai-nose-html-reporting-strong-init-strong-py">7、修改nose_html_reporting/<strong>init</strong>.py</h2>
<p>如果不修改，会报如下错误：</p>
<img class="shadow" src="/img/in-post/modify_nose_html_report_init.png" width="1200">
<p>解决方法：</p>
<p><code>vi /usr/local/lib/python2.7/dist-packages/nose_html_reporting-0.2.3-py2.7.egg/nose_html_reporting/__init__.py </code></p>
<p>修改 <code>/usr/local/lib/python2.7/dist-packages/nose_html_reporting-0.2.3-py2.7.egg/nose_html_reporting目录下__init__.py，</code><br>
将203行 <code>lstrip_blocks=True </code>注释掉，并删除掉产生的pyc文件。</p>
<pre><code class="language-shell">root@44:/home/nose_test/src# cd /usr/local/lib/python2.7/dist-packages/nose_html_reporting/
root@44:/usr/local/lib/python2.7/dist-packages/nose_html_reporting# rm __init__.pyc
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>修过__init__.py操作无需人工干预，run.py脚本中已经有修过动作。</p>
</li>
</ul>
<h2 id="8-an-zhuang-nose-testconfig">8、安装nose-testconfig</h2>
<pre><code class="language-shell">pip install nose-testconfig --index-url=https://pypi.python.org/simple
</code></pre>
<p>这个模块是nose的插件，用户用例执行时，接受用户指定的自定义循环执行用例的次数，必须安装。</p>
<h2 id="9-an-zhuang-guan-jian-zi-gao-liang-plugin">9、安装关键字高亮plugin</h2>
<p>参考资料</p>
<pre><code class="language-shell">https://gitee.com/walkingnine/colorunit
https://pypi.org/project/colorama/#files
</code></pre>
<p>需要安装如下这个包：</p>
<pre><code class="language-shell">colorama-0.3.9.tar.gz
walkingnine-colorunit.gz
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>安装上面安装包后，源码有问题，需要修改一些东西，这里是修改好了后，重新打了安装包。</p>
</li>
</ul>
<p>特别说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>测试用例中不需要添加下列步骤中内容，只要在nosetests执行用例的时候，使用–with-colorunit参数即可。</p>
</li>
</ul>
<pre><code class="language-shell">import nose; 
from colorunit import ColorUnit
  和：
if __name__ == '__main__':
    nose.main(addplugins = [ColorUnit()])
</code></pre>
<h2 id="10-yong-li-jin-du">10、用例进度</h2>
<p>参考资料</p>
<pre><code class="language-shell">https://github.com/erikrose/blessings
https://github.com/erikrose/nose-progressive
</code></pre>
<p>源码要求依赖nose 1.2.x，目前产品Ubuntu 14.04自带nose 版本是1.1.2，所以更改了源码版本要求，并重新打包，无需再次修过，直接安装python_3rd_lib目录下对应安装包即可。</p>
<h2 id="11-pylint-zhi-xing-bao-cuo">11、pylint执行报错</h2>
<img class="shadow" src="/img/in-post/nose_pylint_error.png" width="1200">
<p>原因:</p>
<p>未安装pylint， 解决方法：</p>
<p>进入nose_framework/python_3rd_lib/，解压pylint-1.7.6.tar.gz，进入解压缩目录，重新进行pylint的安装：</p>
<pre><code class="language-shell">cd pylint-1.7.6
python setup.py install
</code></pre>
<h1 id="nose-de-ri-chang-shi-yong">nose的日常使用</h1>
<h2 id="1-chang-yong-can-shu-jie-shao">1、常用参数介绍</h2>
<pre><code class="language-shell">-v : debug模式，看到具体执行情况，推荐大家执行时用这个选项。
-s : nose会捕获标准输出，调试的print代码默认不会打印。
   nosetest -s 可打开output输出，否则全部通过时不打印stdout。
   
-x : 一旦case失败立即停止，不执行后续case
-w : 指定一个目录运行测试。目录可以是相对路径或绝对路径.
--tests : 默认情况下，nosetests会执行所有的测试用例，若想单独只执行一个case，
       执行nosetest --tests 后跟要测试的文件(nosetests后面直接跟文件名，其实也可以
       直接运行该case。
--collect-only :  nosetests --collect-only -v，不运行程序，只是搜集并输出各个case的名称。
--processes ： 需要安装插件，--processes=20， 并发执行用例，解决用例总体执行时间
--with-progressive： 需要安装插件，实时展示用例执行进度
--with-colorunit ： 需要安装插件，用例执行结果展示的stdout，以颜色高亮展示
--with-html ： 需要安装插件，且需要和--html-report结合起来使用。这个插件，生成HTML
             格式的测试报告，该测试报告，是以report2.jinja2作为模板。 如果要指定自
             定义模板，可以使用--html-report-template参数，示例如下：
--with-colorunit --with-html --html-report=../report/sds.html --html-report-template=/usr/local/lib/python2.7/dist-packages/nose_html_reporting/templates/report2.jinja2

--tc : 需要安装插件，指定用例运行次数，目前参数名称写死：runs，示例：--tc=runs:20
</code></pre>
<h2 id="2-gong-ju-nose-tools-de-shi-yong">2、工具nose.tools的使用</h2>
<h3 id="da-biao-qian">打标签</h3>
<p>打标签的好处是，可以执行带有某些特定tag的用例，这里用tag，是借用了RF的概念，示例如下：</p>
<pre><code class="language-shell">from nose.plugins.attrib import attr
@attr('slow')
def test_big_download():
    pass

@attr(speed='slow')
def test_big_download():
    pass
</code></pre>
<p>执行的时候，带上 -a参数：</p>
<p><code>nosetests -a '!slow' </code></p>
<h3 id="shi-fou-ce-shi">是否测试</h3>
<p>测试脚本中引入：<code>from nose.tools import nottest,istest </code></p>
<p>1）不测试的方法：方法名上加修饰器@nottest；</p>
<p>2）指定为测试方法：方法名上加修饰器@istest（方法名无需符合命名规则）</p>
<h3 id="duan-yan">断言</h3>
<pre><code class="language-shell">&gt;&gt;&gt; from nose import tools
&gt;&gt;&gt; dir(tools)
['TimeExpired', '__all__', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'assert_almost_equal', 'assert_almost_equals', 'assert_dict_contains_subset', 'assert_dict_equal', 'assert_equal', 'assert_equals', 'assert_false', 'assert_greater', 'assert_greater_equal', 'assert_in', 'assert_is', 'assert_is_instance', 'assert_is_none', 'assert_is_not', 'assert_is_not_none', 'assert_items_equal', 'assert_less', 'assert_less_equal', 'assert_list_equal', 'assert_multi_line_equal', 'assert_not_almost_equal', 'assert_not_almost_equals', 'assert_not_equal', 'assert_not_equals', 'assert_not_in', 'assert_not_is_instance', 'assert_not_regexp_matches', 'assert_raises', 'assert_raises_regexp', 'assert_regexp_matches', 'assert_sequence_equal', 'assert_set_equal', 'assert_true', 'assert_tuple_equal', 'eq_', 'istest', 'make_decorator', 'nontrivial', 'nontrivial_all', 'nottest', 'ok_', 'raises', 'set_trace', 'timed', 'trivial', 'trivial_all', 'with_setup']
&gt;&gt;&gt;
</code></pre>
<h1 id="nose-set-up-tear-down-jie-shao">nose setUP/tearDown 介绍</h1>
<p>nose里面有多种可用的setup和teardown</p>
<h2 id="1-package-ji-bie-de">1、Package级别的</h2>
<p>写在init.py文件里包装</p>
<pre><code class="language-python">def setup_package():
    pass

def teardown_package():
    pass
</code></pre>
<h2 id="2-module-ji-bie-de">2、Module级别的</h2>
<pre><code class="language-python">def setup_module():
    pass

def teardown_module():
    pass
</code></pre>
<h2 id="3-class-ji-bie-de">3、Class级别的</h2>
<p>包装class,所以只执行一次</p>
<pre><code class="language-python">root@Scaler03:~# cat class_method.py
class TestClass():
    @classmethod
    def setup_class(cls):
        print "class method setup"
        
    @classmethod
    def teardown_class(cls):
        print "class method teardown"
        
    
    def test1(self):
        print "test1"

    def test2(self):
        print "test2"

    def test3(self):
        print "test3"
root@Scaler03:~#
</code></pre>
<p>执行结果</p>
<img class="shadow" src="/img/in-post/nose_eg01.png" width="1200">
<p>在nose中，不需要写类，只写函数可能就足够了，所以直接在一个文件中写:</p>
<pre><code class="language-python">root@Scaler03:~# cat nose_method_setup.py
def setup():
    print "setup"

def teardown():
    print "teardown"

def test_xxx():
    print "this is test xxx"

def test_yyy():
    print "this is test yyy"

root@Scaler03:~#
</code></pre>
<p>类似的，也是对整个文件而言，效果同上，测试结果如下：</p>
<img class="shadow" src="/img/in-post/nose_eg02.png" width="1200">
<h2 id="4-class-fang-fa-ji-bie">4、Class方法级别</h2>
<p>包装每一个test方法，所以每一个test函数的前后都会执行。</p>
<pre><code class="language-python">root@node97:/home/nose_framework/src/testcase/Function_Test/case_2_Accounts# cat ../../../testcasebase/Account/wyz.py
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

from __future__ import unicode_literals

import logging


from common.testcasebase import TestBase


class WYZManager(TestBase):
    """  account manager test case base class  """

    def __init__(self):
        super(WYZManager, self).__init__()
root@node97:/home/nose_framework/src/testcase/Function_Test/case_2_Accounts# cat wyz_test.py
#!/usr/bin/env python


from testcasebase.Account.wyz import WYZManager


class TestNose(WYZManager):
    def setUp(self):
       print "\nsetup"

    def tearDown(self):
        print("teardown")

    def test_case1(self):
        """  case 1  """
        print("this is test case 1")

    def test_case2(self):
        """  case 2  """
        print("this is test case 2")

    def test_case3(self):
        """  case 3  """
        print("this is test case 3")
</code></pre>
<p>执行结果：</p>
<img class="shadow" src="/img/in-post/nose_eg03.png" width="1200">
<p>从执行结果可以看出，测试类中的setUp 和 tearDown，会在每个测试用例中调用，即每个测试用例执行前，都会执行一次setUp，用例执行结束后，会执行tearDown。</p>
<h2 id="5-bao-zhuang-mou-ge-han-shu">5、包装某个函数</h2>
<p>测试函数也可定义setup和teardown属性，它们将会在测试函数开始和结束的时候运行。还可以使用@with_setup装饰器，该方式尤其适用于在相同的模块中的许多方法需要相同的setup操作</p>
<p>示例：</p>
<pre><code class="language-python">root@Scaler03:~# cat fun_nose_setup.py
from nose.tools import with_setup

def setup_func():
    print "set up test fixtures\n"
 
def teardown_func():
    print "tear down test fixtures\n"
 
@with_setup(setup_func, teardown_func)
def test1():
    print "test1"
    
@with_setup(setup_func, teardown_func)
def test2():
    print "test2"
    
    
@with_setup(setup_func, teardown_func)
def test3():
    print "test3"    
root@Scaler03:~# 
</code></pre>
<p>执行结果</p>
<img class="shadow" src="/img/in-post/nose_eg04.png" width="1200">
<h1 id="yong-li-bian-xie-gui-ze-yao-qiu">用例编写规则要求</h1>
<p>1、test_xxxx.py尽量避免逻辑操作，纯粹是function的调用</p>
<p>2、测试用例的名称，建议携带上用例的编号</p>
<p>例如：</p>
<img class="shadow" src="/img/in-post/test_link_case_no.png" width="400">
<p>test_9143_same_daemon_different_signal， 对应TestLink的用例为：<code>Sc-9143:Same daemon, different signal core file </code></p>
<p>3、测试用例的__doc__，不得含有中文字符</p>
<p>例如：</p>
<p><code>"""  Sc-9143:Same daemon，different signal core file  """</code></p>
<p>这里的逗号，是中文符号，会导致用例报错：</p>
<img class="shadow" src="/img/in-post/doc_error.png" width="1200">
<p>4、用例__doc__内容，以TestLink中名称为准</p>
<p>对于SEG自己增加的测试用例，需要以[SEG]开头， 参考如下：</p>
<img class="shadow" src="/img/in-post/nose_case_doc.png" width="400">
<p>5、避免测试用例之间存在依赖关系</p>
<p>（1）每个测试suite中的测试用例互相不依赖；</p>
<p>（2）测试suite中的用例，尽可能避免依赖关系</p>
<p>如TestLInke中上一个用例是创建，下一个用例是删除，则合并这两个用例为一个自动化测试用例。</p>
<p>6、日志记录对齐要求</p>
<p>执行动作的记录，开头增加[Action]；检查动作的记录，开头增加[Check];</p>
<p>断言记录的log，开头增加[ERROR]； 操作成功的log，开头增加[SUCCESS]； 不需要检查点的，开头增加[Skip]；</p>
<p>具体要求如下：</p>
<p><strong>[Prepare]</strong> <strong>后面跟2****个空格；</strong></p>
<p><strong>[Action]</strong> <strong>后面跟3****个空格</strong></p>
<p><strong>[Start]</strong> <strong>后面跟4****个空格</strong></p>
<p><strong>[Check]</strong> <strong>后面跟4****个空格</strong></p>
<p><strong>[Success]</strong> <strong>后面跟2****个空格</strong></p>
<p><strong>[Skip]</strong> <strong>后面跟5****个空格</strong></p>
<p><strong>debug<strong><strong>级别的log</strong></strong>，内容前面跟2<strong><strong>个-</strong></strong>，之后</strong> <strong>再加2****个空格</strong></p>
<p><strong>assert****中，[ERROR]</strong> <strong>后面跟2****个空格</strong></p>
<p>7、用例的执行顺序</p>
<p>执行 nosetests -s 可看到调用顺序， 用例执行顺序，根据ASSII进行排序，在用例有关联情况下，需要对用例名称增加数字编号，来人为的干预用例执行顺序，比如test_1_xxx, test_2_yyy。</p>
<p>8、代码规范要求</p>
<p>执行pylint，确保检查结果分值=10</p>
<p><code>pylint -r y testcasebase/Virtual_Storage/vs_user.py --rcfile=./pylintrc </code></p>
<p>MESSAGE_TYPE 有如下几种：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>© 惯例。违反了编码风格标准</p>
</li>
<li class="lvl-2">
<p>® 重构。写得非常糟糕的代码。</p>
</li>
<li class="lvl-2">
<p>(W) 警告。某些 Python 特定的问题。</p>
</li>
<li class="lvl-2">
<p>(E) 错误。很可能是代码中的错误。</p>
</li>
<li class="lvl-2">
<p>(F) 致命错误。阻止 Pylint 进一步运行的错误</p>
</li>
</ul>
<p>9、用例文件权限</p>
<p>统一使用 644 权限，否则默认情况下无法被 nosetests search 到，自然就不会被执行到，因为 nosetesst 默认只查找 644 权限的文件。</p>
<p>10、避免在 class 与 setup_class 之间做比较重的动作</p>
<p>比如下文中的 RRS 用例 test_remote_replication_tasks.py（下文代码是一个不可取的代码， 这里仅做示例用）</p>
<img class="shadow" src="/img/in-post/bad_eg.png" width="1200">
<p>在class TestReplicationTask 与setup_class 之间，启用了RRS 服务、创建了S3 账号并创建bucket， 最后上传了一些 object 到 bucket 中。正常情况下，这部分动作应该是在用例被执行之前要做的，然后会立刻执行 setup_class 中的动作，接着执行用例，最后 teardown。实际上，<a href="http://xn--run-lp6e.py">在run.py</a>  去执行所有测试用例的时候， 在 init 完所有的 class 之后（即创建完 session 后），会 先执行所有 test_xx.py 中定义在 class  与 setup_class 之间的所有动作， 这也无可厚非，但是，由于约束了用例的执行顺序，case_2_Accounts 会优先于 case_5_Remote_DR 被执行， 而 case_2_Accounts 里将其他 pool 设置为 S3 pool 的动作，这势必会清理掉在执行 <a href="http://run.py">run.py</a> init 结束后所创建的所有 bucket 与 bucket 下的 object，到 case_5_Remote_DR 被执行时，曾经创建的 bucket 与 bucket 下的 object 早已不复存在，自然 case_5_Remote_DR 下面的相关用例就会失败。</p>
<p>故而，建议：</p>
<p>避免在 class 与setup_class 之间做比较重的动作。对于较重的动作，放在 setup_class 中， 好处有 2：</p>
<p>（1）	避免被其他 class import 时做更多、更重的动作</p>
<p>（2）	避免用例 suite 间前后有依赖关系，给用例排查带来难度</p>
<p>11、用例文件名称、用例中定义变量名称全局唯一</p>
<p>对于测试用例中定义的变量，诸如 NAS 文件夹名称、子目录名称、iSCSI target 名称、volume 名称、pool 名称、cephfs 名称、用例执行过程中产生的文件的名称等等，要保持全局唯一， 即所有用例中不出现同名的文件名、目录名、pool 名等。当有用例出错时，可以根据这个名称，定位到是哪个用例产生了问题，因为具有唯一性，可以排除其他用例带来的干扰。</p>
<h1 id="nose-de-qi-ta-cha-jian">nose的其他插件</h1>
<h2 id="1-yong-li-she-ding-yi-lai-guan-xi">1、用例设定依赖关系</h2>
<p>需要安装 nose-dep plugin，具体操作，请参考如下链接： <a href="https://github.com/Zitrax/nose-dep">https://github.com/Zitrax/nose-dep</a></p>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这个 module 目前已经移除，本文档内容暂时留存，不删除，以作备用。</p>
</li>
</ul>
<h2 id="2-yong-li-zhi-xing-shun-xu">2、用例执行顺序</h2>
<p>这里介绍插件：nose-randomly</p>
<p>可以通过 <code>pip install nose-randomly </code></p>
<p>进行安装，成功安装后：</p>
<img class="shadow" src="/img/in-post/nose_plug01.png" width="1200">
<p>默认是按时间来做为随机种子来打乱用例顺序的，也可以自己定义种子。</p>
<h1 id="pei-zhi-wen-jian-shuo-ming">配置文件说明</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>配置文件在 src/config/autotest.config，包括但不限制于集群配置、客户端配置、AD/LDAP配置、检查周期、集群服务启用/停用等相关配置信息，全部在这个配置文件中，在运行用例前，务必确保这个配置文件的准确性。</p>
</li>
</ul>
<h2 id="1-autotest-config-shuo-ming">1、autotest.config 说明</h2>
<p>！！！ 这个文件的内容，需要根据被测环境进行实际修改 ！！！</p>
<pre><code class="language-shell">[CLUSTER]	
root_pass = "p@ssw0rd"	# 被测集群 root 密码，务必要正确
ssh_port = 22
cluster_name = NOSE	# 被测集群名称，仅适用于新建集群情况下；在已有集群下跑用例，不用改
osd_device = sdb	# 哪个分区被用于创建 OSD，仅适用于全新安装系统后 nose 自动创建集群
public_iface = ens160		# public interface 网口名称，务必要正确
storage_iface = ens192	# storage interface 网口名称，务必要正确
rep_no = 2	# 集群副本数，默认 2 副本ntp_server_ip = 202.120.2.101 # NTP server 地址dns_ip = 172.17.75.100 # DNS IP 地 址
storage_ips = "10.10.1.97 10.10.1.98 10.10.1.99" # 存储节点 storage 网络，以单个空格分割
public_ips = "172.17.75.97 172.17.75.98 172.17.75.99" # 存储节点 public 网络，以单个空格分割
forth_node_storage_ip = "10.10.10.249"  # 第四个节点的storage ip地址
license =
"3TYRSI-7IA0OW-109QON-LAZ8RV-27AICZ-FQBB3U-DLJW2P,3TYY0Z-Y3MUPS-0QRA8N-B5A8MT-7KOI1V-D9 T0RD-18X7QLW,3TZ49H-OOZOQO-1H5HY2-BAD4SB-236PNQ-VXNNGG-IY0LEH" # 这里是 Controller
license

[LOGING]
host = https://localhost:8080	# 访问存储 UI 的地址，无须修改
user_id= admin	# 访问 UI 的管理员账号
password = 1	# 访问 UI 的管理员账号对应的密码

[AD/LDAP]
ad_server_addr = 172.17.75.231	# AD 的相关设置
port = 389
ad_base_dns = "DC=hype,DC=com"
ad_admin_account = "hype\Administrator" 
ad_admin_passwd = "Trend#123" 
ad_search_dn = "CN=Users,DC=hype,DC=com" 
ad_acl_folder = 'Shares'
ad_acl_user = 'zhangsan' 
ad_acl_user_passwd = 'bigtera@123' 
ac_guest_folder = 'Guest'

ldap_server_addr = 172.17.75.199	# LDAP 的相关设置
ldap_base_dns = "dc=bigtera-os,dc=com" ldap_admin_account = "cn=admin,dc=bigtera-os,dc=com" ldap_admin_passwd = "12345678"
ldap_search_dn = "dc=bigtera-os,dc=com"

[TAKEOVERIP]
# ctdb takeover ip
takeover_ips = "172.17.73.91/24 172.17.73.92/24 172.17.73.93/24" #GW 接管 IP 地址，以空格分割

# S3 takeover IP
s3_takeover_ips = "172.17.73.94/24,94 172.17.73.95/24,95 172.17.73.96/24,96" # S3 的接管
IP 地址，以空格分割，格式必须是 IP/掩码位数

[SNMP]	# 这部分只要产品不发生变化，这里就不需要更改
mib_id = ".2.25.31690.11968.43142.4581.44107.2.42453.50459"
snmp_cluster_number = ".1.1"
snmp_product_name = ".1.2"
snmp_product_version = ".1.3"
snmp_fsid = ".1.4"
snmp_cluster_health = ".1.5"
snmp_cluster_disk_total_size = ".1.6"
snmp_cluster_disk_user_size = ".1.7"
snmp_read_io = ".1.8"
snmp_write_io = ".1.9"

esxi_vm_host_name = 'SEG_nose_client(!!!Do not power off it!!!)' # nose client 在 ESXi 侧
 
ipmi_ip = "172.17.75.221"	# nose client 是物理机（对应上面的 white_list_ip 参数），这个物理机的IPMI 地址
ipmi_user = 'ADMIN'	# IPMI 的系统管理员账号名称
ipmi_user_passwd = 'ADMIN'	# IPMI 系统管理员账号的密码 

[BACKUP] # nose 用例执行过程中备份文件的存档目录，这里不需要修改
backup_base_path = "/tmp/nose_backup/"
ezs3_log_backup = "/tmp/nose_backup/log_ezs3/"
test_case_output_path = "/tmp/nose_backup/test_case_output"

[RETRY]
retry_interval = 5 # 间隔 5 秒尝试一次，做 check 或 mount 之类的动作
retry_timeout = 40 # 总共尝试次数，默认 40 次

[DAEMON_SERVICE]	# 服务的重启、停止相关动作，不同版本的操作系统指令不一样
# restart or stop or start deamon service
restart_ezmonitor = "/etc/init.d/ezmonitor restart"
restart_csmonitor = "/etc/init.d/csmonitor restart"
restart_ezfs_agent = "/etc/init.d/ezfs-agent restart"
restart_ezfs_recycle_flusher = "/etc/init.d/ezfs-recycle-flusher restart"
restart_eziscsi = "/etc/init.d/eziscsi restart"
restart_eziscsi_rbd_clean = "/etc/init.d/eziscsi-rbd-cleaner restart"
restart_apache = "/etc/init.d/apache2 restart"
restart_rgw = "/etc/init.d/radosgw restart"
restart_smart_monitor = "/etc/init.d/ezs3-smart-monitor restart"
restart_ezs3_agent = "/etc/init.d/ezs3-agent restart"

restart_ctdb = "/etc/init.d/ctdb restart"
start_ctdb = "/etc/init.d/ctdb start"
stop_ctdb = "/etc/init.d/ctdb stop"

restart_multipath_tool = "/etc/init.d/multipath-tools restart"
restart_resolvconf = "/etc/init.d/resolvconf restart"

# For ceph service
ceph_start = "/etc/init.d/ceph start"
start_mon = "/etc/init.d/ceph start mon"
start_mds = "/etc/init.d/ceph start mds"
start_osd = "/etc/init.d/ceph start osd"
start_all_osd = "/etc/init.d/ceph -a start osd"
start_all_mon = "/etc/init.d/ceph -a start mon"
start_all_mds = "/etc/init.d/ceph -a start mds"
# # Start all of ceph service on all node(osd, mon and mds)
start_all_ceph_service = "/etc/init.d/ceph -a start"

restart_mon = "/etc/init.d/ceph restart mon"
restart_mds = "/etc/init.d/ceph restart mds"

stop_mon = "/etc/init.d/ceph stop mon"
stop_mds = "/etc/init.d/ceph stop mds"
stop_osd = "/etc/init.d/ceph stop osd"

start_assign_osd = "/etc/init.d/ceph start osd."
stop_assign_osd = "/etc/init.d/ceph stop osd."

# # For keepalived
stop_keepalived = "/etc/init.d/keepalived stop"
</code></pre>
<h2 id="2-log-config-shuo-ming">2、log.config 说明</h2>
<p>！！！ 这个文件的内容，无需更改 ！！！</p>
<pre><code class="language-shell">#logger.conf
###############################################
[loggers]
keys=root
[logger_root]
level=DEBUG
handlers=hand01
###############################################
[handlers]
keys=hand01
[handler_hand01]
class=StreamHandler
level=ERROR
formatter=form02
args=(sys.stdout,)

[handler_hand02]
class=FileHandler
level=DEBUG
formatter=form01
args=('nose_autotest.log','w')
###############################################
[formatters]
keys=form01,form02
[formatter_form01]
format=%(asctime)s %(filename)-8s[line:%(lineno)-4s] %(levelname)-6s %(message)s
datefmt=%a, %d %b %Y %H:%M:%S
[formatter_form02]
format=%(asctime)s %(filename)-8s[line:%(lineno)-4s] %(levelname)-6s %(message)s
# format=%(name)-12s: %(levelname)-8s %(message)s
datefmt=
###############################################
[nosetests]
verbosity=2
logging-format=%(asctime)s %(filename)-8s[line:%(lineno)-4s] %(levelname)-6s %(message)s
</code></pre>
<h1 id="ce-shi-yong-li-de-zhi-xing">测试用例的执行</h1>
<h2 id="1-zhi-xing-mou-ge-test-suite">1、执行某个test suite</h2>
<pre><code class="language-shell">nosetests -v -x testcase/test_account.py:ManagerAccount --with-html --html-report=../report/nose.html --html-report-template=/usr/local/lib/python2.7/dist-packages/nose_html_reporting/templates/report2.jinja2
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这里的ManagerAccount， 是test_account.py的一个class。</p>
</li>
</ul>
<h2 id="2-zhi-xing-zhi-ding-ce-shi-yong-li">2、执行指定测试用例</h2>
<pre><code class="language-shell">nosetests -v -x testcase/test_account.py:TestManagerAccount.test_add_user_success --with-html --html-report=../report/nose.html
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这里的test_add_user_success， 是具体的测试用例，表明这个用例是test_account.py文件中TestManagerAccount类下的用例</p>
</li>
</ul>
<h2 id="3-zhi-xing-duo-ge-ce-shi-yong-li-ce-shi-ji-he">3、执行多个测试用例/测试集合</h2>
<p>如果是执行不同测试集合中的不同用例，示例如下：</p>
<pre><code class="language-shell">nosetests -v --with-progressive --with-html --html-report=../report/test.html testcase/Function_Test/case_4_Virtual_Storages/NAS/test_NAS_general_management.py:TestN ASGeneral.test_434_create_nfs_cifs_folder testcase/Function_Test/case_7_Statistics_Logs/test_query_export_log.py:TestLogs.test_74
5_4_query_log_by_category_node_management
</code></pre>
<h2 id="4-duo-jin-cheng-bing-fa-ce-shi">4、多进程并发测试</h2>
<p>携带参数–processes， 如–processes=2</p>
<p>可以缩短测试时间，同时，要一并携带上 --process-restartworker和 --process-timeout参数，–process-timeout数值要比较大（单位：秒），否则可能会出现内存泄露。</p>
<p>示例如下：</p>
<pre><code class="language-shell">nosetests -v -x --tc=runs:3 --process-restartworker --process-timeout=100000 --processes=5 testcase/Function_Test/case_4_Virtual_Storages/NAS/test_samba_account.py
</code></pre>
<h2 id="5-dry-run">5、dry-run</h2>
<p>只列出要执行哪些用例</p>
<pre><code class="language-shell">nosetests --collect-only  -v 
</code></pre>
<h2 id="6-yun-xing-bu-tong-mo-kuai-xia-bu-tong-yong-li">6、运行不同模块下不同用例</h2>
<pre><code class="language-shell">nosetests -v -x --tests=testcase/test_account.py:ManagerAccount,testcase/test_mds.py:restart_mds --with-html --html-report=../report/nose.html 
</code></pre>
<h2 id="7-yong-li-zhi-xing-shi-guan-jian-zi-gao-liang">7、用例执行时关键字高亮</h2>
<p>使用前面安装的colurunit plugin，用例执行时带上参数–with-colorunit</p>
<pre><code class="language-shell">nosetests --with-colorunit -s -x -v --with-html --html-report=../report/nose_all_cases.html
</code></pre>
<h2 id="8-yong-li-zhi-xing-xian-shi-jin-du">8、用例执行显示进度</h2>
<pre><code class="language-shell">nosetests --with-progressive --with-colorunit -s -x -v --with-html --html-report=../report/nose_all_cases.html
</code></pre>
<p>输出示例：</p>
<img class="shadow" src="/img/in-post/nose_eg04.png" width="1200">
<p>这里源码有个问题，同时使用高亮和进度，会导致高亮和进度在用例执行结果信息输出时，两部分信息展示混杂在一起，已经修改源码解决，安装后无需做任何调整。</p>
<h2 id="9-xun-huan-yun-xing-yong-li">9、循环运行用例</h2>
<p>携带runs参数，并制定循环执行的次数，如果不携带该参数，默认不循序，即只运行一次（特殊用例除外，比如账号中只创建、删除，不做检查，最后做一轮检查的场景）。</p>
<pre><code class="language-shell">nosetests -s -x -v --with-progressive --with-colorunit --with-html --html-report=../report/sds.html testcase/Function_Test/case_4_Virtual_Storages/NAS/test_samba_account.py:TestSambaAccount.test_add_delete_samab_user_no_check --tc=runs:50
</code></pre>
<p>说明:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果不指定runs，默认不循环，即只执行用例一次（Code写死）。</p>
</li>
</ul>
<h1 id="bian-xie-yong-li-peng-dao-de-wen-ti">编写用例碰到的问题</h1>
<h2 id="1-yong-li-wu-fa-sheng-cheng-html-report">1、用例无法生成 html report</h2>
<p>Jenkins 或者手动执行用例无法生成 html report</p>
<img class="shadow" src="/img/in-post/nose_report_error.png" width="1200"> 
<p>原因：</p>
<p>任意一个测试用例存在UnicodeDecodeError assert 错误，都会导致html 报告的无法生成。</p>
<p>解决方法：</p>
<p>找出有 UnicodeDecodeError 断言错误的用例，往往是测试中文相关的测试用例，解决UnicodeDecodeError。</p>
<h2 id="2-yong-li-zhi-xing-shi-bai-ti-shi-nose-html-reporting-add-error-init-takes-at-least-3-arguments-2-given">2、用例执行失败，提示 nose_html_reporting addError init__() takes at least 3 arguments (2 given)</h2>
<p>堆栈信息显示：</p>
<img class="shadow" src="/img/in-post/nose_report_error2.png" width="1200">
<p>这个原因，往往是测试用例编写上出了问题，可以通过增加 log 或执行 pylint 来检查一下。</p>
<h2 id="3-yong-li-wen-jian-quan-xian-wen-ti">3、用例文件权限问题</h2>
<p>如下图所示，测试用例文件的权限不能是 755，建议统一设置为 644，否则用例无法被nosetest 查找到，也就不会被执行到（nose 默认情况下并不测试那些拥有可执行权限的文件）。</p>
<img class="shadow" src="/img/in-post/nose_primession01.png" width="1200">
<p>如果要执行可以加上 --exe, 如 nosetests --exe, 或者去掉可执行属性chmod 644 <a href="http://xxx.py">xxx.py</a></p>
<img class="shadow" src="/img/in-post/nose_primession02.png" width="600">
<h2 id="4-yong-li-duo-lun-diao-ce-cheng-gong-hou-fang-ke-ti-jiao-dai-ma">4、用例多轮调测成功后方可提交代码</h2>
<p>下面的示例指令：</p>
<pre><code class="language-shell">nosetests -v --tc=runs:1 --with-xunit --traverse-namespace --process-restartworker
--process-timeout=432000 --processes=10 --with-coverage
--cover-package=/home/nose_framework/src/ --cover-inclusive --with-progressive
--with-colorunit --with-html --html-report=/home/nose_framework/src/../report/rrs.html -c config/log.config
/home/nose_framework/src/testcase/Function_Test/case_5_Remote_DR/test_remote_replication_tasks.py 
</code></pre>
<p>是完整的调测某一个suite 下的所有 case 指令， 第一遍整体调试没有问题后，将–tc=runs:1 调整成 --tc=runs:2， 再次执行用例，确保所有用例都是成功的，而且 html report 也成功生成 ， 方 可 提 交 测 试 代 码 ， ！ ！ ！ 请 务 必 这 样 做 ！ ！ ！ （ 参 考test_9339_reupload_onject_to_bucket_after_new_s3_pool）。</p>
<h2 id="5-yong-li-zhi-xing-qi-jian-vm-bei-zhong-qi">5、用例执行期间，VM 被重启</h2>
<p>下图为用例执行卡在了凌晨 01:28:32</p>
<img class="shadow" src="/img/in-post/nose_vm_boot01.png" width="600">
<p>查看对应时间点的 node：</p>
<img class="shadow" src="/img/in-post/nose_vm_boot02.png" width="600">
<p>VM 的确被重启了，所有执行用例的进程都不在了：</p>
<img class="shadow" src="/img/in-post/nose_vm_boot03.png" width="500">
<p>因 VM 使用 converger 提供的 LUN， converger 环境在那个时间点前后并没有异常；对应 ESXi<br>
在那个时间点前有一个告警：</p>
<img class="shadow" src="/img/in-post/nose_vm_boot04.png" width="600">
<p>除此之外，并未发现其他问题，即这个自动重启的原因未知。</p>
<p>后来在 ESXi 对应 VM 目录下，vmware.log 文件中：</p>
<img class="shadow" src="/img/in-post/nose_vm_boot05.png" width="600">
<img class="shadow" src="/img/in-post/nose_vm_boot06.png" width="600">
<p>根 据 VMWare KB 的 解 释 ： <code>https://kb.vmware.com/s/article/2000542 kern panic </code>，导致虚机被重启。</p>
<p>目前尚无有效解决方法，先放大内存看看（从 4G 调整为 6G）</p>
<h2 id="6-zhi-xing-yong-li-de-cun-chu-jie-dian-vm-nose-zhan-yong-guo-duo-nei-cun">6、执行用例的存储节点（VM），nose 占用过多内存</h2>
<img class="shadow" src="/img/in-post/nose_memory_leak.png" width="600">
<p>由于现在用例数比较多，nose 运行时间长，目前尚不知在何种状况下导致 nose 占用了过多的内存。根据官方提供的资料：</p>
<img class="shadow" src="/img/in-post/nose_memory_leak2.png" width="300">
<p>增加–proces-restartworker 可以避免内存泄露，但 <a href="http://run.py">run.py</a> 是有携带这个参数的，没看到效果。目前推测是<strong>失败的用例较多导致</strong>的，也许提高用例的成功率，能够解决这个问题，持续跟踪该问题。</p>
<h2 id="7-apache-2-fu-wu-yi-chang-dao-zhi-connection-error-cannot-assign-requested-address">7、apache2 服务异常，导致 ConnectionError，Cannot assign requested address</h2>
<img class="shadow" src="/img/in-post/apache_error.png" width="600">
<p>这里发现对应节点的 apache2 service 已经不存在了，导致后续用例全部失败，暂时未知具体原因，目前想到的规避方法如下：</p>
<p>方法 1：修改 http_session.py 中 HTTP session header 中 Connection，由‘keep-alive’调整为‘close’， 同时，在发起 HTTP request 后，sleep 0.01 秒。</p>
<p>方法 2：需要增加一个 watchdog，来拉起 apache 服务。</p>
<p>目前上述两个方法暂时未动手，这里先记录一下，如果未来还会发生，再来处理。</p>
<p>2019-05-28 再次发生：</p>
<img class="shadow" src="/img/in-post/apache_error2.png" width="600">
<p>apache2 进程全部退出</p>
<img class="shadow" src="/img/in-post/apache_exit_log.png" width="600">
<p>目前对 http_session.py 做如下调整：</p>
<p>(1)将 HTTP session header 中 Connection，由‘keep-alive’调整为‘close’</p>
<img class="shadow" src="/img/in-post/keep_alive.png" width="600">
<p>(2)捕获 ConnectionError 异常，并重启 apache2 服务</p>
<img class="shadow" src="/img/in-post/connection_exception.png" width="600">
<p>2019-10-10:</p>
<p>鉴于之前的修复，问题再次发生，现在 http_session.py 增加如下内容：</p>
<pre><code class="language-shell">requests.adapters.DEFAULT_RETRIES = 5 # 增加重连次数
self.session.keep_alive = False # 关闭多余连接
</code></pre>
<p>但问题依然存在。</p>
<p>2019-10-11:</p>
<p>再次修复，删除<code>requests.adapters.DEFAULT_RETRIES = 5 </code>,将 <code>session.keep_alive = False </code> 放在 http_request 函数里，继续观察一下吧，下次问题再次发生时候，执行 netstat -tn 或者netstat | grep -c tcp，来查看是否是有太多处于"TIME_WAIT" 状态的 TCP 连接导致问题的发生； 如果是， 需要考虑优化下当前 automation 创建 session、使用session 问题了。</p>
<h2 id="8-gui-bi-logretate-shi-de-apache-reload-dao-zhi-fa-song-http-request-hou-tai-fan-hui-500">8、规避logretate 使得apache reload 导致发送 HTTP request 后台返回 500</h2>
<img class="shadow" src="/img/in-post/backend_return_500.png" width="600">
<p>在00:17 前后，会发生Logrotate，其中有一步apache reload，假如此刻恰巧有发送HTTP request，此时 apache  服务状态异常，后台返回 500 错误码。 为了规避这个问题，自动化做了特殊处理，即在发送 HTTP 请求时，hard code 去判断此刻是否是 00:16，如果是，等待150 秒进行规避。</p>
<img class="shadow" src="/img/in-post/skip_logrotate.png" width="600">
<h2 id="9-gui-bi-client-mount-san-device-chu-xian-already-mounted-or-busy">9、规避client mount SAN device 出现 already mounted or busy</h2>
<img class="shadow" src="/img/in-post/mount_busy.png" width="600">
<p>如上图所示，当 nose 日志显示客户端 mount 出现 device already mounted or busy 状况时， 会影响后续几个用例的正常执行。</p>
<p>目前尚未找到解决方法，只能重启机器，但是此种情况下，reboot or reboot -f 指令往往失效，只能硬重启。</p>
<p>目前解决方法是：</p>
<p>无论客户端是 VM 还是物理机，</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>（1）	执行 <a href="http://run.py">run.py</a> 时，重启一次 Client；</p>
</li>
<li class="lvl-2">
<p>（2）	当 mount SAN device 出现 device already mounted or busy，重启一次 Client</p>
</li>
</ul>
<p>对于 VM，通过 ssh 跳转到 ESXi 执行，所以 ESXi 需要开启 SSH 服务</p>
<p><code>vim-cmd vmsvc/power.off {vm_id}&amp;&amp; vim-cmd vmsvc/power.on {vm_id} </code></p>
<p>对于物理机，通过执行 ipmitool 命令还 power reset 一下，达到重启机器的目的：</p>
<p><code>ipmitool -I lanplus -H {客户端 IP 地址} -U{管理员账号} -P {管理员账号密码} power reset	</code></p>
<h1 id="zhu-yi-shi-xiang">注意事项</h1>
<h2 id="1-vm-xi-tong-fen-qu-ci-pan-da-xiao-yao-da-yu-140-g">1、VM 系统分区磁盘大小要大于 140G</h2>
<p>在创建 VM 分配磁盘大小时，需要系统对应磁盘的分区大小是 140G，之所以有这个要求，是因为需要使用操作系统的一个子分区（比如 sda4）作为 cephfs 的 cache，如果 total size 是 32G，那 sda4 只有几百 M，无法满足 cache size 最低是 10G 的要求。鉴于此，通过 PXE 自动安装 VM 对应的配置文件 nose_70_97-99，osdisksize 要设置成 140：</p>
<p>经验证，如果设置成 128G， 则 sda4 是 6G， 设置成 256， sda4 是 134G</p>
<pre><code class="language-shell">sda	8:0	0	256G 0 disk
├─sda1	8:1		0	7M	0 part
├─sda2	8:2		0	95.4G 0 part /
├─sda3	8:3		0	26.7G 0 part [SWAP]
└─sda4	8:4		0	134G	0 part
sdb	8:16	0		32G	0 disk
sdc	8:32	0		32G	0 disk
sdd	8:48	0		32G	0 disk
sde	8:64	0		32G	0 disk
</code></pre>
<p>在 os disk size 是 140G 的情况下，确保 sda4（18G）有超过 10G 的空间大小。</p>
<h2 id="2-ce-shi-yong-li-bu-yao-zai-di-yi-ge-huo-zui-hou-yi-ge-jie-dian-shang-zhi-xing">2、测试用例不要在第一个或最后一个节点上执行</h2>
<p>有一些 S3 takeover IP 的用例，会执行 reboot 或 ifdown 第一个或最后一个节点的 public和storage NIC，故而，避免在第一个或最后一个节点上执行用例。目前 <a href="http://run.py">run.py</a> 脚本有做约束性检查。</p>
<h2 id="3-ke-hu-duan-cun-zai-dsa-key">3、客户端存在 dsa key</h2>
<p>在配置文件中设置的white_list_ip，如下图所示：</p>
<img class="shadow" src="/img/in-post/key_1.png" width="300">
<p>white_list_ip 这台机器所在的/root/.ssh/目录下，需要存在 id_dsa.pub 这个文件：</p>
<img class="shadow" src="/img/in-post/key_2.png" width="300">
<p>如果不存在，需要执行下来命令来产生：</p>
<p><code>ssh-keygen -t dsa </code></p>
<p>只所以需要这个 key 的原因，是 RRS automation 需要从远端获取这个 sshkey，否则会导致RRS SSH KEY 这部分相关用例失败（test_remote_SSH_keys.py）。</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>这部分操作，无需人工干预，<a href="http://xn--run-7j2en15cikk868b.py">已经放到run.py</a> 脚本中了。</p>
</li>
</ul>
<h2 id="4-ke-hu-duan-qi-yong-multi-path">4、客户端启用 multi-path</h2>
<p>如果默认没有启用，在确保安装了 multipath-tool 的情况下，将下列命令写入/etc/rc.local​<code>/etc/init.d/multipath-tools start </code></p>
<p>上述命令，需要书写在exit 0 前面。</p>
<h2 id="5-ke-hu-duan-ding-qi-zhong-qi">5、客户端定期重启</h2>
<p>由于当前客户端是一台 VM，建议用例执行前重启一下这台VM，主要目的在于:</p>
<h3 id="1-shi-fang-wu-xiao-de-dm-she-bei">1、释放无效的 dm 设备</h3>
<p>！！！此条适用于所有 nose automation 的 client，无论是物理机还是 VM ！！！</p>
<img class="shadow" src="/img/in-post/dm_device1.png" width="1200"> 
<p>对于上图，除了 27d7e5983bd6f7dc5 对应的 dm 设备是有效的，其他的 dm 设备都是无效的，一旦这个 client login 一个 iSCSI LUN 后，如果 map 到了上面一个已经存在的 dm 设备， mkfs 的时候会报类似如下的错误：</p>
<p><code>/dev/dm-2 is apparently in use by the system; will not make a filesystem here! </code></p>
<p>尝试使用 dmsetup remove -f device_name 指令去删除，命令卡住，<strong>目前尚无解决方法， 只能重启机器</strong>，重启后恢复正常：</p>
<img class="shadow" src="/img/in-post/dm_device2.png" width="600">
<p>另外，在 kernen.log 中发现很多的“BUG: unable to handle kernel NULL pointer dereference at (null)”，如下图所示：</p>
<img class="shadow" src="/img/in-post/dm_device3.png" width="600">
<p>不确定这个野指针是否导致 dm 设备的残留。</p>
<h3 id="2-shi-fang-zi-yuan-bi-mian-ke-hu-duan-xiang-ying-guo-man">2、释放资源，避免客户端响应过慢</h3>
<p>如果客户端是物理机，可忽略重启操作。设置脚本：</p>
<pre><code class="language-shell">root@NoseClient:/usr/local/bin# cat /usr/local/bin/reboot_machine.sh #!/bin/bash

reboot -f root@NoseClient:/usr/local/bin#
</code></pre>
<p>每天凌晨3 点（Jenkins 是每天3:20 执行用例，因为这个时刻ISO 正好从台北同步到南京LAB， 当然也可自由设定执行时间）进行 VM 的重启动作：</p>
<pre><code class="language-shell">root@NoseClient:/usr/local/bin# cat /etc/cron.d/reboot_machine PATH=/bin:/usr/bin:/sbin

1 3 * * * root bash /usr/local/bin/reboot_machine.sh &gt;/dev/null 2&gt;&amp;1 root@NoseClient:/usr/local/bin#
</code></pre>
<h2 id="6-neng-bian-xie-dan-xu-yao-yan-chi-bian-xie-de-yong-li-zeng-jia-raise-skip-test">6、能编写但需要延迟编写的用例，增加 raise SkipTest</h2>
<p>比如在写Folder quota 这部分的测试用例，里面有 RRS 和 pool quota 相关的几个case， 因 RRS 或 pool quota 相关 class base 尚未具备，可以标记这部分用例为skip 状态，这样做的目的是避免不加skip 而在将来被忽略掉，导致这部分用例并没有编写。</p>
<p>主要目的:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、意在提醒 skip 状态的用例要在将来被完成</p>
</li>
<li class="lvl-2">
<p>2、某些用例只适用于物理机，VM 无法验证，增加判断，对于 VM 要 skip</p>
</li>
</ul>
<p>skip 示例请参考如下链接：</p>
<p><code>http://swordstyle.com/func_test_tutorial/part_one/extra_skip_test.html </code></p>
<pre><code class="language-python">class TestFolderQuota(ShareFolderManager): @loop_run()
def test_1090_folder_quota_less_than_pool_quota(self):
""" Sc-1090:Folder quota &lt; Pool Quota [limited by folder quota] """ raise SkipTest
</code></pre>
<h2 id="7-base-class-li-jin-zhi-han-shu-ming-cheng-han-you-test">7、base class 里，禁止函数名称含有 test</h2>
<p>nose 运行用例的时候，根据正则匹配测试用例，会匹配到含有 test 的函数，会认为这个函数是一个测试用例，故而要避免此种情况的发生，test 可以使用单词examination 代替。</p>
<img class="shadow" src="/img/in-post/skip_start_test.png" width="600">
<h2 id="8-chuang-jian-vs-shi-pool-ming-cheng-bi-xu-yi-nose-kai-tou">8、创建VS 时，pool 名称必须以nose 开头</h2>
<p>目前是 hard code 的限制，否则对 pool 的一些检验会无法通过。</p>
<h2 id="9-ad-ce-cun-zai-yi-ge-shares-he-guest-gong-xiang-mu-lu">9、AD 侧存在一个 Shares 和 Guest 共享目录</h2>
<p>目前是 hard code 的限制：</p>
<img class="shadow" src="/img/in-post/hard_code1.png" width="600">
<p>在 NAS migration 用例里，涉及到 Windows Server 提供的 folder，目前写在 config 中：</p>
<img class="shadow" src="/img/in-post/hard_code2.png" width="300"> 
<h2 id="10-es-xi-kai-qi-ssh-fu-wu">10、ESXi 开启 SSH 服务</h2>
<p>如果 client 是ESXi 上的一台 VM，则需要 ESXi 开启 SSH 服务，因为需要通过 ssh ESXi， 执行重启 VM 操作。</p>
<h1 id="ce-shi-jie-guo-zhan-shi">测试结果展示</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>用例执行过程中产生日志文件和生成一个HTML格式的测试报告，日志文件名称（默认：nose_autotest.log）在src/config/ autotest.config中配置，以及打印的日志级别（默认：DEBUG）， 也在这个配置文件中设置。</p>
</li>
</ul>
<h2 id="1-ping-xian-shu-chu-xin-xi">1、屏显输出信息</h2>
<p>示例：</p>
<pre><code class="language-shell">root@node98:/home/nose_framework/src# nosetests -s -x -v --processes=10  --with-progressive --with-colorunit --with-html --html-report=../report/sds.html testcase/Function_Test/case_2_Accounts/test_SDS_admin_account_settings.py
</code></pre>
<img class="shadow" src="/img/in-post/display_01.png" width="600">
-------------------------------------------------------  中间内容省略  -----------------------------------------------
<img class="shadow" src="/img/in-post/display_02.png" width="600">
<h2 id="2-zi-dong-hua-chan-sheng-de-ri-zhi-wen-jian">2、自动化产生的日志文件</h2>
<p>日志文件路径：report/ nose_autotest.log，内容示例如下：</p>
<img class="shadow" src="/img/in-post/nose_log_file.png" width="600">
<h2 id="3-html-ce-shi-bao-gao">3、HTML测试报告</h2>
<p>html 测试报告默认路径为：report/ all_test_cases.html，示例如下：</p>
<img class="shadow" src="/img/in-post/nose_report_show.png" width="600">
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>绿色： 表明用例执行成功， Success状态</p>
</li>
<li class="lvl-2">
<p>橙色： 表明用例执行失败， Fail状态</p>
</li>
<li class="lvl-2">
<p>红色： 表明用例执行发生错误， Error状态</p>
</li>
</ul>
<p>点击左下角的“Full log raw output”， 展示用例执行期间记录的日志信息，如果出错，也会将异常详细信息记录下来：</p>
<img class="shadow" src="/img/in-post/nose_fail_log.png" width="1200">
<h1 id="nose-cun-zai-de-wen-ti">Nose存在的问题</h1>
<h2 id="1-nose-memory-leak">1、nose memory leak</h2>
<p>目前nose是执行在存储节点上，对于VM而言，赋予VM的VMemory并不是很大，而nosetests有时候占用70%以上的内存，引发集群异常，此种状况的发生，会导致VM内存不足，没法保证集群正常运行。</p>
<p>这点，本文之前的章节有提及到，怀疑问题的发生点，在于过多的测试用例执行失败，引发nose 要capture过多的信息放在memory里。</p>
<h2 id="2-nose-crash">2、nose crash</h2>
<p>此问题在2019-12-19 00:52:31 左右发生，直接导致nose崩溃，终止用例的执行。</p>
<img class="shadow" src="/img/in-post/nose_crash01.png" width="600">
<img class="shadow" src="/img/in-post/nose_crash02.png" width="600">
<img class="shadow" src="/img/in-post/nose_crash03.png" width="600">
<p>产品成功检测到nosetests core dump了。</p>
<h1 id="dai-ma-fen-zhi-jie-shao">代码分支介绍</h1>
<p>Master是6.3， 其他分支以具体版本号创建分支。 Master分支目前暂停用例编写/更新。</p>
<h1 id="yu-jenkins-jie-he">与jenkins结合</h1>
<h2 id="yong-dao-de-jenkins-cha-jian">用到的jenkins插件</h2>
<p>Jenkins拥有丰富的第三方插件，可以用来帮助我们完成各种各样的雪球。下列是本文中用到的几个插件：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Junit Plugin: 用来展示nose框架生成的单元测试报表</p>
</li>
<li class="lvl-2">
<p>Cobertura Plugin：用来展示Python代码测试覆盖率报表</p>
</li>
<li class="lvl-2">
<p>Violations：用来展示Python静态代码审查报表，支持pylint、jslint等</p>
</li>
</ul>
<h2 id="jenkins-de-job-pei-zhi">jenkins的job配置</h2>
<p>下文以 nose-7.0 project为示例。</p>
<h3 id="1-chuang-jian-credentials">1）创建Credentials</h3>
<img class="shadow" src="/img/in-post/nose_jenkins1.png" width="600">
<img class="shadow" src="/img/in-post/nose_jenkins2.png" width="600">
<img class="shadow" src="/img/in-post/nose_jenkins3.png" width="600">
<h3 id="2-she-zhi-remote-ssh">2）设置remote ssh</h3>
<p>进入jenkisn–系统管理–系统设置界面，在“SSH remote hosts”处，新增新的ssh remote hosts，并进行check connection，如下图所示：</p>
<img class="shadow" src="/img/in-post/nose_jenkins4.png" width="600">
<p>连接测试成功后，保存退出。</p>
<h2 id="3-pei-zhi-nose-7-0-project">3）配置nose-7.0 project</h2>
<h3 id="general">General</h3>
<p>进入nose-7.0 project，设置如下：</p>
<img class="shadow" src="/img/in-post/nose_jenkins5.png" width="600">
<h3 id="yuan-ma-guan-li">源码管理</h3>
<img class="shadow" src="/img/in-post/nose_jenkins6.png" width="600">
<p>下载到 /work/automation-test/nose_7.0/nose_framework/</p>
<h3 id="gou-jian-hong-fa-qi">构建触发器</h3>
<img class="shadow" src="/img/in-post/nose_jenkins7.png" width="600">
<h3 id="gou-jian-huan-jing">构建环境</h3>
<img class="shadow" src="/img/in-post/nose_jenkins8.png" width="600">
<p>需要执行的脚本命令如下：</p>
<pre><code class="language-shell"># delete report on 234
cd /var/lib/jenkins/jobs/nose_7.0/workspace;
rm -rf report;
sleep 2;

# install VM
sshpass -p 1 ssh -p 22 172.17.75.235 -l root "/root/batch_install_vs/batch_install_vs.py /root/batch_install_vs/config/nose/nose_70_97-99"

# scp code to VM
cd /work/automation-test/nose_7.0/nose_framework;
rm -rf build.properties;
rm -rf report;
cd jenkins;chmod a+x *;
ssh-keygen -f "/var/lib/jenkins/.ssh/known_hosts" -R 172.17.75.98;
./rsync_nose.sh 172.17.75.98 root p@ssw0rd
</code></pre>
<img class="shadow" src="/img/in-post/nose_jenkins9.png" width="600">
<p>相关命令如下：</p>
<pre><code class="language-shell">cd /work/automation-test/nose_7.0/nose_framework/jenkins; 
./rsync_report.sh 172.17.75.98 root p@ssw0rd;
./jenkins_build_properties.sh
</code></pre>
<p>外部变量的使用：</p>
<img class="shadow" src="/img/in-post/nose_jenkins10.png" width="600">
<p>路径设置为：</p>
<p><code>/work/automation-test/nose_7.0/nose_framework/build.properties </code></p>
<p>这里使用Inject environment variables的目的，是为了发送邮件内容中，展示任务是从什么时间开始、什么时间点结束，用例执行成功、失败等情况，以及被测试版本信息。</p>
<h3 id="gou-jian-hou-cao-zuo">构建后操作</h3>
<p>发送邮件:</p>
<img class="shadow" src="/img/in-post/nose_jenkins11.png" width="600">
<p>HTML内容如下：</p>
<pre><code class="language-shell">&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;h2 style="color: #5e9ca0; text-align: center;"&gt;
            Note:(This email generated by system automatically, please do not reply!)
        &lt;/h2&gt;
        &lt;table class="editorDemoTable" style="height: 549px; width: 811px;"&gt;
            &lt;thead&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #3498db; text-align: center; width: 801px;" colspan="2" nowrap="nowrap"&gt;
                        &lt;h2&gt;
                            &lt;span style="color: #000000;"&gt;SEG V7.0 NOSE Automation Test Result&lt;/span&gt;
                        &lt;/h2&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #3498db; width: 801px; text-align: left;" colspan="2" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Information&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
            &lt;/thead&gt;
            &lt;tbody&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Test Result&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;&amp;nbsp;&lt;/span&gt;
                        &lt;ul&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Total Cases:&amp;nbsp; &amp;nbsp; ${TEST_COUNTS}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #008000;"&gt;Pass&amp;nbsp; Cases:&amp;nbsp; &amp;nbsp; ${TEST_PASS}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #ffff00;"&gt;Fail&amp;nbsp; &amp;nbsp;Cases:&amp;nbsp; &amp;nbsp; ${TEST_FAIL}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #3366ff;"&gt;Skip&amp;nbsp; Cases:&amp;nbsp; &amp;nbsp; ${TEST_SKIP}&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000; background-color: #ff0000;"&gt;Error Cases:&amp;nbsp; &amp;nbsp; ${TEST_ERROR}&lt;/span&gt;
                            &lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Product Version&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$PRODUCT_VERSION&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        Time Consuming
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;From ($START_TIME) To ($END_TIME)&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Project Name&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$PROJECT_NAME&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Number&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$BUILD_NUMBER&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Status&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;$BUILD_STATUS&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Trigger Reason&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;${CAUSE}&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #3498db; width: 801px; text-align: left;" colspan="2" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Test Information&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build&amp;nbsp;Result&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;&lt;a style="color: #000000;" title="Build Result" href="${BUILD_URL}console"&gt;${BUILD_URL}&lt;/a&gt;&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Build Log&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 643px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;&lt;a style="color: #000000;" title="Build Log" href="${BUILD_URL}console"&gt;${BUILD_URL}console&lt;/a&gt;&lt;/span&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 150px;" nowrap="nowrap"&gt;
                        &lt;span style="color: #000000;"&gt;Log&amp;amp;Report&lt;/span&gt;
                    &lt;/td&gt;
                    &lt;td style="background-color: #beedc7; border-color: gray; width: 643px;" nowrap="nowrap"&gt;
                        &lt;br&gt;
                        &lt;ul&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Test Report:&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;a style="color: #000000;" title="Test Report" href="${BUILD_URL}testReport"&gt;${BUILD_URL}testReport&lt;/a&gt;&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Pylint Violations Report:&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp; &lt;a style="color: #000000;" title="Pylint Violations Report" href="${BUILD_URL}violations"&gt;${BUILD_URL}violations&lt;/a&gt;&lt;/span&gt;
                            &lt;/li&gt;
                            &lt;li&gt;
                                &lt;span style="color: #000000;"&gt;Cobertura Coverage Report:&amp;nbsp;&amp;nbsp; &lt;a style="color: #000000;" title="Cobertura Coverage Report" href="${BUILD_URL}cobertura"&gt;${BUILD_URL}cobertura&lt;/a&gt;&lt;/span&gt;
                            &lt;/li&gt;
                        &lt;/ul&gt;
                    &lt;/td&gt;
                &lt;/tr&gt;
             &lt;/tbody&gt;
        &lt;/table&gt;
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>邮件附件信息</p>
<img class="shadow" src="/img/in-post/nose_jenkins12.png" width="1200">
<p>在Attachment处，填写如下附件路径信息：</p>
<pre><code class="language-shell">report/create_cluster.html,report/setup_cluster.html,report/all_test_cases.html,report/nose_autotest.log
</code></pre>
<p>设置Publish JUnit test result report</p>
<img class="shadow" src="/img/in-post/nose_jenkins13.png" width="1200">
<p>设置Publish Cobertura coverage report</p>
<img class="shadow" src="/img/in-post/nose_jenkins14.png" width="1200">
<p>设置 Report Violation</p>
<img class="shadow" src="/img/in-post/nose_jenkins15.png" width="1200">
<p>在pylint处，录入report/pylint</p>
<img class="shadow" src="/img/in-post/nose_jenkins16.png" width="1200">
<h3 id="4-bu-fen-ming-ling-ji-lu">4）部分命令记录</h3>
<p>这部分命令，已经写入到run.py中，如果想手动单独执行，可以参考如下命令</p>
<h4 id="sheng-cheng-nosetests-xml">生成nosetests.xml</h4>
<pre><code class="language-shell">nosetests --tc=runs:1 --with-xunit --traverse-namespace --with-coverage --cover-package=/home/nose_framework/src --cover-inclusive --with-progressive --with-colorunit --with-html --html-report=../report/all_case.html
</code></pre>
<h4 id="sheng-cheng-coverage-xml">生成coverage.xml</h4>
<pre><code class="language-shell">python -m coverage xml --include=/home/nose_framework/src*
</code></pre>
<h4 id="pylint">pylint</h4>
<pre><code class="language-shell">cd /home/nose_framework/src

pylint --rcfile=.pylintrc -f parseable -d I0011,R0801 * | tee pylint.out
</code></pre>
<h4 id="xiao-guo-tu">效果图</h4>
<img class="shadow" src="/img/in-post/nose_jenkins17.png" width="1200">
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1、右侧，pylint，显示代码规范质量曲线图</p>
</li>
<li class="lvl-2">
<p>2、点击" Code Coverage" 查看测试代码覆盖率</p>
</li>
<li class="lvl-2">
<p>3、点击 “最新测试结果”，查看具体的HTML测试报告</p>
</li>
</ul>
<h5 id="ce-shi-dai-ma-fu-gai-lu">测试代码覆盖率</h5>
<img class="shadow" src="/img/in-post/nose_jenkins18.png" width="1200">
<h5 id="html-zhan-shi-yong-li-ce-shi-jie-guo">HTML展示用例测试结果</h5>
<img class="shadow" src="/img/in-post/nose_jenkins19.png" width="1200">
<h5 id="you-jian-jie-shou-ren-jie-shou-dao-de-you-jian-xin-xi">邮件接收人接收到的邮件信息</h5>
<img class="shadow" src="/img/in-post/nose_jenkins20.png" width="1200">
<h1 id="jenkins-peng-dao-de-wen-ti">Jenkins 碰到的问题</h1>
<h2 id="1-wu-fa-zheng-chang-fa-song-you-jian">1、无法正常发送邮件</h2>
<p>test邮件是OK的，但是每次build的结果，无法正常发送邮件，console信息显示：</p>
<img class="shadow" src="/img/in-post/nose_jenkins21.png" width="1200">
<p>问题解决方法</p>
<p>这个问题是Jenkins管理用户的一个问题，它可以自动从git或者svn读取用户信息以及邮件（如果git等中设置了的话）， 但它不又不创建Jenkins上的用户，所以你可以在pepole列表上看到有用户名，但在jenkins的用户列表上又没有该用户。</p>
<p>修复的方法也比较简单，就是用admin登陆jenkins，帮所有people列表上的用户设置一下默认密码（自己约定）并保存，则会创建相应的jenkins用户了，这样用户就都是registrered用户了。</p>
<p>详请参考：<code>https://www.oschina.net/question/3567295_2246136 </code></p>
<h2 id="2-console-xin-xi-chu-xian-yan-se-zhi">2、Console 信息出现颜色值</h2>
<p>如下图所示</p>
<img class="shadow" src="/img/in-post/nose_jenkins22.png" width="1200">
<p>上图中的“[32m[1m”即为颜色值，不太美观，改进之。</p>
<p>Jenkins 有 一 个 插 件 AnsiColor， 详 请 参 考 ： <code>https://www.jianshu.com/p/12083063957b?utm_campaign=maleskine&amp;utm_content=note&amp;ut m_medium=seo_notes&amp;utm_source=recommendation </code></p>
<p>安装成功并重启Jenkins 服务后，在 Build Environment 处，选择“Color ANSI Console Output”，并设置“ANSI color map”为 xterm 即可：</p>
<img class="shadow" src="/img/in-post/nose_jenkins23.png" width="1200">
<p>效果图：</p>
<img class="shadow" src="/img/in-post/nose_jenkins24.png" width="800">
]]></content>
      <categories>
        <category>Automation</category>
        <category>nose</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>nose</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD盘符漂移导致OSD down场景模拟与恢复</title>
    <url>/2020/01/10/ssd_disk_partition_drift_and_recovery/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>运维团队反馈一个问题，现象是：</p>
<p>某个OSD对应的cache分区发生了变化，比如原来cache使用的分区是/dev/sde,后来还是这块盘，但分区信息不知何故，变成了/dev/sdf（产品OSD设备并不是根据分区名称来map，而是根据partlabel），最终的现象是这个OSD down了，没法启动.<br>
接到这个现象的反馈后，记录一下这个问题在lab的复现方法。</p>
<h1 id="zhun-bei-gong-zuo">准备工作</h1>
<h2 id="step-1-osd-data-pan-zuo-raid-5">Step1. OSD data盘做RAID5</h2>
<h2 id="step-2-zhong-xin-jiang-ssd-make-as-jbod">Step2. 重新将SSD make as JBOD</h2>
<p>在Step1结束后，将在RAID卡上的SSD设置为JBOD</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpSetProp -EnableJBOD -1 -aALL</code></p>
<h2 id="step-3-chuang-jian-ji-qun-zheng-chang-qi-yong-osd-dui-ying-osd-yao-xuan-ze-ssd-zuo-wei-cache">Step3. 创建集群，正常启用OSD，对应osd要选择SSD作为cache</h2>
<p>如下为node245上的data与cache 大致的map关系：</p>
<pre><code class="language-shell">root@node245:~# lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda                         8:0    0 447.1G  0 disk 
├─sda1                      8:1    0     8G  0 part 
├─sda2                      8:2    0 439.1G  0 part 
│ ├─g-osd1-0-cache (dm-0) 252:0    0 380.4G  0 dm   /data/cache/g-osd1-0
│ ├─g-osd1-0-ext4m (dm-1) 252:1    0  58.5G  0 dm   
│ │ └─g-osd1-0 (dm-2)     252:2    0  14.6T  0 dm   /data/osd.0
│ └─g-osd1-0-ext4j (dm-3) 252:3    0   256M  0 dm   
└─sda3                      8:3    0  1007K  0 part 
sdb                         8:16   0 447.1G  0 disk 
├─sdb1                      8:17   0     8G  0 part 
├─sdb2                      8:18   0 439.1G  0 part 
│ ├─g-osd2-0-cache (dm-4) 252:4    0   395G  0 dm   /data/cache/g-osd2-0
│ ├─g-osd2-0-ext4m (dm-5) 252:5    0  43.9G  0 dm   
│ │ └─g-osd2-0 (dm-6)     252:6    0    11T  0 dm   /data/osd.1
│ └─g-osd2-0-ext4j (dm-7) 252:7    0   256M  0 dm   
└─sdb3                      8:19   0  1007K  0 part 
sdc                         8:32   0  14.6T  0 disk 
└─sdc1                      8:33   0  14.6T  0 part 
  └─g-osd1-0 (dm-2)       252:2    0  14.6T  0 dm   /data/osd.0
sdd                         8:48   0  10.9T  0 disk 
└─sdd1                      8:49   0  10.9T  0 part 
  └─g-osd2-0 (dm-6)       252:6    0    11T  0 dm   /data/osd.1
sde                         8:64   0 278.9G  0 disk 
├─sde1                      8:65   0   7.6M  0 part 
├─sde2                      8:66   0  95.4G  0 part /
├─sde3                      8:67   0  26.7G  0 part [SWAP]
└─sde4                      8:68   0 156.8G  0 part 
root@node245:~#
</code></pre>
<h1 id="wen-ti-fu-xian">问题复现</h1>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>本文示例的SSD为E:S为[9:1]，对应的分区信息是sdb， 对应的osd id是1</p>
</li>
</ul>
<h2 id="step-1-que-ren-hao-ssd-suo-zai-de-pan-wei-zhi-jie-cong-she-bei-shang-ba-diao-jin-jie-zhao-zai-cha-hui-qu">Step1. 确认好SSD所在的盘位，直接从设备上拔掉，紧接着再插回去</h2>
<p>重新拔插回去的SSD，此时节点的lsblk吐出信息是：</p>
<pre><code class="language-shell">root@node245:~# lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda                         8:0    0 447.1G  0 disk 
├─sda1                      8:1    0     8G  0 part 
├─sda2                      8:2    0 439.1G  0 part 
│ ├─g-osd1-0-cache (dm-0) 252:0    0 380.4G  0 dm   /data/cache/g-osd1-0
│ ├─g-osd1-0-ext4m (dm-1) 252:1    0  58.5G  0 dm   
│ │ └─g-osd1-0 (dm-2)     252:2    0  14.6T  0 dm   /data/osd.0
│ └─g-osd1-0-ext4j (dm-3) 252:3    0   256M  0 dm   
└─sda3                      8:3    0  1007K  0 part 
sdc                         8:32   0  14.6T  0 disk 
└─sdc1                      8:33   0  14.6T  0 part 
  └─g-osd1-0 (dm-2)       252:2    0  14.6T  0 dm   /data/osd.0
sdd                         8:48   0  10.9T  0 disk 
└─sdd1                      8:49   0  10.9T  0 part 
  └─g-osd2-0 (dm-6)       252:6    0    11T  0 dm   /data/osd.1
sde                         8:64   0 278.9G  0 disk 
├─sde1                      8:65   0   7.6M  0 part 
├─sde2                      8:66   0  95.4G  0 part /
├─sde3                      8:67   0  26.7G  0 part [SWAP]
└─sde4                      8:68   0 156.8G  0 part 
sdf                         8:80   0 447.1G  0 disk 
├─sdf1                      8:81   0     8G  0 part 
├─sdf2                      8:82   0 439.1G  0 part 
└─sdf3                      8:83   0  1007K  0 part 
root@node245:~# 
</code></pre>
<p>此时，发现sdb已经不见了，出现了新的分区sdf：</p>
<pre><code class="language-shell">root@node245:~# gdisk /dev/sdf
GPT fdisk (gdisk) version 0.8.8

Partition table scan:
  MBR: protective
  BSD: not present
  APM: not present
  GPT: present

Found valid GPT with protective MBR; using GPT.

Command (? for help): 

Command (? for help): p
Disk /dev/sdf: 937703088 sectors, 447.1 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 7CB4C196-1B82-4190-B044-C11E96294A62
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 937703054
Partitions will be aligned on 8-sector boundaries
Total free space is 1679 sectors (839.5 KiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048        16779263   8.0 GiB     8300  **g-osd2-0-journal**
   2        16779264       937701375   439.1 GiB   8300  **g-osd2-0-ssd**
   3              34            2047   1007.0 KiB  8300  

Command (? for help): 
</code></pre>
<p>可以看出，sdf分区的partlabel就是之前的名称（g-osd2-0-journal &amp;&amp; g-osd2-0-ssd），只是分区信息发生了变化。虽然不知道现场是如何发生分区突然名称更换（也许是被人为触碰，也许是被插拔，也是是其他原因，总之root cause不确定），但是碰到这种情况，如何恢复环境，先恢复业务，解决客户投诉燃眉之急，然后再来查找root cause或针对产品进行改进、优化，能够更好的适配类似问题的发生，使得能够自动恢复，减少人为干预。</p>
<h2 id="step-2-jiang-cha-ba-hui-qu-de-ssd-make-wei-jbod">Step2. 将插拔回去的SSD make为JBOD</h2>
<p>在Step1里，盘插回去后，这块盘的状态是unconfig good，需要make as JBOD</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDMakeJBOD -PhysDrv[9:1] -a0 </code></p>
<h2 id="step-3-que-ren-dang-qian-dm-xin-xi">Step3. 确认当前dm信息</h2>
<pre><code class="language-shell">root@node245:~# mount
/dev/sde2 on / type ext4 (rw,errors=remount-ro)
proc on /proc type proc (rw,noexec,nosuid,nodev)
sysfs on /sys type sysfs (rw,noexec,nosuid,nodev)
none on /sys/fs/cgroup type tmpfs (rw)
none on /sys/fs/fuse/connections type fusectl (rw)
none on /sys/kernel/debug type debugfs (rw)
none on /sys/kernel/security type securityfs (rw)
udev on /dev type devtmpfs (rw,mode=0755)
devpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620)
tmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)
none on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880)
none on /run/shm type tmpfs (rw,nosuid,nodev)
none on /run/user type tmpfs (rw,noexec,nosuid,nodev,size=104857600,mode=0755)
none on /sys/fs/pstore type pstore (rw)
rpc_pipefs on /run/rpc_pipefs type rpc_pipefs (rw)
systemd on /sys/fs/cgroup/systemd type cgroup (rw,noexec,nosuid,nodev,none,name=systemd)
/dev/mapper/g-osd1-0 on /data/osd.0 type ext4 (rw,noatime,nodelalloc,journal_path=/dev/mapper/g-osd1-0-ext4j)
/dev/mapper/g-osd1-0-cache on /data/cache/g-osd1-0 type ext4 (rw,noatime,nodelalloc)
/dev/mapper/g-osd2-0 on /data/osd.1 type ext4 (rw,noatime,nodelalloc,journal_path=/dev/mapper/g-osd2-0-ext4j)
/dev/mapper/g-osd2-0-cache on /data/cache/g-osd2-0 type ext4 (rw,noatime,nodelalloc)
1.1.1.245,1.1.1.244,1.1.1.243:/ on /var/share/ezfs type ceph (wsize=4194304,mount_timeout=15,noshare,mds_namespace=1)
root@node245:~# dmsetup status
g-osd2-0-ext4m: 0 92012544 linear 
g-osd2-0-cache: 0 828385280 linear 
g-osd2-0-ext4j: 0 524288 linear 
g-osd1-0: 0 31374440415 ext4meta 
g-osd2-0: 0 23530829791 ext4meta 
g-osd1-0-ext4m: 0 122683392 linear 
g-osd1-0-cache: 0 797714432 linear 
g-osd1-0-ext4j: 0 524288 linear 
root@node245:~# 
</code></pre>
<p>这里发现，g-osd2-0对应的ext4m，ext4j之类的信息依然存在于dm设备中</p>
<h2 id="step-4-jie-hong-dm-she-bei-li-map-guan-xi">Step4.  接触dm设备里map关系</h2>
<pre><code class="language-shell">root@node245:~# umount /dev/mapper/g-osd2-0-cache
root@node245:~# dmsetup remove g-osd2-0-cache
root@node245:~# umount /data/osd.1
root@node245:~# dmsetup remove g-osd2-0
root@node245:~# dmsetup remove g-osd2-0-ext4m
root@node245:~# dmsetup remove g-osd2-0-ext4j
root@node245:~# dmsetup table
g-osd1-0: 0 31374440415 ext4meta SSD:252:1 HDD:8:33
g-osd1-0-ext4m: 0 122683392 linear 8:2 797714432
g-osd1-0-cache: 0 797714432 linear 8:2 0
g-osd1-0-ext4j: 0 524288 linear 8:2 920397824
root@node245:~# 
</code></pre>
<h2 id="step-5-zhong-xin-gua-zai-dm-she-bei">Step5.  重新挂载dm设备</h2>
<pre><code class="language-shell">root@node245:~# bt-mount.py 
root@node245:~# 
root@node245:~# 
root@node245:~# 
root@node245:~# lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda                         8:0    0 447.1G  0 disk 
├─sda1                      8:1    0     8G  0 part 
├─sda2                      8:2    0 439.1G  0 part 
│ ├─g-osd1-0-cache (dm-0) 252:0    0 380.4G  0 dm   /data/cache/g-osd1-0
│ ├─g-osd1-0-ext4m (dm-1) 252:1    0  58.5G  0 dm   
│ │ └─g-osd1-0 (dm-2)     252:2    0  14.6T  0 dm   /data/osd.0
│ └─g-osd1-0-ext4j (dm-3) 252:3    0   256M  0 dm   
└─sda3                      8:3    0  1007K  0 part 
sdc                         8:32   0  14.6T  0 disk 
└─sdc1                      8:33   0  14.6T  0 part 
  └─g-osd1-0 (dm-2)       252:2    0  14.6T  0 dm   /data/osd.0
sdd                         8:48   0  10.9T  0 disk 
└─sdd1                      8:49   0  10.9T  0 part 
  └─g-osd2-0 (dm-6)       252:6    0    11T  0 dm   /data/osd.1
sde                         8:64   0 278.9G  0 disk 
├─sde1                      8:65   0   7.6M  0 part 
├─sde2                      8:66   0  95.4G  0 part /
├─sde3                      8:67   0  26.7G  0 part [SWAP]
└─sde4                      8:68   0 156.8G  0 part 
sdf                         8:80   0 447.1G  0 disk 
├─sdf1                      8:81   0     8G  0 part 
├─sdf2                      8:82   0 439.1G  0 part 
│ ├─g-osd2-0-cache (dm-4) 252:4    0   395G  0 dm   /data/cache/g-osd2-0
│ ├─g-osd2-0-ext4m (dm-5) 252:5    0  43.9G  0 dm   
│ │ └─g-osd2-0 (dm-6)     252:6    0    11T  0 dm   /data/osd.1
│ └─g-osd2-0-ext4j (dm-7) 252:7    0   256M  0 dm   
└─sdf3                      8:83   0  1007K  0 part 
root@node245:~# 
root@node245:~# 
root@node245:~# mount
/dev/sde2 on / type ext4 (rw,errors=remount-ro)
proc on /proc type proc (rw,noexec,nosuid,nodev)
sysfs on /sys type sysfs (rw,noexec,nosuid,nodev)
none on /sys/fs/cgroup type tmpfs (rw)
none on /sys/fs/fuse/connections type fusectl (rw)
none on /sys/kernel/debug type debugfs (rw)
none on /sys/kernel/security type securityfs (rw)
udev on /dev type devtmpfs (rw,mode=0755)
devpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620)
tmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)
none on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880)
none on /run/shm type tmpfs (rw,nosuid,nodev)
none on /run/user type tmpfs (rw,noexec,nosuid,nodev,size=104857600,mode=0755)
none on /sys/fs/pstore type pstore (rw)
rpc_pipefs on /run/rpc_pipefs type rpc_pipefs (rw)
systemd on /sys/fs/cgroup/systemd type cgroup (rw,noexec,nosuid,nodev,none,name=systemd)
/dev/mapper/g-osd1-0 on /data/osd.0 type ext4 (rw,noatime,nodelalloc,journal_path=/dev/mapper/g-osd1-0-ext4j)
/dev/mapper/g-osd1-0-cache on /data/cache/g-osd1-0 type ext4 (rw,noatime,nodelalloc)
1.1.1.245,1.1.1.244,1.1.1.243:/ on /var/share/ezfs type ceph (wsize=4194304,mount_timeout=15,noshare,mds_namespace=1)
/dev/mapper/g-osd2-0 on /data/osd.1 type ext4 (rw,noatime,nodelalloc,journal_path=/dev/mapper/g-osd2-0-ext4j)
/dev/mapper/g-osd2-0-cache on /data/cache/g-osd2-0 type ext4 (rw,noatime,nodelalloc)
root@node245:~# root@node245:~# umount /dev/mapper/g-osd2-0-cache
ode245:~# dmsetup remove g-osd2-0-ext4j
root@node245:~# dmsetup table
g-osd1-0: 0 31374440415 ext4meta SSD:252:1 HDD:8:33
g-osd1-0-ext4m: 0 122683392 linear 8:2 797714432
g-osd1-0-cache: 0 797714432 linear 8:2 0
g-osd1-0-ext4j: 0 524288 linear 8:2 920397824
root@node245:~# 
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>经过上面的操作，对应dm map关系恢复，mount point也在</p>
</li>
</ul>
<h2 id="step-6-qi-dong-osd">Step6.  启动OSD</h2>
<pre><code class="language-shell">root@node245:~# /etc/init.d/ceph start osd.1
=== osd.1 === 
Starting Ceph osd.1 on 1.1.1.245...
starting osd.1 at :/0 osd_data /data/osd.1 /dev/disk/by-partlabel/g-osd2-0-journal
root@node245:~# 
</code></pre>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>三种方式修改CentOS hostname</title>
    <url>/2020/01/16/modify_hostname_for_centos/</url>
    <content><![CDATA[<h1 id="san-chong-fang-fa-xiu-gai-centos-hostname">三种方法修改Centos hostname</h1>
<p>在CentOS7中，有三种定义的主机名:静态的（static）、瞬态的（transient）、灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符限制规则。而另一方面，“灵活”主机名则允许使用自由形式（包括特殊/空白字符）的主机名，以展示给终端用户。</p>
<p>本文介绍修改Centos7的hostname的几种方法。</p>
<h2 id="fang-fa-1-hostnamectl">方法1: hostnamectl</h2>
<p>通过hostnamectl来修改主机名，hostnamectl吐出来的示例信息如下：</p>
<pre><code class="language-shell">[root@localhost ~]# hostnamectl
   Static hostname: localhost.localdomain
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 39568e567fd24d9d8bacf3010f9b0ac4
           Boot ID: 23efb67f65454f52bbf810e807267c05
    Virtualization: kvm
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-957.el7.x86_64
      Architecture: x86-64
[root@localhost ~]# 
</code></pre>
<p>修改主机名</p>
<pre><code class="language-shell">[root@localhost ~]# hostnamectl set-hostname host76 --static
[root@localhost ~]# 
</code></pre>
<p>查看修改后的效果：</p>
<pre><code class="language-shell">[root@localhost ~]# 
[root@localhost ~]# hostnamectl
   Static hostname: host76
Transient hostname: localhost.localdomain
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 39568e567fd24d9d8bacf3010f9b0ac4
           Boot ID: 23efb67f65454f52bbf810e807267c05
    Virtualization: kvm
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-957.el7.x86_64
      Architecture: x86-64
[root@localhost ~]# hostname
host76
</code></pre>
<h2 id="fang-fa-2-xiu-gai-etc-hostname">方法2: 修改/etc/hostname</h2>
<p>直接修改/etc/hostname文件，将里面的内容删掉，直接替换成自己需要的主机名称：</p>
<pre><code class="language-shell">[root@localhost ~]# vi /etc/hostname
</code></pre>
<pre><code class="language-shell">[root@localhost ~]# cat /etc/hostname 
host76
</code></pre>
<h2 id="fang-fa-3-nmtui">方法3: nmtui</h2>
<p>还可以通过nmtui进入图形界面来修改主机名。将光标通过键盘的上下键移动到“设定系统主机名”菜单处，按下回车键。</p>
<img class="shadow" src="/img/in-post/nmtui.png" width="200">
<p>此时，屏幕出现“设定主机名”选项卡，输入需要设定的主机名，通过键盘方向键将光标移动到“确定”处，回车键确定即可完成主机名的修改。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>获取SSD寿命</title>
    <url>/2020/01/22/get_ssd_life_span/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>SSD虽然不是机械盘，但上面的晶元伴随着数据的擦写，导致晶元厚度越来越薄，当晶元厚度薄到一定程度时，意味着SSD寿命已尽，对于存储产品，更迫切的需要知道当前集群里使用的SSD，其寿命还有多少。</p>
<p>目前lab里常见的SSD，型号有S4610，S3700和NVME的，NVME的是PCI-e类型的，但intelS4600，S4610，S7300之类型号的SSD，有的设备是在RAID卡上，但有的设备上又不在RAID卡上。如何确定这些NVME，在RAID卡和不在RAID卡上的SSD的剩余寿命呢？</p>
<h1 id="nvme-lei-xing-de-ssd-de-shi-yong-shou-ming-huo-qu">NVME类型的SSD的使用寿命获取</h1>
<h2 id="fang-fa-1-jie-zhu-nvmemgr-huo-qu">方法1：借助nvmemgr获取</h2>
<p>NVME有一个driver，这个driver可以监控NVMESSD的状态以及获取实时信息，有兴趣的可以参考nvmemgr driver的help信息：</p>
<pre><code class="language-shell">root@CVM-01:~# nvmemgr 
nvmemgr version: 00.06.202
usage: nvmemgr &lt;command&gt; [&lt;options&gt;] &lt;target&gt; [&lt;args&gt;]

  list                          List all the controllers and namespaces on this machine
  monitor                       Show basic infomations of the controller in real time
  dump                          Dump the controller registers of the NVMe controller
  identify                      Describe the controller/namespace capabilities and status
  getlogpage                    Return a data buffer containing the log page requested
  asynceventreq                 Request controller to report status/error/health information as these events occurs
  getfeature                    Retrieve the attributes of the feature specified
  setfeature                    Specify the attributes of the feature specified
  fwactivate                    Verify a valid f/w image has been downloaded and activate it
  fwdownload                    Download the firmware image for a future update to the controller
  formatnvm                     Low level format a namespace or all namespace on a controller
  reset                         Initiate an NVM subsystem reset
  locate                        locate nvme device
  cpu-cycle                     Get the cpu performance cycle statistics
  io-count                      Get the I/O counter statistics
  ipc-stats                     Get the IPC statistics
  link-stats                    Get the PCIe link statistics
  io-latency                    Get the I/O latency statistics
  backend-stats                 Get the backend statistics
  flash-latency                 Get the flash latency statistics
  sched-statistic               Get the schedule manager statistics
  sched-rderr                   Get the schedule manager read error state
  sched-wrerr                   Get the schedule manager write error state
  flash-msg-history             Get flash message history
  lun-mgr-sts                   Get lun manager status
  phy-bufid-sts                 Get physical buffer ID status
  dump-pageframe                Dump a page frame with physical flash address
  get-pedata                    Get PE data
  read-retry                    Read retry and dump a data frame with physical flash address
  nvme-dump-msglog              Dump each proccessor's message
  pcie-dump-msglog              Dump each proccessor's message via pcie
  parse-raw-msglog              Parse the raw binary firmware message log
  node-map                      Show the node map
  dump-core-mem                 Dump processor core memory
  pcie-dump-dataframe           Dump a data frame with physical flash address via pcie
  pcie-prog-page                Program a page with physical flash address via pcie
  pcie-erase-block              Erase a block with physical flash address via pcie
  pcie-read-ddr                 Read ddr data out via pcie
  pcie-dump-csr                 Dump command status register value
  pcie-pause                    Force the target node enter the pause state in interrupt context
  pcie-resume                   Exit the pause state
  dump-ftl                      Dump ftl table
  nvme-abrupt-shutdown          Simulate abrupt shutdown via nvme
  pcie-abrupt-shutdown          Simulate abrupt shutdown via pcie
  lookup-chunkInfo              Get lookup chunk Info
  read-eeprom                   Read 32 bits value from eeprom with offset at a time
  write-eeprom                  Write 32 bits value to eeprom with offset at a time
  fw-describe                   Display the firmware description more than version-nmuber only.
  oob-fw-download               Download the firmware image to the oob module
  oob-fw-version                Get the version of oob firmware image in mcu
  oob-fw-activate               Activate the oob firmware image in mcu
  oob-vpd-enable                Execute enable/disable/get_status of oob vpd flag
  set-oob-vpd-model-serial      Set oob vpd model number/serial number
  get-oob-vpd-model-serial      Get oob vpd model number/serial number
  oob-nvme-enable               Execute enable/disable/get_status of oob nvme flag
  set-pcie-id                   Set the PCIe device/vendor/sub-system IDs
  get-pcie-id                   Get the PCIe device/vendor/sub-system IDs
  lookup-statistic              Get the lookup manager statistics
  dump-sb                       Dump super block informations
  allfwdownload                 Download both controller and oob firmware
  write-flash                   Recover bricked PBlaze4 card via write new firmware
  force-pcie-mode               Force drive boot into PCIe mode, always used before write-flash
  read-pci-cmd                  Read out pcicmd&amp;sts reg value
  force-set-pci-cmd             Force set Pci Cmd register MSE and BME bit to 1
  force-sb-open                 Force super block open
  clear-sb-open                 Clear super block open
  pcie-get-rsts                 Get recovery status
  micron-force-wp               Force Micron PB4 into write protect mode
  micron-clear-wp               Clear Micron PB4 from write protect mode
  micron-lowlevelformat         Low level format Micron PB4
  micron-clear-errorlogs        Clear event and error logs for Micron PB4
  micron-set-erase-count        Set erase count for Micron PB4
  micron-bgtask-switch          Execute enable/disable bg task for Micron PB4
  micron-create-small-drive     Create small drive for Micron PB4
  micron-read-flash-prog-cnt    Read flash program count for Micron PB4
  micron-mark-block-as-bad      Mark block as bad for Micron PB4
  micron-del-retired-block      Delete retired block for Micron PB4
  micron-get-bad-block-cnt      Get bad block count for Micron PB4
  micron-get-bad-block-info     Get bad block info for Micron PB4
  micron-get-erase-count        Get erase count for Micron PB4
  micron-get-error-log          Get error log for Micron PB4
  micron-physical-to-lba        Calculate physical address to lba for Micron PB4
  micron-lba-to-physical        Calculate lba to physical address for Micron PB4
  micron-get-config-data        Get drive config data for Micron PB4
  micron-get-rbec               Get read bit error count for Micron PB4
  micron-read-fid               Read fid for Micron PB4
  micron-erase-direct           Erase direct for Micron PB4
  micron-vu-lock                Lock vu for Micron PB4
  micron-seq-wr                 Sequencer write for Micron PB4
  micron-seq-rd                 Sequencer read for Micron PB4
  micron-rd-otp                 Read otp for Micron PB4
  micron-get-temp-thro          Get temp throttling for Micron PB4
  micron-set-temp-thro          Set temp throttling for Micron PB4
  micron-read-temp-sensors      Read all temp sensors for Micron PB4
  micron-vu-unlock              Unlock vu for Micron PB4
  help                          Display all the standard and Memblaze specific NVMe commands

More details about a specific command, see 'nvmemgr command [--help | -h]'
root@CVM-01:~# 
</code></pre>
<p>言归正传，如何通过nvmemgr这个工具获取NVME SSD的寿命呢？</p>
<h2 id="step-1-huo-qu-nvme-de-controller-name">Step1. 获取NVME的controller name</h2>
<pre><code class="language-shell">root@CVM-01:~# nvmemgr list | grep controller
controller nvme0 (namespace nvme0n1):
controller  (namespace nvme0n1p1):
controller  (namespace nvme0n1p10):
controller  (namespace nvme0n1p11):
controller  (namespace nvme0n1p12):
controller  (namespace nvme0n1p13):
controller  (namespace nvme0n1p14):
controller  (namespace nvme0n1p15):
controller  (namespace nvme0n1p16):
controller  (namespace nvme0n1p17):
controller  (namespace nvme0n1p18):
controller  (namespace nvme0n1p19):
controller  (namespace nvme0n1p2):
controller  (namespace nvme0n1p20):
controller  (namespace nvme0n1p21):
controller  (namespace nvme0n1p22):
controller  (namespace nvme0n1p23):
controller  (namespace nvme0n1p24):
controller  (namespace nvme0n1p25):
controller  (namespace nvme0n1p3):
controller  (namespace nvme0n1p4):
controller  (namespace nvme0n1p5):
controller  (namespace nvme0n1p6):
controller  (namespace nvme0n1p7):
controller  (namespace nvme0n1p8):
controller  (namespace nvme0n1p9):
</code></pre>
<p>这里，显示当前系统里，NVME controller name是 <code>nvme0 </code></p>
<h2 id="step-2-shi-yong-nvmemgr-monitor-huo-qu-dui-ying-controller-xin-xi">Step2. 使用nvmemgr monitor获取对应controller信息</h2>
<pre><code class="language-shell">root@CVM-01:~# nvmemgr monitor -i 1000 -p --ctrl nvme0
Manufacture Name:              Memblaze Technology Co.,Ltd
Product Name:                  PBlaze4
Model Number:                  INTEL SSDPEDMD800G4                     8DV10131
Serial Number:                 CVFT521000FK800CGN  INTEL SSDPEDMD800G4                     8DV10131
Available Capacity:            800.16GB
Percentage of Spare Space      100%
Threshold of Spare Space       10%
Percentage of Device Life Used 4%
Total Read                     1.50TB
Total Write:                   620.36GB
Name:                          /dev/nvme0
Firmware:                      8DV10131
Power Cycles:                  109
Power-on Hours:                18485
Device Temperature:            -273C          -273C      -273C     
Power:                         0W             0W         0W        
Status:                        Safe          
Current Read IOPS:             0.00K
Current Write IOPS:            0.00K
Current Read Bandwidth:        0.00MB/s
Current Write Bandwidth:       0.00MB/s

Manufacture Name:              Memblaze Technology Co.,Ltd
Product Name:                  PBlaze4
Model Number:                  INTEL SSDPEDMD800G4                     8DV10131
Serial Number:                 CVFT521000FK800CGN  INTEL SSDPEDMD800G4                     8DV10131
Available Capacity:            800.16GB
Percentage of Spare Space      100%
Threshold of Spare Space       10%
Percentage of Device Life Used 4%
Total Read                     1.50TB
Total Write:                   620.36GB
Name:                          /dev/nvme0
Firmware:                      8DV10131
Power Cycles:                  109
Power-on Hours:                18485
Device Temperature:            -273C          -273C      -273C     
Power:                         0W             0W         0W        
Status:                        Safe          
Current Read IOPS:             0.00K
Current Write IOPS:            0.02K
Current Read Bandwidth:        0.00MB/s
Current Write Bandwidth:       0.07MB/s
</code></pre>
<p>上面吐出信息，有一行<code>Percentage of Device Life Used 4% </code>,这里意味着，这块SSD，目前已经使用了4%的寿命，还有96%的可用寿命。</p>
<h2 id="fang-fa-2-tong-guo-nvme-smart-xin-xi-huo-qu">方法2：通过NVME smart信息获取</h2>
<p>直接上代码</p>
<pre><code class="language-shell">root@CVM-01:~# cat get_nvme_ssd_life_time.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

"""  Get NVME SSD lift left  """

from __future__ import unicode_literals

import os
import ctypes
import ctypes.util


class NVMEPassthruCommand(ctypes.Structure):
    _fields_ = [
        ('opcode', ctypes.c_ubyte),
        ('flags', ctypes.c_ubyte),
        ('rsvd1', ctypes.c_uint16),
        ('nsid', ctypes.c_uint32),
        ('cdw2', ctypes.c_uint32),
        ('cdw3', ctypes.c_uint32),
        ('metadata', ctypes.c_uint64),
        ('addr', ctypes.c_uint64),
        ('metadata_len', ctypes.c_uint32),
        ('data_len', ctypes.c_uint32),
        ('cdw10', ctypes.c_uint32),
        ('cdw11', ctypes.c_uint32),
        ('cdw12', ctypes.c_uint32),
        ('cdw13', ctypes.c_uint32),
        ('cdw14', ctypes.c_uint32),
        ('cdw15', ctypes.c_uint32),
        ('timeout_ms', ctypes.c_uint32),
        ('result', ctypes.c_uint32)
    ]


class NVMESmartLog(ctypes.Structure):
    _fields_ = [
        ('critical_warning', ctypes.c_ubyte),
        ('temperature', ctypes.c_ubyte * 2),
        ('avail_spare', ctypes.c_ubyte),
        ('spare_thresh', ctypes.c_ubyte),
        ('percent_used', ctypes.c_ubyte),
        ('rsvd6', ctypes.c_ubyte * 26),
        ('data_units_read', ctypes.c_ubyte * 16),
        ('data_units_written', ctypes.c_ubyte * 16),
        ('host_reads', ctypes.c_ubyte * 16),
        ('host_writes', ctypes.c_ubyte * 16),
        ('ctrl_busy_time', ctypes.c_ubyte * 16),
        ('power_cycles', ctypes.c_ubyte * 16),
        ('power_on_hours', ctypes.c_ubyte * 16),
        ('unsafe_shutdowns', ctypes.c_ubyte * 16),
        ('media_errors', ctypes.c_ubyte * 16),
        ('num_err_log_entries', ctypes.c_ubyte * 16),
        ('warning_temp_time', ctypes.c_uint32),
        ('critical_comp_time', ctypes.c_uint32),
        ('temp_sensor', ctypes.c_uint16 * 8),
        ('thm_temp1_trans_count', ctypes.c_uint32),
        ('thm_temp2_trans_count', ctypes.c_uint32),
        ('thm_temp1_total_time', ctypes.c_uint32),
        ('thm_temp2_total_time', ctypes.c_uint32),
        ('rsvd232', ctypes.c_ubyte * 280)
    ]


class IoctlGeneric(object):
    _IOC_NRBITS = 8
    _IOC_TYPEBITS = 8
    _IOC_SIZEBITS = 14
    _IOC_DIRBITS = 2
    _IOC_NONE = 0
    _IOC_WRITE = 1
    _IOC_READ = 2

    @classmethod
    def ioc(cls, direction, request_type, request_nr, size):
        _IOC_NRSHIFT = 0
        _IOC_TYPESHIFT = _IOC_NRSHIFT + cls._IOC_NRBITS
        _IOC_SIZESHIFT = _IOC_TYPESHIFT + cls._IOC_TYPEBITS
        _IOC_DIRSHIFT = _IOC_SIZESHIFT + cls._IOC_SIZEBITS
        return (
            (direction &lt;&lt; _IOC_DIRSHIFT) |
            (request_type &lt;&lt; _IOC_TYPESHIFT) |
            (request_nr &lt;&lt; _IOC_NRSHIFT) |
            (size &lt;&lt; _IOC_SIZESHIFT)
        )

NVME_ADMIN_IDENTIFY = 0x06
NVME_LOG_SMART = 0x02
NVME_ADMIN_GET_LOG_PAGE = 0x02
NSID = 0xffffffff
_ioctl_fn = None

def _get_ioctl_fn():
    global _ioctl_fn
    if _ioctl_fn is not None:
        return _ioctl_fn
    libc_name = ctypes.util.find_library('c')
    if not libc_name:
        raise Exception('Unable to find c library')
    libc = ctypes.CDLL(libc_name, use_errno=True)
    _ioctl_fn = libc.ioctl
    return _ioctl_fn


def ioctl(fd, request, *args):
    ioctl_args = [ctypes.c_int(fd), ctypes.c_ulong(request)] + list(args)

    try:
        ioctl_fn = _get_ioctl_fn()
    except Exception as e:
        raise NotImplementedError(
            'Unable to get ioctl()-function from C library: {err}'.format(err=str(e)))

    res = ioctl_fn(*ioctl_args)
    if res &lt; 0:
        err = ctypes.get_errno()
        raise OSError(err, os.strerror(err))
    return res

def IOWR(request_type, request_nr, size):
    calc = IoctlGeneric()
    return calc.ioc(calc._IOC_READ | calc._IOC_WRITE, ord(request_type), request_nr, size)

def nvme_submit_admin_passthru(fd, cmd):
    NVME_IOCTL_ADMIN_CMD = IOWR('N', 0x41, ctypes.sizeof(cmd))
    return ioctl(fd, NVME_IOCTL_ADMIN_CMD, ctypes.byref(cmd))

def get_smart_log(dev_name):
    try:
        fd = os.open(dev_name, os.O_RDONLY)
        smart_log = NVMESmartLog()
        ret = nvme_get_log(fd, NSID, NVME_LOG_SMART, smart_log)
    except Exception as ex:
        raise RuntimeError("can not get device smart log : (%s)", str(ex))
    finally:
        os.close(fd)
    return smart_log

def nvme_get_log(fd, nsid, log_id, data):
    admin_cmd = NVMEPassthruCommand()
    admin_cmd.opcode = NVME_ADMIN_GET_LOG_PAGE
    admin_cmd.nsid = nsid
    admin_cmd.addr = ctypes.addressof(data)
    data_len = ctypes.sizeof(data)
    admin_cmd.data_len = data_len
    numd = (data_len &gt;&gt; 2) - 1
    numdu = numd &gt;&gt; 16
    numdl = numd &amp; 0xffff
    admin_cmd.cdw10 = log_id | (numdl &lt;&lt; 16)
    admin_cmd.cdw11 = numdu
    return nvme_submit_admin_passthru(fd, admin_cmd)

if __name__ == '__main__':
    dev_name= '/dev/nvme0n1'
    smart_log = get_smart_log(dev_name)
    print smart_log.percent_used
</code></pre>
<p>执行效果：</p>
<pre><code class="language-shell">root@CVM-01:~# python get_nvme_ssd_life_time.py 
4
root@CVM-01:~# 
</code></pre>
<p>结果返回是4，说明只使用了4%的寿命，还剩余96%的寿命，这里计算出来的，和通过nvmemgr monitor获取到的，完全一致~</p>
<h1 id="fei-nvme-ssd-shou-ming-huo-qu">非NVME SSD寿命获取</h1>
<h2 id="ru-he-qu-fen-ssd-shi-bu-shi-zai-raid-qia-shang-ni">如何区分SSD是不是在RAID卡上呢？</h2>
<h3 id="ssd-bu-zai-raid-qia-shang">SSD 不在RAID卡上</h3>
<pre><code class="language-shell">root@node243:~# lsscsi
[0:0:9:0]    enclosu GOOXIBM  2U12SXP 24Sx12G  B013  -        
[0:0:13:0]   disk    ATA      INTEL SSDSC2KG48 0100  /dev/sdk 
[0:0:23:0]   disk    ATA      INTEL SSDSC2KG48 0121  /dev/sdl 
[0:2:0:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdd 
[0:2:1:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sda 
[0:2:2:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdb 
[0:2:3:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdc 
[0:2:4:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sde 
[0:2:5:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdf 
[0:2:6:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdg 
[0:2:7:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdh 
[0:2:8:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdi 
[0:2:9:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdj
</code></pre>
<h3 id="ssd-zai-raid-qia-shang">SSD 在RAID卡上</h3>
<pre><code class="language-shell">root@node243:~# lsblk -d -o name,rota
NAME ROTA
sda     1
sdb     1
sdc     1
sdd     1
sde     1
sdf     1
sdg     1
sdh     1
sdi     1
sdj     1
sdk     1
sdl     1
root@node243:~# lsscsi 
[0:0:9:0]    enclosu GOOXIBM  2U12SXP 24Sx12G  B013  -        
[0:2:0:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdd 
[0:2:1:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sda 
[0:2:2:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdb 
[0:2:3:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdc 
[0:2:4:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sde 
[0:2:5:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdf 
[0:2:6:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdg 
[0:2:7:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdh 
[0:2:8:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdi 
[0:2:9:0]    disk    AVAGO    MR9361-8i        4.68  /dev/sdj 
[0:2:10:0]   disk    AVAGO    MR9361-8i        4.68  /dev/sdk 
[0:2:11:0]   disk    AVAGO    MR9361-8i        4.68  /dev/sdl 
root@node243:~# 
</code></pre>
<p>对比了一下 <code>lsscsi </code>吐出的信息，发现在RAID卡上的SSD，都会含有RAID卡的型号，而且没法直接看出是否是SSD，自然也没法分辨出SSD分区信息。</p>
<p>本文RAID卡型号是LSI的，显示是AVAGO，截取了片段信息，如下:</p>
<pre><code class="language-shell">root@CVM-01:~# /opt/MegaRAID/MegaCli/MegaCli64 adpallinfo -a0
                                     
Adapter #0

==============================================================================
                    Versions
                ================
Product Name    : AVAGO 3108 MegaRAID
Serial No       : 
FW Package Build: 24.15.0-0018
</code></pre>
<h2 id="ssd-bu-zai-raid-qia-shang-ssd-shou-ming-de-huo-qu">SSD不在RAID卡上，SSD寿命的获取</h2>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>通过<code>lsblk</code>或者<code>lsscsi</code>命令，都可以获取SSD分区信息</p>
</li>
<li class="lvl-2">
<p>如果SSD在RAID卡上，但是设置成JBOD模式，依然可以通过本章节方法获取SSD寿命</p>
</li>
</ul>
<h3 id="step-1-xian-huo-qu-dao-ssd-fen-qu-xin-xi">Step1. 先获取到SSD分区信息</h3>
<pre><code class="language-shell">root@node-196:~# lsblk -d -o name,rota
NAME ROTA
rbd0    0
sdd     0
sdb     1
sde     0
sdc     1
sda     1
root@node-196:~# lsscsi 
[0:0:8:0]    enclosu AIC CORP SAS 6G Expander  0b01  -        
[0:2:0:0]    disk    LSI      MR9271-8i        3.24  /dev/sda 
[0:2:1:0]    disk    LSI      MR9271-8i        3.24  /dev/sdb 
[0:2:2:0]    disk    LSI      MR9271-8i        3.24  /dev/sdc 
[1:0:0:0]    disk    ATA      INTEL SSDSC2BA40 0270  /dev/sdd 
[2:0:0:0]    disk    ATA      INTEL SSDSC2BA40 0270  /dev/sde 
root@node-196:~# 
</code></pre>
<p>如上，可以看出，SSD对应分区是/dev/sdd 和 /dev/sde，对于rbd0，是存储export出来的device，这里忽略它。</p>
<h3 id="step-2-cha-kan-smart-xin-xi">Step2. 查看smart信息</h3>
<pre><code class="language-shell">root@node-196:~# smartctl -a /dev/sdd
smartctl 7.0 2018-12-30 r4883 [x86_64-linux-4.14.148-server] (local build)
Copyright (C) 2002-18, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF INFORMATION SECTION ===
Model Family:     Intel 730 and DC S35x0/3610/3700 Series SSDs
Device Model:     INTEL SSDSC2BA400G3
Serial Number:    BTTV449301BQ400HGN
LU WWN Device Id: 5 5cd2e4 04b73452c
Firmware Version: 5DV10270
User Capacity:    400,088,457,216 bytes [400 GB]
Sector Sizes:     512 bytes logical, 4096 bytes physical
Rotation Rate:    Solid State Device
Form Factor:      2.5 inches
Device is:        In smartctl database [for details use: -P show]
ATA Version is:   ACS-2 T13/2015-D revision 3
SATA Version is:  SATA 2.6, 6.0 Gb/s (current: 6.0 Gb/s)
Local Time is:    Thu Jan 23 10:10:27 2020 CST
SMART support is: Available - device has SMART capability.
SMART support is: Enabled

=== START OF READ SMART DATA SECTION ===
SMART overall-health self-assessment test result: PASSED

General SMART Values:
Offline data collection status:  (0x02)	Offline data collection activity
					was completed without error.
					Auto Offline Data Collection: Disabled.
Self-test execution status:      (   0)	The previous self-test routine completed
					without error or no self-test has ever 
					been run.
Total time to complete Offline 
data collection: 		(    2) seconds.
Offline data collection
capabilities: 			 (0x79) SMART execute Offline immediate.
					No Auto Offline data collection support.
					Suspend Offline collection upon new
					command.
					Offline surface scan supported.
					Self-test supported.
					Conveyance Self-test supported.
					Selective Self-test supported.
SMART capabilities:            (0x0003)	Saves SMART data before entering
					power-saving mode.
					Supports SMART auto save timer.
Error logging capability:        (0x01)	Error logging supported.
					General Purpose Logging supported.
Short self-test routine 
recommended polling time: 	 (   1) minutes.
Extended self-test routine
recommended polling time: 	 (   2) minutes.
Conveyance self-test routine
recommended polling time: 	 (   2) minutes.
SCT capabilities: 	       (0x003d)	SCT Status supported.
					SCT Error Recovery Control supported.
					SCT Feature Control supported.
					SCT Data Table supported.

SMART Attributes Data Structure revision number: 1
Vendor Specific SMART Attributes with Thresholds:
ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE
  5 Reallocated_Sector_Ct   0x0032   100   100   000    Old_age   Always       -       0
  9 Power_On_Hours          0x0032   100   100   000    Old_age   Always       -       37769
 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       324
170 Available_Reservd_Space 0x0033   100   100   010    Pre-fail  Always       -       0
171 Program_Fail_Count      0x0032   100   100   000    Old_age   Always       -       0
172 Erase_Fail_Count        0x0032   100   100   000    Old_age   Always       -       0
174 Unsafe_Shutdown_Count   0x0032   100   100   000    Old_age   Always       -       271
175 Power_Loss_Cap_Test     0x0033   100   100   010    Pre-fail  Always       -       614 (179 4205)
183 SATA_Downshift_Count    0x0032   100   100   000    Old_age   Always       -       0
184 End-to-End_Error        0x0033   100   100   090    Pre-fail  Always       -       0
187 Reported_Uncorrect      0x0032   100   100   000    Old_age   Always       -       0
190 Temperature_Case        0x0022   077   074   000    Old_age   Always       -       23 (Min/Max 18/26)
192 Unsafe_Shutdown_Count   0x0032   100   100   000    Old_age   Always       -       271
194 Temperature_Internal    0x0022   100   100   000    Old_age   Always       -       34
197 Current_Pending_Sector  0x0032   100   100   000    Old_age   Always       -       0
199 CRC_Error_Count         0x003e   100   100   000    Old_age   Always       -       0
225 Host_Writes_32MiB       0x0032   100   100   000    Old_age   Always       -       20629803
226 Workld_Media_Wear_Indic 0x0032   100   100   000    Old_age   Always       -       5468
227 Workld_Host_Reads_Perc  0x0032   100   100   000    Old_age   Always       -       13
228 Workload_Minutes        0x0032   100   100   000    Old_age   Always       -       2263937
232 Available_Reservd_Space 0x0033   100   100   010    Pre-fail  Always       -       0
233 Media_Wearout_Indicator 0x0032   095   095   000    Old_age   Always       -       0
234 Thermal_Throttle        0x0032   100   100   000    Old_age   Always       -       0/0
241 Host_Writes_32MiB       0x0032   100   100   000    Old_age   Always       -       20629803
242 Host_Reads_32MiB        0x0032   100   100   000    Old_age   Always       -       3310760

SMART Error Log Version: 1
No Errors Logged

SMART Self-test log structure revision number 1
Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error
# 1  Short offline       Completed without error       00%     27499         -

SMART Selective self-test log data structure revision number 1
 SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS
    1        0        0  Not_testing
    2        0        0  Not_testing
    3        0        0  Not_testing
    4        0        0  Not_testing
    5        0        0  Not_testing
Selective self-test flags (0x0):
  After scanning selected spans, do NOT read-scan remainder of disk.
If Selective self-test is pending on power-up, resume after 0 minute delay.

root@node-196:~#
</code></pre>
<p>上面吐出的信息，有一行<code>Media_Wearout_Indicator</code>，这行有一列<code>WORST</code>，它对应的值，就是当前SSD寿命剩余百分比值，比如这里的95%，表示此块SSD还有95%的使用寿命。</p>
<h2 id="ssd-zai-raid-qia-shang-ssd-shou-ming-de-huo-qu">SSD在RAID卡上，SSD寿命的获取</h2>
<h3 id="step-1-huo-qu-ssd-fen-qu-ming-cheng">Step1. 获取SSD分区名称</h3>
<p>尝试使用lsblk去获取</p>
<pre><code class="language-shell">root@node243:~# lsblk -d -o name,rota
NAME ROTA
sda     1
sdb     1
sdc     1
sdd     1
sde     1
sdf     1
sdg     1
sdh     1
sdi     1
sdj     1
sdk     1
sdl     1
root@node243:~# 
</code></pre>
<p>发现吐出的结果全部是1，很显然，当SSD在RAID卡上，且加入RAID组后，lsblk无法获取出哪个分区是SSD了。。。怎么破？</p>
<p>换个思路，使用megacli命令试试：</p>
<pre><code class="language-shell">root@node243:~# /opt/MegaRAID/MegaCli/MegaCli64 ldpdinfo aall | grep -Ei 'Device Id:|Inquiry Data:|Raw Size:'
Enclosure Device ID: 9
Device Id: 24
Raw Size: 279.396 GB [0x22ecb25c Sectors]
Inquiry Data: SEAGATE ST300MM0048     N001W0K156RV            
Enclosure Device ID: 9
Device Id: 12
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: K3H25KAL            HGST HUS726040ALE610                    APGNTD05
Enclosure Device ID: 9
Device Id: 14
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G6BUJN            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 17
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G6GRHN            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 15
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G6DTSN            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 16
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G6GREN            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 19
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G6GL3N            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 20
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G4B65N            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 18
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G6B6NN            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 21
Raw Size: 3.638 TB [0x1d1c0beb0 Sectors]
Inquiry Data: V6G6GYJN            HGST HUS726T4TALE6L4                    VKGNW40H
Enclosure Device ID: 9
Device Id: 23
Raw Size: 447.130 GB [0x37e436b0 Sectors]
Inquiry Data: BTYM7406012Z480BGN  INTEL SSDSC2KG480G7                     SCV10121
Enclosure Device ID: 9
Device Id: 13
Raw Size: 447.130 GB [0x37e436b0 Sectors]
Inquiry Data: BTYM72940D40480BGN  INTEL SSDSC2KG480G7                     SCV10100
root@node243:~# 
</code></pre>
<p>这里有一列信息<code>Inquiry Data</code>，表示每个Device的序列号，里面有品牌信息，其中，<code>INTEL SSDSC2KG480G7</code>表示这块盘，是INTEL SSD，容量480G，至此，可以知道，<code>Device Id: 13</code>（这很重要）这块盘，是SSD，对应分区是/dev/sdl（至于如何确认RAID卡上RAID组对应哪个系统分区（盘符）信息，参考我的其他推文）</p>
<h3 id="step-2-smartctl-huo-qu-smart-xin-xi">Step2. smartctl获取smart信息</h3>
<pre><code class="language-shell">root@node243:~# smartctl -a -d megaraid,23 /dev/sdl
smartctl 6.6 2016-05-31 r4324 [x86_64-linux-4.1.49-server] (local build)
Copyright (C) 2002-16, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF INFORMATION SECTION ===
Device Model:     INTEL SSDSC2KG480G7
Serial Number:    BTYM7406012Z480BGN
LU WWN Device Id: 5 5cd2e4 14ec10087
Firmware Version: SCV10121
User Capacity:    480,103,981,056 bytes [480 GB]
Sector Sizes:     512 bytes logical, 4096 bytes physical
Rotation Rate:    Solid State Device
Form Factor:      2.5 inches
Device is:        Not in smartctl database [for details use: -P showall]
ATA Version is:   ACS-3 T13/2161-D revision 5
SATA Version is:  SATA 3.2, 6.0 Gb/s (current: 6.0 Gb/s)
Local Time is:    Thu Jan 23 11:20:45 2020 CST
SMART support is: Available - device has SMART capability.
SMART support is: Enabled

=== START OF READ SMART DATA SECTION ===
SMART Status not supported: ATA return descriptor not supported by controller firmware
SMART overall-health self-assessment test result: PASSED
Warning: This result is based on an Attribute check.

General SMART Values:
Offline data collection status:  (0x00)	Offline data collection activity
					was never started.
					Auto Offline Data Collection: Disabled.
Self-test execution status:      (   0)	The previous self-test routine completed
					without error or no self-test has ever 
					been run.
Total time to complete Offline 
data collection: 		(    0) seconds.
Offline data collection
capabilities: 			 (0x79) SMART execute Offline immediate.
					No Auto Offline data collection support.
					Suspend Offline collection upon new
					command.
					Offline surface scan supported.
					Self-test supported.
					Conveyance Self-test supported.
					Selective Self-test supported.
SMART capabilities:            (0x0003)	Saves SMART data before entering
					power-saving mode.
					Supports SMART auto save timer.
Error logging capability:        (0x01)	Error logging supported.
					General Purpose Logging supported.
Short self-test routine 
recommended polling time: 	 (   1) minutes.
Extended self-test routine
recommended polling time: 	 (   2) minutes.
Conveyance self-test routine
recommended polling time: 	 (   2) minutes.
SCT capabilities: 	       (0x003d)	SCT Status supported.
					SCT Error Recovery Control supported.
					SCT Feature Control supported.
					SCT Data Table supported.

SMART Attributes Data Structure revision number: 1
Vendor Specific SMART Attributes with Thresholds:
ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE
  5 Reallocated_Sector_Ct   0x0032   099   099   000    Old_age   Always       -       4
  9 Power_On_Hours          0x0032   100   100   000    Old_age   Always       -       6198
 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       85
170 Unknown_Attribute       0x0033   099   099   010    Pre-fail  Always       -       0
171 Unknown_Attribute       0x0032   100   100   000    Old_age   Always       -       1
172 Unknown_Attribute       0x0032   100   100   000    Old_age   Always       -       0
174 Unknown_Attribute       0x0032   100   100   000    Old_age   Always       -       58
175 Program_Fail_Count_Chip 0x0033   100   100   010    Pre-fail  Always       -       477858433335
183 Runtime_Bad_Block       0x0032   100   100   000    Old_age   Always       -       0
184 End-to-End_Error        0x0033   100   100   090    Pre-fail  Always       -       0
187 Reported_Uncorrect      0x0032   100   100   000    Old_age   Always       -       0
190 Airflow_Temperature_Cel 0x0022   076   068   000    Old_age   Always       -       24 (Min/Max 17/33)
192 Power-Off_Retract_Count 0x0032   100   100   000    Old_age   Always       -       58
194 Temperature_Celsius     0x0022   100   100   000    Old_age   Always       -       24
197 Current_Pending_Sector  0x0012   100   100   000    Old_age   Always       -       0
199 UDMA_CRC_Error_Count    0x003e   100   100   000    Old_age   Always       -       0
225 Unknown_SSD_Attribute   0x0032   100   100   000    Old_age   Always       -       1298207
226 Unknown_SSD_Attribute   0x0032   100   100   000    Old_age   Always       -       1392
227 Unknown_SSD_Attribute   0x0032   100   100   000    Old_age   Always       -       17
228 Power-off_Retract_Count 0x0032   100   100   000    Old_age   Always       -       371377
232 Available_Reservd_Space 0x0033   099   099   010    Pre-fail  Always       -       0
233 Media_Wearout_Indicator 0x0032   099   099   000    Old_age   Always       -       0
234 Unknown_Attribute       0x0032   100   100   000    Old_age   Always       -       0
241 Total_LBAs_Written      0x0032   100   100   000    Old_age   Always       -       1298207
242 Total_LBAs_Read         0x0032   100   100   000    Old_age   Always       -       279079
243 Unknown_Attribute       0x0032   100   100   000    Old_age   Always       -       1893917

SMART Error Log Version: 1
No Errors Logged

SMART Self-test log structure revision number 1
No self-tests have been logged.  [To run self-tests, use: smartctl -t]

SMART Selective self-test log data structure revision number 1
 SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS
    1        0        0  Not_testing
    2        0        0  Not_testing
    3        0        0  Not_testing
    4        0        0  Not_testing
    5        0        0  Not_testing
Selective self-test flags (0x0):
  After scanning selected spans, do NOT read-scan remainder of disk.
If Selective self-test is pending on power-up, resume after 0 minute delay.

root@node243:~# 
</code></pre>
<p>这是一个完整的SSD 分区的smart信息，信息有些多，过滤一下，只获取我们关心的几个值就好：</p>
<pre><code class="language-shell">root@node243:~# smartctl -a -d megaraid,23 /dev/sdl | grep -Ei 'Device Model|Serial Number|User Capacity|Media_Wearout_Indicator'
Device Model:     INTEL SSDSC2KG480G7
Serial Number:    BTYM7406012Z480BGN
User Capacity:    480,103,981,056 bytes [480 GB]
233 Media_Wearout_Indicator 0x0032   099   099   000    Old_age   Always       -       0
root@node243:~# 
</code></pre>
<p>从smart吐出的信息可以看出，这块SSD的使用寿命还有99%(对应smart信息的WORST那一列的值)</p>
<p>那如果不带device id，能直接通过smartctl获取SSD寿命信息么？</p>
<pre><code class="language-shell">root@node243:~# smartctl -a /dev/sdl
smartctl 6.6 2016-05-31 r4324 [x86_64-linux-4.1.49-server] (local build)
Copyright (C) 2002-16, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF INFORMATION SECTION ===
Vendor:               AVAGO
Product:              MR9361-8i
Revision:             4.68
User Capacity:        479,559,942,144 bytes [479 GB]
Logical block size:   512 bytes
Logical Unit id:      0x600605b00d75873025bc3ae7a8d1ad1b
Serial number:        001badd1a8e73abc253087750db00506
Device type:          disk
Local Time is:        Thu Jan 23 11:22:10 2020 CST
SMART support is:     Unavailable - device lacks SMART capability.

=== START OF READ SMART DATA SECTION ===
Current Drive Temperature:     0 C
Drive Trip Temperature:        0 C

Error Counter logging not supported

Device does not support Self Test logging
root@node243:~# 
</code></pre>
<p>从吐出信息来看，是没有的~~</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>由于lab里只有intel的SSD，这个SSD使用寿命对应smart项是233（Media_Wearout_Indicator），但并不是所有类型的SSD的都是233，参考如下：</p>
</li>
</ul>
<pre><code class="language-shell">SSD_INDICATOR = {
    'INTEL': '233',
    'INDILINX': '209',
    'MICRON': '202',
    'SAMSUNG': '177',
    'SANDFORCE': '231'
}
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>利用modinfo查看kernel使用的driver版本</title>
    <url>/2020/01/22/user_modinfo_get_driver_version_used_by_kernel/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>Linux modinfo命令用于显示kernel模块的信息，确切讲，会显示kernel模块的对象文件，以及显示该模块的相关信息。</p>
<h1 id="yu-fa">语法</h1>
<pre><code class="language-shell">root@node243:~# modinfo -h
Usage:
	modinfo [options] filename [args]
Options:
	-a, --author                Print only 'author'
	-d, --description           Print only 'description'
	-l, --license               Print only 'license'
	-p, --parameters            Print only 'parm'
	-n, --filename              Print only 'filename'
	-0, --null                  Use \0 instead of \n
	-F, --field=FIELD           Print only provided FIELD
	-k, --set-version=VERSION   Use VERSION instead of `uname -r`
	-b, --basedir=DIR           Use DIR as filesystem root for /lib/modules
	-V, --version               Show version
	-h, --help                  Show this help
root@node243:~# 

</code></pre>
<h1 id="shi-jian">实践</h1>
<p>今天碰到需要给技嘉设备（型号：S451-3R0）更新系统里的QLogic driver，技嘉工程师提供的文件名称为server_driver_qlogic_lan_8.18.16.0.zip，从这里可以看出版本是8.18.16.0，问题来了，我要如何知道，当前系统里QLogic版本是多少？如果版本比技嘉工程师提供的高，自然就不需要更新这个驱动；如果比这个低，那就需要了。</p>
<h2 id="cha-kan-xi-tong-li-q-logic-driver-zai-nei-he-zhong-jia-zai-de-mo-kuai-ming-cheng">查看系统里QLogic driver在内核中加载的模块名称</h2>
<p>使用的<code>lspci -vvv</code>命令，下面只截取片段信息:</p>
<pre><code class="language-shell">3f:00.0 Ethernet controller: QLogic Corp. Device 8070 (rev 02)
        Subsystem: Gigabyte Technology Co., Ltd Device 1000
        Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR+ FastB2B- DisINTx+
        Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &gt;TAbort- &lt;TAbort- &lt;MAbort- &gt;SERR- &lt;PERR- INTx-
        Latency: 0, Cache Line Size: 32 bytes
        Interrupt: pin A routed to IRQ 411
        Region 0: Memory at b7d20000 (64-bit, prefetchable) [size=128K]
        Region 2: Memory at b7c00000 (64-bit, prefetchable) [size=1M]
        Region 4: Memory at b7d50000 (64-bit, prefetchable) [size=64K]
        Expansion ROM at b8680000 [disabled] [size=512K]
        Capabilities: [40] Power Management version 3
                Flags: PMEClk- DSI- D1- D2- AuxCurrent=375mA PME(D0+,D1-,D2-,D3hot+,D3cold+)
                Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME-
        Capabilities: [50] MSI: Enable- Count=1/8 Maskable+ 64bit+
                Address: 0000000000000000  Data: 0000
                Masking: 00000000  Pending: 00000000
        Capabilities: [70] Express (v2) Endpoint, MSI 00
                DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s unlimited, L1 unlimited
                        ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset+
                DevCtl: Report errors: Correctable- Non-Fatal- Fatal- Unsupported-
                        RlxdOrd- ExtTag+ PhantFunc- AuxPwr- NoSnoop+ FLReset-
                        MaxPayload 256 bytes, MaxReadReq 512 bytes
                DevSta: CorrErr+ UncorrErr- FatalErr- UnsuppReq+ AuxPwr+ TransPend-
                LnkCap: Port #0, Speed 8GT/s, Width x8, ASPM not supported, Exit Latency L0s unlimited, L1 &lt;8us
                        ClockPM+ Surprise- LLActRep- BwNot-
                LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+
                        ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt-
                LnkSta: Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-
                DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR+, OBFF Via message/WAKE#
                DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled
                LnkCtl2: Target Link Speed: 8GT/s, EnterCompliance- SpeedDis-
                         Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS-
                         Compliance De-emphasis: -6dB
                LnkSta2: Current De-emphasis Level: -3.5dB, EqualizationComplete+, EqualizationPhase1+
                         EqualizationPhase2+, EqualizationPhase3+, LinkEqualizationRequest-
        Capabilities: [b0] MSI-X: Enable+ Count=129 Masked-
                Vector table: BAR=4 offset=00000000
                PBA: BAR=4 offset=00001000
        Capabilities: [d0] Vital Product Data
                Product Name: QLogic FastLinQ QL41212H 25GbE Adapter
                Read-only fields:
                        [PN] Part number: AH2010406-01 02
                        [SN] Serial number: AFE1702F15357
                        [V0] Vendor specific: FFV8.18.01
                        [RV] Reserved: checksum good, 4 byte(s) reserved
                End
        Capabilities: [100 v2] Advanced Error Reporting
                UESta:  DLP- SDES- TLP- FCP- CmpltTO- CmpltAbrt- UnxCmplt- RxOF- MalfTLP- ECRC- UnsupReq- ACSViol-
                UEMsk:  DLP- SDES- TLP- FCP- CmpltTO- CmpltAbrt- UnxCmplt- RxOF- MalfTLP- ECRC- UnsupReq- ACSViol-
                UESvrt: DLP+ SDES+ TLP- FCP+ CmpltTO- CmpltAbrt- UnxCmplt- RxOF+ MalfTLP+ ECRC- UnsupReq- ACSViol-
                CESta:  RxErr- BadTLP- BadDLLP- Rollover- Timeout- NonFatalErr+
                CEMsk:  RxErr- BadTLP- BadDLLP- Rollover- Timeout- NonFatalErr+
                                AERCap: First Error Pointer: 00, GenCap+ CGenEn- ChkCap+ ChkEn-
        Capabilities: [148 v1] Virtual Channel
                Caps:   LPEVC=0 RefClk=100ns PATEntryBits=1
                Arb:    Fixed- WRR32- WRR64- WRR128-
                Ctrl:   ArbSelect=Fixed
                Status: InProgress-
                VC0:    Caps:   PATOffset=00 MaxTimeSlots=1 RejSnoopTrans-
                        Arb:    Fixed- WRR32- WRR64- WRR128- TWRR128- WRR256-
                        Ctrl:   Enable+ ID=0 ArbSelect=Fixed TC/VC=01
                        Status: NegoPending- InProgress-
        Capabilities: [168 v1] Device Serial Number 00-00-00-00-00-00-00-00
        Capabilities: [178 v1] Power Budgeting &lt;?&gt;
        Capabilities: [188 v1] Alternative Routing-ID Interpretation (ARI)
                ARICap: MFVC- ACS-, Next Function: 1
                ARICtl: MFVC- ACS-, Function Group: 0
        Capabilities: [198 v1] #19
        Capabilities: [1f8 v1] Transaction Processing Hints
                Interrupt vector mode supported
                Device specific mode supported
                Steering table in MSI-X table
        Capabilities: [284 v1] Latency Tolerance Reporting
                Max snoop latency: 0ns
                Max no snoop latency: 0ns
        Capabilities: [28c v1] Vendor Specific Information: ID=0002 Rev=3 Len=100 &lt;?&gt;
        Capabilities: [38c v1] Vendor Specific Information: ID=0001 Rev=1 Len=038 &lt;?&gt;
        Capabilities: [3c4 v1] #1f
        Capabilities: [3d0 v1] Vendor Specific Information: ID=0003 Rev=1 Len=054 &lt;?&gt;
        Capabilities: [424 v1] #15
        Kernel driver in use: qede
</code></pre>
<p>从上面信息看到，qlogic driver，被kernel加载使用的叫qede</p>
<h2 id="cha-kan-qede-ban-ben">查看qede版本</h2>
<pre><code class="language-shell">root@node150:~# lsmod | grep qede
qede                  143360  0 
qed                   880640  1 qede
vxlan                  40960  2 i40e,qede
ptp                    20480  2 i40e,qede
root@node150:~# modinfo qede
filename:       /lib/modules/4.1.49-server/updates/dkms/qede.ko
version:        8.33.9.0
license:        GPL
description:    QLogic FastLinQ 4xxxx Ethernet Driver
srcversion:     AFABFD8F281A74624107FE7
alias:          pci:v00001077d00008090sv*sd*bc*sc*i*
alias:          pci:v00001077d00008070sv*sd*bc*sc*i*
alias:          pci:v00001077d00001664sv*sd*bc*sc*i*
alias:          pci:v00001077d00001656sv*sd*bc*sc*i*
alias:          pci:v00001077d00001654sv*sd*bc*sc*i*
alias:          pci:v00001077d00001644sv*sd*bc*sc*i*
alias:          pci:v00001077d00001636sv*sd*bc*sc*i*
alias:          pci:v00001077d00001666sv*sd*bc*sc*i*
alias:          pci:v00001077d00001634sv*sd*bc*sc*i*
depends:        ptp,vxlan,qed
vermagic:       4.1.49-server SMP mod_unload modversions 
parm:           debug: Default debug msglevel (uint)
parm:           int_mode: Force interrupt mode other than MSI-X:(1 INT#x; 2 MSI) (uint)
parm:           gro_disable: Force HW gro disable:(0 enable (default); 1 disable) (uint)
parm:           err_flags_override: Bitmap for disabling or forcing the actions taken according to the respective error flags bits (uint)
parm:           rdma_lag_support: RDMA Bonding support enable - preview mode (uint)
root@node150:~# 
</code></pre>
<p>从lsmod吐出信息可以看到，当前系统中QLogic driver版本是8.33.9.0，高于技嘉工程师提供的版本，所有不需要跟新。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>利用gparted扩展根分区</title>
    <url>/2020/02/02/use_gparted_enlarge_root_partition/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>lab有一套Jenkins环境，是一台VM环境，最初安装系统的时候，整个系统分区只有20G的容量，后来发现这个容量实在太小，经常因根分区满导致jenkins任务没法正常执行。</p>
<p>后台通过VMware vSphere Client扩大了这个分区空间（扩大到60G）：</p>
<pre><code class="language-shell">root@ubuntu-16:~# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
fd0      2:0    1    4K  0 disk 
sda      8:0    0   20G  0 disk /iso
sdb      8:16   0   60G  0 disk 
├─sdb1   8:17   0   16G  0 part /
├─sdb2   8:18   0    1K  0 part 
└─sdb5   8:21   0    4G  0 part [SWAP]
sr0     11:0    1 1024M  0 rom  
root@ubuntu-16:~# 
</code></pre>
<p>但这多出的40G，如何分配给根/分区呢？</p>
<h1 id="huan-jing-zhun-bei">环境准备</h1>
<p>为此，准备了一个测试环境，进行/分区扩容验证。</p>
<p>安装Ubuntu16.04，系统分区是60G的容量：</p>
<pre><code class="language-shell">root@ubuntu16:~# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
fd0      2:0    1    4K  0 disk 
sda      8:0    0   60G  0 disk 
├─sda1   8:1    0   59G  0 part /
├─sda2   8:2    0    1K  0 part 
└─sda5   8:5    0  975M  0 part [SWAP]
sr0     11:0    1 1024M  0 rom  
root@ubuntu16:~# 
</code></pre>
<p>成功安装后，关机，通过VMware vSphere Client扩大vdisk空间，从60G扩大到80G：</p>
<pre><code class="language-shell">root@ubuntu16:~# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
fd0      2:0    1    4K  0 disk 
sda      8:0    0   80G  0 disk 
├─sda1   8:1    0   59G  0 part /
├─sda2   8:2    0    1K  0 part 
└─sda5   8:5    0  975M  0 part [SWAP]
sr0     11:0    1  873M  0 rom  
root@ubuntu16:~# 
</code></pre>
<p>并在根目录下，创建了一个文件，计算md5值：</p>
<pre><code class="language-shell">root@ubuntu16:/# echo 'check' &gt; test.txt 
root@ubuntu16:/# md5sum test.txt 
5e9b13ce8f6c99f3f510756be58d15fe  test.txt
root@ubuntu16:/# 
</code></pre>
<h1 id="jie-zhu-gparted-live-iso-jin-xing-xiu-gai">借助gparted live ISO进行修改</h1>
<p>gparted可以调整分区大小，且支持无损，但是对于/根目录的分区无法调整，但是它提供ISO工具，可以启动后进行调整。</p>
<p>下载了一个gparted-live-0.29.0-1-amd64.iso，下载链接：</p>
<p>链接：<a href="https://pan.baidu.com/s/1I_JWP7-HKHfNM44mlt6Vow">https://pan.baidu.com/s/1I_JWP7-HKHfNM44mlt6Vow</a> 提取码：moq4</p>
<h3 id="xiu-gai-vm-qi-dong-shun-xu">修改VM启动顺序</h3>
<p>在将gparted-live-0.29.0-1-amd64.iso作为VM “CD/DVD设备”条件下，重新启动VM，进入BIOS界面，设置操作如下图所示：</p>
<img class="shadow" src="/img/in-post/vm_set_BIOS.png" width="800">
<p>进入Boot页面，使用“-/+”按钮，将“CD-ROM Driver”设置为第一启动顺序，保存后退出，如下图所示：</p>
<img class="shadow" src="/img/in-post/change-boot-order.png" width="800">
<h3 id="shi-yong-g-parted-live-an-zhuang-jie-zhi-qi-dong-ni-de-xi-tong">使用 GParted Live 安装介质启动你的系统</h3>
<p>VM重新开机后，会弹出如下界面：</p>
<img class="shadow" src="/img/in-post/boot-gparted.png" width="800">
<p>这里选择 “GParted Live (Default settings)” ，并敲击回车按键。</p>
<h3 id="jian-pan-xuan-ze">键盘选择</h3>
<p>默认情况下，它选择第二个选项，按下回车即可。</p>
<img class="shadow" src="/img/in-post/package_configuration.png" width="800">
<h3 id="yu-yan-xuan-ze">语言选择</h3>
<p>默认情况下，它选择 “33” 美国英语，按下回车即可。</p>
<img class="shadow" src="/img/in-post/language_set.png" width="800">
<h3 id="mo-shi-xuan-ze-tu-xing-yong-hu-jie-mian-huo-ming-ling-xing">模式选择（图形用户界面或命令行)</h3>
<p>默认情况下，它选择 “0” 图形用户界面模式，按下回车即可。</p>
<img class="shadow" src="/img/in-post/mode_select.png" width="800">
<h3 id="jia-zai-g-parted-live-ping-mu">加载 GParted Live 屏幕</h3>
<p>现在，GParted Live 屏幕已经加载，它显示我以前创建的分区列表:</p>
<img class="shadow" src="/img/in-post/gparted_show_all_partitions.png" width="800">
<h3 id="shan-chu-xi-tong-ci-pan-fei-gen-fen-qu">删除系统磁盘非根分区</h3>
<p>这里系统磁盘对应分区是sda，下面有swap分区（sda2， sda5），需要删除sda2和sda5，因为只有连续的分区才能合并（未分配的分区中间间隔着sda2和sda5）。</p>
<h3 id="he-bing-fen-qu">合并分区</h3>
<p>选择根分区，点击“Resize/Move”，将20G空闲空间合并到sda1分区。</p>
<h3 id="zhong-xin-chuang-jian-swap-fen-qu-bing-ge-shi-hua-wei-linux-swap">重新创建swap分区，并格式化为linux-swap</h3>
<p>这里新建一个分区，文件系统选择linux-swap，并格式化为swap分区</p>
<h3 id="sheng-xiao-she-zhi">生效设置</h3>
<p>进行了上面的操作后，点击“Apply”等待生效，gparted处理过程如下图所示：</p>
<img class="shadow" src="/img/in-post/gparted_apply.png" width="800">
<p>成功后，会在界面上显示”complete“字样</p>
<p>然后VM断连GParted Live 安装介质，重启启动VM，VM在启动过程中会出现如下信息(稍微等待一点时间即可，无需人工干预)：</p>
<img class="shadow" src="/img/in-post/vm_start_status.png" width="800">
<h3 id="xiao-guo-que-ren">效果确认</h3>
<p>最终效果如下：</p>
<pre><code class="language-shell">root@ubuntu16:~# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
fd0      2:0    1    4K  0 disk 
sda      8:0    0   80G  0 disk 
├─sda1   8:1    0   79G  0 part /
└─sda2   8:2    0    1G  0 part 
sr0     11:0    1 1024M  0 rom  
root@ubuntu16:~# 
root@ubuntu16:/# cat test.txt 
check
root@ubuntu16:/# md5sum test.txt 
5e9b13ce8f6c99f3f510756be58d15fe  test.txt
root@ubuntu16:/# 
</code></pre>
<p>文件md5值，在扩容前后一样.</p>
<h1 id="shi-fou-huan-you-qi-ta-fang-fa">是否还有其他方法？</h1>
<p>网上有人说在OS里安装gparted，直接执行gparted来扩展分区，下文将验证其可行性。</p>
<h2 id="an-zhuang-gparted">安装gparted</h2>
<p>因为要使用gparted来进行根分区的扩容，需要安装gparted；如果已经安装了，忽略此步骤。</p>
<p><code>apt-get install gparted </code></p>
<p>如果后面使用XManager还有问题，可以在此ubuntu节点上安装如下一个工具：</p>
<p><code>apt install x11-xserver-utils </code></p>
<h2 id="tong-guo-x-manager-fang-wen-ci-jie-dian">通过XManager访问此节点</h2>
<p>需要找一台Windows安装XManager，非本文重点，忽略。</p>
<h3 id="x-manager-shang-chuang-jian-yi-ge-x-start">XManager上创建一个XStart</h3>
<p>新建一个XStart，输入此节点的IP地址、root账号和密码，以及需要执行的命令（gparted），保存即可。之后点击这个新建的XStart，会出现有一个auth文件没有，关掉后重新打开这个XStart再次登录即可。</p>
<p>如果直接在终端执行gparted命令时，会出现如下错误：</p>
<pre><code class="language-shell">root@ubuntu16:/# gparted

(gpartedbin:2462): Gtk-WARNING **: cannot open display:
</code></pre>
<h3 id="cha-kan-jin-ru-gparted-jie-mian-xiao-guo">查看进入gparted界面效果</h3>
<p>成功通过XStart进入可视化界面后，会看到已经使用的空间都带有锁标记，如下图所示：</p>
<img class="shadow" src="/img/in-post/gparted_lock.png" width="1200">
<p>这时是不能对分区进行操作的，网上有人说需要先卸载（unmount）或者停止（swapoff），然后才能进行Resize操作。</p>
<h4 id="chang-shi-swapoff">尝试swapoff</h4>
<pre><code class="language-shell">root@ubuntu16:/# swapoff -a
root@ubuntu16:/# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
fd0      2:0    1    4K  0 disk
sda      8:0    0   80G  0 disk
├─sda1   8:1    0   59G  0 part /
└─sda5   8:5    0  975M  0 part
sr0     11:0    1  873M  0 rom
root@ubuntu16:/#
</code></pre>
<p>上面显示已经swapoff了，此时重新进入gparted界面，显示如下：</p>
<img class="shadow" src="/img/in-post/swapoff_root_lock.png" width="1200">
<p>尝试对根分区进行容量扩展，发现没法扩展；尝试先umount，发现也没法umount掉这个根分区，因为会显示为Busy（其实想想，如果umount掉了，系统都没法使用了吧，更不用谈当前gparted操作了），从这里，基本上把swapoff和umount两条路给堵死了，说明行不通。</p>
<p>还有人说用制作Ubuntu启动U盘试用模式下进行的，不过我的环境是虚机，就没尝试这个方法。</p>
<p>先还原环境吧，swapon回来；</p>
<pre><code class="language-shell">root@ubuntu16:/# swapon -a
root@ubuntu16:/# lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
fd0      2:0    1    4K  0 disk
sda      8:0    0   80G  0 disk
├─sda1   8:1    0   59G  0 part /
└─sda5   8:5    0  975M  0 part [SWAP]
sr0     11:0    1  873M  0 rom
root@ubuntu16:/#
</code></pre>
<h2 id="jie-lun">结论</h2>
<p>直接通过gparted，只能对非根分区进行扩容/缩容，如果想对根分区进行扩容/缩容，可以通过gparted live ISO进行。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Nose html report 模板调整</title>
    <url>/2020/02/06/another_nose_html_report_template/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>网上找到了nose-html-report的另外一个模板，样式看着还可以，做了一些修改和调整，更契合自己的审美需要，现放出来.</p>
<p>如果要使用，可以放在nose-html-report的安装包里，或者安装好nose-html-report后，替换掉：</p>
<p><code>/usr/local/lib/python2.7/dist-packages/nose_html_reporting-0.2.3-py2.7.egg/nose_html_reporting/templates/ </code>目录下的report2.jinja2 和 <code>/usr/local/lib/python2.7/dist-packages/nose_html_reporting-0.2.3-py2.7.egg/nose_html_reporting/ </code>目录下的__init__.py,并删除掉pyc文件。</p>
<h1 id="xiao-guo-tu">效果图</h1>
<img class="shadow" src="/img/in-post/another_nose_report.png" width="1200">
<h1 id="huo-qu-di-zhi">获取地址</h1>
<p>git暂时没法访问，先放百度云盘吧：<code>链接：https://pan.baidu.com/s/1YErHlxPkMST7ALLnvglXRQ 提取码：qfp1 </code></p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>nose</category>
      </categories>
      <tags>
        <tag>Automation</tag>
      </tags>
  </entry>
  <entry>
    <title>unittest,pytest,nose,robot framework简介</title>
    <url>/2020/02/06/unittest_nose_pytest_rf/</url>
    <content><![CDATA[<h1 id="unittest-pytest-nose-robot-framework-jian-jie">unittest,pytest,nose,robot framework简介</h1>
<p>unittest: Python自带，最基础的单元测试框架</p>
<p>nose: 基于unittest开发，易用性好，有许多插件</p>
<p>pytest: 同样基于unittest开发，易用性好，信息更详细，插件众多</p>
<p>robot framework：一款基于Python语言的关键字驱动测试框架，有界面，功能完善，自带报告及log清晰美观</p>
<h1 id="dui-bi">对比</h1>
<table>
<thead>
<tr>
<th>项目</th>
<th>unittest</th>
<th>nose</th>
<th>pytest</th>
<th>robot framework</th>
</tr>
</thead>
<tbody>
<tr>
<td>用例编写</td>
<td>继承unittest.TestCase类需要组织各种testSuite断言种类繁多</td>
<td>test开头的方法即可</td>
<td>test开头的方法即可</td>
<td>robot格式，文本文件</td>
</tr>
<tr>
<td>执行器</td>
<td>自己写run_all_tests+discover+CommandParser+…</td>
<td>nosetests …</td>
<td>py.test …</td>
<td>pybot …</td>
</tr>
<tr>
<td>用例发现Discover</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>跳过用例</td>
<td>unittest.skip()unittest.skipIf()raise uniitest.SkipTest</td>
<td>from nose.plugins.skip import SkipTestraise SkipTest</td>
<td>@pytest.mark.skipif( condition)@pytest.mark.xfail</td>
<td>-</td>
</tr>
<tr>
<td>Fixtures</td>
<td>setUp/tearDown@classmethodsetUpClass…</td>
<td>支持</td>
<td>@pytest.fixture(session=“session”, autouse=True)fixture的作用域：function、module、session ，autouse=True使得函数将默认执行</td>
<td>[Setup] …[Teardown] …</td>
</tr>
<tr>
<td>用例标签tags</td>
<td>借助unittest.skip()+comandParser实现</td>
<td>attrib标签from nose.plugins.attrib import attr@attr(speed=‘slow’)def test_big_download(): pass$ nosetests -a speed=slow</td>
<td>@pytest.mark.webtest自定义一个mark，如下，然后 py.test -v -m webtest 只运行标记了webtest的函数， py.test -v -m “not webtest” 来运行未标记webtest的</td>
<td>[Tags] test level1pybot -i/–include tagName C:\TF-Testpybot -e/–exculde level1 *.robot排除</td>
</tr>
<tr>
<td>超时机制Timeout</td>
<td>自己实现</td>
<td>from nose.tools import timedimport time@timed(1)def test_lean_5():time.sleep(2)pass</td>
<td>pip install pytest-timeout@pytest.mark.timeout(60)或 pytest --timeout=300</td>
<td>[Timeout] 3 seconds</td>
</tr>
<tr>
<td>参数化</td>
<td>结合ddt使用</td>
<td>结合ddt使用</td>
<td>@pytest.mark.parametrize(“a,b,expected”, testdata)def test_timedistance_v0(a, b, expected):diff = a - bassert diff == expected</td>
<td>[Template] 1 2 3</td>
</tr>
<tr>
<td>报告</td>
<td>HTMLTestRunner</td>
<td>pip install nose-htmloutput–with-html --html-file=</td>
<td>pip install -U pytest-htmlpy.test --html=./report.html</td>
<td>支持，默认自动生成</td>
</tr>
<tr>
<td>日志log</td>
<td>自己实现</td>
<td>–nologcapture 不使用log–logging-format=FORMAT使用自定义的格式显示日志–logging-datefmt=FORMAT 和上面类类似，多了日期格式–logging-filter=FILTER日志过滤，一般很少用，可以不关注–logging-clear-handlers 也可以不关注–logging-level=DEFAULT log的等级定义</td>
<td>pytest test_add.py --resultlog=./log.txtpytest test_add.py --pastebin=all</td>
<td>支持，默认自动生成</td>
</tr>
<tr>
<td>只列出用例collect-only</td>
<td>无</td>
<td>nosetests --collect-only/nosetests -v --with-id</td>
<td>–collect-only -v</td>
<td>-</td>
</tr>
<tr>
<td>失败用例重跑rerun failures</td>
<td>无</td>
<td>nosetests -v --failed</td>
<td>pip install -U pytest-rerunfailures@pytest.mark.flaky(reruns=5)py.test --rerun=3</td>
<td>robot --rerunfailed</td>
</tr>
<tr>
<td>baseline对比</td>
<td>无</td>
<td>无</td>
<td>无</td>
<td>无</td>
</tr>
<tr>
<td>并发</td>
<td>改造unittest使用协程并发，或使用线程池+Beautiful Report</td>
<td>命令行并发</td>
<td>pytest-xdist：分发到不用的cpu或机器上</td>
<td>命令行并发</td>
</tr>
<tr>
<td>xml报告</td>
<td>无</td>
<td>–with-xunit</td>
<td>–xunit-file=… /pytest+Allure</td>
<td>–junit-xml=</td>
</tr>
<tr>
<td>Selenium支持</td>
<td>无</td>
<td>无</td>
<td>pytest-selenium</td>
<td>robotframework-seleniumlibraryrobotframwork-selenium2library</td>
</tr>
</tbody>
</table>
<h1 id="zong-jie">总结</h1>
<p>总体来说，unittest比较基础，二次开发方便，适合高手使用；pytest/nose更加方便快捷，效率更高，适合小白及追求效率的公司；robot framework由于有界面及美观的报告，易用性更好，灵活性及可定制性略差。</p>
]]></content>
      <categories>
        <category>Automation</category>
      </categories>
      <tags>
        <tag>Automation</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Keepalive测试S3浮动IP切换对业务中断时间</title>
    <url>/2020/03/05/keepalive_s3_takeover_ip/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>最近产品基于keepalive增加了S3 takeover IP，业务透过这个takeover IP访问业务，当takeover IP对应的主机网络故障或宕机，以期能够减少宕机或断网对业务中断的影响。</p>
<p>如何测试验证呢？</p>
<p>本文增加一个script，来进行业务中断耗时的验证</p>
<h1 id="ce-shi-dai-ma">测试代码</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*_

import sys
import time
import boto
import logging
import boto.s3.connection
from multiprocessing.pool import ThreadPool
from multiprocessing import Process, Value, JoinableQueue as Queue, Lock, Event

from ezs3.log import EZLog

EZLog.init_handler(logging.INFO, "./s3_ha.log")
logger = EZLog.get_logger("s3ha")

pool = ThreadPool(processes=20)


def connect_s3(access_key, secret_key, host):
    logger.info("Connection to S3")
    conn = boto.connect_s3(
           aws_access_key_id=access_key,
           aws_secret_access_key=secret_key,
           host=host,
           calling_format = boto.s3.connection.OrdinaryCallingFormat(),
          )

    return conn


def create_bucket(conn, bucket_name):
    logger.info("Start to create bucket :(%s)", bucket_name)
    try:
        bucket = conn.create_bucket(bucket_name)
    except:
        bucket = conn.get_bucket(bucket_name)

    return bucket


def input_object(bucket, thread_idx, max_time):
    logger.info("Start to input object")
    for i in xrange(20000):
        key_name = str(thread_idx) + "_" + str(i) + '_' + str(time.time())
        start_time = time.time()
        key = bucket.new_key(key_name)
        key.set_contents_from_string(key_name)
        end_time = time.time()
        cost_time = end_time - start_time
        if cost_time &gt; float(max_time):
            logger.warn("Put object : (%s) done, but cost : (%s)s", key_name, cost_time)


def thread_pool_input_object(max_time):
    results = []
    for i in xrange(20):
        results.append(pool.apply_async(input_object, (bucket, i, max_time)))

    for (idx, result) in enumerate(results):
        try:
            r = result.get()
        except:
            logger.exception("Failed to put s3 object")


def multi_procress_pool_input_object(max_time):
    worker_num = 20
    workq = Queue()
    put_finish_event = Event()
    tasks = []
    for i in xrange(worker_num):
        t = Process(
            target=input_object, args=(bucket, i, max_time)
        )
        t.daemon = True
        t.start()
        tasks.append(t)

    workq.join()
    put_finish_event.set()
    for t in tasks:
        t.join()


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print "\nusage: {} max_time\n  e.g: {} 2\n  Des: max_time is a second time\n".format(sys.argv[0], sys.argv[0])
        sys.exit(2)

    max_time = sys.argv[1]

    access_key='4X4A784SUI49J7FETC2J'
    secret_key='OOxHdJyDKU71j0jdNcmX5Tool3R12q4ixPa8rNvR'
    host = '1.1.1.1'
    bucket_name = 's3habucket01'

    conn = connect_s3(access_key, secret_key, host)
    bucket = create_bucket(conn, bucket_name)
    # thread_pool_input_object(max_time)
    multi_procress_pool_input_object(max_time)
</code></pre>
<p>这里由于import了产品的函数，脚本不具有通用性，修改了一下:</p>
<pre><code class="language-python">root@node244:~# cat s3_ha.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*_

import sys
import time
import boto
import logging
from logging import handlers
import boto.s3.connection
from multiprocessing.pool import ThreadPool
from multiprocessing import Process, Value, JoinableQueue as Queue, Lock, Event



class Logger(object):
    level_relations = {
        'debug':logging.DEBUG,
        'info':logging.INFO,
        'warning':logging.WARNING,
        'error':logging.ERROR,
        'crit':logging.CRITICAL
    }

    def __init__(self, filename, level='info', when='D', backCount=3, fmt='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'):
        self.logger = logging.getLogger(filename)
        format_str = logging.Formatter(fmt)  # 设置日志格式
        self.logger.setLevel(self.level_relations.get(level)) # 设置日志级别
        sh = logging.StreamHandler() # 往屏幕上输出
        sh.setFormatter(format_str)  # 设置屏幕上显示的格式
        th = handlers.TimedRotatingFileHandler(filename=filename,when=when,backupCount=backCount,encoding='utf-8') # 往文件里写入#指定间隔时间自动生成文件的处理器
        # 实例化TimedRotatingFileHandler
        # interval是时间间隔，backupCount是备份文件的个数，如果超过这个个数，就会自动删除，when是间隔的时间单位，单位有以下几种：
        # S 秒
        # M 分
        # H 小时、
        # D 天、
        # W 每星期（interval==0时代表星期一）
        # midnight 每天凌晨
        th.setFormatter(format_str) # 设置文件里写入的格式
        self.logger.addHandler(sh)  # 把对象加到logger里
        self.logger.addHandler(th)

pool = ThreadPool(processes=20)
log = Logger(filename='s3_ha.log')

def connect_s3(access_key, secret_key, host):
    log.logger.info("Connection to S3")
    conn = boto.connect_s3(
           aws_access_key_id=access_key,
           aws_secret_access_key=secret_key,
           host=host,
           is_secure=False,
           calling_format = boto.s3.connection.OrdinaryCallingFormat(),
          )

    return conn


def create_bucket(conn, bucket_name):
    log.logger.info("Start to create bucket : (%s)", bucket_name)
    try:
        bucket = conn.create_bucket(bucket_name)
    except:
        bucket = conn.get_bucket(bucket_name)

    return bucket


def input_object(bucket, thread_idx, max_time):
    log.logger.info("Start to input object")
    for i in xrange(100000):
        key_name = str(thread_idx) + "_" + str(i) + '_' + str(time.time())
        start_time = time.time()
        key = bucket.new_key(key_name)
        key.set_contents_from_string(key_name)
        end_time = time.time()
        cost_time = end_time - start_time
        # log.logger.info("--  start_time is : (%s), end_time is : (%s), cost_time is : (%s), max_time is : (%s)", start_time, end_time, cost_time, max_time)
        if cost_time &gt; float(max_time):
            log.logger.warn("Put object : (%s) done, but cost : (%s)s", key_name, cost_time)


def thread_pool_input_object(max_time):
    results = []
    for i in xrange(20):
        results.append(pool.apply_async(input_object, (bucket, i, max_time)))

    for (idx, result) in enumerate(results):
        try:
            r = result.get()
        except:
            log.logger.exception("Failed to put s3 object")


def multi_procress_pool_input_object(max_time):
    worker_num = 20
    workq = Queue()
    put_finish_event = Event()
    tasks = []
    for i in xrange(worker_num):
        t = Process(
            target=input_object, args=(bucket, i, max_time)
        )
        t.daemon = True
        t.start()
        tasks.append(t)

    workq.join()
    put_finish_event.set()
    for t in tasks:
        t.join()


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print "\nusage: {} max_time\n  e.g: {} 2\n  Des: max_time is a second time\n".format(sys.argv[0], sys.argv[0])
        sys.exit(2)

    max_time = sys.argv[1]

    access_key='9QK0PJ5S6TKZLEBN1QO0'
    secret_key='iJCIMyq8Ps47SyTIUjG4Z3EAdAZ69fjfQch66VRk'
    host = '1.6.72.80'
    bucket_name = 's3habucket01'

    conn = connect_s3(access_key, secret_key, host)
    bucket = create_bucket(conn, bucket_name)
    # thread_pool_input_object(max_time)
    multi_procress_pool_input_object(max_time)

root@node244:~#
</code></pre>
]]></content>
      <categories>
        <category>keepalive</category>
      </categories>
      <tags>
        <tag>keepalive</tag>
      </tags>
  </entry>
  <entry>
    <title>移植nose assert到pytest，丰富pytest断言</title>
    <url>/2020/04/02/porting_nose_assert_to_pytest/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>一直很喜欢 nose 的 assert，方法多样，后来打算把所有的用例全部转换成 pytest，而 pytest 的 assert，相较于 nose，感觉太单调了，再者如果要是直接修改用例这部分的 assert，改动有点多，比较懒，直接抄袭 nose 的 assert 过来给 pytest 用。</p>
<p>看了下 nose 的 assert，来自 nose.tools，扫了下 tools 目录下的源码，继承自 unittest，直接照抄就是了。</p>
<h1 id="xiao-guo">效果</h1>
<p>将这部分 code 放在自动化用例公共目录，验证一下效果如何：</p>
<pre><code class="language-shell">root@pytest-70-97:/home/pytest_storage/src/common/tools# ll
total 16
drwxr-xr-x 2 root root 4096 Apr  2 18:01 ./
drwxr-xr-x 3 root root 4096 Apr  2 17:47 ../
-rw-r--r-- 1 root root  305 Apr  2 15:05 __init__.py
-rw-r--r-- 1 root root 1184 Apr  2 15:05 trivial.py
</code></pre>
<p>查看一下是否有这些 assert 属性了：</p>
<pre><code class="language-shell">&gt;&gt;&gt; from common import tools
&gt;&gt;&gt; dir(tools)
['__all__', '__builtins__', '__doc__', '__file__', '__name__', '__package__', '__path__', 'assert_almost_equal', 'assert_almost_equals', 'assert_dict_contains_subset', 'assert_dict_equal', 'assert_equal', 'assert_equals', 'assert_false', 'assert_greater', 'assert_greater_equal', 'assert_in', 'assert_is', 'assert_is_instance', 'assert_is_none', 'assert_is_not', 'assert_is_not_none', 'assert_items_equal', 'assert_less', 'assert_less_equal', 'assert_list_equal', 'assert_multi_line_equal', 'assert_not_almost_equal', 'assert_not_almost_equals', 'assert_not_equal', 'assert_not_equals', 'assert_not_in', 'assert_not_is_instance', 'assert_not_regexp_matches', 'assert_raises', 'assert_raises_regexp', 'assert_regexp_matches', 'assert_sequence_equal', 'assert_set_equal', 'assert_true', 'assert_tuple_equal', 'eq_', 'ok_', 'trivial', 'trivial_all']
&gt;&gt;&gt; 
</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>nose</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest+request+allure自动化指南</title>
    <url>/2020/03/07/pytest_request_allure_guide/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>之前一直用nose完成了产品的1000多个自动化用例，再来学习一下pytest。</p>
<p>本文基于Ubuntu16.04，介绍pytest+request+allure的安装与使用，并结合产品，给出具体示例。</p>
<h1 id="an-zhuang-pytest-ce-shi-suo-xu-lib-yu-pytest-plugin">安装pytest、测试所需lib与pytest plugin</h1>
<h2 id="an-zhuang-pytest">安装pytest</h2>
<p>升级python-pip</p>
<pre><code class="language-shell">pip install --upgrade pip
</code></pre>
<p>需要先升级python-pip，否则安装pytest可能会报：</p>
<pre><code class="language-shell">root@ubuntu16:~# pip install -U pytest
Collecting pytest
  Downloading https://files.pythonhosted.org/packages/f0/5f/41376614e41f7cdee02d22d1aec1ea028301b4c6c4523a5f7ef8e960fe0b/pytest-5.3.5.tar.gz (990kB)
    100% |████████████████████████████████| 993kB 9.5kB/s 
  Running setup.py (path:/tmp/pip-build-lmAIQc/pytest/setup.py) egg_info for package pytest produced metadata for project name unknown. Fix your #egg=pytest fragments.
Collecting py&gt;=1.5.0 (from unknown)
  Downloading https://files.pythonhosted.org/packages/99/8d/21e1767c009211a62a8e3067280bfce76e89c9f876180308515942304d2d/py-1.8.1-py2.py3-none-any.whl (83kB)
    100% |████████████████████████████████| 92kB 12kB/s 
Collecting packaging (from unknown)
  Downloading https://files.pythonhosted.org/packages/98/42/87c585dd3b113c775e65fd6b8d9d0a43abe1819c471d7af702d4e01e9b20/packaging-20.1-py2.py3-none-any.whl
Collecting attrs&gt;=17.4.0 (from unknown)
  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl
Collecting more-itertools&gt;=4.0.0 (from unknown)
  Downloading https://files.pythonhosted.org/packages/a0/47/6ff6d07d84c67e3462c50fa33bf649cda859a8773b53dc73842e84455c05/more-itertools-8.2.0.tar.gz (82kB)
    100% |████████████████████████████████| 92kB 11kB/s 
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):
      File "&lt;string&gt;", line 1, in &lt;module&gt;
      File "/tmp/pip-build-lmAIQc/more-itertools/setup.py", line 5, in &lt;module&gt;
        from more_itertools import __version__
      File "/tmp/pip-build-lmAIQc/more-itertools/more_itertools/__init__.py", line 1, in &lt;module&gt;
        from .more import *  # noqa
      File "/tmp/pip-build-lmAIQc/more-itertools/more_itertools/more.py", line 480
        yield from iterable
                 ^
    SyntaxError: invalid syntax
    
    ----------------------------------------
Command "python setup.py egg_info" failed with error code 1 in /tmp/pip-build-lmAIQc/more-itertools/
You are using pip version 8.1.1, however version 20.0.2 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
root@ubuntu16:~# 
</code></pre>
<p>成功升级python-pip后，安装pytest</p>
<pre><code class="language-shell">root@ubuntu16:~# pip install -U pytest
WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.
Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.
To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.
DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
Collecting pytest
  Downloading pytest-4.6.9-py2.py3-none-any.whl (231 kB)
     |████████████████████████████████| 231 kB 9.2 kB/s 
Collecting atomicwrites&gt;=1.0
  Downloading atomicwrites-1.3.0-py2.py3-none-any.whl (5.9 kB)
Collecting pluggy&lt;1.0,&gt;=0.12
  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)
Collecting packaging
  Using cached packaging-20.1-py2.py3-none-any.whl (36 kB)
Collecting attrs&gt;=17.4.0
  Using cached attrs-19.3.0-py2.py3-none-any.whl (39 kB)
Collecting importlib-metadata&gt;=0.12; python_version &lt; "3.8"
  Downloading importlib_metadata-1.5.0-py2.py3-none-any.whl (30 kB)
Collecting six&gt;=1.10.0
  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)
Collecting funcsigs&gt;=1.0; python_version &lt; "3.0"
  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)
Collecting wcwidth
  Downloading wcwidth-0.1.8-py2.py3-none-any.whl (17 kB)
Collecting more-itertools&lt;6.0.0,&gt;=4.0.0; python_version &lt;= "2.7"
  Downloading more_itertools-5.0.0-py2-none-any.whl (52 kB)
     |████████████████████████████████| 52 kB 10 kB/s 
Collecting pathlib2&gt;=2.2.0; python_version &lt; "3.6"
  Downloading pathlib2-2.3.5-py2.py3-none-any.whl (18 kB)
Collecting py&gt;=1.5.0
  Using cached py-1.8.1-py2.py3-none-any.whl (83 kB)
Collecting pyparsing&gt;=2.0.2
  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)
     |████████████████████████████████| 67 kB 16 kB/s 
Collecting contextlib2; python_version &lt; "3"
  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)
Collecting zipp&gt;=0.5
  Downloading zipp-1.1.0-py2.py3-none-any.whl (4.6 kB)
Collecting configparser&gt;=3.5; python_version &lt; "3"
  Downloading configparser-4.0.2-py2.py3-none-any.whl (22 kB)
Collecting scandir; python_version &lt; "3.5"
  Downloading scandir-1.10.0.tar.gz (33 kB)
Building wheels for collected packages: scandir
  Building wheel for scandir (setup.py) ... done
  Created wheel for scandir: filename=scandir-1.10.0-cp27-cp27mu-linux_x86_64.whl size=38910 sha256=318f6b008a74163b37a42f027091fa98a43455d9ea1e46866cd3f5851d74e271
  Stored in directory: /root/.cache/pip/wheels/58/2c/26/52406f7d1f19bcc47a6fbd1037a5f293492f5cf1d58c539edb
Successfully built scandir
Installing collected packages: atomicwrites, contextlib2, six, scandir, pathlib2, zipp, configparser, importlib-metadata, pluggy, pyparsing, packaging, attrs, funcsigs, wcwidth, more-itertools, py, pytest
Successfully installed atomicwrites-1.3.0 attrs-19.3.0 configparser-4.0.2 contextlib2-0.6.0.post1 funcsigs-1.0.2 importlib-metadata-1.5.0 more-itertools-5.0.0 packaging-20.1 pathlib2-2.3.5 pluggy-0.13.1 py-1.8.1 pyparsing-2.4.6 pytest-4.6.9 scandir-1.10.0 six-1.14.0 wcwidth-0.1.8 zipp-1.1.0
root@ubuntu16:~#
</code></pre>
<p>确认pytest版本</p>
<pre><code class="language-shell">root@ubuntu16:~# pytest --version
This is pytest version 4.6.9, imported from /usr/local/lib/python2.7/dist-packages/pytest.pyc
setuptools registered plugins:
  pytest-ssh-0.1 at /usr/local/lib/python2.7/dist-packages/pytest_ssh-0.1-py2.7.egg/pytest_ssh/plugin.py
root@ubuntu16:~# 
</code></pre>
<h2 id="an-zhuang-pytest-progress">安装pytest-progress</h2>
<pre><code class="language-shell">root@ubuntu16:~# pip install pytest-progress
</code></pre>
<h2 id="an-zhuang-pytest-sugar">安装 pytest-sugar</h2>
<pre><code class="language-shell">root@ubuntu16:~# pip install pytest-sugar
</code></pre>
<h2 id="an-zhuang-pytest-allure">安装pytest-allure</h2>
<p>注意，pytest-allure 与 pytest-allure-adaptor 互相冲突（<a href="https://blog.csdn.net/sinat_40831240/article/details/89711263%EF%BC%89%EF%BC%8C%E4%B8%94pytest-allure-apaptor%E5%B7%B2%E7%BB%8F%E4%B8%8D%E7%BB%B4%E6%8A%A4%E4%BA%86%EF%BC%8C%E5%BB%BA%E8%AE%AE%E5%AE%89%E8%A3%85pytest-allure%E3%80%82">https://blog.csdn.net/sinat_40831240/article/details/89711263），且pytest-allure-apaptor已经不维护了，建议安装pytest-allure。</a></p>
<pre><code class="language-shell">root@ubuntu16:~# pip install allure-pytest
</code></pre>
<h2 id="an-zhuang-ce-shi-suo-xu-de-mo-kuai">安装测试所需的模块</h2>
<p>比如发起HTTP请求的request模块之类的，具体根据所需安装。</p>
<h1 id="shi-yong-guo-cheng-zhong-peng-dao-de-wen-ti">使用过程中碰到的问题</h1>
<h2 id="request-insecure-request-warning-gao-jing">request InsecureRequestWarning告警</h2>
<p>用例执行时，出现如下文所示的告警内容：</p>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework/src# python -m pytest testcase/case_2_Accounts/test_common_account_settings.py
Test session starts (platform: linux2, Python 2.7.12, pytest 4.6.9, pytest-sugar 0.9.2)
rootdir: /home/pytest_framework/src
plugins: ssh-0.1, progress-1.2.1, metadata-1.8.0, sugar-0.9.2, html-1.22.1
collecting ... 
====================================================================================== warnings summary =======================================================================================
/usr/lib/python2.7/dist-packages/urllib3/connectionpool.py:794
  /usr/lib/python2.7/dist-packages/urllib3/connectionpool.py:794: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html
    InsecureRequestWarning)

testcase/case_2_Accounts/test_common_account_settings.py:14
  /home/pytest_framework/src/testcase/case_2_Accounts/test_common_account_settings.py:14: PytestCollectionWarning: cannot collect test class 'TestCommonAccountSettings' because it has a __init__ constructor (from: testcase/case_2_Accounts/test_common_account_settings.py)
    class TestCommonAccountSettings(AccountManager):

-- Docs: https://docs.pytest.org/en/latest/warnings.html

Results (2.97s):
</code></pre>
<p>这里有两个告警，一个是request的，一个是测试用例的 _<em>init</em>_ constructor，</p>
<p>对于request</p>
<pre><code class="language-shell">import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)
</code></pre>
<p>对于测试用例，在执行用例时，可以增加<code>-W ignore::pytest.PytestCollectionWarning</code>进行屏蔽示例如下：</p>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework/src# python -m pytest testcase/case_2_Accounts/test_common_account_settings.py -W ignore::pytest.PytestCollectionWarning
Test session starts (platform: linux2, Python 2.7.12, pytest 4.6.9, pytest-sugar 0.9.2)
rootdir: /home/pytest_framework/src
plugins: ssh-0.1, progress-1.2.1, metadata-1.8.0, sugar-0.9.2, html-1.22.1
collecting ... 

Results (1.77s):
</code></pre>
<p>参考链接如下：</p>
<p><a href="https://stackoverflow.com/questions/58624641/how-to-prevent-pytestcollectionwarning-when-testing-class-testament-via-pytest">https://stackoverflow.com/questions/58624641/how-to-prevent-pytestcollectionwarning-when-testing-class-testament-via-pytest</a></p>
<p><a href="https://stackoverflow.com/questions/27981545/suppress-insecurerequestwarning-unverified-https-request-is-being-made-in-python">https://stackoverflow.com/questions/27981545/suppress-insecurerequestwarning-unverified-https-request-is-being-made-in-python</a></p>
<p>pytest会跳过类中定义__init__()的用例</p>
<p>参考：</p>
<pre><code class="language-shell">https://stackoverflow.com/questions/21430900/py-test-skips-test-class-if-constructor-is-defined
</code></pre>
<p>文中有这么一段：</p>
<pre><code class="language-shell">py.test purposely skips classes which have a constructor. The reason for this is that classes are only used for structural reasons in py.test and do not have any inherent behaviour, while when actually writing code it is the opposite and much rarer to not have an .__init__() method for a class.
</code></pre>
<p>目前所写的测试用例并未通过增加<code>-W ignore::pytest.PytestCollectionWarning</code>参数来规避，而是契合上文提及的要求，避免在test case中出现_<em>init</em>_</p>
<h2 id="sheng-cheng-allure-ce-shi-bao-gao-shi-zhao-bu-dao-allure">生成allure测试报告时，找不到allure</h2>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework/src# allure serve allure-results/
allure: command not found
root@ubuntu16:/home/pytest_framework/src# 
</code></pre>
<p>解决方法：</p>
<h3 id="zai-xian-an-zhuang">在线安装</h3>
<pre><code class="language-shell">apt-add-repository ppa:qameta/allure
apt-get update 
apt-get install allure
</code></pre>
<h3 id="ben-di-an-zhuang">本地安装</h3>
<p>下载allure-commandline（<a href="https://dl.bintray.com/qameta/maven/io/qameta/allure/allure-commandline/2.13.2/%EF%BC%89">https://dl.bintray.com/qameta/maven/io/qameta/allure/allure-commandline/2.13.2/）</a></p>
<p>将allure-commandline.tar.gz解压后，在python_3rd_lib目录下，有一个bin目录，目录下有allure和allure.bat</p>
<p>使用allure-command目录下的allure命令，将可执行文件allure拷贝到/usr/bin/目录下，执行allure会报错：</p>
<pre><code>root@ubuntu16:/home/pytest_framework/src# allure generate ../report/ -o ./allure-reports/
Error: Could not find or load main class ru.yandex.qatools.allure.CommandLine
</code></pre>
<p>将allure命令路径，写到配置~/.bashrc文件中：</p>
<p>Step1. 将解压后的allure-2.13.2目录，复制到/opt目录下</p>
<p>Step2. 修改~/.bashrc文件，增加如下一行</p>
<p><code>alias allure='/opt/allure-2.13.2/bin/allure' </code></p>
<p>Step3. Source一下~/.bashrc</p>
<p>至此，后面就可以直接使用allure命令了</p>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework# allure generate ./allure-results/ -o ./report/ --clean
Report successfully generated to ./report
root@ubuntu16:/home/pytest_framework# 
</code></pre>
<p>参考：</p>
<p><code>https://stackoverflow.com/questions/43875741/allure-command-not-found-on-linux </code></p>
<h2 id="shi-yong-allure-sheng-cheng-bao-gao-shi-hou-ti-shi-mei-you-java-home">使用allure生成报告时候，提示没有JAVA_HOME</h2>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework/src# allure generate ../report/ -o ./allure-reports/
Could not find java implementation: try to set JAVA_HOME, JRE_HOME or add java to PATH
root@ubuntu16:/home/pytest_framework/src# 
</code></pre>
<p>这是因为allure是基于JAVA开发的，它的运行需要java的支持。</p>
<p>解决方法：</p>
<p>Step1、下载jdk相应版本，放入 /opt并解压</p>
<p>Step2、配置环境变量</p>
<pre><code class="language-shell">vi /etc/profile
</code></pre>
<p>在最后加入(修改为自己的存放目录)</p>
<pre><code class="language-shell">export JAVA_HOME=/opt/jdk1.8.0_161
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
</code></pre>
<p>Step3、保存后source一下profile文件</p>
<p>执行 java –version显示如下即成功：</p>
<pre><code class="language-shell">root@ubuntu16:~# source /etc/profile
root@ubuntu16:~# java -version
java version "1.8.0_161"
Java(TM) SE Runtime Environment (build 1.8.0_161-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)
root@ubuntu16:~# 
</code></pre>
<h2 id="allure-bao-gao-kong-bai">allure报告空白</h2>
<p>一打开index.html，显示空白（下图是window本地访问）：</p>
<img class="shadow" src="/img/in-post/allure_report_index_null.png" width="1200">
<p>解决方法：</p>
<p>参考： <a href="https://blog.csdn.net/feishicheng/article/details/91970402">https://blog.csdn.net/feishicheng/article/details/91970402</a></p>
<p>allure使用了两种方式来渲染页面。分别是allure open 和 allure serve。前者用于在本地渲染和查看结果，后者用于在本地渲染后对外展示结果。这里我们使用allure open。运行命令 allure open allure-report即可自动打开浏览器展示渲染好的结果。这里的allure-report为allure generate生成的结果所在目录。</p>
<p>根据上面的方法，成功展示如下：</p>
<img class="shadow" src="/img/in-post/allure_cmd_bat.png" width="1200">
<img class="shadow" src="/img/in-post/allure_html_null.png" width="1200">
<p>对于Ubuntu来说，则是执行如下操作：</p>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework/report# allure generate json/ -o html --clean
Report successfully generated to html
root@ubuntu16:/home/pytest_framework/report# allure open html/
Starting web server...
2020-03-07 11:43:22.434:INFO::main: Logging initialized @490ms to org.eclipse.jetty.util.log.StdErrLog
Can not open browser because this capability is not supported on your platform. You can use the link below to open the report manually.
Server started at &lt;http://127.0.1.1:44307/&gt;. Press &lt;Ctrl+C&gt; to exit
</code></pre>
<h2 id="gei-allure-report-zhong-zeng-jia-ce-shi-huan-jing-xin-xi">给Allure report中增加测试环境信息</h2>
<p>在allure html report界面，有一项测试环境信息，如何展示被测环境的信息呢？</p>
<img class="shadow" src="/img/in-post/allure_report_env_null.png" width="1200">
<p>在allure html report生成前，在对应的json目录下增加environment.properties ：</p>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework/report/json# cat environment.properties 
Product=Scaler 7.0-889 (202002280200~2b00e3b44)
HostIP=172.17.75.97
StartTime=2020-03-02 17:58:56
EndTime=2020-03-03 20:04:25

root@ubuntu16:/home/pytest_framework/report/json# 
</code></pre>
<p>然后再生成allure html report：</p>
<img class="shadow" src="/img/in-post/allure_report_env_show.png" width="1200">
<h2 id="allure-html-report-zhong-bu-zhan-shi-log-de-ri-qi">Allure html report中不展示log的日期</h2>
<p>如下图所示，在查看测试用例运行日志时，log里面并没有日期记录，一旦测试用例失败，可以根据展示的日期，迅速判断问题发生前后时间点，根据前后时间点查找产品日志：</p>
<img class="shadow" src="/img/in-post/allure_report_no_time.png" width="1200">
<p>解决方法：</p>
<p>在pytest.ini文件中，增加了log_format &amp;&amp; log_data_format</p>
<pre><code class="language-shell">log_format = %(asctime)s [%(filename)s:%(lineno)-4s] [%(levelname)5s] %(message)s
log_date_format=%Y-%m-%d %H:%M:%S
</code></pre>
<p>这样生成的allure html report中，就会有时间戳了：</p>
<img class="shadow" src="/img/in-post/allure_report_show_timestamp.png" width="1200">
<h2 id="allure-html-report-zhong-chu-xian-32-m-0-m-zhi-lei-de-fu-hao">Allure html report中出现[32m、[0m之类的符号</h2>
<p>如下图所示：</p>
<img class="shadow" src="/img/in-post/allure_report_log_color.png" width="1200">
<p>查看了pytest的help信息，有这么一项：</p>
<pre><code class="language-shell">--color=color         color terminal output (yes/no/auto).
</code></pre>
<p>在用例执行时，携带上这个参数（–color=no），则不会在report中展示这些符号了。</p>
<h2 id="allure-html-report-overview-jie-mian-bu-xian-shi-lei-bie-he-qu-shi">Allure html report Overview界面不显示类别和趋势</h2>
<p>没显示“Categories”，是因为只有在测试用例出错的情况下，这个区域才会显示；</p>
<p>没显示“Trend”，是因为需要与集成工具（比如jenkins）使用后方可展示。</p>
<h1 id="wan-zheng-can-shu-yong-li-shi-li">完整参数用例示例</h1>
<h2 id="dai-ma-mu-lu-jie-gou">代码目录结构</h2>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework# ll
total 56
drwxr-xr-x 8 root root  4096 Mar  7 11:56 ./
drwxr-xr-x 4 root root  4096 Mar  7 11:55 ../
-rw-r--r-- 1 root root     0 Feb 21 11:20 __init__.py
drwxr-xr-x 3 root root  4096 Mar  4 14:03 python_3rd_lib/
drwxr-xr-x 4 root root  4096 Mar  7 11:43 report/
drwxr-xr-x 6 root root  4096 Mar  7 11:55 src/
root@ubuntu16:/home/pytest_framework#
root@ubuntu16:/home/pytest_framework# cd src
root@ubuntu16:/home/pytest_framework/src# ll
total 60
drwxr-xr-x 6 root root  4096 Mar  7 11:55 ./
drwxr-xr-x 8 root root  4096 Mar  7 11:56 ../
-rw-r--r-- 1 root root   579 Mar  2 13:46 clear_pyc.py
drwxr-xr-x 2 root root  4096 Mar  7 11:54 common/
drwxr-xr-x 2 root root  4096 Mar  5 11:37 config/
-rw-r--r-- 1 root root  1186 Mar  4 15:33 conftest.py
-rw-r--r-- 1 root root     0 Mar  2 13:46 __init__.py
-rw-r--r-- 1 root root 17511 Mar  2 13:46 .pylintrc
-rw-r--r-- 1 root root   472 Mar  7 10:53 pytest.ini
-rw-r--r-- 1 root root   291 Mar  4 14:06 run.py
drwxr-xr-x 3 root root  4096 Mar  7 11:54 testcase/
drwxr-xr-x 3 root root  4096 Mar  7 11:54 testcasebase/
root@ubuntu16:/home/pytest_framework/src# 
root@ubuntu16:/home/pytest_framework/src/common# ll
total 80
drwxr-xr-x 2 root root  4096 Mar  7 11:54 ./
drwxr-xr-x 6 root root  4096 Mar  7 11:55 ../
-rw-r--r-- 1 root root 18822 Mar  2 13:46 api.py
-rw-r--r-- 1 root root  6678 Mar  2 13:46 config.py
-rw-r--r-- 1 root root  4874 Mar  2 13:46 errors.py
-rw-r--r-- 1 root root  9727 Mar  2 13:46 http_session.py
-rw-r--r-- 1 root root     0 Mar  2 13:46 __init__.py
-rw-r--r-- 1 root root   741 Mar  2 13:46 path_util.py
-rw-r--r-- 1 root root  6296 Mar  3 15:05 ssh.py
-rw-r--r-- 1 root root  9462 Mar  2 13:46 util.py
root@ubuntu16:/home/pytest_framework/src/common# 
</code></pre>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>common目录下</p>
<ul class="lvl-2">
<li class="lvl-4">
<ul class="lvl-4">
<li class="lvl-6"><a href="http://api.py">api.py</a> 存放产品的API接口地址</li>
<li class="lvl-6"><a href="http://ssh.py">ssh.py</a> 用来建立当前客户端到服务端的ssh链接；</li>
<li class="lvl-6">path_util.py 获取配置文件路径和测试报告路径</li>
<li class="lvl-6"><a href="http://util.py">util.py</a> 常用函数的封装，比如创建指定长度的字符串、数字串、智能等待等</li>
<li class="lvl-6">http_session.py 封装发起不同类型的HTTP消息，以及返回结果</li>
<li class="lvl-6"><a href="http://errors.py">errors.py</a> 存放产品错误码，以及常见的HTTP返回状态码（200,401,500等）</li>
</ul>
</li>
</ul>
</li>
<li class="lvl-2">
<p>testcase 存放具体测试用例，纯粹调用testcasebase的函数，所有的检查点，全部放在testcasebase中</p>
</li>
<li class="lvl-2">
<p>testcasebase 各个用例基类，构造http消息体，发送http请求，对请求结果做检测，对产品应用层做检测</p>
</li>
<li class="lvl-2">
<p>config目录，存放被测环境配置信息</p>
</li>
<li class="lvl-2">
<p><a href="http://run.py">run.py</a> 给jenkins使用，执行所有测试用例或指定用例的入口</p>
</li>
</ul>
<h2 id="zhu-yao-wen-jian-nei-rong">主要文件内容</h2>
<h3 id="a-href-http-conftest-py-conftest-py-a"><a href="http://conftest.py">conftest.py</a></h3>
<pre><code class="language-python">import pytest
import logging

@pytest.fixture(scope='package', autouse=True)
def testsuite_setup_teardown():
    logging.info('------------------------------------- Start to run test case ---------------------------------\n')
    yield
    logging.info('------------------------------------- End to run test case------------------------------------')


@pytest.fixture(scope='function', autouse=True)
def testcase_setup_teardown():
    case_name = os.environ.get('PYTEST_CURRENT_TEST').split(':')[-1].split(' ')[0]

logging.info('----------------------------------- Begin ----------------------------------------')
logging.info('Current test case name : (%s)', case_name)
yield
logging.info('----------------------------------- End ------------------------------------------\n')
</code></pre>
<h3 id="pytest-ini">pytest.ini</h3>
<pre><code class="language-ini">root@ubuntu16:/home/pytest_framework/src# cat pytest.ini 
[pytest]
log_cli = false
log_level = NOTSET
log_file = ../report/pytest_autotest.log
log_format = %(asctime)s [%(filename)s:%(lineno)-4s] [%(levelname)5s] %(message)s
log_date_format=%Y-%m-%d %H:%M:%S
log_file_format = %(asctime)s [%(filename)s:%(lineno)-4s] [%(levelname)5s] %(message)s
log_file_date_format=%Y-%m-%d %H:%M:%S
log_cli_level = INFO
log_cli_format = %(asctime)s [%(filename)s:%(lineno)-4s] [%(levelname)5s] %(message)s
log_cli_date_format=%Y-%m-%d %H:%M:%S
root@ubuntu16:/home/pytest_framework/src#
</code></pre>
<h2 id="api-py-bu-fen-nei-rong">api.py部分内容</h2>
<pre><code class="language-python">root@ubuntu16:/home/pytest_framework/src/common# cat api.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

"""  All of API """

from __future__ import unicode_literals

from config import GetConfig as config


class LoginInterface(object):
    """  Login API  """
login_interface = config.host + '/cgi/login?'

</code></pre>
<h2 id="ce-shi-yong-li-ji-lei-shi-li">测试用例基类示例</h2>
<pre><code class="language-python">root@ubuntu16:/home/pytest_framework/src/testcasebase/Account# cat account.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

"""  Account class base  """

from __future__ import unicode_literals

import json
import urllib
import logging
import requests

from common.http_session import HttpSession
from common.config import GetConfig as config
from common.errors import HttpCode, StatusCode
from common.api import LoginInterface, AccountInterface
from common.util import rand_low_ascii, assert_check, ssh_session


ETC_PASSWD = "/etc/passwd"


class AccountManager(object):
    """  Account manager test case base class  """

    session = HttpSession().login_session()

    @staticmethod
    def add_user_data(user_id=None, display_name=None, email=None, password=None, confirm_password=None,
                      account_type=None, account_dn=None):
        """
        add account data
        :param user_id, string, account id
        :param display_name, string, an account display name
        :param email, string, email address for an account
        :param password, int or string, password for an account
        :param confirm_password, int or string, password for an account
        :param account_type, string, account type
        :param account_dn, string, account dn
        """

        data = {
            'user_id': user_id,
            'display_name': display_name,
            'email': email,
            'password': password,
            'confirm_password': confirm_password,
            'type': account_type,
            'dn': account_dn
        }

        return data

    def add_user(self, user_id=None, display_name=None, email=None, password=None, confirm_password=None,
                 account_type=None, account_dn=None, expect_return_code=None, need_check=None):
        """
        add account
        :param user_id, string, account id
        :param display_name, string, an account display name
        :param email, string, email address for an account
        :param password, int or string, password for an account
        :param confirm_password, int or string, password for an account
        :param account_type, string, account type
        :param account_dn, string, account dn
        :param expect_return_code, string, expected http response content return code, default is success
        :param need_check, bool, check sync result or not, defualt value is True, it means check
        """
        user_id = rand_low_ascii(6) if user_id is None else user_id
        display_name = user_id if display_name is None else display_name
        email = rand_low_ascii() + u'@163.com' if email is None else email
        password = '1' if password is None else password
        confirm_password = password if confirm_password is None else confirm_password
        account_type = '' if account_type is None else account_type
        account_dn = '' if account_dn is None else account_dn
        expect_return_code = StatusCode.SUCCESS if expect_return_code is None else expect_return_code
        need_check = True if need_check is None else need_check

        add_user_url = AccountInterface().add_acount
        add_user_data = self.add_user_data(user_id=user_id,
                                           display_name=display_name,
                                           email=email,
                                           password=password,
                                           confirm_password=confirm_password,
                                           account_type=account_type,
                                           account_dn=account_dn)

        logging.info('[Action]   Start to add a user: (%s)', user_id)
        add_user_request = HttpSession().http_request(self.session, 'GET', add_user_url, params=add_user_data)

        logging.info('[Check]    Check add user : (%s) result', user_id)
        add_user_err_msg = '[ERROR] Add user account fail, background return: {}'.format(add_user_request.text)
        assert HttpCode.SUCCESS == add_user_request.status_code
        assert expect_return_code == json.loads(add_user_request.text)['return_code']

        if expect_return_code == StatusCode.SUCCESS:
            if account_type != "AD":
                if need_check is True:
                    self.check_user_sync_rados(user_id)
                    self.check_user_in_radosgw(user_id)
                    # self.check_user_sync_system(user_id)
                    self.check_user_sync_samba(user_id)
                    logging.info('[Success]  Add account : (%s) success.', user_id)
                else:
                    logging.info('[SKIP]     Need_check is : (%s), so no need to check', need_check)
            else:
                if need_check is True:
                    self.check_user_sync_rados(user_id)
                    logging.info('[Success]  Add AD/LDAP account success.')
                else:
                    logging.info('[SKIP]     Import user from AD/LDAP, but need_check is : (%s), '
                                 'so does not need to check', need_check)
            return user_id
        else:
            logging.info("[Abnormal Scene Test]  Add an account failed as expected, "
                         "backend return: (%s)", add_user_request.text)
            return

    @assert_check
    def check_user_sync_system(self, user_id, vs_name=None):
        """
        :param user_id, string, a user name
        :param vs_name, string, a virtual storage name
        """
        logging.info("[Check]   Start to check user : (%s) sync to system", user_id)

        # should not in /etc/passwd
        vs_name = 'Default' if vs_name is None else vs_name

        all_ctdb_nodes = get_ctdb_nodes(vs_name).strip()
        ctdb_nodes = list()

        for line in all_ctdb_nodes.split("\n"):
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            ctdb_nodes.append(line)

        for each_node in ctdb_nodes:
            cmd = "cat {} | grep {} | awk -F ':' '{{print $1}}'".format(each_node, ETC_PASSWD, user_id)
            res_status, etc_passwd = ssh_session().run_cmd(cmd)
            logging.info("[Check]    [Add user]  Check user in : /etc/passwd on node : (%s)", each_node)
            err_msg = 'Found account : ({}) in /etc/passwd on node : ({})'.format(user_id, each_node)
            assert '' == etc_passwd.strip(), err_msg

    @assert_check
    def check_user_sync_samba(self, user_id):
        """
        :param user_id, string, a user name
        """
        logging.info("[Check]   Start to check user : (%s) sync to samba", user_id)

        # should not in samba
        res_status, ctdb_db_tmp = ssh_session().run_cmd("pdbedit -L | grep {}".format(user_id))
        ctdb_db_user = ctdb_db_tmp.split(":")

        logging.info("[Check]    [Add user]  Check user in samba: pdbedit -L | grep %s", user_id)
        err_msg = '[ERROR]  Found ({}) in samba'.format(user_id)
        assert '' == ctdb_db_user[0], err_msg

    @assert_check
    def check_user_sync_rados(self, user_id, op_type=None):
        """
        Check in rados
        :param user_id, string, a user name
        :param op_type, string, add or del
        """
        logging.info("[Check]    Start to check user : (%s) sync to rados", user_id)

        op_type = 'add' if op_type is None else op_type

        res_status, user_in_rados = ssh_session().run_cmd("rados -p default.rgw.users.uid ls | grep {}".format(user_id))

        logging.info("[Check]    [Add user]  Check user in rados : "
                     "rados -p default.rgw.users.uid ls | grep %s", user_id)
        if op_type == 'add':
            err_msg = '[ERROR]  Not found ({}) in rados'.format(user_id)
            assert user_id == user_in_rados.strip(), err_msg
        elif op_type == 'del':
            err_msg = '[ERROR]  Found ({}) in rados'.format(user_id)
            assert '' == user_in_rados.strip(), err_msg

    @assert_check
    def check_user_in_radosgw(self, user_id):
        """
        :param user_id, string, a user name
        """
        logging.info("[Check]   Start to check user : (%s) in radosgw", user_id)

        res_status, user_info = ssh_session().run_cmd("radosgw-admin --uid={} user info".format(user_id))
        assert user_id in user_info, "[ERROR]  Not found user in radosgw-admin, will retry again."

    @staticmethod
    def delete_user_data(user_id):
        """
        delete user, return HTTP get url
        :param user_id, string, account id
        """
        request_body = {'user_ids': '["' + user_id + '"]'}

        data = urllib.urlencode(request_body)
        return data

    def delete_user(self, user_id, expected_return_code=None, need_check=None):
        """
        delete user operation
        :param user_id, string, account id
        :param expected_return_code, strins, return status code
        :param need_check, bool, check account sync results
        """
        expected_return_code = StatusCode.SUCCESS if expected_return_code is None else expected_return_code
        need_check = True if need_check is None else need_check

        # logging.debug('Structure delete account HTTP message body')
        delete_user_url = AccountInterface().del_user
        delete_user_body = self.delete_user_data(user_id)

        logging.info('[Action]   Delete account : (%s)', user_id)
        for i in xrange(10):
            delete_user_res = HttpSession().http_request(self.session, 'POST', delete_user_url, data=delete_user_body)
            if json.loads(delete_user_res.text)['return_code'] == StatusCode.DELETE_USER_ERROR:
                # Delete user failed, KVStoreError: KVStoreError: fetching entry sds_admin_account timeout
                logging.warn("[Warn]  Delete user : (%s) failed, backend return : (%s)", user_id, delete_user_res.text)
                time.sleep(5)
            else:
                break

        logging.info('[Check]    Check delete user result.')

        delete_user_err_msg = "[ERROR]  Delete user failed, background return is {}".format(delete_user_res)
        assert HttpCode.SUCCESS == delete_user_res.status_code, delete_user_err_msg
        assert expected_return_code == json.loads(delete_user_res.text)['return_code'], delete_user_err_msg

        if need_check is True:
            self.check_user_sync_rados(user_id, op_type='del')
            logging.info('[Success]  Delete user : (%s) success.', user_id)
        else:
            logging.info("[SKIP]     Set need_check is : (%s), so no need to check", need_check)
root@ubuntu16:/home/pytest_framework/src/testcasebase/Account# 
</code></pre>
<h2 id="ce-shi-yong-li-shi-li">测试用例示例</h2>
<pre><code class="language-python">root@ubuntu16:/home/pytest_framework/src/testcase/case_2_Accounts# cat test_common_account_settings.py 
#!/usr/bin/env python

# -*- coding:UTF-8 -*-

"""  Test case of common account settings  """

from __future__ import unicode_literals

import allure
import logging

from common.errors import StatusCode
from testcasebase.Account.account import AccountManager


class TestCommonAccountSettings(AccountManager):
    """  test case for: common account settings  """
@allure.tag('RAT')
def test_add_user_success(self):
    """  Sc-48:Create new user  """
    user_id = self.add_user()
    self.delete_user(user_id)
</code></pre>
<h2 id="yong-li-de-zhi-xing">用例的执行</h2>
<p>示例如下：</p>
<pre><code class="language-shell">root@ubuntu16:/home/pytest_framework/src# python clear_pyc.py; clear; PYTHONPATH=. py.test -v --cache-clear --alluredir ../report/json testcase/case_2_Accounts/test_common_account_settings.py 
</code></pre>
<h2 id="yong-li-de-zhi-xing-ru-kou">用例的执行入口</h2>
<p><a href="http://xn--run-bs1h888gizeuqa.py">通过调用run.py</a>，完成环境的检查、相关包的安装、以及用例的执行。</p>
<p>运行环境是Ubuntu14.04，经过多次摸索，确定只能使用pytest-4.6.9，脚本具体内容如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""  Install package, ENV check and run test case  """

from __future__ import unicode_literals

import os
import sys
import time
import getopt
import shutil
import pexpect

from ezs3.cluster import ClusterManager
from ezs3.utils import get_storage_ip
from ezs3.notify_manager import WebEventCache
from ezs3.command import do_cmd, DoCommandError

from common.cluster import ClusterInfo, OSCheck
from common.path_util import get_report_path
from common.config import GetConfig as config


def clean_pyc():
    """  Clean pyc files  """
    for dirs, folders, files in os.walk('.'):
        for each_file in files:
            root, end = os.path.splitext(each_file)
            if end == '.pyc':
                os.remove(os.path.abspath(os.path.join(dirs, each_file)))


def mkdir_report_path():
    """  Create report path if not exist   """
    report_path = get_report_path()
    if not os.path.exists(report_path):
        os.mkdir(report_path)

    return report_path


def rm_sessions():
    """  Delete all session files in /tmp/sessions  """
    sessions_path = "/tmp/sessions"
    session_files_num = do_cmd('ls -l {}/* | wc -l', 30, True).strip()
    if int(session_files_num) != 0 and os.path.exists(sessions_path):
        storage_ip = get_storage_ip()
        WebEventCache(storage_ip).clean_all()
        do_cmd("rm {}/*".format(sessions_path), 30)


def get_test_product_version():
    """
    Get product version for jenkins email content
    """
    media_info = "/var/log/installer/media-info"
    version = '/etc/ezs3/version'

    if os.path.exists(media_info):
        full_version = do_cmd('cat {}'.format(media_info), 30).strip()
        p_version = full_version.split()[2] + ' ' + full_version.split()[3] + ' ' + full_version.split()[7]
    else:
        p_version = do_cmd('cat {}'.format(version), 30, True).strip()

    do_cmd("echo '{}' &gt; ../report/version.txt".format(p_version), 30, True)


def physical_or_vm(ip=None):
    """
    Adjust the IP address is a physical machine or a VM
    :param ip, client IP or local host(if None)
    """
    cmd = 'dmidecode -s system-product-name | grep -v "#"'
    if ip:
        client_ip_passwd = config.white_ip_root_password
        port = config.ssh_port
        client_ip = config.white_list_ip
        if ip != client_ip:
            print "    [ERROR]    The given IP : ({}) is not same as client IP in " \
                  "autotest.config, exit!!!\n".format(ip)

        dmidecode_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port, client_ip, cmd)
        system_produce = do_cmd(dmidecode_cmd, 30, True).strip()
    else:
        system_produce = do_cmd(cmd, 30, True).strip()

    if not system_produce:
        print "        [ERROR]    Not get the system product name for client ({}), make sure the\n" \
              "                   client exist and power on\n".format(client_ip)
        sys.exit(0)

    if 'VM' in system_produce or 'Virtual' in system_produce:
        return False
    else:
        return True


def append_write(file_name, add_content):
    """
    Append content to file
    :param file_name, string. a file name, needs full path
    :param add_content, string, some content which will added to file_name
    """
    with open(file_name, 'a') as f:
        f.write(add_content)


def run_node_check():
    """  Check run node and configuration in autotest.conf   """
    print "[Step 1]  Check test case execution node.\n"

    public_ips = config.public_ips
    all_public_ips = public_ips.split()
    all_public_ips.sort()
    storage_ips = config.storage_ips
    all_storage_ips = storage_ips.split()
    public_iface = config.public_iface
    storage_iface = config.storage_iface
    client_ip = config.white_list_ip
    client_ip_passwd = config.white_ip_root_password
    port = config.ssh_port

    # Check the client, should install NFS and CIFS, need to remove old SSH to skip
    # error of "Permission denied (publickey,password)"
    do_cmd("ssh-keygen -f '/root/.ssh/known_hosts' -R {}".format(client_ip), 30, True)

    print "    1-1 [Check]    Client : ({}) should install fio, multipath-tools, \n" \
          "                   openssh-server, open-iscsi and  NFS and CIFS".format(client_ip)

    grep_fio = "dpkg -l | grep fio"
    grep_multipath = "dpkg -l | grep multipath-tools"
    grep_ssh = "dpkg -l | grep openssh"
    grep_scsi = "dpkg -l | grep open-iscsi"
    grep_nfs = "dpkg -l | grep nfs"
    grep_cifs = "dpkg -l | grep cifs"

    remote_fio = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port, client_ip, grep_fio)
    remote_multipath = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                        client_ip, grep_multipath)
    remote_ssh = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port, client_ip, grep_ssh)
    remote_scsi = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port, client_ip, grep_scsi)
    remote_nfs = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port, client_ip, grep_nfs)
    remote_cifs = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port, client_ip, grep_cifs)

    fio_exist = do_cmd(remote_fio, 30, True).strip()
    multipath_exist = do_cmd(remote_multipath, 30, True).strip()
    ssh_exist = do_cmd(remote_ssh, 30, True).strip()
    scsi_exist = do_cmd(remote_scsi, 30, True).strip()
    nfs_exist = do_cmd(remote_nfs, 30, True).strip()
    cifs_exist = do_cmd(remote_cifs, 30, True).strip()

    if not fio_exist:
        print "        [ERROR]    Client : ({}) not install fio, please run " \
              "'apt-get install fio' to install it\n".format(client_ip)
        sys.exit(0)

    if not multipath_exist:
        print "        [ERROR]    Client : ({}) not install multipath-tools, please run " \
              "'apt-get install multipath-tools ' to install it\n".format(client_ip)
        sys.exit(0)

    if not ssh_exist:
        print "        [ERROR]    Client : ({}) not install openssh-server, please run " \
              "'apt-get install openssh-server' to install it\n".format(client_ip)
        sys.exit(0)

    if not scsi_exist:
        print "        [ERROR]    Client : ({}) not install open-iscsi, please run " \
              "'apt-get install open-iscsi' to install it\n".format(client_ip)
        sys.exit(0)

    if not nfs_exist:
        print "        [ERROR]    Client : ({}) not install NFS, please run " \
              "'apt-get install nfs-kernel-server' to install it \n".format(client_ip)
        sys.exit(0)

    if not cifs_exist:
        print "        [ERROR]    Client : ({}) not install CIFS, please run " \
              "'apt-get install cifs-utils' to install it \n".format(client_ip)
        sys.exit(0)

    print "        [Success]  Client : ({}) installed fio, multipath-tools,\n" \
          "                   openssh-server, open-iscsi and  NFS and CIFS\n".format(client_ip)

    print "    1-2 [Check]    The running node must be non-first and non-last node"
    nums = len(all_public_ips)
    if nums &lt; 3:
        print "        [ERROR]    A minimum of 3 nodes is required to execute test case, so exit!!!\n"
        sys.exit(0)

    list_before = all_public_ips[:nums-2]
    list_after = all_public_ips[nums-1:]

    list_union = list_before + list_after
    ip_a_info = do_cmd("ip a", 10, True).strip()
    for each_ip in list_union:
        if each_ip in ip_a_info:
            print "        [ERROR]    Forbidden to run case on first or last node, so exit!!!\n"
            sys.exit(0)
    else:
        print "        [Success]  Check the running node IP address successfully\n"

    print "    1-3 [Check]    The network between all nodes should be smooth"
    # Check public network for each node
    for each_public_ip in all_public_ips:
        ping_public_ip_res = do_cmd("ping {} -c 1".format(each_public_ip), 30, True)
        if ping_public_ip_res == "":
            print "        [ERROR]    Public IP of : ({}) unreachable, please check the public IP settings " \
                  "in autotest.config, and the node has been booted normally .".format(each_public_ip)
            sys.exit(0)
        else:
            print "        [Success]  Public IP of : ({}) reachable".format(each_public_ip)

    # Check storage network for each node
    for each_storage_ip in all_storage_ips:
        ping_storage_ip_res = do_cmd("ping {} -c 1".format(each_storage_ip), 30, True)
        if ping_storage_ip_res == "":
            print "        [ERROR]    The storage network of the fourth node is different from other nodes\n"
            sys.exit(0)
        else:
            print "        [Success]  Storage IP of : ({}) reachable".format(each_storage_ip)

    # Check the 4th nodes ip
    storage_ip_pref_1th = '.'.join(all_storage_ips[0].split('.')[:-1])
    storage_ip_pref_4th = '.'.join(config.host_4th_storage_ip.split('.')[:-1])
    if storage_ip_pref_1th == storage_ip_pref_4th:
        print "        [Success]  The forth node's storage IP can be used"
    else:
        print "        [ERROR]    Storage IP of : ({}) unreachable, please check the storage IP settings " \
                  "in autotest.config, and the node has been booted normally .".format(each_storage_ip)
        sys.exit(0)

    print "\n    1-4 [Check]    Check public and storage network interface on each node"
    for each_ip in all_public_ips:
        grep_pub_net_cmd = "ip a | grep {}".format(config.public_iface)
        grep_storage_net_cmd = "ip a | grep {}".format(config.storage_iface)
        rempte_grep_pub_net = "sshpass -p {} ssh -p {} -l root {} '{}'".format(config.root_pass,
                                                                               config.ssh_port, each_ip,
                                                                               grep_pub_net_cmd)
        rempte_storage_pub_net = "sshpass -p {} ssh -p {} -l root {} '{}'".format(config.root_pass,
                                                                                  config.ssh_port, each_ip,
                                                                                  grep_storage_net_cmd)

        grep_pub_net = do_cmd(rempte_grep_pub_net, 30, True).strip()
        grep_storage_net = do_cmd(rempte_storage_pub_net, 30, True).strip()

        if grep_pub_net and grep_storage_net:
            print "        [Success]  Public and Storage interface is correct on node ({})".format(each_ip)
        elif grep_pub_net and not grep_storage_net:
            print "        [ERROR]    Storage interface is incorrect on node ({}) in " \
                  "config/autotest.config\n".format(each_ip)
            sys.exit(0)
        elif not grep_pub_net and grep_storage_net:
            print "        [ERROR]    Public interface is incorrect on node ({}) " \
                  "in config/autotest.config\n".format(each_ip)
            sys.exit(0)
        else:
            print "        [ERROR]    Both Public and Storage interface is incorrect " \
                  "on node ({}) in config/autotest.config\n".format(each_ip)
            sys.exit(0)

    print "\n    1-5 [Check]    Check OSD device on each node, make sure the disk partition exist.\n" \
          "                   If OSD disk partition size gap on each node can not be too large, \n" \
          "                   otherwise PG is difficult to reach a healthy state in a short time"
    osd_device = config.osd_device
    disk_size_list = []

    for each_ip in all_public_ips:
        grep_dev_cmd = "lsblk | grep {} | head -n 1".format(osd_device)
        remote_grep_dev_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(config.root_pass,
                                                                               config.ssh_port, each_ip,
                                                                               grep_dev_cmd)
        grep_dev = do_cmd(remote_grep_dev_cmd, 30, True).strip()
        if 'SWAP' in grep_dev:
            print "        [ERROR]    OSD device is a OS partition on node ({}), please to \n" \
                   "                   check 'osd_device' " \
                   "in config/autotest.config\n".format(each_ip)
            sys.exit(0)

        if not grep_dev:
            print "        [ERROR]    Has no disk partition of ({}) on node ({}), please to \n" \
                   "                   check 'osd_device' in config/autotest.config\n".format(osd_device, each_ip)
            sys.exit(0)

        # Get size of OSD disk partition
        disk_size = grep_dev.split()[-3]
        if disk_size.endswith('G'):
            disk_size_list.append(disk_size.split('G')[0])
        elif disk_size.endswith('T'):
            disk_size_list.append(int(float(disk_size.split('T')[0]) * 1024))
        else:
            print "        [ERROR]    Get size of OSD disk partition is incorrect : ({})".format(disk_size)
            sys.exit(0)

    # Check OSD disk partition size
    if int(float(max(disk_size_list))) / int(float(min(disk_size_list))) &gt; 2000:
        print "        [ERROR]    Size of OSD disk partition is very larger than other " \
               "node on node ({})".format(disk_size)
        sys.exit(0)

    print "        [Success]  Check OSD device on each node success\n"

    print "    1-6 [Check]    Service of apache on each node should be in running state"
    for each_ip in all_public_ips:
        ps_cmd = "ps -ef | grep apache | grep -v grep | wc -l"
        remote_ps_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(config.root_pass, 22, each_ip, ps_cmd)
        apache_pid_no = do_cmd(remote_ps_cmd, 60).strip()
        if int(apache_pid_no) == 0:
            print "        [ERROR]    Service of Apache2 is not running on node ({}), try to start it".format(each_ip)
            start_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(config.root_pass, 22,
                                                                         each_ip, config.restart_apache)
            do_cmd(start_cmd, 40, True)
            apache_pid_no = do_cmd(remote_ps_cmd, 60, True).strip()
            if int(apache_pid_no) == 0:
                print "        [ERROR]    Service of Apache2 is still not running on node ({}) after try " \
                     "to start it, so exit!!!\n".format(each_ip)
                sys.exit(0)
        else:
            print "        [Success]  Service of Apache2 is running on node ({})".format(each_ip)

    # Check ESXi host IP or IPMI IP
    print "\n    1-7 [Check]    Check ESXi host IP config or IPMI IP config in config/autotest.config"
    system_produce = physical_or_vm(ip=client_ip)
    # # Client is a VM
    if system_produce is False:
        list_vm_cmd = "vim-cmd vmsvc/getallvms"
        remote_list_vm_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(config.esxi_root_passwd, port,
                                                                              config.esxi_ip, list_vm_cmd)
        all_vms = do_cmd(remote_list_vm_cmd, 30, True).strip()
        if config.esxi_vm_host_name not in all_vms:
            print "        [ERROR]    Incorrect information in config/autotest.config about ESXi:\n" \
                  "                   (1) Not enabled SSH service on ESXi?\n" \
                  "                   (2) Wrong vm_host_name in config/autotest.config?\n" \
                  "                   (3) Wrong IP address or wrong password for root in config/autotest.config?\n"
            sys.exit(0)
        else:
            print "        [Success]  ESXi host information is correct in config/autotest.config\n"
    else:
        # Client is a physical machine
        get_ipmi_cmd = 'ipmitool lan print | grep "IP Address"'
        remote_get_ipmi_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                               client_ip, get_ipmi_cmd)
        ipmi_info = do_cmd(remote_get_ipmi_cmd, 30, True).strip()
        if ipmi_info:
            get_ipmi_ip = ipmi_info.split('\n')[-1].split(':')[-1].strip()
        else:
            get_ipmi_ip = 'not-get'

        if config.ipmi_ip not in ipmi_info:
            print "        [ERROR]    ipmi_ip is not correct in config/autotest.config, currently \n" \
                  "                   acquired : ({}), but in conf is : ({})\n".format(get_ipmi_ip, config.ipmi_ip)
            sys.exit(0)
        else:
            # Check ipmi user
            ipmi_user_list = []
            list_ipmi_user_cmd = "ipmitool user list -c"
            remote_list_user_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                    client_ip, list_ipmi_user_cmd)
            ipmi_uses = do_cmd(remote_list_user_cmd, 30, True).strip()
            for each_user in ipmi_uses.split('\n'):
                user_name = each_user.split(',')[1]
                ipmi_user_list.append(user_name)

            if config.ipmi_user not in ipmi_user_list:
                print "        [ERROR]    ipmi_user is not correct in config/autotest.config\n"
                sys.exit(0)
            else:
                print "        [Success]  IPMI user is correct in config/autotest.config"

            # Check ipmi user's password
            try:
                list_frc_cmd = "ipmitool -H {} -I lanplus -U {} -P {} fru list".format(config.ipmi_ip,
                                                                                       config.ipmi_user,
                                                                                       config.ipmi_user_passwd)
                do_cmd(list_frc_cmd, 30).strip()
                print "        [Success]  IPMI of ipmi_user_passwd is correct in config/autotest.config\n"
            except DoCommandError as ex:
                if 'Unable to establish' in str(ex):
                    print "        [ERROR]    IPMI of ipmi_user_passwd is not correct in config/autotest.config\n"
                    sys.exit(0)
                else:
                    print "        [ERROR]    Get FRU list failed, backend return : ({})".format(str(ex))
                    sys.exit(0)

    # Check AD and LDAP reachable or not
    print "    1-8 [Check]    Check AD and LDAP reachable or not in config/autotest.config"
    ad_ip = config.ad_server_addr
    ldap_ip = config.ldap_server_addr

    if ad_ip == ldap_ip:
        print "        [ERROR]    AD IP is same as LDAP IP, please check AD and LDAP settings in autotest.config\n"
        sys.exit(0)

    ping_ad_res = do_cmd("ping {} -c 1".format(ad_ip), 60, True).strip()
    if ping_ad_res == "":
        print "        [ERROR]    AD : ({}) unreachable, please check AD settings " \
               "in autotest.config.".format(ad_ip)
        sys.exit(0)
    else:
        print "        [Success]  AD   : ({}) reachable".format(ad_ip)

    ping_ldap_res = do_cmd("ping {} -c 1".format(ldap_ip), 60, True).strip()
    if ping_ldap_res == "":
        print "        [ERROR]    LDAP : ({}) unreachable, please check LDAP " \
               "settings in autotest.config.".format(ldap_ip)
        sys.exit(0)
    else:
        print "        [Success]  LDAP : ({}) reachable\n".format(ldap_ip)

    # If other cluster has configured the DNS IP, should exit
    print "    1-9 [Check]    Check DNS IP in config/autotest.config"
    dns_ip = config.dns_ip
    try:
        ping_dns_res = do_cmd("ping -c2 {}".format(dns_ip), 60).strip()
        if ping_dns_res and '0% packet loss' in ping_dns_res:
            print "        [ERROR]    DNS IP of ({}) in config/autotest.config is used, " \
                      "please check the Environment.\n".format(dns_ip)
            sys.exit(0)
    except Exception as ex:
        print "        [Success]  DNS IP : ({}) is available in config/autotest.config\n".format(dns_ip)

    # If other environment used this takeover IP, should exit
    print "    1-10 [Check]    Check takeover IP in config/autotest.config"
    takeover_ip_list = []

    takeover_ips = config.takeover_ips
    for each_ip in takeover_ips.split():
        takeover_ip_list.append(each_ip.split('/')[0])

    node_ip_prefix = all_public_ips[0].split('.')[0:2]
    prefix_ip = takeover_ip_list[0].split('.')[0:2]
    if node_ip_prefix != prefix_ip:
        print "         [ERROR]    Takeover IP and public ip are not in same segment\n" \
              "                    Takeover IP is : {} \n" \
              "                    public ip is : {} \n" \
              "                    please check the Environment.\n".format(takeover_ips, public_ips)
        sys.exit(0)

    for each_takeover_ip in takeover_ip_list:
        ping_cmd = 'ping -c2 {}'.format(each_takeover_ip)
        try:
            ping_res = do_cmd(ping_cmd, 60).strip()
            if ping_res and '0% packet loss' in ping_res:
                print "         [ERROR]    Takeover IP of ({}) in config/autotest.config is used, " \
                      "please check the Environment.\n".format(each_takeover_ip)
                sys.exit(0)
        except Exception as ex:
            # print "        [ERROR]    Ping takeover IP : {} occur
            # exception : ({})".format(each_takeover_ip, str(ex))
            pass
    print "         [Success]  Takeover IP is available in config/autotest.config"

    # If other cluster used S3 takeover IP, should exit
    s3_takeover_ips = config.s3_takeover_ips
    s3_prefix_ip = s3_takeover_ips.split()[0].split('/')[0].split('.')[0:2]
    if node_ip_prefix != s3_prefix_ip:
        print "         [ERROR]    S3 takeover IP and public ip are not same segment, s3 takeover IP is {}, " \
                              "public ip is {}, please check the Environment.\n".format(s3_prefix_ip, public_ips)
        sys.exit(0)

    s3_vips = [each_ip.split(',')[0].split('/')[0] for each_ip in s3_takeover_ips.split()]
    s3_vip_union = list((set(s3_vips).union(set(all_public_ips))) ^ (set(s3_vips) ^ set(all_public_ips)))
    if len(s3_vip_union) &gt; 0:
        print "         [ERROR]    S3 takeover IP in config/autotest.config should not include " \
               "cluster public IP, please check the Environment.\n"
        sys.exit(0)
    # # Check ping result
    for each_s3_vip in s3_vips:
        ping_cmd = "ping -c2 {}".format(each_s3_vip)
        try:
            ping_res = do_cmd(ping_cmd, 60).strip()
            if ping_res and '0% packet loss' in ping_res:
                print "         [ERROR]    S3 takeover IP of ({}) in config/autotest.config is used, " \
                      "please check the Environment.\n".format(each_s3_vip)
                sys.exit(0)
        except Exception as ex:
            # print "        [ERROR]    Ping S3 takeover IP : {} occur
            #  exception : ({})".format(each_takeover_ip, str(ex))
            pass
    print "         [Success]  S3 takeover IP is available in config/autotest.config\n"

    # Check public or storage interface should config in autotest.conf
    print "    1-11 [Check]    Check public and storage interface from config/autotest.config"

    iface = []
    local_iface = do_cmd('cat /etc/network/interfaces | grep iface').strip()
    for each_iface in local_iface.split('\n'):
        iface.append(each_iface.split()[1])

    if public_iface not in iface or storage_iface not in iface:
        print "         [ERROR]    public_iface or storage_iface is not correct in config/autotest.config\n"
        sys.exit(0)
    else:
        print "         [Success]  Public and storage interface are correct in config/autotest.config\n"

    # Check cluster network speed, avoid having more bandwidth unused
    print "    1-12 [Check]    Check public interface BW performance and DNS ip segment"

    all_nic_speed = {}
    for each_iface in iface:
        each_speed_info = do_cmd("ethtool {} | grep Speed | grep -v Unknown".format(each_iface), 30, True).strip()
        each_speed = each_speed_info.split(':')[-1].split('Mb/s')[0]
        all_nic_speed[each_iface] = each_speed.strip()

    local_public_speed_info = do_cmd("ethtool {} | grep Speed".format(public_iface), 30, True).strip()
    local_public_speed = local_public_speed_info.split(':')[-1].split('Mb/s')[0].strip()

    max_speed = max(all_nic_speed.values())
    max_speed_iface = []
    for key, value in all_nic_speed.iteritems():
        if value == max_speed:
            max_speed_iface.append(key)

    if int(max_speed) &gt; int(local_public_speed):
        print "         [ERROR]    May not use 10G network, check public_iface or " \
              "storage_iface in config/autotest.config\n"
        sys.exit(0)
    else:
        # Check DNS ip, should use same segment network with public NIC
        _ip = []
        for each_nic in max_speed_iface:
            ip_info = do_cmd("ip a | grep 'scope global {}'".format(each_nic), 30, True).strip()
            if ip_info:
                ip = ip_info.split()[1].split('/')[0]
                _ip.append(ip)
        
        _ip_prefix = []
        for each_prefix in _ip:
            _ip_prefix.append('.'.join(each_prefix.split('.')[:-2]))

        dns_ip = config.dns_ip
        dns_ip_prefix = '.'.join(dns_ip.split('.')[:-2])
        if dns_ip_prefix not in _ip_prefix:
            print "         [ERROR]    DNS ip in config/autotest.config is not correct, " \
                   "should start with these segments : ({})\n".format(_ip_prefix)
            sys.exit(0)

    print "         [Success]  Use correct public interface and config dns ip correct in config/autotest.config\n"

    # Check local host IP should config in autotest.conf
    print "    1-13 [Check]    Local host IP should configed in config/autotest.config"

    ceph_conf = "/etc/ceph/ceph.conf"
    health = do_cmd("ceph health detail", 60, True).strip()
    if 'HEALTH_OK' in health and os.path.exists(ceph_conf):
        pub_ifce_info = do_cmd("cat {} | grep 'public interface'".format(ceph_conf), 15).strip()
        sto_ifce_info = do_cmd("cat {} | grep 'storage interface'".format(ceph_conf), 15).strip()
        pub_ifce = pub_ifce_info.split('=')[-1].strip()
        sto_ifce = sto_ifce_info.split('=')[-1].strip()

        if pub_ifce != public_iface or sto_ifce != storage_iface:
            print "         [ERROR]    Check public or storage interface failed, please check " \
                   "config/autotest.config. "
            print "                    Get public interface from ceph.conf is ({}), " \
                  "but in config/autotest.config is ({})".format(pub_ifce, public_iface)
            print "                    Get storage interface from ceph.conf is ({}), " \
                  "but in config/autotest.config is ({})\n".format(sto_ifce, storage_iface)
            sys.exit(0)
        else:
            print "         [Success]  Check public and storage interface success " \
                  "from config/autotest.config and ceph.conf"

        scope_pub_cmd = "ip a | grep 'scope global {}' | awk '{{print $2}}'".format(pub_ifce)
        scope_sto_cmd = "ip a | grep 'scope global {}' | awk '{{print $2}}'".format(sto_ifce)
        local_pub_ip_info = do_cmd(scope_pub_cmd, 15).strip()
        local_sto_ip_info = do_cmd(scope_sto_cmd, 15).strip()
        local_pub_ip = local_pub_ip_info.split('/')[0]
        local_sto_ip = local_sto_ip_info.split('/')[0]

        if local_pub_ip in all_public_ips and local_sto_ip in all_storage_ips:
            print "         [Success]  Cluster is Health OK, check public and storage " \
                  "IP address in config/autotest.config success\n"
        else:
            print "         [ERROR]    Local host ip is not in config/autotest.config " \
                  "of storage_ips or public_ips\n"
            sys.exit(0)
    else:
        local_ip = []
        local_ip_info = do_cmd("ip a | grep 'scope global' | awk '{{print $2}}'", 30).strip()

        for each_ip in local_ip_info.split("\n"):
            local_ip.append(each_ip.split('/')[0])
        # List union
        public_ret_list = list((set(all_public_ips).union(set(local_ip))) ^ (set(all_public_ips) ^ set(local_ip)))
        storage_ret_list = list((set(all_storage_ips).union(set(local_ip))) ^ (set(all_storage_ips) ^ set(local_ip)))

        if len(public_ret_list) &gt; 0 and len(storage_ret_list) &gt; 0:
            print "         [Success]  Check public and storage IP address in config/autotest.config success\n"
        else:
            print "         [ERROR]    Local host ip is not in config/autotest.config of storage_ips or " \
                  "public_ips, please check config/autotest.config\n"
            sys.exit(0)

    # Check the node of cluster IP should not be as client
    print "    1-14 [Check]    Check the node of cluster IP should not be as client"

    client_ips_list = [config.white_list_ip, config.white_second_ip, config.black_list_ip]
    client_ip_union = list((set(client_ips_list).union(set(all_public_ips))) ^
                           (set(client_ips_list) ^ set(all_public_ips)))
    if len(client_ip_union) &gt; 0:
        print "         [ERROR]    In config/autotest.config, at [CLIENTS], client IP should not " \
              "same as cluster nodes's IP\n"
        sys.exit(0)

    print "         [Success]  Check IP and interface success in config/autotest.config\n"

    # Check the client, should has /root/.ssh/id_dsa.pub, used for RRS SSH key
    id_dsa_pub = "/root/.ssh/id_dsa.pub"
    print "    1-15 [Check]    Client : ({}) should has file of ({})".format(client_ip, id_dsa_pub)

    ls_cmd = "ls -l {}".format(id_dsa_pub)
    remote_ls_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                     client_ip, ls_cmd)
    ls_dsa_pub_flag = do_cmd(remote_ls_cmd, 20, True).strip()
    if ls_dsa_pub_flag:
        print "         [Success]  Client : ({}) has file of ({})".format(client_ip, id_dsa_pub)

        # If client is a cluster of Virtual Storage node, which reset-node or create cluster for many
        # times(not refresh install OS), will has many old ssh key in /root/.ssh/authorized_keys
        expect_pub_files_list = ['/root/.ssh/id_dsa.pub', '/root/.ssh/id_ecdsa.pub', '/root/.ssh/id_rsa.pub']
        ls_pub_files = "ls -l /root/.ssh/id*.pub | awk '{{print $NF}}'"
        cat_auth_keys_file = "cat /root/.ssh/authorized_keys"
        client_ls_pub_files = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                               client_ip, ls_pub_files)
        client_ls_auth_files = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                client_ip, cat_auth_keys_file)
        # If client has file of /root/.ssh/authorized_keys, break
        client_auth_keys_res = do_cmd(client_ls_auth_files, 30, True).strip()
        # print "--------- client_auth_keys_res : ({})".format(client_auth_keys_res)
        if client_auth_keys_res:
            # A cluster node as client
            key_content_cmd = "ceph config-key get ssh_authorized_keys &gt; /tmp/kv_key.txt"
            remote_key_content_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                      client_ip, key_content_cmd)
            kv_store_res = do_cmd(remote_key_content_cmd, 30, True).strip()
            if kv_store_res:
                cat_id_rsa_pub = "cat /root/.ssh/id_rsa.pub &gt; /tmp/ssh_keys.txt"
                cat_id_ecdsa_pub = "cat /root/.ssh/id_ecdsa.pub &gt;&gt; /tmp/ssh_keys.txt"
                cat_id_dsa_pub = "cat /root/.ssh/id_dsa.pub &gt;&gt; /tmp/ssh_keys.txt"
                mix_cmd = "{};{};{}".format(cat_id_rsa_pub, cat_id_ecdsa_pub, cat_id_dsa_pub)
                remote_echo_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                   client_ip, mix_cmd)
                do_cmd(remote_echo_cmd, 30)
                diff_cmd = "diff /tmp/kv_key.txt /tmp/ssh_keys.txt"
                remote_diff_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                   client_ip, diff_cmd)
                diff_res = do_cmd(remote_diff_cmd, 30).strip()
                if diff_res:
                    print "         [Action]   Need to change content of /root/.ssh/authorized_keys " \
                          "on client : ({})".format(client_ip)
                    put_kv_store = "ceph config-key put ssh_authorized_keys -i /tmp/ssh_keys.txt"
                    remote_put_kv_store = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                           client_ip, put_kv_store)
                    do_cmd(remote_put_kv_store, 30)
            else:
                print "         [SKIP]     Cluster node as client, but no need to change content of " \
                      "/root/.ssh/authorized_keys "

            # Not a cluster node as client
            client_ls_pub_files_res = do_cmd(client_ls_pub_files, 30, True).strip()
            if client_ls_pub_files_res:
                pub_list = client_ls_pub_files_res.split('\n')
                pub_list.sort()
                # Like this : ['/root/.ssh/id_dsa.pub', '/root/.ssh/id_ecdsa.pub', '/root/.ssh/id_rsa.pub']
                if set(expect_pub_files_list).issubset(set(pub_list)) is False:
                    print "         [ERROR]    expect_pub_files_list : ({}) is not a subset of " \
                          "pub_list : ({})\n".format(expect_pub_files_list, pub_list)
                else:
                    # Check content of /root/.ssh/authorized_keys, if has many same host name, should change it
                    cat_auth_keys_cmd = "cat /root/.ssh/authorized_keys | awk '{{print $NF}}'"
                    get_content_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                       client_ip, cat_auth_keys_cmd)
                    auth_keys_res = do_cmd(get_content_cmd, 30).strip()
                    if len(auth_keys_res.split('\n')) - len(set(auth_keys_res.split('\n'))) &gt; 2:
                        # authorized_keys has some old ssh keys, need to change it
                        print "         [Action]   Need to change content of /root/.ssh/authorized_keys " \
                              "on client : ({})".format(client_ip)
                        cat_id_rsa_pub = "cat /root/.ssh/id_rsa.pub &gt; /tmp/ssh_keys.txt"
                        cat_id_ecdsa_pub = "cat /root/.ssh/id_ecdsa.pub &gt;&gt; /tmp/ssh_keys.txt"
                        cat_id_dsa_pub = "cat /root/.ssh/id_dsa.pub &gt;&gt; /tmp/ssh_keys.txt"
                        mix_cmd = "{};{};{}".format(cat_id_rsa_pub, cat_id_ecdsa_pub, cat_id_dsa_pub)
                        remote_echo_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                                           client_ip, mix_cmd)
                        do_cmd(remote_echo_cmd, 30)
                    else:
                        print "         [Success]  Correct content of /root/.ssh/authorized_keys " \
                              "on client : ({})\n".format(client_ip)
            else:
                print "         [SKIP]     Not a cluster node as client, but no need to change content of " \
                      "/root/.ssh/authorized_keys\n"
        else:
            print "         [Success]  Client : ({}) has no file of /root/.ssh/authorized_keys, " \
                  "do nothing\n".format(client_ip)
    else:
        print "         [WARN]     Client : ({}) has no file of ({}), now install " \
              "it".format(client_ip, id_dsa_pub)

        import pexpect
        gen_cmd = "ssh-keygen -t dsa"
        remote_gen_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd, port,
                                                                          client_ip, gen_cmd)
        process = pexpect.spawn(remote_gen_cmd)
        match_enter_file = process.expect("Enter file in which to save the key")
        if match_enter_file == 0:
            process.sendline('\n')
        else:
            print "         [ERROR]    Not match content of 'Enter file in which to save the key'\n"

        match_enter_passphrase = process.expect("Enter passphrase")
        if match_enter_passphrase == 0:
            process.sendline('\n')
        else:
            print "         [ERROR]    Not match content of 'Enter passphrase'\n"

        match_enter_passphrase_again = process.expect("Enter same passphrase again")
        if match_enter_passphrase_again == 0:
            process.sendline('\n')
        else:
            print "         [ERROR]    Not match content of 'Enter same passphrase again'\n"

        process.close()

        # ls_dsa_pub_flag = install_on_remote_check(remote_ls_cmd)
        ls_dsa_pub_flag = do_cmd(remote_ls_cmd, 20, True).strip()
        if not ls_dsa_pub_flag:
            print "         [ERROR]    Client : ({}) has no file of ({}), please run " \
                  "'ssh-keygen -t dsa' to generate it\n".format(client_ip, id_dsa_pub)
            sys.exit(0)
        else:
            print "         [Success]  Generate dsa key on client : ({}) success\n".format(client_ip)

    print "    1-16 [Check]    Check cluster public IP and client IP segment"
    pub_ip_prefix = '.'.join(config.public_ips.split()[0].split('.')[:-2])
    client_1st_ip_prefix = '.'.join(config.white_list_ip.split()[0].split('.')[:-2])
    client_2nd_ip_prefix = '.'.join(config.white_second_ip.split()[0].split('.')[:-2])
    client_black_ip_prefix = '.'.join(config.black_list_ip.split()[0].split('.')[:-2])

    if pub_ip_prefix == client_1st_ip_prefix == client_2nd_ip_prefix == client_black_ip_prefix:
        print "         [Success]  Client IP prefix : ({}) is same as cluster public " \
              "ips : ({})".format(config.white_list_ip, config.public_ips)
    else:
        if pub_ip_prefix != client_1st_ip_prefix:
            print "         [ERROR]    Client first client IP address segment : ({}) is not on the same network\n" \
                  "                    segment as the public IP : ({})\n".format(config.white_list_ip,
                                                                                 config.public_ips)
            sys.exit(0)

        if pub_ip_prefix != client_2nd_ip_prefix:
            print "         [ERROR]    The second client IP address segment : ({}) is not on the same network\n" \
                  "                    segment as the public IP : ({})\n".format(config.white_second_ip,
                                                                                 config.public_ips)
            sys.exit(0)

        if pub_ip_prefix != client_black_ip_prefix:
            print "         [ERROR]    Client black IP address segment : ({}) is not on the same network\n" \
                  "                    segment as the public IP : ({})\n".format(config.black_list_ip,
                                                                                 config.public_ips)
            sys.exit(0)


def unlink_unavailable_scsi_session():
    # Clean all of target nodes on client, it is necessary to check the file system to ensure client
    # does not try to re-establish the connection on future boot operations
    port = config.ssh_port
    client_ip = config.white_list_ip
    client_ip_passwd = config.white_ip_root_password

    white_second_ip = config.white_second_ip
    white_second_ip_root_password = config.white_second_ip_root_password
    black_list_ip = config.black_list_ip
    black_ip_root_password = config.black_ip_root_password

    # Use rm on first client, because this client is only used by pytest
    rm_iqn_cmd = "rm -rf /etc/iscsi/nodes/iqn*"
    remote_rm_iqn_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd,
                                                                         port, client_ip, rm_iqn_cmd)
    do_cmd(remote_rm_iqn_cmd, 60, True).strip()

    rm_tgt_cmd = "rm -rf /etc/iscsi/send_targets/*"
    remote_rm_tgt_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(client_ip_passwd,
                                                                         port, client_ip, rm_tgt_cmd)
    do_cmd(remote_rm_tgt_cmd, 60, True).strip()

    # Delete all of folder which name include pytest, then rm unavailable link file in send_targets
    ls_session_cmd = "iscsiadm -m session | grep pytest | sed 's/,1//g' | awk '{{print $3, $NF}}'"
    rm_iqn_cmd = "rm -rf /etc/iscsi/nodes/iqn*pytest*"
    rm_tgt_cmd = "for f in $(find /etc/iscsi/send_targets/ -type l); do [ ! -e $f ] &amp;&amp; rm -rf $f; done"

    remote_ls_2nd_session_cmd = 'sshpass -p {} ssh -p {} -l root {} "{}"'.format(white_second_ip_root_password,
                                                                                 port, white_second_ip, ls_session_cmd)
    remote_ls_3rd_session_cmd = 'sshpass -p {} ssh -p {} -l root {} "{}"'.format(black_ip_root_password,
                                                                                 port, black_list_ip, ls_session_cmd)

    session_res_2nd = do_cmd(remote_ls_2nd_session_cmd, 30, True).strip()
    if session_res_2nd:
        for each_session in session_res_2nd.split("\n"):
            each_session_list = each_session.split()
            logout_cmd = "iscsiadm -m node -T {} -p {} --logout".format(each_session_list[1], each_session_list[0])
            delete_cmd = "iscsiadm -m node -o delete -T {} -p {}".format(each_session_list[1], each_session_list[0])
            remote_logout_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(white_second_ip_root_password,
                                                                                 port, white_second_ip, logout_cmd)
            remote_delete_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(white_second_ip_root_password,
                                                                                 port, white_second_ip, delete_cmd)
            do_cmd(remote_logout_cmd, 30, True)
            do_cmd(remote_delete_cmd, 30, True)

    session_res_3rd = do_cmd(remote_ls_3rd_session_cmd, 30, True).strip()
    if session_res_3rd:
        for each_session in session_res_3rd.split("\n"):
            each_session_list = each_session.split()
            logout_cmd = "iscsiadm -m node -T {} -p {} --logout".format(each_session_list[1], each_session_list[0])
            delete_cmd = "iscsiadm -m node -o delete -T {} -p {}".format(each_session_list[1], each_session_list[0])
            remote_logout_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(black_ip_root_password,
                                                                                 port, black_list_ip, logout_cmd)
            remote_delete_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(black_ip_root_password,
                                                                                 port, black_list_ip, delete_cmd)
            do_cmd(remote_logout_cmd, 30, True)
            do_cmd(remote_delete_cmd, 30, True)

    remote_rm_2nd_iqn_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(white_second_ip_root_password,
                                                                             port, white_second_ip, rm_iqn_cmd)
    remote_rm_2nd_tgt_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(white_second_ip_root_password,
                                                                             port, white_second_ip, rm_tgt_cmd)
    remote_rm_3rd_iqn_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(black_ip_root_password, port,
                                                                             black_list_ip, rm_iqn_cmd)
    remote_rm_3rd_tgt_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(black_ip_root_password, port,
                                                                             black_list_ip, rm_tgt_cmd)

    do_cmd(remote_rm_2nd_iqn_cmd, 60, True).strip()
    do_cmd(remote_rm_2nd_tgt_cmd, 60, True).strip()
    do_cmd(remote_rm_3rd_iqn_cmd, 60, True).strip()
    do_cmd(remote_rm_3rd_tgt_cmd, 60, True).strip()


def check_dns_set():
    """  Check DNS setting in network  """
    print "[Step 2]  Check DNS setting in order to connect to WWW to install some packages"
    ping_res = do_cmd("ping www.baidu.com -c 1", 60, True).strip()

    if ping_res == "":
        print "\n    [ERROR]    Not set dns or dns is not work, please check network settings.\n"
        sys.exit(0)
    elif "icmp_seq=1" in ping_res:
        print "\n    [Success]  DNS works well\n"


def pre_check(cmd, version):
    """
    :param cmd, string, command line
    :param version, string, package version
    """
    try:
        expect_ver = do_cmd(cmd, 30, True).strip()
        if expect_ver != "":
            expect_ver = expect_ver.split()[2]

        return version == expect_ver
    except IndexError as ex:
        print "{}".format(str(ex))


def install_on_remote_check(cmd):
    """
    Check the remote has been install or not install the package, such as pv at client
    return True or False, True means has been install; False means not install
    :param cmd, string, a command line will run on remote server
    """
    res = os.popen(cmd)
    res_info = res.read()

    if len(res_info.split()) &gt; 0:
        return True
    else:
        return False


def install_package():
    """  Install some python package for pytest  """
    python_pip_flag = pre_check("dpkg -l | grep python-pip", "1.0-1build1")
    python_configobj_flag = pre_check("dpkg -l | grep python-configobj", "4.7.2+ds-3build1")
    unzip_flag = pre_check("dpkg -l | grep unzip", "6.0-4ubuntu2.5")
    stress_flag = pre_check("dpkg -l | grep stress", "1.0.1-1ubuntu1")
    pytest_plugins = do_cmd("pytest --fixtures | grep -w plugins | head -n 1", 30, True)

    if os.path.exists("../python_3rd_lib"):
        current_path = os.getcwd()
        client_ip = config.white_list_ip
        passwd = config.white_ip_root_password
        port = config.ssh_port

        print "\n[Step 3]  Install packages ...\n"
        os.chdir("../python_3rd_lib")

        print "    3-1. Upgrade apt source "
        os.system("apt-get update")

        print "    3-2. Install unzip"
        if unzip_flag:
            print "         unzip has been installed, skip\n"
        else:
            os.system("dpkg -i unzip_6.0-4ubuntu2.5_amd64.deb")

        print "    3-3. Install and upgrade python-pip"
        # pylint needs setuptools version &gt;12, so need install a high level version of setuptools
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/setuptools-40.6.3-py2.7.egg"):
            print "         Has been installed setuptools-40.6.3, skip"
        else:
            os.system("unzip -o setuptools-40.6.3.zip; cd setuptools-40.6.3; python setup.py install")

        if python_pip_flag:
            print "         python-pip has been installed, skip\n"
        else:
            os.system("dpkg -i python-pip_1.0-1build1_all.deb")

        # os.system("pip install --upgrade pip")

        print "    3-4. Install python-configobj"
        if python_configobj_flag:
            print "         python-configobj has been installed, skip\n"
        else:
            os.system("dpkg -i python-configobj_4.7.2+ds-3build1_all.deb")

        print "    3-5. Install more-itertools"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/more_itertools-3.0.0-py2.7.egg"):
            print "         Has been installed more_itertools-3.0.0, skip\n"
        else:
            os.system("tar -zxvf more-itertools-3.0.0.tar.gz;"
                      "cd more-itertools-3.0.0/; "
                      "python setup.py install; cd ../")

        print "    3-6. Install zipp"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/zipp-1.0.0-py2.7.egg"):
            print "         Has been installed zipp, skip\n"
        else:
            os.system("tar -zxvf zipp-1.0.0.tar.gz; "
                      "cd zipp-1.0.0/; "
                      "python setup.py install; cd ../")

        print "    3-7. Install pytest"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/pytest-4.6.9-py2.7.egg/pytest.py"):
            print "         pytest has been installed, skip\n"
        else:
            # os.system("pip install -U pytest") for V8.0
            os.system("tar -zxvf pytest-4.6.9.tar.gz; "
                      "cd pytest-4.6.9/; "
                      "python setup.py install; cd ../")

        print "    3-8. Install pytest-progress"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/pytest_progress-1.2.1-py2.7.egg"):
            print "         Plugin of progress has been installed, skip\n"
        else:
            os.system("tar -zxvf pytest-progress-1.2.1.tar.gz; "
                      "cd pytest-progress-1.2.1/; "
                      "python setup.py install; cd ../")

        print "    3-9. Install syslog-tool"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/pytest_cov-2.8.1-py2.7.egg/pytest-cov.pth"):
            print "          Has been installed pytest-cov, skip\n"
        else: 
            os.system("tar -zxvf pytest-cov-2.8.1.tar.gz; "
                      "cd pytest-cov-2.8.1/; "
                      "python setup.py install; cd ../")

        print "    3-10. Install JDK"
        # Modify /etc/profile
        target_file = "/etc/profile"
        res = do_cmd("cat {} | grep JAVA_HOME".format(target_file), 20, True).strip()
        add_content = """
export JAVA_HOME=/opt/jdk1.8.0_161
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
"""

        if os.path.exists("/opt/jdk1.8.0_161/release"):
            print "          Has been installed JDK, skip\n"

            if not res:
                append_write(target_file, add_content)
                os.system(". {}".format(target_file))
        else:
            os.system("tar -zxvf jdk-8u161-linux-x64.tar.gz -C /opt/")

            if not res:
                append_write(target_file, add_content)
                os.system(". {}".format(target_file))

        print "    3-11. Install allure_pytest"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/allure_pytest-2.8.11-py2.7.egg"):
            print "          Has been installed allure_pytest, skip\n"
        else:
            os.system("tar -xvf allure-pytest-2.8.11.tar; "
                      "cd allure-pytest-2.8.11/; "
                      "python setup.py install; cd ../")

        print "    3-12. Install allure_command"

        bashrc_file = "/root/.bashrc"
        allure_cmd_path = "/opt/allure-2.13.2/bin/allure"
        res = do_cmd("cat {} | grep allure".format(bashrc_file), 20, True).strip()
        add_content = "alias allure='{}'".format(allure_cmd_path)

        if os.path.exists(allure_cmd_path):
            print "          Has been installed allure_command, skip\n"

            if not res:
                append_write(bashrc_file, add_content)
                os.system(". {}".format(bashrc_file))
        else:
            os.system("unzip allure-commandline-2.13.2.zip -d /opt/")

            if not res:
                append_write(bashrc_file, add_content)
                os.system(". {}".format(bashrc_file))

        print "    3-13. Install pylint"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/pylint-1.7.6-py2.7.egg/pylint/epylint.py"):
            print "          pylint-1.7.6 has been installed, skip\n"
        else:
            os.system("tar -zxvf pylint-1.7.6.tar.gz; "
                      "cd pylint-1.7.6; "
                      "python setup.py install; cd ../")

        print "    3-14. Install pv at client : {}".format(client_ip)
        pv_cmd = "dpkg -l | grep -w pv"
        remote_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(passwd, port, client_ip, pv_cmd)
        # print remote_cmd
        pv_flag = install_on_remote_check(remote_cmd)
        if pv_flag:
            print "          PV has been installed on client {}, skip\n".format(client_ip)
        else:
            # Sync pv deb to remote
            sync_file_cmd = "scp pv_1.2.0-1_amd64.deb root@{}:/root/".format(client_ip)
            pexpect.run(sync_file_cmd, events={'yes': 'yes', 'password:': passwd + '\n'}, logfile=sys.stdout)

            # Install package on remote
            install_cmd = "dpkg -i /root/pv_1.2.0-1_amd64.deb"
            remote_install_cmd = "sshpass -p {} ssh -p {} -l root {} '{}'".format(passwd, port, client_ip, install_cmd)
            os.system(remote_install_cmd)

        print "    3-15. Remove old ssh key from /root/.ssh/known_hosts for client : {}\n".format(client_ip)
        do_cmd("ssh-keygen -f '/root/.ssh/known_hosts' -R {}".format(client_ip), 30, True)

        print "    3-16. Install stress"
        if stress_flag:
            print "          stress has been installed, skip\n"
        else:
            os.system("dpkg -i stress_1.0.1-1ubuntu1_amd64.deb ")

        print "    3-17. Install syslog-tool"
        do_cmd('cp -r syslog-tool /home/')
        do_cmd('cd /home/syslog-tool; make clean ; make')
        if os.path.exists("/home/syslog-tool/tsyslog.ko"):
            print "          syslog-tool install success\n"
        else:
            do_cmd('cd /home/syslog-tool; make clean ; make')

        print "    3-18. Install pytest-repeat"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/pytest_repeat-0.8.0-py2.7.egg"):
            print "          Has been installed pytest-repeat, skip\n"
        else:
            os.system("tar -zxvf pytest-repeat-0.8.0.tar.gz; "
                      "cd pytest-repeat-0.8.0/; "
                      "python setup.py install; cd ../")

        print "    3-19. Install pytest-timeout"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/pytest_timeout-1.3.4-py2.7.egg"):
            print "          Has been installed pytest-timeout, skip\n"
        else:
            os.system("tar -zxvf pytest-timeout-1.3.4.tar.gz; "
                      "cd pytest-timeout-1.3.4/; "
                      "python setup.py install; cd ../")

        print "    3-20. Install configparser"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/configparser-4.0.2-py2.7.egg"):
            print "          Has been installed configparser, skip\n"
        else:
            os.system("tar -zxvf configparser-4.0.2.tar.gz; "
                      "cd configparser-4.0.2/; "
                      "python setup.py install; cd ../")

        print "    3-21. Install pyparsing"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/pyparsing-2.4.6-py2.7.egg"):
            print "          Has been installed pyparsing, skip\n"
        else:
            os.system("tar -zxvf pyparsing-2.4.6.tar.gz; "
                      "cd pyparsing-2.4.6/; "
                      "python setup.py install; cd ../")

        print "    3-22. Install scandir"
        if os.path.exists("/usr/local/lib/python2.7/dist-packages/scandir-1.10.0-py2.7-linux-x86_64.egg"):
            print "          Has been installed scandir, skip\n"
        else:
            os.system("tar -zxvf scandir-1.10.0.tar.gz; "
                      "cd scandir-1.10.0/; "
                      "python setup.py install; cd ../")

        os.chdir(current_path)

    else:
        print "         [ERROR]    Path {} is not exists!".format("../python_3rd_lib")
        sys.exit(2)


def del_report_dir():
    """  Delete the report directory  """
    print "    5 [Check]    Check if the report directory is deleted\n"

    if os.path.exists("../report"):
        shutil.rmtree("../report")
        print "      [Success]  Delete report directory success"
    else:
        print "      [SKIP]     No need to delete report directory"

    mkdir_report_path()


def reboot_client_clean_session():
    print "[Step 6]  Restart client, and clean unavailable scsi session\n"

    client_ip = config.white_list_ip

    print "    6-1 [Check]    Power off then power on for client : {}\n".format(client_ip)
    # First, reboot client if it is a VM, then check network
    OSCheck().reboot_client_node()

    print "    6-2 [Check]    Check network of client : {}".format(client_ip)
    for i in xrange(30):
        ping_res = do_cmd("ping {} -c 5".format(client_ip), 60, True).strip()
        if ping_res:
            print "        [Success]  Client of ({}) works well\n".format(client_ip)
            break
        else:
            time.sleep(3)
    else:
        print "        [ERROR]    Client of ({}) is not work, please check network settings.\n".format(client_ip)
        sys.exit(0)

    print "    6-3 [Clean]    Delete all of iqn on client, make sure client will not try " \
          "to re-establish the discard connection\n"
    unlink_unavailable_scsi_session()


def check_cluser_has_san():
    """
    Cluster should has no iSCSI or FC LUN under Default Virtual Storage.
    Otherwise, assigning GW to VS will report "ASSIGN_GWGROUP_ERROR": 1402
    Caused many use cases to fail
    """
    print "    7-1 [Check]    Check SAN devices created on Default Virtual Storage"
    res = do_cmd("scstadmin --list_device", 60, True).strip()

    if 'tgt' in res or 'nulldev' in res:
        print "        [Warn]     Has been create SAN device in Default Virtual " \
              "Storage, now delete it/them!\n"
        from testcasebase.Virtual_Storage.iSCSI import SANManager
        SANManager().env_clean_san()
    else:
        print "        [Success]  SAN device has not been created in Default Virtual Storage.\n"


def check_cluster_health():
    """  pg is all active + clean  """
    print "    7-2 [Check]    Check all PG state"
    try:
        pg_stat = ClusterInfo().get_pg_stat()
        if pg_stat is True:
            print "        [Success]  ALL PG is active+clean.\n"
            return True
        else:
            print "        [ERROR]    All PG is not active+clean, will exit!\n"
            return False
    except RuntimeError:
        print "        [Warn]     ClusterManager failed: no monitors found, " \
              "maybe the cluster has not been created.\n"
        return False


def check_ctdb_status():
    """  Check ctdb status  """
    print "    7-3 [Check]    Check ctdb state"

    for i in xrange(10):
        ctdb_status_ok = do_cmd("ctdb status | grep OK | wc -l", 30, True).strip()
        ctdb_status_not_ok = do_cmd("ctdb status | grep pnn | grep -v OK | wc -l", 30, True).strip()

        if int(ctdb_status_ok) &gt;= 3 and int(ctdb_status_not_ok) == 0:
            print "        [Success]  ctdb status is OK\n"
            break
        else:
            time.sleep(6)
    else:
        print "        [ERROR]    Ctdb is not OK, need more than 3 ctdbs with OK status, so exit!\n"
        sys.exit()


def restart_rgw():
    """
    In order to avoid rgw not starting, here to restart the rgw service of all nodes
    """
    print "    7-4 [Check]    Restart RGW service\n"
    all_nodes = ClusterInfo().get_all_nodes()
    for each_node in all_nodes:
        try:
            do_cmd('ssh {} {}'.format(each_node, config.restart_rgw), 30)
        except Exception as ex:
            do_cmd('ssh {} {}'.format(each_node, config.restart_rgw), 10, True)


def modify_apache_conf():
    """  Modify apache.conf to make session is available  """
    print "    7-5 [Check]    Check apache conf"

    all_nodes = ClusterManager().list_nodes()
    apache_conf = "/etc/apache2/apache2.conf"

    for each_node in all_nodes:
        res = do_cmd("ssh {} cat {} | grep -w KeepAlive | grep -v '#' | "
                     "awk '{{print $2}}'".format(each_node, apache_conf), 30).strip()
        if res == "On":
            print "        [Action]   Start to modify ({}) on node ({}) to " \
                  "change KeepAlive to Off".format(apache_conf, each_node)
            do_cmd('ssh {} \"sed -i \'s/KeepAlive On/KeepAlive Off/\'\" {}'.format(each_node, apache_conf), 30)
            do_cmd("ssh {} {}".format(each_node, config.restart_apache))
        else:
            print "        [Success]  Has been changed KeepAlive from On to Off on node : ({})".format(each_node)


def modify_webpy_session():
    """  Modify /usr/lib/cgi-bin/ezs3/index.py, to change session from 1800 to 86400(24Hours)  """
    index_py = "/usr/lib/cgi-bin/ezs3/index.py"
    print "\n    7-6 [Check]    Check  session timeout in {}".format(index_py)

    if not os.path.exists(index_py):
        print "    [ERROR]    File of {} does not exist"
    else:
        all_nodes = ClusterManager().list_nodes()
        for each_node in all_nodes:
            res = do_cmd("ssh {} cat {} | grep web.config.session_parameters | "
                         " grep timeout | awk '{{print $NF}}'".format(each_node, index_py), 30).strip()
            if res == '1800':
                print "        [Action]   Start to modify ({}) on node ({}) to " \
                  "change session from 1800 to 86400".format(index_py, each_node)
                do_cmd('ssh {} \"sed -i \'s/ = 1800/ = 86400/\'\" {}'.format(each_node, index_py), 30)
                do_cmd("ssh {} {}".format(each_node, config.restart_apache))
            else:
                print "        [Success]  Has been changed session from 1800 to 86400 " \
                      "on node : ({})".format(each_node)


def check_disk_nums():
    """  Check disk numbers, each vm has more than 6 disks  """
    print "    7-7 [Check]    Check disk nums"
    all_nodes_ip = ClusterInfo().get_all_nodes()
    for each_node in all_nodes_ip:
        disks = do_cmd("ssh {} lsscsi | grep -v INTEL | grep -v NVME | grep "
                       "disk | wc -l".format(each_node), 30, True).strip()
        if int(disks) &lt; 6:
            print "        [ERROR]    Disk member on node : ({}) is not match automation test.".format(each_node)
            sys.exit()
        break
    else:
        print "        [Success]  Check disk numbers pass.\n"


def run_create_cluster():
    """  Create the cluster   """
    is_created_cluster = False
    is_config_cluster = False
    is_cluster_health = False

    res = do_cmd("ceph -s", 90, True).strip()
    if res == '':
        # Not create cluster
        is_created_cluster = False
        is_config_cluster = False
        is_cluster_health = False
    else:
        if 'fsmap' not in res or 'no osds' in res or "client io" not in res:
            # Create cluster, but not create OSD/MDS
            is_created_cluster = True
            is_config_cluster = False
            is_cluster_health = False
        elif 'stuck' in res or 'peering' in res or 'recovery' in res or 'osds are down' in res:
            is_created_cluster = True
            is_config_cluster = True
            is_cluster_health = False
        elif "client io" in res and 'fsmap' in res and 'up:active' in res and 'active+clean' in res:
            osd_stat = do_cmd("ceph -s | grep osdmap", 60, True).strip()
            osd_stat = osd_stat.split()
            all_osd = osd_stat[2]
            up_osd = osd_stat[4]
            in_osd = osd_stat[6]
            if int(all_osd) == int(up_osd) and int(up_osd) == int(in_osd):
                is_created_cluster = True
                is_config_cluster = True
                is_cluster_health = True
            else:
                is_created_cluster = True
                is_config_cluster = True
                is_cluster_health = False

    return is_created_cluster, is_config_cluster, is_cluster_health


def check_cluster_state():
    """  Check cluster status   """
    source_path = os.getcwd()
    report_path = mkdir_report_path()

    print "[Step 7]  Start checking that the cluster environment meets the " \
          "requirements for automation case execution\n"

    cluster_state = run_create_cluster()
    # print cluster_state[0], cluster_state[1], cluster_state[2]

    if cluster_state[0] is False:
        # Generate run time of start
        do_cmd("date '+%Y-%m-%d %H:%M:%S' &gt; {}/time.txt".format(report_path), 60)

        print "    7-1 [Check]    Not create cluster. First, create cluster, " \
              "then create&amp;enable OSD/MDS service.\n"
        create_cls_cmd = "PYTHONPATH=. py.test -v -s --cache-clear --full-trace --alluredir ../report/json " \
                         "{}/prepare/create_cluster/test_cluster_creation_wizard.py".format(source_path)
        # print "create_cls_cmd is : {}".format(create_cls_cmd)
        os.system(create_cls_cmd)

        enable_service_cmd = "PYTHONPATH=. py.test -v -s --cache-clear --full-trace --alluredir ../report/json " \
                         "{}/prepare/setup_cluster/test_config_cluster.py".format(source_path)
        # print "enable_service_cmd is : {}".format(enable_service_cmd)
        os.system(enable_service_cmd)

        cluster_flag = check_cluster_health()
        if cluster_flag:
            restart_rgw()
            modify_apache_conf()
            modify_webpy_session()

        cook_file = source_path + os.sep + "cookie.jar"
        if os.path.exists(cook_file):
            os.unlink(cook_file)

        # Check the cluster created result
        res = do_cmd("ceph -s", 60, True).strip()
        if not res:
            print "\n      [ERROR]    Create cluster failed, please to view log of " \
                  "pytest_autotest.log under report directory!!!\n"
            sys.exit()
    elif cluster_state[0] is True and cluster_state[1] is False:
        print "    7-1 [Check]    Not create&amp;enable OSD/MDS service, now create&amp;enable OSD/MDS\n"

        # Generate run time of start
        do_cmd("date '+%Y-%m-%d %H:%M:%S' &gt; {}/time.txt".format(report_path), 60)

        enable_service_cmd = "PYTHONPATH=. py.test -v -s --cache-clear --full-trace --alluredir ../report/json " \
                             "{}/prepare/setup_cluster/test_config_cluster.py".format(source_path)
        # print "enable_service_cmd is : {}".format(enable_service_cmd)
        os.system(enable_service_cmd)
        cluster_flag = check_cluster_health()
        if cluster_flag:
            restart_rgw()
            modify_apache_conf()
            modify_webpy_session()
    elif cluster_state[0] is True and cluster_state[1] is True and cluster_state[2] is False:
        print "    7-1 [Check]    Cluster is not health, Skip to run test case, exit!"
        sys.exit()
    else:
        print "        [Success]  The current tested environment cluster is normal, and all test \n" \
              "                   cases are run directly.\n"

        # Generate  run time of start
        do_cmd("date '+%Y-%m-%d %H:%M:%S' &gt; {}/time.txt".format(report_path), 60)

        check_cluser_has_san()
        cluster_flag = check_cluster_health()
        if cluster_flag:
            check_ctdb_status()
            # check_disk_nums()
            restart_rgw()
            modify_apache_conf()
            modify_webpy_session()


def run_part_or_all_test_case(part=False, case_file=None):
    """
    Running part or all of test case
    :param part, bool, True means to run all of test case
    :param case_file, string, some python file name of case, split by space, the base path is current path
    like "testcase/Function_Test/case_2_Accounts/test_account_ad.py Function_Test/
    case_3_Hosts/Roles/test_SAN_volume_cache.py"
    """
    # If setup cluster failed, no need to run all test case
    # Check cluster and ctdb health status
    cls_health = check_cluster_health()
    if cls_health is False:
        print "\n        [ERROR]    Cluster is not health, so no need to run all test case, exit!"
        sys.exit()
    check_ctdb_status()

    print "[Step 8]  Start to run test cases\n"

    source_path = os.getcwd()
    report_path = mkdir_report_path()

    skip_path = source_path + os.sep + "prepare"

    if not part:
        run_all_cmd = "PYTHONPATH=. py.test -v -s -m 'not migration' --cache-clear --full-trace " \
                      "--cov-report xml:../report/coverage.xml --cov=./ --cov-config .coveragerc --ignore={} " \
                      "--alluredir ../report/json {}".format(skip_path, source_path)

        print "    8-1 Start to run all of test case\n"
        os.system(run_all_cmd)
    else:
        run_part_cmd = "PYTHONPATH=. py.test -v -s --cache-clear --full-trace " \
                      "--cov-report xml:../report/coverage.xml --cov=./ --cov-config .coveragerc " \
                      "--alluredir ../report/json {}".format(case_file)

        print "    8-1 Start to run part of test case\n"
        os.system(run_part_cmd)

    # Move converage source file to report
    coverage_source = source_path + os.sep + ".coverage"
    if os.path.exists(coverage_source):
        do_cmd("mv {} {}/../report".format(coverage_source, source_path))

    # Generate pylint output
    print "    8-2 Start to Generate pylint output\n"

    try:
        do_cmd("pylint --rcfile={}/.pylintrc -f parseable -d I0011,R0801 "
               "{}/testcasebase* | tee {}/../report/pylint.out".format(source_path, source_path, source_path))
    except Exception as ex:
        print "      Generate pylint failed, backend return : ({})\n".format(str(ex))

    # Generate run time of end
    do_cmd("date '+%Y-%m-%d %H:%M:%S' &gt;&gt; {}/time.txt".format(report_path), 60)

    # Compress pytest_autotest.log
    pytest_log_path = "{}/pytest_autotest.log".format(report_path)
    new_name = "{}.gz".format(pytest_log_path)
    if os.path.exists(pytest_log_path):
        do_cmd("tar -zcvf {} {}".format(new_name, pytest_log_path), 60)
    else:
        print "      [ERROR]    No file of {}\n".format(pytest_log_path)

    # Compress html report, if the html is larger than 30M, send email failed
    # html_path = "{}/{}".format(report_path, report_name)
    # if os.path.exists(html_path):
    #     new_name = "{}.gz".format(report_name)
    #     do_cmd("tar -zcvf {}/{} {}".format(report_path, new_name, html_path), 60)
    # else:
    #     print "      [ERROR]    No html file of {}\n".format(html_path)

    # Generate environment.properties for allure
    report_path = get_report_path()
    time_file = report_path + os.sep + "time.txt"
    version_file = report_path + os.sep + "version.txt"
    env_file = report_path + os.sep + "json/environment.properties"

    host_ip = config.public_ips.split()[1]
    start_time = do_cmd("cat {} | head -n 1".format(time_file), 20, True).strip()
    end_time = do_cmd("tac {} | head -n 1".format(time_file), 20, True).strip()
    product_name = do_cmd("cat {}".format(version_file), 20, True).strip()

    write_content = """Host_IP : {}
Start_Time : {}
End_Time : {}
Product_Info : {}
""".format(host_ip, start_time, end_time, product_name)

    do_cmd("echo '{}' &gt; {}".format(write_content, env_file), 30)

    # Generate allure html report
    # do_cmd(". ~/.bashrc;allure generate --clean ../report/json -o ../report/html")
    do_cmd(". /etc/profile;/opt/allure-2.13.2/bin/allure generate --clean ../report/json -o ../report/html")


def main():
    opts, args = getopt.getopt(sys.argv[1:], '-t', ['testcase='])
    for opt_name, opt_value in opts:
        if opt_name == '-t':
            part_flag = True
            break
    else:
        part_flag = False

    print '-' * 80
    run_node_check()

    print '-' * 80
    check_dns_set()

    print '-' * 80
    install_package()

    print '-' * 80
    del_report_dir()

    print '-' * 80
    reboot_client_clean_session()

    print '-' * 80
    check_cluster_state()

    print '-' * 80
    rm_sessions()
    get_test_product_version()
    run_part_or_all_test_case(part=part_flag, case_file=' '.join(args))

    print '-' * 80


if __name__ == "__main__":
    main()
</code></pre>
<h1 id="yu-jenkins-jie-he">与Jenkins结合</h1>
<p>非本文重点，此处省略。</p>
<p>附带脚本</p>
<p>此脚本放在jenkins账号的email-templates目录下:</p>
<pre><code class="language-shell">jenkins@ubuntu-16:~/email-templates$ pwd
/var/lib/jenkins/email-templates
jenkins@ubuntu-16:~/email-templates$ ls -l
total 20
-rw-rw-r-- 1 jenkins jenkins  5697 Mar 27 16:57 allure-report.groovy
-rw-rw-r-- 1 jenkins jenkins 10764 Jun 17  2019 email-template.groovy
jenkins@ubuntu-16:~/email-templates$
</code></pre>
<p>allure-report.groovy文件内容如下：</p>
<pre><code class="language-shell">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;
&lt;style type="text/css"&gt;
/*base css*/
    body
    {
      margin: 0px;
      padding: 15px;
    }

    body, td, th
    {
      font-family: "Lucida Grande", "Lucida Sans Unicode", Helvetica, Arial, Tahoma, sans-serif;
      font-size: 10pt;
    }

    th
    {
      text-align: left;
    }

    h1
    {
      margin-top: 0px;
    }
    a
    {
      color:#4a72af
    }
/*div styles*/

.status{background-color:&lt;%= 
            build.result.toString() == "SUCCESS" ? 'green' : 'red' %&gt;;font-size:28px;font-weight:bold;color:white;width:720px;height:52px;margin-bottom:18px;text-align:center;vertical-align:middle;border-collapse:collapse;background-repeat:no-repeat}
.status .info{color:white!important;text-shadow:0 -1px 0 rgba(0,0,0,0.3);font-size:32px;line-height:36px;padding:8px 0}
&lt;/style&gt;
&lt;body&gt;
&lt;div class="content round_border"&gt;
                &lt;div class="status"&gt;
                        &lt;p class="info"&gt;pytest automation build &lt;%= build.result.toString().toLowerCase() %&gt;&lt;/p&gt;
                &lt;/div&gt;
                &lt;!-- status --&gt;
                        &lt;table&gt;
                                &lt;tbody&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Project:&lt;/th&gt;
                                                &lt;td&gt;${project.name}&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Build ${build.displayName}:&lt;/th&gt;
                                                &lt;td&gt;&lt;a
                                                        href="${rooturl}${build.url}"&gt;${rooturl}${build.url}&lt;/a&gt;&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Product Version:&lt;/th&gt;
                                                &lt;td&gt;&lt;%=build.environment['PRODUCT_VERSION']%&gt;&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Date of build:&lt;/th&gt;
                                                &lt;td&gt;${it.timestampString}&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Build duration:&lt;/th&gt;
                                                &lt;td&gt;${build.durationString}&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;td colspan="2"&gt;&amp;nbsp;&lt;/td&gt;
                                        &lt;/tr&gt;
                                &lt;/tbody&gt;

                        &lt;/table&gt;
                &lt;!-- main --&gt;
        &lt;% def artifacts = build.artifacts
            if(artifacts != null &amp;&amp; artifacts.size() &gt; 0) { %&gt;

                        &lt;b&gt;Build Artifacts:&lt;/b&gt;
                        &lt;ul&gt;
            &lt;%          artifacts.each() { f -&gt; %&gt;
                &lt;li&gt;&lt;a href="${rooturl}${build.url}artifact/${f}"&gt;${f}&lt;/a&gt;&lt;/li&gt;
            &lt;%          } %&gt;
                        &lt;/ul&gt;
        &lt;% } %&gt;
  &lt;!-- artifacts --&gt;

&lt;% 
  lastAllureReportBuildAction = build.getAction(ru.yandex.qatools.allure.jenkins.AllureReportBuildAction.class)
  lastAllureBuildAction = build.getAction(ru.yandex.qatools.allure.jenkins.AllureBuildAction.class)

  if (lastAllureReportBuildAction) {
    allureResultsUrl = "${rooturl}${build.url}allure"
    allureLastBuildSuccessRate = String.format("%.2f", lastAllureReportBuildAction.getPassedCount() * 100f / lastAllureReportBuildAction.getTotalCount())
  }
%&gt;

&lt;%
pylintResultsUrl = "${rooturl}${build.url}violations"
coberturaResultsUrl = "${rooturl}${build.url}cobertura"
%&gt;

&lt;% if (lastAllureReportBuildAction) { %&gt;
&lt;h2&gt;Allure Results&lt;/h2&gt;
&lt;table&gt;
            &lt;tbody&gt;
                        &lt;tr&gt;
                            &lt;th&gt;Total Allure tests run:&lt;/th&gt;
                            &lt;td&gt;&lt;a href="${allureResultsUrl}"&gt;${lastAllureReportBuildAction.getTotalCount()}&lt;/a&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #ffff00;"&gt;Failed:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #ffff00;"&gt;${lastAllureReportBuildAction.getFailedCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #008000;"&gt;Passed:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #008000;"&gt;${lastAllureReportBuildAction.getPassedCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #3366ff;"&gt;Skipped:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #3366ff;"&gt;${lastAllureReportBuildAction.getSkipCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #ff0000;"&gt;Broken:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #ff0000;"&gt;${lastAllureReportBuildAction.getBrokenCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;Success rate: &lt;/th&gt;
                            &lt;td&gt;${allureLastBuildSuccessRate}%  &lt;/td&gt;
                        &lt;/tr&gt;

            &lt;/tbody&gt;
&lt;/table&gt;

&lt;br&gt;
&lt;img lazymap="${allureResultsUrl}/graphMap" src="${allureResultsUrl}/graph" alt="Allure results trend"/&gt;
&lt;/br&gt;

&lt;br&gt;
&lt;font size=4&gt;&lt;b&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Pylint history trend&lt;/b&gt;&lt;/font&gt;
&lt;/br&gt;
&lt;br&gt;
&lt;img lazymap="${pylintResultsUrl}" src="${pylintResultsUrl}/graph" alt="pylint"/&gt;
&lt;/br&gt;

&lt;br&gt;
&lt;font size=4&gt;&lt;b&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Code Coverage history trend&lt;/b&gt;&lt;/font&gt;
&lt;/br&gt;
&lt;br&gt;
&lt;img lazymap="${coberturaResultsUrl}/graphMap" src="${coberturaResultsUrl}/graph"/&gt;
&lt;/br&gt;
&lt;% } %&gt;                  
  &lt;!-- content --&gt;
  &lt;!-- bottom message --&gt;
&lt;/body&gt;
</code></pre>
<p>说明：脚本内容中有一个PRODUCT_VERSION变量，通过‘Inject environment vairables’来定义。</p>
<img class="shadow" src="/img/in-post/inject_env_variables.png" width="800">
<p>上一张Jenkins运行后发email报告图吧:</p>
<img class="shadow" src="/img/in-post/jenkins_allure.png" width="800">
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest skip</title>
    <url>/2020/04/06/pytest_skip/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p><code>pytest.mark.skip</code>  可以标记无法在某些平台上运行的测试功能，或者您希望失败的测试功能，或者硬件不满足用例执行条件的功能。希望满足某些条件才执行某些测试用例，否则<code>pytest</code>会跳过运行该测试用例实际常见场景：跳过非Windows平台上的仅Windows测试，或者跳过依赖于当前不可用的外部资源（例如数据库）的测试，或者跳过VM上执行用例而用例实际需要硬件支撑的测试。</p>
<p>本文只是概述一下skip的简易用法。</p>
<h1 id="shi-zhan">实战</h1>
<h2 id="skip">skip</h2>
<p><code>@pytest.mark.skip</code></p>
<p>跳过执行测试用例，有可选参数reason：跳过的原因，会在执行结果中打印</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-

import pytest


@pytest.fixture(autouse=True)
def login():
    print("====登录====")


def test_case01():
    print("我是测试用例11111")


@pytest.mark.skip(reason="不执行该用例！！因为没写好！！")
def test_case02():
    print("我是测试用例22222")


class Test1:

    def test_1(self):
        print("%% 我是类测试用例1111 %%")

    @pytest.mark.skip(reason="不想执行")
    def test_2(self):
        print("%% 我是类测试用例2222 %%")


@pytest.mark.skip(reason="类也可以跳过不执行")
class TestSkip:
    def test_1(self):
        print("%% 不会执行 %%")
</code></pre>
<p>执行结果：</p>
<pre><code class="language-shell">root@FC-2:~/pytest_framework/src# PYTHONPATH=. pytest --alluredir=../report/test test.py 
============================================================================================================================ test session starts =============================================================================================================================
platform linux2 -- Python 2.7.12, pytest-4.6.11, py-1.8.1, pluggy-0.13.1 -- /usr/bin/python2.7
cachedir: .pytest_cache
rootdir: /root/pytest_framework/src, inifile: pytest.ini
plugins: cov-2.10.0, progress-1.2.1, allure-pytest-2.8.11, repeat-0.8.0, timeout-1.3.4, ordering-0.6
collected 5 items                                                                                                                                                                                                                                                            

test.py::test_case01 PASSED                                                                                                                                                                                                                                             [1/5]
________________________________________________________________________________________________ 1 of 5 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

test.py::test_case02 SKIPPED                                                                                                                                                                                                                                            [2/5]
________________________________________________________________________________________________ 2 of 5 completed, 1 Pass, 0 Fail, 1 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

test.py::Test1::test_1 PASSED                                                                                                                                                                                                                                           [3/5]
________________________________________________________________________________________________ 3 of 5 completed, 2 Pass, 0 Fail, 1 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

test.py::Test1::test_2 SKIPPED                                                                                                                                                                                                                                          [4/5]
________________________________________________________________________________________________ 4 of 5 completed, 2 Pass, 0 Fail, 2 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

test.py::TestSkip::test_1 SKIPPED                                                                                                                                                                                                                                       [5/5]
________________________________________________________________________________________________ 5 of 5 completed, 2 Pass, 0 Fail, 3 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

========================================================================================================================== short test summary info ===========================================================================================================================
SKIPPED [1] test.py:16: 不执行该用例！！因为没写好！！
SKIPPED [1] test.py:26: 不想执行
SKIPPED [1] test.py: 类也可以跳过不执行
==================================================================================================================== 2 passed, 3 skipped in 0.14 seconds =====================================================================================================================
</code></pre>
<p>知识点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>@pytest.mark.skip 可以加在函数上，类上，类方法上</p>
</li>
<li class="lvl-2">
<p>如果加在类上面，类里面的所有测试用例都不会执行</p>
</li>
</ul>
<p>以上小案例都是针对：整个测试用例方法跳过执行，如果想在测试用例执行期间跳过不继续往下执行呢？</p>
<h2 id="pytest-skip-han-shu-ji-chu-shi-yong">pytest.skip()函数基础使用</h2>
<p>作用：在测试用例执行期间强制跳过不再执行剩余内容</p>
<p>类似：在Python的循环里面，满足某些条件则break 跳出循环</p>
<p>示例：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-

import pytest

def test_function():
    n = 1
    while True:
        print("这是我第{n}条用例")
        n += 1
        if n == 5:
            pytest.skip("我跑五次了不跑了")
</code></pre>
<p>执行结果：</p>
<pre><code class="language-shell">root@FC-2:~/pytest_framework/src# PYTHONPATH=. pytest --alluredir=../report/test test2.py 
============================================================================================================================ test session starts =============================================================================================================================
platform linux2 -- Python 2.7.12, pytest-4.6.11, py-1.8.1, pluggy-0.13.1 -- /usr/bin/python2.7
cachedir: .pytest_cache
rootdir: /root/pytest_framework/src, inifile: pytest.ini
plugins: cov-2.10.0, progress-1.2.1, allure-pytest-2.8.11, repeat-0.8.0, timeout-1.3.4, ordering-0.6
collected 1 item                                                                                                                                                                                                                                                             

test2.py::test_function SKIPPED                                                                                                                                                                                                                                         [1/1]
________________________________________________________________________________________________ 1 of 1 completed, 0 Pass, 0 Fail, 1 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

========================================================================================================================== short test summary info ===========================================================================================================================
SKIPPED [1] /root/pytest_framework/src/test2.py:13: 我跑五次了不跑了
========================================================================================================================= 1 skipped in 0.04 seconds ==========================================================================================================================
root@FC-2:~/pytest_framework/src# 
</code></pre>
<h2 id="allow-module-level">allow_module_level</h2>
<p>pytest.skip(msg=“”, allow_module_level=False)</p>
<p>当 allow_module_level=True 时，可以设置在模块级别跳过整个模块</p>
<p>示例：</p>
<pre><code class="language-python">root@FC-2:~/pytest_framework/src# cat test3.py 
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import pytest

if sys.platform.startswith("win"):
    pytest.skip("skipping windows-only tests", allow_module_level=True)


@pytest.fixture(autouse=True)
def login():
    print("====登录====")


def test_case01():
    print("我是测试用例11111")
</code></pre>
<p>执行结果：</p>
<pre><code class="language-shell">root@FC-2:~/pytest_framework/src# PYTHONPATH=. pytest --alluredir=../report/test test3.py 
============================================================================================================================ test session starts =============================================================================================================================
platform linux2 -- Python 2.7.12, pytest-4.6.11, py-1.8.1, pluggy-0.13.1 -- /usr/bin/python2.7
cachedir: .pytest_cache
rootdir: /root/pytest_framework/src, inifile: pytest.ini
plugins: cov-2.10.0, progress-1.2.1, allure-pytest-2.8.11, repeat-0.8.0, timeout-1.3.4, ordering-0.6
collected 1 item                                                                                                                                                                                                                                                             

test3.py::test_case01 PASSED                                                                                                                                                                                                                                            [1/1]
________________________________________________________________________________________________ 1 of 1 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

========================================================================================================================== 1 passed in 0.06 seconds ==========================================================================================================================
root@FC-2:~/pytest_framework/src# 
</code></pre>
<h2 id="skipif">skipif</h2>
<p><code>@pytest.mark.skipif(condition, reason="")</code></p>
<p>作用：希望有条件地跳过某些测试用例</p>
<p>注意：condition需要返回True才会跳过</p>
<p>示例：</p>
<pre><code class="language-python">root@FC-2:~/pytest_framework/src# cat test4.py 
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import pytest

@pytest.mark.skipif(sys.platform == 'win32', reason="does not run on windows")
class TestSkipIf(object):
    def test_function(self):
        print("不能在window上运行")

</code></pre>
<p>执行结果：</p>
<pre><code class="language-shell">root@FC-2:~/pytest_framework/src# PYTHONPATH=. pytest --alluredir=../report/test test4.py 
============================================================================================================================ test session starts =============================================================================================================================
platform linux2 -- Python 2.7.12, pytest-4.6.11, py-1.8.1, pluggy-0.13.1 -- /usr/bin/python2.7
cachedir: .pytest_cache
rootdir: /root/pytest_framework/src, inifile: pytest.ini
plugins: cov-2.10.0, progress-1.2.1, allure-pytest-2.8.11, repeat-0.8.0, timeout-1.3.4, ordering-0.6
collected 1 item                                                                                                                                                                                                                                                             

test4.py::TestSkipIf::test_function PASSED                                                                                                                                                                                                                              [1/1]
________________________________________________________________________________________________ 1 of 1 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

========================================================================================================================== 1 passed in 0.05 seconds ==========================================================================================================================

</code></pre>
<h2 id="tiao-guo-biao-ji">跳过标记</h2>
<p>可以将 pytest.mark.skip 和 pytest.mark.skipif 赋值给一个标记变量在不同模块之间共享这个标记变量若有多个模块的测试用例需要用到相同的 skip 或 skipif ，可以用一个单独的文件去管理这些通用标记，然后适用于整个测试用例集</p>
<p>示例：</p>
<pre><code class="language-python">root@FC-2:~/pytest_framework/src# cat test5.py 
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import pytest

# 标记
skipmark = pytest.mark.skip(reason="不能在window上运行=====")
skipifmark = pytest.mark.skipif(sys.platform == 'win32', reason="不能在window上运行啦啦啦=====")


@skipmark
class TestSkip_Mark(object):

    @skipifmark
    def test_function(self):
        print("测试标记")

    def test_def(self):
        print("测试标记")


@skipmark
def test_skip():
    print("测试标记")

</code></pre>
<p>执行结果：</p>
<pre><code class="language-shell">root@FC-2:~/pytest_framework/src# PYTHONPATH=. pytest --alluredir=../report/test test5.py 
============================================================================================================================ test session starts =============================================================================================================================
platform linux2 -- Python 2.7.12, pytest-4.6.11, py-1.8.1, pluggy-0.13.1 -- /usr/bin/python2.7
cachedir: .pytest_cache
rootdir: /root/pytest_framework/src, inifile: pytest.ini
plugins: cov-2.10.0, progress-1.2.1, allure-pytest-2.8.11, repeat-0.8.0, timeout-1.3.4, ordering-0.6
collected 3 items                                                                                                                                                                                                                                                            

test5.py::TestSkip_Mark::test_function SKIPPED                                                                                                                                                                                                                          [1/3]
________________________________________________________________________________________________ 1 of 3 completed, 0 Pass, 0 Fail, 1 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

test5.py::TestSkip_Mark::test_def SKIPPED                                                                                                                                                                                                                               [2/3]
________________________________________________________________________________________________ 2 of 3 completed, 0 Pass, 0 Fail, 2 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

test5.py::test_skip SKIPPED                                                                                                                                                                                                                                             [3/3]
________________________________________________________________________________________________ 3 of 3 completed, 0 Pass, 0 Fail, 3 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun ________________________________________________________________________________________________

========================================================================================================================== short test summary info ===========================================================================================================================
SKIPPED [1] test5.py:15: 不能在window上运行=====
SKIPPED [1] test5.py:23: 不能在window上运行=====
SKIPPED [1] test5.py: 不能在window上运行=====
========================================================================================================================= 3 skipped in 0.06 seconds ==========================================================================================================================

</code></pre>
<h2 id="pytest-importorskip">pytest.importorskip</h2>
<p><code>pytest.importorskip( modname: str, minversion: Optional[str] = None, reason: Optional[str] = None )</code></p>
<p>作用：如果缺少某些导入，则跳过模块中的所有测试</p>
<p>参数列表</p>
<p><code>modname</code>：模块名<code>minversion</code>：版本号<code>reason</code>：跳过原因，默认不给也行</p>
<p>示例：</p>
<pre><code class="language-python">pexpect = pytest.importorskip("pexpect", minversion="0.3")


@pexpect
def test_import():
    print("test")

</code></pre>
<p>执行结果：</p>
<p>如本版本匹配不是:</p>
<pre><code class="language-shell">Skipped: could not import 'pexpect': No module named 'pexpect'
collected 0 items / 1 skipped
</code></pre>
<p>如果版本对应上：</p>
<pre><code class="language-shell">如果版本对应不上
Skipped: module 'sys' has __version__ None, required is: '0.3'
collected 0 items / 1 skipped
</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>Put S3 objects with metadata</title>
    <url>/2020/04/22/put_s3_object_with_metadata/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>产品引入<code>keepalive</code>，做了HA，在设置了浮动IP情况下，观察测试过程中浮动IP所在节点发生异常（如宕机，断网，<code>keepalived</code>服务挂掉等情况）业务中断时间，为此写了如下测试脚本，通过浮动IP，模拟并发/批量上传S3 对象文件。</p>
<h1 id="jiao-ben">脚本</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*_

from __future__ import unicode_literals

import time
import boto
import logging
import boto.s3.connection

from random import choice
from string import digits
from multiprocessing.pool import ThreadPool

from ezs3.log import EZLog

EZLog.init_handler(logging.INFO, "./s3_ha.log")
logger = EZLog.get_logger("s3")

pool = ThreadPool(processes=100)


def rand_alpha(length=16):
    return ''.join([choice(digits) for i in xrange(length)])


def connect_s3(access_key, secret_key, host):
    logger.info("Connection to S3")
    conn = boto.connect_s3(
           aws_access_key_id=access_key,
           aws_secret_access_key=secret_key,
           host=host,
           is_secure=False,
           calling_format = boto.s3.connection.OrdinaryCallingFormat(),
          )

    return conn


def create_bucket(conn, bucket_name):
    logger.info("Start to create bucket :(%s)", bucket_name)
    try:
        # bucket = conn.get_bucket(bucket_name)
        bucket = conn.create_bucket(bucket_name)
    except:
        bucket = conn.get_bucket(bucket_name)

    return bucket


def input_object(bucket):
    logging.info("Start to input object")
    for i in xrange(100000000):
        key_name = str(i) + '_' + str(time.time())
        key = bucket.new_key(key_name)

        meta_name = rand_alpha()
        meta_value = rand_alpha()
        # key.metadata = { 'name':'xyz', 'meta2':'value2'}
        key.metadata = {meta_name:meta_value}

        key.set_contents_from_string(key_name)
        if i % 1000000 == 0 and i &gt; 0:
            logger.info("Put done one million object")


def thread_pool_input_object():
    results = []
    for i in xrange(1):
        results.append(pool.apply_async(input_object, (bucket,)))

    for (idx, result) in enumerate(results):
        try:
            r = result.get()
        except:
            logger.exception('Failed to put s3 object')


if __name__ == "__main__":
    access_key='8MHV7BB286YXKE9FFF9X'
    secret_key='hstEN5QEODmENh2Vf5KHCGwOwj61XV1KfbkQxJaC'
    host = '10.16.172.76'
    bucket_name = 's3habucket01'

    conn = connect_s3(access_key, secret_key, host)
    bucket = create_bucket(conn, bucket_name)
    thread_pool_input_object()
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>更改pip&amp;easy_install默认安装源</title>
    <url>/2020/05/05/change_pip_install_source/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>pip默认安装源来自国外，很多时候由于墙的原因，导致下载很慢，或者超时，为了解决这个问题，尝试修改了pip默认安装源（具体操作下文介绍）。但在更改默认源后，如果被安装的包有依赖，需要先安装依赖的包，但这个依赖包还是使用的默认源。本文介绍如何解决这些问题。</p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>本文以Ubuntu OS为例进行文档描述。</p>
</li>
</ul>
<h1 id="pip-yu-easy-install">pip 与easy_install</h1>
<p>这两个都是Python的包管理工具，简单来说pip是easy_install的升级版，推荐优先使用pip。</p>
<p>如果python通过源码setup.py文件进行安装，如python <a href="http://setup.py">setup.py</a> install xxx，那么其安装所依赖包的下载镜像源的配置文件为easy_install的配置，所以即便修改了pip的下载镜像配置文件(e.g:<sub>/.pip/pip.conf)是没有效果的，要修改</sub>/.pydistutils.cfg才能起作用，具体方式在下文说明。</p>
<h1 id="guo-nei-an-zhuang-yuan">国内安装源</h1>
<h2 id="an-zhuang-yuan-lie-biao">安装源列表</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>阿里：<a href="https://mirrors.aliyun.com/pypi/simple">https://mirrors.aliyun.com/pypi/simple</a></p>
</li>
<li class="lvl-2">
<p>豆瓣：<a href="http://pypi.douban.com/simple/">http://pypi.douban.com/simple/</a></p>
</li>
<li class="lvl-2">
<p>清华大学：<a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>
</li>
<li class="lvl-2">
<p>中国科学技术大学： <a href="https://pypi.mirrors.ustc.edu.cn/simple">https://pypi.mirrors.ustc.edu.cn/simple</a></p>
</li>
<li class="lvl-2">
<p>华中理工大学： <a href="http://pypi.hustunique.com/simple">http://pypi.hustunique.com/simple</a></p>
</li>
<li class="lvl-2">
<p>山东理工大学： <a href="http://pypi.sdutlinux.org/simple">http://pypi.sdutlinux.org/simple</a></p>
</li>
</ul>
<h2 id="ce-su">测速</h2>
<p>阿里:</p>
<pre><code class="language-shell">root@pytest-70-97:~# ping -c 3 aliyun.com
PING aliyun.com (140.205.60.46) 56(84) bytes of data.
64 bytes from 140.205.60.46: icmp_seq=1 ttl=44 time=9.64 ms
64 bytes from 140.205.60.46: icmp_seq=2 ttl=44 time=8.91 ms
64 bytes from 140.205.60.46: icmp_seq=3 ttl=44 time=9.25 ms

--- aliyun.com ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 8.917/9.272/9.647/0.318 ms
root@pytest-70-97:~#
</code></pre>
<p>豆瓣:</p>
<pre><code class="language-shell">root@pytest-70-97:~# ping -c 3 douban.com
PING douban.com (154.8.131.171) 56(84) bytes of data.
64 bytes from 154.8.131.171: icmp_seq=1 ttl=49 time=25.7 ms
64 bytes from 154.8.131.171: icmp_seq=2 ttl=49 time=26.3 ms
64 bytes from 154.8.131.171: icmp_seq=3 ttl=49 time=25.8 ms

--- douban.com ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 25.784/25.981/26.344/0.256 ms
root@pytest-70-97:~# 
</code></pre>
<p>清华大学:</p>
<pre><code class="language-shell">root@pytest-70-97:~# ping -c 3 tuna.tsinghua.edu.cn
PING tuna.tsinghua.edu.cn (101.6.6.172) 56(84) bytes of data.
64 bytes from 101.6.6.172: icmp_seq=1 ttl=47 time=33.8 ms
64 bytes from 101.6.6.172: icmp_seq=2 ttl=47 time=31.3 ms
64 bytes from 101.6.6.172: icmp_seq=3 ttl=47 time=31.4 ms

--- tuna.tsinghua.edu.cn ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 11045ms
rtt min/avg/max/mdev = 31.311/32.210/33.874/1.195 ms
root@pytest-70-97:~# 

</code></pre>
<p>中国科学技术大学:</p>
<pre><code class="language-shell">root@pytest-70-97:~# ping -c 3 ustc.edu.cn
PING ustc.edu.cn (202.38.64.246) 56(84) bytes of data.
64 bytes from 202.38.64.246: icmp_seq=1 ttl=49 time=16.6 ms
64 bytes from 202.38.64.246: icmp_seq=2 ttl=49 time=16.2 ms
64 bytes from 202.38.64.246: icmp_seq=3 ttl=49 time=16.5 ms

--- ustc.edu.cn ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 11025ms
rtt min/avg/max/mdev = 16.204/16.465/16.602/0.212 ms
root@pytest-70-97:~# 
</code></pre>
<p>华中理工大学:</p>
<pre><code class="language-shell">root@pytest-70-97:~# ping -c 3 hustunique.com
PING hustunique.com (129.211.140.244) 56(84) bytes of data.
64 bytes from 129.211.140.244: icmp_seq=1 ttl=53 time=10.4 ms
64 bytes from 129.211.140.244: icmp_seq=2 ttl=53 time=10.1 ms
64 bytes from 129.211.140.244: icmp_seq=3 ttl=53 time=10.3 ms

--- hustunique.com ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 11022ms
rtt min/avg/max/mdev = 10.182/10.323/10.415/0.131 ms
root@pytest-70-97:~# 
</code></pre>
<p>山东理工大学:</p>
<pre><code class="language-shell">root@pytest-70-97:~# ping -c 3 sdutlinux.org
PING sdutlinux.org (170.178.168.203) 56(84) bytes of data.
64 bytes from becrawl-show.flatreutic.com (170.178.168.203): icmp_seq=1 ttl=51 time=182 ms
64 bytes from becrawl-show.flatreutic.com (170.178.168.203): icmp_seq=2 ttl=51 time=181 ms
64 bytes from becrawl-show.flatreutic.com (170.178.168.203): icmp_seq=3 ttl=51 time=182 ms

--- sdutlinux.org ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2002ms
rtt min/avg/max/mdev = 181.990/182.156/182.343/0.144 ms
root@pytest-70-97:~# 
</code></pre>
<p>从ping效果上看，还是阿里更快一些，故而本文以阿里pip源为示例进行讲述。</p>
<h1 id="xiu-gai-pip-mo-ren-an-zhuang-yuan">修改pip默认安装源</h1>
<h2 id="fang-fa-1-pei-zhi-fang-shi-xiu-gai-yong-jiu-you-xiao">方法1 配置方式修改（永久有效）</h2>
<p>创建或修改pip.conf文件，如果文件或目录不存在，创建之</p>
<pre><code class="language-shell">cd ~
mkdir .pip
cd .pip
vi pip.conf
</code></pre>
<p>添加如下内容：</p>
<pre><code class="language-shell">[global]
index-url=http://mirrors.aliyun.com/pypi/simple/

[install]
trusted-host=mirrors.aliyun.com
</code></pre>
<h2 id="fang-fa-2-ming-ling-fang-shi-lin-shi-xiu-gai">方法2 命令方式临时修改</h2>
<p><code>pip install -i https://mirrors.aliyun.com/pypi/simple fabric</code></p>
<h1 id="geng-gai-easy-install-mo-ren-an-zhuang-yuan">更改easy_install默认安装源</h1>
<p>这个主要是解决开篇提及到的pip安装有依赖包时没有使用指定的源问题。</p>
<p>打开<code>pydistutils.cfg</code></p>
<p><code>vi ~/.pydistutils.cfg </code></p>
<p>写入以下内容</p>
<pre><code class="language-shell">[easy_install]
index_url = https://mirrors.aliyun.com/pypi/simple
</code></pre>
<h1 id="an-zhuang-ce-shi">安装测试</h1>
<p>读取了<code>requirements.txt(pip install -r requirements.txt)</code>，安装效果如下：</p>
<img class="shadow" src="/img/in-post/pip_install_test.png" width="1200">
<p>发现已经不在使用python官方源了，换成了阿里的源。</p>
<h1 id="zong-shu">综述</h1>
<p>只有同时修改了pip 和 easy_install的默认安装源，才能彻底解决pip install时使用指定安装源。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Megacli详解</title>
    <url>/2020/05/06/megacli_guide/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>通常，我们使用的DELL/HP/IBM三家的机架式PC级服务器阵列卡是从LSI的卡OEM出来的，DELL和IBM两家的阵列卡原生程度较高， 没有做太多封装，可以用原厂提供的阵列卡管理工具进行监控；而HP的阵列卡一般都做过封装了，因此需要使用自身特有的管理工具来监控。本文以几种常用的阵列卡为例，展示其阵列卡及硬盘监控的方法。</p>
<p>DELL SAS 6/iR卡，全称LSI Logic SAS1068E，只支持RAID 0, RAID 1, RAID 1+0, 不支持RAID 5等高级RAID特性，不支持阵列卡电池。<br>
DELL PERC PERC H700卡，全称LSI Logic MegaRAID SAS 2108，支持各种RAID级别及高级特性，可选配阵列卡电池。<br>
DELL PERC H310 Mini卡 ，全称LSI Logic / Symbios Logic MegaRAID SAS 2008，支持常见RAID级别，不支持高级RAID特性，不支持阵列卡电池。<br>
IBM ServeRAID M5014 SAS/SATA Controller卡，全称LSI Logic / Symbios Logic MegaRAID SAS 2108，支持各种RAID级别及高级特性，可选配阵列卡电池。<br>
IBM ServeRAID-MR10i SAS/SATA Controller卡，全称LSI Logic / Symbios Logic MegaRAID SAS 1078，支持常见RAID级别，不支持高级RAID特性，可选配阵列卡电池，这个卡其实和DELL的PERC 6/i卡是一样的，都是基于LSI MegaRAID SAS 1078基础上OEM出来的。</p>
<p>上面是几种常见的阵列卡型号，更多的可以自行查看官方的技术手册。下面我们要继续的是，这些阵列卡以及硬盘如何监控，阵列卡的管理也请查看官方技术手册，不在本文讨论范畴。一般地，支持RAID 5的卡，我们称其为阵列卡，都可以使用LSI官方提供的MegaCli工具来管理，而不支持RAID 5的卡，我们称其为SAS卡，使用lsiutil工具来管理。HP的服务器使用其特有的hpacucli工具来管理。</p>
<h1 id="gong-ju-gai-shu">工具概述</h1>
<h2 id="strong-mega-cli-gong-ju-strong"><strong>MegaCli工具</strong></h2>
<h3 id="mega-cli-adpallinfo-aall-cha-kan-zhen-lie-qia-xin-xi">MegaCli -adpallinfo -aall — 查看阵列卡信息</h3>
<p>-a 参数指定阵列卡的编号，一般服务器上只会配一个阵列卡，因此我们通常指定为 -a0（阵列卡适配器编号，从0开始） 即可，主要关注下面几个信息：</p>
<table>
<thead>
<tr>
<th><strong>状态值</strong></th>
<th><strong>对应含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Product Name : PERC  H710 Mini</td>
<td>阵列卡名称</td>
</tr>
<tr>
<td>FW Package Build:  21.2.0-0007</td>
<td>阵列卡firmware版本号，版本如果太低，建议升级以提高稳定性及性能</td>
</tr>
<tr>
<td>BBU : Present</td>
<td>是否有配BBU电池</td>
</tr>
</tbody>
</table>
<h3 id="mega-cli-cfgdsply-aall-cha-kan-zhen-lie-pei-zhi">MegaCli -cfgdsply -aall — 查看阵列配置</h3>
<table>
<thead>
<tr>
<th><strong>状态值</strong></th>
<th><strong>对应含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Memory: 512MB</td>
<td>阵列卡cache大小，2的N次方，如果不是，说明阵列卡有异常</td>
</tr>
<tr>
<td>Number of dedicated  Hotspares: 0</td>
<td>阵列是否有专用/独享热备盘（如果有多个逻辑磁盘组/disk group，则可以指定一个硬盘用于全局热备，那么该disk group上的专用热备盘数量为0也不用担心），除了RAID  1/RAID 1+0一般不指定热备盘以外，其他几个阵列级别建议都要指定热备盘</td>
</tr>
<tr>
<td>State : Optimal</td>
<td>阵列状态，如果不是 Optimal 就要关注了</td>
</tr>
<tr>
<td>Current Cache  Policy: WriteBack, ReadAheadNone, Direct, Write Cache OK if Bad BBU</td>
<td>阵列读写cache策略，建议写策略设置为FORCE WB，最起码是WB，预读策略可以关掉，意义不大，几乎没影响</td>
</tr>
<tr>
<td>Disk Cache Policy :  Disabled</td>
<td>硬盘cache策略，建议关闭，防止意外时数据丢失</td>
</tr>
<tr>
<td>Current Power  Savings Policy: None</td>
<td>节电策略，建议关闭</td>
</tr>
<tr>
<td>Media Error Count:  0</td>
<td>三个错误计数器，任何一个值大于100就要立刻引起关注，尤其要关注起增长速度。1T以上SATA盘，计数值不够精确，可能所有盘上该值都会大于0，一般重启就会重新清0，如果重启后还是大于0的话，赶紧报修吧。SAS盘的计数值则比较准确。</td>
</tr>
<tr>
<td>Other Error Count:  0</td>
<td></td>
</tr>
<tr>
<td>Predictive Failure  Count: 0</td>
<td></td>
</tr>
<tr>
<td>Firmware state:  Online, Spun Up</td>
<td>查看硬盘状态，如果是unconfigured表示该硬盘未分配加入到阵列中；如果是  unconfigured(bad)表示该盘不但是未分配，而且还坏了，正是“出师未捷身先死”；如果是failed，表示该盘故障无法识别；如果是  rebuilding，表示该盘正在重建数据</td>
</tr>
</tbody>
</table>
<h3 id="mega-cli-adpbbucmd-aall-cha-kan-zhen-lie-qia-dian-chi-xin-xi">MegaCli -adpbbucmd -aall — 查看阵列卡电池信息</h3>
<table>
<thead>
<tr>
<th><strong>状态值</strong></th>
<th><strong>对应含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Temperature: 39 C</td>
<td>查看电池温度，如果相比上一次查看高出不少，就需要关注了，或者可以根据经验设置一个基线值</td>
</tr>
<tr>
<td>Battery State:  Optimal</td>
<td>电池状态，如果不是为Optimal，就需要关注了</td>
</tr>
<tr>
<td>Charger Status:  Complete</td>
<td>电池充放电状态</td>
</tr>
<tr>
<td>isSOHGood: Yes</td>
<td>电池状态，如果不是为Yes，需要关注</td>
</tr>
<tr>
<td>Relative State of  Charge: 93 %</td>
<td>当前电量，当电量低于15%，或者电池坏掉时，默认都会将写策略从WB改成WT，除非设定为FORCE WB策略</td>
</tr>
<tr>
<td>Max Error = 0 %</td>
<td>电池是否有错误信息</td>
</tr>
<tr>
<td>Next Learn time:  Tue Oct 14 22:06:50 2014</td>
<td>电池充放电时间，注意这是美国时间。另外，新的阵列卡电池很多改成电容式的了，也就不需要重复充放电了</td>
</tr>
</tbody>
</table>
<h2 id="lsiutil-gong-ju">lsiutil工具</h2>
<p>lsiutil有交互和非交互两种方式，作为监控，我们肯定选择非交互模式。想要使用交互模式的，可以根据非交互模式自行练习。</p>
<h3 id="lsiutil-p-1-a-20-12-0-0-cha-kan-ying-pan-ji-shu-qi">lsiutil -p 1 -a 20,12,0,0 — 查看硬盘计数器</h3>
<p>Invalid DWord Count 2,563 — 任何一个值大于0，都需要引起关注</p>
<p>Running Disparity Error Count 2,366</p>
<p>Loss of DWord Synch Count 0</p>
<p>Phy Reset Problem Count 0</p>
<h3 id="lsiutil-p-1-a-21-1-0-0-0-cha-kan-luo-ji-juan-zhuang-tai">lsiutil -p 1 -a 21,1,0,0,0 — 查看逻辑卷状态</h3>
<table>
<thead>
<tr>
<th><strong>状态值</strong></th>
<th><strong>对应含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Volume State:  optimal, enabled</td>
<td>逻辑卷健康状况</td>
</tr>
<tr>
<td>Volume draws from  Hot Spare Pools: 0</td>
<td>是否有热备</td>
</tr>
<tr>
<td>Volume Size 139392  MB, 2 Members</td>
<td>由几块硬盘组成</td>
</tr>
<tr>
<td>Primary is PhysDisk  1 (Bus 0 Target 9)</td>
<td>物理硬盘1</td>
</tr>
<tr>
<td>Secondary is  PhysDisk 0 (Bus 0 Target 3)</td>
<td>物理硬盘0</td>
</tr>
</tbody>
</table>
<h3 id="lsiutil-p-1-a-21-2-0-0-0-cha-kan-wu-li-ying-pan-zhuang-tai">lsiutil -p 1 -a 21,2,0,0,0 — 查看物理硬盘状态</h3>
<table>
<thead>
<tr>
<th><strong>状态值</strong></th>
<th><strong>对应含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>PhysDisk 0 is Bus 0  Target 3</td>
<td>编号</td>
</tr>
<tr>
<td>PhysDisk State:  online</td>
<td>状态</td>
</tr>
<tr>
<td>Error Count 13,  Last Error: Command = 28h, Key = 3, ASC/ASCQ = 11h/00h</td>
<td>错误计数器，大于0的话，就需要引起关注</td>
</tr>
</tbody>
</table>
<h2 id="hpacucli-gong-ju">hpacucli工具</h2>
<p>hpacucli工具查看阵列、硬盘、电池信息，其实就只要一条指令：</p>
<p><strong>hpacucli ctrl all show config detail — 查看阵列详细信息、配置</strong></p>
<table>
<thead>
<tr>
<th><strong>状态值</strong></th>
<th><strong>对应含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Controller Status:  OK</td>
<td>阵列卡状态</td>
</tr>
<tr>
<td>Firmware Version:  1.18</td>
<td>firmware版本，太低了建议升级，以提高稳定性及性能</td>
</tr>
<tr>
<td>Cache Board  Present: True</td>
<td>是否配备了cache模块</td>
</tr>
<tr>
<td>Cache Status: OK</td>
<td>cache模块状态</td>
</tr>
<tr>
<td>Cache Ratio: 100%  Read / 0% Write</td>
<td>cache策略，此处只有读cache，不用于写cache，因为没有bbu电池，见下方结果</td>
</tr>
<tr>
<td>Drive Write Cache:  Disabled</td>
<td>关闭磁盘cache</td>
</tr>
<tr>
<td>Total Cache Size:  256 MB</td>
<td>cache大小</td>
</tr>
<tr>
<td>Total Cache Memory  Available: 208 MB</td>
<td>实际可用cache大小，和理论cache大小不一样，说明cache模块可能有问题</td>
</tr>
<tr>
<td>No-Battery Write  Cache: Disabled</td>
<td>关闭FORCEWB策略</td>
</tr>
<tr>
<td>Battery/Capacitor  Count: 0</td>
<td>阵列卡BBU电池数量为0，也就是没有BBU模块</td>
</tr>
<tr>
<td>Battery/Capacitor  Status: Failed (Replace Batteries)</td>
<td>阵列卡BBU电池状态，这里显示是错误状态，需要及时更换</td>
</tr>
<tr>
<td>Array: A</td>
<td>第一个乌列阵列，编号从A开始，依次是A、B、C</td>
</tr>
<tr>
<td>Status: OK</td>
<td>物理阵列状态</td>
</tr>
<tr>
<td>Logical Drive: 1</td>
<td>第一个逻辑卷，编号从1开始</td>
</tr>
<tr>
<td>Fault Tolerance:  RAID 5</td>
<td>第一个逻辑卷的阵列级别</td>
</tr>
<tr>
<td>Status: OK</td>
<td>第一个逻辑卷状态</td>
</tr>
<tr>
<td>Caching: Enabled</td>
<td>第一个逻辑卷是否启用了cache策略</td>
</tr>
<tr>
<td>physicaldrive  1I:1:1</td>
<td>第一块物理硬盘，编号从1开始</td>
</tr>
<tr>
<td>Status: OK</td>
<td>第一块物理硬盘状态</td>
</tr>
<tr>
<td>Firmware Revision:  HPDA</td>
<td>第一块物理硬盘firmware，如果太低，也需要及时升级，HP的硬盘每个批次都有不同的firmware</td>
</tr>
</tbody>
</table>
<h1 id="megacli-shi-jian">Megacli实践</h1>
<h2 id="cha-kan-you-feng-xian-de-pan">查看有风险的盘</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -LDPDinfo -A0 |grep "Device Id" |awk '{print $3}' |xargs -I {} smartctl -a -d megaraid,{} /dev/sdc |grep -Ei "^187|^188|^197|^198|Reallocated_Sector_Ct" | xargs -I{} echo {} </code></p>
<h2 id="cha-kan-ci-pan-de-smart-xin-xi">查看磁盘的smart信息</h2>
<p>如果磁盘在RAID卡上：</p>
<p>（1）先获取磁盘的device id</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 PDList aall </code></p>
<p>这里的输出，会有ES信息，同时还会有device id</p>
<p>（2）根据device id，查询smart信息</p>
<p><code>smartctl -a -d megaraid,11 /dev/sdc </code></p>
<p>这里的11就是磁盘的device id，哪怕后面的/dev/sdc不存在，获取是这颗磁盘不属于sdc，也能输出正确的信息，只要device id是正确的就行。</p>
<p>如果不在RAID卡上，直接<code>smartctl -a /dev/sdc </code></p>
<h2 id="shou-gong-pei-zhi-chu-shi-hua">手工配置初始化</h2>
<pre><code class="language-shell">/opt/MegaRAID/MegaCli/MegaCli64 -LDInit -start –L0 -a0         # 快速初始化

/opt/MegaRAID/MegaCli/MegaCli64 -LDInit -start -full –L0 -a0     # 完全初始化

/opt/MegaRAID/MegaCli/MegaCli64 -LDInit -progdsply -L0 -a0      # 显示初始化的进度

/opt/MegaRAID/MegaCli/MegaCli64 -LDInit -abort -L0 -a0        # 结束完全初始化

/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -Abort -LALL -aALL # 忽略初始化

/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -ProgDsply -LALL -aALL
</code></pre>
<h2 id="she-zhi-raid-cache">设置RAID cache</h2>
<pre><code class="language-shell">/opt/MegaRAID/MegaCli/MegaCli64 -ldinfo -l1 -a0

/opt/MegaRAID/MegaCli/MegaCli64 -ldsetprop cached -l1 -a0

/opt/MegaRAID/MegaCli/MegaCli64 -ldinfo -l1 -a0

</code></pre>
<h2 id="xian-shi-rebuid-jin-du">显示Rebuid进度</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDRbld -ShowProg -physdrv[20:2] -aALL </code></p>
<h2 id="cha-kan-e-s">查看E S</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aAll -NoLog | grep -Ei "(enclosure|slot)" </code></p>
<h2 id="cha-kan-suo-you-ying-pan-de-zhuang-tai">查看所有硬盘的状态</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aAll -NoLog  </code></p>
<p>如果有热备，则 Firmware State会显示为hotspace</p>
<h2 id="cha-kan-copyback-jin-du">查看copyback进度</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDCpyBk -ShowProg -PhysDrv[33:3] -a0 </code></p>
<h2 id="cha-kan-suo-you-virtual-disk-de-zhuang-tai">查看所有Virtual Disk的状态</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -LdPdInfo -aAll -NoLog</code></p>
<p>RAID Level对应关系：</p>
<pre><code class="language-shell">RAID Level : Primary-1, Secondary-0, RAID Level Qualifier-0	RAID 1
RAID Level : Primary-0, Secondary-0, RAID Level Qualifier-0	RAID 0
RAID Level : Primary-5, Secondary-0, RAID Level Qualifier-3	RAID 5
RAID Level : Primary-1, Secondary-3, RAID Level Qualifier-0	RAID 10
</code></pre>
<h2 id="zai-xian-zuo-raid">在线做Raid</h2>
<pre><code class="language-shell">/opt/MegaRAID/MegaCli/MegaCli64 -CfgLdAdd -r0 [0:11] WB NORA Direct CachedBadBBU -strpsz64 -a0 -NoLog
/opt/MegaRAID/MegaCli/MegaCli64 -CfgLdAdd -r5 [12:2,12:3,12:4,12:5,12:6,12:7] WB Direct -a0 
</code></pre>
<h2 id="rang-ying-pan-led-deng-shan-shuo-ding-wei">让硬盘LED灯闪烁（定位）</h2>
<pre><code class="language-shell">    1、  MegaCli  -AdpSetProp UseDiskActivityforLocate -1 -a0 
    2、  MegaCli  -PdLocate  -start  –physdrv[E:S]  -a0  让硬盘LED灯闪烁
    3、  MegaCli  -PdLocate  -stopt  –physdrv[E:S]  -a0 停掉硬盘LED灯
</code></pre>
<h2 id="qing-chu-foreign-zhuang-tai">清除Foreign状态</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -a0 </code></p>
<h2 id="cha-kan-raid-zhen-lie-zhong-diao-xian-de-pan">查看RAID阵列中掉线的盘</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -pdgetmissing -a0 </code></p>
<h2 id="ti-huan-pi-diao-de-mo-kuai">替换坏掉的模块</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -pdreplacemissing -physdrv[12:10] -Array5 -row0 -a0 </code></p>
<h2 id="shou-dong-kai-qi-rebuid">手动开启rebuid</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -pdrbld -start -physdrv[12:10] -a0 </code></p>
<h2 id="she-zhi-hot-spare">设置HotSpare</h2>
<pre><code class="language-shell">/opt/MegaRAID/MegaCli/MegaCli64 -pdhsp -set [-Dedicated [-Array2]] [-EnclAffinity] [-nonRevertible] -PhysDrv[4:11] -a0
/opt/MegaRAID/MegaCli/MegaCli64 -pdhsp -set [-EnclAffinity] [-nonRevertible] -PhysDrv[32：1}] -a0
</code></pre>
<h2 id="guan-bi-rebuild">关闭Rebuild</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpAutoRbld -Dsbl -a0 </code></p>
<h2 id="she-zhi-rebuild-de-su-lu">设置rebuild的速率</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpSetProp RebuildRate -30 -a0 </code></p>
<h2 id="cha-kan-raid-zu-cheng-yuan">查看RAID组成员</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64  -LdPdInfo -aAll </code></p>
<h2 id="qiang-zhi-xiu-gai-raid-qia-you-write-through-dao-write-back-fang-fa">强制修改RAID卡由write through到write back 方法</h2>
<p><code>opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp CachedBadBBU -Lall -aALL </code></p>
<p>一般在没有BBU情况下， 要执行如下命令进行修改：</p>
<pre><code class="language-shell">/opt/MegaRAID/MegaCli/MegaCli64 -ldsetprop WB -lall -aall;

/opt/MegaRAID/MegaCli/MegaCli64 -LDSetProp CachedBadBBU -Lall -aALL;

/opt/MegaRAID/MegaCli/MegaCli64 ldinfo lall aall
</code></pre>
<h2 id="cha-raid-qia-xin-xi">查raid卡信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpAllInfo -aALL </code></p>
<h2 id="cha-kan-dian-chi-xin-xi">查看电池信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -aAll </code></p>
<h2 id="cha-kan-raid-qia-ri-zhi">查看raid卡日志</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -FwTermLog -Dsply -aALL </code></p>
<h2 id="xian-shi-gua-pei-qi-ge-shu">显示适配器个数</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -adpCount </code></p>
<h2 id="xian-shi-gua-pei-qi-shi-jian">显示适配器时间</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpGetTime –aALL </code></p>
<h2 id="xian-shi-suo-you-gua-pei-qi-xin-xi">显示所有适配器信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpAllInfo -aAll </code></p>
<h2 id="xian-shi-suo-you-luo-ji-ci-pan-zu-xin-xi">显示所有逻辑磁盘组信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -LDInfo -LALL -aAll  </code></p>
<h2 id="xian-shi-suo-you-de-wu-li-xin-xi">显示所有的物理信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDList -aAll </code></p>
<h2 id="cha-kan-chong-dian-zhuang-tai">查看充电状态</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuStatus -aALL |grep 'Charger Status' </code></p>
<h2 id="xian-shi-bbu-zhuang-tai-xin-xi">显示BBU状态信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuStatus -aALL </code></p>
<h2 id="xian-shi-bbu-rong-liang-xin-xi">显示BBU容量信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuCapacityInfo -aALL </code></p>
<h2 id="xian-shi-bbu-she-ji-can-shu">显示BBU设计参数</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuDesignInfo -aALL </code></p>
<h2 id="xian-shi-dang-qian-bbu-shu-xing">显示当前BBU属性</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpBbuCmd -GetBbuProperties -aALL</code></p>
<h2 id="xian-shi-raid-qia-xing-hao-raid-she-zhi-disk-xiang-guan-xin-xi">显示Raid卡型号，Raid设置，Disk相关信息</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64-cfgdsply -aALL </code></p>
<h2 id="ci-pan-zhuang-tai-de-bian-hua-cong-ba-pan-dao-cha-pan-de-guo-cheng-zhong">磁盘状态的变化，从拔盘，到插盘的过程中</h2>
<p>Device             : Normal --&gt; Damage --&gt; Rebuild --&gt; Normal</p>
<p>Virtual Drive      : Optimal --&gt; Degraded --&gt; Degraded --&gt; Optimal</p>
<p>Physical Drive     : Online --&gt; Failed Unconfigured --&gt; Rebuild --&gt; Online</p>
<h2 id="cha-kan-wu-li-ci-pan-zhuang-tai">查看物理磁盘状态</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDRbld -ShowProg -PhysDrv [Enclosure Device ID:Slot Number] -a0</code></p>
<p>Rebuild 中的物理磁盘状态中会显示：“Firmware state: Rebuild”</p>
<h2 id="yi-wen-ben-jin-du-tiao-yang-shi-xian-shi-rebuild-jin-du">以文本进度条样式显示 Rebuild 进度</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64-pdrbld -progdsply -physdrv[E:S] -aALL </code></p>
<p>屏幕显示类似下面的内容：</p>
<pre><code class="language-shell">Rebuild progress of physical drives...
Enclosure:Slot         Percent Complete           Time Elps
     032 :05   #######################87 %################*******  01:59:07

</code></pre>
<h2 id="cha-kan-raid-qia-rebuild-can-shu">查看 RAID 卡 Rebuild 参数</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64-AdpAllinfo -aALL | grep -i rebuild </code></p>
<p>返回结果类似下面这样</p>
<pre><code class="language-shell">Rebuild Rate                             : 30%
Auto Rebuild                             : Enabled
Rebuild Rate                             : Yes
Force Rebuild                            : Yes
</code></pre>
<h2 id="she-zhi-raid-qia-rebuild-bi-li-wei-60">设置 RAID 卡 Rebuild 比例为60%</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64-AdpSetProp { RebuildRate -60} -aALL </code></p>
<h2 id="shan-chu-quan-ju-re-bei">删除全局热备</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64-PDHSP -Rmv -PhysDrv[E:S] -a0 </code></p>
<h2 id="jiang-wu-li-pan-xia-xian-he-shang-xian">将物理盘下线和上线</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -PDOffline/Online -PhysDrv [E:S] -a0 </code></p>
<h2 id="zai-xian-tian-jia-ci-pan">在线添加磁盘</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64-LDRecon -Start -r5 -Add -PhysDrv[E:S] -L1 -a0</code></p>
<h2 id="shan-chu-zhen-lie">删除阵列</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -CfgLdDel -L1 -a0 </code></p>
<h2 id="cha-kan-ci-pan-huan-cun-ce-lue">查看磁盘缓存策略</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64-LDGetProp -DskCache -LALL -aALL </code></p>
<p>or</p>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -LDGetProp -Cache -LALL -aALL</code></p>
<h2 id="cha-kan-raid-qia-event-log">查看raid卡event log</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpEventLog -GetEvents -f event.log -A0 </code></p>
<h2 id="cha-kan-megacli-de-log">查看Megacli的log</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -fwtermlog -dsply -aALL</code> ，关注里面的error/fail/warn等多个关键字</p>
<h2 id="cha-kan-raid-qia-shi-jian">查看raid卡时间</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -AdpGetTime -A0 ; date </code></p>
<h2 id="stop-yi-zhi-xing-jian-cha">Stop 一致性检查</h2>
<p><code>/opt/MegaRAID/MegaCli/MegaCli64 -LDCC -stop -lall -aall </code></p>
<h1 id="can-kao-wen-dang">参考文档</h1>
<p><code>https://kamaok.org.ua/?p=2507 </code></p>
]]></content>
      <categories>
        <category>Megacli</category>
      </categories>
      <tags>
        <tag>Megacli</tag>
      </tags>
  </entry>
  <entry>
    <title>API获取Jenkins构建信息</title>
    <url>/2020/05/08/get_jenkins_information/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Jenkins 的 REST API 可以从外部调用 Jenkins 实例，一些库例如 jenkins-rest 和 java-client-api 封装了相关 API，可以在 Java 中操作 Jenkins。</p>
<h1 id="xiang-shu">详述</h1>
<p>本文参考jenkins-rest库，将API根据获取的资源类型不同分为6个类别。</p>
<table>
<thead>
<tr>
<th><strong>API类型</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>JobsAP</td>
<td>任务管理（任务信息、创建、修改）</td>
</tr>
<tr>
<td>OBPluginManagerAPI</td>
<td>插件管理（插件信息、安装插件）</td>
</tr>
<tr>
<td>QueueAPI</td>
<td>任务队列相关（队列状态）</td>
</tr>
<tr>
<td>StatisticsAPI</td>
<td>Jenkins统计信息</td>
</tr>
<tr>
<td>CrumbIssuerAPI</td>
<td>系统哈希值信息（用于防御CSRF攻击）</td>
</tr>
<tr>
<td>SystemAPI</td>
<td>Jenkins系统状态（版本、路径）</td>
</tr>
</tbody>
</table>
<h2 id="zhu-yu-ding-yi">术语定义</h2>
<table>
<thead>
<tr>
<th><strong>名词</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>job</td>
<td>任务</td>
</tr>
<tr>
<td>payload</td>
<td>在POST请求中提交的数据</td>
</tr>
<tr>
<td>{optionalFolderPath}</td>
<td>可选参数：任务所在目录的路径</td>
</tr>
<tr>
<td>{project_name}</td>
<td>必须参数：任务名称</td>
</tr>
</tbody>
</table>
<p>注意:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>在 GET/POST 时需要附加 HTTP 认证才能访问 API</p>
</li>
<li class="lvl-2">
<p>本文使用的数据结构可以在 jenkins-rest/domain 中查看详细定义</p>
</li>
</ul>
<h2 id="jobs-xiang-guan-api">Jobs 相关 API</h2>
<h3 id="job-info-huo-qu-ren-wu-xin-xi">job-info 获取任务信息</h3>
<p><code>GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/api/json </code></p>
<p>返回类型：JobInfo</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>description</td>
<td>String</td>
<td>描述</td>
</tr>
<tr>
<td>name</td>
<td>String</td>
<td>项目名称</td>
</tr>
<tr>
<td>url</td>
<td>boolean</td>
<td>路径</td>
</tr>
<tr>
<td>buildable</td>
<td>String</td>
<td>是否可构建</td>
</tr>
<tr>
<td>builds</td>
<td>List<buildinfo></buildinfo></td>
<td>构建记录</td>
</tr>
<tr>
<td>lastBuild</td>
<td>BuildInfo</td>
<td>上次构建记录</td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="build-info-huo-qu-gou-zhu-xin-xi">build-info 获取构筑信息</h3>
<p><code>GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/{number}/api/json </code></p>
<p>返回类型：BuildInfo</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>artifacts</td>
<td>List</td>
<td>artifacts</td>
</tr>
<tr>
<td>actions</td>
<td>Lis</td>
<td>actions</td>
</tr>
<tr>
<td>building</td>
<td>boolean	路径</td>
<td></td>
</tr>
<tr>
<td>description</td>
<td>String</td>
<td>描述</td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="create-shi-yong-xml-wen-jian-chuang-jian-ren-wu">create 使用 XML 文件创建任务</h3>
<p>从 XML 文件中加载任务配置并创建任务</p>
<p><code>POST http://127.0.0.1:8080/createItem </code></p>
<h4 id="can-shu">参数</h4>
<table>
<thead>
<tr>
<th>key</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>任务名称</td>
</tr>
<tr>
<td>payload</td>
<td>XML配置文件</td>
</tr>
</tbody>
</table>
<p>返回类型：RequestStatus</p>
<p>|字段 | 类型 | 说明 |<br>
| ------- | -------------------- |<br>
| value | Boolean |<br>
| errors | List |</p>
<h3 id="get-config-huo-qu-ren-wu-pei-zhi-wen-jian">get-config 获取任务配置文件</h3>
<p><code>GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/config.xml </code></p>
<p>返回类型： String</p>
<h3 id="update-config-geng-xin-ren-wu-pei-zhi-wen-jian">update-config 更新任务配置文件</h3>
<p><code>POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/config.xml </code></p>
<h4 id="can-shu-1">参数</h4>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>payload</td>
<td>XML配置文件</td>
</tr>
</tbody>
</table>
<p>返回类型：Boolean</p>
<h3 id="get-description-huo-qu-ren-wu-miao-shu">get-description 获取任务描述</h3>
<p><code>GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/description </code></p>
<p>返回类型：String</p>
<h3 id="set-description-she-zhi-ren-wu-miao-shu">set-description 设置任务描述</h3>
<p><code>POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/description </code></p>
<h4 id="can-shu-2">参数</h4>
<table>
<thead>
<tr>
<th>key</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>description</td>
<td>描述</td>
</tr>
</tbody>
</table>
<p>返回类型：Boolean</p>
<h3 id="delete-shan-chu-ren-wu">delete 删除任务</h3>
<p><code>POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/doDelete </code></p>
<p>返回类型：RequestStatus</p>
<h3 id="enable-yun-xu-ren-wu">enable允许任务</h3>
<p><code>POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/enable </code></p>
<p>返回类型：Boolean</p>
<h3 id="disable-jin-zhi-ren-wu">disable 禁止任务</h3>
<p><code>POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/disable </code></p>
<p>返回类型：Boolean</p>
<h3 id="build-gou-jian">build 构建</h3>
<p><code>POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/build </code></p>
<p>返回类型： IntegerResponse</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>Integer</td>
<td></td>
</tr>
<tr>
<td>errors</td>
<td>List</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="build-with-params-shi-yong-can-shu-chuang-jian-ren-wu">build-with-params  使用参数创建任务</h3>
<p><code>POST http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/buildWithParameters </code></p>
<h4 id="can-shu-3">参数</h4>
<table>
<thead>
<tr>
<th>key</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>payload</td>
<td>Map&lt;String, List<string>&gt; properties</string></td>
</tr>
</tbody>
</table>
<p>返回类型： IntegerResponse</p>
<h3 id="last-build-number-huo-qu-shang-ci-gou-jian-xu-hao">last-build-number 获取上次构建序号</h3>
<p><code>GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/lastBuild/buildNumber </code></p>
<p>返回类型：Integer</p>
<h3 id="last-build-timestamp-huo-qu-shang-ci-gou-jian-shi-jian-chuo">last-build-timestamp 获取上次构建时间戳</h3>
<p><code>GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/lastBuild/buildTimestamp </code></p>
<p>返回类型：String</p>
<h3 id="progressive-text-huo-qu-gou-jian-kong-zhi-tai-shu-chu">progressive-text 获取构建控制台输出</h3>
<p><code>GET http://127.0.0.1:8080/{optionalFolderPath}job/{project_name}/lastBuild/logText/progressiveText </code></p>
<p>返回类型：ProgressiveText</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>text</td>
<td>String</td>
<td>控制台输出</td>
</tr>
<tr>
<td>size</td>
<td>Integer</td>
<td>字数</td>
</tr>
<tr>
<td>hasMoreData</td>
<td>Boolean</td>
<td>是否有更多数据</td>
</tr>
</tbody>
</table>
<h3 id="crumb-issuer-xi-tong-ha-xi-zhi-xin-xi-yong-yu-fang-yu-csrf-gong-ji">CrumbIssuer 系统哈希值信息（用于防御CSRF攻击）</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>CrumbIssuerApi</p>
</li>
<li class="lvl-2">
<p>path: /crumbIssuer/api/xml</p>
</li>
</ul>
<h4 id="crumb">crumb</h4>
<p><code>GET http://127.0.0.1:8080/crumbIssuer/api/xml?{key}={value} </code></p>
<h5 id="can-shu-4">参数</h5>
<table>
<thead>
<tr>
<th>key</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>xpath</td>
<td>concat(//crumbRequestField,“:”,//crumb)</td>
</tr>
</tbody>
</table>
<p>返回类型：Crumb</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>String</td>
</tr>
<tr>
<td>errors</td>
<td>List</td>
</tr>
</tbody>
</table>
<h3 id="plugin-manager-cha-jian-guan-li-cha-jian-xin-xi-an-zhuang-cha-jian">PluginManager 插件管理（插件信息、安装插件）</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>PluginManagerApi</p>
</li>
<li class="lvl-2">
<p>path: /pluginManager</p>
</li>
</ul>
<h4 id="plugins-cha-jian-lie-biao">plugins 插件列表</h4>
<p><code>GET http://127.0.0.1:8080/pluginManager/api/json </code></p>
<p>返回类型：List<plugin></plugin></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>active</td>
<td>Boolean</td>
<td></td>
</tr>
<tr>
<td>backupVersion	String</td>
<td></td>
<td></td>
</tr>
<tr>
<td>bundled</td>
<td>Boolean</td>
<td></td>
</tr>
<tr>
<td>deleted</td>
<td>Boolean</td>
<td></td>
</tr>
<tr>
<td>downgradable</td>
<td>Boolean</td>
<td></td>
</tr>
<tr>
<td>enabled</td>
<td>Boolean</td>
<td></td>
</tr>
<tr>
<td>longName</td>
<td>String</td>
<td></td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="install-necessary-plugins-an-zhuang-cha-jian">installNecessaryPlugins 安装插件</h3>
<p><code>POST http://127.0.0.1:8080/pluginManager/installNecessaryPlugins </code></p>
<h4 id="can-shu-5">参数</h4>
<p><code>payload: &lt;jenkins&gt;&lt;install plugin="{pluginID}"/&gt;&lt;/jenkins&gt; </code></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>{pluginID}</td>
<td>要安装的插件ID</td>
</tr>
</tbody>
</table>
<p>返回类型：RequestStatus</p>
<h3 id="queue-ren-wu-dui-lie-xiang-guan-dui-lie-zhuang-tai">Queue 任务队列相关（队列状态）</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>QueueApi</p>
</li>
<li class="lvl-2">
<p>path: /queue</p>
</li>
</ul>
<h4 id="queue-suo-you-ren-wu-dui-lie-xin-xi">queue 所有任务队列信息</h4>
<p><code>GET http://127.0.0.1:8080/queue/api/json </code></p>
<p>返回类型：List<queueitem></queueitem></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>blocked</td>
<td>Boolean</td>
<td>是否阻塞</td>
</tr>
<tr>
<td>buildable</td>
<td>Boolean</td>
<td>是否可构建</td>
</tr>
<tr>
<td>id</td>
<td>Integer</td>
<td></td>
</tr>
<tr>
<td>inQueueSince</td>
<td>Long</td>
<td></td>
</tr>
<tr>
<td>params</td>
<td>Map&lt;String, String&gt;</td>
<td>任务参数</td>
</tr>
<tr>
<td>task</td>
<td>Task</td>
<td>Task中包含任务名称和URL</td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="item-ren-wu-dui-lie-xin-xi">item 任务队列信息</h3>
<p><code>GET http://127.0.0.1:8080/queue/item/{queueId}/api/json </code></p>
<h4 id="can-shu-6">参数</h4>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>{queueId}</td>
<td>任务队列ID</td>
</tr>
</tbody>
</table>
<p>返回类型：QueueItem</p>
<h3 id="cancel-qu-xiao-ren-wu-dui-lie">cancel 取消任务队列 |</h3>
<p><code>POST http://127.0.0.1:8080/cancelItem?id={id} </code></p>
<h4 id="can-shu-7">参数</h4>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>{id}</td>
<td>任务队列ID</td>
</tr>
</tbody>
</table>
<p>返回类型：RequestStatus</p>
<h3 id="statistics-tong-ji-xin-xi">Statistics 统计信息</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>StatisticsApi</p>
</li>
<li class="lvl-2">
<p>path: /</p>
</li>
</ul>
<h4 id="overall-load">overall-load</h4>
<p><code>GET http://127.0.0.1:8080/overallLoad/api/json </code></p>
<p>返回类型：OverallLoad</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>availableExecutors</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>busyExecutors</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>connectingExecutors</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>definedExecutors</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>idleExecutors</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>onlineExecutors</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>queueLength</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>totalExecutors</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
<tr>
<td>totalQueueLength</td>
<td>Map&lt;String, String&gt;</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="system-xi-tong-xin-xi">System 系统信息</h4>
<ul class="lvl-0">
<li class="lvl-2">
<p>path: /</p>
</li>
</ul>
<p>返回类型：SystemInfo</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>hudsonVersion</td>
<td>String</td>
<td></td>
</tr>
<tr>
<td>jenkinsVersion</td>
<td>String</td>
<td></td>
</tr>
<tr>
<td>jenkinsSession</td>
<td>String</td>
<td></td>
</tr>
<tr>
<td>instanceIdentity</td>
<td>String</td>
<td></td>
</tr>
<tr>
<td>sshEndpoint</td>
<td>String</td>
<td></td>
</tr>
<tr>
<td>server</td>
<td>String</td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="ju-ji-ge-li-zi">举几个例子</h1>
<h2 id="huo-qu-jenkins-job-zhuang-tai">获取jenkins job状态</h2>
<p><code>oot@node248:~# curl http://172.12.12.234:8080/job/pytest_7.0/lastBuild/api/xml --user jenkins:1</code></p>
<p>结果示例如下:</p>
<pre><code class="language-shell">&lt;freeStyleBuild _class='hudson.model.FreeStyleBuild'&gt;&lt;action _class='hudson.model.CauseAction'&gt;&lt;cause _class='hudson.model.Cause$UserIdCause'&gt;&lt;shortDescription&gt;Started by user jenkins&lt;/shortDescription&gt;&lt;userId&gt;jenkins&lt;/userId&gt;&lt;userName&gt;jenkins&lt;/userName&gt;&lt;/cause&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action _class='hudson.plugins.git.util.BuildData'&gt;&lt;buildsByBranchName&gt;&lt;refsremotesoriginmaster _class='hudson.plugins.git.util.Build'&gt;&lt;buildNumber&gt;68&lt;/buildNumber&gt;&lt;marked&gt;&lt;SHA1&gt;6388b644c4405a31611f179dca6c1e485ad92aa5&lt;/SHA1&gt;&lt;branch&gt;&lt;SHA1&gt;6388b644c4405a31611f179dca6c1e485ad92aa5&lt;/SHA1&gt;&lt;name&gt;refs/remotes/origin/master&lt;/name&gt;&lt;/branch&gt;&lt;/marked&gt;&lt;revision&gt;&lt;SHA1&gt;6388b644c4405a31611f179dca6c1e485ad92aa5&lt;/SHA1&gt;&lt;branch&gt;&lt;SHA1&gt;6388b644c4405a31611f179dca6c1e485ad92aa5&lt;/SHA1&gt;&lt;name&gt;refs/remotes/origin/master&lt;/name&gt;&lt;/branch&gt;&lt;/revision&gt;&lt;/refsremotesoriginmaster&gt;&lt;/buildsByBranchName&gt;&lt;lastBuiltRevision&gt;&lt;SHA1&gt;6388b644c4405a31611f179dca6c1e485ad92aa5&lt;/SHA1&gt;&lt;branch&gt;&lt;SHA1&gt;6388b644c4405a31611f179dca6c1e485ad92aa5&lt;/SHA1&gt;&lt;name&gt;refs/remotes/origin/master&lt;/name&gt;&lt;/branch&gt;&lt;/lastBuiltRevision&gt;&lt;remoteUrl&gt;git@10.1.12.10:yunzeng_wang/pytest_framework.git&lt;/remoteUrl&gt;&lt;scmName&gt;&lt;/scmName&gt;&lt;/action&gt;&lt;action _class='hudson.plugins.git.GitTagAction'&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action _class='hudson.plugins.violations.ViolationsBuildAction'&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;action&gt;&lt;/action&gt;&lt;artifact&gt;&lt;displayPath&gt;allure-report.zip&lt;/displayPath&gt;&lt;fileName&gt;allure-report.zip&lt;/fileName&gt;&lt;relativePath&gt;allure-report.zip&lt;/relativePath&gt;&lt;/artifact&gt;&lt;building&gt;false&lt;/building&gt;&lt;displayName&gt;#68&lt;/displayName&gt;&lt;duration&gt;87155647&lt;/duration&gt;&lt;estimatedDuration&gt;85209450&lt;/estimatedDuration&gt;&lt;fullDisplayName&gt;pytest_7.0 #68&lt;/fullDisplayName&gt;&lt;id&gt;68&lt;/id&gt;&lt;keepLog&gt;false&lt;/keepLog&gt;&lt;number&gt;68&lt;/number&gt;&lt;queueId&gt;343&lt;/queueId&gt;&lt;result&gt;UNSTABLE&lt;/result&gt;&lt;timestamp&gt;1588762417068&lt;/timestamp&gt;&lt;url&gt;http://172.12.12.234:8080/job/pytest_7.0/68/&lt;/url&gt;&lt;builtOn&gt;&lt;/builtOn&gt;&lt;changeSet _class='hudson.plugins.git.GitChangeSetList'&gt;&lt;kind&gt;git&lt;/kind&gt;&lt;/changeSet&gt;&lt;culprit&gt;&lt;absoluteUrl&gt;http://172.12.12.234:8080/user/shengdan061&lt;/absoluteUrl&gt;&lt;fullName&gt;shengdan061&lt;/fullName&gt;&lt;/culprit&gt;&lt;culprit&gt;&lt;absoluteUrl&gt;http://172.12.12.234:8080/user/yunzeng_wang&lt;/absoluteUrl&gt;&lt;fullName&gt;yunzeng_wang&lt;/fullName&gt;&lt;/culprit&gt;&lt;/freeStyleBuild&gt;root@node248:~#
root@node248:~#
</code></pre>
<h2 id="huo-qu-mou-yi-ge-gou-jian-ban-ben-hao-wei-56-de-gou-jian-jie-guo">获取某一个构建版本号为56的构建结果</h2>
<p><code>curl http://172.12.12.234:8080/job/pytest_7.0/56/api/xml --user jenkins:1 </code></p>
<h2 id="huo-qu-zui-hou-yi-ci-gou-jian-de-ban-ben-hao">获取最后一次构建的版本号：</h2>
<p><code>curl http://172.12.12.234:8080/job/pytest_7.0/lastBuild/buildNumber --user jenkins:1 </code></p>
<h2 id="huo-qu-mou-ge-xiang-mu-suo-you-gou-jian-ban-ben-hao-de-jie-guo">获取某个项目所有构建版本号的结果</h2>
<p><code>curl http://172.12.12.234:8080/job/pytest_7.0/api/xml --user jenkins:1 </code></p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>以上pytest_7.0为项目名称，jenkins:1是访问jenkins server的账号和密码</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Automation</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins部署pipeline并发执行pytest自动化用例</title>
    <url>/2020/05/13/pipeline_parallel_job/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>目前现有自动化用例数比较多了，在free style jenkins project中顺次执行，耗时1天左右，很明显，耗时太久，急需用例能够并发执行，从而实现节约时间。</p>
<p>本文介绍如何通过pipeline project，实现现有用例执行流程的改造，实现并发执行。</p>
<h1 id="gai-zao-she-ji-nei-rong">改造涉及内容</h1>
<p>针对当前automation project，需要做如下内容调整：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>(1) run.py中，提取出reboot client，生成pylint数据操作</p>
</li>
<li class="lvl-2">
<p>(2) Jenkins节点中email-templates发送email内容groovy脚本调整</p>
</li>
<li class="lvl-2">
<p>(3) 测试代码config目录下autotest.conf，含有多个，命名格式为autotest_ip.conf</p>
</li>
<li class="lvl-2">
<p>(4) 测试代码jenkins目录下生成build properties文件，以及rsync脚本要做修改，主要是路径问题</p>
</li>
</ul>
<p>说明：</p>
<p>第(1)点： 以前用例是顺次执行的，只需要执行一次，一旦调整成并发后，存在每个执行node均会执行一次的情况；</p>
<p>第(3)点： 每个执行用例的集群节点，需要mv autotest_ip.conf为autotest.conf</p>
<p>第(4)点:  free style与pipeline的jenkins project，所需要的workspace与jobspace是不一样的</p>
<h1 id="xu-yao-jenkins-an-zhuang-de-cha-jian">需要Jenkins安装的插件</h1>
<p>Warnings，pipeline相关插件，具体安装本文忽略。</p>
<h1 id="gai-zao-guo-cheng">改造过程</h1>
<h2 id="liu-cheng-shi-yi-tu">流程示意图</h2>
<img class="shadow" src="/img/in-post/pipeline_project_parallel_circuit.png" width="800">
<h2 id="jenkins-project-pei-zhi">Jenkins project配置</h2>
<img class="shadow" src="/img/in-post/pipeline_project_config1.png" width="1200">
<img class="shadow" src="/img/in-post/pipeline_project_config2.png" width="1200">
<img class="shadow" src="/img/in-post/pipeline_project_config3.png" width="1200">
<img class="shadow" src="/img/in-post/pipeline_project_config4.png" width="1200">
<img class="shadow" src="/img/in-post/pipeline_project_config5.png" width="1200">
<img class="shadow" src="/img/in-post/pipeline_project_config6.png" width="1200">
<h2 id="pipelint-jenkinsfile">pipelint Jenkinsfile</h2>
<p>新增了Jenlinsfile，具体内容示例参考如下：</p>
<pre><code class="language-shell">#!groovy

ip_list = IPS.split(',')
ips_size = ip_list.size()

def cluster1_ip = ip_list[0..2][1]
def cluster2_ip = ip_list[3..5][1]

def cluster_ip = "${cluster1_ip} ${cluster2_ip}"

pipeline {
    agent any

    options {
        timestamps()
        }

    stages {
        /* IP check */
        stage("IP Cheeck") {
                agent { label "master" }
                steps {
                    script {
                            sh """
                                if [[ ${ips_size} != 6 ]]; then
                                    echo "IPS is not enough, but give (${ips_size}) nodes to run case"
                                    exit 1
                                fi
                            """
                            }
                       }
            }

        /* Install VM by PVE */
        stage("Initialize") {
                agent { label "master" }
                steps {
                    script {
                            sh """
                            #!/bin/bash -xe
                            echo "Call batch_install_vs.py to install ISO."
                            sshpass -p 1 ssh -p 22 17.1.1.235 -l root \${BAT_INSTALL}
                            """
                        }
                }
            }

        /* Get code */
        stage("Checkout") {
                agent { label "master" }
                steps {
                    retry(2) {
                        timeout(activity: false, time: 60, unit: 'MINUTES') {
                            checkout([$class: 'GitSCM',
                                branches: [[name: GIT_BRANCH]],
                                browser: [$class: 'GitLab', repoUrl: GIT_WEB, version: '12.8'],
                                doGenerateSubmoduleConfigurations: false,
                                extensions: [
                                    [$class: 'CleanBeforeCheckout', deleteUntrackedNestedRepositories: true],
                                    [$class: 'SubmoduleOption', recursiveSubmodules: true],
                                    [$class: 'GitLFSPull'],
                                    [$class: 'PruneStaleBranch']
                                ],
                                submoduleCfg: [],
                                userRemoteConfigs: [[url: GIT_URL]]
                            ])
                        }
                    }
                }
            }

        /* scp code to nodes */
        stage("Scp") {
                agent { label "master" }
                steps {
                    script {                            
                            sh """
                            #!/bin/bash -xe
                            cd \${WORK_SPACE};
                            rm -rf build.properties;
                            rm -rf report;
                            cd jenkins;
                            chmod a+x *;
                            for each_ip in ${cluster_ip}
                                do
                                    echo "Scp code to node : \${each_ip}"
                                    ssh-keygen -f '/var/lib/jenkins/.ssh/known_hosts' -R \${each_ip};
                                    ./rsync_pytest.sh \${WORK_SPACE} \${each_ip} root p@ssw0rd
                                    sleep 1
                                done
                            """
                        }
                    }
            }

        // Parallel Stage
        stage('Parallel Stage') {
            failFast true
            parallel {
                stage('Run test case on Cluster1') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster1_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root ${cluster1_ip} \'cd ${CODE_DIR};python run.py -t testcase/Function_Test/case_02_Accounts/test_02_account_ad.py\'"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }


                    }
                }
                stage('Run test case on Cluster2') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster2_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root ${cluster2_ip} \'cd ${CODE_DIR};cp config/autotest_106.config config/autotest.config;python run.py -t testcase/Function_Test/case_02_Accounts/test_03_account_ldap.py\'"

                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }
                    }
                }
                /*
                stage('Run test case on Cluster3 : ${cluster3_ip}') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster3_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root 172.17.75.96 uname -r"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }


                    }
                }
                stage('Run test case on Cluster4 : ${cluster4_ip}') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster4_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root 172.17.75.96 uname -r"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }


                    }
                }
                stage('Run test case on Cluster5 : ${cluster5_ip}') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster5_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root 172.17.75.96 uname -r"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }


                    }
                }
                */
            }
        }

    /* Merge report */
        stage("Merge Report") {
            agent { label "master" }
            steps {
                script {
                        sh """
                        #!/bin/bash -xe
                        cd \${WORK_SPACE}/jenkins;
                        for each_ip in ${cluster_ip}
                            do
                                echo "Scp report from : (\${each_ip}) to jenkins node"
                                ./rsync_report.sh \${each_ip} root p@ssw0rd \${REPORT_DIR} \${WORK_SPACE} \${JOB_SPACE};
                                ./jenkins_build_properties.sh \${WORK_SPACE}
                            done
                        """
                    }
            }
        }


        stage("Allure Report") {
            agent { label "master" }
            steps {
                script {
                    allure([
                            includeProperties: false,
                            jdk: '',
                            properties: [],
                            reportBuildPolicy: 'ALWAYS',
                            results: [[path: 'report/json']]
                       ])
                    }
                }
        }

        /* Publish Cobertura Coverage Report */
        stage("Publish Cobertura Coverage Report") {
            agent { label "master" }
            steps {
                script {
                       cobertura([
                               autoUpdateHealth: false,
                               autoUpdateStability: false,
                               coberturaReportFile: 'report/coverage.xml',
                               conditionalCoverageTargets: '70, 0, 0',
                               failUnhealthy: false,
                               failUnstable: false,
                               lineCoverageTargets: '80, 0, 0',
                               maxNumberOfBuilds: 0,
                               methodCoverageTargets: '80, 0, 0',
                               onlyStable: false,
                               sourceEncoding: 'ASCII',
                               zoomCoverageChart: false
                       ])
                    }
                }
        }

        /* Generate pylint Report */
        stage('Code Quality Check') {
            agent { label "master" }
            steps {
                script{
                    echo "Run pylint code style check"
        		    // Ignore pylint comments via "-d C"
                    /*
        		    sh """
        		    	. .venv/bin/activate
        			    pylint -d C -f parseable ${SOURCE_ROOT} --exit-zero | tee ${PYLINT_REPORT}
        		    """
                    */
                }
        	}

        	post { 
                always { 
                       // Requires Warnings plugin since Violations plugin is deprecated
        			   // http://wiki.jenkins-ci.org/x/G4CGAQ
        			   warnings canComputeNew: false, canResolveRelativePaths: false, canRunOnFailed: true, categoriesPattern: '', defaultEncoding: '', excludePattern: '', healthy: '', includePattern: '', messagesPattern: '', parserConfigurations: [[parserName: 'PyLint', pattern: "report/pylint.out"]], unHealthy: ''
                }
            }
        }

        /* Send Email */
        stage("Send Email") {
            agent { label "master" }
            steps {
                script {
                        /*
                        build_status = sh (
                            script: """curl http://127.0.0.1:8080/job/${JOB_NAME}/lastBuild/api/json | json_pp | grep result | sed 's/   \"result" : \"//g' | sed 's/",//g'""",
                            returnStdout: true
                            ).trim()
                        echo "build status  ${build_status}"
                       */
                        product_version = sh (
                            script: """sshpass -p btadminuser ssh -p 22 ${cluster1_ip} -l btadminuser ezs3-version""",
                            returnStdout: true
                            ).trim()
                        env.PRODUCT_VERSION = product_version

                        emailext([
                                attachLog: true,
                                attachmentsPattern: 'report/cgi_response_elapsed_time.txt,report/pytest_autotest.log.gz',
                                body: '${SCRIPT, template="allure-pipeline-report.groovy"}',
                                compressLog: true,
                                postsendScript: '$DEFAULT_POSTSEND_SCRIPT',
                                presendScript: '$DEFAULT_PRESEND_SCRIPT',
                                replyTo: '$PROJECT_DEFAULT_REPLYTO',
                                subject: '${JOB_NAME} - ${BUILD_DISPLAY_NAME}',
                                to: 'user01@bigtera.com.cn user02@bigtera.com.cn user03@bigtera.com.cn'
                       ])
                    }
                }
        }
    }
}
</code></pre>
<h2 id="email-template">email template</h2>
<p>Jenkins server处，对应的email template内容参考如下:</p>
<pre><code class="language-shell">&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"&gt;
&lt;style type="text/css"&gt;
/*base css*/
    body
    {
      margin: 0px;
      padding: 15px;
    }

    body, td, th
    {
      font-family: "Lucida Grande", "Lucida Sans Unicode", Helvetica, Arial, Tahoma, sans-serif;
      font-size: 10pt;
    }

    th
    {
      text-align: left;
    }

    h1
    {
      margin-top: 0px;
    }
    a
    {
      color:#4a72af
    }
/*div styles*/

.status{background-color:&lt;%= 
            build.result.toString() == "SUCCESS" ? 'green' : 'red' %&gt;;font-size:28px;font-weight:bold;color:white;width:720px;height:52px;margin-bottom:18px;text-align:center;vertical-align:middle;border-collapse:collapse;background-repeat:no-repeat}
.status .info{color:white!important;text-shadow:0 -1px 0 rgba(0,0,0,0.3);font-size:32px;line-height:36px;padding:8px 0}
&lt;/style&gt;
&lt;body&gt;
&lt;div class="content round_border"&gt;
                &lt;div class="status"&gt;
                        &lt;p class="info"&gt;pytest automation build &lt;%= build.result.toString().toLowerCase() %&gt;&lt;/p&gt;
                &lt;/div&gt;

                &lt;%
                    def envOverrides = it.getAction("org.jenkinsci.plugins.workflow.cps.EnvActionImpl").getOverriddenEnvironment()
                    product_version =  envOverrides["PRODUCT_VERSION"]
                %&gt;

                &lt;!-- status --&gt;
                        &lt;table&gt;
                                &lt;tbody&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Project:&lt;/th&gt;
                                                &lt;td&gt;${project.name}&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Build ${build.displayName}:&lt;/th&gt;
                                                &lt;td&gt;&lt;a
                                                        href="${rooturl}${build.url}"&gt;${rooturl}${build.url}&lt;/a&gt;&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Product Version:&lt;/th&gt;
                                                &lt;!--
                                                &lt;td&gt;&lt;%=build.environment['PRODUCT_VERSION']%&gt;&lt;/td&gt; --&gt;
                                                &lt;td&gt;${product_version}&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Date of build:&lt;/th&gt;
                                                &lt;td&gt;${it.timestampString}&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;th&gt;Build duration:&lt;/th&gt;
                                                &lt;td&gt;${build.durationString}&lt;/td&gt;
                                        &lt;/tr&gt;
                                        &lt;tr&gt;
                                                &lt;td colspan="2"&gt;&amp;nbsp;&lt;/td&gt;
                                        &lt;/tr&gt;
                                &lt;/tbody&gt;

                        &lt;/table&gt;
                &lt;!-- main --&gt;
        &lt;% def artifacts = build.artifacts
            if(artifacts != null &amp;&amp; artifacts.size() &gt; 0) { %&gt;

                        &lt;b&gt;Build Artifacts:&lt;/b&gt;
                        &lt;ul&gt;
            &lt;%          artifacts.each() { f -&gt; %&gt;
                &lt;li&gt;&lt;a href="${rooturl}${build.url}artifact/${f}"&gt;${f}&lt;/a&gt;&lt;/li&gt;
            &lt;%          } %&gt;
                        &lt;/ul&gt;
        &lt;% } %&gt;
  &lt;!-- artifacts --&gt;

&lt;% 
  lastAllureReportBuildAction = build.getAction(ru.yandex.qatools.allure.jenkins.AllureReportBuildAction.class)
  lastAllureBuildAction = build.getAction(ru.yandex.qatools.allure.jenkins.AllureBuildAction.class)

  if (lastAllureReportBuildAction) {
    allureResultsUrl = "${rooturl}${build.url}allure"
    allureLastBuildSuccessRate = String.format("%.2f", lastAllureReportBuildAction.getPassedCount() * 100f / lastAllureReportBuildAction.getTotalCount())
  }
%&gt;

&lt;%
pylintResultsUrl = "${build.environment['JOB_URL']}warnings50/trendGraph"
coberturaResultsUrl = "${rooturl}${build.url}cobertura"
%&gt;

&lt;% if (lastAllureReportBuildAction) { %&gt;
&lt;h2&gt;Allure Results&lt;/h2&gt;
&lt;table&gt;
            &lt;tbody&gt;
                        &lt;tr&gt;
                            &lt;th&gt;Total Allure tests run:&lt;/th&gt;
                            &lt;td&gt;&lt;a href="${allureResultsUrl}"&gt;${lastAllureReportBuildAction.getTotalCount()}&lt;/a&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #ffff00;"&gt;Failed:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #ffff00;"&gt;${lastAllureReportBuildAction.getFailedCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #008000;"&gt;Passed:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #008000;"&gt;${lastAllureReportBuildAction.getPassedCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #3366ff;"&gt;Skipped:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #3366ff;"&gt;${lastAllureReportBuildAction.getSkipCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;&lt;span style="color: #000000; background-color: #ff0000;"&gt;Broken:&lt;/span&gt;&lt;/th&gt;
                            &lt;td&gt;&lt;span style="color: #000000; background-color: #ff0000;"&gt;${lastAllureReportBuildAction.getBrokenCount()} &lt;/span&gt;&lt;/td&gt;
                        &lt;/tr&gt;
                        &lt;tr&gt;
                            &lt;th&gt;Success rate: &lt;/th&gt;
                            &lt;td&gt;${allureLastBuildSuccessRate}%  &lt;/td&gt;
                        &lt;/tr&gt;

            &lt;/tbody&gt;
&lt;/table&gt;

&lt;br&gt;
&lt;img lazymap="${allureResultsUrl}/graphMap" src="${allureResultsUrl}/graph" alt="Allure results trend"/&gt;
&lt;/br&gt;

&lt;br&gt;
&lt;font size=4&gt;&lt;b&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Pylint history trend&lt;/b&gt;&lt;/font&gt;
&lt;/br&gt;
&lt;br&gt;
&lt;img src="${pylintResultsUrl}/png?url=PRIORITY"/&gt;
&lt;/br&gt;

&lt;br&gt;
&lt;font size=4&gt;&lt;b&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Code Coverage history trend&lt;/b&gt;&lt;/font&gt;
&lt;/br&gt;
&lt;br&gt;
&lt;img lazymap="${coberturaResultsUrl}/graphMap" src="${coberturaResultsUrl}/graph"/&gt;
&lt;/br&gt;
&lt;% } %&gt;                  
  &lt;!-- content --&gt;
  &lt;!-- bottom message --&gt;
&lt;/body&gt;
</code></pre>
<h2 id="yun-xing-xiao-guo">运行效果</h2>
<p>Jenkins pipeline project流程图：</p>
<img class="shadow" src="/img/in-post/pipeline_Process_rendering.png" width="1200">
<p>Jenkins send email效果图：</p>
<img class="shadow" src="/img/in-post/pipeline_send_email1.png" width="1200">
<img class="shadow" src="/img/in-post/pipeline_send_email2.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Jenkins</tag>
        <tag>pytest</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux开机启动，进入welcome to emergency mode</title>
    <url>/2020/05/21/boot_machine_met_welcome_to_emergency_mode/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Ubuntu 18.04系统, 执行reboot -f后，网络不通，通过IPMI console查看，发现出现 ‘welcome to emergency mode!’，详细信息如下图所示：</p>
<pre><code class="language-shell">welcome to emergency mode! after logging in, type "journalctl -xb" to view system logs，
"systemctl reboot" to reboot ，"systemctl default" to try again to boot into default mode.
give root password for maintenance(Control-D)
</code></pre>
<img class="shadow" src="/img/in-post/welcome_to_emergency_mode.png" width="1200">
<h1 id="wen-ti-jie-jue">问题解决</h1>
<p>按照提示操作：Control-D， systemctl reboot 命令后，依然如此。</p>
<p>考虑到当时产品有停用过ES(ElasticSearch)，由于存在bug，导致ES对应存储挂载点并没有被umount掉，更没有更新/etc/fstab，但是自己使用gdisk命令，重新格式化了这个分区，并dd擦写了上面的部分数据。可能是这个原因, 导致重启系统出现此界面。</p>
<p>想到这里，开始动手检查/etc/fstab内容，果然是有对应一条ES mount 记录：</p>
<img class="shadow" src="/img/in-post/es_disk_mount_point.png" width="1200">
<p>删除掉它，并重启机器。</p>
<h1 id="xiao-jie">小结</h1>
<p>报这个错误多数情况下是因为/etc/fstab文件的错误。注意一下是不是加载了外部硬盘、存储器或者是网络共享空间，在重启时没有加载上导致的。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>控制keepalive VIP漂移范围</title>
    <url>/2020/05/21/keepalive_contro_vip_floating_range/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>产品有配置keepalive功能，但该功能目前仅通过priority来控制VIP在不同节点间漂移，此处的不同节点，是集群内部的所有节点。</p>
<p>我们先看看下各个节点（以3节点为例），keepalive.conf内容信息，参考如下：</p>
<p>== node243</p>
<pre><code class="language-shell">root@node243:/etc/keepalived# cat keepalived.conf 
global_defs {
    vrrp_version 3
}

vrrp_instance VRRP0 {
    state BACKUP
#   Specify the network interface to which the virtual address is assigned
    interface enp5s0f0
    virtual_router_id 89
#   Set the value of priority lower on the backup server than on the master server
    priority 3
    advert_int 0.4
    track_interface {
        bond1
    }
    virtual_ipaddress {
        12.7.3.89
    }
}
</code></pre>
<p>== node244</p>
<pre><code class="language-shell">root@node244:/var/log# cat /etc/keepalived/keepalived.conf 
global_defs {
    vrrp_version 3
}

vrrp_instance VRRP0 {
    state BACKUP
#   Specify the network interface to which the virtual address is assigned
    interface enp5s0f0
    virtual_router_id 89
#   Set the value of priority lower on the backup server than on the master server
    priority 2
    advert_int 0.4
    track_interface {
        bond1
    }
    virtual_ipaddress {
        12.7.3.89
    }
}
</code></pre>
<p>== node245</p>
<pre><code class="language-shell">root@node245:/etc/keepalived# cat keepalived.conf 
global_defs {
    vrrp_version 3
}

vrrp_instance VRRP0 {
    state BACKUP
#   Specify the network interface to which the virtual address is assigned
    interface bond0
    virtual_router_id 89
#   Set the value of priority lower on the backup server than on the master server
    priority 1
    advert_int 0.4
    track_interface {
        bond1
    }
    virtual_ipaddress {
        12.7.3.89
    }
}
</code></pre>
<p>通过上面的配置文件，可以看出来，各个节点间的priority值不一样，仅仅是通过priority来控制VIP的漂移。</p>
<p>讲到这里，问题来了，如果客户生产环境因预算不足，只能有2个节点物理设备，按照产品部署要求，&gt;=3个节点，势必会需要一台VM作为仲裁节点（不承担任何业务数据，仅启用ceph-mon参与mon election用），那就不能讲这台VM纳入keepalive VIP漂移范围了，即keepalive VIP不能落到这台VM上。</p>
<h1 id="gai-jin">改进</h1>
<p>问题已经清晰了，那么，如何控制VIP，落在指定的设备节点上呢？</p>
<p>通过查询一些资料，更改keepalive.conf配置文件信息，可以达到预期效果：</p>
<h2 id="geng-gai-hou-de-keepalive-conf-xin-xi">更改后的keepalive.conf信息</h2>
<p>== node243</p>
<pre><code class="language-shell">root@node243:/etc/keepalived# cat keepalived.conf 
global_defs {
   notification_email {
   root@localhost
   }
   notification_email_from keepalived@localhost
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id node243                    #主调度器的主机名
   vrrp_mcast_group4 224.26.1.1             #发送心跳信息的组播地址
    
}

vrrp_instance VI_1 {
    state MASTER                            #主调度器的初始角色
    interface enp5s0f0                      #虚拟IP工作的网卡接口
    virtual_router_id 89                    #虚拟路由的ID
    priority 100                            #主调度器的选举优先级
    advert_int 1
    virtual_ipaddress {
        12.7.3.89                     #虚拟IP
    }
}

virtual_server 12.7.3.89 80 {         #LVS配置段，VIP
    delay_loop 6
    lb_algo rr                              #调度算法轮询
    lb_kind DR                              #工作模式DR
    nat_mask 255.255.252.0
#    persistence_timeout 50                  #持久连接，在测试时需要注释，否则会在设置的时间内把请求都调度到一台RS服务器上面
    protocol TCP
    sorry_server 127.0.0.1 80               #Sorry server的服务器地址及端口
    real_server 12.7.3.243 80 { 
        weight 1 
        HTTP_GET {                          #健康状态检测方法
            url {
              path /
              status_code 200               #状态判定规则
            }
            connect_timeout 1
            nb_get_retry 3
            delay_before_retry 1
        }
    }

    real_server 12.7.3.244 80 {
        weight 1
        HTTP_GET {
            url {
              path /
                status_code 200
            }
            connect_timeout 1
            nb_get_retry 3
            delay_before_retry 1
        }
    }
}
</code></pre>
<p>== node244</p>
<pre><code class="language-shell">root@node244:/etc/keepalived# cat keepalived.conf 
global_defs {
   notification_email {
   root@localhost
   }
   notification_email_from keepalived@localhost
   smtp_server 127.0.0.1
   smtp_connect_timeout 30
   router_id node244                #备份调度器的主机名
   vrrp_mcast_group4 224.26.1.1         #这个组播地址需与集群内的其他主机相同

}

vrrp_instance VI_1 {
    state BACKUP                        #初始角色，备份服务器需设置为BACKUP
    interface enp5s0f0
    virtual_router_id 89                #虚拟路由的ID一定要和集群内的其他主机相同
    priority 90                         #选举优先级，要比主调度器地一些
    advert_int 1
    virtual_ipaddress {
        12.7.3.89
    }
}
                #余下配置和主服务器相同
virtual_server 12.7.3.89 80 {
    delay_loop 6
    lb_algo rr
    lb_kind DR
    nat_mask 255.255.252.0
#    persistence_timeout 50              
    protocol TCP
    sorry_server 127.0.0.1 80

    real_server 12.7.3.243 80 {
        weight 1
        HTTP_GET {
            url {
              path /
              status_code 200
            }
            connect_timeout 1
            nb_get_retry 3
            delay_before_retry 1
        }
    }

    real_server 12.7.3.244 80 {
        weight 1
        HTTP_GET {
            url {
              path /
                status_code 200
            }
            connect_timeout 1
            nb_get_retry 3
            delay_before_retry 1
        }
    }
}
</code></pre>
<p>== node245</p>
<pre><code class="language-shell">root@node245:/etc/keepalived# cat keepalived.conf 
global_defs {}
root@node245:/etc/keepalived# 
</code></pre>
<h2 id="yan-zheng-xiao-guo">验证效果</h2>
<h3 id="zhong-qi-suo-you-jie-dian-de-keepalive-fu-wu">重启所有节点的keepalive服务</h3>
<pre><code class="language-shell">root@node245:/etc/keepalived# onnode -p all 'systemctl restart keepalived.service'
root@node245:/etc/keepalived# 
</code></pre>
<p>检查syslog，是否有keepalive日常日志，以及keepalive进程是否存在。如果都没有问题，说明keepalive启动正常。</p>
<h3 id="jian-cha-vip-luo-zai-na-ge-node-shang">检查VIP落在哪个node上</h3>
<pre><code class="language-shell">root@node243:/etc/keepalived# ip a | grep '12.7.3.89'
    inet 12.7.3.89/32 scope global enp5s0f0
root@node243:/etc/keepalived# 

</code></pre>
<p>说明当前VIP 12.7.3.89落在node243上，这个也符合keepalive.conf中的设定（priority=100，另外一个是90，最后一个node没有）</p>
<h3 id="ting-yong-node-243-de-keepalive-fu-wu">停用node243的keepalive服务</h3>
<pre><code class="language-shell">root@node243:/etc/keepalived# systemctl stop keepalived.service 
root@node243:/etc/keepalived# ip a | grep '12.7.3.89'
root@node243:/etc/keepalived# 
</code></pre>
<h3 id="zai-ci-jian-cha-vip-luo-zai-na-ge-node-shang">再次检查VIP落在哪个node上</h3>
<pre><code class="language-shell">root@node243:/etc/keepalived# ip a | grep '12.7.3.89'
root@node243:/etc/keepalived# 

</code></pre>
<pre><code class="language-shell">root@node244:/etc/keepalived# ip a | grep '12.7.3.89'
    inet 12.7.3.89/32 scope global enp5s0f0
root@node244:/etc/keepalived# 
</code></pre>
<pre><code class="language-shell">root@node245:/etc/keepalived# ip a | grep '12.7.3.89'
root@node245:/etc/keepalived# 
</code></pre>
<h3 id="ting-yong-node-244-de-keepalive-fu-wu">停用node244的keepalive服务</h3>
<pre><code class="language-shell">root@node244:/etc/keepalived# systemctl stop keepalived.service 
</code></pre>
<h3 id="zai-ci-jian-cha-vip-luo-zai-na-ge-node-shang-1">再次检查VIP落在哪个node上</h3>
<pre><code class="language-shell">root@node243:/etc/keepalived# ip a | grep '12.7.3.89'
root@node243:/etc/keepalived# 
</code></pre>
<pre><code class="language-shell">root@node244:/etc/keepalived# ip a | grep '12.7.3.89'
root@node244:/etc/keepalived# 
</code></pre>
<pre><code class="language-shell">root@node245:/etc/keepalived# ip a | grep '12.7.3.89'
root@node245:/etc/keepalived# 
</code></pre>
<h1 id="jie-yu">结语</h1>
<p>至此，通过上述验证方法，可以控制住keepalive的VIP漂移到哪些指定的host上。</p>
]]></content>
      <categories>
        <category>keepalive</category>
      </categories>
      <tags>
        <tag>keepalive</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下统计行数性能对比</title>
    <url>/2020/05/28/get_line_no_performace_compare/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>这次使用esrally进行elastic search性能测试，构造了产品自己生成的索引所需要的数据，由于数据比较大，行数有700million+，统计行数碰到了问题，主要是时间问题，统计太耗时，所以，想知道哪个统计效率更高。</p>
<p>本文介绍几种方法，以100million行数的文件，在Linux下统计文件行数，对比下统计性能如何。</p>
<h1 id="zhun-bei-gong-zuo">准备工作</h1>
<p>准备一个100million行数的文件：</p>
<pre><code class="language-shell">root@host75:~/tmp# ll
total 3018132
drwxr-xr-x 2 root root       4096 May 28 17:39 ./
drwx------ 4 root root       4096 May 28 17:38 ../
-rw-r--r-- 1 root root 3090550784 May 28 17:39 documents-2.json
root@host75:~/tmp# du -sh *
3.3G	documents-2.json
root@host75:~/tmp# cat documents-2.json | head -n 2
{"name": "50_9213603372.65", "bucket": "bucket01", "instance": "null", "meta": {"custom-string": {"name": "1729620399787334", "value": "9600528609211706"}, "mtime": "2020-05-25T18:26:36.457Z", "etag": "e7b592f4a6232de9c7a070e5d7456ab1", "content_type": "application/octet-stream", "tail_tag": "a3a5cefd-376d-421b-6085-08b56886e7c1.4520.288519", "size": "972"}, "owner": {"display_name": "user01", "id": "user01"}, "versioned_epoch": "0"}
{"name": "39_1283951288.80", "bucket": "bucket01", "instance": "null", "meta": {"custom-string": {"name": "5902405182780371", "value": "6086948407181992"}, "mtime": "2020-05-28T12:22:37.787Z", "etag": "e7b351f4a7411de9c7a070e5d2381ab1", "content_type": "application/octet-stream", "tail_tag": "a3a5cefd-376d-421b-7442-08b70241e7c1.4520.567559", "size": "152"}, "owner": {"display_name": "user01", "id": "user01"}, "versioned_epoch": "0"}
root@host75:~/tmp# 
</code></pre>
<h1 id="tong-ji-xing-shu-xing-neng-bi-jiao">统计行数性能比较</h1>
<h2 id="shi-yong-wc-tong-ji">使用wc统计</h2>
<pre><code class="language-shell">root@host75:~/tmp# time wc -l documents-2.json 
100000000 documents-2.json

real	0m9.857s
user	0m2.767s
sys	0m7.041s
root@host75:~/tmp#
</code></pre>
<h2 id="awk">awk</h2>
<pre><code class="language-shell">root@host75:~/tmp# time awk '{print NR}' documents-2.json | tail -n1
100000000

real	1m16.523s
user	1m5.944s
sys	0m14.584s
root@host75:~/tmp# 
</code></pre>
<pre><code class="language-shell">root@host75:~/tmp# time awk 'END{print NR}' documents-2.json 
100000000

real	0m43.118s
user	0m32.708s
sys	0m10.395s
root@host75:~/tmp#
</code></pre>
<h2 id="grep-amp-awk-jie-he">grep &amp; awk 结合</h2>
<pre><code class="language-shell">root@host75:~/tmp# time grep -n "" documents-2.json | awk '{{print }}' | tail -n1
100000000:{"name": "23_1479119854.64", "bucket": "bucket01", "instance": "null", "meta": {"custom-string": {"name": "6389993698492958", "value": "9869611550099604"}, "mtime": "2020-05-29T13:24:30.042Z", "etag": "e7b195f4a3730de9c7a070e5d5762ab1", "content_type": "application/octet-stream", "tail_tag": "a3a5cefd-376d-421b-7964-08b62339e7c1.4520.381771", "size": "819"}, "owner": {"display_name": "user01", "id": "user01"}, "versioned_epoch": "0"}

real	1m31.090s
user	1m21.797s
sys	2m8.774s
</code></pre>
<h2 id="sed">sed</h2>
<pre><code class="language-shell">root@host75:~/tmp# time sed -n '$=' documents-2.json 
100000000

real	0m23.395s
user	0m13.503s
sys	0m9.891s
root@host75:~/tmp# 
</code></pre>
<h2 id="cat">cat</h2>
<pre><code class="language-shell">root@host75:~/tmp# time cat documents-2.json | wc -l
100000000

real	0m22.773s
user	0m3.910s
sys	0m31.834s
root@host75:~/tmp# 
</code></pre>
<p>说明：</p>
<p>这个方法不建议使用，比较考验CPU能力。</p>
<h1 id="zong-jie">总结</h1>
<p>由于被统计的文件的数据结构不一样，上述命令统计出来的性能也会有一些差异。本文示例的文档，统计效果比较好的方法是：</p>
<p>wc -l 优于 cat 优于 sed 优于 awk 优于 grep</p>
<p>具体哪个统计方法适合当前被统计文档，可以适当的使用一部分数据作为统计效果看看哪个更优，然后再做抉择使用哪个方法。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>bzip2 vs pbzip2 性能对比</title>
    <url>/2020/06/01/bzip2_vs_pbzip2/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>近期使用esrally进行Elastic Search性能压测，使用script产生了原始数据，这些原始数据需要被压缩成bz2格式，如果原文件大小很大，压缩起来就非常耗时。本文介绍几种bzip2压缩操作，观察耗时情况。</p>
<h1 id="zhun-bei-ce-shi-shu-ju">准备测试数据</h1>
<p>准备10万笔记录，看看压缩耗时如何：</p>
<pre><code class="language-shell">root@node244:/mnt/disk/esrally_data/test# time wc -l documents-2.json 
100000 documents-2.json

real	0m0.025s
user	0m0.005s
sys	0m0.020s
root@node244:/mnt/disk/esrally_data/test# cat documents-2.json | head -n 1
{"name": "08_9837907241.49", "bucket": "bucket01", "instance": "null", "meta": {"custom-string": {"name": "1597699173358823", "value": "5714268441146127"}, "mtime": "2020-05-26T19:21:32.598Z", "etag": "e7b647f4a3959de9c7a070e5d3093ab1", "content_type": "application/octet-stream", "tail_tag": "a3a5cefd-376d-421b-3110-08b41412e7c1.4520.862976", "size": "760"}, "owner": {"display_name": "user01", "id": "user01"}, "versioned_epoch": "0"}
root@node244:/mnt/disk/esrally_data/test# 
</code></pre>
<h1 id="ya-suo-yan-zheng">压缩验证</h1>
<h2 id="shi-yong-mo-ren-de-bzip-2-ya-suo-zhi-ling">使用默认的bzip2压缩指令</h2>
<pre><code class="language-shell">root@node244:/mnt/disk/esrally_data/test# time bzip2 -k documents-2.json documents-2.json.bz2
bzip2: Input file documents-2.json.bz2 already has .bz2 suffix.

real	0m8.482s
user	0m8.454s
sys	0m0.028s
root@node244:/mnt/disk/esrally_data/test# ll
total 47444
drwxr-xr-x 2 root root     4096 Jun  2 16:01 ./
drwxr-xr-x 5 root root     4096 Jun  2 15:55 ../
-rw-r--r-- 1 root root 43800000 Jun  2 15:55 documents-2.json
-rw-r--r-- 1 root root  4769476 Jun  2 15:55 documents-2.json.bz2
root@node244:/mnt/disk/esrally_data/test# 
</code></pre>
<h2 id="bzip-2-shi-yong-1-can-shu">bzip2 使用 -1 参数</h2>
<pre><code class="language-shell">root@node244:/mnt/disk/esrally_data/test# time bzip2 -k -1 documents-2.json documents-2.json.bz2
bzip2: Input file documents-2.json.bz2 already has .bz2 suffix.

real	0m5.411s
user	0m5.390s
sys	0m0.020s
root@node244:/mnt/disk/esrally_data/test# ll
total 48020
drwxr-xr-x 2 root root     4096 Jun  2 16:03 ./
drwxr-xr-x 5 root root     4096 Jun  2 15:55 ../
-rw-r--r-- 1 root root 43800000 Jun  2 15:55 documents-2.json
-rw-r--r-- 1 root root  5357900 Jun  2 15:55 documents-2.json.bz2
root@node244:/mnt/disk/esrally_data/test# 
</code></pre>
<h2 id="bzip-2-shi-yong-9-can-shu">bzip2 使用 -9 参数</h2>
<pre><code class="language-shell">root@node244:/mnt/disk/esrally_data/test# time bzip2 -k -9 documents-2.json documents-2.json.bz2
bzip2: Input file documents-2.json.bz2 already has .bz2 suffix.

real	0m8.053s
user	0m8.049s
sys	0m0.004s
root@node244:/mnt/disk/esrally_data/test#
root@node244:/mnt/disk/esrally_data/test# ll
total 47444
drwxr-xr-x 2 root root     4096 Jun  2 16:10 ./
drwxr-xr-x 5 root root     4096 Jun  2 15:55 ../
-rw-r--r-- 1 root root 43800000 Jun  2 15:55 documents-2.json
-rw-r--r-- 1 root root  4769476 Jun  2 15:55 documents-2.json.bz2
</code></pre>
<h2 id="pbzip-2">pbzip2</h2>
<pre><code class="language-shell">root@node244:/mnt/disk/esrally_data/test# time pbzip2 documents-2.json -z -k -1 -f  &gt; documents-2.json.bz2

real	0m0.449s
user	0m9.834s
sys	0m0.096s
root@node244:/mnt/disk/esrally_data/test# ll
total 48028
drwxr-xr-x 2 root root     4096 Jun  2 16:09 ./
drwxr-xr-x 5 root root     4096 Jun  2 15:55 ../
-rw-r--r-- 1 root root 43800000 Jun  2 15:55 documents-2.json
-rw-r--r-- 1 root root  5366033 Jun  2 15:55 documents-2.json.bz2
root@node244:/mnt/disk/esrally_data/test# 
</code></pre>
<p>根据pbzip2的help信息，这里没有携带-p参数，默认会自己根据当前硬件CPU核数，计算使用多少路并发，默认32</p>
<h1 id="bzip-2-vs-pbzip-2-xing-neng-dui-bi">bzip2 vs pbzip2性能对比</h1>
<p>使用 Compression Level -9, 压缩比率最大，但耗时会比 -1 要久，此选项是默认选项；</p>
<p>使用pzip2进行压缩，多并发情况下，压缩耗时明显要比bzip2 -1 要快。</p>
<p>孰优孰略，一目了然。</p>
<p>BTW，由于pbzip2只能压缩文件，不能对目录进行压缩，所以如果想使用pbzip2压缩目录，则需要借助tar工具。</p>
]]></content>
      <categories>
        <category>bzip2</category>
        <category>pbzip2</category>
      </categories>
      <tags>
        <tag>bzip2</tag>
        <tag>pbzip2</tag>
      </tags>
  </entry>
  <entry>
    <title>Cosbench wirte speed scenario test script</title>
    <url>/2020/05/28/calc_cosbench_rgw_speed/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>A recent test scenario was encountered:<br>
The customer wanted to know how fast the product writes S3 Object per second (the customer required 3000/s), so it started to construct a test scenario, and wrote 120 million objects in total by counting the writing speed every 10 million objects interval.</p>
<p>Unify the write speed on the RGW side, and the write speed on the cosbench side, and the write speed to ES esrally.</p>
<h1 id="script-directory-structure">Script directory structure</h1>
<pre><code class="language-shell">root@scaler80:/mnt/code/cosbench_elastic_search# ls -lR
.:
total 16
-rw-r--r-- 1 root root 2248 May 28 01:42 calc_cosbench_speed.py
-rw-r--r-- 1 root root 2092 May 28 01:42 calc_rgw_write_speed.py
drwxr-xr-x 2 root root 4096 May 28 01:42 run_cosbench
-rw-r--r-- 1 root root 2274 May 28 01:42 write_json_data_for_esrally.py

./run_cosbench:
total 8
-rw-r--r-- 1 root root 1063 May 28 01:42 cosbench.sh
-rw-r--r-- 1 root root 2866 May 28 01:42 roundN_10K_10Mfiles_Write.xml.in
root@scaler80:/mnt/code/cosbench_elastic_search# 
</code></pre>
<h1 id="script-introduction">Script Introduction</h1>
<p>calc_cosbench_speed.py         --&gt;  From cosbench archive log to get Write/Read/Mix speed and AVG Time<br>
calc_rgw_write_speed.py        --&gt;  From output of ‘ceph df’ to get RGW write speed<br>
write_json_data_for_esrally.py --&gt;  Struct data for esally to write into ES<br>
run_cosbench                   --&gt; Submit cosbench task</p>
<h1 id="script-contents">Script contents</h1>
<p><code>calc_cosbench_speed.py</code></p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

from __future__ import unicode_literals

import os
import sys
import time


ARCHIVE_PATH = "/root/0.4.2.c4/archive"
HISTORY = "run-history.csv"

HISTORY_FILE = ARCHIVE_PATH + os.sep + HISTORY

if not os.path.exists(HISTORY_FILE):
    print("\033[31m \n  [ERROR]  Not find path for : ({}) \033[0m \n".format(HISTORY_FILE))
    sys.exit(1)

his_content = os.popen("cat {}".format(HISTORY_FILE)).read()
for each_line in his_content.strip().split("\n"):
    if each_line.startswith("Id"):
        continue

    try:
        line_list = each_line.split(',')
        task_id = line_list[0]
        task_name = line_list[1]
        task_state = line_list[6].strip()

        if task_state == 'finished':
            work_dir = "{}/{}-{}".format(ARCHIVE_PATH, task_id, task_name)
            start_time = line_list[3]
            end_time = line_list[4]

            start_time_array = time.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            end_time_array = time.strptime(end_time, "%Y-%m-%d %H:%M:%S")
            start_times_tamp = time.mktime(start_time_array)
            end_times_tamp = time.mktime(end_time_array)
            time_diff = end_times_tamp - start_times_tamp

            total_objs_cmd = "cat {}/driver*.csv | grep write | grep -v init " \
                             "| awk -F',' '{{print $3}}'".format(work_dir)
            count_str = os.popen(total_objs_cmd).read().strip()
            couts_str_list = count_str.split("\n")
            couts_str_int = map(int, couts_str_list)
            total_objs = sum(couts_str_int)

            write_speed = total_objs / time_diff

            print("\033[32m  Task : ({}-{}), total: ({}), elapsed : ({}s), "
                  "speed : ({}) \033[0m\n".format(task_id, task_name, total_objs, time_diff, write_speed))
        else:
            print("\033[33m  [WARN]  Task : ({}-{}) status is not finished, but : ({}), "
                  "please pay more attention \033[0m\n".format(task_id, task_name, task_state))

    except Exception as ex:
        print("\n\033[31m \n  [ERROR]  Parase file of '{}' "
              "exception : ({}) \033[0m\n".format(HISTORY_FILE, str(ex)))
        sys.exit(1)


if __name__ == "__main__":
    pass

</code></pre>
<p><code>calc_rgw_write_speed.py</code></p>
<pre><code class="language-python">#!/usr/bin/env python

import os
import sys
import time
import datetime

from ezs3.command import do_cmd


def get_object_counts(pool_name):
    cur_objects_info = do_cmd("ceph df | grep {}".format(pool_name)).strip()
    if cur_objects_info:
        cur_objects = int(cur_objects_info.split()[-1])

        return cur_objects
    else:
        print("[ERROR]  Not get objects from pool : ({})".format(pool_name))
        return


def calc_rgw_speed(pool_name=None, sleep_time=None, loop_times=None):
    pool_name = 'default.rgw.buckets.data' if pool_name is None else pool_name
    sleep_time = 5 if sleep_time is None else sleep_time
    loop_times = 10 if loop_times is None else loop_times

    rgw_speed_list = []
    log_file = "rgw_write_speed.log"

    if os.path.exists(log_file):
        cur_time = datetime.datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
        bak_log = log_file + '_{}'.format(cur_time)
        do_cmd("mv {} {}".format(log_file, bak_log))

    title = "--------------- Before Counts ---------- After Counts ---------- Sleep Time ----------- RGW Speed --------"
    print(title)
    do_cmd("echo '{}' &gt;&gt; {}".format(title, log_file))

    for i in xrange(loop_times):
        before_count = get_object_counts(pool_name)
        time.sleep(sleep_time)
        after_count = get_object_counts(pool_name)

        if after_count - before_count == 0:
            print("[ERROR]  Maybe has been writed over, exit!")
            sys.exit(1)

        write_speed = (after_count - before_count) / sleep_time
        out_put = "\t\t{}  \t\t {} \t\t  {} \t\t\t {}".format(before_count, after_count, sleep_time, write_speed)
        print(out_put)
        do_cmd("echo '{}' &gt;&gt; {}".format(out_put, log_file))
        rgw_speed_list.append(write_speed)

    avg_speed = sum(rgw_speed_list) * 1.0 / len(rgw_speed_list)
    avg_speed_output = "RGW AVG speed : {}".format(avg_speed)

    print(avg_speed_output)
    do_cmd("echo '{}' &gt;&gt; {}".format(avg_speed_output, log_file))


if __name__ == '__main__':
    # calc_rgw_speed()
    calc_rgw_speed(sleep_time=600, loop_times=300)

</code></pre>
<p><code>write_json_data_for_esrally.py</code></p>
<pre><code>#!/usr/bin/env python

import os
import sys
from random import choice
from string import digits
from string import ascii_lowercase


def rand_low_ascii(length=10):
    return ''.join([choice(ascii_lowercase) for i in xrange(length)])


def rand_alpha(length=9):
    return ''.join([choice(digits) for i in xrange(length)])



"""
{
    "bucket": "bucket01",
    "owner": {
        "id": "user01",
        "display_name": "user01"
    },
    "instance": "",
    "meta": {
        "expires": "",
        "storage_class": "",
        "content_encoding": "",
        "mtime": "2020-05-27T03:14:57.855Z",
        "content_language": "",
        "custom-date": {
            "name": "",
            "value": ""
        },
        "content_type": "application/octet-stream",
        "custom-int": {
            "name": "",
            "value": ""
        },
        "custom-string": {
            "name": "7385228445730524",
            "value": "8590745273515960"
        },
        "size": "10",
        "content_disposition": "",
        "etag": "e7b4c2f4a8153de9c7a070e5d6550ab1",
        "tail_tag": "a3a5cefd-376d-421b-9080-08b98962e7c1.4520.681216"
    },
    "permissions": "",
    "name": "25_1590549297.82",
    "versioned_epoch": "0"
}
"""

def json_data():
    src = {"bucket":"bucket01","owner":{"id":"user01","display_name":"user01"},"instance":"null","meta":{"mtime":"2020-05-2{}T1{}:2{}:3{}.{}Z".format(rand_alpha(1), rand_alpha(1), rand_alpha(1), rand_alpha(1), rand_alpha(3)),"content_type":"application/octet-stream","custom-string":{"name":"{}".format(rand_alpha(16)),"value":"{}".format(rand_alpha(2048))},"size":"{}".format(rand_alpha(3)),"etag":"e7b{}f4a{}de9c7a070e5d{}ab1".format(rand_alpha(3), rand_alpha(4), rand_alpha(4)),"tail_tag":"a3a5cefd-376d-421b-{}-08b{}e7c1.4520.{}".format(rand_alpha(4), rand_alpha(5), rand_alpha(6))},"name":"{}_{}.{}".format(rand_alpha(2), rand_alpha(10), rand_alpha(2)),"versioned_epoch":"0"}

    return src


def write_data(src):
    with open("./documents-2.json", 'a') as f:
            # replace ' to "
            new_str = str(src).replace("'", '"')
            f.write(new_str)
            f.write('\n')



if __name__ == '__main__':
    for i in xrange(300000000):
        src = json_data()
        write_data(src)

</code></pre>
<p><a href="http://cosbench.sh">cosbench.sh</a></p>
<pre><code>#!/bin/bash

INFILE=roundN_10K_10Mfiles_Write.xml.in
CLI=/root/0.4.2.c4/cli.sh
EP1=10.16.172.161
EP2=10.16.172.162
EP3=10.16.172.163
ACCESS_KEY=73WH14UOZ7QU0H8KYR2V
SECRET_KEY=4WR0T7wPNlRTJsOvEEmWo3w7bwAyJ5vzHQd9dTTA

ssh root@${EP1} ceph status
ssh root@${EP1} ceph df
for round in {1..40}
do
    while (( $(${CLI} info |&amp; grep PROCESSING | wc -l) &gt;= 1 )); do
        sleep 60
    done

    sed "s/@@@ROUND@@@/${round}/g" ${INFILE} | \
    sed "s/@@@ENDPOINT_1@@@/${EP1}/g" | \
    sed "s/@@@ENDPOINT_2@@@/${EP2}/g" | \
    sed "s/@@@ENDPOINT_3@@@/${EP3}/g" | \
    sed "s/@@@ACCESS_KEY@@@/${ACCESS_KEY}/g" | \
    sed "s/@@@SECRET_KEY@@@/${SECRET_KEY}/g" &gt; workload.xml
    ${CLI} submit workload.xml

    date
    # Get memory for each node
    ssh root@${EP1} python /root/run_nmon.py
    ssh root@${EP2} python /root/run_nmon.py
    ssh root@${EP3} python /root/run_nmon.py

    date
    sleep 60

    while (( $(${CLI} info |&amp; grep PROCESSING | wc -l) &gt;= 1 )); do
        sleep 60
    done

    ssh root@${EP1} ceph status
    ssh root@${EP1} ceph df

done
</code></pre>
<p>roundN_10K_10Mfiles_Write.xml.in</p>
<pre><code class="language-shell">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;workload name="Datasearch_round@@@ROUND@@@_10K_files_write_once" description="Datasearch_round@@@ROUND@@@_10K_files_write_once"&gt;
&lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_1@@@/" /&gt;

  &lt;workflow&gt;
		&lt;!-- ******************************* --&gt;
  	&lt;!-- 1mch 20wrks 60threads write job --&gt;
		&lt;!-- ******************************* --&gt;

    &lt;workstage name="10K-10M-40wrks-write-init"&gt;
        &lt;work name="10mch-40wrks-160threads-write-init" type="init" workers="1" interval="10" division="container" runtime="0" rampup="0" rampdown="0" driver="driver1"  config="cprefix=dana;containers=r(1,1)" /&gt;
    &lt;/workstage&gt;

    &lt;workstage name="10K-10M-40wrks-write-WRITEJOB"&gt;
        &lt;work name="write1" type="write" workers="40" interval="10" division="object" totalOps="3500000" rampup="0" rampdown="0" driver="driver1"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_1@@@/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=dana;oprefix=round@@@ROUND@@@_10KB_;containers=s(1,1);objects=r(1,3500000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2" type="write" workers="40" interval="10" division="object" totalOps="3500000" rampup="0" rampdown="0" driver="driver1"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_2@@@/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=dana;oprefix=round@@@ROUND@@@_10KB_;containers=s(1,1);objects=r(3500001,7000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write3" type="write" workers="40" interval="10" division="object" totalOps="3000000" rampup="0" rampdown="0" driver="driver1"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_3@@@/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=dana;oprefix=round@@@ROUND@@@_10KB_;containers=s(1,1);objects=r(7000001,10000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
    &lt;/workstage&gt;

&lt;!--
    &lt;workstage name="1mch-20wrks-60threads-write-cleanup"&gt;
          &lt;work type="cleanup" workers="1" driver="driver1" config="cprefix=tmo;oprefix=round2_10KB_;containers=r(1,1);objects=r(1,10)" /&gt;
    &lt;/workstage&gt;
    &lt;workstage name="1mch-20wrks-60threads-write-dispose"&gt;
          &lt;work type="dispose" workers="1" driver="driver1" config="cprefix=tmo;containers=r(1,1)" /&gt;
    &lt;/workstage&gt;
--&gt;

	&lt;/workflow&gt;
&lt;/workload&gt;
</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>esrally实战</title>
    <url>/2020/06/02/esrally_practice/</url>
    <content><![CDATA[<h1 id="geng-gai-pip-yuan">更改pip源</h1>
<p>考虑到使用esrally官方数据进行工具熟悉，需要下载一些json文件，而这些json文件又比较大，使用国外的源会下载很久，所以需要先更改pip源，详细操作方法，参考：<a href="https://gavin-wang-note.github.io/2020/05/05/change-pip-install-source/">https://gavin-wang-note.github.io/2020/05/05/change-pip-install-source/</a></p>
<h1 id="install">install</h1>
<pre><code class="language-shell">pip install --upgrade pip
pip3 install esrally
esrally configure
</code></pre>
<p>其中，esrally configure选择默认，一路下去就好：</p>
<pre><code class="language-shell">root@node244:~# esrally configure

    ____        ____
   / __ \____ _/ / /_  __
  / /_/ / __ `/ / / / / /
 / _, _/ /_/ / / / /_/ /
/_/ |_|\__,_/_/_/\__, /
                /____/

Running simple configuration. Run the advanced configuration with:

  esrally configure --advanced-config

* Setting up benchmark root directory in /root/.rally/benchmarks
* Setting up benchmark source directory in /root/.rally/benchmarks/src/elasticsearch

Configuration successfully written to /root/.rally/rally.ini. Happy benchmarking!

More info about Rally:

* Type esrally --help
* Read the documentation at https://esrally.readthedocs.io/en/1.4.1/
* Ask a question on the forum at https://discuss.elastic.co/c/elasticsearch/rally
root@node244:~# 

</code></pre>
<p>执行pip3 install esrally时，报错：</p>
<pre><code class="language-shell">Successfully built py-cpuinfo thespian tabulate psutil pyrsistent
ERROR: awscli 1.18.21 has requirement botocore==1.15.21, but you'll have botocore 1.13.50 which is incompatible.
ERROR: awscli 1.18.21 has requirement s3transfer&lt;0.4.0,&gt;=0.3.0, but you'll have s3transfer 0.2.1 which is incompatible.
Installing collected packages: MarkupSafe, Jinja2, py-cpuinfo, elasticsearch, pyrsistent, attrs, zipp, importlib-metadata, jsonschema, thespian, tabulate, psutil, botocore, s3transfer, boto3, esrally
  Attempting uninstall: psutil
    Found existing installation: psutil 3.4.2
ERROR: Cannot uninstall 'psutil'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.
root@node244:~# 
</code></pre>
<p>解决方法：</p>
<pre><code class="language-shell">root@node244:~# dpkg -l | grep psutil
ii  python-psutil                   3.4.2-1ubuntu0.1                           amd64        module providing convenience functions for managing processes
ii  python3-psutil                  3.4.2-1ubuntu0.1                           amd64        module providing convenience functions for managing processes (Python3)

root@node244:~# apt-get remove python3-psutil
</code></pre>
<h1 id="an-zhuang-git">安装git</h1>
<p>忽略。</p>
<h1 id="an-zhuang-kibana">安装kibana</h1>
<p>由于ES版本是7.6.0，所以要使用7.6.0版本的kibana，两者版本一定要一一对应。</p>
<p>直接从官网下载源码，放在ES集群的任意一个节点，或者非ES节点，进入config目录，修改kibana.yml</p>
<pre><code class="language-shell">root@node76:~/kibana-7.6.0-linux-x86_64/config# ll
total 20
drwxrwxr-x  2 root root 4096 May 28 17:00 ./
drwxr-xr-x 13 root root 4096 May 26 09:42 ../
-rw-r--r--  1 root root 3009 Feb  6 08:47 apm.js
-rw-r--r--  1 root root 5944 May 28 17:00 kibana.yml
root@node76:~/kibana-7.6.0-linux-x86_64/config#
</code></pre>
<p>增加如下内容：</p>
<pre><code class="language-shell">i18n.locale: "zh-CN"			                        # kibana默认文字是英文，变更成中文
server.port: 5601		        		                # 浏览器访问端口
server.host: "0.0.0.0"	                		        # 对外的服务地址
elasticsearch.hosts: ["http://10.16.172.75:9200"]       # 这里为你的elasticsearch集群的地址
kibana.index: ".kibana"                                 # 开启此选项
</code></pre>
<p>在tmux中，启动kibana：</p>
<p><code>root@node76:~/kibana-7.6.0-linux-x86_64# ./bin/kibana --allow-root</code></p>
<p>看看output是否无异常，然后通过浏览器，可以正常访问5601端口了：</p>
<img class="shadow" src="/img/in-post/esrally/kibina-view.png" width="1200">
<h1 id="ru-he-chuang-jian-zi-ding-yi-de-track">如何创建自定义的track</h1>
<h2 id="huo-qu-chan-pin-index-xin-xi">获取产品index信息</h2>
<p>由于产品在启用ES时，radosgw会创建出来一个index，命名格式如下：</p>
<p><code>rgw-pool_name-xxx </code></p>
<p>其中，pool_name为当前S3 pool的名称，xxx为一串随机字母和数字组合体，比如：rgw-default-0185294c。</p>
<p>知道了产品创建的index，通过Chrome插件elastic head，成功查询出该index的index information：</p>
<pre><code class="language-shell">{
    "state": "open",
    "settings": {
        "index": {
            "creation_date": "1590482452838",
            "number_of_shards": "6",
            "number_of_replicas": "1",
            "uuid": "ETvwijSKRjyyF93yeQ4PgA",
            "version": {
                "created": "7060099"
            },
            "provided_name": "rgw-default-0185294c"
        }
    },
    "mappings": {
        "_doc": {
            "properties": {
                "bucket": {
                    "type": "keyword"
                },
                "owner": {
                    "properties": {
                        "id": {
                            "type": "text",
                            "fields": {
                                "keyword": {
                                    "ignore_above": 256,
                                    "type": "keyword"
                                }
                            }
                        },
                        "display_name": {
                            "type": "text",
                            "fields": {
                                "keyword": {
                                    "ignore_above": 256,
                                    "type": "keyword"
                                }
                            }
                        }
                    }
                },
                "instance": {
                    "type": "keyword"
                },
                "meta": {
                    "properties": {
                        "expires": {
                            "type": "keyword"
                        },
                        "storage_class": {
                            "type": "keyword"
                        },
                        "content_encoding": {
                            "type": "keyword"
                        },
                        "cache_control": {
                            "type": "keyword"
                        },
                        "mtime": {
                            "type": "date"
                        },
                        "content_language": {
                            "type": "keyword"
                        },
                        "custom-date": {
                            "type": "nested",
                            "properties": {
                                "name": {
                                    "type": "keyword"
                                },
                                "value": {
                                    "type": "date"
                                }
                            }
                        },
                        "content_type": {
                            "type": "keyword"
                        },
                        "custom-int": {
                            "type": "nested",
                            "properties": {
                                "name": {
                                    "type": "keyword"
                                },
                                "value": {
                                    "type": "long"
                                }
                            }
                        },
                        "custom-string": {
                            "type": "nested",
                            "properties": {
                                "name": {
                                    "type": "keyword"
                                },
                                "value": {
                                    "type": "keyword"
                                }
                            }
                        },
                        "size": {
                            "type": "long"
                        },
                        "content_disposition": {
                            "type": "keyword"
                        },
                        "etag": {
                            "type": "keyword"
                        },
                        "tail_tag": {
                            "type": "text",
                            "fields": {
                                "keyword": {
                                    "ignore_above": 256,
                                    "type": "keyword"
                                }
                            }
                        }
                    }
                },
                "permissions": {
                    "type": "text",
                    "fields": {
                        "keyword": {
                            "ignore_above": 256,
                            "type": "keyword"
                        }
                    }
                },
                "name": {
                    "type": "keyword"
                },
                "versioned_epoch": {
                    "type": "long"
                }
            }
        }
    },
    "aliases": [
        
    ],
    "primary_terms": {
        "0": 2,
        "1": 2,
        "2": 3,
        "3": 2,
        "4": 2,
        "5": 2
    },
    "in_sync_allocations": {
        "0": [
            "2_0-lXLvSbyExIEMJzL1lA",
            "KPvnjrHgSy-AjEWVxj8sOA"
        ],
        "1": [
            "Hls3ybkQRRG8775SV-7rsA",
            "iZOWaQZ4TBCXYwazPSo38g"
        ],
        "2": [
            "hP40oioMSUOjOS8-NlWB2w",
            "Hef19xB1Ru2J9zbeDmZ4PQ"
        ],
        "3": [
            "jwu4T-z2RvKrupWGam4QWw",
            "ThRg4-UESYqwo5iKYzzJ4A"
        ],
        "4": [
            "a8R3KMiyRTenLI5jDC2wrw",
            "4e5LfW6SRPWyTkXU0xQPbQ"
        ],
        "5": [
            "6xcWh3JTTVGc8eHwChkmfw",
            "_Bzi1GwAS4G3J5kESmRMDw"
        ]
    }
}
</code></pre>
<p>重点关注“mappings”里的内容，其他信息不用关心。</p>
<h2 id="gen-ju-chan-pin-index-xin-xi-gou-zao-zi-ding-yi-index-json">根据产品index信息，构造自定义index.json</h2>
<p>有了上面的mappings信息，就可以自定义track所需要的index了：</p>
<pre><code class="language-shell">root@node244:~/my_esrally_data/tracks/bigtera# ll
total 48
drwxr-xr-x 4 root root  4096 May 27 18:28 ./
drwxr-xr-x 3 root root  4096 May 27 10:07 ../
drwxr-xr-x 2 root root  4096 May 27 18:04 challenges/
-rw-r--r-- 1 root root    44 May 26 14:50 files.txt
-rw-r--r-- 1 root root  3559 May 27 17:51 index.json
drwxr-xr-x 2 root root  4096 May 27 15:14 operations/
-rw-r--r-- 1 root root  3224 May 26 14:50 README.md
-rw-r--r-- 1 root root   745 May 27 17:58 track.json
-rw-r--r-- 1 root root  3736 May 26 14:50 track.py
root@node244:~/my_esrally_data/tracks/bigtera# 
</code></pre>
<p>自定义的index信息如下：</p>
<pre><code class="language-shell">root@node244:~/my_esrally_data/tracks/bigtera# cat index.json 
{
  "settings": {
    "index.number_of_shards": {{number_of_shards | default(5)}},
    "index.number_of_replicas": {{number_of_replicas | default(0)}},
    "index.store.type": "{{store_type | default('fs')}}",
    "index.requests.cache.enable": false
  },
  "mappings": {
    "_source": {
      "enabled": {{ source_enabled | default(true) | tojson }}
    },
    "properties": {
        "bucket": {
            "type": "keyword"
            },
        "owner": {
            "properties": {
            "id": {
                "type": "text",
                "fields": {
                    "keyword": {
                       "ignore_above": 256,
                       "type": "keyword"
                    }
                }
            },
            "display_name": {
                "type": "text",
                "fields": {
                    "keyword": {
                        "ignore_above": 256,
                        "type": "keyword"
                        }
                     }
                 }
             }
        },
        "instance": {
            "type": "keyword"
        },
        "meta": {
            "properties": {
            "expires": {
                "type": "keyword"
                },
            "storage_class": {
                "type": "keyword"
                },
            "content_encoding": {
                "type": "keyword"
                },
             "cache_control": {
                 "type": "keyword"
                },
            "mtime": {
                "type": "date"
                },
            "content_language": {
                "type": "keyword"
                },
            "custom-date": {
                "type": "nested",
                "properties": {
                    "name": {
                        "type": "keyword"
                        },
                    "value": {
                         "type": "date"
                        }
                 }
             },
             "content_type": {
                 "type": "keyword"
                 },
             "custom-int": {
                 "type": "nested",
                 "properties": {
                     "name": {
                         "type": "keyword"
                     },
                     "value": {
                          "type": "long"
                     }
                 }
             },
             "custom-string": {
                 "type": "nested",
                 "properties": {
                     "name": {
                         "type": "keyword"
                         },
                      "value": {
                          "type": "keyword"
                          }
                  }
             },
            "size": {
                "type": "long"
                },
            "content_disposition": {
                "type": "keyword"
                },
            "etag": {
                "type": "keyword"
                },
            "tail_tag": {
                "type": "text",
                "fields": {
                    "keyword": {
                        "ignore_above": 256,
                        "type": "keyword"
                        }
                }
            }
   }
},
    "permissions": {
        "type": "text",
        "fields": {
            "keyword": {
                "ignore_above": 256,
                "type": "keyword"
                }
        }
    },
    "name": {
        "type": "keyword"
        },
    "versioned_epoch": {
        "type": "long"
        }
    }
  }
}
</code></pre>
<h2 id="gen-ju-index-xin-xi-gou-zao-ce-shi-shu-ju">根据index信息，构造测试数据</h2>
<p>有了index了，如何给esrally构造数据呢？依然使用elastic head插件，查询出产品生产的index里的数据（前提条件是写了部分数据，哪怕几条也行，可以通过cosbench写，也可以自己写个脚本put s3 object），如下图所示：</p>
<img class="shadow" src="/img/in-post/esrally/es_head_view.png" width="1200">
<p>图中，可以看出，从“bucket开始，就是当前index的字段信息，没有子键值项；</p>
<p><a href="http://owner.id">owner.id</a>，owner.display_nane，这说明owner是一级key，id 和 display_nane是二级key</p>
<p><a href="http://meta.custom-string.name">meta.custom-string.name</a> 和 meta.custom-string.value, 这说明meta是一级key， custom-string是二级key，name和value是三级key</p>
<p>分析到这里，就会知道，esrally工具需要什么样的数据结构的数据，一个完整的数据结构如下：</p>
<pre><code class="language-shell">{
    "bucket": "bucket01",
    "owner": {
        "id": "user01",
        "display_name": "user01"
    },
    "instance": "",
    "meta": {
        "expires": "",
        "storage_class": "",
        "content_encoding": "",
        "mtime": "2020-05-27T03:14:57.855Z",
        "content_language": "",
        "custom-date": {
            "name": "",
            "value": ""
        },
        "content_type": "application/octet-stream",
        "custom-int": {
            "name": "",
            "value": ""
        },
        "custom-string": {
            "name": "7385228445730524",
            "value": "8590745273515960"
        },
        "size": "10",
        "content_disposition": "",
        "etag": "e7b4c2f4a8153de9c7a070e5d6550ab1",
        "tail_tag": "a3a5cefd-376d-421b-9080-08b98962e7c1.4520.681216"
    },
    "permissions": "",
    "name": "25_1590549297.82",
    "versioned_epoch": "0"
}
</code></pre>
<p>比如上面的custom-int 和custom-date，可以不需要，我只需要custom-string类型的信息，那就可以忽略掉这两个键值，只生成必须的字典信息即可，参考如下:</p>
<pre><code class="language-shell">root@node244:~/my_esrally_data/data/bigtera# cat documents-2.json | head -n 6
{"name": "83_0916035289.68", "bucket": "bucket01", "instance": "null", "meta": {"custom-string": {"name": "2427603943521294", "value": "6309708009398746"}, "mtime": "2020-05-22T55:60:03.465Z", "etag": "e7b834f4a0650de9c7a070e5d8446ab1", "content_type": "application/octet-stream", "tail_tag": "a3a5cefd-376d-421b-2627-08b32656e7c1.4520.354058", "size": "315"}, "owner": {"display_name": "user01", "id": "user01"}, "versioned_epoch": "0"}
{"name": "83_0916035289.68", "bucket": "bucket01", "instance": "null", "meta": {"custom-string": {"name": "2427603943521294", "value": "6309708009398746"}, "mtime": "2020-05-22T55:60:03.465Z", "etag": "e7b834f4a0650de9c7a070e5d8446ab1", "content_type": "application/octet-stream", "tail_tag": "a3a5cefd-376d-421b-2627-08b32656e7c1.4520.354058", "size": "315"}, "owner": {"display_name": "user01", "id": "user01"}, "versioned_epoch": "0"}
</code></pre>
<p>这里产生的数据，通过python script来生成，script 内容参考如下：</p>
<pre><code class="language-python">root@node244:~# cat write_json_data.py 
#!/usr/bin/env python

import os
import sys
from random import choice
from string import digits
from string import ascii_lowercase
from multiprocessing.pool import ThreadPool


# data like this:
"""
{
    "bucket": "bucket01",
    "owner": {
        "id": "user01",
        "display_name": "user01"
    },
    "instance": "",
    "meta": {
        "expires": "",
        "storage_class": "",
        "content_encoding": "",
        "mtime": "2020-05-27T03:14:57.855Z",
        "content_language": "",
        "custom-date": {
            "name": "",
            "value": ""
        },
        "content_type": "application/octet-stream",
        "custom-int": {
            "name": "",
            "value": ""
        },
        "custom-string": {
            "name": "7385228445730524",
            "value": "8590745273515960"
        },
        "size": "10",
        "content_disposition": "",
        "etag": "e7b4c2f4a8153de9c7a070e5d6550ab1",
        "tail_tag": "a3a5cefd-376d-421b-9080-08b98962e7c1.4520.681216"
    },
    "permissions": "",
    "name": "25_1590549297.82",
    "versioned_epoch": "0"
}
"""

def rand_low_ascii(length=10):
    return ''.join([choice(ascii_lowercase) for i in xrange(length)])


def rand_alpha(length=9):
    return ''.join([choice(digits) for i in xrange(length)])


def json_data():
    src = {"bucket":"bucket01","owner":{"id":"user01","display_name":"user01"},"instance":"null","meta":{"mtime":"2020-05-2{}T1{}:2{}:3{}.{}Z".format(rand_alpha(1), rand_alpha(1), rand_alpha(1), rand_alpha(1), rand_alpha(3)),"content_type":"application/octet-stream","custom-string":{"name":"{}".format(rand_alpha(16)),"value":"{}".format(rand_alpha(16))},"size":"{}".format(rand_alpha(3)),"etag":"e7b{}f4a{}de9c7a070e5d{}ab1".format(rand_alpha(3), rand_alpha(4), rand_alpha(4)),"tail_tag":"a3a5cefd-376d-421b-{}-08b{}e7c1.4520.{}".format(rand_alpha(4), rand_alpha(5), rand_alpha(6))},"name":"{}_{}.{}".format(rand_alpha(2), rand_alpha(10), rand_alpha(2)),"versioned_epoch":"0"}

    return src


def write_data():
    with open("./documents-2.json", 'a') as f:
        for i in xrange(10):
            src = json_data()
            # replace ' to "
            new_str = str(src).replace("'", '"')
            f.write(new_str)
            f.write('\n')


def thread_pool_input_object():
    results = []
    for i in xrange(20):
        results.append(pool.apply_async(write_data, ()))

    for (idx, result) in enumerate(results):
        try:
            r = result.get()
        except:
            print('[ERROR]  Failed to write data into file')


if __name__ == '__main__':
    # Suggest to set same as cpu processor : cat /proc/cpuinfo |grep "processor"|wc -l
    pool = ThreadPool(processes=32)
    thread_pool_input_object()
</code></pre>
<h2 id="xiu-gai-esrally-pei-zhi-wen-jian">修改esrally配置文件</h2>
<p>有构造数据的脚本了，通过修改esrally的配置文件以及track.json，读取指定目录下指定文件，共同完成一个rally job的运行。</p>
<h3 id="xiu-gai-track-json">修改track.json</h3>
<pre><code class="language-shell">root@node244:~/my_esrally_data/tracks/bigtera# cat track.json 
# {% import "rally.helpers" as rally with context %}
{
  "version": 2,
  "description": "POIs from bigtera",
  "data-url": "/root/my_esrally_data/tracks/bigtera/index.json",
  "indices": [
    {
      "name": "bigtera",
      "body": "index.json"
    }
  ],
  "corpora": [
    {
      "name": "bigtera",
      "base-url": "/root/my_esrally_data/tracks/bigtera/index.json",
      "documents": [
        {
          "source-file": "documents-2.json.bz2",
          "document-count": 761377675,
          "compressed-bytes": 36309135809,
          "uncompressed-bytes": 333483421650
        }
      ]
    }
  ],
  "operations": [
    {{ rally.collect(parts="operations/*.json") }}
  ],
  "challenges": [
    {{ rally.collect(parts="challenges/*.json") }}
  ]
}
root@node244:~/my_esrally_data/tracks/bigtera#
</code></pre>
<p>主要修改点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>data-url： 这个是自定义的index文件的位置</p>
</li>
<li class="lvl-2">
<p>name： 请填写为待创建的index名称</p>
</li>
<li class="lvl-2">
<p>source-file: 务必填写为压缩后的bz2文件名称，如 “documents-2.json.bz2”</p>
</li>
<li class="lvl-2">
<p>document-count: 未压缩文件的行数，不能有错，如 761377675</p>
</li>
<li class="lvl-2">
<p>compressed-bytes: documents-2.json文件压缩后的字节数，不能有错，如36309135809</p>
</li>
<li class="lvl-2">
<p>uncompressed-bytes:  documents-2.json文件未压缩时的字节数，不能有错，如333483421650</p>
</li>
</ul>
<h3 id="xiu-gai-rally-mu-lu-xia-rally-ini-wen-jian">修改 .rally目录下rally.ini文件</h3>
<pre><code class="language-ini">root@node244:~/.rally# cat rally.ini 
[meta]
config.version = 17

[system]
env.name = local

[node]
root.dir = /root/.rally/benchmarks
src.root.dir = /root/.rally/benchmarks/src

[source]
remote.repo.url = https://github.com/elastic/elasticsearch.git
elasticsearch.src.subdir = elasticsearch

[benchmarks]
# local.dataset.cache = /root/.rally/benchmarks/data
# local.dataset.cache = /root/my_esrally_data/data
local.dataset.cache = /mnt/sata/700million
# local.dataset.cache = /mnt/sata/100million

[reporting]
datastore.type = in-memory
datastore.host = 
datastore.port = 
datastore.secure = False
datastore.user = 
datastore.password = 

[tracks]
default.url = https://github.com/elastic/rally-tracks

[teams]
default.url = https://github.com/elastic/rally-teams

[defaults]
preserve_benchmark_candidate = False

[distributions]
release.cache = true

root@node244:~/.rally# 

</code></pre>
<p>[benchmarks]标签下，有个参数local.dataset.cache，这个路径是要运行当前track所需要的原始数据文件：</p>
<pre><code class="language-shell">root@node244:~/.rally# cd /mnt/sata/700million
root@node244:/mnt/sata/700million# ls -lR
.:
total 361125600
drwxr-xr-x 2 root root         4096 May 29 21:33 bigtera

./bigtera:
total 361125928
-rw-r--r-- 1 root root 333483421650 May 29 14:09 documents-2.json
-rw-r--r-- 1 root root  36309135809 May 29 11:05 documents-2.json.bz2
-rw-r--r-- 1 root root       342932 May 29 21:51 documents-2.json.offset
root@node244:/mnt/sata/700million# 
</code></pre>
<p>其中，documents-2.json.offset为esrally工具运行时自动产生的，如下是运行时屏显信息：</p>
<p><code>[INFO] Preparing file offset table for [/root/my_esrally_data/data/bigtera/documents-2.json] ... </code></p>
<p>另外，bigtera为对应要创建的index名称，这个在track.json中有定义，所有的数据源，要放在与index同名的目录下。</p>
<h3 id="xiu-gai-challenges">修改challenges</h3>
<p>可以参考官方示例，构造自己需要的challenges，如下challenges为参考了genonames的示例:</p>
<pre><code class="language-shell">root@node244:~/my_esrally_data/tracks/bigtera/challenges# cat default.json 
    {
      "name": "append-no-conflicts",
      "description": "Indexes the whole document corpus using Elasticsearch default settings. We only adjust the number of replicas as we benchmark a single node cluster and Rally will only start the benchmark if the cluster turns green. Document ids are unique so all index operations are append only. After that a couple of queries are run.",
      "default": true,
      "schedule": [
        {
          "operation": "delete-index"
        },
        {
          "operation": {
            "operation-type": "create-index",
            "settings": \{\{index_settings | default(\{\}) | tojson}}
          }
        },
        {
          "name": "check-cluster-health",
          "operation": {
            "operation-type": "cluster-health",
            "index": "bigtera",
            "request-params": {
              "wait_for_status": "{{cluster_health | default('green')}}",
              "wait_for_no_relocating_shards": "true"
            }
          }
        },
        {
          "operation": "index-append",
          "warmup-time-period": 120,
          "clients": {{bulk_indexing_clients | default(8)}}
        },
        {
          "name": "refresh-after-index",
          "operation": "refresh"
        }
        ]
    },
    {
      "name": "append-no-conflicts-index-only",
      "description": "Indexes the whole document corpus using Elasticsearch default settings. We only adjust the number of replicas as we benchmark a single node cluster and Rally will only start the benchmark if the cluster turns green. Document ids are unique so all index operations are append only.",
      "schedule": [
        {
          "operation": "delete-index"
        },
        {
          "operation": {
            "operation-type": "create-index",
            "settings": \{\{index_settings | default(\{\}) | tojson}}
          }
        },
        {
          "name": "check-cluster-health",
          "operation": {
            "operation-type": "cluster-health",
            "index": "bigtera",
            "request-params": {
              "wait_for_status": "{{cluster_health | default('green')}}",
              "wait_for_no_relocating_shards": "true"
            }
          }
        },
        {
          "operation": "index-append",
          "warmup-time-period": 120,
          "clients": {{bulk_indexing_clients | default(8)}}
        },
        {
          "operation": {
            "operation-type": "force-merge",
            "request-timeout": 7200
          }
        },
        {
          "name": "wait-until-merges-finish",
          "operation": {
            "operation-type": "index-stats",
            "index": "_all",
            "condition": {
              "path": "_all.total.merges.current",
              "expected-value": 0
            },
            "retry-until-success": true,
            "include-in-reporting": false
          }
        }
      ]
    }
root@node244:~/my_esrally_data/tracks/bigtera/challenges# 
</code></pre>
<p>说明：</p>
<p>​    如果只想跑"append-no-conflicts-index-only"下的向index中追加数据，可以删除"schedule": []中的除了"operation": "index-append"这个{}，这样就只剩这个operation了。</p>
<h3 id="xiu-gai-operations">修改operations</h3>
<p>参考如下所示：</p>
<pre><code class="language-shell">root@node244:~/my_esrally_data/tracks/bigtera/operations# cat default.json 
    { 
      "name": "index-append",
      "operation-type": "bulk",
      "bulk-size": {{bulk_size | default(5000)}},
      "ingest-percentage": {{ingest_percentage | default(100)}}
    },
    { 
      "name": "index-update",
      "operation-type": "bulk",
      "bulk-size": {{bulk_size | default(5000)}},
      "ingest-percentage": {{ingest_percentage | default(100)}},
      "conflicts": "{{conflicts | default('random')}}",
      "on-conflict": "{{on_conflict | default('index')}}",
      "conflict-probability": {{conflict_probability | default(25)}},
      "recency": {{recency | default(0)}}
    },
    { 
      "name": "default",
      "operation-type": "search",
      "body": {
        "query": {
          "match_all": {}
        }
      }   
    },
    {
      "name": "term",
      "operation-type": "search",
      "body": {
        "query": {
          "term": {
            "meta.etag": "9b7cabc0dbbdf9708cvtazfylkjkqaum"
          }
        }
      }
    },
    {
      "name": "phrase",
      "operation-type": "search",
      "body": {
        "query": {
          "match_phrase": {
            "name": "2_4409197807.1"
          }
        }
      }
    }
</code></pre>
<h1 id="shi-yong-ji-qiao">使用技巧</h1>
<h2 id="yun-xing-shi-xi-dai-can-shu">运行时携带参数</h2>
<p>执行<code>esrally -h </code>，查看具体的帮助信息，以及官方示例中的readme.md文档。</p>
<p>比如下列这个示例：</p>
<pre><code class="language-shell">esrally  --pipeline=benchmark-only --target-hosts=10.16.172.243:9200 --track=geonames  --challenge=append-no-conflicts-index-only --track-params="bulk_size:1,bulk_indexing_clients:2"
</code></pre>
<p>指定了只跑append-no-conflicts-index-only这个challenge，同时指定了bulk_size和bulk_indexing_clients，当然，可以携带其他参数了，比如<code>number_of_replicas</code> 和 <code>number_of_shards</code>，参考如下：</p>
<pre><code class="language-shell">esrally --pipeline=benchmark-only --track-path=/root/my_esrally_data/tracks/bigtera --target-hosts=10.16.172.76:9200 --offline --report-file=/root/my_esrally_data/report/427112_1Mmetadata_6shards_1rep.json --challenge=append-no-conflicts-index-only --track-params="number_of_shards:6,number_of_replicas:1"
</code></pre>
<h2 id="esrally-ri-zhi-de-cha-kan">esrally日志的查看</h2>
<p>在esrally运行时，可以查看日志文件，来帮助定位工具运行中碰到的问题。</p>
<pre><code class="language-shell">root@node244:~# cd .rally/logs/
root@node244:~/.rally/logs# ll
total 51520
drwxr-xr-x 2 root root     4096 Jun  2 11:03 ./
drwxr-xr-x 4 root root     4096 Jun  2 11:03 ../
-rw-r--r-- 1 root root 52740698 Jun  2 13:54 rally.log
root@node244:~/.rally/logs# 
</code></pre>
]]></content>
      <categories>
        <category>esrally</category>
      </categories>
      <tags>
        <tag>esrally</tag>
      </tags>
  </entry>
  <entry>
    <title>统计cosbench写速度</title>
    <url>/2020/06/05/calc_cosbench_write_speed/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>BTW，今天是24节气的芒种，因新型冠状病毒疫情影响，高考延后了1个月。</p>
<p>言归正传，测试任务要求如下：</p>
<p>需要知道当前集群，单一bucket中，存放1000万object，存放2000万object，存放3000万object，。。。。一直到存放110million个object，即每间隔存放1000万笔记录情况下，RGW性能是否伴随单一bucket中object数量的增加，写性能存在下降状况?</p>
<p>最初我测试的时候，是组织了11个xml文件，每个xml文件中总共写1000万笔，单笔object大小10K，在cosbench web界面上提交11个任务，这样综合起来就是110million的object了，测试效果统计RGW写速度如下：</p>
<img class="shadow" src="/img/in-post/rgw_write_speed_v7.0_1.png" width="1200">
<p>参数调整后效果:</p>
<img class="shadow" src="/img/in-post/rgw_write_speed_v7.0_2.png" width="1200">
<p>环境信息与说明：</p>
<p>3节点集群，每个节点4块8T盘组RAID5（64K srip size），每个节点8组RAID5；每个节点有2块3.5T NVME SSD，和2块480G intel 4600 SSD</p>
<p>带NVME的，比如2+1 EC 3.5TNVME，表示使用每个2块3.5T的NVME作为OSD journal&amp;cache， intel 480G 4600独立组成OSD，作为S3 index pool；</p>
<p>不带NVME，比如2Replicate 480G SSD，表示没有使用NVME设备，使用480G SSD作为OSD journal&amp;cache，这个场景更贴合当前客户实施要求的硬件配置</p>
<p>图中的X坐标，每一千万个object采样一次获取的OPS值，从0到1.1亿，采样11个点</p>
<p>上述测试结果，是在7.0版本测试验证，发现7.0版本的性能，同场景下远高于8.0版本的，所以就交由Henry大神进行RGW性能调优，后来他使用shell写了支script，实现自动提交cosbench任务，比我的土方法方便多了，这里抄袭一下他的输出贴出来：</p>
<p>目录结构如下:</p>
<pre><code class="language-shell">root@node244:~/henry# ll
total 20
drwxr-xr-x  2 root root 4096 Jun  4 16:16 ./
drwx------ 13 root root 4096 Jun  4 15:35 ../
-rwxr-xr-x  1 root root  825 Jun  4 09:55 cosbench.sh*
-rw-r--r--  1 root root 1878 Jun  4 09:51 roundN_10K_10Mfiles_Write.xml.in
-rw-r--r--  1 root root 1913 Jun  4 15:30 workload.xml
root@node244:~/henry# 
</code></pre>
<p>roundN_10K_10Mfiles_Write.xml.in 文件内容参考如下:</p>
<pre><code class="language-shell">root@node244:~/henry# cat roundN_10K_10Mfiles_Write.xml.in 
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;workload name="HM_round@@@ROUND@@@_10M_files_write_once" description="HM_round@@@ROUND@@@_10M_files_write_once"&gt;
&lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_1@@@/" /&gt;

  &lt;workflow&gt;
		&lt;!-- ******************************* --&gt;
  	&lt;!-- 1mch 20wrks 60threads write job --&gt;
		&lt;!-- ******************************* --&gt;

    &lt;workstage name="10K-40wrks-write-init"&gt;
        &lt;work name="10mch-40wrks-160threads-write-init" type="init" workers="1" interval="10" division="container" runtime="0" rampup="0" rampdown="0" driver="driver1"  config="cprefix=tmo;containers=r(1,1)" /&gt;
    &lt;/workstage&gt;

    &lt;workstage name="10K-40wrks-write-WRITEJOB"&gt;
        &lt;work name="write1" type="write" workers="40" interval="10" division="object" totalOps="350000" rampup="0" rampdown="0" driver="driver1"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_1@@@/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=tmo;oprefix=round@@@ROUND@@@_10KB_;containers=s(1,1);objects=r(1,350000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write2" type="write" workers="40" interval="10" division="object" totalOps="350000" rampup="0" rampdown="0" driver="driver1"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_2@@@/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=tmo;oprefix=round@@@ROUND@@@_10KB_;containers=s(1,1);objects=r(350001,700000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="write3" type="write" workers="40" interval="10" division="object" totalOps="300000" rampup="0" rampdown="0" driver="driver1"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=@@@ACCESS_KEY@@@;secretkey=@@@SECRET_KEY@@@;endpoint=http://@@@ENDPOINT_3@@@/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=tmo;oprefix=round@@@ROUND@@@_10KB_;containers=s(1,1);objects=r(700001,1000000);sizes=c(10240)B;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
    &lt;/workstage&gt;

	&lt;/workflow&gt;
&lt;/workload&gt;

root@node244:~/henry#
</code></pre>
<p>说明:</p>
<p>这里要注意一下xml文档中的 ‘workload name=“HM_round@@@ROUND@@@_10M_files_write_once”’，此处的workload name对应的内容，一定不能含有空格，因为后面有个shell脚本去cat archive里面的内容，脚本并没有对空格目录做转移处理，建议规避一下，避免使用空格。</p>
<p>cosbench.sh内容如下:</p>
<pre><code class="language-shell">root@node244:~/henry# cat cosbench.sh
#!/bin/bash

INFILE=roundN_10K_10Mfiles_Write.xml.in
CLI=/root/0.4.2.c4/cli.sh
EP1=1.6.17.246
EP2=1.6.17.247
EP3=1.6.17.248
ACCESS_KEY=BHP0VGIGL5TGU1I82S9H
SECRET_KEY=Q5o9c2haivMQeKLiAbBOzKrF7Nfqu0gbInKT1xWL

ssh root@${EP1} ceph status
ssh root@${EP1} ceph df
for round in {1..100}
do
    while (( $(${CLI} info |&amp; grep PROCESSING | wc -l) &gt;= 1 )); do
        echo "[WARN]  Has more than one cosbench task in running status, sleep 60s"
        sleep 60
    done

    sed "s/@@@ROUND@@@/${round}/g" ${INFILE} | \
    sed "s/@@@ENDPOINT_1@@@/${EP1}/g" | \
    sed "s/@@@ENDPOINT_2@@@/${EP2}/g" | \
    sed "s/@@@ENDPOINT_3@@@/${EP3}/g" | \
    sed "s/@@@ACCESS_KEY@@@/${ACCESS_KEY}/g" | \
    sed "s/@@@SECRET_KEY@@@/${SECRET_KEY}/g" &gt; workload.xml
    ${CLI} submit workload.xml
    date
    sleep 60

    while (( $(${CLI} info |&amp; grep PROCESSING | wc -l) &gt;= 1 )); do
        echo "[WARN]  Has more than one cosbench task in running status, sleep 60s"
        sleep 60
    done

    ssh root@${EP1} ceph status
    ssh root@${EP1} ceph df
done

root@node244:~/henry#
</code></pre>
<h1 id="tong-ji-cosbench-xie-su-du">统计cosbench写速度</h1>
<p>终于到本文主题了，既然有了上面的测试script方便QA提交测试任务，那统计RGW写速度，以前写了一个python来统计，不是很通用，因为import了产品的function，一旦脱离产品环境运行cosbench，python脚本就没法执行了，今天重写了个统计cosbench写速度的shell脚本，内容如下：</p>
<pre><code class="language-shell">root@node244:~# cat calc_cosbench_speed.sh 
#!/bin/bash

ARCHIVE=/root/0.4.2.c4/archive/
HISTORY=run-history.csv

HISTORY_FILE=${ARCHIVE}${HISTORY}

if [ ! -f ${HISTORY_FILE} ]; then
  echo ""
  echo -e "\033[31m [ERROR]  !!! Not find file : ${HISTORY_FILE} \033[0m"
  echo ""
  exit 1
fi

while read line
do
    # echo $line
    if [[ x"$line" =~ x"Id" ]]; then
        continue
    else
        task_id=`echo $line | awk -F"," '{{print $1}}'`
        task_name=`echo $line | awk -F"," '{{print $2}}'`
        TASK_STATUS=`echo $line | awk -F"," '{{print $7}}'`
        work_dir=${ARCHIVE}${task_id}-${task_name}

        # echo ${task_id}, ${task_name}, ${TASK_STATUS}, ${work_dir}

        if [[ -d ${work_dir} ]]; then
            if [[ x"${TASK_STATUS}" == x"finished" ]]; then
                TOTAL_OBJS=`cat ${work_dir}/driver*.csv | grep write | grep -v init | awk -F',' '{{print $3}}' | awk '{sum += $1};END {print sum}'`
                # echo ${TOTAL_OBJS}

                START_TIME=`echo $line | awk -F"," '{{print $4}}'`
                END_TIME=`echo $line | awk -F"," '{{print $5}}'`
                START_TIME_STR=`date -d "${START_TIME}" +%s`
                END_TIME_STR=`date -d "${END_TIME}" +%s`
                COST_TIME=`expr ${END_TIME_STR} - ${START_TIME_STR}`
                # echo ${COST_TIME}
                WRITE_SPEED=`echo | awk "{print (${TOTAL_OBJS} / ${COST_TIME})}"`

                echo ""
                echo -e "\033[32m   Task : (${task_id}-${task_name}), write total objects : (${TOTAL_OBJS}), cost time : (${COST_TIME}(s)), write speed : (${WRITE_SPEED}) \033[0m"
                echo ""
            else
                echo -e "\033[33m   [WARN]  Task : (${task_id}-${task_name}) status is not finished, but : (${TASK_STATUS}), please pay more attention!!! \033[0m"
                echo ""
            fi
        else
            echo -e "\033[31m [ERROR]   !!! Not find cosbench archive folder : ${work_dir}  \033[0m"
            exit 1
        fi
    fi
done &lt; ${HISTORY_FILE}
</code></pre>
<p>执行效果如下:</p>
<img class="shadow" src="/img/in-post/calc_cosbench_speed_output.png" width="1200">
<h1 id="python-jiao-ben">python脚本</h1>
<p>今天（2020-06-18）使用python改写了一版，参考如下:</p>
<pre><code class="language-python">root@node244:~/75# cat calc_cosbench_speed.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

from __future__ import unicode_literals

import os
import sys
import time


ARCHIVE_PATH = "/root/0.4.2.c4/archive"
HISTORY = "run-history.csv"

HISTORY_FILE = ARCHIVE_PATH + os.sep + HISTORY

if not os.path.exists(HISTORY_FILE):
    print("\033[31m \n  [ERROR]  Not find path for : ({}) \033[0m \n".format(HISTORY_FILE))
    sys.exit(1)

his_content = os.popen("cat {}".format(HISTORY_FILE)).read()
for each_line in his_content.strip().split("\n"):
    if each_line.startswith("Id"):
        continue

    try:
        line_list = each_line.split(',')
        task_id = line_list[0]
        task_name = line_list[1]
        task_state = line_list[6].strip()

        if task_state == 'finished':
            work_dir = "{}/{}-{}".format(ARCHIVE_PATH, task_id, task_name)
            start_time = line_list[3]
            end_time = line_list[4]

            start_time_array = time.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            end_time_array = time.strptime(end_time, "%Y-%m-%d %H:%M:%S")
            start_times_tamp = time.mktime(start_time_array)
            end_times_tamp = time.mktime(end_time_array)
            time_diff = end_times_tamp - start_times_tamp

            total_objs_cmd = "cat {}/driver*.csv | grep write | grep -v init " \
                             "| awk -F',' '{{print $3}}'".format(work_dir)
            count_str = os.popen(total_objs_cmd).read().strip()
            couts_str_list = count_str.split("\n")
            couts_str_int = map(int, couts_str_list)
            total_objs = sum(couts_str_int)

            write_speed = total_objs / time_diff

            print("\033[32m  Task : ({}-{}), total: ({}), elapsed : ({}s), "
                  "speed : ({}) \033[0m\n".format(task_id, task_name, total_objs, time_diff, write_speed))
        else:
            print("\033[33m  [WARN]  Task : ({}-{}) status is not finished, but : ({}), "
                  "please pay more attention \033[0m\n".format(task_id, task_name, task_state))

    except Exception as ex:
        print("\n\033[31m \n  [ERROR]  Parase file of '{}' "
              "exception : ({}) \033[0m\n".format(HISTORY_FILE, str(ex)))
        sys.exit(1)


if __name__ == "__main__":
    pass

</code></pre>
<p>执行效果如下:</p>
<img class="shadow" src="/img/in-post/calc_cosbench_speed_output_py.png" width="1200">
<h1 id="gai-jin">改进</h1>
<p>(2020-06-28)在使用过程中，碰到两个问题：</p>
<p>由于cosnbench controller log level默认是INFO，导致运行cosbench这台机器根分区空间满，引发cosbench任务卡住，不得不清理空间，删除了mission log信息，引发archive中run-history.csv文件内容有缺失，即少了某个/某些任务，导致统计脚本异常，没法继续统计后续存在的任务了</p>
<p>修改后的脚本内容如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

from __future__ import unicode_literals

import os
import sys
import time


ARCHIVE_PATH = "/root/0.4.2.c4/archive"
HISTORY = "run-history.csv"

HISTORY_FILE = ARCHIVE_PATH + os.sep + HISTORY

if not os.path.exists(HISTORY_FILE):
    print("\033[31m \n  [ERROR]  Not find path for : ({}) \033[0m \n".format(HISTORY_FILE))
    sys.exit(1)

his_content = os.popen("cat {}".format(HISTORY_FILE)).read().strip()
for each_line in his_content.split("\n"):
    if each_line.startswith("Id"):
        continue

    try:
        line_list = each_line.split(',')
        task_id = line_list[0]
        task_name = line_list[1]
        task_state = line_list[6].strip()

        if task_state == 'finished':
            work_dir = "{}/{}-{}".format(ARCHIVE_PATH, task_id, task_name)
            start_time = line_list[3]
            end_time = line_list[4]

            start_time_array = time.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            end_time_array = time.strptime(end_time, "%Y-%m-%d %H:%M:%S")
            start_times_tamp = time.mktime(start_time_array)
            end_times_tamp = time.mktime(end_time_array)
            time_diff = end_times_tamp - start_times_tamp

            total_objs_cmd = "cat {}/driver*.csv | grep write | grep -v init " \
                             "| awk -F',' '{{print $3}}'".format(work_dir)
            count_str = os.popen(total_objs_cmd).read().strip()
            if count_str:
                counts_str_list = count_str.split("\n")
                counts_str_int = map(int, counts_str_list)
                total_objs = sum(counts_str_int)

                write_speed = total_objs / time_diff

                print("\033[32m  Task : ({}-{}), total: ({}), elapsed : ({}s), "
                      "speed : ({}) \033[0m".format(task_id, task_name, total_objs, time_diff, write_speed))
            else:
                print("\033[33m  [WARN]  Not found task : ({}-{}), please pay more attention \033[0m\n".format(task_id, task_name))
                continue
        else:
            print("\033[33m  [WARN]  Task : ({}-{}) status is not finished, but : ({}), "
                  "please pay more attention \033[0m\n".format(task_id, task_name, task_state))

    except Exception as ex:
        print("\n\033[31m \n  [ERROR]  Parase file of '{}' "
              "exception : ({}) \033[0m\n".format(HISTORY_FILE, str(ex)))
        sys.exit(1)


if __name__ == "__main__":
    pass

</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>shell</category>
        <category>cosbench</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>shell</tag>
        <tag>cosbench</tag>
      </tags>
  </entry>
  <entry>
    <title>VD与RAID分区对应关系</title>
    <url>/2020/06/08/correspondence_between_vd_and_raid_partition/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>环境中创建了VD,lsblk可以看到创建好后的分区信息，如何获取分区与RAID VD之间的对应关系呢，比如/dev/sdc分区，对应RAID组哪个VD？</p>
<h1 id="shi-jian">实践</h1>
<p>Step1. 获取RAID卡的Vendor Id和Device Id</p>
<pre><code class="language-shell">root@ec-node3:~# /opt/MegaRAID/MegaCli/MegaCli64 -adpallinfo -aall | grep -Ei 'Vendor Id|Device Id'
Vendor Id       : 1000
Device Id       : 005d
</code></pre>
<p>Step2. 获取VD的Target Id</p>
<pre><code class="language-shell">root@ec-node3:~# /opt/MegaRAID/MegaCli/MegaCli64 -ldpdinfo  aall | grep 'Target Id'
Virtual Drive: 0 (Target Id: 0)
Virtual Drive: 1 (Target Id: 1)
Virtual Drive: 2 (Target Id: 2)
Virtual Drive: 3 (Target Id: 3)
Virtual Drive: 4 (Target Id: 4)
Virtual Drive: 5 (Target Id: 5)
Virtual Drive: 6 (Target Id: 6)
Virtual Drive: 7 (Target Id: 7)
Virtual Drive: 8 (Target Id: 8)
root@ec-node3:~#
</code></pre>
<p>Step3. 获取设备前缀信息</p>
<pre><code class="language-shell">root@ec-node3:~# lspci -nd 1000:005d
af:00.0 0104: 1000:005d (rev 02)
root@ec-node3:~# 
</code></pre>
<p>这里的<code>af:00.0</code>，就是我们所需的设备前缀信息。</p>
<p>Step4. 根据设备前缀信息以及Target Id，获取对应分区信息</p>
<p>Linux 命令行操作如下：</p>
<pre><code class="language-shell">root@ec-node3:~# cd /dev/disk/by-path
root@ec-node3:/dev/disk/by-path# ls -l
total 0
lrwxrwxrwx 1 root root  9 Jun  8 14:39 pci-0000:00:11.5-ata-1 -&gt; ../../sdj
lrwxrwxrwx 1 root root 10 Jun  8 14:39 pci-0000:00:11.5-ata-1-part1 -&gt; ../../sdj1
lrwxrwxrwx 1 root root 10 Jun  8 14:39 pci-0000:00:11.5-ata-1-part2 -&gt; ../../sdj2
lrwxrwxrwx 1 root root 10 Jun  8 14:39 pci-0000:00:11.5-ata-1-part3 -&gt; ../../sdj3
lrwxrwxrwx 1 root root 10 Jun  8 14:39 pci-0000:00:11.5-ata-1-part4 -&gt; ../../sdj4
lrwxrwxrwx 1 root root  9 Jun  8 14:39 pci-0000:00:11.5-ata-2 -&gt; ../../sdk
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:0:0 -&gt; ../../sda
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:0:0-part1 -&gt; ../../sda1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:1:0 -&gt; ../../sdb
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:1:0-part1 -&gt; ../../sdb1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:2:0 -&gt; ../../sdc
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:2:0-part1 -&gt; ../../sdc1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:3:0 -&gt; ../../sdd
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:3:0-part1 -&gt; ../../sdd1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:4:0 -&gt; ../../sde
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:4:0-part1 -&gt; ../../sde1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:5:0 -&gt; ../../sdf
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:5:0-part1 -&gt; ../../sdf1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:6:0 -&gt; ../../sdg
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:6:0-part1 -&gt; ../../sdg1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:7:0 -&gt; ../../sdh
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:7:0-part1 -&gt; ../../sdh1
lrwxrwxrwx 1 root root  9 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:8:0 -&gt; ../../sdi
lrwxrwxrwx 1 root root 10 Jun  8 16:54 pci-0000:af:00.0-scsi-0:2:8:0-part1 -&gt; ../../sdi1
root@ec-node3:/dev/disk/by-path#
root@ec-node3:/dev/disk/by-path# ls -l |grep 'pci-0000:af:00.0-scsi-0:2:2:0' | grep -v part | awk '{{print $NF}}' | awk -F'/' '{{print $NF}}' 
sdc
</code></pre>
<p>说明：</p>
<p><code>pci-0000:af:00.0-scsi-0:2:2:0 </code>，这里的 <code>0:2:2:0 </code>，从左向右数，第三位，3，表示的就是Target Id，<code>af:00.0 </code>为设备前缀信息。</p>
<p>Python Code示例如下:</p>
<pre><code class="language-shell">root@ec-node3:~# python
Python 2.7.12 (default, Oct  8 2019, 14:14:10) 
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; slot_name = 'af:00.0'
&gt;&gt;&gt; target_id = '2'
&gt;&gt;&gt; import os, re
&gt;&gt;&gt; pattern = re.compile(r':{}-scsi-\d+:\d+:{}:\d+$'.format(slot_name, target_id))
&gt;&gt;&gt; disk_path = None
&gt;&gt;&gt; dev_path = '/dev/disk/by-path'
&gt;&gt;&gt; for disk in os.listdir(dev_path):
...     if pattern.search(disk):
...         path_to_disk = os.readlink(os.path.join(dev_path, disk))
...         disk_path = os.path.normpath(os.path.join(dev_path, path_to_disk))
...         print disk_path
...         break
... 
/dev/sdc
&gt;&gt;&gt; 
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>gzip vs bzip2 vs xz vs pbzip2 性能对比</title>
    <url>/2020/06/03/gzip_vs_bzip2_vs_xz_vs_pbzip2_performance_comparison/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>两天前，简单写了篇bzip2 与 pbzip2 压缩哪个更快，当时是处于使用esrally压测Elastic search性能，并没有太多的关注几种压缩工具的性能如何。本文介绍常用的几种压缩命令，分别汇总出各个命令的压缩&amp;解压缩全方面性能对比。</p>
<h1 id="zhun-bei-gong-zuo">准备工作</h1>
<p>看了下gzip，bzip2，pbzip2，xz这4个命令的help信息，帮助信息比较相似：</p>
<img class="shadow" src="/img/in-post/compress_help.png" width="1200">
<p>准备了一个测试文件方便测试：</p>
<pre><code class="language-shell">root@node244:/mnt/disk/compress_test# ll
total 557704
drwxr-xr-x 2 root root      4096 Jun  3 10:34 ./
drwxr-xr-x 5 root root      4096 Jun  3 10:32 ../
-rw-r--r-- 1 root root 571073631 Jun  3 10:33 ceph-client.radosgw.0.log
root@node244:/mnt/disk/compress_test# 
</code></pre>
<p>结合各个命令的help信息，可以使用简单的shell命令来完成测试工作，例如：</p>
<pre><code class="language-shell">for i in {1..9}; do echo "============================  Compress Level $i  ==========================="; echo " ----- Compress -----"; time gzip -k -f -$i ceph-client.radosgw.0.log; echo " ----- Compress info -----"; gzip -l -v ceph-client.radosgw.0.log.gz; echo "-----  Uncompress -----"; time gzip -d -f ceph-client.radosgw.0.log.gz; done
</code></pre>
<h1 id="ce-shi-guo-cheng">测试过程</h1>
<h2 id="gzip-ya-suo-yu-jie-ya-suo">gzip 压缩与解压缩</h2>
<pre><code class="language-shell">root@node244:/mnt/disk/compress_test# for i in {1..9}; do echo "============================  Compress Level $i  ==========================="; echo " ----- Compress -----"; time gzip -k -f -$i ceph-client.radosgw.0.log; echo " ----- Compress info -----"; gzip -l -v ceph-client.radosgw.0.log.gz; echo "-----  Uncompress -----"; time gzip -d -f ceph-client.radosgw.0.log.gz; done
============================  Compress Level 1  ===========================
 ----- Compress -----

real	0m3.389s
user	0m3.261s
sys	0m0.128s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            27542300           571073631  95.2% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.502s
user	0m1.962s
sys	0m0.472s
============================  Compress Level 2  ===========================
 ----- Compress -----

real	0m3.385s
user	0m3.257s
sys	0m0.128s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            27158636           571073631  95.2% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.782s
user	0m1.893s
sys	0m0.444s
============================  Compress Level 3  ===========================
 ----- Compress -----

real	0m3.407s
user	0m3.262s
sys	0m0.144s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            26820084           571073631  95.3% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.403s
user	0m1.919s
sys	0m0.417s
============================  Compress Level 4  ===========================
 ----- Compress -----

real	0m4.302s
user	0m4.150s
sys	0m0.152s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            22196434           571073631  96.1% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.413s
user	0m1.914s
sys	0m0.433s
============================  Compress Level 5  ===========================
 ----- Compress -----

real	0m4.385s
user	0m4.237s
sys	0m0.149s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            20643438           571073631  96.4% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.370s
user	0m1.937s
sys	0m0.349s
============================  Compress Level 6  ===========================
 ----- Compress -----

real	0m5.298s
user	0m5.142s
sys	0m0.156s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            19503464           571073631  96.6% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.367s
user	0m1.910s
sys	0m0.400s
============================  Compress Level 7  ===========================
 ----- Compress -----

real	0m5.518s
user	0m5.402s
sys	0m0.116s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            19396724           571073631  96.6% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.435s
user	0m1.842s
sys	0m0.486s
============================  Compress Level 8  ===========================
 ----- Compress -----

real	0m6.961s
user	0m6.853s
sys	0m0.108s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            18411146           571073631  96.8% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.480s
user	0m1.884s
sys	0m0.399s
============================  Compress Level 9  ===========================
 ----- Compress -----

real	0m7.233s
user	0m7.077s
sys	0m0.156s
 ----- Compress info -----
method  crc     date  time           compressed        uncompressed  ratio uncompressed_name
defla d30eafa2 Jun  3 10:33            18186392           571073631  96.8% ceph-client.radosgw.0.log
-----  Uncompress -----

real	0m2.877s
user	0m1.820s
sys	0m0.456s
root@node244:/mnt/disk/compress_test# 
</code></pre>
<h2 id="bzip-2-de-ya-suo-yu-jie-ya-suo">bzip2的压缩与解压缩</h2>
<pre><code class="language-shell">root@node244:/mnt/disk/compress_test# for i in {1..9}; do echo "============================  Compress Level $i  ==========================="; echo " ----- Compress -----"; time bzip2 -k -f -v -$i ceph-client.radosgw.0.log ceph-client.radosgw.0.log.bz2; echo "-----  Uncompress -----"; time bzip2 -d -f ceph-client.radosgw.0.log.bz2; done
============================  Compress Level 1  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     28.266:1,  0.283 bits/byte, 96.46% saved, 571073631 in, 20203523 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	1m14.986s
user	1m14.115s
sys	0m0.212s
-----  Uncompress -----

real	0m8.986s
user	0m7.820s
sys	0m0.492s
============================  Compress Level 2  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     34.344:1,  0.233 bits/byte, 97.09% saved, 571073631 in, 16627875 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	1m26.956s
user	1m25.741s
sys	0m0.232s
-----  Uncompress -----

real	0m8.858s
user	0m8.241s
sys	0m0.488s
============================  Compress Level 3  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     37.331:1,  0.214 bits/byte, 97.32% saved, 571073631 in, 15297380 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	1m35.014s
user	1m34.232s
sys	0m0.140s
-----  Uncompress -----

real	0m9.019s
user	0m8.451s
sys	0m0.512s
============================  Compress Level 4  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     38.943:1,  0.205 bits/byte, 97.43% saved, 571073631 in, 14664242 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	1m41.031s
user	1m40.805s
sys	0m0.160s
-----  Uncompress -----

real	0m9.702s
user	0m8.491s
sys	0m0.596s
============================  Compress Level 5  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     40.177:1,  0.199 bits/byte, 97.51% saved, 571073631 in, 14214101 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	1m46.857s
user	1m46.109s
sys	0m0.172s
-----  Uncompress -----

real	0m9.378s
user	0m8.565s
sys	0m0.536s
============================  Compress Level 6  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     41.332:1,  0.194 bits/byte, 97.58% saved, 571073631 in, 13816797 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	1m50.821s
user	1m50.619s
sys	0m0.196s
-----  Uncompress -----

real	0m9.688s
user	0m8.611s
sys	0m0.556s
============================  Compress Level 7  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     41.987:1,  0.191 bits/byte, 97.62% saved, 571073631 in, 13601242 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	1m55.011s
user	1m54.842s
sys	0m0.168s
-----  Uncompress -----

real	0m9.197s
user	0m8.560s
sys	0m0.575s
============================  Compress Level 8  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     42.637:1,  0.188 bits/byte, 97.65% saved, 571073631 in, 13393739 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	2m0.052s
user	1m59.319s
sys	0m0.100s
-----  Uncompress -----

real	0m9.232s
user	0m8.650s
sys	0m0.516s
============================  Compress Level 9  ===========================
 ----- Compress -----
  ceph-client.radosgw.0.log:     43.064:1,  0.186 bits/byte, 97.68% saved, 571073631 in, 13261043 out.
bzip2: Input file ceph-client.radosgw.0.log.bz2 already has .bz2 suffix.

real	2m1.284s
user	2m1.072s
sys	0m0.204s
-----  Uncompress -----

real	0m9.246s
user	0m8.667s
sys	0m0.512s
root@node244:/mnt/disk/compress_test# 
</code></pre>
<h2 id="pbzip-2-de-ya-suo-yu-jie-ya-suo">pbzip2的压缩与解压缩</h2>
<p>由于担心不同CPU并发影响测试效果，这里指定了CPU个数为24个，在不带-p参数情况下，默认32个，当前环境虽然有32cores，但并不是每次都能全部参与，有时候是32，有时候是29，有时候是26，所以这里指定一个更低值，确保每次执行都使用相同cores的CPU数。</p>
<pre><code class="language-shell">@node244:/mnt/disk/compress_test# for i in {1..9}; do echo "============================  Compress Level $i  ==========================="; echo " ----- Compress -----"; time pbzip2 -k -f -v -p24 -$i ceph-client.radosgw.0.log; echo "----- Uncompress -----"; time pbzip2 -p24 -d -f ceph-client.radosgw.0.log.bz2; done
============================  Compress Level 1  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 100 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 20251314 bytes
-------------------------------------------

     Wall Clock: 5.553146 seconds

real	0m5.557s
user	2m10.868s
sys	0m0.600s
----- Uncompress -----

real	0m0.675s
user	0m11.626s
sys	0m0.710s
============================  Compress Level 2  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 200 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 17034671 bytes
-------------------------------------------

     Wall Clock: 6.295284 seconds

real	0m6.299s
user	2m28.521s
sys	0m0.892s
----- Uncompress -----

real	0m0.706s
user	0m12.163s
sys	0m0.780s
============================  Compress Level 3  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 300 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 15336308 bytes
-------------------------------------------

     Wall Clock: 7.094542 seconds

real	0m7.098s
user	2m46.324s
sys	0m1.328s
----- Uncompress -----

real	0m1.047s
user	0m12.899s
sys	0m0.723s
============================  Compress Level 4  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 400 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 15289111 bytes
-------------------------------------------

     Wall Clock: 7.390034 seconds

real	0m7.393s
user	2m53.305s
sys	0m1.428s
----- Uncompress -----

real	0m0.738s
user	0m13.124s
sys	0m0.806s
============================  Compress Level 5  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 500 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 14424635 bytes
-------------------------------------------

     Wall Clock: 7.929576 seconds

real	0m7.933s
user	3m5.904s
sys	0m1.616s
----- Uncompress -----

real	0m0.783s
user	0m14.003s
sys	0m0.780s
============================  Compress Level 6  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 600 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 14320561 bytes
-------------------------------------------

     Wall Clock: 8.235693 seconds

real	0m8.240s
user	3m12.339s
sys	0m2.512s
----- Uncompress -----

real	0m0.770s
user	0m13.975s
sys	0m0.789s
============================  Compress Level 7  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 700 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 14284009 bytes
-------------------------------------------

     Wall Clock: 8.463171 seconds

real	0m8.467s
user	3m17.862s
sys	0m2.209s
----- Uncompress -----

real	0m0.828s
user	0m14.793s
sys	0m0.932s
============================  Compress Level 8  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 800 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 14161949 bytes
-------------------------------------------

     Wall Clock: 9.343830 seconds

real	0m9.348s
user	3m37.798s
sys	0m3.541s
----- Uncompress -----

real	0m0.844s
user	0m15.348s
sys	0m0.937s
============================  Compress Level 9  ===========================
 ----- Compress -----
Parallel BZIP2 v1.1.9     - by: Jeff Gilchrist [http://compression.ca]
[Apr. 13, 2014]               (uses libbzip2 by Julian Seward)
Major contributions: Yavor Nikolov &lt;nikolov.javor+pbzip2@gmail.com&gt;

         # CPUs: 24
 BWT Block Size: 900 KB
File Block Size: 900 KB
 Maximum Memory: 100 MB
-------------------------------------------
         File #: 1 of 1
     Input Name: ceph-client.radosgw.0.log
    Output Name: ceph-client.radosgw.0.log.bz2

     Input Size: 571073631 bytes
Compressing data...
    Output Size: 13295516 bytes
-------------------------------------------

     Wall Clock: 10.434447 seconds

real	0m10.438s
user	4m3.675s
sys	0m4.175s
----- Uncompress -----

real	0m0.796s
user	0m15.991s
sys	0m0.911s
root@node244:/mnt/disk/compress_test#
</code></pre>
<h2 id="xz-de-ya-suo-yu-jie-ya-suo">xz的压缩与解压缩</h2>
<pre><code class="language-shell">root@node244:/mnt/disk/compress_test# for i in {0..9}; do echo "============================  Compress Level $i  ==========================="; echo " ----- Compress -----"; rm -rf *.xz; time xz -k -f -v -$i ceph-client.radosgw.0.log; echo " ----- Compress info -----"; xz -l -v ceph-client.radosgw.0.log.xz; echo "----- Uncompress -----"; time xz -d -f ceph-client.radosgw.0.log.xz; done
============================  Compress Level 0  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        17.9 MiB / 544.6 MiB = 0.033    71 MiB/s       0:07             

real	0m7.703s
user	0m7.567s
sys	0m0.136s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    17.9 MiB (18,732,968 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.033
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      18,732,968     571,073,631  0.033  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      18,732,928     571,073,631  0.033  CRC64
----- Uncompress -----

real	0m2.886s
user	0m1.895s
sys	0m0.444s
============================  Compress Level 1  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        17.2 MiB / 544.6 MiB = 0.032    56 MiB/s       0:09             

real	0m9.666s
user	0m9.514s
sys	0m0.152s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    17.2 MiB (18,010,756 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.032
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      18,010,756     571,073,631  0.032  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      18,010,716     571,073,631  0.032  CRC64
----- Uncompress -----

real	0m2.282s
user	0m1.719s
sys	0m0.496s
============================  Compress Level 2  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        16.3 MiB / 544.6 MiB = 0.030    45 MiB/s       0:12             

real	0m12.128s
user	0m11.964s
sys	0m0.164s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    16.3 MiB (17,065,980 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.030
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      17,065,980     571,073,631  0.030  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      17,065,940     571,073,631  0.030  CRC64
----- Uncompress -----

real	0m2.277s
user	0m1.694s
sys	0m0.517s
============================  Compress Level 3  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        16.1 MiB / 544.6 MiB = 0.030    32 MiB/s       0:16             

real	0m16.986s
user	0m16.778s
sys	0m0.208s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    16.1 MiB (16,899,448 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.030
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      16,899,448     571,073,631  0.030  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      16,899,408     571,073,631  0.030  CRC64
----- Uncompress -----

real	0m2.252s
user	0m1.664s
sys	0m0.532s
============================  Compress Level 4  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        16.4 MiB / 544.6 MiB = 0.030    17 MiB/s       0:31             

real	0m31.449s
user	0m31.220s
sys	0m0.228s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    16.4 MiB (17,154,260 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.030
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      17,154,260     571,073,631  0.030  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      17,154,220     571,073,631  0.030  CRC64
----- Uncompress -----

real	0m2.349s
user	0m1.868s
sys	0m0.412s
============================  Compress Level 5  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        15.6 MiB / 544.6 MiB = 0.029    12 MiB/s       0:45             

real	0m45.585s
user	0m45.152s
sys	0m0.420s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    15.6 MiB (16,360,932 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.029
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      16,360,932     571,073,631  0.029  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      16,360,892     571,073,631  0.029  CRC64
----- Uncompress -----

real	0m2.398s
user	0m1.851s
sys	0m0.488s
============================  Compress Level 6  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        15.1 MiB / 544.6 MiB = 0.028   7.1 MiB/s       1:17             

real	1m17.152s
user	1m16.763s
sys	0m0.388s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    15.1 MiB (15,786,352 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.028
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      15,786,352     571,073,631  0.028  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      15,786,312     571,073,631  0.028  CRC64
----- Uncompress -----

real	0m2.302s
user	0m1.752s
sys	0m0.487s
============================  Compress Level 7  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        15.1 MiB / 544.6 MiB = 0.028   6.7 MiB/s       1:20             

real	1m20.962s
user	1m20.478s
sys	0m0.460s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    15.1 MiB (15,862,848 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.028
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      15,862,848     571,073,631  0.028  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      15,862,808     571,073,631  0.028  CRC64
----- Uncompress -----

real	0m2.368s
user	0m1.803s
sys	0m0.497s
============================  Compress Level 8  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        15.4 MiB / 544.6 MiB = 0.028   6.4 MiB/s       1:25             

real	1m25.153s
user	1m24.488s
sys	0m0.660s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    15.4 MiB (16,130,916 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.028
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      16,130,916     571,073,631  0.028  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      16,130,876     571,073,631  0.028  CRC64
----- Uncompress -----

real	0m2.359s
user	0m1.768s
sys	0m0.535s
============================  Compress Level 9  ===========================
 ----- Compress -----
ceph-client.radosgw.0.log (1/1)
  100 %        15.7 MiB / 544.6 MiB = 0.029   5.9 MiB/s       1:32             

real	1m32.645s
user	1m31.211s
sys	0m1.424s
 ----- Compress info -----
ceph-client.radosgw.0.log.xz (1/1)
  Streams:            1
  Blocks:             1
  Compressed size:    15.7 MiB (16,510,384 B)
  Uncompressed size:  544.6 MiB (571,073,631 B)
  Ratio:              0.029
  Check:              CRC64
  Stream padding:     0 B
  Streams:
    Stream    Blocks      CompOffset    UncompOffset        CompSize      UncompSize  Ratio  Check      Padding
         1         1               0               0      16,510,384     571,073,631  0.029  CRC64            0
  Blocks:
    Stream     Block      CompOffset    UncompOffset       TotalSize      UncompSize  Ratio  Check
         1         1              12               0      16,510,344     571,073,631  0.029  CRC64
----- Uncompress -----

real	0m2.394s
user	0m1.763s
sys	0m0.500s
root@node244:/mnt/disk/compress_test# 
</code></pre>
<h1 id="ce-shi-jie-guo">测试结果</h1>
<h2 id="compression-size">Compression Size</h2>
<p>Unit:bytes</p>
<table>
<thead>
<tr>
<th><strong>Compress Level</strong></th>
<th><strong>gzip</strong></th>
<th><strong>bzip2</strong></th>
<th><strong>pbzip2</strong></th>
<th><strong>xz</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>18,732,968</td>
</tr>
<tr>
<td>1</td>
<td>27542300</td>
<td>20203523</td>
<td>20251314</td>
<td>18,010,756</td>
</tr>
<tr>
<td>2</td>
<td>27158636</td>
<td>16627875</td>
<td>17034671</td>
<td>17,065,980</td>
</tr>
<tr>
<td>3</td>
<td>26820084</td>
<td>15297380</td>
<td>15336308</td>
<td>16,899,448</td>
</tr>
<tr>
<td>4</td>
<td>22196434</td>
<td>14664242</td>
<td>15289111</td>
<td>17,154,260</td>
</tr>
<tr>
<td>5</td>
<td>20643438</td>
<td>14214101</td>
<td>14424635</td>
<td>16,360,932</td>
</tr>
<tr>
<td>6</td>
<td>19503464</td>
<td>13816797</td>
<td>14320561</td>
<td>15,786,352</td>
</tr>
<tr>
<td>7</td>
<td>19396724</td>
<td>13601242</td>
<td>14284009</td>
<td>15,862,848</td>
</tr>
<tr>
<td>8</td>
<td>18411146</td>
<td>13393739</td>
<td>14161949</td>
<td>16,130,916</td>
</tr>
<tr>
<td>9</td>
<td>18186392</td>
<td>13261043</td>
<td>13295516</td>
<td>16,510,384</td>
</tr>
</tbody>
</table>
<h2 id="compression-time">Compression Time</h2>
<p>先从压缩时间开始，下列图表显示了从1到9的每个压缩级别完成压缩所花费的时间。</p>
<p>Unit: seconds</p>
<table>
<thead>
<tr>
<th><strong>Compress Level</strong></th>
<th><strong>gzip</strong></th>
<th><strong>bzip2</strong></th>
<th><strong>pbzip2</strong></th>
<th><strong>xz</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>0m7.703s</td>
</tr>
<tr>
<td>1</td>
<td>0m3.389s</td>
<td>1m14.986s</td>
<td>0m5.557s</td>
<td>0m9.666s</td>
</tr>
<tr>
<td>2</td>
<td>0m3.385s</td>
<td>1m26.956s</td>
<td>0m6.299s</td>
<td>0m12.128s</td>
</tr>
<tr>
<td>3</td>
<td>0m3.407s</td>
<td>1m35.014s</td>
<td>0m7.098s</td>
<td>0m16.986s</td>
</tr>
<tr>
<td>4</td>
<td>0m4.302s</td>
<td>1m41.031s</td>
<td>0m7.393s</td>
<td>0m31.449s</td>
</tr>
<tr>
<td>5</td>
<td>0m4.385s</td>
<td>1m46.857s</td>
<td>0m7.933s</td>
<td>0m45.585s</td>
</tr>
<tr>
<td>6</td>
<td>0m5.298s</td>
<td>1m50.821s</td>
<td>0m8.240s</td>
<td>1m17.152s</td>
</tr>
<tr>
<td>7</td>
<td>0m5.518s</td>
<td>1m55.011s</td>
<td>0m8.467s</td>
<td>1m20.962s</td>
</tr>
<tr>
<td>8</td>
<td>0m6.961s</td>
<td>2m0.052s</td>
<td>0m9.348s</td>
<td>1m25.153s</td>
</tr>
<tr>
<td>9</td>
<td>0m7.233s</td>
<td>2m1.284s</td>
<td>0m10.438s</td>
<td>1m32.645s</td>
</tr>
</tbody>
</table>
<img class="shadow" src="/img/in-post/compression_time.png" width="1200">
<p>从折线图可以看出，随着压缩级别的提高，bzip2需要花费更长的时间才能完成，pbzip2和gzip的变化不大，而压缩级别为3后，xz的增长非常明显。</p>
<h2 id="compression-ratio">Compression Ratio</h2>
<p>Unit: %</p>
<table>
<thead>
<tr>
<th><strong>Compress Level</strong></th>
<th><strong>gzip</strong></th>
<th><strong>bzip2</strong></th>
<th><strong>pbzip2</strong></th>
<th><strong>xz</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>3.3</td>
</tr>
<tr>
<td>1</td>
<td>4.8</td>
<td>3.54</td>
<td>3.55</td>
<td>3.3</td>
</tr>
<tr>
<td>2</td>
<td>4.8</td>
<td>2.91</td>
<td>2.98</td>
<td>3.0</td>
</tr>
<tr>
<td>3</td>
<td>4.7</td>
<td>2.68</td>
<td>2.69</td>
<td>3.0</td>
</tr>
<tr>
<td>4</td>
<td>3.9</td>
<td>2.57</td>
<td>2.68</td>
<td>3.0</td>
</tr>
<tr>
<td>5</td>
<td>3.6</td>
<td>2.49</td>
<td>2.53</td>
<td>2.9</td>
</tr>
<tr>
<td>6</td>
<td>3.4</td>
<td>2.42</td>
<td>2.51</td>
<td>2.8</td>
</tr>
<tr>
<td>7</td>
<td>3.4</td>
<td>2.38</td>
<td>2.50</td>
<td>2.8</td>
</tr>
<tr>
<td>8</td>
<td>3.2</td>
<td>2.35</td>
<td>2.48</td>
<td>2.8</td>
</tr>
<tr>
<td>9</td>
<td>3.2</td>
<td>2.32</td>
<td>2.33</td>
<td>2.9</td>
</tr>
</tbody>
</table>
<img class="shadow" src="/img/in-post/compression_ratio.png" width="1200">
<p>compression ratio，越小越好，比如说源文件大小是100MiB，ratio为5%，则压缩后文件大小为5MiB。</p>
<p>从折线图看到趋势是：压缩级别越高，压缩率越低，说明文件被压缩的更小了。在这种情况下，xz始终提供比较平稳的压缩率（但从压缩时间图所示，xz在压缩级别3之后花费更长的时间才能获得这个效果），紧跟其后的是pbzip2和bzip2，gzip在压缩级别为3后，压缩率有所下降。</p>
<h2 id="compression-speed">Compression Speed</h2>
<p>Unit:MiB/s</p>
<table>
<thead>
<tr>
<th><strong>Compress Level</strong></th>
<th><strong>gzip</strong></th>
<th><strong>bzip2</strong></th>
<th><strong>pbzip2</strong></th>
<th><strong>xz</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>70.702</td>
</tr>
<tr>
<td>1</td>
<td>160.702</td>
<td>7.263</td>
<td>98.006</td>
<td>56.344</td>
</tr>
<tr>
<td>2</td>
<td>160.892</td>
<td>6.263</td>
<td>86.461</td>
<td>44.906</td>
</tr>
<tr>
<td>3</td>
<td>159.853</td>
<td>5.732</td>
<td>76.728</td>
<td>32.063</td>
</tr>
<tr>
<td>4</td>
<td>126.597</td>
<td>5.391</td>
<td>73.667</td>
<td>17.318</td>
</tr>
<tr>
<td>5</td>
<td>124.200</td>
<td>5.097</td>
<td>68.652</td>
<td>11.947</td>
</tr>
<tr>
<td>6</td>
<td>102.797</td>
<td>4.914</td>
<td>66.094</td>
<td>7.059</td>
</tr>
<tr>
<td>7</td>
<td>98.698</td>
<td>4.735</td>
<td>64.322</td>
<td>6.727</td>
</tr>
<tr>
<td>8</td>
<td>78.239</td>
<td>4.536</td>
<td>58.260</td>
<td>6.396</td>
</tr>
<tr>
<td>9</td>
<td>75.296</td>
<td>4.490</td>
<td>52.176</td>
<td>5.879</td>
</tr>
</tbody>
</table>
<img class="shadow" src="/img/in-post/compression_speed.png" width="1200">
<h2 id="decompression-time">Decompression Time</h2>
<p>Unit: seconds</p>
<table>
<thead>
<tr>
<th>Decompress Level</th>
<th><strong>gzip</strong></th>
<th><strong>bzip2</strong></th>
<th><strong>pbzip2</strong></th>
<th><strong>xz</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>0m2.886s</td>
</tr>
<tr>
<td>1</td>
<td>0m2.502s</td>
<td>0m8.986s</td>
<td>0m0.675s</td>
<td>0m2.282s</td>
</tr>
<tr>
<td>2</td>
<td>0m2.782s</td>
<td>0m8.858s</td>
<td>0m0.706s</td>
<td>0m2.277s</td>
</tr>
<tr>
<td>3</td>
<td>0m2.403s</td>
<td>0m9.019s</td>
<td>0m1.047s</td>
<td>0m2.252s</td>
</tr>
<tr>
<td>4</td>
<td>0m2.413s</td>
<td>0m9.702s</td>
<td>0m0.738s</td>
<td>0m2.349s</td>
</tr>
<tr>
<td>5</td>
<td>0m2.370s</td>
<td>0m9.378s</td>
<td>0m0.783s</td>
<td>0m2.398s</td>
</tr>
<tr>
<td>6</td>
<td>0m2.367s</td>
<td>0m9.688s</td>
<td>0m0.770s</td>
<td>0m2.302s</td>
</tr>
<tr>
<td>7</td>
<td>0m2.435s</td>
<td>0m9.197s</td>
<td>0m0.828s</td>
<td>0m2.368s</td>
</tr>
<tr>
<td>8</td>
<td>0m2.480s</td>
<td>0m9.232s</td>
<td>0m0.844s</td>
<td>0m2.359s</td>
</tr>
<tr>
<td>9</td>
<td>0m2.877s</td>
<td>0m9.246s</td>
<td>0m0.796s</td>
<td>0m2.394s</td>
</tr>
</tbody>
</table>
<img class="shadow" src="/img/in-post/decompression_time.png" width="1200">
<p>由于数值比较小，从折线图上直接看不出什么效果，从表格中可以看出，当文件的压缩级别越高，解压相应的压缩文件耗时越低。xz的解压缩时间几乎是一条直线，非常平稳，gbip2次之，当gbzip2解压比xz更快。</p>
<p>从Compression time, Compression Ratio，结合当前的Decompress Time看，总体上推荐gbzip2进行文件的压缩与解压缩操作。</p>
<h2 id="decompression-speed">Decompression Speed</h2>
<p>Unit: MiB/s</p>
<table>
<thead>
<tr>
<th>Decompress Level</th>
<th><strong>gzip</strong></th>
<th><strong>bzip2</strong></th>
<th><strong>pbzip2</strong></th>
<th><strong>xz</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>6.202</td>
</tr>
<tr>
<td>1</td>
<td>10.498</td>
<td>2.144</td>
<td>28.612</td>
<td>7.537</td>
</tr>
<tr>
<td>2</td>
<td>9.310</td>
<td>1.790</td>
<td>23.011</td>
<td>7.159</td>
</tr>
<tr>
<td>3</td>
<td>10.644</td>
<td>1.618</td>
<td>13.970</td>
<td>7.149</td>
</tr>
<tr>
<td>4</td>
<td>8.773</td>
<td>1.441</td>
<td>19.757</td>
<td>6.982</td>
</tr>
<tr>
<td>5</td>
<td>8.307</td>
<td>1.445</td>
<td>17.569</td>
<td>6.505</td>
</tr>
<tr>
<td>6</td>
<td>7.858</td>
<td>1.360</td>
<td>17.737</td>
<td>6.560</td>
</tr>
<tr>
<td>7</td>
<td>7.598</td>
<td>1.410</td>
<td>16.452</td>
<td>6.558</td>
</tr>
<tr>
<td>8</td>
<td>7.080</td>
<td>1.384</td>
<td>16.002</td>
<td>6.528</td>
</tr>
<tr>
<td>9</td>
<td>6.028</td>
<td>1.368</td>
<td>15.929</td>
<td>6.558</td>
</tr>
</tbody>
</table>
<img class="shadow" src="/img/in-post/decompression_speed.png" width="1200">
<h1 id="xing-neng-chai-yi-he-bi-jiao">性能差异和比较</h1>
<p>默认情况下，当未指定压缩级别时，gzip 使用 -6，bzip2 和 pbzip2 使用 -9，xz 使用 -6。</p>
<p>根据测试结果，原因非常明确：对于 gzip 和 xz -6 作为默认压缩方法提供良好的压缩级别，但完成时间不会太长，损失一个平衡点，因为较高的压缩级别需要更长的时间来处理压缩。另一方面，pbzip2 最好使用默认压缩级别为 9，如手册页中建议的那样，此处的结果证实了这一点，压缩比增加，但所采用的时间几乎相同，在级别 1 到 9 之间相差不到一秒；但反观bzip2，使用不同的压缩级别，压缩耗时还是有蛮大幅度变化的。</p>
<p>一般来说，xz 达到最佳压缩级别，非常的平稳，然后是 bzip2和pbzip2，然后是 gzip。为了达到更好的压缩，但是xz通常需要最长的完成，其次是pbzip2，然后是gzip，最差的是bzip2，耗时太久。</p>
<p>xz 的默认压缩级别为 6，而 pbzip2 在压缩级别 9 时仅花费比 gzip 稍长一点的时间，并且压缩量更好，而 pbzip2 和 xz 之间的差异小于 pbzip2 和 gzip 之间的差异，因此 pbzip2 成为压缩的优先选择。</p>
<p>根据这些测试结果，pbzip2是压缩的良好中间地带，gzip只是压缩的更快一点，而xz可能并不真正值得使用，尤其使用更高的文件压缩级别（&gt;=6），因为它需要更长的时间来完成压缩操作。</p>
<p>然而，使用 bzip2 解压缩比 xz 或 gzip 或 pbzip2 需要更长的时间，xz 处于解压缩文件的良好中间地带，而 gbzip2 则是解压缩最快的。</p>
<h1 id="xuan-ze-na-chong-ya-suo-fang-shi">选择哪种压缩方式？</h1>
<p>那么我该选择哪种压缩/解压缩方式？这完全取决于应用目的了，需要因地制宜选择所需的压缩/解压缩方法。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果是交互式的压缩文件，可以使用pxz，这个指令可以看到压缩进度；</p>
</li>
<li class="lvl-2">
<p>如果只是想尽可能快的压缩和解压缩文件，很少考虑压缩比情况下，gzip是一个很好的选择；</p>
</li>
<li class="lvl-2">
<p>如果只想要一个更好的压缩比，以节约磁盘空间，并愿意话费更多的时间去加压缩它，那么xz只比较好的选择，其次是pbzip2</p>
</li>
</ul>
]]></content>
      <categories>
        <category>bzip2</category>
        <category>pbzip2</category>
        <category>gzip</category>
        <category>xz</category>
      </categories>
      <tags>
        <tag>bzip2</tag>
        <tag>pbzip2</tag>
        <tag>gzip</tag>
        <tag>xz</tag>
      </tags>
  </entry>
  <entry>
    <title>shell计算精度</title>
    <url>/2020/06/11/shell_calculation_accuracy/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>为何要写这篇文章，因为在上篇文章 <a href="https://gavin-wang-note.github.io/2020/06/10/stastic_ES_write_speed_by_shell_script/" target="_blank">stastic ES write speed by shell script</a>有使用shell去尝试统计ES的写入速度，需要精确到毫秒级别的时间差，但是尝试了expr，let，发现不行，而是awk却可以，所以本文汇总一下，以bash为例，shell中的计算精度问题。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="bc">bc</h2>
<p>bc是比较常用的Linux中计算器了，简单方便，而且是支持浮点的。一般系统不自带，需要额外安装。</p>
<pre><code class="language-shell">root@code80:~# echo 1+2 | bc
3
root@code80:~# echo 1.1*6 | bc
6.6
root@code80:~# echo 5/3 | bc
1
root@code80:~# echo 5/3.0 | bc
1
root@code80:~# echo 5.0/3 | bc
1
root@code80:~# echo 5.1/3 | bc
1
root@code80:~# echo "scale=2;5/3" | bc
1.66
root@code80:~# 
root@code80:~# echo "scale=2;1/2" | bc
.50
root@code80:~# echo "scale=4;1/2" | bc
.5000
root@code80:~# 
</code></pre>
<p>这里有个问题，如果整数为0，这个整数不会显示，直接显示小数点，解决方法如下:</p>
<pre><code class="language-shell">root@code80:~# echo "print 0;scale=2;1/2" | bc
0.50
root@code80:~#
</code></pre>
<h2 id="expr">expr</h2>
<p>不支持浮点计算，即不支持小数，所以也常被用来判断变量内容或者结果是不是非0整数（expr 0的echo $?不是0）。</p>
<p>另外，expr 后面的两个参数与运算符之间，一定要含有空格:</p>
<pre><code class="language-shell">root@code80:~# expr 1+2
1+2
root@code80:~# expr 1 + 2
3
root@code80:~# expr 5/3
5/3
root@code80:~# expr 5 / 3
1
root@code80:~# expr 99 / 3.0
expr: non-integer argument
root@code80:~# expr 99 / 3
33
root@code80:~# expr 0
0
root@code80:~# echo $?
1
root@code80:~# 
</code></pre>
<h2 id="">$(())</h2>
<p>此方法不支持浮点计算。</p>
<pre><code class="language-shell">root@code80:~# echo $((1+2.0))
bash: 1+2.0: syntax error: invalid arithmetic operator (error token is ".0")
root@code80:~# echo $((1+2))
3
root@code80:~# echo $((10/2))
5
root@code80:~# echo $((10.1/2))
bash: 10.1/2: syntax error: invalid arithmetic operator (error token is ".1/2")
root@code80:~#
</code></pre>
<h2 id="let">let</h2>
<p>不仅不支持浮点计算，而且还只能赋值，不能直接输出。</p>
<pre><code class="language-shell">root@code80:~# let a=1+2
root@code80:~# echo $a
3
root@code80:~# let b=10/5
root@code80:~# echo $b
2
root@code80:~# let b=10/3
root@code80:~# echo $b
3
root@code80:~# let c=1.1*2
bash: let: c=1.1*2: syntax error: invalid arithmetic operator (error token is ".1*2")
root@code80:~# 
</code></pre>
<p>上面的方法，bc一般系统不带需要自行安装，不是很方便，万一系统不联网，又没有安装包，没法使用；其他的几个方法，都不支持浮点数，是否有其他方法支持浮点数的？答案是肯定的，继续往下看。</p>
<h1 id="ji-suan-fu-dian-shu">计算浮点数</h1>
<p>这里，使用awk获浮点数。</p>
<pre><code class="language-shell">root@code80:~# echo | awk "{print 10.2/2}"
5.1
root@code80:~# echo | awk "{print 10*2.1}"
21
root@code80:~# echo | awk "{print 10.2*2.1}"
21.42
root@code80:~# echo | awk "{print 10.2/2}"
5.1
root@code80:~# echo | awk "{print 10.2*2.1}"
21.42
root@code80:~# echo | awk "{print 10.2+2.1}"
12.3
root@code80:~# echo | awk "{print 10.2-2.1}"
8.1
root@code80:~# echo | awk '{print 10.2-2.1}'
8.1
root@code80:~# echo | awk '{print 10.2+2.1}'
12.3
root@code80:~# echo | awk '{print 10.2*2.1}'
21.42
root@code80:~# echo | awk '{print 10.2/2.1}'
4.85714
root@code80:~#
</code></pre>
<p>将数值参数化试试：</p>
<pre><code class="language-shell">root@code80:~# pam1=10.2
root@code80:~# pam2=2.1
root@code80:~# pam3=2
root@code80:~# echo | awk '{print $pam1/$pam2}'
awk: cmd. line:1: (FILENAME=- FNR=1) fatal: division by zero attempted
root@code80:~# echo | awk "{print $pam1/$pam2}"
4.85714
root@code80:~# echo | awk "{print $pam1*$pam2}"
21.42
root@code80:~# echo | awk "{print $pam1-$pam2}"
8.1
root@code80:~# echo | awk "{print $pam1-$pam2*$pam3}"
6
root@code80:~# echo | awk "{print ($pam1-$pam2)*$pam3}"
16.2
root@code80:~#
</code></pre>
<p>说明：</p>
<p>这里awk后的print，在不使用参数/变量情况下，使用单引号和双引号都可以，推荐使用双引号，养成习惯。</p>
<p>这里小数点后的位数不受控制，比如本文示例中计算出来的结果4.85714，小数点后有5位，如果只想保留指定位数的小数点，加上printf：</p>
<pre><code class="language-shell">root@code80:~# echo | awk '{print 10/3}' 
3.33333
root@code80:~# echo | awk '{printf ("%.2f\n",10/3)}' 
3.33
root@code80:~# 
</code></pre>
<p>看看参数化后的执行效果:</p>
<pre><code class="language-shell">root@code80:~# echo | awk "{printf ("%.2f\n",$pam1/$pam2)}"
awk: cmd. line:1: {printf (%.2fn,10/3)}
awk: cmd. line:1:          ^ syntax error
root@code80:~# 
root@code80:~# echo | awk '{printf ("%.2f\n",$pam1/$pam2)}'
awk: cmd. line:1: (FILENAME=- FNR=1) fatal: division by zero attempted
</code></pre>
<p>报错了，这种情况，建议先在前面的echo中将需要使用的变量输出出来，再进行调用。</p>
<pre><code class="language-shell">root@code80:~# echo $pam1 $pam2 | awk '{{printf ("%.2f\n", $1/$2)}}'
3.33
root@code80:~# 
</code></pre>
<p>说明：</p>
<p>上面的命令示例中，保留2位小数，printf默认是保留6位。</p>
<p>如果碰到科学计数类型的爆大数字，会出问题：</p>
<pre><code class="language-shell">
t@code80:~# echo "5.9637e+12/100" | bc
(standard_in) 1: syntax error
root@code80:~# 
</code></pre>
<p>解决方法如下：</p>
<pre><code class="language-shell">root@code80:~# echo "5.9637e+12/100" | awk '{printf ("%.0f\n",$1)}'
5963700000000
root@code80:~# echo "5.9637e+12/100" | awk '{printf ("%.2f\n",$1)}'
5963700000000.00
root@code80:~# 
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>脚本统计ES写入速度</title>
    <url>/2020/06/10/stastic_es_write_speed_by_shell_script/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍下如何call API的方式去统计ES的写速度，当然，你可以使用监控工具去统计，不在本文描述范围。</p>
<h1 id="na-xie-api-ke-yi-huo-qu-dao-es-index-zhong-de-shu-ju-liang">哪些API可以获取到ES index中的数据量</h1>
<p>这里介绍两种API,参考如下：</p>
<pre><code class="language-shell">_cat/count?v&amp;format=json&amp;pretty
</code></pre>
<p>吐出信息参考如下：</p>
<pre><code class="language-shell">[
  {
    "epoch" : "1591598061",
    "timestamp" : "06:34:21",
    "count" : "3626228"
  }
]
</code></pre>
<p>另外一种是</p>
<pre><code class="language-shell">index_name/_cat/indices?v&amp;pretty
</code></pre>
<p>输出示例参考如下:</p>
<pre><code class="language-shell">root@node248:/opt/datasearch# curl -XGET -s 'localhost:9200/_cat/indices?v&amp;pretty'
health status index                uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   rgw-default-fb9bb242 fZDCxLRPRKS1hn6GD_PE-g  12   0    8796770         6075      3.3gb          3.3gb
root@node248:/opt/datasearch# 
</code></pre>
<p>说明：</p>
<p>因为ES集群中只有一个index，所以可以不带index_name，如果有多个，在不带具体index_name情况下，或查询出所有的，建议根据所需进行查询。</p>
<h1 id="zhe-liang-ge-api-na-ge-geng-he-gua">这两个API，哪个更合适？</h1>
<p>先说<code>_cat/count?v&amp;format=json&amp;pretty </code>， 它的吐出信息中，epoch其实就是时间戳，但精度只到秒级别，如果要计算ES写入速度：获取前后两个count的值，以及前后两个epoch的值，分别做差，使用前者的差值，除以后者的差值，得到当前ES的写入速度，效果如下：</p>
<pre><code class="language-shell">root@node76:~# python calc_es_write_speed.py 
-------  Timestamp ----------- Total Counts ---------- Counts diff --------- Time diff ------- ES speed -------
	 1591778958 	       4645564 		       1616  	        	3 		  538
	 1591778961 	       4647574 		       921  			2 		  460
	 1591778964 	       4649407 		       755  			1 		  755
	 1591778967 	       4651841 		       849  			1 		  849
	 1591778971 	       4654225 		       1062  			2 		  531
	 1591778974 	       4656417 		       1012  			2 		  506
	 1591778978 	       4658627 		       1151  			2 		  575
	 1591778981 	       4661607 		       1067  			1 		  1067
.................................................. 中间数据省略 ................................................                                            
	 1591779923 		5264956 		873  			1 		   873
	 1591779926 		5267410 		845  			1 		   845
	 1591779929 		5269377 		1030  			1 		   1030
	 1591779933 		5271217 		933  			2 		   466
	 1591779936 		5273646 		973  			1 		   973
---------------------------------------------------------------------------------------------------------------
AVG speed : 700.153333333
root@node76:~# 
</code></pre>
<p>弊端比较明显了，精度不够，有时除以1，有时除以2，比如上次统计是1000，下次就可能是500了。</p>
<p>另外一种API <code>index_name/_cat/indices?v&amp;pretty </code>,通过观察，大约60秒左右才会更新一次数据，更新频率不大，但是计算起止时间可以自己控制，精度也可以自己控制。</p>
<h1 id="jiao-ben">脚本</h1>
<p>分别使用了 <code>_cat/count?v&amp;format=json&amp;pretty</code> 和 <code>index_name/_cat/indices?v&amp;pretty </code> 这两个API，写了统计脚本，本文只给出shell 使用<code>index_name/_cat/indices?v&amp;pretty </code>的示例,脚本内容如下:</p>
<pre><code class="language-shell">#!/bin/bash

TOTAL_COUNTS=10000000
LOG_FILE=es_speed.log
TITLE_NAME="------ Timestamp ------  Total Counts ------ Time Diff ------ Count Diff ------  AVG Speed ------"


# start_time=`echo $[$(date +%s%N)/1000000]`
cur_counts=`curl -XGET -s 'localhost:9200/_cat/indices?v&amp;pretty' | grep 'rgw-default' | awk '{{print $7}}' 2&gt;&amp;1`

echo ${TITLE_NAME} | tee ${LOG_FILE}

while [ ${cur_counts} -lt ${TOTAL_COUNTS} ]
do
    before_counts=${cur_counts}

    start_time=`echo $[$(date +%s%N)/1000000]`
    sleep 60

    cur_counts=`curl -XGET -s 'localhost:9200/_cat/indices?v&amp;pretty' | grep 'rgw-default' | awk '{{print $7}}' 2&gt;&amp;1`
    end_time=`echo $[$(date +%s%N)/1000000]`

    if [[ ${cur_counts} -ne ${before_counts}  ]]; then
        diff=`expr ${end_time} - ${start_time}`
        time_diff=`echo | awk "{print $diff/1000}"`
        count_diff=`expr ${cur_counts} - ${before_counts}`
        avg_speed=`echo | awk "{print ${count_diff}/${time_diff}}"`

        echo "      ${end_time}       ${cur_counts}           ${time_diff}           ${count_diff}             ${avg_speed}" | tee ${LOG_FILE}
    else
        echo "${end_time}    [WARN]  Get the same count : (${cur_counts}) in adjacent intervals, wait 2 seconds" &gt;&gt; ${LOG_FILE}
        sleep 2
    fi
done
</code></pre>
<p>输出内容示例如下:</p>
<pre><code class="language-shell">root@node76:~# bash speed_calc_es.sh 
------ Timestamp ------ Total Counts ------ Time Diff ------ Count Diff ------ AVG Speed ------
      1591781812805       6372650           60.043           44556             742.068
      1591781934909       6416426           60.04           43776             729.114
      1591782057108       6509848           60.128           93422             1553.72
      1591782117259       6554868           60.131           45020             748.699
      1591782177403       6604810           60.118           49942             830.733
      1591782237568       6648911           60.139           44101             733.318
      1591782359825       6692497           60.114           43586             725.056
      1591782419957       6735616           60.115           43119             717.275
      1591782542227       6833050           60.121           97434             1620.63
      1591782602341       6958258           60.088           125208             2083.74
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>ceph S3 多租户</title>
    <url>/2020/06/16/ceph_multi_tenancy/</url>
    <content><![CDATA[<h1 id="shi-yao-shi-multi-tenancy">什么是multi-tenancy</h1>
<p>在J版之前，同一个ceph集群中不允许有同名的bucket和S3账号的存在，从J版本开始，引入multi-tenancy功能，使得不同tenant（租户）下的账号和bucket可以同名，为了兼容J之前的版本，提供了一名为空的“legacy” 租户，如果没有指定tenant，则从这个“legacy” tenant去获取账号/bucket信息。</p>
<h1 id="cha-kan-mo-ren-tenant-zhong-s-3-zhang-hao-xin-xi">查看默认tenant中S3账号信息</h1>
<pre><code class="language-shell">root@node76:/var/log/ezcloudstor# radosgw-admin metadata list user
[
    "admin",
    "user01"
]
</code></pre>
<p>上述信息中，有两个S3账号，admin账号先忽略，此账号为超级管理员， user01为我创建的一个普通S3账号，此账号信息如下：</p>
<pre><code class="language-shell">root@node76:/var/log/ezcloudstor# radosgw-admin user info --uid=user01
{
    "user_id": "user01",
    "display_name": "user01",
    "email": "user01@126.com",
    "suspended": 0,
    "max_buckets": 1000,
    "auid": 0,
    "subusers": [
        {
            "id": "user01:user01",
            "permissions": "full-control"
        }
    ],
    "keys": [
        {
            "user": "user01",
            "access_key": "U3SNDWWAJRSTQU2YZAMG",
            "secret_key": "5l1fg5VgsWo1z9fCd2IvCdrTwGi1asHBqb4b6DTQ"
        }
    ],
    "swift_keys": [
        {
            "user": "user01",
            "secret_key": "1"
        },
        {
            "user": "user01:user01",
            "secret_key": "1"
        }
    ],
    "caps": [],
    "op_mask": "read, write, delete",
    "default_placement": "",
    "placement_tags": [],
    "bucket_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "user_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "temp_url_keys": [],
    "type": "rgw",
    "bigtera_roles": {
        "cluster_admin": false,
        "deleting": false,
        "migrated": false,
        "s3_admin": false,
        "sds_admin": false,
        "sns": false,
        "sqs": false
    }
}

root@node76:/var/log/ezcloudstor# 
</code></pre>
<p>直接指定tenant为空，再次查询一下这个S3账号</p>
<pre><code class="language-shell">root@node76:~# radosgw-admin user info --uid=user01 --tenant=''
{
    "user_id": "user01",
    "display_name": "user01",
    "email": "user01@126.com",
    "suspended": 0,
    "max_buckets": 1000,
    "auid": 0,
    "subusers": [
        {
            "id": "user01:user01",
            "permissions": "full-control"
        }
    ],
    "keys": [
        {
            "user": "user01",
            "access_key": "U3SNDWWAJRSTQU2YZAMG",
            "secret_key": "5l1fg5VgsWo1z9fCd2IvCdrTwGi1asHBqb4b6DTQ"
        }
    ],
    "swift_keys": [
        {
            "user": "user01",
            "secret_key": "1"
        },
        {
            "user": "user01:user01",
            "secret_key": "1"
        }
    ],
    "caps": [],
    "op_mask": "read, write, delete",
    "default_placement": "",
    "placement_tags": [],
    "bucket_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "user_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "temp_url_keys": [],
    "type": "rgw",
    "bigtera_roles": {
        "cluster_admin": false,
        "deleting": false,
        "migrated": false,
        "s3_admin": false,
        "sds_admin": false,
        "sns": false,
        "sqs": false
    }
}
</code></pre>
<p>可以确认一点，当不携带tenant或者指定的tenant为空时，从一个为空的tenant中获取S3账号信息，ceph只所以这么做，是为了兼容J之前的版本。</p>
<h1 id="chuang-jian-bu-tong-zu-hu-xia-de-xiang-tong-zhang-hao">创建不同租户下的相同账号</h1>
<p>这里会预先创建两个租户下的同名账号，tenant1下的user01，和tenant2下的user01</p>
<pre><code class="language-shell">radosgw-admin user create --tenant tenant1 --uid user01 --display-name "tenant1_user01"
radosgw-admin user create --tenant tenant2 --uid user01 --display-name "tenant2_user01"
</code></pre>
<pre><code class="language-shell">root@node76:~# radosgw-admin user list
[
    "admin",
    "tenant1$user01",
    "tenant2$user01",
    "user01"
]
root@node76:~# 
</code></pre>
<p>这里可以看到两个账号，“tenant1$user01” 和 “tenant2$user01”，以符号“$”间隔开，用户名相同，只是属于不同的租户（tenant），不相互冲突。</p>
<p>通过user info，指定tenant，获取到这两个账号的access key 和 secret key，示例如下:</p>
<pre><code class="language-shell">root@node76:~# radosgw-admin --uid=user01 user info --tenant tenant1
{
    "user_id": "tenant1$user01",
    "display_name": "tenant1_user01",
    "email": "",
    "suspended": 0,
    "max_buckets": 1000,
    "auid": 0,
    "subusers": [],
    "keys": [
        {
            "user": "tenant1$user01",
            "access_key": "SSCBPW100ED03TI0MU51",
            "secret_key": "Tnnjsw7e8A7Gu4qblQlHaka4uoOq5rVVR2cDEfOz"
        }
    ],
    "swift_keys": [],
    "caps": [],
    "op_mask": "read, write, delete",
    "default_placement": "",
    "placement_tags": [],
    "bucket_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "user_quota": {
        "enabled": false,
        "check_on_raw": false,
        "max_size": -1,
        "max_size_kb": 0,
        "max_objects": -1
    },
    "temp_url_keys": [],
    "type": "rgw",
    "bigtera_roles": {
        "cluster_admin": false,
        "deleting": false,
        "migrated": false,
        "s3_admin": false,
        "sds_admin": false,
        "sns": false,
        "sqs": false
    }
}

root@node76:~# 
</code></pre>
<h1 id="dui-xiang-shang-chuan">对象上传</h1>
<p>分别给这两个租户下的同名账号创建相同的bucket，以及上传对象。</p>
<p>node75上，使用tenant1的user01账号；node76上，使用tenant2的user01账号分别创建同名的bucket，以及上传对象到bucket中：</p>
<pre><code class="language-shell">root@node75:~# cat .s3cfg | grep _key | grep -v kms
access_key = SSCBPW100ED03TI0MU51
secret_key = Tnnjsw7e8A7Gu4qblQlHaka4uoOq5rVVR2cDEfOz
</code></pre>
<pre><code class="language-shell">root@node76:~# cat .s3cfg | grep _key | grep -v kms
access_key = 22XOFAUIPFR11C45483R
secret_key = vN5C1bNMcBbprfPm0v3ozKQ4rvvgsZeLuNRoVJ9B
root@node76:~# 
</code></pre>
<p>尝试创建同名bucket:</p>
<pre><code class="language-shell">root@node75:~# s3cmd mb s3://tenant-bucket01
Bucket 's3://tenant-bucket01/' created
root@node75:~# 
</code></pre>
<pre><code class="language-shell">root@node76:~# s3cmd mb s3://tenant-bucket01
Bucket 's3://tenant-bucket01/' created
root@node76:~# 
</code></pre>
<pre><code class="language-shell">root@node76:~# radosgw-admin bucket list
[
    "tenant1/tenant-bucket01",
    "tenant2/tenant-bucket01",
    "bigtera-admin-log-target-bucket"
]
root@node76:~#
</code></pre>
<p>这里并不需要指定tenant，因为rgw是以key去区分用户数据使用哪一个tenant的，至此，同名的bucket创建成功，可以看到，bucket是以符号"/"间隔开。</p>
<p>开始上传对象到这两个bucket中，分别上传不同的对象:</p>
<pre><code class="language-shell">root@node75:~# s3cmd put tenant1.png s3://tenant-bucket01
upload: 'tenant1.png' -&gt; 's3://tenant-bucket01/tenant1.png'  [1 of 1]
 8 of 8   100% in    0s   610.87 B/s  done
root@node75:~#
</code></pre>
<pre><code class="language-shell">root@node76:~# s3cmd put tenant2.png s3://tenant-bucket01
upload: 'tenant2.png' -&gt; 's3://tenant-bucket01/tenant2.png'  [1 of 1]
 27 of 27   100% in    0s  2019.45 B/s  done
root@node76:~#
</code></pre>
<p>查看对象上传效果：</p>
<pre><code class="language-shell">root@node75:~# s3cmd ls s3://tenant-bucket01
2020-06-16 06:58         8   s3://tenant-bucket01/tenant1.png
root@node75:~#
</code></pre>
<pre><code class="language-shell">root@node76:~# s3cmd ls s3://tenant-bucket01/
2020-06-16 07:03        27   s3://tenant-bucket01/tenant2.png
root@node76:~#
</code></pre>
<h1 id="zong-jie">总结</h1>
<p>本文所示的多租户，解决了如下问题：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>实现同集群中创建同名bucket和S3账号，即实现租户的数据隔离。</p>
</li>
</ul>
<p>而实际应用要远比本文所示要复杂的多，比如不同tenant之间不同bucket下的数据共享，这就涉及到RGW bucket policy 设置问题了。</p>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>API响应慢问题复现</title>
    <url>/2020/06/12/reproduce_slow_api_issue/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>现在测试有个需求，需要验证某个API响应时间，之所以关注这个API时间，是因为有时响应太久，超过30s，估计这个时间客户也无法容忍。</p>
<h1 id="ju-ti-yao-qiu">具体要求</h1>
<p>具体的API是RAID界面，去list出RAID卡上所有的VD，PD，SSD，RAID card等诸多信息，如果响应时间超过预定时间，比如30s，则认为API出状况了。</p>
<p>上述过程，使用测试脚本完成，一旦响应时间超过预定时间，程序退出。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="shell">shell</h2>
<pre><code class="language-shell">root@node76:~# cat raid_api_elapsed.sh
#!/bin/bash

PUBLIC_IP=7.73.7.76
STORAGE_IP=1.1.1.76
TIMEOUT=30
LOG_FILE=./raid_api_elapsed.log

# Login
login_res=`curl --insecure --cookie-jar cookie.jar -s -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${PUBLIC_IP}:8080/auth" --data '{"password": "1", "user_id": "admin"}'`
login_return_code=`echo ${login_res} | sed 's@{"name": "login", "return_code": @@' | sed 's/}//'`

if [ x"${login_return_code}" == x"300" ]; then
    echo ""
    echo "[ERROR]  Login Failed, exit!!!"
    echo ""
    exit 1
elif [[ ${login_return_code} =~ 'session_id' ]]; then
    echo ""
    echo "Login success"
    echo ""
fi

echo "======================================================= RAID API Elapsed Time Test =======================================================" | tee ${LOG_FILE}

while :
do
    # RAID API
    # start_time=`date +%F-%H-%M.%N`
    start_time=`date "+%Y-%m-%d %H:%M:%S"`
    start_time_stamp=`date -d "${start_time}" +%s`
    start_mills=$((${start_time_stamp}*1000+`date "+%N" | sed 's/^[0]*//'`/1000000))

    result_code=`curl --insecure --cookie cookie.jar --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" -s -I -m ${TIMEOUT} -w %{http_code} "https://${PUBLIC_IP}:8080/system/host/${STORAGE_IP}/disk/raid"`
    end_time=`date "+%Y-%m-%d %H:%M:%S"`
    end_time_stamp=`date -d "${end_time}" +%s`
    end_mills=$((${end_time_stamp}*1000+`date "+%N" | sed 's/^[0]*//'`/1000000))

    if [[ ${result_code} =~ '200' ]]; then
        time_diff=`expr ${end_mills} - ${start_mills}`
        echo "${end_time}  --&gt; OK, elapsed time is : (${time_diff} milliseconds), now sleep 2s" | tee ${LOG_FILE}
        sleep 2
    elif [[ ${result_code} =~ '401'  ]]; then
        echo "[WARN]  Session timeout, login again"
        curl --insecure --cookie-jar cookie.jar -s -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${PUBLIC_IP}:8080/auth" --data '{"password": "1", "user_id": "admin"}'
    else
        echo "${end_time}  [ERROR]  Cost more than ${TIMEOUT}s, exit!" | tee ${LOG_FILE}
        echo ""
        exit 1
    fi
done
</code></pre>
<p>核心是-s -I -m 10 -w %{http_code}，解释一下携带的参数信息：</p>
<pre><code class="language-shell">-I 仅测试HTTP头

-m 10 最多查询10s

-o /dev/null 屏蔽原有输出信息

-s silent 模式，不输出任何东西

-w %{http_code} 控制额外输出
</code></pre>
<p>这里还有另外一个方法:</p>
<pre><code class="language-shell">root@node76:~# curl --insecure --cookie cookie --header 'Accept: application/json, text/javascript, */*; q=0.01' --header 'Content-Type: application/json' -o /dev/null -s -w "time_connect: %{time_connect}\ntime_starttransfer: %{time_starttransfer}\ntime_total: %{time_total}\n" https://7.73.7.76:8080/system/host/1.1.1.76/disk/raid
time_connect: 0.000
time_starttransfer: 8.435
time_total: 8.436
root@node76:~# 
</code></pre>
<p>可以根据time_total时间来判断，此时间超过一定值，就退出。</p>
<pre><code class="language-shell">root@node76:~# cat raid_api_elapsed2.sh 
#!/bin/bash

PUBLIC_IP=7.73.7.76
STORAGE_IP=1.1.1.76
TIMEOUT=30
LOG_FILE=./raid_api_elapsed.log

# Login
login_res=`curl --insecure --cookie-jar cookie.jar -s -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${PUBLIC_IP}:8080/auth" --data '{"password": "1", "user_id": "admin"}'`
login_return_code=`echo ${login_res} | sed 's@{"name": "login", "return_code": @@' | sed 's/}//'`

if [ x"${login_return_code}" == x"300" ]; then
    echo ""
    echo "[ERROR]  Login Failed, exit!!!"
    echo ""
    exit 1
elif [[ ${login_return_code} =~ 'session_id' ]]; then
    echo ""
    echo "Login success"
    echo ""
fi

echo "======================================================= RAID API Elapsed Time Test =======================================================" | tee ${LOG_FILE}

while :
do
    # RAID API
    start_time=`date "+%Y-%m-%d %H:%M:%S"`

    time_total=`curl --insecure --cookie cookie.jar --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" -o /dev/null -s -w "%{time_total}\n" "https://${PUBLIC_IP}:8080/system/host/${STORAGE_IP}/disk/raid"`
    end_time=`date "+%Y-%m-%d %H:%M:%S"`

    int_time_total=`echo $time_total | cut -d '.' -f1`
    if [[ ${int_time_total} -lt ${TIMEOUT} ]]; then
        echo "${end_time}  --&gt; OK, elapsed time is : (${time_total} milliseconds), now sleep 2s" | tee ${LOG_FILE}
        sleep 2
    elif [[ ${result_code} =~ '401'  ]]; then
        echo "[WARN]  Session timeout, login again"
        curl --insecure --cookie-jar cookie.jar -s -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${PUBLIC_IP}:8080/auth" --data '{"password": "1", "user_id": "admin"}'
    else
        echo "${end_time}  [ERROR]  Cost time : (${time_total}) is more than ${TIMEOUT}s, exit!" | tee ${LOG_FILE}
        echo ""
        exit 1
    fi
done
</code></pre>
<h2 id="python">python</h2>
<pre><code class="language-python">root@node76:~# cat raid_api_elapsed.py 
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import unicode_literals

import sys
import json
import time
import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)


class HttpSession(requests.Session):
    """  http request session  """

    def __init__(self):
        super(HttpSession, self).__init__()

        # Not verify SSL certificate
        self.verify = False

        # timeout time
        self.timeout = (60, 600)

        # session information
        self.session = ""

    def login_session(self, user_id, password, public_ip):
        """ Login Session """
        login_url = "https://{}:8080/auth".format(public_ip)

        login_data = {"user_id": user_id,
                     "password": password}

        self.session = requests.session()
        self.session.keep_alive = False
        self.session.headers.update({'Accept': 'application/json, text/javascript, */*; q=0.01'})
        # print("[Login]    login_url: %s, login_data: %s", login_url, json.dumps(login_data))
        response = self.session.request("POST", login_url, json=login_data, verify=False)

        if response.status_code != 200:
            print("[ERROR]  Login web error, http status code is {}".format(response.status_code))
            sys.exit(1)

        return self.session

    def http_request(self, session, http_method, url, user_id, password, public_ip, params=None, data=None):
        """  Send HTTP request, support GET/POST  """
        params = {} if params is None else params
        data = {} if data is None else data

        # set SSL Verify to False
        session.verify = False

        # Set session keep alive to False
        session.keep_alive = False

        try:
            start_time = time.time()
            start_trans = time.localtime(start_time)
            format_start_time = time.strftime('%Y-%m-%d %H:%M:%S.%3d', start_trans)

            if "cgi-bin" in url:
                # Legacy CGI
                response = session.request(http_method, url, params=params, data=data)
                if response.status_code == 401:
                    session = self.login_session(user_id, password, public_ip)
                    response = session.request(http_method, url, params=params, data=data)
            else:
                # Restful CGI
                response = session.request(http_method, url, params=params, json=data)

                if response.status_code == 401:
                    session = self.login_session(user_id, password, public_ip)
                    response = session.request(http_method, url, params=params, json=data)

            elapsed_sec = response.elapsed.seconds
            if elapsed_sec &gt;= 30:
                print("[{}]  [ERROR]  URL response elapsed time : ({}), return_text : ({})".format(format_start_time, elapsed_sec, response.text))
                sys.exit(1)
            else:
                print("[{}]    URL response elapsed time : ({})".format(format_start_time, elapsed_sec))
        except Exception as ex:
            print("[WARN]  Session request exception : (%s)", str(ex))

        return response


def call_raid_api(user_id, password, http_method, url, public_ip, storage_ip):
    """  Call API """
    session = HttpSession()
    login_s = session.login_session(user_id, password, public_ip)

    for i in xrange(100):
        session.http_request(login_s, http_method, url, user_id, password, public_ip) 


if __name__ == '__main__':
    public_ip = '7.73.7.76'
    storage_ip = '1.1.1.76'
    user_id = 'admin'
    password = '1'
    http_method = 'GET'
    url = "https://{}:8080/system/host/{}/disk/raid".format(public_ip, storage_ip)

    call_raid_api(user_id, password, http_method, url, public_ip, storage_ip)
</code></pre>
<h1 id="ce-shi-xiao-guo-ru-xia">测试效果如下：</h1>
<h2 id="shell-1">shell</h2>
<pre><code class="language-shell">root@node76:~# tailf raid_api_elapsed.log 
2020-06-12 12:41:05  --&gt; OK, elapsed time is : (8433 milliseconds), now sleep 2s
2020-06-12 12:41:27  --&gt; OK, elapsed time is : (8514 milliseconds), now sleep 2s
2020-06-12 12:41:37  --&gt; OK, elapsed time is : (8698 milliseconds), now sleep 2s
2020-06-12 12:41:48  --&gt; OK, elapsed time is : (8518 milliseconds), now sleep 2s
2020-06-12 12:42:09  --&gt; OK, elapsed time is : (8436 milliseconds), now sleep 2s
2020-06-12 12:42:20  --&gt; OK, elapsed time is : (8660 milliseconds), now sleep 2s
2020-06-12 12:42:51  --&gt; OK, elapsed time is : (8559 milliseconds), now sleep 2s
2020-06-12 12:43:02  --&gt; OK, elapsed time is : (8501 milliseconds), now sleep 2s
2020-06-12 12:43:12  --&gt; OK, elapsed time is : (8597 milliseconds), now sleep 2s
2020-06-12 12:43:23  --&gt; OK, elapsed time is : (8470 milliseconds), now sleep 2s
.................................. 中间省略 ....................................
2020-06-12 12:53:50  --&gt; OK, elapsed time is : (8632 milliseconds), now sleep 2s
2020-06-12 12:54:00  --&gt; OK, elapsed time is : (8605 milliseconds), now sleep 2s
2020-06-12 12:54:22  --&gt; OK, elapsed time is : (8526 milliseconds), now sleep 2s
2020-06-12 12:55:04  --&gt; OK, elapsed time is : (8507 milliseconds), now sleep 2s
2020-06-12 12:55:14  --&gt; OK, elapsed time is : (8483 milliseconds), now sleep 2s
2020-06-12 12:56:07  --&gt; OK, elapsed time is : (8357 milliseconds), now sleep 2s
2020-06-12 12:56:39  --&gt; OK, elapsed time is : (8671 milliseconds), now sleep 2s
2020-06-12 12:56:50  --&gt; OK, elapsed time is : (8573 milliseconds), now sleep 2s
2020-06-12 12:57:11  --&gt; OK, elapsed time is : (8435 milliseconds), now sleep 2s
2020-06-12 12:57:26  [ERROR]  Cost more than 30s, exit!
</code></pre>
<h2 id="python-1">python</h2>
<pre><code class="language-shell">root@node76:~# python raid_api_elapsed.py 
[2020-06-12 14:33:13.012]    URL response elapsed time : (8)
[2020-06-12 14:33:22.012]    URL response elapsed time : (8)
[2020-06-12 14:33:30.012]    URL response elapsed time : (8)
[2020-06-12 14:33:39.012]    URL response elapsed time : (8)
[2020-06-12 14:33:48.012]    URL response elapsed time : (8)
[2020-06-12 14:33:56.012]    URL response elapsed time : (8)
[2020-06-12 14:34:05.012]    URL response elapsed time : (8)
[2020-06-12 14:34:13.012]    URL response elapsed time : (8)
.......................... 中间省略 .........................
[2020-06-12 14:39:30.012]    URL response elapsed time : (8)
[2020-06-12 14:39:38.012]    URL response elapsed time : (13)
[2020-06-12 14:39:52.012]    URL response elapsed time : (8)
.......................... 中间省略 .........................
[2020-06-12 14:44:19.012]    URL response elapsed time : (9)
[2020-06-12 14:44:29.012]    URL response elapsed time : (9)
[2020-06-12 14:44:38.012]    URL response elapsed time : (9)
[2020-06-12 14:44:47.012]    URL response elapsed time : (8)
[2020-06-12 14:44:55.012]    URL response elapsed time : (9)
[2020-06-12 14:45:05.012]    URL response elapsed time : (9)
[2020-06-12 14:45:14.012]    URL response elapsed time : (8)
[2020-06-12 14:45:23.012]    URL response elapsed time : (8)
[2020-06-12 14:45:31.012]    URL response elapsed time : (8)
[2020-06-12 14:45:40.012]  [ERROR]  URL response elapsed time : (39), return_text : ({"assigned": [{"vd": "0", "current_cache_policy": "WriteThrough, ReadAheadNone, Direct, No Write Cache if Bad BBU", "drive_num": "7", "pds": [{"slot": "1", "copyback_progress": null, "other_error": 0, "healthy": "none", "rebuild_progress": null, "adapter": null, "size": "7.277 TB", "media_error": 0, "pd_type": "SATA", "lifetime_remaining": -1, "firmware_state": "Online, Spun Up", "pd": "0", "media_type": "HDD", "device_id": "38", "smart_info": "smartctl 7.0 2018-12-30 r4883 [x86_64-linux-4.14.148-server] (local build)\nCopyright (C) ....后面省略，这里展示具体的response详细信息...
</code></pre>
<h1 id="qi-ta">其他</h1>
<p>看了同事写的一个python版本，非常简洁，不过没有考虑session过期问题，脚本内容参考如下:</p>
<pre><code class="language-python">root@246:/home# cat c.py 
# -*- coding: utf-8 -*-

import time
import urllib3
import requests

urllib3.disable_warnings()

ip = "1.1.7.246"
storage_ip = "1.1.1.246"
headers = {"accept": "application/bigtera.vs.v1+json, application/json"}

session = requests.Session()
# login
url = "https://{}:8080/auth".format(ip)
response = session.post(
    url, json={"user_id": "admin", "password": "1"}, headers=headers, verify=False
)

while True:
    start = time.time()
    # get raid info
    url = "https://{}:8080/system/host/{}/disk/raid".format(ip, storage_ip)
    response = session.get(url, headers=headers, verify=False)
    end = time.time()
    try:
        response.raise_for_status()
    except Exception as e:
        print(e)
        break

    if end - start &gt; 10:
        print("last request cost {} seconds", end - start)
        break
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>快速获取Lab中哪些IPMI IP地址被使用</title>
    <url>/2020/06/23/get_lab_ipmi_address/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Lab里有一大批设备，每个设备都配置了IPMI地址，虽然Office提供了一个在线的excel供大家编辑，但未必每个人都会定期去更新它（因为设备偶尔有进有出），时间久了就会发现excel记录太旧了。</p>
<p>本文不是介绍如何定期更新excel，而是如何快速获取哪些IPMI地址在使用。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="li-yong-ping-huo-qu-na-xie-di-zhi-bei-shi-yong">利用ping获取哪些地址被使用</h2>
<pre><code class="language-shell">#!/bin/bash

for ip in 1.72.5.{1..255};
do
    ping $ip -c 2 &amp;&gt; /dev/null
    if [ $? -eq 0 ]; then
        echo "($ip) is alive"
    fi
done

</code></pre>
<p>看看执行耗时：</p>
<pre><code class="language-shell">root@node77:~# time bash ping.sh 2&gt;&amp;1 &gt;/dev/null

real	12m47.366s
user	0m0.161s
sys	0m0.627s
root@node77:~# 
</code></pre>
<p>在这个脚本中，每个ping是顺次独立执行的，即每个IP地址都会被ping到，每执行有ping，都会有一段最低2秒的时延（-c 2），很明显，把255给都ping一遍，起码255*2s的时间，效率太低了。</p>
<h2 id="shell-gai-jin">shell 改进</h2>
<p>改进上述脚本的操作，使用并发，要想并发，可将循环体放在()&amp;中，将命令放在()，使其中的命令可作为shell的子shell来执行，而&amp;脱离当前线程，在后台继续执行，改进后如下：</p>
<pre><code class="language-shell">#!/bin/bash

for ip in 1.72.5.{1..255};
do
(
    ping $ip -c 2 &amp;&gt; /dev/null
    if [ $? -eq 0 ]; then
        echo "($ip) is alive"
    fi
)&amp;

wait

done
</code></pre>
<p>看看执行耗时：</p>
<pre><code class="language-shell">root@node77:~# time bash ping2.sh 2&gt;&amp;1 &gt;/dev/null

real	12m31.581s
user	0m0.326s
sys	0m0.849s
root@node77:~# 
</code></pre>
<p>从时间上看，基本没差啊，整体上时间还是非常的久，有没有更好的办法？答案是肯定的，使用fping，但fping Linux系统不自带，需要自行安装，安装地址参考如下： <code>https://pkgs.org/download/fping </code></p>
<h2 id="shi-yong-fping">使用fping</h2>
<p>fping类似于ping，但比ping强大的多。与ping要等待某一主机连接超时或发回反馈信息不同，fping给一个主机发送完数据包后，马上给下一个主机发送数据包，实现多主机同时ping。</p>
<p>看一下官方解释：</p>
<pre><code class="language-shell">NAME
       fping - send ICMP ECHO_REQUEST packets to network hosts

SYNOPSIS
       fping [ options ] [ systems... ] fping6 [ options ] [ systems... ]

DESCRIPTION
       fping is a program like ping which uses the Internet Control Message Protocol (ICMP) echo request to determine if a target host is responding.  fping differs from ping in that you can specify any number of targets on the command line, or specify a file
       containing the lists of targets to ping.  Instead of sending to one target until it times out or replies, fping will send out a ping packet and move on to the next target in a round-robin fashion.  In the default mode, if a target replies, it is noted and
       removed from the list of targets to check; if a target does not respond within a certain time limit and/or retry limit it is designated as unreachable. fping also supports sending a specified number of pings to a target, or looping indefinitely (as in ping
       ). Unlike ping, fping is meant to be used in scripts, so its output is designed to be easy to parse.

       The binary named fping6 is the same as fping, except that it uses IPv6 addresses instead of IPv4.
</code></pre>
<p>测试一下fping的效果：</p>
<pre><code class="language-shell">root@node77:~# time fping -s -a -q -g 1.72.5.0/24
1.72.5.111
1.72.5.114
1.72.5.115
1.72.5.116
1.72.5.117
1.72.5.118
1.72.5.124
1.72.5.125
1.72.5.126
1.72.5.127
1.72.5.128
1.72.5.181
1.72.5.182
1.72.5.183
1.72.5.195
1.72.5.196
1.72.5.197
1.72.5.199
1.72.5.202
1.72.5.204
1.72.5.205
1.72.5.206
1.72.5.207
1.72.5.208
1.72.5.209
1.72.5.210
1.72.5.211
1.72.5.212
1.72.5.213
1.72.5.214
1.72.5.215
1.72.5.216
1.72.5.217
1.72.5.218
1.72.5.220
1.72.5.221
1.72.5.222
1.72.5.223
1.72.5.229
1.72.5.231
1.72.5.233
1.72.5.234
1.72.5.235
1.72.5.249
1.72.5.251
1.72.5.252
1.72.5.253
1.72.5.254
1.72.5.53
1.72.5.141
1.72.5.144
1.72.5.151
1.72.5.152
1.72.5.153
1.72.5.154
1.72.5.160
1.72.5.165
1.72.5.166
1.72.5.167
1.72.5.169
1.72.5.174
1.72.5.175
1.72.5.176
1.72.5.177

     254 targets
      64 alive
     190 unreachable
       0 unknown addresses

     190 timeouts (waiting for response)
     840 ICMP Echos sent
      64 ICMP Echo Replies received
     714 other ICMP received

 0.15 ms (min round trip time)
 0.38 ms (avg round trip time)
 2.00 ms (max round trip time)
       22.798 sec (elapsed real time)


real	0m22.801s
user	0m0.007s
sys	0m0.077s
root@node77:~# 
</code></pre>
<p>效率非常的高，不足23秒，而且输出的IP地址就是alive的，并增加了汇总信息，非常的直观。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>fping</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>fping</tag>
      </tags>
  </entry>
  <entry>
    <title>统计两个时间的时间差</title>
    <url>/2020/06/28/calc_time_difference/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近在跑cosbench，由于OS根分区空间满，导致cosbench任务失败，误删了一部分cosbench archive记录，但controller html页面还是能展示这部分数据记录的片段信息，比如任务的提交时间，起始时间与结束时间，而每个cosbench 任务写数据的总量可以从定义的xml中获取到，需要手动计算一下起止时间差，统计总量/时间差，就可以得到这轮任务的平均写速度了。</p>
<p>本文介绍通过script计算前后两个时间差，每次都记不住，这次写下来，避免每次都去查资料重新写script。</p>
<h1 id="jiao-ben-nei-rong">脚本内容</h1>
<p>参考如下：</p>
<pre><code class="language-python">root@node244:~/75# cat timestamp_calc.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

from __future__ import unicode_literals

import sys
from datetime import datetime

if len(sys.argv) == 3:
    start = datetime.strptime(sys.argv[1], '%Y-%m-%d %H:%M:%S')
    end = datetime.strptime(sys.argv[2], '%Y-%m-%d %H:%M:%S')
    print (end-start).seconds
else:
    print "\nUsage: %s start_time end_time" % sys.argv[0]
    print "  e.g: %s '2020-06-28 09:18:59' '2020-06-28 10:00:33' \n" % sys.argv[0]
    sys.exit(2)

root@node244:~/75#
</code></pre>
<h1 id="yun-xing-xiao-guo">运行效果</h1>
<pre><code class="language-shell">root@node244:~/75# python timestamp_calc.py '2020-06-28 10:49:18' '2020-06-28 11:22:53'
2015
root@node244:~/75# 
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>wc统计为何少了一行</title>
    <url>/2020/06/29/why_wc_lost_one_line/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>使用<code>wc</code>统计文件时，发现文件数量总是少一行，原因何在？</p>
<h1 id="shi-jian">实践</h1>
<h2 id="zhun-bei-gong-zuo">准备工作</h2>
<p>分布准备两个文件，一个是<code>Linux</code>平台下通过vi写入的，一个文件是在windows平台，通过记事本写入的，内容如下：</p>
<pre><code class="language-shell">root@node244:~/test# cat wins.txt 
1
2
3
4
5
6
7
8
9
0root@node244:~/test# cat linux.txt 
1
2
3
4
5
6
7
8
9
0
root@node244:~/test#
</code></pre>
<p>注意这里的区别:</p>
<img class="shadow" src="/img/in-post/end_of_file_content.png" height="300px" width="300px">
<h2 id="tong-ji-xiao-guo">统计效果</h2>
<pre><code class="language-shell">root@node244:~/test# wc -l wins.txt 
9 wins.txt
root@node244:~/test# wc -l linux.txt 
10 linux.txt
root@node244:~/test# 
</code></pre>
<p>明明文件记录是10条，为何windows平台生成的文件，统计少了？</p>
<h2 id="yuan-yin-fen-xi">原因分析</h2>
<p><code>wc -l</code> 是按\n作为行结束符统计行数，所以最后一行如果没有\n的话会统计丢失。</p>
<pre><code class="language-shell">root@node244:~/test# cat linux.txt | od -c
0000000   1  \n   2  \n   3  \n   4  \n   5  \n   6  \n   7  \n   8  \n
0000020   9  \n   0  \n
0000024
root@node244:~/test# cat wins.txt | od -c
0000000   1  \r  \n   2  \r  \n   3  \r  \n   4  \r  \n   5  \r  \n   6
0000020  \r  \n   7  \r  \n   8  \r  \n   9  \r  \n   0
0000034
root@node244:~/test# 
</code></pre>
<p>两者的区别如下:</p>
<img class="shadow" src="/img/in-post/end_of_file.png" width="1200">
<p>通过od -c指令，可以看到，windows生成的文件，最后一笔记录后面是没有换行符的，而linux是有的，同时也发现，linux只有\n，这表示换行符，而windows，\r \n，这表示回车换行符，两者是有区别的，即EOF不一样，Linux占用2bytes，而windows占用4bytes，下图是通过UE这个文本编辑器，分别对Linux和windows下产生的文件，转换成16进制看到的效果:</p>
<img class="shadow" src="/img/in-post/HX_diff.png" width="2400">
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>Linux平台上，<code>dos2unix</code>一把 windows产生的文件即可。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>awk引用shell中变量</title>
    <url>/2020/07/01/awk_refers_variables_in_shell/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在网上找了一个统计pool下pg分布的脚本，拿来使用了一下，发现可以在ceph J版上执行，在L版报错，原脚本内容参考如下:</p>
<pre><code class="language-shell">ceph pg dump | egrep -v "^[0-9]*  " | awk '
/^pg_stat/ { col=1; while($col!="up") {col++}; col++ }
/^[0-9a-f]+.[0-9a-f]+/ { match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;
up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) { osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) }
for(i in osds) {array[osds[i],pool]++; osdlist[osds[i]];}
}
END {
printf("\n");
printf("pool :\t"); for (i in poollist) printf("%s\t",i); printf("| SUM \n");
for (i in poollist) printf("--------"); printf("-------------\n");
for (i in osdlist) { printf("osd.%i\t", i); sum=0;
for (j in poollist) { printf("%i\t", array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] }; printf("| %i\n",sum) }
for (i in poollist) printf("--------"); printf("--------------\n");
printf("SUM :\t"); for (i in poollist) printf("%s\t",poollist[i]); printf("|\n");
}'
</code></pre>
<p>本文讲述awk如何引用shell变量，来解决上面这个脚本对我们产品的兼容问题。</p>
<h1 id="shi-jian">实践</h1>
<p>修改后的脚本参考如下:</p>
<pre><code class="language-shell">ceph_version=`ceph -v | awk '{{print $3}}'`

if [[ ${ceph_version} =~ '10.' ]]; then
    pg_stat="pg_stat"
    up="up"
elif [[ ${ceph_version} =~ '12.' ]]; then
    pg_stat="PG_STAT"
    up="UP"
fi

ceph pg dump | egrep -v "^[0-9]*  " | awk '
/^'$pg_stat'/ { col=1; while($col!="'"$up"'") {col++}; col++ }
/^[0-9a-f]+.[0-9a-f]+/ { match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;
up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) { osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) }
for(i in osds) {array[osds[i],pool]++; osdlist[osds[i]];}
}
END {
printf("\n");
printf("pool :\t"); for (i in poollist) printf("%s\t",i); printf("| SUM \n");
for (i in poollist) printf("--------"); printf("-------------\n");
for (i in osdlist) { printf("osd.%i\t", i); sum=0;
for (j in poollist) { printf("%i\t", array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] }; printf("| %i\n",sum) }
for (i in poollist) printf("--------"); printf("--------------\n");
printf("SUM :\t"); for (i in poollist) printf("%s\t",poollist[i]); printf("|\n");
}'
</code></pre>
<h1 id="awk-yin-yong-shell-zhong-bian-liang">awk引用shell中变量</h1>
<h2 id="fang-fa-1-code-quot-var-quot-code">方法1： <code>"'$var'" </code></h2>
<p>这种写法大家无需改变用’括起awk程序的习惯,是老外常用的写法.如:</p>
<pre><code class="language-shell">var="test"

awk 'BEGIN{print "'$var'"}'
</code></pre>
<p>这种写法其实就是把一对单引号分成了两段单引号，中间的shell变量直接按照shell变量的引用方式即可，但是如果var中含空格,为了shell不把空格作为分格符,便应该如下使用:</p>
<pre><code class="language-shell">var="thisis a test"

awk 'BEGIN{print "'"$var"'"}'    （也就是在shell变量的两边加上一对双引号即可）
</code></pre>
<h2 id="fang-fa-2-export-bian-liang">方法2：export变量</h2>
<p>使用ENVIRON[“var”]形式, (ENVIRON为awk中的内置环境变量数组)</p>
<p>如:</p>
<pre><code class="language-shell">var="thisis a test";export $var

awk 'BEGIN{print ENVIRON["var"]}'
</code></pre>
<h2 id="fang-fa-3-shi-yong-v-xuan-xiang">方法3：使用-v选项</h2>
<p>如:</p>
<pre><code class="language-shell">var="thisis a test"

awk –v nvar="$var"  'BEGIN{print nvar}'
</code></pre>
<p>这样便把系统变量定义成了awk变量.</p>
<p>如果在awk是这种格式的话 <code>awk  'script'  filename</code> 也可以这样引用shell变量</p>
<pre><code class="language-shell">awk 'script' awkvar="shellvar" filename

awk 'END{print awkvar}' awkvar="$shellvar" filename
</code></pre>
<h1 id="huan-you-yi-ge-python-ban-ben">还有一个python版本</h1>
<p>参考如下:</p>
<pre><code class="language-python">#!/usr/bin/env  python
import sys 
import os
import json

ceph_version_cmd = "ceph -v | awk '{{print $3}}'"
_vers = os.popen(ceph_version_cmd).read()
if '10.' in _vers:
    cmd = '''
ceph pg dump | awk ' /^pg_stat/ { col=1; while($col!="up") {col++}; col++ } /^[0-9a-f]+\.[0-9a-f]+/ {print $1,$col}'
'''
elif '12.' in _vers:
    cmd = '''
ceph pg dump | awk ' /^PG_STAT/ { col=1; while($col!="UP") {col++}; col++ } /^[0-9a-f]+\.[0-9a-f]+/ {print $1,$col}'
'''

body = os.popen(cmd).read()
SUM = {}
for line in  body.split('\n'):
   if not line.strip():
     continue
   SUM[line.split()[0]] = json.loads(line.split()[1])
pool = set()
for  key in  SUM:
  pool.add(key.split('.')[0])
mapping = {}
for number in pool:
  for k,v in SUM.items():
    if k.split('.')[0] == number:
       if number in mapping:
           mapping[number] += v
       else:
           mapping[number] = v
MSG = """%(pool)-6s: %(pools)s | SUM
%(line)s
%(dy)s
%(line)s
%(sun)-6s: %(end)s |"""
pools = " ".join(['%(a)-6s' % {"a": x} for x in sorted(list(mapping))])
line = len(pools) + 20
MA = {}
OSD = []
for p in mapping:
    osd = sorted(list(set(mapping[p])))
    OSD += osd
    count = sum([mapping[p].count(x) for x in osd])
    osds = {}
    for x in osd:
        osds[x] = mapping[p].count(x)
    MA[p] = {"osd": osds, "count": count}
MA = sorted(MA.items(), key=lambda x:x[0])
OSD = sorted(list(set(OSD)))
DY = ""
for osd in OSD:
    count = sum([x[1]["osd"].get(osd,0) for x in MA])
    w = ["%(x)-6s" % {"x": x[1]["osd"].get(osd,0)} for x in MA]
    #print w
    w.append("| %(x)-6s" % {"x": count})
    DY += 'osd.%(osd)-3s %(osds)s\n' % {"osd": osd, "osds": " ".join(w)}
SUM = " ".join(["%(x)-6s" % {"x": x[1]["count"]} for x in MA])
msg = {"pool": "pool", "pools": pools, "line": "-" * line, "dy": DY, "end": SUM, "sun": "SUM"}
print MSG % msg
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>ceph</category>
        <category>awk</category>
      </categories>
      <tags>
        <tag>awk</tag>
        <tag>shell</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>shell中|&amp;含义</title>
    <url>/2020/06/30/what_means_pipeline_and/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天细看了同事Henry编写的一个shell脚本，看到如下片断内容：</p>
<pre><code class="language-shell">    while (( $(${CLI} info |&amp; grep PROCESSING | wc -l) &gt;= 1 )); do
        sleep 60
    done
</code></pre>
<p>这里有一个<code>'|&amp;' </code>，不明觉厉~  (#<sup>.</sup>#)</p>
<h1 id="wo-de-yi-huo">我的疑惑</h1>
<p><code>'|&amp;' </code> 是什么意思？</p>
<p>man了下bash，得到如下信息：</p>
<pre><code class="language-shell">   Pipelines
       A pipeline is a sequence of one or more commands separated by one of the control operators | or |&amp;.  The format for a pipeline is:

              [time [-p]] [ ! ] command [ [|?|&amp;] command2 ... ]

       The  standard  output of command is connected via a pipe to the standard input of command2.  This connection is performed before any redirections specified by the command (see REDIRECTION below).  If |&amp; is used, command's standard error, in addition to its
       standard output, is connected to command2's standard input through the pipe; it is shorthand for 2&gt;&amp;1 |.  This implicit redirection of the standard error to the standard output is performed after any redirections specified by the command.

       The return status of a pipeline is the exit status of the last command, unless the pipefail option is enabled.  If pipefail is enabled, the pipeline's return status is the value of the last (rightmost) command to exit with a non-zero status, or zero if all
       commands  exit  successfully.   If  the  reserved word !  precedes a pipeline, the exit status of that pipeline is the logical negation of the exit status as described above.  The shell waits for all commands in the pipeline to terminate before returning a
       value.

       If the time reserved word precedes a pipeline, the elapsed as well as user and system time consumed by its execution are reported when the pipeline terminates.  The -p option changes the output format to that specified by POSIX.  When the shell is in posix
       mode,  it  does  not  recognize time as a reserved word if the next token begins with a `-'.  The TIMEFORMAT variable may be set to a format string that specifies how the timing information should be displayed; see the description of TIMEFORMAT under Shell
       Variables below.

       When the shell is in posix mode, time may be followed by a newline.  In this case, the shell displays the total user and system time consumed by the shell and its children.  The TIMEFORMAT variable may be used to specify the format of the time information.

       Each command in a pipeline is executed as a separate process (i.e., in a subshell).
</code></pre>
<p>这里解释的非常清楚了，<code>'|&amp;' </code> 等价于  <code>'2&gt;&amp;1|' </code>，前者是后者的简写方式，将标准错误输出(stderr)隐式重定向到标准输出(stdout)是在命令指定的任何重定向之后执行的。</p>
<h1 id="qi-ta-xin-xi">其他信息</h1>
<p>最早是csh/tcsh里有这个特性，被bash和zsh学过来了，ksh里<code>'|&amp;' </code> 是另外一种用法，表示的是协同处理。</p>
<p>如果你的shell不支持这种特性，一旦脚本中含有<code>'|&amp;' </code>，执行时报错：</p>
<p><code>Syntax error: "&amp;" unexpected </code></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>频繁启用&amp;停用ES服务，出现local-fs.target failed with result dependency</title>
    <url>/2020/06/22/disable_es_local_fs.target_failed_with_result_dependency/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Ubuntu16.04，产品新增了Elasticsearch功能，在测试ES服务启用过程冲，选择240G 的Intel S4510 型号的SSD一块作为ES的data：</p>
<pre><code class="language-shell">Model Family:     Intel S4510/S4610/S4500/S4600 Series SSDs
Device Model:     INTEL SSDSC2KG240G8
</code></pre>
<p>在频繁测试ES服务启&amp;停过程中，发现有个node上的众多服务接收到终止信号(15),而且复现几率非常的高,此时ipmi console出现如下信息：</p>
<img class="shadow" src="/img/in-post/emergency_mode.png" width="1200">
<p>执行systemctl --failed，信息如下：</p>
<img class="shadow" src="/img/in-post/systemctl_failed.png" width="1200">
<p>使用 ‘journalctl -xb’，dump的信息中，未找到问题发生的原因，只有类似如下的片断信息：</p>
<pre><code class="language-shell">Jun 19 18:20:17 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:17 node76 multipath[829224]: sdf: using deprecated getuid callout
Jun 19 18:20:18 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:18 node76 kernel:  sdf: sdf1
Jun 19 18:20:18 node76 multipath[829250]: sdf: using deprecated getuid callout
Jun 19 18:20:19 node76 multipath[829286]: sdf: using deprecated getuid callout
Jun 19 18:20:19 node76 sshd[829305]: Accepted publickey for root from 10.10.10.75 port 53688 ssh2: RSA SHA256:5/ngrgVfOOOLNuPyS1dflwHrc/sN9BSgDxNHVmJA0UE
Jun 19 18:20:19 node76 sshd[829305]: pam_unix(sshd:session): session opened for user root by (uid=0)
Jun 19 18:20:19 node76 systemd-logind[1841]: New session 3065 of user root.
-- Subject: A new session 3065 has been created for user root
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A new session with the ID 3065 has been created for the user root.
--
-- The leading process of the session is 829305.
Jun 19 18:20:19 node76 systemd[1]: Started Session 3065 of user root.
-- Subject: Unit session-3065.scope has finished start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit session-3065.scope has finished starting up.
--
-- The start-up result is done.
Jun 19 18:20:19 node76 multipath[829322]: sdf: using deprecated getuid callout
Jun 19 18:20:19 node76 sshd[829305]: Received disconnect from 10.10.10.75 port 53688:11: disconnected by user
Jun 19 18:20:19 node76 sshd[829305]: Disconnected from 10.10.10.75 port 53688
Jun 19 18:20:19 node76 sshd[829305]: pam_unix(sshd:session): session closed for user root
Jun 19 18:20:19 node76 systemd-logind[1841]: Removed session 3065.
-- Subject: Session 3065 has been terminated
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A session with the ID 3065 has been terminated.
Jun 19 18:20:19 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:19 node76 sshd[829336]: Accepted publickey for root from 10.10.10.75 port 53694 ssh2: RSA SHA256:5/ngrgVfOOOLNuPyS1dflwHrc/sN9BSgDxNHVmJA0UE
Jun 19 18:20:19 node76 sshd[829336]: pam_unix(sshd:session): session opened for user root by (uid=0)
Jun 19 18:20:19 node76 kernel:  sdf: sdf1
Jun 19 18:20:19 node76 systemd-logind[1841]: New session 3066 of user root.
-- Subject: A new session 3066 has been created for user root
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A new session with the ID 3066 has been created for the user root.
--
-- The leading process of the session is 829336.
Jun 19 18:20:19 node76 systemd[1]: Started Session 3066 of user root.
-- Subject: Unit session-3066.scope has finished start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit session-3066.scope has finished starting up.
--
-- The start-up result is done.
Jun 19 18:20:19 node76 multipath[829356]: sdf: using deprecated getuid callout
Jun 19 18:20:19 node76 sshd[829336]: Received disconnect from 10.10.10.75 port 53694:11: disconnected by user
Jun 19 18:20:19 node76 sshd[829336]: Disconnected from 10.10.10.75 port 53694
Jun 19 18:20:19 node76 sshd[829336]: pam_unix(sshd:session): session closed for user root
Jun 19 18:20:19 node76 systemd-logind[1841]: Removed session 3066.
-- Subject: Session 3066 has been terminated
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A session with the ID 3066 has been terminated.
Jun 19 18:20:20 node76 sshd[829382]: Accepted publickey for root from 10.10.10.75 port 53696 ssh2: RSA SHA256:5/ngrgVfOOOLNuPyS1dflwHrc/sN9BSgDxNHVmJA0UE
Jun 19 18:20:20 node76 sshd[829382]: pam_unix(sshd:session): session opened for user root by (uid=0)
Jun 19 18:20:20 node76 systemd-logind[1841]: New session 3067 of user root.
-- Subject: A new session 3067 has been created for user root
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A new session with the ID 3067 has been created for the user root.
--
-- The leading process of the session is 829382.
Jun 19 18:20:20 node76 systemd[1]: Started Session 3067 of user root.
-- Subject: Unit session-3067.scope has finished start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit session-3067.scope has finished starting up.
--
-- The start-up result is done.
Jun 19 18:20:20 node76 sshd[829382]: Received disconnect from 10.10.10.75 port 53696:11: disconnected by user
Jun 19 18:20:20 node76 sshd[829382]: Disconnected from 10.10.10.75 port 53696
Jun 19 18:20:20 node76 sshd[829382]: pam_unix(sshd:session): session closed for user root
Jun 19 18:20:20 node76 systemd-logind[1841]: Removed session 3067.
-- Subject: Session 3067 has been terminated
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A session with the ID 3067 has been terminated.
Jun 19 18:20:20 node76 sshd[829415]: Accepted publickey for root from 10.10.10.75 port 53702 ssh2: RSA SHA256:5/ngrgVfOOOLNuPyS1dflwHrc/sN9BSgDxNHVmJA0UE
Jun 19 18:20:20 node76 sshd[829415]: pam_unix(sshd:session): session opened for user root by (uid=0)
Jun 19 18:20:20 node76 systemd-logind[1841]: New session 3068 of user root.
-- Subject: A new session 3068 has been created for user root
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A new session with the ID 3068 has been created for the user root.
--
-- The leading process of the session is 829415.
Jun 19 18:20:20 node76 systemd[1]: Started Session 3068 of user root.
-- Subject: Unit session-3068.scope has finished start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit session-3068.scope has finished starting up.
--
-- The start-up result is done.
Jun 19 18:20:20 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:20 node76 kernel:  sdf: sdf1
Jun 19 18:20:20 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:20 node76 kernel:  sdf:
Jun 19 18:20:20 node76 multipath[829431]: sdf: using deprecated getuid callout
Jun 19 18:20:20 node76 sshd[829415]: Received disconnect from 10.10.10.75 port 53702:11: disconnected by user
Jun 19 18:20:20 node76 sshd[829415]: Disconnected from 10.10.10.75 port 53702
Jun 19 18:20:20 node76 sshd[829415]: pam_unix(sshd:session): session closed for user root
Jun 19 18:20:20 node76 systemd-logind[1841]: Removed session 3068.
-- Subject: Session 3068 has been terminated
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A session with the ID 3068 has been terminated.
Jun 19 18:20:21 node76 systemd-udevd[829425]: inotify_add_watch(9, /dev/sdf1, 10) failed: No such file or directory
Jun 19 18:20:21 node76 multipath[829479]: sdf: using deprecated getuid callout
Jun 19 18:20:21 node76 multipath[829507]: sdf: using deprecated getuid callout
Jun 19 18:20:21 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:21 node76 kernel:  sdf:
Jun 19 18:20:21 node76 multipath[829550]: sdf: using deprecated getuid callout
Jun 19 18:20:22 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:22 node76 kernel:  sdf:
Jun 19 18:20:22 node76 multipath[829590]: sdf: using deprecated getuid callout
Jun 19 18:20:22 node76 multipath[829616]: sdf: using deprecated getuid callout
Jun 19 18:20:23 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:23 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:23 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:20:23 node76 multipath[829658]: sdf: using deprecated getuid callout
Jun 19 18:20:23 node76 multipath[829685]: sdf: using deprecated getuid callout

..............................此处省略一部分信息......................................

Jun 19 18:22:48 node76 systemd[1]: Started Session 3077 of user root.
-- Subject: Unit session-3077.scope has finished start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit session-3077.scope has finished starting up.
--
-- The start-up result is done.
Jun 19 18:22:59 node76 sshd[844776]: Accepted publickey for root from 10.16.172.75 port 41614 ssh2: RSA SHA256:5/ngrgVfOOOLNuPyS1dflwHrc/sN9BSgDxNHVmJA0UE
Jun 19 18:22:59 node76 sshd[844776]: pam_unix(sshd:session): session opened for user root by (uid=0)
Jun 19 18:22:59 node76 systemd-logind[1841]: New session 3078 of user root.
-- Subject: A new session 3078 has been created for user root
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
-- Documentation: http://www.freedesktop.org/wiki/Software/systemd/multiseat
--
-- A new session with the ID 3078 has been created for the user root.
--
-- The leading process of the session is 844776.
Jun 19 18:22:59 node76 systemd[1]: Started Session 3078 of user root.
-- Subject: Unit session-3078.scope has finished start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit session-3078.scope has finished starting up.
--
-- The start-up result is done.
Jun 19 18:22:59 node76 radosgw[793492]: 2020-06-19 18:22:59.685447 7f3df412b700 -1 received  signal: Terminated from  PID: 1 task name: /sbin/init  UID: 0
Jun 19 18:22:59 node76 radosgw[793492]: 2020-06-19 18:22:59.685486 7f3e336e4040 -1 shutting down
Jun 19 18:22:59 node76 systemd[1]: Stopping Ceph rados gateway...
-- Subject: Unit ceph-radosgw@radosgw.0.service has begun shutting down
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
</code></pre>
<p>重新开机启动后，syslog日志片断如下:</p>
<pre><code class="language-shell">Jun 18 18:19:35 node75 kernel: [174076.635228] ata2.00: Enabling discard_zeroes_data
Jun 18 18:19:35 node75 kernel: [174076.639312]  sdf:
Jun 18 18:19:35 node75 multipath: sdf: using deprecated getuid callout
Jun 18 18:19:35 node75 ntpd[3446]: Listen normally on 68 bond0 10.16.172.79:123
Jun 18 18:19:35 node75 ntpd[3446]: Listen normally on 69 bond0 10.16.172.80:123
Jun 18 18:19:35 node75 ntpd[3446]: new interface(s) found: waking up resolver
Jun 18 18:19:35 node75 systemd-udevd[149835]: inotify_add_watch(9, /dev/sdf1, 10) failed: No such file or directory
Jun 18 18:19:35 node75 systemd[1]: Mounting /opt/datasearch/0...
Jun 18 18:19:35 node75 mount[149927]: mount: special device /dev/disk/by-partlabel/datasearch0 does not exist
Jun 18 18:19:35 node75 systemd[1]: opt-datasearch-0.mount: Mount process exited, code=exited status=32
Jun 18 18:19:35 node75 systemd[1]: Failed to mount /opt/datasearch/0.
Jun 18 18:19:35 node75 systemd[1]: opt-datasearch-0.mount: Unit entered failed state.
Jun 18 18:19:35 node75 multipath: sdf: using deprecated getuid callout
Jun 18 18:19:36 node75 kernel: [174077.640278] ata2.00: Enabling discard_zeroes_data
Jun 18 18:19:36 node75 kernel: [174077.642668]  sdf:
Jun 18 18:19:37 node75 kernel: [174078.789459] ata2.00: Enabling discard_zeroes_data
Jun 18 18:19:37 node75 kernel: [174078.794294] ata2.00: Enabling discard_zeroes_data
Jun 18 18:19:37 node75 kernel: [174078.800320] ata2.00: Enabling discard_zeroes_data
Jun 18 18:19:38 node75 kernel: [174079.491352] ata2.00: Enabling discard_zeroes_data
Jun 18 18:19:38 node75 multipath: message repeated 5 times: [ sdf: using deprecated getuid callout]
Jun 18 18:19:40 node75 systemd[1]: Stopping ezs3 bucket logging agent service...
Jun 18 18:19:44 node75 systemd[1]: Stopped ezs3 bucket logging agent service.
Jun 18 18:19:44 node75 systemd[1]: Reloading.
Jun 18 18:19:44 node75 systemd[1]: Reloading.
Jun 18 18:19:44 node75 systemd[1]: Started ACPI event daemon.
Jun 18 18:19:44 node75 systemd[1]: Stopping Ceph rados gateway...
Jun 18 18:19:44 node75 radosgw[138955]: 2020-06-18 18:19:44.455571 7f349a88c700 -1 received  signal: Terminated from  PID: 1 task name: /sbin/init  UID: 0
Jun 18 18:19:44 node75 radosgw[138955]: 2020-06-18 18:19:44.455636 7f34d9e45040 -1 shutting down
Jun 18 18:19:44 node75 systemd[1]: Stopped Ceph rados gateway.
Jun 18 18:19:44 node75 systemd[1]: Reloading.
Jun 18 18:19:44 node75 systemd[1]: Reloading.
Jun 18 18:19:44 node75 systemd[1]: Started ACPI event daemon.
Jun 18 18:19:45 node75 radosgw[131963]: 2020-06-18 18:19:45.107577 7fcfdfa6a700 -1 received  signal: Terminated from  PID: 1 task name: /sbin/init  UID: 0
Jun 18 18:19:45 node75 radosgw[131963]: 2020-06-18 18:19:45.107620 7fd01f023040 -1 shutting down
Jun 18 18:19:45 node75 systemd[1]: Stopping Ceph rados gateway...
Jun 18 18:19:45 node75 systemd[1]: Stopped Ceph rados gateway.
Jun 18 18:19:45 node75 systemd[1]: Started Ceph rados gateway.
Jun 18 18:19:45 node75 systemd[1]: Reloading.
Jun 18 18:19:45 node75 systemd[1]: Reloading.
Jun 18 18:19:45 node75 systemd[1]: Started ACPI event daemon.
Jun 18 18:19:45 node75 systemd[1]: Stopped ezs3 bucket logging agent service.
Jun 18 18:19:45 node75 systemd[1]: Starting ezs3 bucket logging agent service...
Jun 18 18:19:45 node75 systemd[1]: Stopped ezs3 bucket logging agent service.
Jun 18 18:19:45 node75 systemd[1]: Starting ezs3 bucket logging agent service...
Jun 18 18:19:46 node75 systemd[1]: ezs3-bucket-logging-agent.service: Supervising process 152415 which is not our child. We'll most likely not notice when it exits.
Jun 18 18:19:46 node75 systemd[1]: Started ezs3 bucket logging agent service.
Jun 18 18:19:46 node75 systemd[1]: Reloading.
Jun 18 18:19:46 node75 systemd[1]: Reloading.
Jun 18 18:19:47 node75 systemd[1]: Started ACPI event daemon.
Jun 18 18:19:53 node75 Keepalived[149387]: Stopping
Jun 18 18:19:53 node75 Keepalived_vrrp[149388]: (VRRP0) sent 0 priority
Jun 18 18:19:53 node75 systemd[1]: Stopping Keepalive Daemon (LVS and VRRP)...
Jun 18 18:19:53 node75 avahi-daemon[1704]: Withdrawing address record for 10.16.172.80 on bond0.
Jun 18 18:19:53 node75 avahi-daemon[1704]: Withdrawing address record for 10.16.172.79 on bond0.
Jun 18 18:19:53 node75 Keepalived_vrrp[149388]: (DATASEARCH) sent 0 priority
Jun 18 18:19:54 node75 Keepalived_vrrp[149388]: Stopped
Jun 18 18:19:54 node75 Keepalived[149387]: Stopped Keepalived v2.0.10 (09/19,2019), git commit 6.0-rc1-9509-gb73d9e153
Jun 18 18:19:54 node75 systemd[1]: Stopped Keepalive Daemon (LVS and VRRP).
Jun 18 18:19:54 node75 systemd[1]: Started Keepalive Daemon (LVS and VRRP).
Jun 18 18:19:54 node75 Keepalived[154125]: Starting Keepalived v2.0.10 (09/19,2019), git commit 6.0-rc1-9509-gb73d9e153
Jun 18 18:19:54 node75 Keepalived[154125]: Running on Linux 4.14.148-server #1 SMP Thu Jun 11 18:49:19 CST 2020 (built for Linux 4.4.176)
Jun 18 18:19:54 node75 Keepalived[154125]: Command line: '/usr/sbin/keepalived' '--dont-fork'
Jun 18 18:19:54 node75 Keepalived[154125]: Opening file '/etc/keepalived/keepalived.conf'.
Jun 18 18:19:54 node75 Keepalived[154125]: Starting VRRP child process, pid=154126
Jun 18 18:19:54 node75 Keepalived_vrrp[154126]: Registering Kernel netlink reflector
Jun 18 18:19:54 node75 Keepalived_vrrp[154126]: Registering Kernel netlink command channel
Jun 18 18:19:54 node75 Keepalived_vrrp[154126]: Opening file '/etc/keepalived/keepalived.conf'.
Jun 18 18:19:54 node75 Keepalived_vrrp[154126]: Registering gratuitous ARP shared channel
Jun 18 18:19:54 node75 Keepalived_vrrp[154126]: (VRRP0) Entering BACKUP STATE (init)
Jun 18 18:19:55 node75 ntpd[3446]: Deleting interface #68 bond0, 10.16.172.79#123, interface stats: received=0, sent=0, dropped=0, active_time=20 secs
Jun 18 18:19:55 node75 ntpd[3446]: Deleting interface #69 bond0, 10.16.172.80#123, interface stats: received=0, sent=0, dropped=0, active_time=20 secs
Jun 18 18:19:56 node75 Keepalived_vrrp[154126]: (VRRP0) Entering MASTER STATE
Jun 18 18:19:56 node75 Keepalived_vrrp[154126]: (VRRP0) using locally configured advertisement interval (400 milli-sec)
Jun 18 18:19:56 node75 avahi-daemon[1704]: Registering new address record for 10.16.172.79 on bond0.IPv4.
Jun 18 18:19:57 node75 ntpd[3446]: Listen normally on 70 bond0 10.16.172.79:123
Jun 18 18:19:57 node75 ntpd[3446]: new interface(s) found: waking up resolver
Jun 18 18:20:01 node75 CRON[154717]: (root) CMD (bash /usr/local/bin/monitor_ctdb.sh &gt;/dev/null 2&gt;&amp;1)
Jun 18 18:21:49 node75 systemd[1]: Started Session 3232 of user root.
Jun 18 18:22:01 node75 CRON[165327]: (root) CMD (bash /usr/local/bin/monitor_ctdb.sh &gt;/dev/null 2&gt;&amp;1)
Jun 18 18:22:03 node75 systemd[1]: Stopping ezrpc service...
Jun 18 18:22:04 node75 systemd[1]: Started Session 3234 of user root.
Jun 18 18:22:05 node75 systemd[1]: Stopped ezrpc service.
Jun 18 18:22:05 node75 systemd[1]: Starting ezrpc service...
Jun 18 18:22:05 node75 systemd[1]: Started Session 3235 of user root.
Jun 18 18:22:05 node75 systemd[1]: Started Session 3236 of user root.
Jun 18 18:22:05 node75 systemd[1]: ezrpc.service: Supervising process 165656 which is not our child. We'll most likely not notice when it exits.
Jun 18 18:22:05 node75 systemd[1]: Started ezrpc service.
Jun 18 18:22:06 node75 systemd[1]: Started Session 3237 of user root.
Jun 18 18:22:07 node75 systemd[1]: Started Session 3238 of user root.
Jun 18 18:22:09 node75 systemd[1]: Started Session 3239 of user root.
Jun 18 18:22:10 node75 systemd[1]: Started Session 3240 of user root.
Jun 18 18:22:10 node75 systemd[1]: Started Session 3241 of user root.
Jun 18 18:22:10 node75 systemd[1]: Started Session 3242 of user root.
Jun 18 18:22:10 node75 systemd[1]: Started Session 3243 of user root.
Jun 18 18:22:11 node75 systemd[1]: Started Session 3244 of user root.
Jun 18 18:22:11 node75 systemd[1]: Started Session 3245 of user root.
Jun 18 18:22:13 node75 systemd[1]: Started Session 3246 of user root.
Jun 18 18:22:14 node75 systemd[1]: Started Session 3247 of user root.
Jun 18 18:22:17 node75 systemd[1]: Started Session 3248 of user root.
Jun 18 18:22:22 node75 kernel: [174244.149039] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:22 node75 multipath: sdf: using deprecated getuid callout
Jun 18 18:22:23 node75 kernel: [174245.160084] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:23 node75 kernel: [174245.163924]  sdf:
Jun 18 18:22:24 node75 kernel: [174246.313987] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:24 node75 kernel: [174246.320486] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:24 node75 kernel: [174246.326831] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:25 node75 kernel: [174247.217690] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:26 node75 kernel: [174247.496059] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:27 node75 kernel: [174248.504647] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:27 node75 kernel: [174248.512515]  sdf:
Jun 18 18:22:27 node75 multipath: message repeated 8 times: [ sdf: using deprecated getuid callout]
Jun 18 18:22:28 node75 kernel: [174249.667311] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:28 node75 kernel: [174249.673618] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:28 node75 systemd[1]: Started Session 3258 of user root.
Jun 18 18:22:28 node75 multipath: sdf: using deprecated getuid callout
Jun 18 18:22:29 node75 kernel: [174250.362596] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:30 node75 kernel: [174251.374819] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:30 node75 kernel: [174251.379011]  sdf: sdf1
Jun 18 18:22:30 node75 kernel: [174252.064736] ata2.00: Enabling discard_zeroes_data
Jun 18 18:22:30 node75 kernel: [174252.069092]  sdf: sdf1
Jun 18 18:22:30 node75 multipath: message repeated 5 times: [ sdf: using deprecated getuid callout]
Jun 18 18:22:34 node75 systemd[1]: Started Session 3259 of user root.
Jun 18 18:22:34 node75 systemd[1]: Started Session 3260 of user root.
Jun 18 18:22:35 node75 systemd[1]: Started Session 3261 of user root.
Jun 18 18:22:37 node75 kernel: [174258.563000] EXT4-fs (sdf1): mounted filesystem with ordered data mode. Opts: (null)
Jun 18 18:22:37 node75 systemd[1]: Failed to set up mount unit: Device or resource busy
Jun 18 18:22:37 node75 systemd[1]: Reloading.
Jun 18 18:22:37 node75 systemd[1]: Started ACPI event daemon.
Jun 18 18:22:37 node75 systemd[1]: Reloading.
Jun 18 18:22:38 node75 systemd[1]: Started ACPI event daemon.
Jun 18 18:22:38 node75 systemd[1]: Reloading.
Jun 18 18:22:38 node75 systemd[1]: Started ACPI event daemon.
Jun 18 18:22:38 node75 systemd[1]: Starting Elasticsearch...
Jun 18 18:22:38 node75 elasticsearch[169315]: OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
Jun 18 18:22:42 node75 systemd[1]: Started Session 3262 of user root.
Jun 18 18:22:49 node75 systemd[1]: Started Session 3263 of user root.
Jun 18 18:22:50 node75 systemd[1]: Started Session 3264 of user root.
Jun 18 18:22:51 node75 systemd[1]: Started Session 3265 of user root.
Jun 18 18:22:51 node75 systemd[1]: Started Elasticsearch.
Jun 18 18:22:52 node75 elasticsearch[169315]: loading dict /usr/share/elasticsearch/plugins/jieba/dic/user.dict
Jun 18 18:22:52 node75 elasticsearch[169315]: loading dict /usr/share/elasticsearch/plugins/jieba/dic/sougou.dict
Jun 18 18:22:53 node75 systemd[1]: Started Session 3266 of user root
</code></pre>
<p>说明一下：</p>
<p>上文中的sdf这个分区，是启用ES时选择的ES DATA disk,为了能够复现这个问题，写了支script指定循环次数去启用，停用ES 服务，并检查对应的挂载点，ES集群健康状态，ceph集群健康状态（因为出现shutdown ceph核心服务进行，ceph集群不健康作为退出条件）.</p>
<h1 id="wen-ti-fu-xian-shi-yong-de-python-jiao-ben">问题复现使用的python脚本</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import os
import sys
import time
import json
import requests
from requests.exceptions import ConnectionError
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)


def login_session(public_ip, user_id, password):
    login_url = "https://{}:8080/auth".format(public_ip)
    login_data = {"user_id": user_id, "password": password}

    session = requests.session()
    session.keep_alive = False
    session.headers.update({'Accept': 'application/json, text/javascript, */*; q=0.01'})
    response = session.request("POST", login_url, json=login_data, verify=False)

    if response.status_code != 200:
        print("[ERROR]    Login web error, http status code is {} \n".format(response.status_code))
        sys.exit(1)

    return session


def http_request(session, http_method, url, params=None, data=None, public_ip=None, user_id=None, password=None):
    params = {} if params is None else params
    data = {} if data is None else data

    # set SSL Verify to False
    session.verify = False

    # Set session keep alive to False
    session.keep_alive = False

    if "cgi-bin" in url:
        # Legacy CGI
        try:
            response = session.request(http_method, url, params=params, data=data)
        except ConnectionError as ex:
            time.sleep(2)
            response = session.request(http_method, url, params=params, data=data)

        if response.status_code == 401:
            session = login_session(public_ip, user_id, password)
            response = session.request(http_method, url, params=params, data=data)
    else:
        # Restful CGI
        response = session.request(http_method, url, params=params, json=data)

        if response.status_code == 401:
            session = login_session(public_ip, user_id, password)
            response = session.request(http_method, url, params=params, json=data)

    if response.status_code == 500:
        print("[ERROR]    Send HTTP request failed, backend return 500, internal server error \n")
        sys.exit(1)

    return response


def es_enable_data(public_ip, storage_ip, vip):

    data = {
        "ip":storage_ip,
        "vip":vip,
        "router_id":"80",
        "num_shards":"6",
        "num_replicas":"1",
        "storage_location":"disk",
        "disks":"[\"/dev/sdf\"]"
    }

    return data


def enable_es(public_ip, storage_ip, session, http_method, url, data):
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    print("\n[{}] [Action]   Start to enable ES service on node : ({})".format(cur_time, storage_ip))

    response = http_request(session, http_method, url, data=data)

    if json.loads(response.text)['return_code'] == 0:
        progress_url = "https://{}:8080/cgi-bin/ezs3/json/elasticsearch_role_progress".format(public_ip)
        check_progress(session, storage_ip, progress_url)

        check_es_service_file(storage_ip)
        check_mount_point(storage_ip)
        check_fstab(storage_ip)
    else:
        print("[ERROR]    Enable ES service failed, backend return : ({})".format(response.text))
        sys.exit(1)


def es_disable_data(storage_ip):
    data = {'ip': storage_ip}

    return data

def disable_es(public_ip, storage_ip, session, http_method, url, data):
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    print("\n[{}] [Action]   Disable ES service on node : ({})".format(cur_time, storage_ip))

    response = http_request(session, http_method, url, data=data)

    if json.loads(response.text)['return_code'] == 0:
        progress_url = "https://{}:8080/cgi-bin/ezs3/json/elasticsearch_role_progress".format(public_ip)
        check_progress(session, storage_ip, progress_url, enable_flag=False)

        check_fstab(storage_ip, enable_flag=False)
        check_mount_point(storage_ip, enable_flag=False)
        check_es_service_file(storage_ip, enable_flag=False)
    else:
        print("[ERROR]    Disable ES service failed, backend return : ({})".format(response.text))
        sys.exit(1)


def progress_params(storae_ip, enable='true'):
    param = {'ip': storae_ip, 'enable': enable}

    return param


def get_enable_progress(session, url, param):
    for i in xrange(60):
        response = http_request(session, "GET", url, params=param) 
        res = json.loads(response.text)
        if res['return_code'] == 0:
            progress = res['response']['info']['progress']
            if progress == 100:
                break
            else:
                if i == 30:
                    print("                                 Wait for more than 150s, go on")
                if i &gt;= 58:
                    print("                                 ES progress is : ({})".format(progress))
                time.sleep(5)
    else:
        cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
        print("[{}] [ERROR]    Check ES progress failed, exit! \n".format(cur_time))
        sys.exit(1)


def check_progress(session, storage_ip, url, enable_flag=True):
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    if enable_flag:
        print("[{}] [Check]    Check ES enable progress on node : ({})".format(cur_time, storage_ip))
        param = progress_params(storage_ip)
    else:
        print("[{}] [Check]    Check ES disable progress on node : ({})".format(cur_time, storage_ip))
        param = progress_params(storage_ip, enable='false')

    get_enable_progress(session, url, param=param)


def get_radosgw_pid(hosts):
    host_rgw_pid = {}
    for each_host in hosts:
        pid = os.popen("ssh {} ps aux | grep client.radosgw.0 | grep -v grep | awk '{{print $2}}'").read().strip()
        if pid:
            host_rgw_pid[each_host] = pid
        else:
            cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
            print("[{}] [ERROR]    Not get radosgw pid on node :({})".foramt(cur_time, each_host))
            sys.exit(1)

    return host_rgw_pid


def check_fstab(storage_ip, enable_flag=True):
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    print("[{}] [Check]    Check mount config in /etc/fstab on node : ({})".format(cur_time, storage_ip))

    fstab_content = os.popen("ssh {} 'cat /etc/fstab | grep datasearch'".format(storage_ip)).read().strip()
    if enable_flag:
        if "datasearch" not in fstab_content:
            cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
            print("[{}] [ERROR]    Enable ES, but not find mount point information in /etc/fstab \n".format(cur_time))
            sys.exit(1)
    else:
        if "datasearch" in fstab_content:
            cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
            print("[{}] [ERROR]    Disable ES, but still find mount point information in /etc/fstab \n".format(cur_time))
            sys.exit(1)


def check_mount_point(storage_ip, enable_flag=True, pre_check=False):
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    if not pre_check:
        print("[{}] [Check]    Check mount point on node : ({})".format(cur_time, storage_ip))

    mount_info = os.popen("ssh {} 'mount | grep datasearch'".format(storage_ip)).read().strip()
    if enable_flag:
        if not mount_info:
            cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
            print("[{}] [ERROR]    Enable ES, but not find mount point \n".format(cur_time))
            sys.exit(1)
    else:
        if mount_info:
            cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
            if not pre_check:
                print("[{}] [ERROR]    Disable ES, but still find mount point \n".format(cur_time))
            else:
                print("[{}] [ERROR]    Precheck before enable ES, but still find mount point on node : ({}) \n".format(cur_time, storage_ip))
            sys.exit(1)


def check_es_service_file(storage_ip, enable_flag=True):
    file_path = "/etc/systemd/system/multi-user.target.wants/elasticsearch.service"
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    print("\n[{}] [Check]    Check {}".format(cur_time, file_path))

    if enable_flag:
        if not os.path.exists(file_path):
            cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
            print("[{}] [ERROR]  Enable ES, but not find ({}) \n".format(cur_time, file_path))
            sys.exit(1)
    else:
        if os.path.exists(file_path):
            cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
            print("[{}] [ERROR]  Disable ES, but still find ({}) \n".format(cur_time, file_path))
            sys.exit(1)


def check_es_cluster_helath(public_ip):
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    print("\n[{}] [Check]    Check ES cluster status".format(cur_time))

    cmd = "curl -s GET http://{}:9200/_cluster/health | json_pp | grep status".format(public_ip)
    for i in xrange(30):
        es_health = os.popen(cmd).read().strip()
        if 'green' not in es_health:
            time.sleep(5)
            if i == 29:
                cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
                print("[{}] [ERROR]    ES Cluser helath status is : ({})".format(cur_time, es_health))
        else:
            break
    else:
        cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
        print("[{}] [ERROR]  Wait 60s, but ES cluser status is not 'green' \n".format(cur_time))
        sys.exit(1)


def check_ceph_cluster_health():
    cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    print("\n[{}] [Check]    Check ceph cluster status".format(cur_time))

    cmd = "ceph -s | grep health"
    for i in xrange(30):
        ceph_health = os.popen(cmd).read().strip()
        if "HEALTH_OK" not in ceph_health:
            time.sleep(5)
        else:
            break
    else:
        cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
        print("[{}] [ERROR]  Wait 60s, but ceoh cluser status is not 'HEALTH_OK' \n".format(cur_time))
        sys.exit(1)


def force_clean(storage_ip):
    print("[Action]   Start to force to clean umount and disk on node : ({})".format(storage_ip))

    umount_cmd = "ssh {} 'umount /opt/datasearch/0'".format(storage_ip)
    sgdisk_o = "ssh {} 'sgdisk -o /dev/sdf'".format(storage_ip)
    sgdisk_z = "ssh {} 'sgdisk -Z /dev/sdf'".format(storage_ip)
    ude = "ssh {} 'udevadm settle'".format(storage_ip)
    wip = " ssh {} 'wipefs -a -f /dev/sdf'".format(storage_ip)
    rm_folder = "ssh {} 'rm -rf /opt/datasearch/0/'".format(storage_ip)
    os.popen(umount_cmd)
    os.popen(sgdisk_o)
    os.popen(sgdisk_z)
    os.popen(ude)
    os.popen(wip)
    os.popen(rm_folder)


def loop_run(loop_times):
    password = "1"
    user_id = "admin"
    vip = "10.16.172.80/22"
    public_ip = "10.16.172.75"
    storage_ips = ["10.10.10.75", "10.10.10.76", "10.10.10.77"]

    session = login_session(public_ip, user_id, password)
    enable_es_url = "https://{}:8080/cgi-bin/ezs3/json/elasticsearch_role_enable".format(public_ip)
    disable_es_url = "https://{}:8080/cgi-bin/ezs3/json/elasticsearch_role_disable".format(public_ip)

    for i in xrange(loop_times):
        print("\n---------------------------------------------- {} --------------------------------------------".format(i+1))
        # Before disable, check datasearch mount point again, because not known why the mount point mount again
        cur_time = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
        print("[{}] [Check]    Precheck mount point on each node before enable ES service".format(cur_time))

        # Only check once by the first time
        if i &lt; 1:
            for each_storage_ip in storage_ips:
                check_mount_point(each_storage_ip, enable_flag=False, pre_check=True)
            time.sleep(1)
        else:
            for j in xrange(10):
                for each_storage_ip in storage_ips:
                    check_mount_point(each_storage_ip, enable_flag=False, pre_check=True)
                time.sleep(1)

        # # Force clean
        # for each_storae_ip in storage_ips:
        #     force_clean(each_storae_ip)

        # Enable ES service on all node
        for each_storage_ip in storage_ips:
            enable_es_data = es_enable_data(public_ip, each_storage_ip, vip)
            enable_es(public_ip, each_storage_ip, session, "POST", enable_es_url, data=enable_es_data)

        # Check ES cluser status
        os.popen("iptables -F")
        check_es_cluster_helath(public_ip)

        # Disable ES service on all node
        for each_storage_ip in storage_ips:
            disable_es_data = es_disable_data(each_storage_ip) 
            disable_es(public_ip, each_storage_ip, session, "POST", disable_es_url, data=disable_es_data)


        # Check ceph cluster status
        check_ceph_cluster_health()
        time.sleep(2)

        # # Force clean
        # for each_storae_ip in storage_ips:
        #     force_clean(each_storae_ip)


if __name__ == '__main__':
    loop_times = sys.argv[1]

    if loop_times &lt; 1:
        print("[ERROR]  loop_times must &gt;=1 \n")
        sys.exit(1)

    loop_run(int(loop_times))
</code></pre>
<h1 id="zhi-xing-xiao-guo">执行效果</h1>
<pre><code class="language-shell">root@node75:~# python enable_disable_es.py 3

---------------------------------------------- 1 --------------------------------------------
[Action]   Start to force to clean umount and disk on node : (10.10.10.75)
umount: /opt/datasearch/0: mountpoint not found
[Action]   Start to force to clean umount and disk on node : (10.10.10.76)
umount: /opt/datasearch/0: mountpoint not found
[Action]   Start to force to clean umount and disk on node : (10.10.10.77)
umount: /opt/datasearch/0: mountpoint not found

[2020-06-19 14:17:39] [Action]   Start to enable ES service on node : (10.10.10.75)
[2020-06-19 14:17:40] [Check]    Check ES enable progress on node : (10.10.10.75)
[2020-06-19 14:19:41] [Check]    Check mount config in /etc/fstab on node : (10.10.10.75)
[2020-06-19 14:19:41] [Check]    Check mount point on node : (10.10.10.75)

[2020-06-19 14:19:41] [Action]   Start to enable ES service on node : (10.10.10.76)
[2020-06-19 14:19:41] [Check]    Check ES enable progress on node : (10.10.10.76)
[2020-06-19 14:20:22] [Check]    Check mount config in /etc/fstab on node : (10.10.10.76)
[2020-06-19 14:20:22] [Check]    Check mount point on node : (10.10.10.76)

[2020-06-19 14:20:22] [Action]   Start to enable ES service on node : (10.10.10.77)
[2020-06-19 14:20:22] [Check]    Check ES enable progress on node : (10.10.10.77)
[2020-06-19 14:20:58] [Check]    Check mount config in /etc/fstab on node : (10.10.10.77)
[2020-06-19 14:20:58] [Check]    Check mount point on node : (10.10.10.77)

[2020-06-19 14:20:58] [Check]    Check ES cluster status

[2020-06-19 14:21:04] [Action]   Disable ES service on node : (10.10.10.75)
[2020-06-19 14:21:04] [Check]    Check ES disable progress on node : (10.10.10.75)
[2020-06-19 14:21:14] [Check]    Check mount config in /etc/fstab on node : (10.10.10.75)
[2020-06-19 14:21:14] [Check]    Check mount point on node : (10.10.10.75)

[2020-06-19 14:21:14] [Action]   Disable ES service on node : (10.10.10.76)
[2020-06-19 14:21:14] [Check]    Check ES disable progress on node : (10.10.10.76)
[2020-06-19 14:21:24] [Check]    Check mount config in /etc/fstab on node : (10.10.10.76)
[2020-06-19 14:21:25] [Check]    Check mount point on node : (10.10.10.76)

[2020-06-19 14:21:25] [Action]   Disable ES service on node : (10.10.10.77)
[2020-06-19 14:21:25] [Check]    Check ES disable progress on node : (10.10.10.77)
[2020-06-19 14:21:50] [Check]    Check mount config in /etc/fstab on node : (10.10.10.77)
[2020-06-19 14:21:50] [Check]    Check mount point on node : (10.10.10.77)

[2020-06-19 14:21:51] [Check]    Check ceph cluster status
[Action]   Start to force to clean umount and disk on node : (10.10.10.75)
umount: /opt/datasearch/0: mountpoint not found
[Action]   Start to force to clean umount and disk on node : (10.10.10.76)
umount: /opt/datasearch/0: mountpoint not found
[Action]   Start to force to clean umount and disk on node : (10.10.10.77)
umount: /opt/datasearch/0: mountpoint not found

---------------------------------------------- 2 --------------------------------------------
[Action]   Start to force to clean umount and disk on node : (10.10.10.75)
umount: /opt/datasearch/0: mountpoint not found
[Action]   Start to force to clean umount and disk on node : (10.10.10.76)
umount: /opt/datasearch/0: mountpoint not found
[Action]   Start to force to clean umount and disk on node : (10.10.10.77)
umount: /opt/datasearch/0: mountpoint not found

[2020-06-19 14:22:13] [Action]   Start to enable ES service on node : (10.10.10.75)
[2020-06-19 14:22:14] [Check]    Check ES enable progress on node : (10.10.10.75)
                                 Wait for more than 150s, go on
                                 ES progress is : (30)
                                 ES progress is : (30)
[2020-06-19 14:27:16] [ERROR]    Check ES progress failed, exit! 

root@node75:~#
</code></pre>
<h1 id="wei-he-hui-chu-xian-local-fs-target-failed-with-result-dependency">为何会出现 ‘local-fs.target failed with result dependency’</h1>
<p>这篇文章： <code>https://unix.stackexchange.com/questions/416640/how-to-disable-systemd-agressive-emergency-shell-behaviour </code></p>
<p>有提及到:</p>
<pre><code class="language-shell">If you search through the unit files, there are only a very few ways for the boot to fall back to emergency.target. It's usually when a .mount unit for a local filesystem fails, causing local-fs.target to fail. Or when your initramfs fails to mount the root filesystem, if your initramfs uses systemd.

local-fs.target has OnFailure=emergency.target. And it gets failed because units for local filesystems are automatically added to the Requires list of local-fs.target (unless they have DefaultDependencies=no).
</code></pre>
<p>没有尝试去修改 <code>/lib/systemd/system/local-fs.target </code> 中 <code>OnFailure=</code> 为空(此文件中DefaultDependencies=no)，也没有新增<code>/etc/systemd/system/local-fs.target.d/nofail.conf </code>文件单独去设置``OnFailure=``` 为空。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>由于担心修改<code>local-fs.target </code>会带来额外影响，这里没有采用修改<code>OnFailure=</code> 为空的方法，具体处理方法如下：</p>
<p>使用systemctl show查看local-fs.target requires</p>
<pre><code class="language-shell">root@node76:/var/log# systemctl show --property Requires local-fs.target
Requires=-.mount opt-datasearch-0.mount
root@node76:/var/log#
</code></pre>
<p>这里有个opt-datasearch-0.mount，而这个正好是ES data所对应的挂载点信息，说明启停ES服务时动了/etc/fstab文件了，新增或删除了/etc/fsta对应的ES挂载点信息了，依照这个思路，调整一下产品修改/etc/fstab时间点，在停用ES时，最先去修改/etc/fstab文件，然后才去执行清理zone-group、umount、formate disk，disable es等等动作，然后使用上述脚本验证了30次，问题没有再次浮现。而在调整前，几次就会复现。</p>
<h1 id="tui-lun">推论</h1>
<p>产品停用ES时：</p>
<img class="shadow" src="/img/in-post/disable_es1.png" width="1200">
<p>上图中，红色箭头1，是自己手动添加的，这个步骤，原先是放在红色箭头2的函数里的。 可以看出，停用ES服务时，先拔除了elasticsearch的开机自启动，再进行ES disk分区的擦写操作（其中包括修改/etc/fstab文件）：</p>
<img class="shadow" src="/img/in-post/disable_es2.png" width="1200">
<img class="shadow" src="/img/in-post/disable_es3.png" width="1200">
<p>而ES disk对应的mount挂载点：</p>
<img class="shadow" src="/img/in-post/fstab_content.png" width="1200">
<p>options 选项是auto,部分journalctl -xb信息如下：</p>
<pre><code class="language-shell">Jun 19 18:30:02 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:30:02 node76 kernel:  sdf: sdf1
Jun 19 18:30:02 node76 kernel: ata2.00: Enabling discard_zeroes_data
Jun 19 18:30:02 node76 kernel:  sdf:
Jun 19 18:30:02 node76 multipath[854423]: sdf: using deprecated getuid callout
Jun 19 18:30:02 node76 systemd-udevd[854418]: inotify_add_watch(9, /dev/sdf1, 10) failed: No such file or directory
Jun 19 18:30:02 node76 systemd[1]: Mounting /opt/datasearch/0...
-- Subject: Unit opt-datasearch-0.mount has begun start-up
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
-- Unit opt-datasearch-0.mount has begun starting up.
Jun 19 18:30:02 node76 systemd[1]: Stopped target Local File Systems.
-- Subject: Unit local-fs.target has finished shutting down
cal-fs.targetlocal-fs.target
-- Defined-By: systemd
-- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel
--
</code></pre>
<p>推断，local-fs.target requires <code>opt-datasearch-0.mount</code>，而对应挂载点出现’not found’(见开篇’systemctl --failed’的输出信息)，导致local-fs.target出现timeout（DefaultTimeoutStartSec=90，/etc/systemd/system.conf文件中，默认90s），而local-fs.target.wants是需要/etc/fstab,这里还有个Conflicts=shutdown.target</p>
<img class="shadow" src="/img/in-post/local-fs.target.wants.png" width="1200">
<p>最终应该是触发了shutdown操作，停止了众多的服务，而被停止的服务，是依赖于local-fs.target的，以ceph-osd为示例：</p>
<img class="shadow" src="/img/in-post/ceph-osd.target.wants.png" width="1200">
<h1 id="jie-yu">结语</h1>
<p>分析至此，基本上知道问题的所在了，具体解法如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>启用ES服务时，等ES相关的服务启用好后，最最后更改/etc/fstab文件；</p>
</li>
<li class="lvl-2">
<p>停用ES服务时，第一步就是更改/etc/fstab文件。</p>
</li>
</ul>
<h1 id="can-kao-wen-dang">参考文档</h1>
<pre><code class="language-shell">https://zhangguanzhang.github.io/2019/01/30/fstab/
https://www.freedesktop.org/software/systemd/man/systemd.mount.html
https://www.freedesktop.org/software/systemd/man/systemd-system.conf.html#
http://www.jinbuguo.com/systemd/systemd.special.html
https://unix.stackexchange.com/questions/416640/how-to-disable-systemd-agressive-emergency-shell-behaviour
https://www.freedesktop.org/software/systemd/man/systemd.unit.html
</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>利用oceanfile批量构造文件并统计cephfs速度</title>
    <url>/2020/07/06/calc_cephfs_write_speed/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>前段时间RD优化了rocksdb，S3的性能有显著提升，在此基础上，利用RD自研工具验证cepfhs 写速度，每间隔5million个文件进行一次写速度的统计。</p>
<h1 id="shell-script">shell script</h1>
<p>直接上脚本，参考如下:</p>
<pre><code class="language-shell">root@node76:~/oceanfile# cat run_oceanfile.sh 
#!/bin/bash

EFILE=/usr/local/bin/oceanfile
target_no=5000000
WRITE_DIR="/vol/nas02/"
LOG="/var/log/nas_ocean.log"


function check_arch()
{   
    new_arch=(`echo $arch | tr ',' ' '` )
    total_no=1 
    for var in ${new_arch[@]}
    do  
        # echo $var
        let total_no*=$var
    done 

    if [[ ${total_no} -ne ${target_no} ]]; then
        echo ''
        echo '[ERROR]  The current round amount of data: (${total_no}) is less than expected amount of data: (${target_no})'
        echo ''
        exit 1
    fi
}


if [ $# != 3 ] ; then
    echo ""
    echo "USAGE: $0 parallel size arch"
    echo "  e.g.: $0 20 64 10,10,10,10,100"
    echo ""
    exit 1;
fi

parallel=$1
file_size=$2  # Unit is K
arch=$3

# Check arch numbers
check_arch

for round in {1..22}
do
    while (( $(ps aux | grep -w oceanfile | grep -v grep | wc -l) &gt;= 1 )); do
        sleep 60
    done

    write_dir=${WRITE_DIR}/round_${round}

    if [[ ! -d ${write_dir} ]]; then
        mkdir -p ${write_dir}
    fi

    echo $(date) ROUND ${round} BEGIN  &gt;&gt;$LOG 2&gt;&amp;1
    start_time=`echo $[$(date +%s%N)/1000000]`
    ${EFILE} -d ${write_dir} -p ${parallel} -s ${file_size}k -b ${file_size}k -a ${arch} -i 5 &gt;&gt;$LOG 2&gt;&amp;1 
    end_time=`echo $[$(date +%s%N)/1000000]`

    diff=`expr ${end_time} - ${start_time}`
    time_diff=`echo | awk "{print $diff/1000}"`
    avg_speed=`echo | awk "{print ${target_no}/${time_diff}}"`
   
    # echo ROUND $round "* ${target_no}  cost $time_diff (ms) avg_speed $avg_speed"
    printf "ROUND %-8s  %12d (Files)       Cost %10.2f (s)  Avage: %8.2f\n" $round $target_no $time_diff $avg_speed
    
    echo &gt;&gt;$LOG 2&gt;&amp;1
    echo "ROUND $round  * $target_no (files) cost $time_diff (s)  avg_speed: $avg_speed" &gt;&gt; $LOG 2&gt;&amp;1
    echo $(date) ROUND ${round} FINISH  &gt;&gt;$LOG 2&gt;&amp;1
    echo &gt;&gt;$LOG 2&gt;&amp;1
    echo &gt;&gt;$LOG 2&gt;&amp;1
done
</code></pre>
<h1 id="yun-xing-xiao-guo">运行效果</h1>
<img class="shadow" src="/img/in-post/cephfs_write_speed.png" width="1200">
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell随机数生成的几种方法</title>
    <url>/2020/07/01/generate_random_number_in_shell/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天验证在对存储不断灌S3 10K小对象数据情况下，对设备强制断电，观察是否引发ceph-osd crash问题，简易写了个临时命令完成检查操作，如下：</p>
<pre><code class="language-shell">for i in {1..100}; do echo "================== $i =================="; rand_time=`expr $RANDOM / 400`; echo "  sleep ${rand_time}s"; sleep ${rand_time}; ipmitool -I lan  -U ADMIN -P ADMIN -H 172.17.75.169 chassis power off; rand_time=`expr $RANDOM / 400`; echo "  sleep ${rand_time}s"; sleep ${rand_time};ipmitool -I lan  -U ADMIN -P ADMIN -H 172.17.75.169 chassis power on; echo "  power on, then sleep 300s"; sleep 300;done
</code></pre>
<p>另外一个临时check脚本参考如下:</p>
<pre><code class="language-shell">root@node76:~# cat check_cores.sh 
#!/bin/bash

i=1

while [[ $i -lt 1000  ]];do
    echo "=========================== $i ==============================="

    res=`onnode all 'ls /var/log/cores -lhrt | grep -vi ldb' 2&gt;/dev/null|grep ezcore`
    if [[ $? -eq 0 ]]; then
        echo "`date`: FAIL!! Core dump of others yielded."
        exit 1
    else
        rand_time=`expr $RANDOM / 1000`
        echo "  OK --&gt; sleep ${rand_time}s"
        sleep ${rand_time} 
        let i+=1
    fi    
    
done
root@node76:~# 
</code></pre>
<p>这里使用到了随机数，本文介绍shell几种生成随机数的方法。</p>
<h1 id="shell-chan-sheng-sui-ji-shu-de-ji-chong-fang-fa">shell 产生随机数的几种方法</h1>
<h2 id="nei-zhi-bian-liang-random">内置变量$RANDOM</h2>
<p>参考 <code>http://www.tldp.org/LDP/abs/html/randomvar.html </code></p>
<p>RANDOM 是 Bash 的一个内建函数(而不是常量)，会返回一个在区间 [0, 32767] 内的整数，若超过5位可以加个固定10位整数，然后进行求余。</p>
<pre><code class="language-shell">root@node76:~# echo $RANDOM 
27399
root@node76:~# echo $RANDOM 
17012
root@node76:~#
</code></pre>
<h3 id="shi-li-sheng-cheng-10-yi-nei">示例：生成10以内</h3>
<pre><code class="language-shell">root@node76:~# expr $RANDOM % 10 + 1
10
root@node76:~# 
</code></pre>
<h3 id="shi-li-sheng-cheng-zhi-ding-fan-wei-nei-de-sui-ji-shu">示例： 生成指定范围内的随机数</h3>
<p>生成1000~2000的随机数，示例如下:</p>
<pre><code class="language-shell">root@node76:~/shell# cat r.sh 
#!/bin/bash    

function rand(){
    min=$1
    max=$(($2 - $min + 1))
    num=$(($RANDOM+1000000000)) # 增加一个10位的数再求余
    echo $(($num%$max + $min))
}

rand_no=$(rand 1000 2000)
echo $rand_no

exit 0
root@node76:~/shell#
</code></pre>
<p>运行结果示例如下:</p>
<pre><code class="language-shell">root@node76:~/shell# bash r.sh
1332
root@node76:~/shell# bash r.sh
1581
root@node76:~/shell# bash r.sh
1293
root@node76:~/shell# bash r.sh
1787
root@node76:~/shell# 
</code></pre>
<h2 id="shi-yong-awk-de-sui-ji-han-shu">使用awk的随机函数</h2>
<p><code>awk 'BEGIN{srand();print rand()*1000000}'  </code></p>
<h2 id="shi-yong-date-s-n">使用date +%s%N</h2>
<pre><code class="language-shell">date +%s%N  # 生成19位数
date +%s%N | cut -c6-13 # 取八位数字
date +%s%N | md5sum | head -c 8 # 八位字母和数字的组合
</code></pre>
<h3 id="shi-li-sheng-cheng-1-50-de-sui-ji-shu">示例：生成1~50的随机数</h3>
<pre><code class="language-shell">#!/bin/bash

function rand(){
    min=$1
    max=$(($2- $min + 1))
    num=$(date +%s%N)
    echo $(($num % $max + $min))
}

rnd=$(rand 1 50)
echo $rnd

exit 0
</code></pre>
<h2 id="openssl-rand-chan-sheng-sui-ji-shu">openssl rand产生随机数</h2>
<p>openssl rand 用于产生指定长度个bytes的随机字符。-base64或-hex对随机字符串进行base64编码或用hex格式显示。</p>
<pre><code class="language-shell">openssl rand -base64 3 | md5sum | cut -c1-8      # 八位字母和数字的组合
openssl rand -base64 2 | cksum | cut -c1-8       # 八位数字
</code></pre>
<p>额外补充一下：</p>
<pre><code class="language-shell">root@node76:~/shell# openssl rand  -base64 0 | md5sum | cut -c1-8
d41d8cd9
root@node76:~/shell# openssl rand  -base64 0 | md5sum | cut -c1-8
d41d8cd9
root@node76:~/shell# openssl rand  -base64 0 | md5sum | cut -c1-8
d41d8cd9
root@node76:~/shell# openssl rand  -base64 1 | md5sum | cut -c1-8
e2740bcc
root@node76:~/shell# openssl rand  -base64 1 | md5sum | cut -c1-8
d8fb4cee
root@node76:~/shell# openssl rand  -base64 1 | md5sum | cut -c1-8
212e9682
root@node76:~/shell# 
root@node76:~/shell# openssl rand  -base64 0
root@node76:~/shell# openssl rand  -base64 1
IQ==
root@node76:~/shell# openssl rand  -base64 1
4g==
root@node76:~/shell# openssl rand  -base64 1
zA==
root@node76:~/shell# openssl rand  -base64 10
94pxE5KZvYNU9g==
root@node76:~/shell# openssl rand  -base64 30
PxfQot0kAO9KdTO6H4ny71AguR28LZiWa/ruVaja
root@node76:~/shell#
</code></pre>
<p>通过上面参数-base64后面的值，可以看到，当值为0时，<code>openssl rand  -base64 0 </code>输出为空，而非0值时才有输出，没有找到这个具体数值的含义，个人推测是seed(种子)，seed=0,产生的值时一个固定值。</p>
<h2 id="tong-guo-xi-tong-nei-wei-yi-shu-ju-sheng-cheng-sui-ji-shu-dev-random-ji-dev-urandom">通过系统内唯一数据生成随机数（/dev/random及/dev/urandom）</h2>
<h3 id="random">random</h3>
<p>/dev/random是 Linux 上的一个字符设备，里面会源源不断地产生随机数(存储系统当前运行的环境的实时数据), 是阻塞的随机数发生器，读取有时需要等待，可以看作系统某时候的唯一值数据。</p>
<p>一般来说，用 od 命令即可:</p>
<pre><code class="language-shell">root@node76:~/shell# od -An -N2 -i /dev/random
        4291
root@node76:~/shell# 
</code></pre>
<p>这里的 -N2 指定要读取的字节数， -i 则是指定输入。</p>
<p>若要产生特定范围内的随机数，则和使用 $RANDOM 的方法类似:</p>
<pre><code class="language-shell"># @args &lt;beg&gt; &lt;end&gt;
# return random integer in [&lt;beg&gt;, &lt;end&gt;)
function random_range() {
    local beg=$1
    local end=$2
    echo $(($(od -An -N2 -i /dev/random) % ($end - $beg) + $beg))
}
</code></pre>
<h3 id="urandom">urandom</h3>
<p>/dev/urandom 是非阻塞的随机数产生器，读取时不会产生阻塞，速度更快、安全性较差的随机数发生器。</p>
<p><code>cat /dev/urandom | head -n 10 | md5sum | head -c 10 </code>     # 生成字母数字组合串</p>
<p><code>cat /dev/urandom | strings -n 8 | head -n 1 </code>      # 生成全字符的随机字符串，含特殊字符（e.g: NO&gt;0/D}I?ln）</p>
<p><code>cat /dev/urandom | sed -e 's/[^a-zA-Z0-9]//g' | strings -n 8 | head -n 1 </code>   # 生成数字加字母的随机字符串</p>
<p>其中 strings -n设置字符串的字符数，head -n并不像是设置输出的行数，更像是seed(种子)。</p>
<p><code>head -n 20 /dev/urandom| cksum | cut -d" " -f1 </code>   # urandom的数据很多使用cat会比较慢，在此使用head读20行，cksum将读取文件内容生成唯一的表示整型数据，cut以空格分割然后得到分割的第一个字段数据</p>
<h3 id="shi-li-shi-yong-dev-urandom-sheng-cheng-100-500-de-sui-ji-shu">示例：使用/dev/urandom生成100~500的随机数</h3>
<p>这里使用urandom避免阻塞。</p>
<pre><code class="language-shell">#!/bin/bash

function rand(){
    min=$1
    max=$(($2 - $min + 1))
    num=$(cat /dev/urandom | head -n 10 | cksum | awk -F ' ' '{print $1}')
    echo $(($num % $max + $min))
}

rnd=$(rand 100 500)
echo $rnd

exit 0
</code></pre>
<h2 id="seq-sort">seq + sort</h2>
<p>sort 命令有一个 -R 选项，可以根据随机 hash 排序，那么我们就可以用 seq 命令先生成一个整数序列，然后用 sort 的 -R 选项处理取其中一行即可。</p>
<pre><code class="language-shell"># @args &lt;beg&gt; &lt;end&gt;
# return random integer in [&lt;beg&gt;, &lt;end&gt;]
function random_range {
    local beg=$1
    local end=$2
    seq $beg $end | sort -R | head -n1
}
</code></pre>
<p>值得注意的是，使用这种方法时，要求的值域可以包含负数区域，而本文的其他方法则要进行不同的处理。</p>
<h2 id="shuf">shuf</h2>
<p>shuf 和 ‘sort -R’ 的作用类似，用来根据输入生成随机序列:</p>
<pre><code class="language-shell"># @args &lt;beg&gt; &lt;end&gt;
# return random integer in [&lt;beg&gt;, &lt;end&gt;]
function random_range {
    shuf -i $1-$2 -n1
}
</code></pre>
<p>在各种方法中，使用 shuf 命令是最简洁的。</p>
<h2 id="du-qu-linux-de-uuid-ma">读取linux的uuid码</h2>
<p>UUID码全称是通用唯一识别码 (Universally Unique Identifier, UUID)，UUID格式是：包含32个16进制数字，以“-”连接号分为五段，形式为8-4-4-4-12的32个字符。linux的uuid码也是有内核提供的，在/proc/sys/kernel/random/uuid这个文件内。cat/proc/sys/kernel/random/uuid每次获取到的数据都会不同。</p>
<p><code>cat /proc/sys/kernel/random/uuid| cksum | cut -f1 -d" " </code>    # 获取不同的随机整数</p>
<p><code>cat /proc/sys/kernel/random/uuid| md5sum | cut -c1-8 </code>      # 数字加字母的随机数</p>
<h3 id="shi-li-shi-yong-linux-uuid-sheng-cheng-100-500-sui-ji-shu">示例: 使用linux uuid 生成100~500随机数</h3>
<pre><code class="language-shell">#!/bin/bash    
    
function rand(){    
    min=$1    
    max=$(($2 - $min + 1))    
    num=$(cat /proc/sys/kernel/random/uuid | cksum | awk -F ' ' '{print $1}')    
    echo $(($num % $max + $min))    
}    
    
rnd=$(rand 100 500)    
echo $rnd    
    
exit 0
</code></pre>
<h2 id="cong-yuan-su-chi-zhong-sui-ji-chou-qu-qu">从元素池中随机抽取取</h2>
<pre><code class="language-shell">pool=(a b c d e f g h i j k l m n o p q r s t u v w x y z 0 1 2 3 4 5 6 7 8 9)

num=${#pool[*]}

result=${pool[$((RANDOM%num))]}
</code></pre>
<p>用于生成一段特定长度的有数字和字母组成的字符串，字符串中元素来自自定义的池子。</p>
<pre><code class="language-shell">length=10 
i=1

seq=(0 1 2 3 4 5 6 7 8 9 a b c d e f g h i j k l m n o p q r s t u v w x y z A B C D E F G H I J K L M N O P Q R S T U V W X Y Z)
num_seq=${#seq[@]}
  
while [ "$i" -le "$length" ]
do
    seqrand[$i]=${seq[$((RANDOM%num_seq))]}  
    let "i=i+1"  
done  
  
echo "The random string is:"  
for j in ${seqrand[@]}  
do  
    echo -n $j  
done  

echo
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>获取系统中所有的pid</title>
    <url>/2020/07/08/get_all_of_pid_from_os/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Linux进程的pid，会在/proc目录下产生对应pid目录，如果想获取当前系统所有的pid，可以到此目录下去找。</p>
<p>本文介绍几种方法，获取到所有的pid。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="fang-fa-1-grep">方法1. grep</h2>
<p><code>ls /proc/ | grep ^[0-9] </code></p>
<h2 id="fang-fa-2-echo">方法2. echo</h2>
<p><code>(cd /proc &amp;&amp; echo +([0-9])) </code></p>
<p>或者</p>
<p><code>for d in /proc/*;do [[ $d =~ /proc/[0-9]+ ]] &amp;&amp; echo ${d#/proc/};done </code></p>
<h2 id="fang-fa-3-awk">方法3. awk</h2>
<p><code>ls | awk '{if ($i ~ /^[0-9]/) print $i}' </code></p>
<h2 id="fang-fa-4-ls-yu-echo-jie-he">方法4. ls 与 echo 结合</h2>
<p><code>ls -d *[0-9]* </code></p>
<p>或者:</p>
<p><code>ls -d * | echo +([0-9]) </code></p>
<p>或者:</p>
<p><code>ls -F |grep "/$" | echo +([0-9]) </code></p>
<p>或者:</p>
<p><code>ls -l |grep "^d" | echo +([0-9]) </code></p>
<p>或者:</p>
<p><code>ls -l |grep "^d" |awk '{print $NF}' |  echo +([0-9]) </code></p>
<h2 id="fang-fa-5-find-yu-echo-jie-he">方法5. find 与 echo 结合</h2>
<p><code>find . -type d -maxdepth 1 |&amp; echo +([0-9]) </code></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell完成一次ceph-osd crash验证</title>
    <url>/2020/07/01/shell_reproduce_ceph_osd_replay_crash/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近在测试ceph rocksdb性能优化效果，由于频繁的重启机器（ipmitool power off），出现了两次ceph-osd replay crash问题，由于频繁的power off太伤机器了，验证完毕rocksdb性能优化后，重写了个script，通过kill ceph 核心服务来模拟突然掉电，同时cosbench持续狂打流量，以及不间断的reset s3 pool 来完成场景的复现。</p>
<h1 id="jiao-ben-can-kao-ru-xia">脚本参考如下</h1>
<pre><code class="language-shell">root@node76:~# cat kill_ceph_and_reset_s3_pool.sh 
#!/bin/bash

loop_cnt=100
ctdb_wait_time=600
ceph_wait_time=900
node_num=3
pgnum=6656
target_ip=10.16.172.77
public_ip=10.16.172.76
target_pool='pool01'
default_pool='Default'
default_s3_pool='default.rgw.buckets.data'
bucket_objs_no=300000


function rand(){
    min=$1
    max=$(($2- $min + 1))
    num=$(date +%s%N)
    echo $(($num % $max + $min))
}


function login_ui(){
    login_res=`curl --insecure --cookie-jar cookie.jar -s -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${public_ip}:8080/auth" --data '{"password": "1", "user_id": "admin"}'`
    login_return_code=`echo ${login_res} | sed 's@{"name": "login", "return_code": @@' | sed 's/}//'`

    if [ x"${login_return_code}" == x"300" ]; then
        echo ""
        echo "[ERROR]  Login Failed, exit!!!"
        echo ""
        exit 1
    elif [[ ${login_return_code} =~ 'session_id' ]]; then
        echo ""
        echo "Login success"
        echo ""
    fi
}


function check_pool_exist()
{
    pool_grep=`rados lspools | grep ${target_pool}`

    if [[ -z ${pool_grep}  ]]; then
        echo ""
        echo "[ERROR]  Not exists pool : ${target_pool}, needs to create in cluster, exit!!!"
        echo ""
        exit 0
    fi
}


function reset_s3_pool(){
    pool_name=$1

    # Reset s3 pool
    start_time=`date "+%Y-%m-%d %H:%M:%S"`
    echo "${start_time}  Start to set pool : (${pool_name}) as s3 pool" 

    result_code=`curl --insecure --cookie cookie.jar --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" -s -I -w %{http_code} "https://${public_ip}:8080/cgi-bin/ezs3/json/pool_enable_s3?pool_name=${pool_name}"`

    cur_time=`date "+%Y-%m-%d %H:%M:%S"`
    if [[ ${result_code} =~ '200' ]]; then
        sleep_time=$(rand 100 120)
        echo "${cur_time}  --&gt; OK, set pool : (${pool_name}) as s3 pool success, now sleep ${sleep_time}s" 
        sleep ${sleep_time}
    elif [[ ${result_code} =~ '401'  ]]; then
        echo "[WARN]  Session timeout, login again"
        login_ui
    else
        echo "${cur_time}  [ERROR]  exit!" 
        echo ""
        exit 1
    fi
}


function wait_until_ctdb_ok()
{
    expect_num=$1
    max_wait_time=$2
    current_time=0
    while [[ $current_time -lt $max_wait_time ]];do
        current_ctdb_ok=`ctdb status 2&gt;/dev/null|grep OK|wc -l`
        if [ $current_ctdb_ok -eq $expect_num ];then
            break
        fi
        sleep 5
        current_time=$((current_time+5))
        #echo "...elapse: $current_time, ctdb: ${current_ctdb_ok}"
    done
    if [[ $current_time -ge $max_wait_time ]];then
        echo "Fail!!! After wait $max_wait_time seconds, ctdb number is still $current_ctdb_ok, should be $expect_num, exit!"
        # ceph tell osd.* injectargs '--debug-osd 0/0'
        # ceph tell mds.* injectargs '--debug-mds 0/0'
        onnode -p all 'truncate --size 0 /var/log/ceph/ceph*.log'
        exit 1
    fi
    echo "${current_time}"
}


function wait_until_ceph_ok()
{
    max_wait_time=$1
    start_time=`date +%s`
    max_end_time=$((start_time+max_wait_time))
    current_time=`date +%s`
    while [[ $current_time -lt $max_end_time ]];do
        ceph -s|grep "$pgnum active+clean" &gt;/dev/null
        if [ $? -eq 0 ];then
            break
        fi
        sleep 5
        current_time=`date +%s`
    done
    if [[ $current_time -ge $max_end_time ]];then
        echo "Fail!!! After wait $max_wait_time seconds, ceph is not healthy, but is `ceph health`, exit!"
        # ceph tell osd.* injectargs '--debug-osd 0/0'
        # ceph tell mds.* injectargs '--debug-mds 0/0'
        exit 1
    fi
    echo "$((current_time-start_time))"
}

# ceph tell mds.* injectargs '--debug-mds 20' 2&amp;&gt;/dev/null


function wait_objects_reach()
{
    echo "`date '+%Y-%m-%d %H:%M:%S'`: Wait S3 objects number should be large than ${bucket_objs_no}"

    cur_s3_pool=`radosgw-admin zone get --rgw-zone=default | grep data_pool | awk -F ':' '{{print $NF}}' | sed 's/,//g' | sed 's/"//g' | sed 's/ //g'`
    objs=`ceph df | grep ${cur_s3_pool} | awk '{{print $NF}}'`

    while [[ ${objs} -le ${bucket_objs_no} ]]; do
        sleep_time=$(rand 30 60)
        echo "`date '+%Y-%m-%d %H:%M:%S'`: Objects number : ${objs} is less than ${bucket_objs_no}, sleep ${sleep_time}"
        sleep ${sleep_time}
        objs=`ceph df | grep ${cur_s3_pool} | awk '{{print $NF}}'`
    done

    echo "`date '+%Y-%m-%d %H:%M:%S'`: Objects number : ${objs} is large than ${bucket_objs_no}"
}


function kill_ceph_service()
{
    process_to_kill='ceph-osd ceph-mds ceph-mon radosgw'
    for seed in ${process_to_kill}; do
        process_list=`ssh ${target_ip} pidof ${seed}`
        killed=
        for killpid in $process_list; do
          if [ ! -z $killpid ];then
            echo "`date '+%Y-%m-%d %H:%M:%S'`: Killed ${seed} PID ${killpid} on node : ${target_ip}"
            ssh ${target_ip} kill -9 $killpid
            killed=yes
          fi
        done

        if [ -z $killed ];then
            echo "`date '+%Y-%m-%d %H:%M:%S'`: Didn't kill anything on node ${target_ip}"
        fi
    done

    ssh ${target_ip} systemctl stop ceph.target
    sleep_time=$(rand 100 180)
    echo "`date '+%Y-%m-%d %H:%M:%S'`: After kill ceph service, sleep ${sleep_time}"
    sleep ${sleep_time}
}


function start_ceph_service(){
    echo "`date '+%Y-%m-%d %H:%M:%S'`: Start ceph service on node ${target_ip}"
    ssh ${target_ip} systemctl start ceph.target
    ssh ${target_ip} systemctl restart ceph-radosgw@radosgw.0.service
}


function restart_cosbench_job()
{
    cosbench_ip=10.16.172.244
    cosbench_dir="/root/0.4.2.c4"
    submit_dir="/root/75"
    root_passwd=1

    job_no=`sshpass -p ${root_passwd} ssh -o ServerAliveInterval=60 -p 22 -l root ${cosbench_ip} "${cosbench_dir}/cli.sh info |&amp; grep PROCESSING | wc -l"`

    if [[ ${job_no} -gt 0 ]]; then
        job_id=`sshpass -p ${root_passwd} ssh -o ServerAliveInterval=60 -p 22 -l root ${cosbench_ip} "${cosbench_dir}/cli.sh info |&amp; grep PROCESSING | awk '{{print \\$1}}'"`

        # Cancel the job
        echo "`date '+%Y-%m-%d %H:%M:%S'`: Cancel cosbench job : ${job_id}"
        sshpass -p ${root_passwd} ssh -o ServerAliveInterval=60 -p 22 -l root ${cosbench_ip} "${cosbench_dir}/cli.sh cancel ${job_id}"

        # Start another new job
        echo "`date '+%Y-%m-%d %H:%M:%S'`: Sumbit a new cosbench job"
        kill_cmd="ps -ef |grep cosbench.sh | grep -v grep | awk '{{print \$2}}' | xargs -I {} kill -9 {}"
        sshpass -p ${root_passwd} ssh -o ServerAliveInterval=60 -p 22 -l root ${cosbench_ip} "${kill_cmd}; cd ${submit_dir}; bash cosbench.sh"&amp;
    else
        # Start another new job
        echo "`date '+%Y-%m-%d %H:%M:%S'`: Sumbit a new cosbench job"
        kill_cmd="ps -ef |grep cosbench.sh | grep -v grep | awk '{{print \$2}}' | xargs -I {} kill -9 {}"
        sshpass -p ${root_passwd} ssh -o ServerAliveInterval=60 -p 22 -l root ${cosbench_ip} "${kill_cmd}; cd ${submit_dir}; bash cosbench.sh"&amp;
    fi
}


# Check pool exists or not
check_pool_exist

# First, needs to login UI, generate session
login_ui

for ((i=1;i&lt;=$loop_cnt;i++));
do
    echo "============================================== $i =============================================="
    # Secondly, reset s3 pool
    cur_s3_pool=`radosgw-admin zone get --rgw-zone=default | grep data_pool | awk -F ':' '{{print $NF}}' | sed 's/,//g' | sed 's/"//g' | sed 's/ //g'`
    if [[ X${cur_s3_pool} == X${target_pool} ]]; then
        reset_s3_pool ${default_pool}
    elif [[ X${cur_s3_pool} == X${default_s3_pool} ]]; then
        reset_s3_pool ${target_pool}
    else
        reset_s3_pool ${target_pool}
    fi

    # Resubmit a cosbench job
    restart_cosbench_job

    # Wait S3 pool objects reach to the target numbers
    wait_objects_reach

    # Then kill and start ceph-osd, ceph-mds, ceph-mon, radosgw
    kill_ceph_service
    start_ceph_service

    cost_time=$(wait_until_ceph_ok $ceph_wait_time)
    echo "`date '+%Y-%m-%d %H:%M:%S'`: After ${cost_time}s, ceph becomes HEALTH_OK."

    onnode all 'ls /var/log/cores -lhrt | grep -vi ldb' 2&gt;/dev/null|grep ezcore
    if [[ $? -eq 0 ]]; then
        echo "`date '+%Y-%m-%d %H:%M:%S'`: FAIL!! Core dump of others yielded."
        # ceph tell osd.* injectargs '--debug-osd 0/0'
        # ceph tell mds.* injectargs '--debug-mds 0/0'
        exit 1
    fi

    onnode -p all 'truncate --size 0 /var/log/ceph/ceph*.log'
    echo "[Success]  Loop $i pass"
done
root@node76:~#
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>热插拔设备</title>
    <url>/2020/07/10/hot_swap_device/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>测试中碰到破坏RAID或下线磁盘的场景，需要从设备上拔盘，然后等产品侦测到对应Disk或VD异常后，再插回去，验证程序侦测及时性是否存在问题。</p>
<p>由于要频繁的进出机房进行设备的拔出与插回操作，比较麻烦，是否有更便捷的方式进行操作呢？</p>
<p>本文介绍同事推荐的，在有热交换驱动器情况下，通过scsi热插拔指令（scsi remove-single-device，scsi add-single-device），移除和回插某块设备。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="yi-chu-she-bei">移除设备</h2>
<pre><code class="language-shell">echo 'scsi remove-single-device 0 0 17 0' &gt; /proc/scsi/scsi
</code></pre>
<h2 id="tian-jia-she-bei">添加设备</h2>
<pre><code class="language-shell">echo 'scsi add-single-device 0 0 17 0' &gt; /proc/scsi/scsi
</code></pre>
<p>其中，0 0 17 0 为对应磁盘的信息，参考如下：</p>
<pre><code class="language-shell">root@node75:~# lsscsi 
[0:0:0:0]    enclosu GIGABYTE S451 series      000a  -        
[0:0:1:0]    enclosu GIGABYTE S451 series      000a  -        
[0:0:17:0]   disk    ATA      INTEL SSDSC2KG48 0142  /dev/sdh 
[0:2:0:0]    disk    AVAGO    Gigabyte MR-3108 4.68  /dev/sdb 
[0:2:1:0]    disk    AVAGO    Gigabyte MR-3108 4.68  /dev/sde 
[0:2:2:0]    disk    AVAGO    Gigabyte MR-3108 4.68  /dev/sdc 
[0:2:3:0]    disk    AVAGO    Gigabyte MR-3108 4.68  /dev/sdd 
[1:0:0:0]    disk    ATA      INTEL SSDSC2KG24 0100  /dev/sdf 
[2:0:0:0]    disk    ATA      INTEL SSDSC2KG24 0100  /dev/sdg 
root@node75:~#
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>第一列：SCSI设备id，这四个字段分别对应信息为：hostadapter id，SCSI channel on hostadapter，vd target ID， LUN(分别对应本文的0，0，17，0)</p>
</li>
<li class="lvl-2">
<p>第二列：设备类型</p>
</li>
<li class="lvl-2">
<p>第3，4，5列：设备厂商，型号，版本信息  (Vendor,Model,Rev)</p>
</li>
<li class="lvl-2">
<p>最后一列：Rev，设备主节点名，可以理解为设备在系统中的名称，如果是磁盘，则为/dev/sdxxx</p>
</li>
</ul>
<p>单独展示一下这里的第三列，第四列，第五列信息：</p>
<p>| <strong>第三列</strong>                     | <strong>第四列</strong>         | <strong>第五列</strong>                               |<br>
| ------------------------------ | ------------------------------------------------------------ |<br>
| AVAGO  | Gigabyte MR-3108   | 4.68    |</p>
<p>分别对应着Vendor，Model， Rev，参考如下：</p>
<pre><code class="language-shell">root@node75:/proc/scsi# lsscsi -c
Attached devices: 
Host: scsi0 Channel: 00 Target: 00 Lun: 00
  Vendor: GIGABYTE Model: S451 series      Rev: 000a
  Type:   Enclosure                        ANSI SCSI revision: 05
Host: scsi0 Channel: 00 Target: 01 Lun: 00
  Vendor: GIGABYTE Model: S451 series      Rev: 000a
  Type:   Enclosure                        ANSI SCSI revision: 05
Host: scsi0 Channel: 00 Target: 17 Lun: 00
  Vendor: ATA      Model: INTEL SSDSC2KG48 Rev: 0142
  Type:   Direct-Access                    ANSI SCSI revision: 06
Host: scsi0 Channel: 02 Target: 00 Lun: 00
  Vendor: AVAGO    Model: Gigabyte MR-3108 Rev: 4.68
  Type:   Direct-Access                    ANSI SCSI revision: 05
Host: scsi0 Channel: 02 Target: 01 Lun: 00
  Vendor: AVAGO    Model: Gigabyte MR-3108 Rev: 4.68
  Type:   Direct-Access                    ANSI SCSI revision: 05
Host: scsi0 Channel: 02 Target: 02 Lun: 00
  Vendor: AVAGO    Model: Gigabyte MR-3108 Rev: 4.68
  Type:   Direct-Access                    ANSI SCSI revision: 05
Host: scsi0 Channel: 02 Target: 03 Lun: 00
  Vendor: AVAGO    Model: Gigabyte MR-3108 Rev: 4.68
  Type:   Direct-Access                    ANSI SCSI revision: 05
Host: scsi1 Channel: 00 Target: 00 Lun: 00
  Vendor: ATA      Model: INTEL SSDSC2KG24 Rev: 0100
  Type:   Direct-Access                    ANSI SCSI revision: 05
Host: scsi2 Channel: 00 Target: 00 Lun: 00
  Vendor: ATA      Model: INTEL SSDSC2KG24 Rev: 0100
  Type:   Direct-Access                    ANSI SCSI revision: 05
root@node75:/proc/scsi#
</code></pre>
<p>热插拔磁盘后，对应的kern log信息片断参考如下:</p>
<pre><code class="language-shell">Jul  9 13:46:46 node75 kernel: [ 8752.867575] sd 0:0:17:0: SCSI device is removed
Jul  9 13:46:46 node75 kernel: [ 8752.867895] [830035]: scst: scst_unregister_device:1188:Detached from scsi0, channel 0, id 17, lun 0, type 0
Jul  9 13:46:46 node75 kernel: [ 8752.868087] print_req_error: I/O error, dev sda, sector 0
Jul  9 13:46:46 node75 kernel: [ 8752.875385] sd 0:0:17:0: [sda] Synchronizing SCSI cache
Jul  9 13:46:46 node75 kernel: [ 8752.875497] sd 0:0:17:0: [sda] Synchronize Cache(10) failed: Result: hostbyte=DID_BAD_TARGET driverbyte=DRIVER_OK
Jul  9 13:46:46 node75 kernel: [ 8752.895282] megaraid_sas 0000:af:00.0: scanning for scsi0...
Jul  9 13:46:48 node75 kernel: [ 8754.164633] scsi 0:0:17:0: Direct-Access     ATA      INTEL SSDSC2KG48 0142 PQ: 0 ANSI: 6
Jul  9 13:46:48 node75 kernel: [ 8754.166811] sd 0:0:17:0: Attached scsi generic sg2 type 0
Jul  9 13:46:48 node75 kernel: [ 8754.166818] sd 0:0:17:0: [sdh] 937703088 512-byte logical blocks: (480 GB/447 GiB)
Jul  9 13:46:48 node75 kernel: [ 8754.166821] sd 0:0:17:0: [sdh] 4096-byte physical blocks
Jul  9 13:46:48 node75 kernel: [ 8754.166838] [830035]: scst: scst_register_device:1102:Attached to scsi0, channel 0, id 17, lun 0, type 0
Jul  9 13:46:48 node75 kernel: [ 8754.167729] sd 0:0:17:0: [sdh] Write Protect is off
Jul  9 13:46:48 node75 kernel: [ 8754.167731] sd 0:0:17:0: [sdh] Mode Sense: 9b 00 10 08
Jul  9 13:46:48 node75 kernel: [ 8754.168049] sd 0:0:17:0: [sdh] Write cache: enabled, read cache: enabled, supports DPO and FUA
Jul  9 13:46:48 node75 kernel: [ 8754.174319]  sdh: sdh1 sdh2
Jul  9 13:46:48 node75 kernel: [ 8754.176615] sd 0:0:17:0: [sdh] Attached SCSI disk
Jul  9 13:46:48 node75 kernel: [ 8754.739509] blk_partition_remap: fail for partition 2
Jul  9 13:46:48 node75 kernel: [ 8754.739514] EXT4-fs error (device sda2): ext4_find_entry:1455: inode #2: comm ezrpcd: reading directory lblock 0
Jul  9 13:46:52 node75 kernel: [ 8758.867351] sd 0:0:17:0: SCSI device is removed
Jul  9 13:46:52 node75 kernel: [ 8758.867648] [830035]: scst: scst_unregister_device:1188:Detached from scsi0, channel 0, id 17, lun 0, type 0
Jul  9 13:46:52 node75 kernel: [ 8758.872546] sd 0:0:17:0: [sdh] Synchronizing SCSI cache
Jul  9 13:46:52 node75 kernel: [ 8758.872627] sd 0:0:17:0: [sdh] Synchronize Cache(10) failed: Result: hostbyte=DID_BAD_TARGET driverbyte=DRIVER_OK
Jul  9 13:46:52 node75 kernel: [ 8758.897329] megaraid_sas 0000:af:00.0: scanning for scsi0...
Jul  9 13:46:57 node75 kernel: [ 8763.163262] scsi 0:0:17:0: Direct-Access     ATA      INTEL SSDSC2KG48 0142 PQ: 0 ANSI: 6
Jul  9 13:46:57 node75 kernel: [ 8763.165348] sd 0:0:17:0: Attached scsi generic sg2 type 0
Jul  9 13:46:57 node75 kernel: [ 8763.165372] [830035]: scst: scst_register_device:1102:Attached to scsi0, channel 0, id 17, lun 0, type 0
Jul  9 13:46:57 node75 kernel: [ 8763.166274] sd 0:0:17:0: [sdh] 937703088 512-byte logical blocks: (480 GB/447 GiB)
Jul  9 13:46:57 node75 kernel: [ 8763.166279] sd 0:0:17:0: [sdh] 4096-byte physical blocks
Jul  9 13:46:57 node75 kernel: [ 8763.166558] sd 0:0:17:0: [sdh] Write Protect is off
Jul  9 13:46:57 node75 kernel: [ 8763.166561] sd 0:0:17:0: [sdh] Mode Sense: 9b 00 10 08
Jul  9 13:46:57 node75 kernel: [ 8763.166893] sd 0:0:17:0: [sdh] Write cache: enabled, read cache: enabled, supports DPO and FUA
Jul  9 13:46:57 node75 kernel: [ 8763.175450]  sdh: sdh1 sdh2
Jul  9 13:46:57 node75 kernel: [ 8763.177604] sd 0:0:17:0: [sdh] Attached SCSI disk
</code></pre>
<p>BTW，本示例中，0:0:17:0: [sdh] 是一块SSD，做成JBOD模式，当JBOD对应盘正常在设备上运行时，是不支持Megacli/storcli下线磁盘指令的，一旦执行报错信息参考如下:</p>
<pre><code class="language-shell">root@node75:~# storcli64 /c0/e1/s17 set offline
Controller = 0
Status = Failure
Description = No drive found!

Detailed Status :
===============

-----------------------------------------
Drive      Status  ErrCd ErrMsg
-----------------------------------------
/c0/e1/s17 Failure   255 Drive not found
-----------------------------------------


root@node75:~#
</code></pre>
<h1 id="qi-ta">其他</h1>
<p>上文中的热插拔，和 ‘Rescan SCSI/SATA Host Bus’ 有着异曲同工之处，毕竟方法都是多样的，，根据不同场合使用。</p>
<pre><code class="language-shell">#/bin/bash
# ReScan all SCSI/SATA Hosts
for SHOST in /sys/class/scsi_host/host*; do
    echo -n "Scanning ${SHOST##*/}..."
    echo "- - -" &gt; ${SHOST}/scan
    echo Done
done
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>因存在多文件系统导致OSD启用失败</title>
    <url>/2020/08/31/more_filesystem_detected/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天在创建OSD并启用它的时候，出现了如下一个错误:</p>
<pre><code class="language-shell">[2020-08-31 10:23:32,948] [ERROR] [2163] [ezs3.storage_volume] [enable:816] enable osd fail
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/ezs3/storage_volume.py", line 803, in enable
    self.mount(True)
  File "/usr/lib/python2.7/dist-packages/ezs3/storage_volume.py", line 1284, in mount
    options + data_dev_options)
  File "/usr/lib/python2.7/dist-packages/ezs3/storage_volume.py", line 257, in mount
    ','.join(options), fstab_path, mountpoint))
  File "/usr/lib/python2.7/dist-packages/ezs3/remote.py", line 201, in callable
    return func(*args, **kwargs)
  File "/usr/lib/python2.7/dist-packages/ezs3/command.py", line 140, in do_cmd
    raise DoCommandError(err, p.returncode, output, cmdstr)
DoCommandError: DoCommandError: errno 1 stdout '' stderr 'mount: /dev/mapper/g-osd-2: more filesystems detected. This should not happen,
       use -t &lt;type&gt; to explicitly specify the filesystem type or
       use wipefs(8) to clean up the device.
' cmd 'mount -o noauto,nodelalloc,nomtime,noatime,journal_path=/dev/mapper/g-osd-2-ext4j /dev/mapper/g-osd-2 /data/osd.8'
[2020-08-31 10:23:32,949] [ERROR] [2163] [ezs3.node_management] [enable:1115] enable storage volume g-osd-2 osd 8 failed
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/ezs3/node_management.py", line 1106, in enable
    osd_id = sv.enable(sip, cip, osd_id)
  File "/usr/lib/python2.7/dist-packages/ezs3/storage_volume.py", line 817, in enable
    raise e
DoCommandError: DoCommandError: errno 1 stdout '' stderr 'mount: /dev/mapper/g-osd-2: more filesystems detected. This should not happen,
       use -t &lt;type&gt; to explicitly specify the filesystem type or
       use wipefs(8) to clean up the device.
' cmd 'mount -o noauto,nodelalloc,nomtime,noatime,journal_path=/dev/mapper/g-osd-2-ext4j /dev/mapper/g-osd-2 /data/osd.8'
</code></pre>
<h1 id="jie-jue-si-lu">解决思路</h1>
<p>看到这个错误的时候，直接使用了sgdisk -Z /dev/sdX 抹掉分区，回头尝试，还是同样的错误信息， 回想之前做的操作，分区有被用来做ZFS类型的OSD,会不会是它导致的?</p>
<p>使用wipefs指令，查看文件系统信息:</p>
<pre><code class="language-shell">root@pytest-80-12:~# wipefs /dev/sdg2
offset               type
----------------------------------------------------------------
0x1ffe6c800          zfs_member   [raid]
                     LABEL: pytest_advance_osd_lba
                     UUID:  8560903119562917028

0x438                ext4   [filesystem]
                     UUID:  01c5f798-2e00-4527-ae90-c5442d0f8f6e

root@pytest-80-12:~# wipefs /dev/sdf2
offset               type
----------------------------------------------------------------
0x1ffe7fc00          zfs_member   [raid]
                     LABEL: pytest_edit_osd_hkq
                     UUID:  6743149755630861260

0x438                ext4   [filesystem]
                     UUID:  146c1897-efe8-4f9e-b05c-391601dc33fd
</code></pre>
<p>果然，这里显示同一个分区，有两个文件系统类型，一个是zfs_member，后面的[raid]表示是software raid，的确是之前使用过这个分区做过OSD;后面还有一个ext4的文件系统类型，两个文件系统类型并存，导致mount时候失败了。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>只用wipefs -a -f /dev/sdX来抹掉信息即可，有时候可能要抹掉多次，参考如下：</p>
<pre><code class="language-shell">root@host248:/dev# wipefs /dev/sdc1
offset               type
----------------------------------------------------------------
0x574dfe70000        zfs_member   [raid]
                     LABEL: softraid
                     UUID:  13987007202510144699

root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfe70000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfe6d000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfe6c000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfe6b000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfe6a000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfe69000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfe68000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfea6000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfea5000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
/dev/sdc1: 8 bytes were erased at offset 0x574dfea4000 (zfs_member): 0c b1 ba 00 00 00 00 00
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
root@host248:/dev# wipefs /dev/sdc1 |grep zfs_member | awk '{{print $1}}' | xargs -I{} wipefs -o {} /dev/sdc1
root@host248:/dev# wipefs /dev/sdc1
root@host248:/dev#
</code></pre>
<h1 id="can-kao-wen-dang">参考文档</h1>
<pre><code class="language-shell">https://bbs.archlinux.org/viewtopic.php?id=202587
https://wiki2.xbits.net:4430/hardware:lsi:wipefs%E6%B8%85%E9%99%A4raid%E4%BF%A1%E6%81%AF
</code></pre>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>mds damaged test script</title>
    <url>/2020/08/26/mds_damaged/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>The product introduces multiple mds, and each cephfs is allowed to set the upper limit to 6 mds number, i.e., under each cephfs, the maximum number of active-mds allowed to exist is 6.<br>
In order to verify the robustness of these forked ceph-mds, a test script was written to simulate the corruption of ceph-mds, in order to verify the robustness of the product under the scenario of mds corruption.</p>
<h1 id="scripts">Scripts</h1>
<p><code>mds_damaged.sh</code></p>
<pre><code class="language-shell">#!/bin/bash

loop_cnt=1000
ctdb_wait_time=500
ceph_wait_time=60
throughput_wait_time=300
throughput_min=200
node_num=3
pgnum=25600
errno=0

function send_mail()
{
    echo "$1"
    python -c "from ezs3.mail_notification import MailNotificationManager; \
               MailNotificationManager().send_mail('Quit of ctdb_event_lost scipt: ${1}', '${1}')"
}

turn_on_debug()
{
#    onnode all 'echo "module libceph +ftpl" &gt; /sys/kernel/debug/dynamic_debug/control' 2&gt;/dev/null
#    onnode all 'echo "file caps.c +ftpl" &gt; /sys/kernel/debug/dynamic_debug/control' 2&gt;/dev/null
    ceph tell osd.* injectargs '--debug-osd 20/20' 2&amp;&gt;/dev/null
#    ceph tell osd.* injectargs '--debug-ms 20/20' 2&amp;&gt;/dev/null
    ceph tell mds.* injectargs '--debug-mds 20/20' 2&amp;&gt;/dev/null
}

turn_off_debug()
{
#    onnode all 'echo "module libceph -ftpl" &gt; /sys/kernel/debug/dynamic_debug/control' 2&gt;/dev/null
#    onnode all 'echo "file caps.c -ftpl" &gt; /sys/kernel/debug/dynamic_debug/control' 2&gt;/dev/null
    ceph tell osd.* injectargs '--debug-osd 0/0' 2&amp;&gt;/dev/null
    ceph tell osd.* injectargs '--debug-ms 0/0' 2&amp;&gt;/dev/null
    ceph tell mds.* injectargs '--debug-mds 0/0' 2&amp;&gt;/dev/null
}

function truncate_files_if_near_full()
{
    usage=`df -h .|tail -n 1|sed -nr 's/.* ([0-9]+)%.*/\1/gp'`
    if (( $usage &gt; 80 ));then
        echo "`date`: WARN! root partition usage is over 80%, truncate all logs on all nodes."
        onnode -p all 'truncate --size 0 /var/log/ceph/ceph*.log;truncate --size 0 /var/log/kern.log;truncate --size 0 /var/log/syslog'
    fi
}

function wait_until_ctdb_ok()
{
    expect_num=$1
    max_wait_time=$2
    current_time=0
    while [[ $current_time -lt $max_wait_time ]];do
        current_ctdb_ok=`ctdb status 2&gt;/dev/null|grep OK|wc -l`
        if [ $current_ctdb_ok -eq $expect_num ];then
            break
        fi
        #truncate_files_if_near_full
        sleep 5
        current_time=$((current_time+5))
        #echo "...elapse: $current_time, ctdb: ${current_ctdb_ok}"
    done
    if [[ $current_time -ge $max_wait_time ]];then
        turn_off_debug
        #send_mail "Fail!!! After wait $max_wait_time seconds, ctdb number is still $current_ctdb_ok, should be $expect_num, exit!"
        echo "`date`: Fail!!! After wait $max_wait_time seconds, ctdb number is still $current_ctdb_ok, should be $expect_num, exit!"
    fi
    echo $current_time
}

function wait_until_ceph_ok()
{
    max_wait_time=$1
    current_time=0
    while [[ $current_time -lt $max_wait_time ]];do
        ceph -s|grep "$pgnum active+clean" &gt;/dev/null
        if [ $? -eq 0 ];then
            ceph -s|grep "mons down" &gt;/dev/null
            if [ $? -ne 0 ];then
                break
            fi
        fi
        #truncate_files_if_near_full
        sleep 5
        current_time=$((current_time+5))
    done
    if [[ $current_time -ge $max_wait_time ]];then
        turn_off_debug
        #send_mail "Fail!!! After wait $max_wait_time seconds, ceph is not healthy, but is `ceph health`, exit!"
        echo "`date`: Fail!!! After wait $max_wait_time seconds, ceph is not healthy, but is `ceph health`, exit!"
    fi
    echo $current_time

}

function wait_until_throughput_ok()
{
    max_wait_time=$1
    current_time=0
    while [[ $current_time -lt $max_wait_time ]];do
        throughput=`ceph -s |sed -nr 's/.*client.*rd, ([0-9]+).*rd.*/\1/gp'`
        if (( throughput &gt; throughput_min ));then
            break
        fi
        sleep 5
        current_time=$((current_time+5))
    done
    if [[ $current_time -ge $max_wait_time ]];then
        turn_off_debug
        #send_mail "Fail!!! After wait $max_wait_time seconds, throughput is still only $throughput MiB/s, exit!"
        echo "`date`: Fail!!! After wait $max_wait_time seconds, throughput is still only $throughput MiB/s, exit!"
    fi
    echo $current_time
}

function find_ctdb_master()
{
    pnn=$(ctdb status| sed -nr 's/Recovery master:([0-3])/\1/p')
    echo $(ctdb status| sed -nr "s/pnn:$pnn 10.10.51.([0-9]+).*/\1/p")
}

for ((i=1;i&lt;=$loop_cnt;i++));do
    echo "===================$i==================="
    turn_on_debug
    ip="10.16.172.$(find_ctdb_master)"
    echo "`date`: Find the master ip: $ip"
    case "$ip" in 
        "10.16.172.51")
            intdev=enp94s0f1
        ;;
        "10.16.172.52")
            ctdb setrecmasterrole off
            sleep 20
            #ctdb setrecmasterrole on
            echo "`date`: Skip this round due to script is running on 52"
            continue
        ;;
        "10.16.172.53")
            intdev=enp94s0f1
        ;;
        *)
          echo "`date`: Invalid master ip: $ip, quit!"
          exit 1
        ;;
    esac
    echo "`date`: ssh $ip ifconfig $intdev down"
    ssh $ip ifconfig $intdev down
    sleep 30
    cost_time=$(wait_until_ctdb_ok $((node_num-1)) $ctdb_wait_time)
    if [[ $cost_time =~ "Fail" ]];then
        echo $cost_time
        exit 1 
    fi
    echo "`date`: After $((cost_time+30))s, ctdb OK nodes reaches $((node_num-1))."
    echo "`date`: ssh $ip ifconfig $intdev up"
    ssh $ip ifconfig $intdev up
    sleep 11
    echo "`date`: ssh $ip ifconfig $intdev down"
    ssh $ip ifconfig $intdev down
    sleep 35
    echo "`date`: systemctl stop ceph-mon.target"
    systemctl stop ceph-mon.target
    sleep 10
    echo "`date`: ssh $ip ifconfig $intdev up"
    ssh $ip ifconfig $intdev up
    sleep 10
    echo "`date`: systemctl start ceph-mon.target"
    systemctl disable ceph-mon.target 2&amp;&gt; /dev/null
    systemctl enable ceph-mon.target 2&amp;&gt; /dev/null
    systemctl start ceph-mon.target 2&amp;&gt; /dev/null
    cost_time=$(wait_until_ctdb_ok $node_num $ctdb_wait_time)
    if [[ $cost_time =~ "Fail" ]];then
        echo $cost_time
        exit 1 
    fi
    echo "`date`: After ${cost_time}s, ctdb OK nodes reaches ${node_num}."
    cost_time=$(wait_until_ceph_ok $ceph_wait_time)
    if [[ $cost_time =~ "Fail" ]];then
        echo $cost_time
        exit 1 
    fi
    echo "`date`: After ${cost_time}s, ceph becomes HEALTH_OK."
    onnode all 'ls /var/log/cores/ -lhrt' 2&gt;/dev/null|grep ezcore.tp_peering
    if [[ $? -eq 0 ]]; then
        turn_off_debug
        #send_mail "`date`: FAIL!! Core dump of peering yielded."
        echo "`date`: FAIL!! Core dump of peering yielded."
        exit 1
    fi
    onnode all 'rm -f /var/log/cores/ezcore.msgr*' 2&gt;/dev/null
    onnode all 'ls /var/log/cores -lhrt' 2&gt;/dev/null|grep ezcore
    if [[ $? -eq 0 ]]; then
#        onnode all 'rm -f /var/log/cores/ezcore*' 2&gt;/dev/null
#        echo "`date`: WARN!! Other core dump yielded."
        turn_off_debug
        #send_mail "`date`: FAIL!! Core dump yielded."
        echo "`date`: FAIL!! Core dump yielded."
        exit 1
    fi
    ceph -s | grep "mds daemon damaged"
    if [[ $? -eq 0 ]]; then
        turn_off_debug
        #send_mail "`date`: FAIL!! mds daemon damaged."
        echo "`date`: FAIL!! mds daemon damaged."
        exit 1
    fi
    onnode -p all 'truncate --size 0 /var/log/ceph/ceph*.log;truncate --size 0 /var/log/kern.log;truncate --size 0 /var/log/syslog; truncate --size 0 /var/log/rsyslog.debug '
#     cost_time=$(wait_until_throughput_ok $throughput_wait_time)
#     echo "`date`: After ${cost_time}s, nfs traffic achieves ${throughput_min} MiB/s."
    echo "`date`: Sleep 10s to end this loop."
    sleep 10
    echo "Loop $i pass."
done
turn_off_debug
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>ceph</tag>
        <tag>mds</tag>
      </tags>
  </entry>
  <entry>
    <title>python字段反转去重</title>
    <url>/2020/10/02/revert_dict_then_delete_duplicate/</url>
    <content><![CDATA[<h1 id="qian-yan">前言</h1>
<p>最近在写script支持cobbler全自动部署OS，由于profile与system对应关系是1:N，下次执行自动安装前会清理掉对应的profile与system，但当有其他人使用了script生成的profile后，就形成了一个profile对应多个system，回头再删profile时出错，因为这个profile有被其他system占用，删除失败了。解决方法就是找处profile关联的system，先删除掉system，再删除profile。</p>
<p>这个过程碰到一个问题，如何获取cobbler profile与system的map关系（虽然可以通过cobbler CGI来获取map关系，但太重了点）。</p>
<h1 id="wen-ti-suo-zai">问题所在</h1>
<p>如下为测试示例获取到的profile与system的字典信息：</p>
<pre><code class="language-shell">{'test02': 'Scaler-8.0-latest-x86_64', 'Scaler-CentOS-8.0-latest-x86_64': 'Scaler-CentOS-8.0-latest-x86_64', 'Scaler-8.0-latest-x86_64': 'Scaler-8.0-latest-x86_64', 'test01': 'Scaler-8.0-latest-x86_64'}
</code></pre>
<p>而我预期的映射关系是：</p>
<pre><code class="language-shell">{'Scaler-CentOS-8.0-latest-x86_64': ['Scaler-CentOS-8.0-latest-x86_64'], 'Scaler-8.0-latest-x86_64': ['test02', 'Scaler-8.0-latest-x86_64', 'test01']}
</code></pre>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<pre><code class="language-shell">from collections import defaultdict
reversed_dict = defaultdict(list)
for key,value in mydict.iteritems():
    reversed_dict[value].append(key)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS6.5 testlink-1.9.10升级到1.9.20</title>
    <url>/2020/12/29/upgrade_testlink_from_1.9.10_to_1.9.20/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Lab使用的testlink版本是1.9.10，运行在CentOS6.5上，应大家要求，对testlink进行升级，升级到官方最新1.9.20版本</p>
<h1 id="shi-jian">实践</h1>
<h2 id="she-zhi-ben-di-yuan">设置本地源</h2>
<h2 id="bei-fen-ben-di-yuan">备份本地源</h2>
<p><code>cd /etc/yum.repos.d/;mkdir backup_repo; mv *.repo  mirrors-rpmforge* backup_repo/ </code></p>
<p>修改源</p>
<pre><code class="language-shell">vi redhat.repo
[rhel6-media]
name=local
baseurl=file:///mnt/cdrom
gpgcheck=0
enabled=1
</code></pre>
<h2 id="shang-chuan-jing-xiang-bing-gua-zai">上传镜像并挂载</h2>
<p>上传镜像 ‘rhel-server-6.6-x86_64-dvd.iso’, 并挂载</p>
<p><code>cd /mnt;mkdir cdrom;mount /dev/sr0 /mnt/cdrom/ </code></p>
<h2 id="shi-yong-ben-di-yuan">使用本地源</h2>
<p><code>yum clean all;yum makecache </code></p>
<h2 id="xie-zai-jiu-ban-php">卸载旧版php</h2>
<p><code>yum remove php-common </code></p>
<h2 id="an-zhuang-rpm-sheng-ji-bao">安装rpm升级包</h2>
<p><code>rpm -Uvh https://mirror.webtatic.com/yum/el6/latest.rpm </code></p>
<h2 id="an-zhuang-php-5-6">安装php5.6</h2>
<p><code>yum install -y php56w php56w-opcache php56w-xml php56w-mcrypt php56w-gd php56w-devel php56w-mysql php56w-intl php56w-mbstring --skip-broken </code></p>
<h2 id="cha-kan-php-ban-ben">查看php版本</h2>
<pre><code class="language-shell">[root@localhost mnt]# php -v
PHP 5.6.40 (cli) (built: Jan 12 2019 09:19:57) 
Copyright (c) 1997-2016 The PHP Group
Zend Engine v2.6.0, Copyright (c) 1998-2016 Zend Technologies
    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2016, by Zend Technologies
[root@localhost mnt]# 
</code></pre>
<h2 id="sheng-ji-mysql-5-5-dao-mysql-5-6">升级mysql 5.5 到 mysql 5.6</h2>
<h3 id="cha-kan-sheng-ji-qian-ban-ben">查看升级前版本</h3>
<pre><code class="language-shell">[root@localhost mnt]# yum info mysql-server
Loaded plugins: fastestmirror, refresh-packagekit, security
Loading mirror speeds from cached hostfile
 * webtatic: us-east.repo.webtatic.com
Installed Packages
Name        : mysql-server
Arch        : x86_64
Version     : 5.5.38
Release     : 1.el6.remi
Size        : 45 M
Repo        : installed
From repo   : remi
Summary     : The MySQL server and related files
URL         : http://www.mysql.com
License     : GPLv2 with exceptions and LGPLv2 and BSD
Description : MySQL is a multi-user, multi-threaded SQL database server. MySQL is a
            : client/server implementation consisting of a server daemon (mysqld)
            : and many different client programs and libraries. This package contains
            : the MySQL server and some accompanying files and directories.

[root@localhost mnt]# 
</code></pre>
<h3 id="xie-zai-jiu-ban-ben-mysql">卸载旧版本mysql</h3>
<p><code>yum remove mysql mysql-server </code></p>
<h3 id="xie-zai-mysql-client">卸载mysql-client</h3>
<p><code>yum remove mysql-client </code></p>
<h3 id="xie-zai-mysql-devel">卸载mysql-devel</h3>
<p><code>yum remove mysql-devel </code></p>
<h3 id="tian-jia-my-sql-de-yum-an-zhuang-ku">添加MySQL的yum安装库</h3>
<pre><code class="language-shell">wget http://dev.mysql.com/get/mysql-community-release-el6-5.noarch.rpm
rpm -ivh mysql-community-release-el6-5.noarch.rpm
</code></pre>
<p><code>yum list | grep mysql </code>, 这样很多更新的MySQL安装包就都有了。</p>
<p>如有必要，运行下面的命令确保yum安装库是最新的：</p>
<p><code>yum update mysql-community-release </code></p>
<h3 id="an-zhuang-mysql">安装mysql</h3>
<p><code>yum install mysql-server </code></p>
<h3 id="qi-dong-shu-ju-ku">启动数据库</h3>
<p><code>/etc/init.d/mysqld start </code></p>
<h3 id="xiu-fu-mysql">修复mysql</h3>
<p><code>mysql_upgrade -uroot -pp@ssw0rd </code></p>
<h2 id="an-zhuang-testlink-1-9-20">安装testlink-1.9.20</h2>
<h3 id="jie-ya-testlink-1-9-20">解压testlink-1.9.20</h3>
<p>略</p>
<h3 id="bei-fen-jiu-ban-testlink-shu-ju-ku">备份旧版testlink数据库</h3>
<h4 id="xian-bei-fen-hou-dao-ru-bei-fen-ku">先备份，后导入备份库</h4>
<p><code>mysql -uroot -pp@ssw0rd </code></p>
<p><code>create database testlink_bak; </code></p>
<h4 id="dao-chu-jiu-ku-shu-ju">导出旧库数据</h4>
<p><code>mysqldump -uroot -pp@ssw0rd testlink &gt; testlink_backup.sql </code></p>
<h4 id="dao-ru-dao-bei-fen-shu-ju-ku-zhong">导入到备份数据库中</h4>
<p><code>mysql -uroot -pp@ssw0rd testlink_bak &lt; testlink_backup.sql </code></p>
<h4 id="jiang-jiu-testlink-db-qie-huan-dao-testlink-bak">将旧testlink db切换到testlink_bak</h4>
<p>Step1. 修改config_db.conf，并重启httpd服务</p>
<p>Step2. 尝试访问旧版testlink报错</p>
<pre><code class="language-shell">[root@localhost logs]# mysql -ubigtera -p111111 testlink_bak
Warning: Using a password on the command line interface can be insecure.
ERROR 1044 (42000): Access denied for user 'bigtera'@'localhost' to database 'testlink_bak'
</code></pre>
<pre><code class="language-shell">mysql -uroot -pp@ssw0rd testlink_bak
</code></pre>
<p>执行</p>
<pre><code class="language-shell">GRANT ALL PRIVILEGES ON *.* TO 'bigtera'@'localhost' IDENTIFIED BY '111111';
</code></pre>
<h3 id="ui-an-zhuang-xin-testlink">UI 安装新testlink</h3>
<h4 id="an-zhuang-xin-ban-testlink">安装新版testlink</h4>
<p>如果不先修复mysql，在安装过程中会报错：</p>
<pre><code class="language-shell">TestLink setup will now attempt to setup the database:

Creating connection to Database Server:OK!

Database testlink_20 does not exist.
Will attempt to create:
Creating database `testlink_20`:OK!

 ============================================================================== 
 DB Access Error - debug_print_backtrace() OUTPUT START 
 ATTENTION: Enabling more debug info will produce path disclosure weakness (CWE-200) 
            Having this additional Information could be useful for reporting 
            issue to development TEAM. 
 ============================================================================== 
#0  database-&gt;exec_query() called at [/var/www/html/testlink-1.9.20/install/installUtils.php:571]
#1  _mysql_assign_grants() called at [/var/www/html/testlink-1.9.20/install/installUtils.php:311]
#2  create_user_for_db() called at [/var/www/html/testlink-1.9.20/install/installNewDB.php:420]
</code></pre>
<p>创建账户时：</p>
<pre><code class="language-shell">CREATE USER 'bigtera'@'localhost' IDENTIFIED BY '111111';

ERROR 1558 (HY000): Column count of mysql.user is wrong. Expected 43, found 42. Created with MySQL 50538, now running 50650. Please use mysql_upgrade to fix this error.
</code></pre>
<h4 id="zhi-xing-sql">执行sql</h4>
<p>先修改，再执行：</p>
<p><code>mysql -uroot -pp@ssw0rd testlink_20 &lt; /var/www/html/testlink-1.9.20/install/sql/mysql/testlink_create_udf0.sql </code></p>
<h4 id="xiu-gai-xin-ban-testlink-db-zhi-xiang-testlink-zhe-ge-db">修改新版testlink db，指向testlink这个db</h4>
<p>需要重启httpd服务</p>
<h4 id="ui-fang-wen-xin-ban-testlink">UI访问新版testlink</h4>
<p>提示要升级db，执行：</p>
<p><code>mysql -uroot -pp@ssw0rd testlink </code></p>
<p>然后执行下面操作：</p>
<pre><code class="language-shell">alter table platforms add enable_on_design tinyint(1) unsigned NOT NULL default '0';
alter table platforms add enable_on_execution tinyint(1) unsigned NOT NULL default '1';

CREATE OR REPLACE VIEW /*prefix*/latest_exec_by_testplan
AS SELECT tcversion_id, testplan_id, MAX(id) AS id
FROM /*prefix*/executions
GROUP BY tcversion_id,testplan_id;

CREATE TABLE /*prefix*/testplan_platforms (
  id int(10) unsigned NOT NULL auto_increment,
  testplan_id int(10) unsigned NOT NULL,
  platform_id int(10) unsigned NOT NULL,
  active tinyint(1) NOT NULL default '1',
  PRIMARY KEY (id),
  UNIQUE KEY /*prefix*/idx_testplan_platforms(testplan_id,platform_id)
) DEFAULT CHARSET=utf8 COMMENT='Connects a testplan with platforms';


CREATE TABLE /*prefix*/testcase_platforms (
  id int(10) unsigned NOT NULL AUTO_INCREMENT,
  testcase_id int(10) unsigned NOT NULL DEFAULT '0',
  tcversion_id int(10) unsigned NOT NULL DEFAULT '0',
  platform_id int(10) unsigned NOT NULL DEFAULT '0',
  PRIMARY KEY (id),
  UNIQUE KEY idx01_testcase_platform (testcase_id,tcversion_id,platform_id),
  KEY idx02_testcase_platform (tcversion_id)
) DEFAULT CHARSET=utf8;

CREATE OR REPLACE VIEW /*prefix*/tcversions_without_platforms
AS SELECT
   NHTCV.parent_id AS testcase_id,
   NHTCV.id AS id
FROM /*prefix*/nodes_hierarchy NHTCV
WHERE NHTCV.node_type_id = 4 AND
NOT(EXISTS(SELECT 1 FROM /*prefix*/testcase_platforms TCPL
           WHERE TCPL.tcversion_id = NHTCV.id));
           
CREATE TABLE /*prefix*/baseline_l1l2_context (
  id int(10) unsigned NOT NULL AUTO_INCREMENT,
  testplan_id int(10) unsigned NOT NULL DEFAULT '0',
  platform_id int(10) unsigned NOT NULL DEFAULT '0',
  being_exec_ts timestamp NOT NULL,
  end_exec_ts timestamp NOT NULL,
  creation_ts timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (id),
  UNIQUE KEY udx1 (testplan_id,platform_id,creation_ts)
) DEFAULT CHARSET=utf8;
</code></pre>
<p>然后执行如下操作，升级testlink db</p>
<pre><code class="language-shell">mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.10/mysql/DB.1.9.10/step1/db_data_update.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.11/mysql/DB.1.9.11/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.11/mysql/DB.1.9.11/stepZ/z_final_step.sql

mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.12/mysql/DB.1.9.12/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.12/mysql/DB.1.9.12/stepZ/z_final_step.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.13/mysql/DB.1.9.13/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.13/mysql/DB.1.9.13/stepZ/z_final_step.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.14/mysql/DB.1.9.14/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.14/mysql/DB.1.9.14/stepZ/z_final_step.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.15/mysql/DB.1.9.15/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.15/mysql/DB.1.9.15/stepZ/z_final_step.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.16/mysql/DB.1.9.16/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.16/mysql/DB.1.9.16/stepZ/z_final_step.sql

mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.17/mysql/DB.1.9.17/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.17/mysql/DB.1.9.17/stepZ/z_final_step.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.18/mysql/DB.1.9.18/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.18/mysql/DB.1.9.18/stepZ/z_final_step.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.19/mysql/DB.1.9.19/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.19/mysql/DB.1.9.19/stepZ/z_final_step.sql


mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.20/mysql/DB.1.9.20/step1/db_schema_update.sql
mysql -uroot -pp@ssw0rd testlink &lt; /var/www/html/testlink-1.9.20/install/sql/alter_tables/1.9.20/mysql/DB.1.9.20/stepZ/z_final_step.sql
</code></pre>
<p>至此，升级结束，可以删除旧版本testlink，重命名新版本testlink，并使用UI访问新版本testlink。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Config QCT switch port network</title>
    <url>/2021/02/09/config_qct_network_config/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>QCT 100G switch, need to do port adaptation.</p>
<h1 id="action">Action</h1>
<pre><code class="language-shell">admin@Switch:~$ sudo qnos-cli
[sudo] password for admin: 

(Switch) #configure 


show interface port-mode


interface 0/17


(Switch) (Interface 0/17)#port-mode ?

1x100G                   Configure the port as a single 100G port
1x40G                    Configure the port as a single 40G port
2x50G                    Configure the port as two 50G ports.
4x10G                    Configure the port as four 10G ports
4x25G                    Configure the port as four 25G ports

(Switch) (Interface 0/17)#port-mode 1x100G

(Switch) (Interface 0/18)#exit

(Switch) (Config)#exit

(Switch) #copy running-config startup-config
</code></pre>
<h1 id="she-zhi-ji-lian">设置级联</h1>
<h2 id="swtich-a-cao-zuo">SwtichA 操作</h2>
<pre><code class="language-shell">admin@Switch:~$ sudo qnos-cli
(Switch) #configure
(Switch) (Config)#interface port-channel 64
(Switch) (Config)#no staticcapability
(Switch) (Config)#switchport mode trunk
(Switch) (Config)#mlag peer-link
(Switch) (Config)#interface 0/31
(Switch) (Interface 0/31)#channel-group 64 mode active
(Switch) (Interface 0/31)#exit
(Switch) (Config)#mlag
(Switch) (Config)#mlag domain 1
(Switch) (Config)#mlag peer-keepalive enable
(Switch) (Config)#mlag peer-keepalive destination 172.17.75.248 source 172.17.75.249
(Switch) (Config)#exit
</code></pre>
<h2 id="swtich-b-cao-zuo">SwtichB 操作</h2>
<pre><code class="language-shell">admin@Switch:~$ sudo qnos-cli
(Switch) #configure
(Switch) (Config)#interface port-channel 64
(Switch) (Config)#no staticcapability
(Switch) (Config)#switchport mode trunk
(Switch) (Config)#mlag peer-link
(Switch) (Config)#interface 0/31
(Switch) (Interface 0/31)#channel-group 64 mode active
(Switch) (Interface 0/31)#exit
(Switch) (Config)#mlag
(Switch) (Config)#mlag domain 1
(Switch) (Config)#mlag peer-keepalive enable
(Switch) (Config)#mlag peer-keepalive destination 172.17.75.249 source 172.17.75.248
(Switch) (Config)#exit
</code></pre>
]]></content>
      <categories>
        <category>switch</category>
      </categories>
      <tags>
        <tag>switch</tag>
      </tags>
  </entry>
  <entry>
    <title>ps_mem:报告Linux内存用量的指令</title>
    <url>/2021/02/19/ps_mem/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天偶然发现一个指令：ps_mem</p>
<p>ps_mem 是一个可以帮助我们精确获取 Linux 中各个程序核心内存使用情况的简单 python 脚本。虽然在 Linux 上有很多可用于查看内存使用情况的工具，比如 free、vmstat、smem、top、htop、atop等，但这个工具和其它的区别在于其精确显示核心内存使用情况。<br>
ps_mem会分别计算一个程序私有内存总量和共享内存总量，并以更准确的方式给出了总的内存使用量，显示系统中哪些程序正在占用多少的内存。</p>
<h1 id="cao-zuo-shi-li">操作实例</h1>
<h2 id="bang-zhu">帮助</h2>
<pre><code class="language-shell">[root@node161 ~]# ps_mem -h
ps_mem.py - Show process memory usage

-h                                 Show this help
-w &lt;N&gt;                             Measure and show process memory every N seconds
-p &lt;pid&gt;[,pid2,...pidN]            Only show memory usage PIDs in the specified list
-s, --show-cmdline                 Show complete program path with options

</code></pre>
<h2 id="shi-li-1">示例1</h2>
<pre><code class="language-shell">[root@node161 ~]# ps_mem
 Private  +   Shared  =  RAM used	Program 

  4.0 KiB +  12.0 KiB =  16.0 KiB	acpid
112.0 KiB +  13.0 KiB = 125.0 KiB	agetty
124.0 KiB +  27.0 KiB = 151.0 KiB	ipmievd
  4.0 KiB + 164.5 KiB = 168.5 KiB	lvmetad
184.0 KiB +  20.5 KiB = 204.5 KiB	rpc.rquotad
204.0 KiB +  33.0 KiB = 237.0 KiB	atd
184.0 KiB +  55.0 KiB = 239.0 KiB	auditd
196.0 KiB +  49.0 KiB = 245.0 KiB	rpc.idmapd
240.0 KiB +  31.5 KiB = 271.5 KiB	crond
196.0 KiB + 127.5 KiB = 323.5 KiB	rpcbind
328.0 KiB +  33.5 KiB = 361.5 KiB	ntpd
352.0 KiB +  14.5 KiB = 366.5 KiB	iscsi-scstd
316.0 KiB +  85.0 KiB = 401.0 KiB	gssproxy
568.0 KiB +  69.5 KiB = 637.5 KiB	zed
532.0 KiB + 105.5 KiB = 637.5 KiB	smartd
412.0 KiB + 335.0 KiB = 747.0 KiB	avahi-daemon (2)
692.0 KiB +  91.0 KiB = 783.0 KiB	systemd-udevd
696.0 KiB +  87.5 KiB = 783.5 KiB	nscd
660.0 KiB + 192.5 KiB = 852.5 KiB	dbus-daemon
824.0 KiB +  52.5 KiB = 876.5 KiB	irqbalance
924.0 KiB + 106.0 KiB =   1.0 MiB	rpc.mountd
992.0 KiB + 106.5 KiB =   1.1 MiB	rpc.statd
  1.1 MiB +  86.5 KiB =   1.1 MiB	master
  1.1 MiB + 110.0 KiB =   1.2 MiB	qmgr
  1.2 MiB +  87.0 KiB =   1.3 MiB	stunnel
128.0 KiB +   1.3 MiB =   1.4 MiB	cleanupd
136.0 KiB +   1.3 MiB =   1.4 MiB	smbd-notifyd
  1.5 MiB +  46.5 KiB =   1.5 MiB	rsyslogd
  1.5 MiB + 111.0 KiB =   1.6 MiB	pickup
  1.9 MiB +  39.0 KiB =   2.0 MiB	systemd-logind
  2.1 MiB + 209.5 KiB =   2.3 MiB	ctdb_eventd
  2.3 MiB + 487.5 KiB =   2.8 MiB	su (4)
  2.3 MiB + 601.5 KiB =   2.8 MiB	ctdb_recovered
  2.6 MiB + 352.0 KiB =   3.0 MiB	sudo (2)
  2.8 MiB + 567.0 KiB =   3.4 MiB	multipathd
  2.4 MiB +   1.3 MiB =   3.7 MiB	nmbd
  3.6 MiB + 127.0 KiB =   3.7 MiB	systemd
  3.4 MiB + 316.0 KiB =   3.8 MiB	polkitd
  1.6 MiB +   3.1 MiB =   4.7 MiB	smbd
  4.4 MiB + 405.0 KiB =   4.8 MiB	tmux (2)
  6.1 MiB + 501.0 KiB =   6.6 MiB	tuned
  1.5 MiB +   6.7 MiB =   8.2 MiB	winbindd (4)
  8.4 MiB +  12.6 MiB =  21.0 MiB	systemd-journald
 22.4 MiB +  79.5 KiB =  22.5 MiB	gmond
 23.1 MiB +  78.5 KiB =  23.2 MiB	memcached
 24.4 MiB + 275.5 KiB =  24.7 MiB	python2.7
 30.1 MiB +   2.6 MiB =  32.7 MiB	bash (89)
 37.1 MiB +   1.7 MiB =  38.8 MiB	ctdbd
 12.2 MiB +  50.0 MiB =  62.2 MiB	ezs3-agent.py
 68.7 MiB + 306.0 KiB =  69.0 MiB	davserver
 69.9 MiB + 951.0 KiB =  70.8 MiB	csmonitord
 73.9 MiB + 314.0 KiB =  74.2 MiB	ezfs-recycle-fl
 72.7 MiB +   2.4 MiB =  75.2 MiB	radosgw
 74.3 MiB + 920.5 KiB =  75.2 MiB	ezsnapsched.py
 77.1 MiB + 921.5 KiB =  78.0 MiB	bt-pool-reweigh
 81.5 MiB + 964.5 KiB =  82.4 MiB	bt-recovery-qos
 84.7 MiB +   1.2 MiB =  85.9 MiB	eziscsi-rbd-cle
 85.4 MiB +   1.2 MiB =  86.6 MiB	eziscsid.py
 85.8 MiB + 975.0 KiB =  86.7 MiB	bt-ipmi-agent.p
 86.5 MiB +   1.0 MiB =  87.5 MiB	ezfs-agent
 87.1 MiB + 653.5 KiB =  87.7 MiB	atop (2)
 88.1 MiB + 918.0 KiB =  89.0 MiB	ezqosd
120.0 MiB + 468.0 KiB = 120.5 MiB	ceph-mgr
103.2 MiB +  19.4 MiB = 122.6 MiB	sshd (86)
136.2 MiB +   1.1 MiB = 137.3 MiB	ezs3-smart-moni
139.1 MiB +   1.6 MiB = 140.7 MiB	ezrpcd
 11.1 MiB + 156.6 MiB = 167.8 MiB	ezmonitord
202.0 MiB +  17.6 MiB = 219.6 MiB	ssh (213)
266.3 MiB +   8.5 MiB = 274.8 MiB	httpd (12)
501.0 MiB +  35.4 MiB = 536.3 MiB	ezs3-bucket-log (9)
544.1 MiB + 312.5 KiB = 544.4 MiB	ceph-mon
 75.7 GiB +  14.8 MiB =  75.7 GiB	ceph-osd (12)
---------------------------------
                         79.3 GiB
=================================
[root@node161 ~]#
</code></pre>
<p>说明：</p>
<p>最后一列输出中，括号里显示的，是对应进程名称的数量，确认一下：</p>
<pre><code class="language-shell">[root@node161 ~]# ps -ef |grep sshd | grep -v grep | wc -l
86
[root@node161 ~]# ps -ef |grep ceph-osd | grep -v grep | wc -l
12
[root@node161 ~]# ps -ef |grep bash | grep -v grep | wc -l
89
[root@node161 ~]# 
</code></pre>
<h2 id="shu-chu-zhong-da-yin-chu-command-line">输出中打印出command line</h2>
<pre><code class="language-shell">[root@node161 ~]# ps_mem -s
 Private  +   Shared  =  RAM used	Program 

  4.0 KiB +  12.0 KiB =  16.0 KiB	/usr/sbin/acpid
  4.0 KiB + 118.0 KiB = 122.0 KiB	avahi-daemon: chroot helper
 96.0 KiB +  27.0 KiB = 123.0 KiB	/usr/sbin/ipmievd sel daemon pidfile=/var/run/ipmievd.pid
112.0 KiB +  13.0 KiB = 125.0 KiB	/sbin/agetty --noclear tty1 linux
  4.0 KiB + 164.5 KiB = 168.5 KiB	/usr/sbin/lvmetad -f
184.0 KiB +  20.5 KiB = 204.5 KiB	rpc.rquotad
204.0 KiB +  33.0 KiB = 237.0 KiB	/usr/sbin/atd -f
。。。。。。 中间信息省略 。。。。。。
 86.6 MiB +   1.0 MiB =  87.6 MiB	/usr/bin/python2 /usr/local/bin/ezfs-agent start
 88.2 MiB + 937.0 KiB =  89.1 MiB	/usr/bin/python2 /usr/local/bin/ezqosd start
110.0 MiB + 330.0 KiB = 110.4 MiB	/usr/bin/atop -a -R -w /var/log/atop/atop_20210219 600
109.7 MiB +   1.1 MiB = 110.8 MiB	/usr/bin/python2 /usr/local/bin/ezs3-agent.py start
101.0 MiB +  12.7 MiB = 113.7 MiB	sshd: root@notty     (77)
121.8 MiB + 477.0 KiB = 122.2 MiB	/usr/bin/ceph-mgr -f --cluster ceph --id ojzrm --setuser root --setgroup root
136.3 MiB +   1.1 MiB = 137.4 MiB	/usr/bin/python2 /usr/local/bin/ezs3-smart-monitor.py start
139.1 MiB +   1.6 MiB = 140.7 MiB	/usr/bin/python2 /usr/local/bin/ezrpcd start
230.2 MiB +   2.6 MiB = 232.8 MiB	(wsgi:ezs3admin -DFOREGROUND
320.4 MiB +   1.9 MiB = 322.3 MiB	/usr/bin/python2 /usr/local/bin/ezmonitord start
500.9 MiB +  33.3 MiB = 534.2 MiB	/usr/bin/python2 /usr/local/bin/ezs3-bucket-logging-agent.py start (9)
562.3 MiB + 315.5 KiB = 562.6 MiB	/usr/bin/ceph-mon -f --cluster ceph --id ojzrm --setuser root --setgroup root
  4.4 GiB + 980.0 KiB =   4.4 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 2 --setuser root --setgroup root
  4.5 GiB +   1.1 MiB =   4.5 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 10 --setuser root --setgroup root
  4.5 GiB +   1.1 MiB =   4.5 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 4 --setuser root --setgroup root
  4.7 GiB +   1.0 MiB =   4.7 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 6 --setuser root --setgroup root
  4.9 GiB + 985.0 KiB =   4.9 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 8 --setuser root --setgroup root
  5.4 GiB + 988.0 KiB =   5.4 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 0 --setuser root --setgroup root
  5.7 GiB +   1.0 MiB =   5.7 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 11 --setuser root --setgroup root
  6.4 GiB +   1.3 MiB =   6.4 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 9 --setuser root --setgroup root
  7.5 GiB +   1.0 MiB =   7.5 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 7 --setuser root --setgroup root
  7.7 GiB +   1.1 MiB =   7.7 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 5 --setuser root --setgroup root
  8.7 GiB +   1.1 MiB =   8.7 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 1 --setuser root --setgroup root
  9.0 GiB +   1.1 MiB =   9.0 GiB	/usr/bin/ceph-osd -f --cluster ceph --id 3 --setuser root --setgroup root
---------------------------------
                         77.2 GiB
=================================
</code></pre>
<h2 id="zhi-xian-shi-te-ding-de-pid-lie-biao-de-nei-cun-shi-yong-qing-kuang">只显示特定的 PID 列表的内存使用情况</h2>
<pre><code class="language-shell">[root@node161 ~]# ps_mem -p 6646
 Private  +   Shared  =  RAM used	Program 

  6.4 GiB +   1.2 MiB =   6.4 GiB	ceph-osd
---------------------------------
                          6.4 GiB
=================================
[root@node161 ~]# 
</code></pre>
<h2 id="mei-n-miao-da-yin-jin-cheng-nei-cun">每 N 秒打印进程内存</h2>
<p>以下命令每5秒报告一次内存使用情况</p>
<pre><code class="language-shell">[root@node161 ~]# ps_mem -p 6646 -w 5
 Private  +   Shared  =  RAM used	Program 

  6.4 GiB +   1.2 MiB =   6.4 GiB	ceph-osd
---------------------------------
                          6.4 GiB
=================================
  6.4 GiB +   1.2 MiB =   6.4 GiB	ceph-osd
---------------------------------
                          6.4 GiB
=================================
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Cobbler自动部署OS与使用指南</title>
    <url>/2020/10/09/cobbler_based_automatic_install_os_and_usage_guide/</url>
    <content><![CDATA[<h1 id="ip-gui-hua">IP规划</h1>
<table>
<thead>
<tr>
<th>分类</th>
<th>IP</th>
<th>netmask</th>
<th>gateway</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>172.17.75.236</td>
<td>255.255.252.0</td>
<td>172.17.75.254</td>
<td>cobbler manager地址</td>
</tr>
<tr>
<td>cobbler</td>
<td>172.10.0.1</td>
<td>255.255.255.0</td>
<td>172.10.0.255</td>
<td>cobbler dhcp server地址(domain-name-servers)，<strong>对应ESXi PXE网络</strong></td>
</tr>
<tr>
<td></td>
<td>10.16.172.236</td>
<td>255.255.255.0</td>
<td></td>
<td>cobbler挂载外部ISO镜像地址，也可使用cobbler manager地址</td>
</tr>
<tr>
<td>DHCP</td>
<td>172.10.0.0</td>
<td></td>
<td></td>
<td>DHCP server的subnet</td>
</tr>
<tr>
<td></td>
<td></td>
<td>255.255.255.0</td>
<td></td>
<td>DHCP option routers</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>172.10.0.254</td>
<td>DHCP option subnet-mask</td>
</tr>
<tr>
<td></td>
<td>172.10.0.100~172.10.0.200</td>
<td></td>
<td></td>
<td>DHCP range dynamic-bootp</td>
</tr>
</tbody>
</table>
<p>说明：</p>
<p>​    cobbler必须要有PXE网络，同时推荐OS分区空间要&gt;= 300G,或额外增加一个分区用于ISO挂载使用。只所以占用空间，更多是因为cobbler repo sync后将镜像中文件复制一份出来，建议删除repo，并增加定时任务清理存在的repo，以期保证空间的充足。</p>
<h1 id="bu-shu-cobbler">部署cobbler</h1>
<h2 id="cha-kan-xi-tong-xin-xi">查看系统信息</h2>
<pre><code class="language-shell">[root@cobbler-236 ~]# cat /etc/redhat-release
CentOS Linux release 7.6.1810 (Core) 
[root@cobbler-236 ~]# uname -r
3.10.0-957.el7.x86_64
[root@cobbler-236 ~]# hostname -I
172.17.75.236 
[root@cobbler-236 ~]# 
</code></pre>
<h2 id="pei-zhi-ip">配置IP</h2>
<pre><code class="language-shell">[root@cobbler-236 network-scripts]# pwd
/etc/sysconfig/network-scripts
[root@cobbler-236 network-scripts]# ls ifcfg-ens*
ifcfg-ens160  ifcfg-ens192
[root@cobbler-236 network-scripts]# cat ifcfg-ens160 
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens160
UUID=fad33a53-af8c-48dd-9cb9-46565a8cac98
DEVICE=ens160
ONBOOT=yes
IPADDR0=172.17.75.236
PREFIX=24
DNS1=8.8.8.8
DNS2=114.114.114.114
GATEWAY0=172.17.75.254
[root@cobbler-236 network-scripts]# cat ifcfg-ens192 
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=none
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens192
DEVICE=ens192
ONBOOT=yes
IPADDR=172.10.0.1
PREFIX=24
[root@cobbler-236 network-scripts]# 
</code></pre>
<p>重启网络服务，并查看ip地址:</p>
<pre><code class="language-shell">[root@cobbler-236 network-scripts]# systemctl restart network.service
[root@cobbler-236 network-scripts]# ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:9e:8c:1e brd ff:ff:ff:ff:ff:ff
    inet 172.17.75.236/16 brd 172.17.255.255 scope global noprefixroute ens160
       valid_lft forever preferred_lft forever
    inet6 fe80::4d94:54dc:9eb2:2864/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever
3: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000
    link/ether 00:50:56:9e:07:2b brd ff:ff:ff:ff:ff:ff
    inet 172.10.0.1/24 brd 172.10.0.255 scope global noprefixroute ens192
       valid_lft forever preferred_lft forever
    inet6 fe80::ddb7:d654:f5be:b66a/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever
[root@cobbler-236 network-scripts]# 
</code></pre>
<h2 id="pei-zhi-ssh">配置 ssh</h2>
<p>默认 ssh_config 启用了 DNS 解析，导致每次远程 ssh 时都特别慢</p>
<pre><code class="language-shell">[root@cobbler-236 ~]# sed -i 's%#UseDNS yes%UseDNS no%' /etc/ssh/sshd_config
[root@cobbler-236 ~]# service sshd restart
</code></pre>
<h2 id="guan-bi-fang-huo-qiang-selinux-deng">关闭防火墙、selinux等</h2>
<h3 id="guan-bi-fang-huo-qiang">关闭防火墙</h3>
<pre><code class="language-shell">systemctl stop firewalld.service        # 停止firewall
systemctl disable firewalld.service     # 禁止firewall开机启动
</code></pre>
<h3 id="guan-bi-se-linux">关闭SELinux</h3>
<p>编辑/etc/selinux/config文件，将SELINUX的值设置为disabled，下次开机SELinux就不会启动了。接着再执行如下命令,注意 setenforce 后面有空格:</p>
<pre><code class="language-shell">setenforce 0
</code></pre>
<p>查看SELinux状态,执行getenforce命令, Disabled 表示已经关闭了。</p>
<h2 id="an-zhuang-wget">安装wget</h2>
<pre><code class="language-shell">yum -y install wget
</code></pre>
<h2 id="an-zhuang-epel-yuan">安装epel源</h2>
<p>cobbler由epel源提供，所以需要事先配置epel的yum源。</p>
<p><code>wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo </code></p>
<p>这里使用的是阿里的epel源，你也可以直接 <code>yum install epel-release </code></p>
<h2 id="xin-zeng-yi-ge-fen-qu-zeng-jia-iso-zi-dong-gua-zai">新增一个分区，增加ISO自动挂载</h2>
<p>手动创建一个空的目录/var/www/cobbler，此时新增一个300~500G大小的分区（假如分区是sdb，以此为示例），执行 <code>msfs -t xfs /dev/sdb</code>，并将该分区挂载到这个目录:</p>
<ol>
<li class="lvl-3">
<p><code>mkfs.xfs /dev/sdb </code></p>
</li>
<li class="lvl-3">
<p><code>mount /dev/sdb /var/www/cobbler/</code></p>
</li>
<li class="lvl-3">
<p><code>使用blkid获取uuid </code></p>
</li>
</ol>
<p>用于/etc/fstab文件的编辑,比如：</p>
<pre><code class="language-shell">[root@cobbler-236 ~]# blkid 
/dev/mapper/centos-root: UUID="f43b464c-78b9-4877-9c9b-72c5f01eb69d" TYPE="xfs" 
/dev/sda2: UUID="bwMXPE-QMkC-gbwC-vCxn-q7W0-HCss-RBsmtK" TYPE="LVM2_member" 
/dev/sdb: UUID="eaa27ae0-63bd-4d9e-a683-35d785269848" TYPE="xfs" 
/dev/sda1: UUID="5d3aa690-2d88-45c3-b647-1efe372980b6" TYPE="xfs" 
/dev/mapper/centos-swap: UUID="cfcd9e7b-2b02-45fc-a097-21c3f871ea92" TYPE="swap" 
/dev/mapper/centos-home: UUID="82402837-18a5-471f-87f9-d50eb73914df" TYPE="xfs" 
[root@cobbler-236 ~]# 
</code></pre>
<pre><code class="language-shell">10.16.172.101:/vol/share/Builds/buildwindow/ /mnt/buildwindow nfs rsize=8192,wsize=8192,timeo=14,intr
UUID=eaa27ae0-63bd-4d9e-a683-35d785269848  /var/www/cobbler        xfs     defaults        0 2
</code></pre>
<h2 id="an-zhuang-cobbler">安装cobbler</h2>
<pre><code class="language-shell">yum -y install cobbler cobbler-web pykickstart debmirror httpd dhcp tftp-server xinetd syslinux
</code></pre>
<h2 id="qi-dong-xiang-guan-fu-wu-bing-she-zhi-kai-ji-zi-qi">启动相关服务并设置开机自启</h2>
<pre><code class="language-shell">systemctl start httpd
systemctl enable httpd
systemctl start cobblerd
systemctl enable cobblerd
systemctl start rsyncd
systemctl enable rsyncd
# systemctl enable dhcpd
</code></pre>
<h2 id="jian-cha-cobbler-pei-zhi">检查cobbler配置</h2>
<p>通过cobbler自带的命令检查，而后逐一按提示解决。</p>
<pre><code class="language-shell">cobbler check
</code></pre>
<p>出现如下提示信息：</p>
<pre><code class="language-shell">[root@cobbler-236 ~]# cobbler check
The following are potential configuration items that you may want to fix:

1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work.  This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.
2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network.
3 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment:
    https://github.com/cobbler/cobbler/wiki/Selinux
4 : change 'disable' to 'no' in /etc/xinetd.d/tftp
5 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely.  Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements.
6 : comment out 'dists' on /etc/debmirror.conf for proper debian support
7 : comment out 'arches' on /etc/debmirror.conf for proper debian support
8 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: "openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'" to generate new one
9 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them

Restart cobblerd and then run 'cobbler sync' to apply changes.
[root@cobbler-236 ~]# 
</code></pre>
<p>如上各问题的解决方法如下所示：</p>
<p>1、修改/etc/cobbler/settings文件，将默认server的127.0.0.1替换为本机IP地址(cobbler地址)</p>
<p><code>sed -i 's#^server: 127.0.0.1#server: 172.10.0.1#' /etc/cobbler/settings </code></p>
<p>2、修改/etc/cobbler/settings文件，将默认next_server的127.0.0.1替换为本机IP地址</p>
<p><code>sed -i 's#^next_server: 127.0.0.1#next_server: 172.10.0.1#' /etc/cobbler/settings </code></p>
<p>3、将/etc/xinetd.d/tftp中disable改为no</p>
<p><code>disable = no </code></p>
<p>4、执行 <code>cobbler get-loaders </code> 命令即可</p>
<p>可能会出现timeout，没关系，多执行几次，直到成功为止（会出现TASK COMPLETE）。</p>
<p>5、注释/etc/debmirror.conf文件中的@dists=“sid”;一行</p>
<p><code>sed -i 's/@dists="sid";/#@dists="sid";/' /etc/debmirror.conf </code></p>
<p>6、注释/etc/debmirror.conf文件中的@arches=“i386”;一行</p>
<p><code>sed -i 's/@arches="i386";/#@arches="i386";/' /etc/debmirror.conf </code></p>
<p>7、 防止循环装系统，适用于服务器第一启动项是PXE启动。<br>
<code>sed -i 's/pxe_just_once: 0/pxe_just_once: 1/' /etc/cobbler/settings </code></p>
<p>8、设置新系统默认的root密码</p>
<p>执行  <code>openssl passwd -1 -salt $(openssl rand -hex 4) </code> 生成密码，并用其替换/etc/cobbler/settings文件中default_password_crypted参数的值；</p>
<pre><code class="language-shell">[root@cobbler-236 ~]# openssl passwd -1 -salt $(openssl rand -hex 4)
Password: 
$1$2a25cee5$NK/O/uGlcl3tue7mc/Iy5/
[root@cobbler-236 ~]# 
</code></pre>
<pre><code class="language-shell">vi /etc/cobbler/settings

default_password_crypted: "$1$2a25cee5$NK/O/uGlcl3tue7mc/Iy5/"
</code></pre>
<h2 id="an-zhuang-qi-ta-bao">安装其他包</h2>
<pre><code class="language-shell">yum -y install fence-agents
yum -y install perl-JSON-PP
</code></pre>
<h2 id="zhong-qi-cobblerd-bing-tong-bu-jian-cha">重启cobblerd并同步检查</h2>
<pre><code class="language-shell">systemctl restart cobblerd
cobbler sync
cobbler check
</code></pre>
<p>如果出现如下信息，表明check ok：</p>
<pre><code class="language-shell">[root@cobbler-236 ~]# cobbler check
No configuration problems found.  All systems go.
[root@cobbler-236 ~]# 
</code></pre>
<h2 id="tong-guo-cobbler-lai-guan-li-dhcp">通过cobbler来管理dhcp</h2>
<pre><code class="language-shell">[root@cobbler-236 ~]# sed -i 's#manage_dhcp: 0#manage_dhcp: 1#' /etc/cobbler/settings
</code></pre>
<h2 id="pei-zhi-dhcp-fu-wu">配置DHCP服务</h2>
<p><code>vi /etc/cobbler/dhcp.template </code></p>
<pre><code class="language-shell">subnet 172.10.0.0 netmask 255.255.255.0 {
     option routers             172.10.0.254;
     option domain-name-servers 172.10.0.1;
     option subnet-mask         255.255.255.0;
     range dynamic-bootp        172.10.0.100 172.10.0.200;
     default-lease-time         21600;
     max-lease-time             43200;
     next-server                $next_server;
     class "pxeclients" {
          match if substring (option vendor-class-identifier, 0, 9) = "PXEClient";
          if option pxe-system-type = 00:02 {
                  filename "ia64/elilo.efi";
          } else if option pxe-system-type = 00:06 {
                  filename "grub/grub-x86.efi";
          } else if option pxe-system-type = 00:07 {
                  filename "grub/grub-x86_64.efi";
          } else if option pxe-system-type = 00:09 {
                  filename "grub/grub-x86_64.efi";
          } else {
                  filename "pxelinux.0";
          }
     }

}
</code></pre>
<p>然后重启cobbler服务并同步配置</p>
<pre><code class="language-shell">systemctl restart cobblerd
cobbler sync
</code></pre>
<h1 id="bu-shu-nginx">部署Nginx</h1>
<h2 id="an-zhuang-nginx">安装Nginx</h2>
<p><code>yum -y install nginx</code></p>
<p>安装的版本为：</p>
<pre><code class="language-shell">[root@cobbler-236 ~]# nginx -v
nginx version: nginx/1.16.1
[root@cobbler-236 ~]# 
</code></pre>
<p>如果要卸载的话，执行 <code>yum -y remove nginx   </code></p>
<h2 id="she-zhi-kai-ji-qi-dong">设置开机启动</h2>
<p><code>systemctl enable nginx</code></p>
<p>其他指令参考如下：</p>
<pre><code class="language-shell">service nginx start      # 启动 nginx 服务
service nginx stop       # 停止 nginx 服务
service nginx restart    # 重启 nginx 服务
service nginx reload     # 重新加载配置，一般是在修改过 nginx 配置文件时使用。
</code></pre>
<h2 id="pei-zhi-nginx">配置Nginx</h2>
<p>由于Nginx默认使用80端口，而80端口又被cobbler web占用，需要修改Nginx的默认端口，以及Nginx的其他配置，下文结束修改/etc/nginx/nginx.conf。</p>
<h3 id="1-xiu-gai-nginx-qi-yong-zhang-hao">1. 修改Nginx启用账号</h3>
<p>默认是nginx这个账号启用nginx服务的，需要改成root</p>
<pre><code class="language-shell">user root;
</code></pre>
<h3 id="2-xiu-gai-mo-ren-duan-kou">2. 修改默认端口</h3>
<p>下面改成81：</p>
<pre><code class="language-shell">        listen       81 default_server;
        listen       [::]:81 default_server;
</code></pre>
<p>​</p>
<h3 id="3-zhi-ding-location">3. 指定location</h3>
<pre><code class="language-shell">        location / {
            root /var/www/html;
            autoindex on;
        }
</code></pre>
<p>同时，执行如下命令：</p>
<pre><code class="language-shell">cd /var/www
rm -rf html
ln -s /var/lib/tftpboot /var/www/html
</code></pre>
<p>/etc/nginx/nginx.conf内容参考如下：</p>
<img class="shadow" src="/img/in-post/cobbler/image-20200927163055922.png" width="1200">
<h3 id="4-autoinit-sh-pei-zhi-wen-jian-de-cun-fang">4. autoinit.sh配置文件的存放</h3>
<p>autiinit.sh脚本，作用于通过PXE网络安装OS最后时刻，修改apache2.conf，修改ssh_config，重置avahi扫描网络所需的配置信息（避免节点avahi config中配置的IP是PXE网络的IP，而非预期设定的public或storage或class网络），内容参考如下：</p>
<pre><code class="language-shell">#!/bin/sh
sed -i 's/KeepAlive On/KeepAlive Off/' /etc/apache2/apache2.conf;
sed -i.bak 's/^#\ \ \ StrictHostKeyChecking ask/\ \ \ \ StrictHostKeyChecking no/' /etc/ssh/ssh_config
python -c "from ezs3.utils import start_web_ui,start_freenode_service;start_web_ui();start_freenode_service()"
python -c "from ezs3.config import Ezs3CephConfig; Ezs3CephConfig()"
sed -i '/\/root\/autoinit.sh/d' /etc/rc.local
</code></pre>
<p>将autoinit.sh脚本，复制到 /var/lib/tftpboot/netconf/目录下：</p>
<pre><code class="language-shell">cp autoinit.sh /var/lib/tftpboot/netconf/
</code></pre>
<h1 id="shou-dong-an-zhuang-shi-jian">手动安装实践</h1>
<h2 id="an-zhuang-cent-os-7">安装CentOS7</h2>
<h3 id="1-dao-ru-jing-xiang">1. 导入镜像：</h3>
<p>以官方CentOS为示例，先在cobbler对应vm上挂载iso，然后ssh到后端执行：</p>
<p><code>mount /dev/cdrom  /mnt/ </code></p>
<p>在导入期间，可以在后端查看导入进程信息：</p>
<pre><code class="language-shell">[root@cobbler-236 ~]# ps -ef |grep rsync
root      4661     1  0 Sep13 ?        00:00:00 /usr/bin/rsync --daemon --no-detach
root     14477 12531 21 23:09 ?        00:00:02 rsync -a /mnt/ /var/www/cobbler/ks_mirror/centos-7-x86_64 --progress
root     14478 14477  0 23:09 ?        00:00:00 rsync -a /mnt/ /var/www/cobbler/ks_mirror/centos-7-x86_64 --progress
root     14479 14478 35 23:09 ?        00:00:04 rsync -a /mnt/ /var/www/cobbler/ks_mirror/centos-7-x86_64 --progress
root     14497 12822  0 23:10 pts/3    00:00:00 grep --color=auto rsync
[root@cobbler-236 ~]# 
</code></pre>
<p>如果rsync进程消失，表明import结束：</p>
<pre><code class="language-shell">[root@localhost network-scripts]# ps -ef | grep rsync
root      4854     1  0 Sep16 ?        00:00:00 /usr/bin/rsync --daemon --no-detach
root     11284  9927  0 11:12 pts/0    00:00:00 grep --color=auto rsync
[root@localhost network-scripts]# 
</code></pre>
<p>导入完成后生成的文件夹</p>
<pre><code class="language-shell">[root@cobbler-236 ks_mirror]# pwd
/var/www/cobbler/ks_mirror
[root@cobbler-236 ks_mirror]# ll
total 0
drwxrwxr-x  8 root root 254 Nov 26  2018 centos-7-x86_64
drwxr-xr-x. 2 root root  62 Sep 17 11:12 config
[root@cobbler-236 ks_mirror]# 
</code></pre>
<h3 id="2-bian-ji-kickstart-wen-jian">2. 编辑kickstart文件</h3>
<p>vi /var/lib/cobbler/kickstarts/CentOS-7-x86_64.cfg</p>
<pre><code class="language-shell"># Centos7
# This kickstart file should only be used with EL &gt; 5 and/or Fedora &gt; 7.
# For older versions please use the sample.ks kickstart file.
 
#platform=x86, AMD64, or Intel EM64T
# System authorization information
auth --useshadow --passalgo=sha512
# System bootloader configuration
bootloader --location=mbr
# Partition clearing information
clearpart --all --initlabel
# Use text mode install
text
# Firewall configuration
firewall --disable
# Run the Setup Agent on first boot
firstboot --disable
ignoredisk --only-use=sda
# System keyboard
keyboard us
# System language
lang en_US
# Use network installation
url --url=$tree
# If any cobbler repo definitions were referenced in the kickstart profile, include them here.
$yum_repo_stanza
# Network information
$SNIPPET('network_config')
# Reboot after installation
reboot
 
#Root password
rootpw --iscrypted $default_password_crypted
# SELinux configuration
selinux --disabled
# Do not configure the X Window System
skipx
# System timezone
timezone Asia/Shanghai
# Install OS instead of upgrade
install
# Clear the Master Boot Record
zerombr
# Allow anaconda to partition the system as needed
part /boot --fstype="xfs" --size=300 --ondisk=sda
part swap --fstype="swap" --size=2048 --ondisk=sda
part / --fstype="xfs" --grow --size=1 --ondisk=sda
 
%pre
 
$SNIPPET('log_ks_pre')
$SNIPPET('kickstart_start')
$SNIPPET('pre_install_network_config')
# Enable installation monitoring
$SNIPPET('pre_anamon')
%end
 
 
%packages
 
@^minimal
@core
kexec-tools
%end
 
 
%post
 
systemctl disable postfix.service
%end
</code></pre>
<h3 id="3-xiu-gai-kickstart-wen-jian-wei-zi-ding-yi-de-cent-os-7-x-86-64-cfg">3. 修改kickstart文件为自定义的CentOS-7-x86_64.cfg</h3>
<p>cobbler profile edit --name=CentOS-7-x86_64 --kickstart=/var/lib/cobbler/kickstarts/CentOS-7-x86_64.cfg</p>
<p>用cobbler profile report查看，Kickstart前后信息已经改变</p>
<pre><code class="language-shell">[root@cobbler-236 kickstarts]# cobbler profile report
Name                           : centos-7-x86_64
TFTP Boot Files                : {}
Comment                        : 
DHCP Tag                       : default
Distribution                   : centos-7-x86_64
Enable gPXE?                   : 0
Enable PXE Menu?               : 1
Fetchable Files                : {}
Kernel Options                 : {}
Kernel Options (Post Install)  : {}
Kickstart                      : /var/lib/cobbler/kickstarts/sample_end.ks
Kickstart Metadata             : {}
Management Classes             : []
Management Parameters          : &lt;&lt;inherit&gt;&gt;
Name Servers                   : []
Name Servers Search Path       : []
Owners                         : ['admin']
Parent Profile                 : 
Internal proxy                 : 
Red Hat Management Key         : &lt;&lt;inherit&gt;&gt;
Red Hat Management Server      : &lt;&lt;inherit&gt;&gt;
Repos                          : []
Server Override                : &lt;&lt;inherit&gt;&gt;
Template Files                 : {}
Virt Auto Boot                 : 1
Virt Bridge                    : xenbr0
Virt CPUs                      : 2
Virt Disk Driver Type          : raw
Virt File Size(GB)             : 5
Virt Path                      : 
Virt RAM (MB)                  : 4096
Virt Type                      : kvm

[root@cobbler-236 kickstarts]# cobbler profile edit --name=CentOS-7-x86_64 --kickstart=/var/lib/cobbler/kickstarts/CentOS-7-x86_64.cfg
[root@cobbler-236 kickstarts]# cobbler profile report
Name                           : CentOS-7-x86_64
TFTP Boot Files                : {}
Comment                        : 
DHCP Tag                       : default
Distribution                   : centos-7-x86_64
Enable gPXE?                   : 0
Enable PXE Menu?               : 1
Fetchable Files                : {}
Kernel Options                 : {}
Kernel Options (Post Install)  : {}
Kickstart                      : /var/lib/cobbler/kickstarts/CentOS-7-x86_64.cfg
Kickstart Metadata             : {}
Management Classes             : []
Management Parameters          : &lt;&lt;inherit&gt;&gt;
Name Servers                   : []
Name Servers Search Path       : []
Owners                         : ['admin']
Parent Profile                 : 
Internal proxy                 : 
Red Hat Management Key         : &lt;&lt;inherit&gt;&gt;
Red Hat Management Server      : &lt;&lt;inherit&gt;&gt;
Repos                          : []
Server Override                : &lt;&lt;inherit&gt;&gt;
Template Files                 : {}
Virt Auto Boot                 : 1
Virt Bridge                    : xenbr0
Virt CPUs                      : 2
Virt Disk Driver Type          : raw
Virt File Size(GB)             : 5
Virt Path                      : 
Virt RAM (MB)                  : 4096
Virt Type                      : kvm

[root@cobbler-236 kickstarts]# 
</code></pre>
<h3 id="4-zhong-qi-xinetd-fu-wu">4. 重启xinetd服务</h3>
<p>systemctl restart xinetd</p>
<h3 id="5-an-zhuang-xi-tong-xi-tong-hou-zi-dong-she-ding-ip-di-zhi">5. 安装系统系统后，自动设定IP地址</h3>
<pre><code class="language-shell">[root@cobbler-236 ~]# cobbler system add --name=CentOS-7-x86_64 --mac=00:50:56:9e:ee:2e  --profile=CentOS-7-X86_64  --ip-address=172.17.73.76 --subnet=255.255.252.0 --gateway=172.17.75.254 --interface=eth0 --static=1 --hostname=wyz_au01 --name-servers="114.114.114.114 8.8.8.8"
[root@cobbler-236 ~]# cobbler system list
   CentOS-7-x86_64
[root@cobbler-236 ~]# cobbler sync
task started: 2020-09-17_165512_sync

</code></pre>
<p>网络组bond：</p>
<p>4个网口：</p>
<pre><code class="language-shell">cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=eth0 --mac=00:50:56:9e:ee:2e --interface-type=bond_slave --interface-master=bond0
cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=eth1 --mac=00:50:56:9e:ee:2e --interface-type=bond_slave --interface-master=bond0
cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=bond0 --interface-type=bond --bonding-opts="mode=active-backup miimon=100" --ip-address=172.17.73.76 --subnet=255.255.252.0 --gateway=172.17.75.254 --static=1

cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=eth2 --mac=00:50:56:9e:cc:0c --interface-type=bond_slave --interface-master=bond1
cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=eth3 --mac=00:50:56:9e:cc:0c --interface-type=bond_slave --interface-master=bond1
cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=bond1 --interface-type=bond --bonding-opts="mode=active-backup miimon=100" --ip-address=10.1.1.76 --subnet=255.255.255.0 --static=1
</code></pre>
<p>2个网口：</p>
<pre><code class="language-shell">cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=eth0 --mac=00:50:56:9e:ee:2e --interface-type=bond_slave --interface-master=bond0
cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=eth1 --mac=00:50:56:9e:cc:0c --interface-type=bond_slave --interface-master=bond1
cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=bond0 --interface-type=bond --bonding-opts="mode=active-backup miimon=100" --ip-address=172.17.73.76 --subnet=255.255.252.0 --gateway=172.17.75.254 --static=1
cobbler system edit --name=CentOS-7-x86_64 --profile=CentOS-7-X86_64 --interface=bond1 --interface-type=bond --bonding-opts="mode=active-backup miimon=100" --ip-address=10.1.1.76 --subnet=255.255.255.0 --static=1
</code></pre>
<p>说明：</p>
<p>​    上面bond信息仅供参考，并未执行成功，即未正常形成bond关系。</p>
<p>安装参考：</p>
<p><a href="https://blog.csdn.net/admin_root1/article/details/84965608">https://blog.csdn.net/admin_root1/article/details/84965608</a></p>
<h2 id="ububtu-an-zhuang">Ububtu 安装</h2>
<p>这个以我们产品为示例。</p>
<h3 id="1-gua-zai-jing-xiang">1. 挂载镜像</h3>
<pre><code class="language-shell">cd /var/www/cobbler/ks_mirror
mkdir Scaler-8.0-latest
mount /mnt/buildwindow/xenial/virtualstor_scaler_8.0/builds/2020-09-25_00_33_00/VirtualStor\ Scaler-v8.0-413-xenial~202009250033~5f910ea.iso /var/www/cobbler/ks_mirror/Scaler-8.0-latest
</code></pre>
<h3 id="2-dao-ru-jing-xiang">2. 导入镜像</h3>
<pre><code class="language-shell">cobbler import --path=/var/www/cobbler/ks_mirror/Scaler-8.0-latest --name=Scaler-8.0-latest-x86_64  --arch=x86_64
</code></pre>
<h3 id="3-xin-zeng-system-config">3. 新增system config</h3>
<img class="shadow" src="/img/in-post/cobbler/image-20200925172717405.png" width="1200">
<img class="shadow" src="/img/in-post/cobbler/image-20200925172726750.png" width="1200">
<p>00:50:56:9e:4c:12 是被安装系统所在VM的PXE网络对应的mac地址</p>
<img class="shadow" src="/img/in-post/cobbler/image-20200925172807485.png" width="1200">
<img class="shadow" src="/img/in-post/cobbler/image-20200925172816714.png" width="1200">
<img class="shadow" src="/img/in-post/cobbler/image-20200925172829380.png" width="1200">
<p>其他页面未截图，表明使用默认设置。</p>
<p>然后重启vm，自动进入安装界面。</p>
<h1 id="zi-dong-hua-an-zhuang-jiao-ben-de-shi-yong">自动化安装脚本的使用</h1>
<h2 id="bi-yao-de-an-zhuang-bao">必要的安装包</h2>
<pre><code class="language-shell">yum -y install python3
yum -y install python3-pip
yum -y install vim
yum -y install nfs-utils
yum -y install net-tools
yum -y install tmux
pip3 install pyVmomi
</code></pre>
<h2 id="xiang-guan-jiao-ben-mo-ban-zhun-bei">相关脚本/模板准备</h2>
<p>对于Ubuntu Scaler，无需任何手工干预，其preseed文件目前是自动生成，存放于 <code>/var/lib/tftpboot/netconf </code>对应版本（安装脚本<strong>PXE_MAP</strong>处定义的版本信息）目录下，参考如下：</p>
<pre><code class="language-shell">[root@cobbler-236 netconf]# ls -l
total 8
drwxr-xr-x 2 root root 4096 Oct  3 18:15 8.0
drwxr-xr-x 3 root root   31 Sep 29 16:06 8.0_centos
-rwxr-xr-x 1 root root  405 Sep 27 10:59 autoinit.sh
[root@cobbler-236 netconf]# 
[root@cobbler-236 netconf]# ls -lR
.:
total 8
drwxr-xr-x 2 root root 4096 Oct  3 18:15 8.0
drwxr-xr-x 3 root root   31 Sep 29 16:06 8.0_centos
-rwxr-xr-x 1 root root  405 Sep 27 10:59 autoinit.sh

./8.0:
total 68
-rw-r--r-- 1 root root 557 Oct  2 22:09 interfaces_cobbler-80
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-11
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-12
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-13
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-14
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-15
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-16
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-17
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-18
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-19
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-20
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-21
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-22
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-23
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-24
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-25
-rw-r--r-- 1 root root 555 Oct  9 16:02 interfaces_pytest-80-26

./8.0_centos:
total 0
drwxr-xr-x 2 root root 84 Sep 29 16:06 cobbler-centos-80

./8.0_centos/cobbler-centos-80:
total 16
-rw-r--r-- 1 root root 206 Oct  9 16:37 ifcfg-bond0
-rw-r--r-- 1 root root 165 Oct  9 16:37 ifcfg-bond1
-rw-r--r-- 1 root root  79 Oct  9 16:37 ifcfg-ens160
-rw-r--r-- 1 root root  79 Oct  9 16:37 ifcfg-ens192
[root@cobbler-236 netconf]#
</code></pre>
<p>而对于CentOS Scaler来说，需要先将 <code>centos-ezs3-auto-8.0.ks </code> 这个模板，事先存放在<code>/var/lib/cobbler/templates </code>目录下，当前ks文件，仅支持8.0的CentOS下Scaler的安装，如果将来有其他版本的CentOS，可能需要额外调整安装脚本/新增ks文件。</p>
<h2 id="vm-pei-zhi-wen-jian-zhun-bei">VM配置文件准备</h2>
<p>参考示例如下（可以在“vms”中以{}形式，增加其他节点信息）：</p>
<pre><code class="language-shell">{
    "ostype":"ubuntu",
    "version":"8.0",
    "isopath":"latest",
    "vmyesno":"yes",
    "esxuser":"root",
    "esxpass":"p@ssw0rd",
    "disknum":2,
    "disksize":50,
    "osdisk":"yes",
    "osdisksize":60,
    "vms":[
        {
            "hostname":"cobbler-80",
            "esxhost":"172.17.75.184",
            "datastore":"rdqa02",
            "os_disk":"/dev/sda",
            "disknum":6,
            "disksize":30,
            "netconf":[
                {
                    "iface":"bond0",
                    "slave":[
                        "ens160"
                    ],
                    "bond_mode":"active-backup",
                    "address":"172.17.73.81",
                    "netmask":"255.255.252.0",
                    "gateway":"172.17.75.254",
                    "dns-nameservers":"114.114.114.114"
                },
                {
                    "iface":"bond1",
                    "slave":[
                        "ens192"
                    ],
                    "bond_mode":"active-backup",
                    "address":"1.1.1.81",
                    "netmask":"255.255.255.0"
                }
            ]
        }
    ]
}
</code></pre>
<p>对于配置文件中版本信息：</p>
<pre><code class="language-shell">    "8.0": {
        "buildpath":     "xenial/virtualstor_scaler_8.0/",
        "pxeint":        ["ens160", "ens192", "ens224"]
    },
    "8.0_centos": {
        "buildpath":     "centos7/virtualstor_scaler_8.0/",
        "pxeint":        ["ens160", "ens192", "ens224"]
    },
    "8.0_converger1": {
        "buildpath":     "buster/virtualstor_converger_one_1.0/",
        "pxeint":        ["ens160", "ens192", "ens224"]
    }
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>8.0 表示版本为8.0的Ubuntu类型的Scaler</p>
</li>
<li class="lvl-2">
<p>8.0_centos 表示版本为8.0的CentOS类型的Scaler</p>
</li>
<li class="lvl-2">
<p>8.0_converger1 表示版本为8.0的ConvergerOne</p>
</li>
</ul>
<p>上述值目前写死在code中，所以json格式的配置文件中<code>"version":</code>的取值要去适配自己要安装的什么产品类型的ISO。</p>
<h1 id="qi-ta">其他</h1>
<p>如何判断ks文件有效性</p>
<pre><code class="language-shell"># yum install pykickstart
</code></pre>
<p>After installing the package, you can validate a Kickstart file using the following command:</p>
<pre><code class="language-shell">$ ksvalidator /path/to/kickstart.ks
</code></pre>
<p>参考：</p>
<p><a href="https://docs.centos.org/en-US/centos/install-guide/Kickstart2/">https://docs.centos.org/en-US/centos/install-guide/Kickstart2/</a></p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>cobbler</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>cobbler</tag>
      </tags>
  </entry>
  <entry>
    <title>PVE集群给Ubuntu18.04直通GPU</title>
    <url>/2021/02/23/pass_through_gpu_to_ubuntu18_in_pve_cluster/</url>
    <content><![CDATA[<h1 id="pei-zhi-xiu-gai">配置修改</h1>
<h2 id="converger-one-ce-pei-zhi-xiu-gai">ConvergerOne侧配置修改</h2>
<h3 id="step-1-xiu-gai-etc-default-grub">Step1 修改/etc/default/grub</h3>
<p><code>vi /etc/default/grub</code></p>
<p>在 quiet后面，增加“<strong>intel_iommu=on video=efifb:off,vesafb:off</strong>”，完整内容如下所示：</p>
<pre><code class="language-shell">GRUB_CMDLINE_LINUX_DEFAULT="quiet intel_iommu=on video=efifb:off,vesafb:off 915.modeset=0 nomodeset net.ifnames=1 biosdevname=0"

GRUB_CMDLINE_LINUX="video=VGA-1:800x600"

GRUB_GFXMODE=800x600

GRUB_GFXPAYLOAD_LINUX=keep
</code></pre>
<p>说明：</p>
<ol>
<li class="lvl-3">
<p>iommu开启直通分组</p>
</li>
<li class="lvl-3">
<p>efifb:off 禁用efi启动的显示设备</p>
</li>
<li class="lvl-3">
<p>vesafb:off 禁用legacy启动的显示设备</p>
</li>
</ol>
<p>保存后，执行如下指令更新grub：</p>
<pre><code class="language-shell">update-grub
</code></pre>
<h3 id="step-2-jia-zai-mo-kuai">Step 2 加载模块</h3>
<p>编辑 /etc/modules，直接添加以下几个模块：</p>
<pre><code class="language-shell">vfio
vfio_iommu_type1
vfio_pci
vfio_virqfd
</code></pre>
<h3 id="step-3-zu-zhi-qu-dong-jia-zai">Step 3 阻止驱动加载</h3>
<p>因为ConvergetOne启动时会尝试加载显卡驱动，为了避免pve占用显卡，需要阻止pve的显卡驱动加载。</p>
<h4 id="3-1-tian-jia-qu-dong-hei-ming-dan">3.1 添加驱动黑名单</h4>
<p>编辑/etc/modprobe.d/pve-blacklist.conf</p>
<p><code>vi /etc/modprobe.d/pve-blacklist.conf</code></p>
<p>添加以下内容</p>
<pre><code class="language-shell"># block AMD driver

blacklist radeon
blacklist amdgpu

# block NVIDIA driver

blacklist nouveau
blacklist nvidia
blacklist nvidiafb

# block INTEL driver

blacklist snd_hda_intel
blacklist snd_hda_codec_hdmi
blacklist i915
</code></pre>
<p>编辑/etc/modprobe.d/blacklist.conf，执行如下指令，增加blacklist</p>
<pre><code class="language-shell">  echo "blacklist radeon" &gt;&gt; /etc/modprobe.d/blacklist.conf 
  echo "blacklist nouveau" &gt;&gt; /etc/modprobe.d/blacklist.conf 
  echo "blacklist nvidia" &gt;&gt; /etc/modprobe.d/blacklist.conf
</code></pre>
<h4 id="3-2-tian-jia-xian-qia-dao-zhi-tong-she-bei-zhong">3.2 添加显卡到直通设备中</h4>
<p>查看所有pci设备。</p>
<pre><code class="language-shell">lspci
</code></pre>
<p>由于我们已经知道了当前设备用的是什么型号的GPU卡，这里直接过滤：</p>
<pre><code class="language-shell">root@gpu01:~# lspci |grep -i Tesla
02:00.0 3D controller: NVIDIA Corporation GP102GL [Tesla P40] (rev a1)
root@gpu01:~# 
</code></pre>
<p>找到了前面的硬件id（上面显示的是<strong>02:00</strong>），获取核心显卡的硬件id：</p>
<pre><code class="language-shell">root@gpu01:~# lspci -n -s 02:00
02:00.0 0302: 10de:1b38 (rev a1)
root@gpu01:~# 
</code></pre>
<p>找到显卡后记下硬件id，形式是<code>xxxx:xxxx</code>，比如上面的Tesla P40的核心显卡的硬件id是**<code>10de:1b38</code>**。编辑<code>/etc/modprobe.d/vfio.conf</code></p>
<pre><code class="language-shell">vi /etc/modprobe.d/vfio.conf
</code></pre>
<p>添加以下内容注意！把<strong>10de:1b38</strong>换成你的显卡的硬件id：</p>
<pre><code class="language-shell">echo "options vfio-pci ids=10de:1b38 disable_vga=1" &gt; /etc/modprobe.d/vfio.conf
</code></pre>
<p>然后查看内容是否正确：</p>
<pre><code class="language-shell">root@gpu01:~# cat /etc/modprobe.d/vfio.conf
options vfio-pci ids=10de:1b38 disable_vga=1
root@gpu01:~# 
</code></pre>
<p>最后执行<code>update-initramfs -u</code> 生效配置。</p>
<h3 id="step-4-zhong-qi-ji-qi">Step 4 重启机器</h3>
<p>重启ConvergerOne宿主机。</p>
<h3 id="step-5-an-zhuang-xu-ji">Step 5 安装虚机</h3>
<p>等待ConvergerOne宿主机重启好，集群恢复健康后，创建Ubuntu18.04的vm，配置参考如下：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223153926661.png" width="1200"></p>
<p>此时是VM是没有直通GPU设备的。</p>
<h1 id="vm-ce-pei-zhi-xiu-gai">VM侧配置修改</h1>
<p>VM OS成功 安装后进行配置文件的修改操作（以下操作以root用户进行修改）。</p>
<h4 id="bian-ji-etc-modprobe-d-kvm-conf">编辑 /etc/modprobe.d/kvm.conf</h4>
<pre><code class="language-shell">echo "options kvm ignore_msrs=1 report_ignored_msrs=0" &gt; /etc/modprobe.d/kvm.conf
</code></pre>
<h1 id="an-zhuang-qu-dong-qian-zhun-bei-gong-zuo">安装驱动前准备工作</h1>
<h2 id="jin-yong-nouveau-qu-dong">禁用Nouveau驱动</h2>
<h3 id="bian-ji-hei-ming-dan">编辑黑名单</h3>
<pre><code class="language-shell">vi /etc/modprobe.d/blacklist-nouveau.conf
</code></pre>
<p>添加两行语句：</p>
<pre><code class="language-shell">blacklist nouveau
options nouveau modeset=0
</code></pre>
<h3 id="geng-xin-initramfs">更新initramfs</h3>
<pre><code class="language-shell">update-initramfs -u
</code></pre>
<p>输出信息参考如下：</p>
<pre><code class="language-shell">root@vmgpu:~# update-initramfs -u
update-initramfs: Generating /boot/initrd.img-4.15.0-55-generic
root@vmgpu:~# 
</code></pre>
<h3 id="zhong-qi-vm">重启 VM</h3>
<pre><code class="language-shell">reboot
</code></pre>
<h3 id="yan-zheng">验证</h3>
<p>终端执行如下指令：</p>
<pre><code class="language-shell">lsmod | grep nouveau
</code></pre>
<p>如果没有结果表示禁用成功。</p>
<h2 id="an-zhuang-gcc-amp-make">安装gcc&amp;make</h2>
<p>由于安装NVIDIA driver需要7.4版本的gcc和make指令，需进行gcc与make的安装。</p>
<pre><code class="language-shell">apt-get update
apt-get install gcc 7.4.0
apt-get install make
</code></pre>
<h2 id="vm-zeng-jia-gpu-pci-e-she-bei">VM增加GPU PCI-e设备</h2>
<p>将VM关机，并增加GPU设备：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223160023098.png" width="1200"></p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223160848107.png" width="1200"></p>
<p>完整的UI展示VM信息参考如下：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223180038078.png" width="1200"></p>
<p>注意：</p>
<p>1、不要勾选主GPU，否则VM启动报错：</p>
<pre><code class="language-shell">/dev/rbd0
kvm: failed to find file '/usr/share/qemu-server/bootsplash.jpg'
kvm: -device vfio-pci,host=0000:02:00.0,id=hostpci0,bus=pci.0,addr=0x10,rombar=0,x-vga=on: vfio 0000:02:00.0: failed getting region info for VGA region index 8: Invalid argument
device does not support requested feature x-vga
TASK ERROR: start failed: command '/usr/bin/kvm -id 100 -name vm100 -chardev 'socket,id=qmp,path=/var/run/qemu-server/100.qmp,server,nowait' -mon 'chardev=qmp,mode=control' -chardev 'socket,id=qmp-event,path=/var/run/qmeventd.sock,reconnect=5' -mon 'chardev=qmp-event,mode=control' -pidfile /var/run/qemu-server/100.pid -daemonize -smbios 'type=1,uuid=6739feef-a51c-4ec4-b24f-e80cb402a832' -smp '8,sockets=2,cores=4,maxcpus=8' -nodefaults -boot 'menu=on,strict=on,reboot-timeout=1000,splash=/usr/share/qemu-server/bootsplash.jpg' -vga none -nographic -cpu 'kvm64,+lahf_lm,+sep,+kvm_pv_unhalt,+kvm_pv_eoi,enforce,kvm=off' -m 4096 -device 'pci-bridge,id=pci.1,chassis_nr=1,bus=pci.0,addr=0x1e' -device 'pci-bridge,id=pci.2,chassis_nr=2,bus=pci.0,addr=0x1f' -device 'vmgenid,guid=9ee6f244-c03d-4e0f-852e-3790f8d09adf' -device 'piix3-usb-uhci,id=uhci,bus=pci.0,addr=0x1.0x2' -device 'usb-tablet,id=tablet,bus=uhci.0,port=1' -device 'vfio-pci,host=0000:02:00.0,id=hostpci0,bus=pci.0,addr=0x10,rombar=0,x-vga=on' -device 'virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x3' -iscsi 'initiator-name=iqn.1993-08.org.debian:01:2ffe281c6e13' -device 'virtio-scsi-pci,id=scsihw0,bus=pci.0,addr=0x5' -drive 'file=/dev/rbd/rbd/vm-100-disk-0,if=none,id=drive-scsi0,discard=on,format=raw,cache=none,aio=native,detect-zeroes=unmap' -device 'scsi-hd,bus=scsihw0.0,channel=0,scsi-id=0,lun=0,drive=drive-scsi0,id=scsi0,bootindex=100' -netdev 'type=tap,id=net0,ifname=tap100i0,script=/var/lib/qemu-server/pve-bridge,downscript=/var/lib/qemu-server/pve-bridgedown,vhost=on' -device 'virtio-net-pci,mac=B6:5F:BC:F0:3D:9F,netdev=net0,bus=pci.0,addr=0x12,id=net0,bootindex=300' -machine 'type=pc+pve1'' failed: exit code 1
</code></pre>
<p>2、 不要勾选PCIE-Express选择，否则VM启动报错：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161023563.png" width="1200"></p>
<h1 id="an-zhuang-qu-dong">安装驱动</h1>
<p>事先准备好NVIDIA的driver，本文以  <strong>NVIDIA-Linux-x86_64-460.32.03.run</strong> 示例。</p>
<pre><code class="language-shell">root@vmgpu:~# chmod a+x NVIDIA-Linux-x86_64-460.32.03.run 
root@vmgpu:~# ./NVIDIA-Linux-x86_64-460.32.03.run 
</code></pre>
<p>安装过程记录如下：</p>
<p>忽略gcc版本告警：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161702180.png" width="1200"></p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161729108.png" width="1200"></p>
<p>开始Build kernel modules：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161755290.png" width="1200"></p>
<p>出现了warning，直接一路回车就好：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161825771.png" width="1200"></p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161834580.png" width="1200"></p>
<p>install NVIDIA Accolerated Graphics Driver：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161846564.png" width="1200"></p>
<p>提示安装成功：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223161930679.png" width="1200"></p>
<p>重启VM，检查驱动是否被成功安装：</p>
<pre><code class="language-shell">root@vmgpu:~# lsmod | grep nvidia
nvidia_drm             49152  0
nvidia_modeset       1220608  1 nvidia_drm
nvidia              33988608  1 nvidia_modeset
drm_kms_helper        167936  1 nvidia_drm
drm                   401408  3 drm_kms_helper,nvidia_drm
root@vmgpu:~# 
</code></pre>
<pre><code class="language-shell">root@vmgpu:~# nvidia-smi 
Tue Feb 23 16:40:19 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P40           Off  | 00000000:00:10.0 Off |                    0 |
| N/A   28C    P0    50W / 250W |      0MiB / 22919MiB |      3%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre>
<p>如下图所示：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223162330661.png" width="1200"></p>
<p>出现如上信息，表明成功安装了驱动。</p>
<h1 id="qi-ta-xin-xi">其他信息</h1>
<h2 id="bu-zhi-yuan-biso-lei-xing-wei-ovmf-xia-gpu-de-zhi-tong">不支援BISO类型为OVMF下GPU的直通</h2>
<p>更改VM BIOS 类型为OVMF，支持q35，如下图所示：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223173032251.png" width="1200"></p>
<p>按照上面的部署步骤安装NVIDIA-Linux-x86_64-460.32.03.run：</p>
<p><img class="shadow" src="/img/in-post/pve/image-20210223173124492.png" width="1200"></p>
<p>对应log内容：</p>
<pre><code class="language-shell">   /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nvidia-drm-modeset.c: In function '__will_generate_flip_event':
   /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nvidia-drm-modeset.c:96:23: warning: unused variable 'primary_plane' [-Wunused-variable]
        struct drm_plane *primary_plane = crtc-&gt;primary;
                          ^~~~~~~~~~~~~
     CC [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nvidia-drm-helper.o
     CC [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nv-pci-table.o
     CC [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nvidia-drm-gem-nvkms-memory.o
     CC [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nvidia-drm-gem-user-memory.o
     CC [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nvidia-drm-gem-dma-buf.o
     CC [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm/nvidia-drm-format.o
   ld -r -o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-interface.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-frontend.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-pci.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-acpi.o /tmp/selfgz19048/NVIDIA-Linux-x86_
   64-460.32.03/kernel/nvidia/nv-cray.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-dma.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-i2c.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-mmap.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-p2p.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-pat.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-procfs.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-usermap.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-vm.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-vtophys.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/os-interface.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/os-mlock.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/os-pci.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/os-registry.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel
   /nvidia/os-usermap.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-modeset-interface.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-pci-table.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-kthread-q.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-memdbg.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-ibmnpu.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-report-err.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-rsync.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-msi.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv-caps.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nv_uvm_interface.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nvlink_linux.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/nvlink_caps.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia/linux_nvswitch.o /tmp/selfgz19048/NVIDI
   A-Linux-x86_64-460.32.03/kernel/nvidia/procfs_nvswitch.o
   ld -r -o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-modeset/nv-modeset-interface.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-modeset/nvidia-modeset-linux.o /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-modeset/nv-kthread-q.o
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia.o
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-uvm.o
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-modeset.o
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm.o
     Building modules, stage 2.
     MODPOST 4 modules
     CC      /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm.mod.o
     CC      /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-modeset.mod.o
     CC      /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-uvm.mod.o
     CC      /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia.mod.o
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-drm.ko
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia.ko
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-uvm.ko
     LD [M]  /tmp/selfgz19048/NVIDIA-Linux-x86_64-460.32.03/kernel/nvidia-modeset.ko
   make[1]: Leaving directory '/usr/src/linux-headers-4.15.0-55-generic'
-&gt; done.
-&gt; Kernel module compilation complete.
-&gt; Unable to determine if Secure Boot is enabled: No such file or directory
</code></pre>
<h2 id="gpu-qia-gong-dian-bu-zu-dao-zhi-cheng-gong-an-zhuang-qu-dong-hou-wu-fa-shi-yong-gpu-qia">GPU卡供电不足导致成功安装驱动后无法使用GPU卡</h2>
<p>对应VM kern.log片断信息如下：</p>
<pre><code class="language-shell">Feb 23 08:23:46 gpu01 kernel: [   12.954627] [drm] [nvidia-drm] [GPU ID 0x00000010] Loading driver
Feb 23 08:23:46 gpu01 kernel: [   12.954628] [drm] Initialized nvidia-drm 0.0.0 20160202 for 0000:00:10.0 on minor 1
Feb 23 08:23:46 gpu01 kernel: [   13.025196] EXT4-fs (sda2): mounted filesystem with ordered data mode. Opts: (null)
Feb 23 08:23:46 gpu01 kernel: [   13.111410] audit: type=1400 audit(1614068624.068:2): apparmor="STATUS" operation="profile_load" profile="unconfined" name="/usr/bin/lxc-start" pid=735 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.112890] audit: type=1400 audit(1614068624.072:3): apparmor="STATUS" operation="profile_load" profile="unconfined" name="/usr/bin/man" pid=736 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.112893] audit: type=1400 audit(1614068624.072:4): apparmor="STATUS" operation="profile_load" profile="unconfined" name="man_filter" pid=736 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.112895] audit: type=1400 audit(1614068624.072:5): apparmor="STATUS" operation="profile_load" profile="unconfined" name="man_groff" pid=736 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.113310] audit: type=1400 audit(1614068624.072:6): apparmor="STATUS" operation="profile_load" profile="unconfined" name="/usr/lib/snapd/snap-confine" pid=737 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.113312] audit: type=1400 audit(1614068624.072:7): apparmor="STATUS" operation="profile_load" profile="unconfined" name="/usr/lib/snapd/snap-confine//mount-namespace-capture-helper" pid=737 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.114956] audit: type=1400 audit(1614068624.072:8): apparmor="STATUS" operation="profile_load" profile="unconfined" name="/usr/sbin/tcpdump" pid=739 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.116269] audit: type=1400 audit(1614068624.080:9): apparmor="STATUS" operation="profile_load" profile="unconfined" name="lxc-container-default" pid=733 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.116272] audit: type=1400 audit(1614068624.080:10): apparmor="STATUS" operation="profile_load" profile="unconfined" name="lxc-container-default-cgns" pid=733 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   13.116277] audit: type=1400 audit(1614068624.080:11): apparmor="STATUS" operation="profile_load" profile="unconfined" name="lxc-container-default-with-mounting" pid=733 comm="apparmor_parser"
Feb 23 08:23:46 gpu01 kernel: [   15.853079] new mount options do not match the existing superblock, will be ignored
Feb 23 08:24:46 gpu01 kernel: [   77.010198] random: crng init done
Feb 23 08:24:46 gpu01 kernel: [   77.010218] random: 7 urandom warning(s) missed due to ratelimiting
Feb 23 08:25:00 gpu01 kernel: [   90.796257] NVRM: GPU 0000:00:10.0: GPU does not have the necessary power cables connected.
Feb 23 08:25:00 gpu01 kernel: [   90.825600] NVRM: GPU 0000:00:10.0: RmInitAdapter failed! (0x25:0x1c:1262)
Feb 23 08:25:00 gpu01 kernel: [   90.825801] NVRM: GPU 0000:00:10.0: rm_init_adapter failed, device minor number 0
Feb 23 08:25:00 gpu01 kernel: [   91.062551] NVRM: GPU 0000:00:10.0: GPU does not have the necessary power cables connected.
Feb 23 08:25:00 gpu01 kernel: [   91.092368] NVRM: GPU 0000:00:10.0: RmInitAdapter failed! (0x25:0x1c:1262)
Feb 23 08:25:00 gpu01 kernel: [   91.092560] NVRM: GPU 0000:00:10.0: rm_init_adapter failed, device minor number 0
Feb 23 08:25:15 gpu01 kernel: [  105.451286] NVRM: GPU 0000:00:10.0: GPU does not have the necessary power cables connected.
Feb 23 08:25:15 gpu01 kernel: [  105.451804] NVRM: GPU 0000:00:10.0: RmInitAdapter failed! (0x25:0x1c:1262)
Feb 23 08:25:15 gpu01 kernel: [  105.452011] NVRM: GPU 0000:00:10.0: rm_init_adapter failed, device minor number 0
Feb 23 08:25:15 gpu01 kernel: [  105.718690] NVRM: GPU 0000:00:10.0: GPU does not have the necessary power cables connected.
Feb 23 08:25:15 gpu01 kernel: [  105.719179] NVRM: GPU 0000:00:10.0: RmInitAdapter failed! (0x25:0x1c:1262)
Feb 23 08:25:15 gpu01 kernel: [  105.719362] NVRM: GPU 0000:00:10.0: rm_init_adapter failed, device minor number 0
</code></pre>
<p>解决方法：</p>
<p>拆机箱，将Tesla P40这块GPU的两根电源线都接上，之前是只接了一根电源线。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>PVE</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>PVE</tag>
        <tag>GPU</tag>
        <tag>Pass through</tag>
      </tags>
  </entry>
  <entry>
    <title>Demo for trasferring large file from break point</title>
    <url>/2021/01/10/demo_for_trasferring_large_file/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Daemon of python script tools to transfer larger of S3 Objects</p>
<h2 id="file-list">File list</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>bigtera_download_file.py</code> for downloading file from S3 from breakpoint</p>
</li>
<li class="lvl-2">
<p><code>bigtera_multipart_upload.py</code> for uploading file to S3 from breakpoint</p>
</li>
<li class="lvl-2">
<p><code>obsync.py</code> for RRS to S3 from breakpoint</p>
</li>
</ul>
<h2 id="usage">Usage</h2>
<h3 id="setup-environment">Setup environment</h3>
<ol>
<li class="lvl-3">
<p>Install Python2.7</p>
</li>
<li class="lvl-3">
<p>Install library</p>
</li>
</ol>
<p>Run the following command in command line</p>
<pre><code>pip install boto
pip install filechunkio
</code></pre>
<ol start="3">
<li class="lvl-3">
<p>Create S3 account and  bucket in cluster</p>
</li>
</ol>
<h3 id="configuration">Configuration</h3>
<p>Change configuration in the head part of <code>bigtera_download_file.py</code>  and <code>bigtera_multipart_upload.py</code></p>
<h3 id="test-downloading-file-from-breakpoint">Test downloading file from breakpoint</h3>
<ol>
<li class="lvl-3">
<p>Run <code>python bigtera_download_file.py</code> in command line</p>
</li>
<li class="lvl-3">
<p><code>CTRL+C</code> to stop downloading process</p>
</li>
<li class="lvl-3">
<p>Run <code>python bigtera_download_file.py</code> again</p>
</li>
<li class="lvl-3">
<p>Check downloading status</p>
</li>
</ol>
<h3 id="test-uploading-file-from-breakpoint">Test uploading file from breakpoint</h3>
<ol>
<li class="lvl-3">
<p>Run <code>python bigtera_multipart_upload.py</code> in command line</p>
</li>
<li class="lvl-3">
<p><code>CTRL+C</code> to stop uploading process</p>
</li>
<li class="lvl-3">
<p>Run <code>python bigtera_multipart_upload.py</code> again</p>
</li>
<li class="lvl-3">
<p>Check uploading status</p>
</li>
</ol>
<h3 id="content-of-scripts">Content of Scripts</h3>
<p><code>bigtera_download_file.py</code></p>
<pre><code class="language-python">#!/usr/bin/env python

from boto.s3.connection import S3Connection
from boto.s3.connection import OrdinaryCallingFormat
import os
from StringIO import StringIO
import configparser


HOST = '172.17.59.72'
S3_AK = 'JF06KCDJIAMO8Q3OJQAS'
S3_AS = 'gHnrKj1Vlb6s9IQZRrMDywhTLeNBL2UUMCGeetsf'
S3_BUCKET = 'andy_bucket'
S3_KEY = 'ubuntu-16.04-server-amd64.iso'
LOCAL_FILE = 'E:\\code\\s3_multipart_upload\\localfile.iso'

# Use a chunk size of 10 MiB (feel free to change this, &gt;=5MB)
CHUNK_SIZE = 1024 * 1024 * 10


def create_s3_connection():
    c = S3Connection(calling_format=OrdinaryCallingFormat(),
                     host=HOST, is_secure=False,
                     aws_access_key_id=S3_AK,
                     aws_secret_access_key=S3_AS,
                     validate_certs=False)
    return c


def get_obj_io_ctx(s3_key_obj=None, offset=None, length=None):
    if s3_key_obj is None:
        return None
    io_ctx = StringIO()
    headers = None
    if offset is not None and length is not None:
        headers = {
            "Range": "bytes={}-{}".format(offset, offset+length-1)
        }
    s3_key_obj.get_contents_to_file(io_ctx, headers)
    io_ctx.seek(0)
    return io_ctx


def main():
    c = create_s3_connection()
    b = c.get_bucket(S3_BUCKET)

    key = S3_KEY
    config_file = '.' + os.path.basename(LOCAL_FILE) + '.conf'

    s3_key_obj = b.get_key(key)
    if s3_key_obj is None:
        print(key + " does't exists!")
        exit(1)

    total_file_size = s3_key_obj.size
    remaining = total_file_size

    part_size = CHUNK_SIZE
    part_num = 0

    config = configparser.ConfigParser()
    config.read(config_file)

    stored_total_file_size = config.getint("bigtera_config", "total_file_size", fallback=0)
    stored_chunk_size = config.getint("bigtera_config", "chunk_size", fallback=0)
    stored_downloaded_size = config.getint("bigtera_config", "downloaded_size", fallback=0)

    seek_first = False
    if stored_total_file_size == total_file_size and stored_chunk_size == CHUNK_SIZE:
        remaining = stored_total_file_size - stored_downloaded_size
        part_num = stored_downloaded_size / stored_chunk_size
        open_option = "r+b"
        seek_first = True
    else:
        open_option = "wb"

    with open(LOCAL_FILE, open_option) as f:
        while remaining &gt; 0:
            offset = part_num * part_size
            length = min(remaining, part_size)
            s3_obj_io_ctx = get_obj_io_ctx(s3_key_obj, offset, length)
            if seek_first:
                f.seek(offset)
                seek_first = False
            f.write(s3_obj_io_ctx.read())
            remaining = remaining - length

            downloaded_size = offset + length
            percentage = int(downloaded_size * 100 / total_file_size)
            if percentage &gt; 100:
                percentage = 100
            print(str(downloaded_size) + '/' + str(total_file_size) + '  ' + str(percentage) + '%')

            part_num += 1
            with open(config_file, 'w') as configfile:
                config['bigtera_config'] = {}
                config['bigtera_config']['total_file_size'] = str(total_file_size)
                config['bigtera_config']['chunk_size'] = str(CHUNK_SIZE)
                config['bigtera_config']['downloaded_size'] = str(downloaded_size)

                config.write(configfile)

            if total_file_size == downloaded_size:
                os.remove(config_file)


if __name__ == '__main__':
    main()

</code></pre>
<p><code>bigtera_multipart_upload.py</code></p>
<pre><code class="language-python">#!/usr/bin/env python

from boto.s3.connection import S3Connection
from boto.s3.connection import OrdinaryCallingFormat
from boto.s3.multipart import MultiPartUpload
import math
import os
from filechunkio import FileChunkIO
import hashlib
# import time


HOST = '172.17.59.72'
S3_AK = 'JF06KCDJIAMO8Q3OJQAS'
S3_AS = 'gHnrKj1Vlb6s9IQZRrMDywhTLeNBL2UUMCGeetsf'
S3_BUCKET = 'andy_bucket'

LARGE_FILE = 'E:\\code\\s3_multipart_upload\\ubuntu-16.04-server-amd64.iso'

# Use a chunk size of 10 MiB (feel free to change this, &gt;=5MB)
CHUNK_SIZE = 1024 * 1024 * 10


def create_s3_connection():
    c = S3Connection(calling_format=OrdinaryCallingFormat(),
                     host=HOST, is_secure=False,
                     aws_access_key_id=S3_AK,
                     aws_secret_access_key=S3_AS,
                     validate_certs=False)
    return c


def query_pending_parts(b, key):
    response_all_multipart_upload = []

    # print('Current pending parts in S3:')
    multipart_uploads_filter = {'key_marker': key}
    all_multipart_uploads = b.get_all_multipart_uploads(**multipart_uploads_filter)
    for one_multipart_upload in all_multipart_uploads:
        response_multipart_upload = {'key': one_multipart_upload.key_name,
                                     'upload_id': one_multipart_upload.id,
                                     'parts': []
                                     }
        mp = MultiPartUpload(b)
        mp.key_name = one_multipart_upload.key_name
        mp.bucket_name = b.name
        mp.id = one_multipart_upload.id
        all_parts = mp.get_all_parts()
        one_multipart_upload_len = len(all_parts)
        print(' upload_id:' + one_multipart_upload.id + '   key:' + one_multipart_upload.key_name +
              '        parts:' + str(one_multipart_upload_len))
        # print('one_multipart_upload length:' + str(one_multipart_upload_len))
        for one_parts in all_parts:
            response_part = {
                'part_number': one_parts.part_number,
                'etag': one_parts.etag.replace('"', ''),
                'size': one_parts.size
            }
            response_multipart_upload['parts'].append(response_part)
        response_all_multipart_upload.append(response_multipart_upload)

    return response_all_multipart_upload


def upload_left(b, full_file_path, key, pending_multipart_upload, chunk_size):

    source_size = os.stat(full_file_path).st_size

    pending_upload_id = pending_multipart_upload['upload_id']
    # pending_key = pending_multipart_upload['key']

    mp = MultiPartUpload(b)
    mp.key_name = key
    mp.bucket_name = b.name
    mp.id = pending_upload_id

    # Use a chunk size of 10 MiB (feel free to change this)
    # chunk_size = 1024 * 1024 * 10
    # chunk_size = CHUNK_SIZE
    chunk_count = int(math.ceil(source_size / float(chunk_size)))

    # Send the file parts, using FileChunkIO to create a file-like object
    # that points to a certain byte range within the original file. We
    # set bytes to never exceed the original file size.
    for i in range(chunk_count):
        part_num = i + 1
        offset = chunk_size * i
        upload_bytes = min(chunk_size, source_size - offset)

        with FileChunkIO(full_file_path, 'r', offset=offset, bytes=upload_bytes) as fp:
            m = hashlib.md5()
            m.update(fp.readall())
            chunk_md5 = unicode(m.hexdigest())
            found_part = False
            for one_part in pending_multipart_upload['parts']:
                if part_num == one_part['part_number'] and \
                        upload_bytes == one_part['size'] and \
                        chunk_md5 == one_part['etag']:
                    # print(one_part)
                    found_part = True
                    break
            if found_part is True:
                # pass
                continue
            fp.seek(0)
            mp.upload_part_from_file(fp, part_num=part_num)
            print('%d/%d uploaded' % (part_num, chunk_count))

    try:
        # Finish the upload
        return mp.complete_upload()
    except Exception as e:
        mp.cancel_upload()
        raise e


def upload_large_file(b, full_file_path, key, chunk_size):
    # 100MB
    large_file_threshold = 100 * 1024 * 1024

    if chunk_size &lt; 5 * 1024 * 1024:
        chunk_size = 5 * 1024 * 1024

    all_pending_multipart_uploads = query_pending_parts(b, key)

    # Get file info
    source_size = os.stat(full_file_path).st_size

    pending_multipart_upload = None
    for one_pending_multipart_upload in all_pending_multipart_uploads:
        # In real product,we need check file-key-upload_id relation
        if key == one_pending_multipart_upload['key']:
            pending_multipart_upload = one_pending_multipart_upload
            break

    if source_size &gt;= large_file_threshold and pending_multipart_upload is not None:
        print('keep uploading!')
        return upload_left(b, full_file_path, key, pending_multipart_upload, chunk_size)
    else:
        print('No pending upload exits! Upload_from_beginning!')
        return upload_from_beginning(b, full_file_path, key, chunk_size)


def upload_from_beginning(b, full_file_path, key, chunk_size):

    source_size = os.stat(full_file_path).st_size

    # Create a multipart upload request
    mp = b.initiate_multipart_upload(key)
    # keep file-key-upload_id relation for production use
    print('Uploading file:' + full_file_path)
    print('Key in S3:' + key)
    print('upload_id:' + mp.id)
    print('--------------------')

    # Use a chunk size of 10 MiB (feel free to change this)
    # chunk_size = 1024 * 1024 * 10
    # chunk_size = CHUNK_SIZE
    chunk_count = int(math.ceil(source_size / float(chunk_size)))

    # Send the file parts, using FileChunkIO to create a file-like object
    # that points to a certain byte range within the original file. We
    # set bytes to never exceed the original file size.
    for i in range(chunk_count):
        part_num = i + 1
        offset = chunk_size * i
        upload_bytes = min(chunk_size, source_size - offset)
        with FileChunkIO(full_file_path, 'rb', offset=offset, bytes=upload_bytes) as fp:
            mp.upload_part_from_file(fp, part_num=part_num)

        print('%d/%d uploaded' % (part_num, chunk_count))
        # print('sleeping 1 second ...')
        # time.sleep(1)
    return mp.complete_upload()


def main():
    c = create_s3_connection()
    b = c.get_bucket(S3_BUCKET)

    full_file_path = LARGE_FILE
    key = os.path.basename(full_file_path)

    upload_large_file(b, full_file_path, key, CHUNK_SIZE)


if __name__ == '__main__':
    main()

</code></pre>
<p><code>obsync.py</code></p>
<pre><code class="language-python">"""
obsync.py: common library for ezobsync and s3backup
"""
from boto.exception import S3ResponseError
from boto.s3.connection import OrdinaryCallingFormat, SubdomainCallingFormat
from boto.s3.connection import S3Connection
from boto.s3.key import Key
from boto.s3.multipart import MultiPartUpload
from lxml import etree
from ezs3.log import EZLog
import boto
import errno
import hashlib
import os
from StringIO import StringIO
import tempfile
import time
import traceback
import xattr
import shutil

try:
    import cloudfiles
except ImportError:
    cloudfiles = None

logger = EZLog.get_logger(__name__)

ACL_XATTR = "rados.acl"
META_XATTR_PREFIX = "rados.meta."
BREAK_POINT_META = "break_point"
CONTENT_TYPE_XATTR = "rados.content_type"
# for FileStore xattr
SRC_MULTIPART_ETAG_XATTR = "rados.meta.srcetag"
MD5_XATTR = "rados.md5"
MTIME_XATTR = "rados.mtime"

# It is also in-memory chunk size; don't set it too large!
MULTIPART_THRESH = 10485760
# For S3 backup from breakpoint,100MB
BREAKPOINT_THRESHOLD = 100 * 1024 * 1024


class ObsyncException(Exception):
    def __init__(self, ty, e):
        if (isinstance(e, str)):
            # from a string
            self.tb = "".join(traceback.format_stack())
            self.comment = e
        else:
            # from another exception
            self.tb = traceback.format_exc(100000)
            self.comment = None
        self.ty = ty


class ObsyncTemporaryException(ObsyncException):
    """
    A temporary obsync exception.
    The user may want to retry the operation that failed.
    We can create one of these from a string or from another exception.
    """
    def __init__(self, e):
        ObsyncException.__init__(self, "temporary", e)


class ObsyncPermanentException(ObsyncException):
    """
    A permanent obsync exception.
    We can create one of these from a string or from another exception.
    """
    def __init__(self, e):
        ObsyncException.__init__(self, "permanent", e)


def test_xattr_support(path):
    test_file = path + "/$TEST"
    f = open(test_file, 'w')
    f.close
    try:
        xattr.set(test_file, "test", "123", namespace=xattr.NS_USER)
        if xattr.get(test_file, "test", namespace=xattr.NS_USER) != "123":
            raise ObsyncPermanentException(
                "test_xattr_support: failed to set an xattr and "
                "read it back.")
    except IOError:
        exc = "You do not appear to have xattr support at {}".format(path)
        logger.error(exc)
        raise ObsyncPermanentException(exc)
    finally:
        os.unlink(test_file)


def xattr_is_metadata(k):
    # miscellaneous user-defined metadata
    if (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
        return True
    # content-type
    elif (k == CONTENT_TYPE_XATTR):
        return True
    return False


def mkdir_p(path):
    try:
        os.makedirs(path)
    except OSError, exc:
        if exc.errno != errno.EEXIST:
            raise ObsyncTemporaryException(exc)
        if not os.path.isdir(path):
            raise ObsyncTemporaryException(exc)


def bytes_to_str(b):
    return ''.join(["%02x" % ord(x) for x in b]).strip()


def get_md5(f, block_size=2**20):
    mtime = os.stat(f.name).st_mtime
    try:
        stored_md5 = xattr.get(f.name, MD5_XATTR, namespace=xattr.NS_USER)
        stored_mtime = xattr.get(f.name, MTIME_XATTR, namespace=xattr.NS_USER)
        if str(mtime) == stored_mtime:
            return stored_md5
    except IOError as e:
        if e.errno != errno.ENODATA:
            raise

    md5 = hashlib.md5()
    while True:
        data = f.read(block_size)
        if not data:
            break
        md5.update(data)
    md5sum = md5.hexdigest()
    file_set_md5(f.name, md5sum, mtime)

    return md5sum


def file_set_md5(path, md5, mtime=None):
    if not mtime:
        mtime = str(os.stat(path).st_mtime)
    xattr.set(path, MD5_XATTR, md5, namespace=xattr.NS_USER)
    xattr.set(path, MTIME_XATTR, str(mtime), namespace=xattr.NS_USER)


def strip_prefix(prefix, s):
    if not (s[0:len(prefix)] == prefix):
        return None
    return s[len(prefix):]


def etag_to_md5(etag):
    if (etag[:1] == '"'):
        start = 1
    else:
        start = 0
    if (etag[-1:] == '"'):
        end = -1
    else:
        end = None
    return etag[start:end]


# Escaping functions.
#
# Valid names for local files are a little different than valid object
# names for S3. So these functions are needed to translate.
#
# Basically, in local names, every sequence starting with a dollar sign is
# reserved as a special escape sequence. If you want to create an S3 object
# with a dollar sign in the name, the local file should have a double dollar
# sign ($$).
#
# TODO: translate local files' control characters into escape sequences.
# Most S3 clients (boto included) cannot handle control characters in S3 object
# names.
# TODO: check for invalid utf-8 in local file names. Ideally, escape it, but
# if not, just reject the local file name. S3 object names must be valid
# utf-8.
#
# ----------        -----------
# In S3             Locally
# ----------        -----------
# foo/              foo$slash
#
# $money            $$money
#
# obj-with-acl      obj-with-acl
#                  .obj-with-acl$acl
def s3_name_to_local_name(s3_name):
    # Now we treat an object which names end with slash as a local folder
    return s3_name

def local_name_to_s3_name(local_name):
    # Now we treat a local folder as a prefix object
    return local_name

###### ACLs #######
READ = 1
WRITE = 2
READ_ACP = 4
WRITE_ACP = 8
FULL_CONTROL = READ | WRITE | READ_ACP | WRITE_ACP

PERM_MAP = {
    "FULL_CONTROL": FULL_CONTROL,
    "READ": READ,
    "WRITE": WRITE,
    "READ_ACP": READ_ACP,
    "WRITE_ACP": WRITE_ACP
}


def perm_to_str_list(perm):
    perms = []
    if perm == FULL_CONTROL:
        perms.append("FULL_CONTROL")
    elif (perm &amp; READ):
        perms.append("READ")
    elif (perm &amp; WRITE):
        perms.append("WRITE")
    elif (perm &amp; READ_ACP):
        perms.append("READ_ACP")
    elif (perm &amp; WRITE_ACP):
        perms.append("WRITE_ACP")
    return perms


ACL_TYPE_CANON_USER = "canon:"
ACL_TYPE_EMAIL_USER = "email:"
ACL_TYPE_GROUP = "group:"
ALL_ACL_TYPES = [ACL_TYPE_CANON_USER, ACL_TYPE_EMAIL_USER, ACL_TYPE_GROUP]

S3_GROUP_AUTH_USERS = ACL_TYPE_GROUP + "AuthenticatedUsers"
S3_GROUP_ALL_USERS = ACL_TYPE_GROUP + "AllUsers"
S3_GROUP_LOG_DELIVERY = ACL_TYPE_GROUP + "LogDelivery"

NS = "http://s3.amazonaws.com/doc/2006-03-01/"
NS2 = "http://www.w3.org/2001/XMLSchema-instance"


def get_user_type(utype):
    for ut in [ACL_TYPE_CANON_USER, ACL_TYPE_EMAIL_USER, ACL_TYPE_GROUP]:
        if utype[:len(ut)] == ut:
            return ut
    raise ObsyncPermanentException("unknown user type for user %s" % utype)


def strip_user_type(utype):
    for ut in [ACL_TYPE_CANON_USER, ACL_TYPE_EMAIL_USER, ACL_TYPE_GROUP]:
        if utype[:len(ut)] == ut:
            return utype[len(ut):]
    raise ObsyncPermanentException("unknown user type for user %s" % utype)


def grantee_attribute_to_user_type(utype):
    if (utype == "Canonical User"):
        return ACL_TYPE_CANON_USER
    elif (utype == "CanonicalUser"):
        return ACL_TYPE_CANON_USER
    elif (utype == "Group"):
        return ACL_TYPE_GROUP
    elif (utype == "Email User"):
        return ACL_TYPE_EMAIL_USER
    elif (utype == "EmailUser"):
        return ACL_TYPE_EMAIL_USER
    else:
        raise ObsyncPermanentException("unknown user type for user %s" % utype)


def user_type_to_attr(t):
    if (t == ACL_TYPE_CANON_USER):
        return "CanonicalUser"
    elif (t == ACL_TYPE_GROUP):
        return "Group"
    elif (t == ACL_TYPE_EMAIL_USER):
        return "EmailUser"
    else:
        raise ObsyncPermanentException("unknown user type %s" % t)


def add_user_type(user):
    """
    All users that are not specifically marked as something else
    are treated as canonical users
    """
    for atype in ALL_ACL_TYPES:
        if (user[:len(atype)] == atype):
            return user
    return ACL_TYPE_CANON_USER + user


class AclGrant(object):
    def __init__(self, user_id, display_name, permission):
        self.user_id = user_id
        self.display_name = display_name
        self.permission = permission

    def translate_users(self, xusers):
        # Keep in mind that xusers contains user_ids of the form "type:value"
        # So typical contents might be like { canon:XYZ =&gt; canon.123 }
        if self.user_id in xusers:
            self.user_id = xusers[self.user_id]
            # It's not clear what the new pretty-name should be, so just leave it blank.
            self.display_name = None

    def equals(self, rhs):
        if self.user_id != rhs.user_id:
            return False
        if self.permission != rhs.permission:
            return False
        # ignore display_name
        return True


class AclPolicy(object):
    def __init__(self, owner_id, owner_display_name, grants):
        self.owner_id = owner_id
        self.owner_display_name = owner_display_name
        self.grants = grants  # dict of { string -&gt; ACLGrant }

    @staticmethod
    def create_default(owner_id):
        grants = {}
        grants[ACL_TYPE_CANON_USER + owner_id] = \
            AclGrant(ACL_TYPE_CANON_USER + owner_id, None, FULL_CONTROL)
        return AclPolicy(owner_id, None, grants)

    @staticmethod
    def from_xml(s):
        root = etree.parse(StringIO(s))

        owner_id_node = root.find("{%s}Owner/{%s}ID" % (NS, NS))
        owner_id = owner_id_node.text
        owner_display_name = root.find("{%s}Owner/{%s}DisplayName" % (NS, NS))
        if owner_display_name is not None:
            owner_display_name = owner_display_name.text

        grantlist = root.findall("{%s}AccessControlList/{%s}Grant" % (NS, NS))
        grants = {}

        for g in grantlist:
            grantee = g.find("{%s}Grantee" % NS)
            if "type" in grantee.attrib:
                grantee_type = grantee.attrib["type"]
            else:
                grantee_type = grantee.attrib["{%s}type" % NS2]

            user_type = grantee_attribute_to_user_type(grantee_type)

            if user_type == ACL_TYPE_CANON_USER:
                user_id = grantee.find("{%s}ID" % NS).text
                display_name = grantee.find("{%s}DisplayName" % NS)
                if display_name is not None:
                    display_name = display_name.text
            elif user_type == ACL_TYPE_EMAIL_USER:
                user_id = grantee.find("{%s}EmailAddress" % NS).text
                display_name = None
            elif user_type == ACL_TYPE_GROUP:
                user_id = grantee.find("{%s}URI" % NS).text
                display_name = None
            else:
                raise ObsyncPermanentException("unknown ACL grantee type")

            permission = g.find("{%s}Permission" % NS).text
            perm = PERM_MAP[permission]
            grant_user_id = user_type + user_id
            if grant_user_id not in grants:
                grants[grant_user_id] = AclGrant(grant_user_id, display_name, perm)
            else:
                grants[grant_user_id].permission |= perm

        return AclPolicy(owner_id, owner_display_name, grants)

    def to_xml(self):
        root = etree.Element("AccessControlPolicy", nsmap={None: NS})
        owner = etree.SubElement(root, "Owner")
        id_elem = etree.SubElement(owner, "ID")
        id_elem.text = self.owner_id
        if self.owner_display_name:
            display_name_elem = etree.SubElement(owner, "DisplayName")
            display_name_elem.text = self.owner_display_name

        access_control_list = etree.SubElement(root, "AccessControlList")
        for k, g in self.grants.items():
            perms = perm_to_str_list(g.permission)
            for perm in perms:
                grant_elem = etree.SubElement(access_control_list, "Grant")
                grantee_elem = etree.SubElement(
                    grant_elem, "{%s}Grantee" % NS, nsmap={None: NS, "xsi": NS2})

                user_type = get_user_type(g.user_id)
                grantee_elem.set("{%s}type" % NS2, user_type_to_attr(user_type))

                if user_type == ACL_TYPE_CANON_USER:
                    user_id_elem = etree.SubElement(grantee_elem, "{%s}ID" % NS)
                    user_id_elem.text = strip_user_type(g.user_id)
                    if g.display_name:
                        display_name_elem = etree.SubElement(
                            grantee_elem, "{%s}DisplayName" % NS)
                        display_name_elem.text = g.display_name
                elif user_type == ACL_TYPE_EMAIL_USER:
                    email_elem = etree.SubElement(
                        grantee_elem, "{%s}EmailAddress" % NS)
                    email_elem.text = strip_user_type(g.user_id)
                elif user_type == ACL_TYPE_GROUP:
                    group_elem = etree.SubElement(grantee_elem, "{%s}URI" % NS)
                    group_elem.text = strip_user_type(g.user_id)
                else:
                    raise ObsyncPermanentException("unknown ACL grantee type")

                permission_elem = etree.SubElement(grant_elem, "{%s}Permission" % NS)
                permission_elem.text = perm
        return etree.tostring(root, encoding="UTF-8")

    def translate_users(self, xusers):
        # Owner ids are always expressed in terms of canonical user id
        user = ACL_TYPE_CANON_USER + self.owner_id
        if (user in xusers):
            self.owner_id = strip_user_type(xusers[user])
            self.owner_display_name = ""

        for k, g in self.grants.items():
            g.translate_users(xusers)

    def get_all_users(self):
        """ Get a list of all user ids referenced in this ACL """
        users = {}
        users[ACL_TYPE_CANON_USER + self.owner_id] = 1
        for k, g in self.grants.items():
            users[k] = 1
        return users.keys()

    def set_owner(self, owner_id):
        self.owner_id = owner_id
        self.owner_display_name = ""

    def equals(self, rhs):
        if (self.owner_id != rhs.owner_id):
            return False
        for k, g in self.grants.items():
            if k not in rhs.grants:
                return False
            if not g.equals(rhs.grants[k]):
                return False
        for l, r in rhs.grants.items():
            if l not in self.grants:
                return False
            if not r.equals(self.grants[l]):
                return False
        return True


class Object(object):

    def __init__(self, name, md5, size, meta):
        if isinstance(name, unicode):
            self.name = name
        else:
            self.name = name.decode('UTF-8')
        self.md5 = md5
        self.size = int(size)
        if SRC_MULTIPART_ETAG_XATTR in meta:
            self.md5 = meta[SRC_MULTIPART_ETAG_XATTR]
            del meta[SRC_MULTIPART_ETAG_XATTR]
        self.meta = meta
        self.is_folder = False
        if name.endswith("/"):
            self.is_folder = True

    def __str__(self):
        return u"(name: {}, size: {}: md5: {}, meta: {}, is_folder: {})".format(self.name, self.size, self.md5, self.meta, self.is_folder)

    def should_check_etags(self, rhs, check_etags):
        if check_etags == "never":
            return False
        if check_etags == "relaxed":
            logger.debug(
                "ETAGS: --check-etags={0}, self.md5 = {1}, rhs.md5 = {2}"
                .format(check_etags, self.md5, rhs.md5)
            )
            return not ('-' in self.md5 or '-' in rhs.md5)
        return True

    def equals(self, rhs, ignore_empty_s3_meta=False, cmp_etag="always"):
        if self.is_folder and rhs.is_folder:
            if (self.name != rhs.name):
                logger.debug("EQUALS: self.name = %s, rhs.name = %s" % (self.name, rhs.name))
                return False
            return True
        else:
            if (self.name != rhs.name):
                logger.debug("EQUALS: self.name = %s, rhs.name = %s" % (self.name, rhs.name))
                return False
            if (self.should_check_etags(rhs, cmp_etag) and self.md5 != rhs.md5):
                logger.debug("EQUALS: self.md5 = %s, rhs.md5 = %s" % (self.md5, rhs.md5))
                return False
            if (self.size != rhs.size):
                logger.debug("EQUALS: self.size = %d, rhs.size = %d" % (self.size, rhs.size))
                return False
            for k, v in self.meta.items():
                if k not in rhs.meta:
                    logger.debug("EQUALS: rhs.meta lacks key %s" % k)
                    return False
                if (rhs.meta[k] != v):
                    logger.debug(
                        "EQUALS: self.meta[%s] = %s, rhs.meta[%s] = %s" % (k, v, k, rhs.meta[k])
                    )
                    return False
            if self.meta or not ignore_empty_s3_meta:
                for k, v in rhs.meta.items():
                    if k not in self.meta:
                        logger.debug("EQUALS: self.meta lacks key %s" % k)
                        return False
            logger.debug("EQUALS: the objects are equal.")
            return True

    def local_name(self):
        local_name = s3_name_to_local_name(self.name)
        if not isinstance(local_name, unicode):
            local_name = local_name.decode('UTF-8')
        return local_name

    def local_path(self, base):
        if not isinstance(base, unicode):
            base = base.decode('UTF-8')
        if self.is_folder:
            full_path = os.path.join(base, self.name)
        else:
            full_path = os.path.join(base, self.local_name())
        return full_path.encode('UTF-8')

    @staticmethod
    def from_file(obj_name, path):
        f = open(path, 'r')
        try:
            md5 = get_md5(f)
        finally:
            f.close()
        size = os.path.getsize(path)
        meta = {}
        try:
            xlist = xattr.get_all(path, namespace=xattr.NS_USER)
        except IOError, e:
            if e.errno == 2:
                return meta
            else:
                raise ObsyncTemporaryException(e)
        for k, v in xlist:
            if xattr_is_metadata(k):
                meta[k] = v
        #print "Object.from_file: path="+path+",md5=" + bytes_to_str(md5) +",size=" + str(size)
        return Object(obj_name, md5, size, meta)

    @staticmethod
    def from_folder(obj_name, path):
        return Object(obj_name, 'd41d8cd98f00b204e9800998ecf8427e', 0, {})


class Store(object):
    @staticmethod
    def make_store(type, is_dst, create, akey, skey, dry_run, **kwargs):
        if (type == 's3'):
            try:
                store = S3Store(kwargs['host'], kwargs['bucket'],
                                kwargs['prefix'], create, akey, skey, dry_run,
                                is_secure=True)
                logger.info("Connect to S3 store via HTTPS successfully.")
            except Exception as e:
                store = S3Store(kwargs['host'], kwargs['bucket'],
                                kwargs['prefix'], create, akey, skey, dry_run,
                                is_secure=False)
                logger.info("Connect to S3 store via HTTP successfully.")
            return store
        elif (type == 'swift'):
            return SwiftStore(kwargs['host'], kwargs['bucket'],
                              kwargs['prefix'], create, akey, skey, dry_run,
                              False)
        elif (type == 'file'):
            return FileStore(kwargs['path'], create, dry_run,
                             kwargs.get('follow_symlinks', False))
        raise ObsyncPermanentException('Unknown store type: "%s"' % type)


class LocalCopy(object):

    def __init__(self, obj_name, path, path_is_temp):
        self.obj_name = obj_name
        self.path = path
        self.path_is_temp = path_is_temp

    def remove(self):
        if self.path_is_temp and (self.path is not None):
            os.unlink(self.path)
        self.path = None
        self.path_is_temp = False

    def __del__(self):
        self.remove()


class LocalAcl(object):

    @staticmethod
    def from_xml(obj_name, xml):
        acl_policy = AclPolicy.from_xml(xml)
        return LocalAcl(obj_name, acl_policy)

    @staticmethod
    def get_empty(obj_name):
        return LocalAcl(obj_name, None)

    def __init__(self, obj_name, acl_policy):
        self.obj_name = obj_name
        self.acl_policy = acl_policy

    def equals(self, rhs, ignore_empty_s3_acl=False):
        """ Compare two LocalAcls """
        if self.acl_policy is None:
            return (ignore_empty_s3_acl or rhs.acl_policy is None)
        if rhs.acl_policy is None:
            return (self.acl_policy is None)
        return self.acl_policy.equals(rhs.acl_policy)

    def translate_users(self, xusers):
        """ Translate the users in this ACL """
        if (self.acl_policy is None):
            return
        self.acl_policy.translate_users(xusers)

    def set_owner(self, owner_id):
        if (self.acl_policy is None):
            return
        self.acl_policy.set_owner(owner_id)

    def write_to_xattr(self, file_name):
        """ Write this ACL to an extended attribute """
        if (self.acl_policy is None):
            return
        xml = self.acl_policy.to_xml()
        xattr.set(file_name, ACL_XATTR, xml, namespace=xattr.NS_USER)


###### S3 store #######
def s3_key_to_meta(k):
    meta = {}
    if (k.__dict__.has_key("content_type")):
        meta[CONTENT_TYPE_XATTR] = k.content_type
    for k, v in k.metadata.items():
        meta[META_XATTR_PREFIX + k] = v
    return meta


def meta_to_s3_key(key, meta):
    for k, v in meta.items():
        if (k == CONTENT_TYPE_XATTR):
            key.set_metadata("Content-Type", v)
        elif (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
            k_name = k[len(META_XATTR_PREFIX):]
            key.set_metadata(k_name, v)
        else:
            raise ObsyncPermanentException("can't understand meta entry: %s" % k)


def meta_to_dict(meta):
    result = {}
    for k, v in meta.items():
        if (k == CONTENT_TYPE_XATTR):
            result["Content-Type"] = v
        elif (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
            k_name = k[len(META_XATTR_PREFIX):]
            result[k_name] = v
        else:
            raise ObsyncPermanentException("can't understand meta entry: %s" % k)
    return result


class S3StoreIterator(object):
    """S3Store iterator"""
    def __init__(self, bucket, blrs):
        self.bucket = bucket
        self.blrs = blrs

    def __iter__(self):
        return self

    def next(self):
        # This will raise StopIteration when there are no more objects to
        # iterate on
        key = self.blrs.next()
        # Issue a HEAD request to get content-type and other metadata
        k = self.bucket.get_key(key.name)
        ret = Object(key.name, etag_to_md5(key.etag), key.size, s3_key_to_meta(k))
        return ret


class S3Store(Store):
    def __init__(self, host, bucket_name, object_prefix, create, akey, skey,
                 dry_run, is_secure):
        self.host = host
        self.bucket_name = bucket_name
        self.key_prefix = object_prefix
        self.dry_run = dry_run

        self.conn = S3Connection(calling_format=OrdinaryCallingFormat(),
                                 host=self.host, is_secure=is_secure,
                                 aws_access_key_id=akey, aws_secret_access_key=skey)

        try:
            self.bucket = self.conn.get_bucket(self.bucket_name)
        except S3ResponseError as e:
            if e.status == 301: # Moved Permanently, try subdomain format
                self.conn = S3Connection(
                    calling_format=SubdomainCallingFormat(),
                    host=self.host, is_secure=is_secure,
                    aws_access_key_id=akey,
                    aws_secret_access_key=skey
                )
                try:
                    self.bucket = self.conn.get_bucket(self.bucket_name)
                except S3ResponseError as e:
                    if e.status == 404:
                        self.bucket = None
                    else:
                        raise e
            elif e.status == 404:
                self.bucket = None
            else:
                raise e

        if self.bucket is None: # Not Found
            if create:
                if not self.dry_run:
                    self.bucket = self.conn.create_bucket(self.bucket_name)
            else:
                raise ObsyncPermanentException(
                    "The bucket does not exist and we are not to create it."
                )

    def __str__(self):
        return "s3://" + self.host + "/" + self.bucket_name + "/" + self.key_prefix

    def get_acl(self, obj):
        acl_xml = self.bucket.get_xml_acl(obj.name)
        return LocalAcl.from_xml(obj.name, acl_xml)

    def make_local_copy(self, obj):
        k = Key(self.bucket)
        k.key = obj.name
        temp_file = tempfile.NamedTemporaryFile(prefix='/run/shm/', mode='w+b', delete=False).name
        try:
            k.get_contents_to_filename(temp_file)
        except Exception, e:
            os.unlink(temp_file)
            raise ObsyncTemporaryException(e)
        return LocalCopy(obj.name, temp_file, True)

    def all_objects(self):
        if self.bucket is None:
            return []
        blrs = self.bucket.list(prefix=self.key_prefix)
        return S3StoreIterator(self.bucket, blrs.__iter__())

    def get_object_size(self, obj):
        k = self.bucket.get_key(obj.name)
        if (k is None):
            return 0
        return k.size

    def locate_object(self, obj):
        if self.bucket is None:
            return None
        k = self.bucket.get_key(obj.name)
        if (k is None):
            logger.debug(u"S3Store: cannot locate obj: {}".format(obj.name))
            return None
        else:
            logger.debug(u"S3Store: located obj: {}".format(obj.name))
        return Object(obj.name, etag_to_md5(k.etag), k.size, s3_key_to_meta(k))

    def multipart_upload(self, store, acl, obj):
        pass

    def query_existing_multipart_uploads_in_s3(self, obj):
        multipart_uploads_filter = {'key_marker': obj.name}
        all_multipart_uploads = self.bucket.get_all_multipart_uploads(**multipart_uploads_filter)
        if len(all_multipart_uploads) &gt;= 1:
            logger.debug(u"S3Store: multipart_uploads exists '{}'".format(obj.name))
            existing_parts = []
            mpu = MultiPartUpload(self.bucket)
            mpu.key_name = obj.name
            mpu.bucket_name = self.bucket_name
            mpu.id = all_multipart_uploads[0].id

            all_parts = mpu.get_all_parts()
            for one_parts in all_parts:
                response_part = {
                    'part_number': one_parts.part_number,
                    'etag': one_parts.etag.replace('"', ''),
                    'size': one_parts.size
                }
                existing_parts.append(response_part)
            return {'mpu': mpu, 'parts': existing_parts}

        else:
            return None

    def get_obj_ioctx_md5(self, ioctx):
        if self.dry_run:
            return ''
        m = hashlib.md5()
        m.update(ioctx.read())
        md5 = m.hexdigest()
        ioctx.seek(0)

        return md5

    def upload(self, src, obj):
        if self.dry_run:
            return

        logger.debug(u"S3Store: upload obj '{}'".format(obj.name))

        if obj.size &lt;= MULTIPART_THRESH:
            k = Key(self.bucket)
            k.key = obj.name
            meta_to_s3_key(k, obj.meta)
            ioctx = src.get_obj_ioctx(obj)
            k.set_contents_from_file(ioctx)
        else:
            if obj.size &gt;= BREAKPOINT_THRESHOLD:
                existing_multipart_upload = self.query_existing_multipart_uploads_in_s3(obj)
            else:
                # For small files,just upload them again
                existing_multipart_upload = None

            if existing_multipart_upload is not None:
                logger.info(u"S3Store: uploading file from breakpoint: '{}'".format(obj.name))
                # There some parts in S3,keep uploading ...
                mpu = existing_multipart_upload['mpu']
                try:
                    remaining = obj.size
                    part_num = 0
                    part_size = MULTIPART_THRESH

                    while remaining &gt; 0:
                        current_part_num = part_num + 1
                        offset = part_num * part_size
                        length = min(remaining, part_size)
                        ioctx = src.get_obj_ioctx(obj, offset, length)

                        local_etag = unicode(self.get_obj_ioctx_md5(ioctx))
                        found_part = False
                        for one_part in existing_multipart_upload['parts']:
                            # we'd better check etag.
                            if current_part_num == one_part['part_number'] and \
                                    length == one_part['size'] and \
                                    local_etag == one_part['etag']:
                                found_part = True
                                break
                        if found_part is False:
                            logger.debug(u"S3Store: uploading part: '{}'".format(current_part_num))
                            mpu.upload_part_from_file(ioctx, current_part_num)
                        else:
                            logger.debug(u"S3Store: found part: '{}'".format(current_part_num))

                        remaining -= length
                        part_num += 1

                    logger.info(u"S3Store: Ready to complete_upload: '{}'".format(obj.name))
                    mpu.complete_upload()
                except Exception as e:
                    # Something is wrong.Maybe there are garbage data.Remove them.
                    logger.warning(u"S3Store: Something is wrong.cancel_upload: '{}'".format(obj.name))
                    mpu.cancel_upload()
                    raise e

            else:
                mpu = self.bucket.initiate_multipart_upload(obj.name, metadata=meta_to_dict(obj.meta))
                try:
                    remaining = obj.size
                    part_num = 0
                    part_size = MULTIPART_THRESH

                    while remaining &gt; 0:
                        offset = part_num * part_size
                        length = min(remaining, part_size)
                        ioctx = src.get_obj_ioctx(obj, offset, length)
                        mpu.upload_part_from_file(ioctx, part_num + 1)
                        remaining -= length
                        part_num += 1

                    mpu.complete_upload()
                except Exception as e:
                    # Do NOT cancel for large file.We will use previous parts in future.
                    if obj.size &lt; BREAKPOINT_THRESHOLD:
                        mpu.cancel_upload()
                    raise e

    def set_acl(self, src_acl, obj):
        if src_acl.acl_policy is not None:
            xml = src_acl.acl_policy.to_xml()
            try:
                def fn():
                    self.bucket.set_xml_acl(xml, obj.name)
                do_with_s3_retries(fn)
            except boto.exception.S3ResponseError, e:
                logger.error(
                    "ERROR SETTING ACL on object '{}'\n"
                    "************* ACL: *************\n"
                    "{}\n"
                    "********************************\n"
                    .format(obj.name, str(xml))
                )
                raise ObsyncTemporaryException(e)

    def remove(self, obj):
        if self.dry_run:
            return
        self.bucket.delete_key(obj.name)
        logger.debug("S3Store: removed %s", obj.name)

    def clear(self):
        pass

    def get_obj_ioctx(self, obj, offset=None, length=None):
        k = self.bucket.get_key(obj.name)
        if k is None:
            return None
        ioctx = StringIO()
        headers = None
        if offset is not None and length is not None:
            headers = {
                "Range": "bytes={}-{}".format(offset, offset+length-1)
            }
        k.get_contents_to_file(ioctx, headers)
        ioctx.seek(0)
        return ioctx


# Some S3 servers offer "eventual consistency."
# What this means is that after a change has been made, like the creation of an
# object, it takes some time for this change to become visible to everyone.
# This potentially includes the client making the change.
#
# This means we need to implement a retry mechanism for certain operations.
# For example, setting the ACL on a newly created object may fail with an
# "object not found" error if the object creation hasn't yet become visible to
# us.
def do_with_s3_retries(fn):
    if (os.environ.has_key("DST_CONSISTENCY") and
            os.environ["DST_CONSISTENCY"] == "eventual"):
        sleep_times = [5, 10, 60, -1]
    else:
        sleep_times = [-1]
    for stime in sleep_times:
        try:
            fn()
            return
        except boto.exception.S3ResponseError, e:
            if (stime == -1):
                raise ObsyncTemporaryException(e)
            logger.warning(
                "encountered s3 response error: %s: " \
                    "retrying operation after %d second delay",
                str(e), str(stime)
            )
            time.sleep(stime)


###### Swift store #######
def swift_object_to_meta(obj):
    meta = {}
    if (obj.__dict__.has_key("content_type")):
        meta[CONTENT_TYPE_XATTR] = obj.content_type
    for k, v in obj.metadata.items():
        meta[META_XATTR_PREFIX + k] = v
    return meta


def meta_to_swift_object(obj, meta):
    for k, v in meta.items():
        if (k == CONTENT_TYPE_XATTR):
            obj.metadata["Content-Type"] = v
        elif (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
            k_name = k[len(META_XATTR_PREFIX):]
            obj.metadata[k_name] = v
        else:
            raise ObsyncPermanentException("can't understand meta entry: %s" % k)
        obj.sync_metadata()


class SwiftStoreIterator(object):
    """SwiftStore iterator"""
    def __init__(self, container, object_list):
        self.container = container
        self.generator = (o for o in object_list)

    def __iter__(self):
        return self

    def next(self):
        # This will raise StopIteration when there are no more objects to
        # iterate on
        obj = self.generator.next()
        obj = self.container.get_object(obj.name)
        ret = Object(obj.name, etag_to_md5(obj._etag), obj.size, swift_object_to_meta(obj))
        return ret


class SwiftStore(Store):
    def __init__(self, authurl, container_name, object_prefix, create, akey,
                 skey, dry_run, is_secure):
        self.host = authurl
        self.container_name = container_name
        self.object_prefix = object_prefix
        self.dry_run = dry_run

        self.conn = cloudfiles.get_connection(
            username=akey, api_key=skey, authurl=self.host
        )
        try:
            self.container = self.conn.get_container(self.container_name)
        except cloudfiles.errors.NoSuchContainer:
            self.container = None

        if self.container is None:
            if create:
                if not self.dry_run:
                    self.container = self.conn.create_container(
                        self.container_name
                    )
            else:
                raise ObsyncPermanentException(
                    "%s: no such container as %s" % (self.host, self.container_name)
                )

    def __str__(self):
        return "swift://{}/{}/{}".format(
            self.host, self.container_name, self.object_prefix
        )

    def get_acl(self, obj):
        raise NotImplementedError   # We always use --no-preserve-acls right now

    def make_local_copy(self, obj):
        o = self.container.get_object(obj.name)
        temp_file = tempfile.NamedTemporaryFile(mode='w+b', delete=False).name
        try:
            o.save_to_filename(temp_file)
        except Exception, e:
            os.unlink(temp_file)
            raise ObsyncTemporaryException(e)
        return LocalCopy(obj.name, temp_file, True)

    def all_objects(self):
        if self.container is None:
            return []
        object_list = self.container.get_objects(prefix=self.object_prefix)
        return SwiftStoreIterator(self.container, object_list)

    def locate_object(self, obj):
        if self.container is None:
            return None
        try:
            o = self.container.get_object(obj.name)
        except cloudfiles.errors.NoSuchObject:
            return None
        return Object(obj.name, etag_to_md5(o._etag), o.size, swift_object_to_meta(o))

    def upload(self, src, obj):
        if self.dry_run:
            return

        logger.debug(u"SwiftStore: upload obj '{}'".format(obj.name))

        o = self.container.create_object(obj.name)

        if obj.size &lt;= MULTIPART_THRESH:
            ioctx = src.get_obj_ioctx(obj)
            o.write(ioctx)
            meta_to_swift_object(o, obj.meta)
        else:
            raise NotImplementedError("obj size too large. not supported")

    def set_acl(self, src_acl, obj):
        if src_acl.acl_policy is not None:
            #FIXME: no acls for swift yet
            pass

    def remove(self, obj):
        if self.dry_run:
            return
        self.container.delete_object(obj.name)
        logger.debug("SwiftStore: removed %s", obj.name)

    def clear(self):
        pass

    def get_obj_ioctx(self, obj, offset=None, length=None):
        try:
            o = self.container.get_object(obj.name)
            ioctx = StringIO()
            if offset is None or length is None:
                o.read(buffer=ioctx)
            else:
                o.read(offset=offset, size=length, buffer=ioctx)
            ioctx.seek(0)
            return ioctx
        except cloudfiles.errors.NoSuchObject:
            return None


###### FileStore #######
class FileStoreIterator(object):
    """FileStore iterator"""
    def __init__(self, base, follow_symlinks=False):
        self.base = base
        self.generator = os.walk(base, followlinks=follow_symlinks)
        self.path = ""
        self.files = []

    def __iter__(self):
        return self

    def next(self):
        while True:
            if (len(self.files) == 0):
                self.path, dirs, self.files = self.generator.next()
                self.files.extend(dirs)
                continue
            path = os.path.join(self.path, self.files[0])
            self.files = self.files[1:]
            # Ignore non-files when iterating.
            if os.path.isfile(path):
                obj_name = local_name_to_s3_name(path[len(self.base)+1:])
                return Object.from_file(obj_name, path)
            elif os.path.isdir(path):
                return Object.from_folder(path[len(self.base)+1:] + "/", path)


class FileStore(Store):
    def __init__(self, url, create, dry_run, follow_symlinks=False):
        # Parse the file url
        self.base = url
        self.dry_run = dry_run
        self.follow_symlinks = follow_symlinks
        if (self.base[-1:] == '/'):
            self.base = self.base[:-1]
        if create:
            if not self.dry_run:
                mkdir_p(self.base)
        elif not os.path.isdir(self.base):
            raise ObsyncPermanentException("NonexistentStore")

        if os.path.isdir(self.base):
            test_xattr_support(self.base)

    def __str__(self):
        return "file://" + self.base

    def get_acl(self, obj):
        try:
            xml = xattr.get(obj.local_path(self.base), ACL_XATTR,
                            namespace=xattr.NS_USER)
        except IOError, e:
            #print "failed to get XML ACL from %s" % obj.local_name()
            if e.errno == 61:
                return LocalAcl.get_empty(obj.name)
            raise ObsyncPermanentException(e)
        return LocalAcl.from_xml(obj.name, xml)

    def make_local_copy(self, obj):
        return LocalCopy(obj.name, obj.local_path(self.base), False)

    def all_objects(self):
        if os.path.isdir(self.base):
            return FileStoreIterator(self.base, self.follow_symlinks)
        else:
            return []

    def locate_object(self, obj):
        path = obj.local_path(self.base)
        if obj.is_folder:
            found = os.path.isdir(path)
            if found:
                return Object.from_folder(obj.name, path)
            else:
                return None
        else:
            found = os.path.isfile(path)
            logger.debug("FileStore::locate_object: %s object '%s'",
                         "found" if found else "did not find", obj.name)
            if (not found):
                return None
            return Object.from_file(obj.name, path)

    def upload(self, src, obj):
        if self.dry_run:
            return

        logger.debug(u"FileStore: upload obj '{}'".format(obj.name))

        lname = obj.local_name()
        d = os.path.join(self.base, lname).encode("UTF-8")
        mkdir_p(os.path.dirname(d))

        if obj.is_folder:
            d = os.path.join(self.base, obj.name).encode("UTF-8")
            mkdir_p(d)
        else:
            if obj.size &lt;= MULTIPART_THRESH:
                ioctx = src.get_obj_ioctx(obj)
                with open(d, "wb") as f:
                    f.write(ioctx.read())
            else:
                try:
                    break_point = 0
                    offset = 0
                    if os.path.isfile(d):
                        try:
                            value = xattr.get(d, BREAK_POINT_META, namespace=xattr.NS_USER)
                            break_point = int(value)
                            logger.info('break point for {} is {}'.format(d, break_point))
                        except Exception as e:
                            logger.error(u"failed to get break_point xatr for {} {}".format(d,str(3)))
                            pass

                    if break_point % MULTIPART_THRESH != 0 or break_point &gt; obj.size:
                        logger.info('break point for {} is {}'.format(d, break_point))
                        break_point = 0;

                    remaining = obj.size - break_point
                    part_num = break_point / MULTIPART_THRESH
                    part_size = MULTIPART_THRESH

                    seek_first = False
                    if break_point != 0:
                        seek_first = True
                        open_option = "r+b"
                    else:
                        open_option = "wb"

                    with open(d, open_option) as f:
                        while remaining &gt; 0:
                            offset = part_num * part_size
                            length = min(remaining, part_size)
                            ioctx = src.get_obj_ioctx(obj, offset, length)
                            if seek_first:
                                f.seek(offset)
                                seek_first = False
                            f.write(ioctx.read())
                            remaining -= length
                            part_num += 1

                    if break_point != 0:
                        f = open(d, 'r')
                        try:
                            md5 = get_md5(f)
                        finally:
                            f.close()
                        if md5 != obj.md5:
                            logger.info("file md5 {} is not equal to {}".format(md5, obj.md5))
                            remaining = break_point
                            part_num = 0
                            part_size = MULTIPART_THRESH

                            with open(d, open_option) as f:
                                while remaining &gt; 0:
                                    offset = part_num * part_size
                                    length = min(remaining, part_size)
                                    ioctx = src.get_obj_ioctx(obj, offset, length)
                                    f.write(ioctx.read())
                                    remaining -= length
                                    part_num += 1
                    try:
                        xattr.remove(d, BREAK_POINT_META, namespace=xattr.NS_USER)
                    except Exception as e:
                        pass

                except Exception as e:
                    if break_point == 0 and offset &gt;= 10* MULTIPART_THRESH:
                        xattr.set(d, BREAK_POINT_META, str(int(offset)),namespace=xattr.NS_USER)
                        logger.error('failed to upload ,set break point to {}'.format(offset))
                    raise e

        # Store metadata in extended attributes
        file_set_md5(d, obj.md5)
        for k, v in obj.meta.items():
            xattr.set(d, k, v, namespace=xattr.NS_USER)

    def set_acl(self, src_acl, obj):
        if not obj.is_folder:
            lname = obj.local_name()
            d = os.path.join(self.base, lname).encode("UTF-8")
            mkdir_p(os.path.dirname(d))
            src_acl.write_to_xattr(d)

    def remove(self, obj):
        if self.dry_run:
            return
        path = os.path.join(self.base, obj.name.encode("UTF-8"))
        try:
            if os.path.isfile(path):
                os.unlink(path)
            if os.path.isdir(path):
                shutil.rmtree(path)
        except Exception:
            logger.warning("FileStore: remove %s failed", obj.name)

        logger.debug("FileStore: removed %s", obj.name)

    def clear(self):
        for entry in os.listdir(self.base):
            path = os.path.join(self.base, entry)
            if os.path.isfile(path):
                os.unlink(path)
            elif os.path.isdir(path):
                shutil.rmtree(path)

    def get_obj_ioctx(self, obj, offset=None, length=None):
        if obj.is_folder:
            return StringIO("")
        else:
            path = obj.local_path(self.base)
            found = os.path.isfile(path)
            if not found:
                return None
            with open(path, "rb") as f:
                if offset is not None:
                    f.seek(offset)
                if length is not None:
                    return StringIO(f.read(length))
                else:
                    return StringIO(f.read())

</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Calc NAS write speed by oceanfile tools</title>
    <url>/2021/04/06/nas_write_speed/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>With the help of colleague Bean Li’s oceanfile tool, a simple, quick pressure test of the product’s NAS performance, so I wrote a test script to quickly know the results.</p>
<h1 id="script">Script</h1>
<pre><code class="language-shell">#!/bin/bash

EFILE=/usr/local/bin/oceanfile
target_no=5000000
WRITE_DIR="/vol/nas02/"
LOG="/var/log/nas_ocean.log"


function check_arch()
{   
    new_arch=(`echo $arch | tr ',' ' '` )
    total_no=1 
    for var in ${new_arch[@]}
    do  
        # echo $var
        let total_no*=$var
    done 

    if [[ ${total_no} -ne ${target_no} ]]; then
        echo ''
        echo '[ERROR]  The current round amount of data: (${total_no}) is less than expected amount of data: (${target_no})'
        echo ''
        exit 1
    fi
}


if [ $# != 3 ] ; then
    echo ""
    echo "USAGE: $0 parallel size arch"
    echo "  e.g.: $0 20 64 10,10,10,10,100"
    echo ""
    exit 1;
fi

parallel=$1
file_size=$2  # Unit is K
arch=$3

# Check arch numbers
check_arch

for round in {1..22}
do
    while (( $(ps aux | grep -w oceanfile | grep -v grep | wc -l) &gt;= 1 )); do
        sleep 60
    done

    write_dir=${WRITE_DIR}/round_${round}

    if [[ ! -d ${write_dir} ]]; then
        mkdir -p ${write_dir}
    fi

    echo $(date) ROUND ${round} BEGIN  &gt;&gt;$LOG 2&gt;&amp;1
    start_time=`echo $[$(date +%s%N)/1000000]`
    ${EFILE} -d ${write_dir} -p ${parallel} -s ${file_size}k -b ${file_size}k -a ${arch} -i 5 &gt;&gt;$LOG 2&gt;&amp;1 
    end_time=`echo $[$(date +%s%N)/1000000]`

    diff=`expr ${end_time} - ${start_time}`
    time_diff=`echo | awk "{print $diff/1000}"`
    avg_speed=`echo | awk "{print ${target_no}/${time_diff}}"`
   
    # echo ROUND $round "* ${target_no}  cost $time_diff (ms) avg_speed $avg_speed"
    printf "ROUND %-8s  %12d (Files)       Cost %10.2f (s)  Avage: %8.2f\n" $round $target_no $time_diff $avg_speed
    
    echo &gt;&gt;$LOG 2&gt;&amp;1
    echo "ROUND $round  * $target_no (files) cost $time_diff (s)  avg_speed: $avg_speed" &gt;&gt; $LOG 2&gt;&amp;1
    echo $(date) ROUND ${round} FINISH  &gt;&gt;$LOG 2&gt;&amp;1
    echo &gt;&gt;$LOG 2&gt;&amp;1
    echo &gt;&gt;$LOG 2&gt;&amp;1
done
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>NJ Office OpenVPN 账号访问认证</title>
    <url>/2021/05/30/office_vpn_account_check/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>NJ Office 开放了Open VPN，方便大家远程办公，但没有对访问者进行鉴权认证，任何一个人拿到VPN Config后，都可以接入到NJ Office LAB 网络，存在极大的安全隐患。</p>
<p>本文介绍如何对 Open VPN 账号的鉴权认证，对于非法用户，禁止登录；对于长期休眠账户，禁止登录（解禁后方可恢复正常）。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="xiu-gai-open-vpn-de-server-conf">修改 Open VPN 的 server.conf</h2>
<p>增加用户名校验配置项，在尾部增加如下内容：</p>
<pre><code class="language-shell">username-as-common-name
</code></pre>
<h2 id="she-ding-zhang-hao-mi-ma-wen-jian">设定账号密码文件</h2>
<p>psw-file 文件内容片段参考如下：</p>
<pre><code class="language-shell">Gavin gUOl3h
Kevin NJl3uQ
Echo sHd4cQ
</code></pre>
<p>一行一个记录，第一列是用户名，第二列是密码</p>
<h2 id="zeng-jia-mi-ma-xiao-yan-jiao-ben">增加密码校验脚本</h2>
<p><a href="http://checkpsw.sh">checkpsw.sh</a> 内容如下：</p>
<pre><code class="language-shell">#!/bin/bash
###########################################################
# checkpsw.sh (C) 2004 Mathias Sundman &lt;mathias@openvpn.se&gt;
#
# This script will authenticate OpenVpn users against
# a plain text file. The passfile should simply contain
# one row per user with the username first followed by
# one or more space(s) or tab(s) and then the password.
###########################################################
 
PASSFILE="/etc/openvpn/psw-file"
LOG_FILE="/etc/openvpn/openvpn-password.log"
TIME_STAMP=`date "+%Y-%m-%d %T"`
 
readarray -t lines &lt; $1
username=${lines[0]}
password=${lines[1]}

if [ ! -r "${PASSFILE}" ]; then
echo "${TIME_STAMP}: Could not open password file \"${PASSFILE}\" for reading." &gt;&gt; ${LOG_FILE}
exit 1
fi
 
CORRECT_PASSWORD=`awk '!/^;/&amp;&amp;!/^#/&amp;&amp;$1=="'${username}'"{print $2;exit}' ${PASSFILE}`
 
if [ "${CORRECT_PASSWORD}" = "" ]; then
echo "${TIME_STAMP}: User does not exist: username=\"${username}\", password=\"${password}\"." &gt;&gt; ${LOG_FILE}
exit 1
fi
 
if [ "${password}" = "${CORRECT_PASSWORD}" ]; then
echo "${TIME_STAMP}: Successful authentication: username=\"${username}\"." &gt;&gt; ${LOG_FILE}
exit 0
fi
 
echo "${TIME_STAMP}: Incorrect password: username=\"${username}\", password=\"${password}\"." &gt;&gt; ${LOG_FILE}
exit 1
</code></pre>
<p>脚本中定义了：</p>
<pre><code class="language-shell">PASSFILE="/etc/openvpn/psw-file"
LOG_FILE="/etc/openvpn/openvpn-password.log"
</code></pre>
<p>其中 <code>/etc/openvpn/openvpn-password.log</code> 用于登录账户解析使用，因为不同的账户访问VPN都会记录日志，其中含有当前登录用户名。</p>
<h2 id="zeng-jia-openvpn-password-log-ri-zhi-jie-xi">增加openvpn-password.log日志解析</h2>
<pre><code class="language-shell">#!/bin/bash

record_log='/etc/openvpn/vpn_login_time_check.log'
log_file='/etc/openvpn/openvpn-password.log'
user_file='/etc/openvpn/psw-file'

all_users=`cat ${user_file} | grep -v bigtera | awk '{print $1}'`

current=`date "+%Y-%m-%d %H:%M:%S"`
echo -e "[${current}] Start to check VPN log in time for all of users..." &gt;&gt; ${record_log}

for each_user in ${all_users};
do
    last_login_data=`cat ${log_file} | grep ${each_user} | grep 'Successful authentication' | sed -n '$p' | awk '{print $1, $2}' | sed 's/:$//g'`
    # echo ${each_user}, ${last_login_data}
    if [[ x${last_login_data} != x'' ]];then
        current=`date "+%Y-%m-%d %H:%M:%S"`
        cur_time_stamp=`date -d "${current}" +%s`
        last_login_time_stamp=`date -d "${last_login_data}" +%s`
        # echo ${cur_time_stamp}, ${last_login_time_stamp}
        time_diff=`expr ${cur_time_stamp} - ${last_login_time_stamp}`
        # echo "---  time_diff : (${time_diff})"
        if [[ ${time_diff}  -ge 604800 ]];then  # 7 days
            if [[ x${each_user} == x'Gavin' ]]; then
                email_addr='Gavin.wang@bigtera.com.cn'
            elif [[ "${each_user}" == "Sky" ]]; then
                email_addr='Sky_wu@bigtera.com.cn'
            elif [[ "${each_user}" == "Simon" ]]; then
                email_addr='simon.chen@bigtera.com.cn'
            elif [[ "${each_user}" == "Anhao" ]]; then
                email_addr='stephen.sun@bigtera.com.cn'
            else
                email_addr=''
            fi

            send_mail_cmd='echo -e "\t您已长时间未访问南京VPN，账号('${each_user}')存在过期风险. \n\t您上次访问日期是: '${last_login_data}'\n\n此邮件为系统自动发出，请勿回复." | mail -s "NJ LAB of VPN account expiration notification" '${email_addr}''
            echo "${send_mail_cmd}" &gt;&gt; ${record_log}
            `${send_mail_cmd}`
        fi
    fi
done
</code></pre>
<h2 id="xiao-yan-shi-bai-log-can-kao">校验失败log参考</h2>
<p>当VPN账号认证失败后，会记录 vpn_login_time_check.log，内容格式如下：</p>
<pre><code class="language-shell">echo -e "\t您已长时间未访问南京VPN，账号(Howard)存在过期风险. \n\t您上次访问日期是: 2023-04-29 20:30:57\n\n此邮件为系统自动发出，请勿回复." | mail -s "NJ LAB of VPN account expiration notification" 
echo -e "\t您已长时间未访问南京VPN，账号(Seven)存在过期风险. \n\t您上次访问日期是: 2023-04-30 09:48:44\n\n此邮件为系统自动发出，请勿回复." | mail -s "NJ LAB of VPN account expiration notification" seven.chen@bigtera.com.cn
echo -e "\t您已长时间未访问南京VPN，账号(Wangbx)存在过期风险. \n\t您上次访问日期是: 2023-05-15 20:34:49\n\n此邮件为系统自动发出，请勿回复." | mail -s "NJ LAB of VPN account expiration notification" wangbx@bigtera.com.cn
</code></pre>
<h1 id="zong-shu">综述</h1>
<p>有了账号认证，每个用户在访问VPN时，都会校验改用户的有效性、合法性，提高了LAB 服务器访问的安全性。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title>python debug with pysnooper/snoop</title>
    <url>/2021/05/02/python_debug/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>python代码调测，早期的时候更多的是使用print加日志的方式，后期使用pdb，今天发现了个更好的调试工具 pysnooper 和 snoop.</p>
<h1 id="shi-jian">实践</h1>
<h2 id="an-zhuang-pysnooper">安装 pysnooper</h2>
<p><code>pip install pysnooper </code></p>
<h2 id="li-yong-pysnooper-diao-shi">利用pysnooper调试</h2>
<p>示例代码</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:utf-8 -*-

import pysnooper


@pysnooper.snoop()
def remove_dup_element(a_list):
    return {}.fromkeys(a_list).keys()


if __name__ == '__main__':
    a_list = [10, 9, 1, 2, 2, 3, 3, 5, 6, 6, 7, 7, 8, 9]
    remove_dup_element(a_list)
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">root@wyz-node1:~# python test_pysnooper.py
Source path:... test_pysnooper.py
Starting var:.. a_list = [10, 9, 1, 2, 2, 3, 3, 5, 6, 6, 7, 7, 8, 9]
14:30:22.540068 call         8 def remove_dup_element(a_list):
14:30:22.540068 line         9     return {}.fromkeys(a_list).keys()
14:30:22.540068 return       9     return {}.fromkeys(a_list).keys()
Return value:.. dict_keys([10, 9, 1, 2, 3, 5, 6, 7, 8])
Elapsed time: 00:00:00.000000
</code></pre>
<p>它将每一行变量的值都输出到屏幕上，仅仅需要写一行代码（使用装饰器）就可以实现这个方便的调试功能，比起一行行写print，方便了很多。</p>
<p>如果代码执行过程比较长，输出到屏蔽不方便的话，可以输出到log文件中，在装饰器那行加上log文件路径即可：</p>
<pre><code class="language-shell">@pysnooper.snoop('/log/output.log')
def remove_dup_element(a_list):
    return {}.fromkeys(a_list).keys()
</code></pre>
<h2 id="an-zhuang-snoop">安装 snoop</h2>
<p><code>pip install snoop </code></p>
<h2 id="li-yong-snoop-diao-shi">利用snoop调试</h2>
<p>示例代码：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:utf-8 -*-

import snoop


@snoop
def remove_dup_element(a_list):
    return {}.fromkeys(a_list).keys()


if __name__ == '__main__':
    a_list = [10, 9, 1, 2, 2, 3, 3, 5, 6, 6, 7, 7, 8, 9]
    remove_dup_element(a_list)
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">root@wyz-node1:~# python test_snoop.py
14:35:52.40 &gt;&gt;&gt; Call to remove_dup_element in File "test_snoop.py", line 8
14:35:52.40 ...... a_list = [10, 9, 1, 2, 2, 3, 3, 5, 6, 6, 7, 7, 8, 9]
14:35:52.40 ...... len(a_list) = 14
14:35:52.40    8 | def remove_dup_element(a_list):
14:35:52.40    9 |     return {}.fromkeys(a_list).keys()
14:35:52.40 &lt;&lt;&lt; Return value from remove_dup_element: dict_keys([10, 9, 1, 2, 3, 5, 6, 7, 8])

root@wyz-node1:~# 
</code></pre>
<p>更高级的使用方法，参考：</p>
<p><code>https://www.pypi.com.cn/project/snoop</code><br>
<code>https://github.com/cool-RR/PySnooper/blob/master/ADVANCED_USAGE.md</code></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>WebBIOS里取消磁盘的JBOD设置</title>
    <url>/2021/06/15/webbios_disable_disk_jbod/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>环境之前有使用过storcli或megacli命令开启了JBOD模式，安装系统后始终无法进入系统，grub 引导出问题，BIOS的设置检查了几次，并未发现异常，boot device也是对的，始终无法解决重灌系统后开机问题。决定更换OS盘（换成其他的SAS盘），在更换后，碰到了本文要描述的问题：存在部分是RAID部分是JBOD盘，计划OS盘做RAID0,但WebBIOS里查看到此盘无法最RAID。</p>
<p>本文记录如何在WebBIOS取消JBOD模式，仅附图片mark下，避免忘记。</p>
<h1 id="chu-li-guo-cheng">处理过程</h1>
<h2 id="zui-chu-pan-de-zhuang-kuang">最初盘的状况</h2>
<img class="shadow" src="/img/in-post/disk_mix_mode.png" width="1200">
<h2 id="qu-xiao-jbod">取消JBOD</h2>
<p>开机启动进入WebBIOS，Controller Properties --&gt; ALter+N + 回车，连续三次，进入’Manage JBOD’ 界面，选择对应的JBOD driver，点击’OK’完成取消JBOD mode的设置， 可以按住shift与向下的箭头按钮，多选磁盘的</p>
<img class="shadow" src="/img/in-post/disable_disks_jbod_mode.png" width="1200">
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>HDD损坏了么？</title>
    <url>/2021/06/03/is_my_hdd_wreched/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天同事使用产品对HDD做分区的时候，发现程序抛异常，寻求帮助。</p>
<h1 id="guo-cheng">过程</h1>
<p>由于是一个新安装OS的环境，对现有的HDD除了操作系统之外都可以做格式化处理，尝试格式化一下，出现了如下错误：</p>
<pre><code class="language-shell">root@scaler:/home/btadmin# sgdisk -z /dev/sdb
GPT data structures destroyed! You may now partition the disk using fdisk or
other utilities.
</code></pre>
<p>上面是一个正常分区擦除分区信息的吐出信息，下面是一个异常的：</p>
<pre><code class="language-shell">root@scaler:/home/btadmin# sgdisk -z /dev/sdd
Warning! Read error 5; strange behavior now likely!
Warning! Read error 5; strange behavior now likely!
Creating new GPT entries.
Warning! GPT main header not overwritten! Error is 5
Warning: The kernel is still using the old partition table.
The new table will be used at the next reboot or after you
run partprobe(8) or kpartx(8)
GPT data structures destroyed! You may now partition the disk using fdisk or
other utilities.
</code></pre>
<p>尝试分区：</p>
<pre><code class="language-shell">root@scaler:~# gdisk /dev/sdd
GPT fdisk (gdisk) version 1.0.1

Warning! Read error 5; strange behavior now likely!
Warning! Read error 5; strange behavior now likely!
Partition table scan:
  MBR: not present
  BSD: not present
  APM: not present
  GPT: not present

Creating new GPT entries.

Command (? for help): p  
Disk /dev/sdd: 7811891200 sectors, 3.6 TiB
Logical sector size: 512 bytes
Disk identifier (GUID): 21979075-7523-49C5-A52B-E8055AE1625F
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 7811891166
Partitions will be aligned on 2048-sector boundaries
Total free space is 2014 sectors (1007.0 KiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048      7811891166   3.6 TiB     8300  Linux filesystem

Command (? for help): e
b	back up GPT data to a file
c	change a partition's name
d	delete a partition
i	show detailed information on a partition
l	list known partition types
n	add a new partition
o	create a new empty GUID partition table (GPT)
p	print the partition table
q	quit without saving changes
r	recovery and transformation options (experts only)
s	sort partitions
t	change a partition's type code
v	verify disk
w	write table to disk and exit
x	extra functionality (experts only)
?	print this menu

Command (? for help): w

Final checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTING
PARTITIONS!!

Do you want to proceed? (Y/N): y
OK; writing new GUID partition table (GPT) to /dev/sdd.
Unable to save backup partition table! Perhaps the 'e' option on the experts'
menu will resolve this problem.
Warning! An error was reported when writing the partition table! This error
MIGHT be harmless, or the disk might be damaged! Checking it is advisable.

Command (? for help): 
</code></pre>
<p>从上面可以明显看出sdd这个分区有异常，继续查看vd与pd信息：</p>
<pre><code class="language-shell">Virtual Drive: 3 (Target Id: 3)
Name                :
RAID Level          : Primary-0, Secondary-0, RAID Level Qualifier-0
Size                : 3.637 TB
Sector Size         : 512
Is VD emulated      : No
Parity Size         : 0
State               : Offline
Strip Size          : 64 KB
Number Of Drives    : 2
Span Depth          : 1
Default Cache Policy: WriteBack, ReadAheadNone, Direct, No Write Cache if Bad BBU
Current Cache Policy: WriteBack, ReadAheadNone, Direct, No Write Cache if Bad BBU
Default Access Policy: Read/Write
Current Access Policy: Read/Write
Disk Cache Policy   : Disabled
Encryption Type     : None
PI type: No PI

Is VD Cached: No
Number of Spans: 1
Span: 0 - Number of PDs: 2

PD: 0 Information
Enclosure Device ID: 8
Slot Number: 5
Drive's position: DiskGroup: 3, Span: 0, Arm: 0
Enclosure position: 1
Device Id: 15
WWN: 5000c5007995214d
Sequence Number: 2
Media Error Count: 0
Other Error Count: 0
Predictive Failure Count: 0
Last Predictive Failure Event Seq Number: 0
PD Type: SATA

Raw Size: 1.819 TB [0xe8e088b0 Sectors]
Non Coerced Size: 1.818 TB [0xe8d088b0 Sectors]
Coerced Size: 1.818 TB [0xe8d00000 Sectors]
Sector Size:  512
Logical Sector Size:  512
Physical Sector Size:  512
Firmware state: Online, Spun Up
Commissioned Spare : No
Emergency Spare : No
Device Firmware Level: SN03
Shield Counter: 0
Successful diagnostics completion on :  N/A
SAS Address(0): 0x50015b207898e72d
Connected Port Number: 0(path0) 
Inquiry Data:             Z1X3E91SST2000NM0033-9ZM175                     SN03    
FDE Capable: Not Capable
FDE Enable: Disable
Secured: Unsecured
Locked: Unlocked
Needs EKM Attention: No
Foreign State: None 
Device Speed: 6.0Gb/s 
Link Speed: 6.0Gb/s 
Media Type: Hard Disk Device
Drive:  Not Certified
Drive Temperature :39C (102.20 F)
PI Eligibility:  No 
Drive is formatted for PI information:  No
PI: No PI
Drive's NCQ setting : N/A
Port-0 :
Port status: Active
Port's Linkspeed: 6.0Gb/s 
Drive has flagged a S.M.A.R.T alert : No




PD: 1 Information
Enclosure Device ID: 8
Slot Number: 6
Drive's position: DiskGroup: 3, Span: 0, Arm: 1
Enclosure position: 1
Device Id: 14
WWN: 5000c500798ecb5a
Sequence Number: 3
Media Error Count: 0
Other Error Count: 0
Predictive Failure Count: 0
Last Predictive Failure Event Seq Number: 0
PD Type: SATA

Raw Size: 1.819 TB [0xe8e088b0 Sectors]
Non Coerced Size: 1.818 TB [0xe8d088b0 Sectors]
Coerced Size: 1.818 TB [0xe8d00000 Sectors]
Sector Size:  512
Logical Sector Size:  512
Physical Sector Size:  512
Firmware state: Failed
Commissioned Spare : Yes
Emergency Spare : Yes
Device Firmware Level: SN03
Shield Counter: 0
Successful diagnostics completion on :  N/A
SAS Address(0): 0x50015b207898e730
Connected Port Number: 0(path0) 
Inquiry Data:             Z1Y2CKNFST2000NM0033-9ZM175                     SN03    
FDE Capable: Not Capable
FDE Enable: Disable
Secured: Unsecured
Locked: Unlocked
Needs EKM Attention: No
Foreign State: None 
Device Speed: 6.0Gb/s 
Link Speed: 6.0Gb/s 
Media Type: Hard Disk Device
Drive:  Not Certified
Drive Temperature : N/A
PI Eligibility:  No 
Drive is formatted for PI information:  No
PI: No PI
Drive's NCQ setting : N/A
Port-0 :
Port status: Active
Port's Linkspeed: 6.0Gb/s 
Drive has flagged a S.M.A.R.T alert : No
</code></pre>
<p>这里显示VD 3 是Offline状态，且[8:6]这块盘Firmware state为Failed, 要再确认下，VD3对应的是哪个分区：</p>
<h2 id="step-1-huo-qu-raid-qia-de-vendor-id-he-device-id">Step1. 获取RAID卡的Vendor Id和Device Id</h2>
<pre><code class="language-shell">root@scaler:~# /opt/MegaRAID/MegaCli/MegaCli64 -adpallinfo -aall | grep -Ei 'Vendor Id|Device Id'
Vendor Id       : 1000
Device Id       : 005b
</code></pre>
<h2 id="step-2-huo-qu-vd-de-target-id">Step2. 获取VD的Target Id</h2>
<pre><code class="language-shell">root@scaler:~# /opt/MegaRAID/MegaCli/MegaCli64 -ldpdinfo  aall | grep 'Target Id'
Virtual Drive: 0 (Target Id: 0)
Virtual Drive: 1 (Target Id: 1)
Virtual Drive: 2 (Target Id: 2)
Virtual Drive: 3 (Target Id: 3)
Virtual Drive: 4 (Target Id: 4)
</code></pre>
<h2 id="step-3-huo-qu-she-bei-qian-zhui-xin-xi">Step3. 获取设备前缀信息</h2>
<pre><code class="language-shell">root@scaler:~# lspci -nd 1000:005b
02:00.0 0104: 1000:005b (rev 05)
root@scaler:~# 
</code></pre>
<p>这里的02:00.0，就是我们所需的设备前缀信息。</p>
<h2 id="step-4-gen-ju-she-bei-qian-zhui-xin-xi-yi-ji-target-id-huo-qu-dui-ying-fen-qu-xin-xi">Step4. 根据设备前缀信息以及Target Id，获取对应分区信息</h2>
<p>Linux 命令行操作如下：</p>
<pre><code class="language-shell">root@scaler:~# cd /dev/disk/by-path
root@scaler:/dev/disk/by-path# ls -l |grep 'pci-0000:02:00.0-scsi-0:2:2:0' | grep -v part | awk '{{print $NF}}' | awk -F'/' '{{print $NF}}' 
sdc
root@scaler:/dev/disk/by-path# ls -l
total 0
lrwxrwxrwx 1 root root  9 Jun  2 16:39 pci-0000:00:1f.2-ata-1 -&gt; ../../sdf
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-1-part1 -&gt; ../../sdf1
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-1-part2 -&gt; ../../sdf2
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-1-part3 -&gt; ../../sdf3
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-1-part4 -&gt; ../../sdf4
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-1-part5 -&gt; ../../sdf5
lrwxrwxrwx 1 root root  9 Jun  2 16:39 pci-0000:00:1f.2-ata-2 -&gt; ../../sdg
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-2-part1 -&gt; ../../sdg1
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-2-part2 -&gt; ../../sdg2
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-2-part3 -&gt; ../../sdg3
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-2-part4 -&gt; ../../sdg4
lrwxrwxrwx 1 root root 10 Jun  2 16:39 pci-0000:00:1f.2-ata-2-part5 -&gt; ../../sdg5
lrwxrwxrwx 1 root root  9 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:0:0 -&gt; ../../sda
lrwxrwxrwx 1 root root 10 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:0:0-part1 -&gt; ../../sda1
lrwxrwxrwx 1 root root  9 Jun  2 16:48 pci-0000:02:00.0-scsi-0:2:1:0 -&gt; ../../sdb
lrwxrwxrwx 1 root root 10 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:1:0-part1 -&gt; ../../sdb1
lrwxrwxrwx 1 root root  9 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:2:0 -&gt; ../../sdc
lrwxrwxrwx 1 root root 10 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:2:0-part1 -&gt; ../../sdc1
lrwxrwxrwx 1 root root 10 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:2:0-part2 -&gt; ../../sdc2
lrwxrwxrwx 1 root root 10 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:2:0-part3 -&gt; ../../sdc3
lrwxrwxrwx 1 root root 10 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:2:0-part4 -&gt; ../../sdc4
lrwxrwxrwx 1 root root  9 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:3:0 -&gt; ../../sdd
lrwxrwxrwx 1 root root  9 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:4:0 -&gt; ../../sde
lrwxrwxrwx 1 root root 10 Jun  2 16:50 pci-0000:02:00.0-scsi-0:2:4:0-part1 -&gt; ../../sde1
root@scaler:/dev/disk/by-path# 
root@scaler:/dev/disk/by-path# ls -l |grep 'pci-0000:02:00.0-scsi-0:2:3:0' | grep -v part | awk '{{print $NF}}' | awk -F'/' '{{print $NF}}' 
sdd
root@scaler:/dev/disk/by-path# 
</code></pre>
<p>出现坏盘的，对应RAID组为VD 3，正好是sdd这个分区，说明HDD有损坏了，需要进行更换。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>如何知道CPU降频了呢</title>
    <url>/2021/06/30/how_do_i_know_that_the_cpu_frequency_is_down/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近碰到过几次服务器出现CPU降频的问题，其中两次是硬件BIOS固件的bug，不小心踩到了（概率很低，但有幸被我碰到，巨坑），后来从硬件厂商那获取到了高阶版本，刷了高阶版本的固件解决掉了；</p>
<p>还有一次是设备两路电源线被同事拔掉了一根，只剩下一路了，供电不足，导致CPU主动降频；</p>
<p>今天RD在tuning performance时，再次碰到了CPU降频问题，问题是tuning performance过程中ganesha 跑到 1000 多 %，很凶，造成服务器机体温度升高，整个Lab平均温度达到31度，增加空调紧急降温后恢复正常。</p>
<p>由于碰到过多次，本文汇总下如何判断CPU发生了降频，避免忘记（其实今天没看出来哪里降频了，所以才写了此文XD）。</p>
<h1 id="cha-kan-cpu-jiang-pin-de-fang-fa">查看CPU降频的方法</h1>
<h2 id="lscpu">lscpu</h2>
<img class="shadow" src="/img/in-post/lscpu.png" width="1200">
<p>如上图所示：</p>
<pre><code class="language-shell">CPU MHz:               2579.700
CPU max MHz:           3000.0000
CPU min MHz:           800.0000
</code></pre>
<p>这里有CPU当前HZ（CPU MHz）信息和min MHz（CPU min MHz），如果CPU MHz的值是小于CPU min MHz的值，说明CPU被降频了。</p>
<h2 id="atop-zhong-cha-kan-cruf">atop中查看cruf</h2>
<p>借助atop命令（公司产品有安装），查看CPU的curf（ARM平台，华为鲲鹏服务器，这里的值为’？'，不知道为什么【需要打流量？？】，X86是OK的）</p>
<img class="shadow" src="/img/in-post/atop_cruf.png" width="1200">
<p>如果curf（current frequency）只有几十MHz(正常情况下是XGHz)，CPU铁定是被降频了，此时观察atop中众多process，几乎清一色的只消耗1%的process</p>
<h1 id="zong-jie">总结</h1>
<p>CPU降频的原因，目前碰到的：</p>
<p>（1）硬件设备温度过高</p>
<p>（2）BIOS固件的bug</p>
<p>（3）供电不足</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS中cp -f copy强制覆盖命令无效</title>
    <url>/2021/07/01/slove_cp_command_force_overwrite_issue/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天分几次执行了automation用例，产生不不用的allure需要的json文件，由于部分case执行失败，再次执行了这部分用例，对新产生的json文件覆盖掉旧的，结果在cp时提示是否要overwrite，由于文件数量很多，不可能每个交互信息都要输入y来确认覆盖，于是就要靠强制覆盖来解决，执行cp -rf时并没有起到预期效果。</p>
<p>本文记录解决Linux CentOS中cp -f 复制强制覆盖的命令无效的方法。</p>
<h1 id="huan-jing">环境</h1>
<pre><code class="language-shell">[root@node179 ~]# cat /etc/redhat-release 
Red Hat Enterprise Linux Server release 7.2 (Maipo)
[root@node179 ~]# 
</code></pre>
<h1 id="xian-xiang">现象</h1>
<pre><code class="language-shell">[root@node179 06_30]# cp -i json/* /root/pytest_framework/report/json/
cp: overwrite ‘/root/pytest_framework/report/json/0002c684-9976-416e-8149-ed85c5e38aa8-container.json’? y
cp: overwrite ‘/root/pytest_framework/report/json/001824e6-1cde-4d7d-ae45-02acf4f2d33f-container.json’? y
</code></pre>
<p>换 -rf，效果一样</p>
<pre><code class="language-shell">[root@node179 06_30]# cp -rf json/* /root/pytest_framework/report/json/
cp: overwrite ‘/root/pytest_framework/report/json/0002c684-9976-416e-8149-ed85c5e38aa8-container.json’? y
cp: overwrite ‘/root/pytest_framework/report/json/001824e6-1cde-4d7d-ae45-02acf4f2d33f-container.json’? y
</code></pre>
<h1 id="chu-li-guo-cheng">处理过程</h1>
<p>网上搜索了一下，看到这么个解释： Linux下默认cp命令是有别名的(alias cp=‘cp -i’)，无法在复制时强制覆盖，即使你用 -f 参数也无法强制覆盖文件</p>
<p>在CentOS里执行alias，信息如下:</p>
<pre><code class="language-shell">[root@node179 ~]# alias
alias cp='cp -i'
alias egrep='egrep --color=auto'
alias fgrep='fgrep --color=auto'
alias grep='grep --color=auto'
alias l.='ls -d .* --color=auto'
alias ll='ls -l --color=auto'
alias ls='ls --color=auto'
alias mv='mv -i'
alias rm='rm -i'
alias vi='vim'
alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
</code></pre>
<p>果然，cp是被alias过了。</p>
<h1 id="tui-jian-de-jie-jue-fang-fa">推荐的解决方法</h1>
<p>下面提供几个从网上找的Linux下cp命令覆盖的方法。</p>
<p>1)取消cp的alias（放心这不是永久生效）：</p>
<pre><code class="language-shell"># unalias cp
# cp -rf /test/test_other
</code></pre>
<p>2)加反斜杠 \cp 执行cp命令时不走alias：（注：推荐这个方法！）</p>
<pre><code class="language-shell"># \cp -rf /test/test_other
</code></pre>
<p>3）另外一个有意思的方法：</p>
<pre><code class="language-shell"># yes|cp -rf /test/test_other
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Parsync</title>
    <url>/2021/03/19/parsync/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<h2 id="what-is-parsync">What is parsync?</h2>
<p>Parsync is a script that tries to run multiple rsync command in parallel to speed up the sync progress.</p>
<h2 id="why-not-rsync">Why not rsync?</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>rsync</code> is a single process program, it cannot fully take the advantage of multi-cores CPU and high network band width. In short, it is slow.</p>
</li>
<li class="lvl-2">
<p><code>rsync</code> can be run with tools like <code>find</code>, <code>parallel</code> and <code>xargs</code> to run multiple rsync processes in parallel, e.g.</p>
<pre><code class="language-shell">find SOURCE_DIR -type f | parallel --will-cite -j 5 rsync -av {} DESTINATION
</code></pre>
<p>or</p>
<pre><code class="language-shell">find SOURCE_DIR -type d | xargs -I {} rsync -a {} DESTINATION
</code></pre>
<p>In the first example, <code>parallel</code> will run 5 <code>rsync</code> processes to sync files under <code>SOURCE_DIR</code> one by one. If those files are large files, it is fine. However, if those are small files like 4KB, <code>rsync</code> will still be very slow.</p>
<p>In the second example, one <code>rsync</code> process will be started for each directory under <code>SOURCE_DIR</code>. Usually, all files are not evenly spread under these directories which means, at first, <code>rsync</code> does run in parallel. But, soon, most of <code>rsync</code> processes will finish their work and exit, only the 1 or 2 <code>rsync</code> process will still be running. Then, <code>rsync</code> will become slow again.</p>
</li>
</ul>
<h2 id="usage">Usage</h2>
<pre><code class="language-shell">usage: parsync.py [-h] [--bwlimit BWLIMIT] [--id ID] [--parallel PARALLEL]
                  [--no-progress] [-n]
                  source destination ...

Run rsync in parallel. All parameters for parsync MUST be provided before
source as usage shows, any parameter after destination is directly passed to
rsync.

positional arguments:
  source               source of rsync, cannot be empty. DO NOT use syntax
                       like XXX/* for source, use XXX/ or "XXX/*" instead
  destination          destination of rsync, cannot be empty
  args                 additional arguments that will directly be send to
                       rsync

optional arguments:
  -h, --help           show this help message and exit
  --bwlimit BWLIMIT    limit I/O bandwidth; KBytes per second. Default: 0 KB/s
  --id ID              ID of backup task. It is the pid of current process by
                       default
  --parallel PARALLEL  run how many rsync processes in parallel
  --no-progress        do not show progress bar
  -n, --dry-run        perform a trial run with no changes made
</code></pre>
<p><em>P.S.</em> If you encounter encoding error, add <code>LC_ALL=en_US.UTF-8</code> before parsync, e.g.</p>
<pre><code class="language-shell">LC_ALL=en_US.UTF-8 python parsync.py SOURCE DEST
</code></pre>
<h2 id="example-usage">Example Usage</h2>
<h4 id="sync-source-to-dest">Sync SOURCE to DEST</h4>
<pre><code class="language-shell">parsync.py SOURCE DEST
</code></pre>
<h4 id="sync-files-and-dirs-under-source-to-dest">Sync files and dirs under SOURCE to DEST</h4>
<pre><code class="language-shell">parsync.py SOURCE/ DEST
</code></pre>
<p>or</p>
<pre><code class="language-shell">parsync.py "SOURCE/*" DEST
</code></pre>
<p>The reason adding <code>"</code> around <code>SOURCE/*</code> is to avoid <code>SOURCE/*</code> being expanded into <code>SOURCE/a SOURCE/b …</code> by shell.</p>
<h4 id="run-100-rsync-in-parallel">Run 100 rsync in parallel</h4>
<pre><code class="language-shell">parsync.py --parallel=100 SOURCE DEST
</code></pre>
<h4 id="run-parsync-with-bandwidth-limit-4000-kb-s-with-100-rsync-in-parallel">Run parsync with bandwidth limit 4000KB/s with 100 rsync in parallel</h4>
<pre><code class="language-shell">parsync.py --parallel=100 --bwlimit=4000 SOURCE DEST
</code></pre>
<p>or</p>
<pre><code class="language-shell">parsync.py --parallel=100 SOURCE DEST --bwlimit=40
</code></pre>
<p>In the first example, the <code>bwlimit</code> is passed to parsync and parsync will calculate the <code>bwlimit</code> for each rsync process, in this case, 40 KB/s. In the second example, the <code>bwlimit</code> is directly passed to rsync without any check or change.</p>
<h2 id="test">Test</h2>
<p>Run <code>python test.py</code> to run unittest for parsync. If you encouter encoding error, add <code>LC_ALL=en_US.UTF-8</code> in the beginning of the command, for example: <code>LC_ALL=en_US.UTF-8 python test.py</code></p>
<h1 id="script-content">Script content</h1>
<p><code>parsync.py</code></p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import print_function, division, absolute_import

import os
import sys
from time import sleep
import argparse
from itertools import chain
from subprocess import check_output, CalledProcessError, check_call

try:
    from os import scandir
except ImportError:
    from scandir import scandir

from utils import walk, Pool, lisfile


total_paths = 0
total_tasks = 0
show_progress = True
GROUP_CNT = 10
PATHS = '/tmp/parsync_paths.{}'
paths_file = None
TASKS = '/tmp/parsync_tasks.{}'
tasks_file = None

# this value is used to calculate how long should a progress bar be.
# screen width in IPMI is 100, this value should be smaller than 100,
# so that the progress bar will not be longer than one line
SCREEN_WIDTH = 100


def set_screen_width():
    try:
        output = check_output(['stty', 'size'])
    except CalledProcessError:
        pass    # use default value 30
    else:
        global SCREEN_WIDTH
        try:
            SCREEN_WIDTH = int(output.split()[1])
        except:
            pass


def generate_paths(source='.'):
    if show_progress:
        dot_num = 0
        path_count = 0
        max_dots = SCREEN_WIDTH - len('Generate Paths ')
        sys.stdout.write('Generate Paths ' + ' ' * max_dots)

    with open(paths_file, 'wb', buffering=4194304) as writer:
        if lisfile(source):
            writer.write(source + '\n')
        else:
            for root, dirs, files in walk(source):
                if root != os.path.curdir:  # skip '.'
                    writer.write(root + os.path.sep + '\n')
                for f in files:
                    # DO NOT use str.format() here, it may raise encoding error
                    writer.write(os.path.join(root, f) + '\n')

                if show_progress:
                    path_count += 1
                    if path_count == 1000:
                        if dot_num == max_dots:
                            dot_num = 0
                        sys.stdout.write('\b' * max_dots)
                        dot_num += 1
                        sys.stdout.write('.' * dot_num + ' ' * (max_dots - dot_num))
                        sys.stdout.flush()
                        path_count = 0
    if show_progress:
        print('')


def generate_groups():
    """
    I've tried count line number of a file with 13169031 lines
    1. read file line by line, until the end                            avg 2.3067 s
    2. read N MB file into buffer, count number of '\n', until the end  avg 1.8454 s
    3. open file and load it into mmap(memory map), count line by line  avg 3.0107 s
    4. use "wc -l" command                                              avg 1.0206 s

    "wc -l" is the fastest way to count line number of a file..
    """
    try:
        output = check_output(['wc', '-l', '{}'.format(paths_file)])
    except CalledProcessError as e:
        print('wc failed to get line count, error:\n{}'.format(e))
        raise

    global total_paths
    total_paths = int(output.split()[0])
    line_per_group = (total_paths + GROUP_CNT - 1) // GROUP_CNT

    for group in range(GROUP_CNT):
        begin = line_per_group * group
        end = begin + line_per_group
        yield begin, end


def _generate_tasks_with_progress(group_paths, task_done=None):
    tasks = []
    top_dir = None
    for path in group_paths:
        # remove tailing '\n', do not use str.strip(), because path may end with spaces
        path = path[:-1]
        if path.endswith(os.path.sep):  # is a dir
            # Because rsync is used with '-R', so it's unnecessary to remove tailing '/'
            # path = path[:-1]    # remove tailing os.path.sep
            if top_dir and path.startswith(top_dir):
                task_done.value += 1
                continue

            if group_paths[-1].startswith(path):
                # group may not contain path's all subfolder and files
                if scandir(path):   # path is not an empty folder
                    task_done.value += 1
                    # it will be synced when syncing folders and files it contains
                    continue
                else:               # path is an empty folder
                    task_done.value += 1
                    tasks.append(path)
            else:
                task_done.value += 1
                # all path's subfolders and files are in group
                top_dir = path
                tasks.append(path)
        else:   # not a dir
            if top_dir and path.startswith(top_dir):
                task_done.value += 1
                # path is under top_dir, ignore it
                # it will be synced, when top_dir is synced
                continue
            else:
                task_done.value += 1
                tasks.append(path)
    return tasks


def _generate_tasks_without_progress(group_paths, task_done=None):
    tasks = []
    top_dir = None
    for path in group_paths:
        # remove tailing '\n', do not use str.strip(), because path may end with spaces
        path = path[:-1]
        if path.endswith(os.path.sep):  # is a dir
            # Because rsync is used with '-R', so it's unnecessary to remove tailing '/'
            # path = path[:-1]    # remove tailing '/'
            if top_dir and path.startswith(top_dir):
                continue

            if group_paths[-1].startswith(path):
                # group may not contain path's all subfolder and files
                if scandir(path):   # path is not an empty folder
                    # it will be synced when syncing folders and files it contains
                    continue
                else:               # path is an empty folder
                    tasks.append(path)
            else:
                # all path's subfolders and files are in group
                top_dir = path
                tasks.append(path)
        else:   # not a dir
            if top_dir and path.startswith(top_dir):
                # path is under top_dir, ignore it
                # it will be synced, when top_dir is synced
                continue
            else:
                tasks.append(path)
    return tasks


def generate_tasks(*args, **kwargs):
    if show_progress:
        return _generate_tasks_with_progress(*args, **kwargs)
    else:
        return _generate_tasks_without_progress(*args, **kwargs)


def do_rsync(source, destination, args=None, bwlimit=None, task_done=None):
    if source:
        cmd = ['rsync', '-avqsR', '{}'.format(source), '{}'.format(destination)]
        cmd.extend(args)
        if bwlimit:
            cmd.append('--bwlimit={}'.format(bwlimit))

        try:
            check_call(cmd)
        except CalledProcessError as e:
            print('rsync failed, error:\n{}'.format(e))

        # this task is done, no matter if it is successful or not
        if show_progress:
            task_done.value += 1


def main():
    parser = argparse.ArgumentParser(
        description='Run rsync in parallel. '
                    'All parameters for parsync MUST be provided before source as usage shows, '
                    'any parameter after destination is directly passed to rsync.'
    )
    parser.add_argument('source',
                        help='source of rsync, cannot be empty. DO NOT use syntax '
                             'like XXX/* for source, use XXX/ or "XXX/*" instead')
    parser.add_argument('destination', help='destination of rsync, cannot be empty')
    parser.add_argument('--bwlimit', type=int, default=0,
                        help='limit I/O bandwidth; KBytes per second. Default: 0 KB/s')
    parser.add_argument('--id', default=str(os.getpid()),
                        help='ID of backup task. It is the pid of current process by default')
    parser.add_argument('--parallel', type=int, default=4,
                        help='run how many rsync processes in parallel')
    parser.add_argument('--no-progress', action='store_true', help='do not show progress bar')
    parser.add_argument('-n', '--dry-run', action='store_true',
                        help='perform a trial run with no changes made')
    parser.add_argument('args', nargs=argparse.REMAINDER,
                        help="additional arguments that will directly be send to rsync")

    options = parser.parse_args()

    # do not use strip(), source and destination may contain leading or tailing spaces
    source = options.source
    destination = os.path.abspath(options.destination)
    tid = options.id
    assert options.parallel &gt; 0, 'parallel parameter must be greater than 0'
    # bwlimit parameter for rsync must be an integer
    bwlimit = int(options.bwlimit / options.parallel) or None
    args = options.args

    global show_progress, paths_file, tasks_file, GROUP_CNT
    show_progress = not options.no_progress
    paths_file = PATHS.format(tid)
    tasks_file = TASKS.format(tid)
    if options.parallel &lt; 10:
        GROUP_CNT = 10
    elif options.parallel &gt; 100:
        GROUP_CNT = 100
    else:
        GROUP_CNT = options.parallel

    if show_progress:
        set_screen_width()

    # remove tailing '*'
    source = source[:-1] if source.endswith('*') else source

    # sync root folder of source to destination or not
    sync_root = not source.endswith(os.path.sep)

    # remove tailing '/', e.g. 'XXX/YYY/' ==&gt; 'XXX/YYY'
    source = os.path.normpath(source)
    # AAA/BBB/CCC ==&gt; AAA/BBB, CCC
    base_dir, source = os.path.split(source)
    if base_dir:
        os.chdir(base_dir)

    if not sync_root:
        os.chdir(source)
        source = os.path.curdir

    if not os.path.exists(paths_file):
        generate_paths(source)

    pool = Pool(processes=options.parallel, show_progress=show_progress)
    if not os.path.exists(tasks_file):
        with open(paths_file, 'rb') as reader:
            paths = reader.readlines()

        result = []
        for start, end in generate_groups():
            result.append(pool.apply_async(generate_tasks, (paths[start:end],)))

        if show_progress:
            max_dots = SCREEN_WIDTH - len('Generating Tasks ') - len(' 100.0%')
            while not all([r.ready() for r in result]):
                try:
                    current_progress = pool.task_done / total_paths
                except ZeroDivisionError:
                    break
                if current_progress &gt; 1:
                    current_progress = 1
                dot_num = int(current_progress * max_dots)
                percentage = '{:&gt;6.1f}%'.format(current_progress * 100)
                progress_bar = 'Generating Tasks ' + '.' * dot_num + ' ' * (max_dots - dot_num) + percentage
                sys.stdout.write('\b' * SCREEN_WIDTH)
                sys.stdout.write(progress_bar)
                sys.stdout.flush()
                sleep(0.1)
            else:
                progress_bar = 'Generating Tasks ' + '.' * max_dots + ' 100.0%'
                sys.stdout.write('\b' * SCREEN_WIDTH)
                sys.stdout.write(progress_bar)
                sys.stdout.flush()

            print('')

        tasks = chain.from_iterable([r.get() for r in result])
        global total_tasks
        with open(tasks_file, 'wb', buffering=4194304) as writer:
            for t in tasks:
                writer.write(t + '\n')
                total_tasks += 1

    if not options.dry_run:
        pool = Pool(processes=options.parallel, show_progress=show_progress)
        try:
            results = []
            with open(tasks_file, 'rb') as reader:
                for task in reader:
                    # task[:-1] is to remove tailing '\n'
                    result = pool.apply_async(do_rsync, (task[:-1], destination, args, bwlimit))
                    results.append(result)

            if show_progress:
                max_dots = SCREEN_WIDTH - len('Syncing ') - len(' 100.0%')
                while results:
                    current_progress = pool.task_done / total_tasks
                    if current_progress &gt; 1:
                        current_progress = 1
                    dot_num = int(current_progress * max_dots)
                    percentage = '{:&gt;6.1f}%'.format(current_progress * 100)
                    progress_bar = 'Syncing ' + '.' * dot_num + ' ' * (max_dots - dot_num) + percentage
                    sys.stdout.write('\b' * SCREEN_WIDTH)
                    sys.stdout.write(progress_bar)
                    sys.stdout.flush()
                    sleep(0.1)

                    results = filter(lambda x: not x.ready(), results)
                else:
                    progress_bar = 'Syncing ' + '.' * max_dots + ' 100.0%'
                    sys.stdout.write('\b' * SCREEN_WIDTH)
                    sys.stdout.write(progress_bar)
                    sys.stdout.flush()
                print('')

        except KeyboardInterrupt:
            pool.terminate()
        else:
            pool.close()
        finally:
            pool.join()

    return 0


if __name__ == '__main__':
    main()

</code></pre>
<p><code>utils.py</code></p>
<pre><code class="language-python"># -*- coding: utf-8 -*-

import os
import six
import stat
from multiprocessing import Value
from multiprocessing.pool import Pool
from multiprocessing.util import debug

try:
    from os import scandir
except ImportError:
    from scandir import scandir


__all__ = ['walk', 'Pool', 'lisfile']


def ensure_unicode(obj):
    return obj if isinstance(obj, six.text_type) else obj.decode('utf8')


def ensure_bytes(obj):
    if isinstance(obj, six.text_type):
        return obj.encode('utf8')
    elif isinstance(obj, bytearray):
        return bytes(obj)
    else:
        return obj


def walk(top, onerror=None):
    """A simplified version of scandir.walk().
    It is equals to scandir.walk() with topdown=True, followlinks=False
    """
    dirs = []
    nondirs = []

    try:
        scandir_it = scandir(top)
    except OSError as error:
        if onerror is not None:
            onerror(error)
        return

    while True:
        try:
            try:
                entry = next(scandir_it)
            except StopIteration:
                break
        except OSError as error:
            if onerror is not None:
                onerror(error)
            return

        try:
            is_dir = entry.is_dir(False)
        except OSError:
            is_dir = False

        if is_dir:
            dirs.append(entry.name)
        else:
            nondirs.append(entry.name)

    # Yield before recursion if going top down
    yield top, dirs, nondirs

    # Recurse into sub-directories
    for name in dirs:
        new_path = os.path.join(top, name)
        for entry in walk(new_path, onerror):
            yield entry


def lisfile(path):
    # check if a given path is file or not(do not follow symlinks)
    mode = os.stat(path).st_mode
    if stat.S_ISLNK(mode):
        return True
    else:
        return not stat.S_ISDIR(mode)


def worker(inqueue, outqueue, initializer=None, initargs=(), maxtasks=None, task_done=None):
    assert maxtasks is None or (type(maxtasks) in (six.integer_types,) and maxtasks &gt; 0)
    put = outqueue.put
    get = inqueue.get
    if hasattr(inqueue, '_writer'):
        inqueue._writer.close()
        outqueue._reader.close()

    if initializer is not None:
        initializer(*initargs)

    completed = 0
    while maxtasks is None or (maxtasks and completed &lt; maxtasks):
        try:
            task = get()
        except (EOFError, IOError):
            debug('worker got EOFError or IOError -- exiting')
            break

        if task is None:
            debug('worker got sentinel -- exiting')
            break

        job, i, func, args, kwds = task
        try:
            result = (True, func(*args, task_done=task_done, **kwds))
        except Exception as e:
            result = (False, e)
        try:
            put((job, i, result))
        except Exception as e:
            wrapped = MaybeEncodingError(e, result[1])
            debug("Possible encoding error while sending result: %s" % (
                wrapped))
            put((job, i, (False, wrapped)))

        task = job = result = func = args = kwds = None
        completed += 1
    debug('worker exiting after %d tasks' % completed)


class PoolWithProgress(Pool):
    def __init__(self, *args, **kwargs):
        self.task_summary = []
        self.task_done_of_exited_workers = 0
        super(PoolWithProgress, self).__init__(*args, **kwargs)

    @property
    def task_done(self):
        return self.task_done_of_exited_workers + sum((obj.value for obj in self.task_summary))

    def _join_exited_workers(self):
        """Cleanup after any worker processes which have exited due to reaching
        their specified lifetime.  Returns True if any workers were cleaned up.
        """
        cleaned = False
        for i in reversed(range(len(self._pool))):
            worker = self._pool[i]
            if worker.exitcode is not None:
                # worker exited
                debug('cleaning up worker %d' % i)
                worker.join()
                cleaned = True
                del self._pool[i]
                self.task_done_of_exited_workers += self.task_summary[i].value
                del self.task_summary[i]
        return cleaned

    def _repopulate_pool(self):
        """Bring the number of pool processes up to the specified number,
        for use after reaping workers which have exited.
        """
        for i in range(self._processes - len(self._pool)):
            task_done = Value('L', 0)
            w = self.Process(target=worker,
                             args=(self._inqueue, self._outqueue,
                                   self._initializer, self._initargs,
                                   self._maxtasksperchild, task_done)
                             )
            self.task_summary.append(task_done)
            self._pool.append(w)
            w.name = w.name.replace('Process', 'PoolWorker')
            w.daemon = True
            w.start()
            debug('added worker')


class MaybeEncodingError(Exception):
    """Wraps possible unpickleable errors, so they can be
    safely sent through the socket."""

    def __init__(self, exc, value):
        self.exc = repr(exc)
        self.value = repr(value)
        super(MaybeEncodingError, self).__init__(self.exc, self.value)

    def __str__(self):
        return "Error sending result: '%s'. Reason: '%s'" % (self.value,
                                                             self.exc)

    def __repr__(self):
        return "&lt;MaybeEncodingError: %s&gt;" % str(self)


def Pool(show_progress=True, *args, **kwargs):
    if show_progress:
        return PoolWithProgress(*args, **kwargs)
    else:
        return Pool(*args, **kwargs)

</code></pre>
<p><code>test.py</code></p>
<pre><code class="language-python"># -*- coding: utf-8 -*-

from __future__ import absolute_import, print_function

import os
import six
import shutil
import unittest
import subprocess

try:
    from itertools import izip_longest as zip_longest
except ImportError:
    from itertools import zip_longest
from functools import wraps


TEST = os.path.normpath(os.path.join(__file__, os.path.pardir, 'test'))
SOURCE = os.path.join(TEST, 'source')
PS_DEST = os.path.join(TEST, 'parsync_dest')
RS_DEST = os.path.join(TEST, 'rsync_dest')

names = {
    'file': {
        'normal': 'file',
        'chinese': '文本文件',
        'space': ' regular file with spaces ',
        '*': 'file*',
        '|': 'file|',
        '=': 'file=',
        '?': 'file?',
        '"': '"file"',
        'unicode': 'fileåß∂ƒ©∆¬',
        'spanish': 'fileáéíóú¿¡üñ',
    },
    'dir': {
        'normal': 'dir',
        'chinese': '文件夹',
        'space': ' dir with spaces ',
        '*': 'dir*',
        '|': 'dir|',
        '=': 'dir=',
        '?': 'dir?',
        '"': '"dir"',
        'unicode': 'diråß∂ƒ©∆¬',
        'spanish': 'diráéíóú¿¡üñ',
    }
}


def to_bytes(obj):
    if six.PY3:
        return obj

    if isinstance(obj, six.text_type):
        return obj.encode('utf8')
    elif isinstance(obj, bytearray):
        return bytes(obj)
    else:
        return obj


def ensure_bytes(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        new_args = (to_bytes(arg) for arg in args)
        new_kwargs = {k: to_bytes(v) for k, v in kwargs.items()}
        return func(*new_args, **new_kwargs)
    return wrapper


@ensure_bytes
def touch(name, parent=os.path.curdir):
    path = os.path.join(parent, name)
    try:
        open(path, 'w').close()
    except Exception as e:
        print('Create file [{}] failed, error:\n{}'.format(path, e))


@ensure_bytes
def create_files(parent=os.path.curdir):
    for name in names['file'].values():
        touch(name, parent=parent)


@ensure_bytes
def create_dirs(parent=os.path.curdir):
    for name in names['dir'].values():
        path = os.path.join(parent, name)
        os.mkdir(path)
        touch('example', path)


def create_soft_link():
    cwd = os.getcwd()
    os.chdir(os.path.join(os.path.dirname(__file__), SOURCE))
    os.symlink('dir', 'link_to_dir')
    os.symlink('file', 'link_to_file')

    touch('source')
    os.symlink('source', 'broken_link')
    os.remove('source')

    os.chdir(cwd)


class TestSyncSource(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        if os.path.exists(TEST):
            shutil.rmtree(TEST)

        # create souce and destination dirs for testing
        os.mkdir(TEST)
        os.mkdir(SOURCE)

        # create source files and dirs
        create_files(SOURCE)
        create_dirs(SOURCE)
        create_soft_link()

    @classmethod
    def tearDownClass(cls):
        shutil.rmtree(TEST)

    def setUp(self):
        os.mkdir(PS_DEST)
        os.mkdir(RS_DEST)

    def tearDown(self):
        shutil.rmtree(RS_DEST)
        shutil.rmtree(PS_DEST)

    def base_test(self, source, parallel=None, bwlimit=None, no_progress=True):
        if six.PY2:
            cmd = ['python2', 'parsync.py', source, PS_DEST]
        else:
            cmd = ['python3', 'parsync.py', source, PS_DEST]
        if no_progress:
            cmd.insert(2, '--no-progress')
        if parallel:
            cmd.insert(2, '--parallel')
            cmd.insert(3, str(parallel))
        if bwlimit:
            cmd.insert(2, '--bwlimit')
            cmd.insert(3, str(bwlimit))

        subprocess.check_call(cmd)
        subprocess.check_call(['rsync', '-aqs', source, RS_DEST])

        parsync_dir_tree = os.walk(PS_DEST)
        rsync_dir_tree = os.walk(RS_DEST)

        for ps, rs in zip_longest(parsync_dir_tree, rsync_dir_tree):
            if ps and rs:
                _, dirs1, files1 = ps
                _, dirs2, files2 = rs
                self.assertEqual(sorted(dirs1), sorted(dirs2))
                self.assertEqual(sorted(files1), sorted(files2))
            else:
                self.assertEqual(ps, rs)
                break

    def test_sync_source_dir_with_progress(self):
        self.base_test(SOURCE, no_progress=False)

    def test_sync_files_under_source_dir(self):
        self.base_test('{}/'.format(SOURCE))

    def test_parsync_with_parallel(self):
        self.base_test(SOURCE, parallel=8)

    def test_parsync_with_parallel_1(self):
        self.base_test(SOURCE, parallel=1)

    def test_parsync_with_bwlimit(self):
        self.base_test(SOURCE, bwlimit=10)

    def test_sync_single_file(self):
        self.base_test(os.path.join(SOURCE, names['file']['normal']))

    def test_sync_file_with_Chinese_name(self):
        self.base_test(os.path.join(SOURCE, names['file']['chinese']))

    @unittest.expectedFailure
    def test_source_not_exist(self):
        self.base_test('not_exist')


if __name__ == '__main__':
    suite = unittest.TestLoader().loadTestsFromTestCase(TestSyncSource)
    result = unittest.TextTestRunner(verbosity=2).run(suite)
    exit(not result.wasSuccessful())

</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Get filemap from OSD map</title>
    <url>/2021/08/09/get_filemap/</url>
    <content><![CDATA[<h1 id="script-of-get-fibmap-py">Script of get_fibmap.py</h1>
<pre><code class="language-python">#!/usr/bin/env python
import sys
import argparse
from ezs3.command import do_cmd

osd_map = {
    "0":"172.17.59.173",
    "1":"172.17.59.173",
    "2":"172.17.59.174",
    "3":"172.17.59.174",
    "4":"172.17.59.175",
    "5":"172.17.59.175"
}

def print_fibmap(obj_name, osd_id, node):
    pg = do_cmd("ceph osd map data {} | awk '{{print $11}}'|tr -d \"()\"".format(obj_name))
    obj_path = do_cmd("find /data/osd.{}/current/{}_head/ -name \"*{}*\"".format(osd_id, pg.strip(), obj_name), _host=node)
    layout = do_cmd("hdparm --fibmap {}|grep -v sectors".format(obj_path.strip()), _host=node)
    print layout

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("filepath")
    args = parser.parse_args()
    file_path = args.filepath
    cephfs_map = do_cmd("cephfs '{}' map".format(file_path))
    for line in cephfs_map.strip().split('\n'):
        if "OSD" not in line:
            element = line.strip().split()
            obj_name = element[1]
            osd_id = element[4]
            node = osd_map[osd_id]
            print_fibmap(obj_name, osd_id, node)

if __name__ == '__main__':
    main()
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>监控BigteraStore cache中inode消耗状况</title>
    <url>/2021/10/09/watch_inode_bt_cache_dump/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>S3性能测试， 向单一Bucket下持续灌入4K大下的对象，观察存储是否会随着Bucket下Objects熟的增多而出现性能衰减现象。</p>
<p>在此测试过程中，增加了一个脚本，用于监控BigteraStore cache中inode消耗状况，记录之。</p>
<h1 id="script">Script</h1>
<p><code>watch_inode_bt_cach_dump.sh</code></p>
<pre><code class="language-shell">#!/bin/bash

osd_ids=`ps -ef |grep ceph-osd | grep -v grep | awk '{{print $13}}' | sort`
inode_info='df -ih /data/cache/*'
all_mon_ips=`ceph mon dump | grep mon.* | awk -F ':' '{{print $2}}'`

i=1
max_loop=600
log_file='s3_watch_dump.log'

while true
do
    if [ $i -ge ${max_loop}  ]; then
        cur_date="`date +%Y-%m-%d,%H:%m:%s`"
        echo -e [${cur_date}] " Finished, exit\n" &gt;&gt; ${log_file}
        break
    else
        echo -e "\n=======================================  $i  ============================================" &gt;&gt; ${log_file}
        echo -e "\n-- ceph df output: --\n" &gt;&gt; ${log_file}
        echo -e "`ceph df`" &gt;&gt; ${log_file}
        echo -n "" &gt;&gt; ${log_file}

        echo -e "\n-- dump bigterastore output: --" &gt;&gt; ${log_file}
        for each_ip in ${all_mon_ips}
        do
            for each_id in ${osd_ids}
            do
                echo -e "\n[${each_ip}] osd.${each_id} perf dump bigterastore info" &gt;&gt; ${log_file}
                perf_info=`ceph daemon osd.${each_id} perf dump bigterastore`
                cur_date="`date +%Y-%m-%d,%H:%m:%s`" 
                echo -e [${cur_date}] [${each_ip}] "${perf_info}" &gt;&gt; ${log_file}
            done
        done
        sleep 0.5

        for each_ip in ${all_mon_ips}
        do
            cur_date="`date +%Y-%m-%d,%H:%m:%s`" 
            cache_info=`ssh ${each_ip} 'df -ih /data/cache/*'`
            echo -e "\n[${each_ip}  cache inode usage info" &gt;&gt; ${log_file}
            echo -e [${cur_date}] "\n${cache_info}" &gt;&gt; ${log_file}
            sleep 1
        done
        i=`expr $i + 1`
        sleep 600
    fi
done
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell正则简介</title>
    <url>/2021/09/29/shell_regex/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>正则表达式，简称"regex"，是一种用于处理字符串的强大工具。它有自己的语法和运算符，我们可以通过这些运算符来创建所有类型的模式。在Shell编程中，它用于行匹配，文本搜索，数据验证等，通常用于 grep、sed、awk 等命令中。</p>
<h1 id="shi-yong-chang-jing">使用场景</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>查找包含特定字符串的文件：可以使用grep命令结合正则表达式来查找包含特定模式的文件。例如，<code>grep 'pattern' filename</code>会在文件filename中查找所有包含pattern的行，并将这些行输出到终端。</p>
</li>
<li class="lvl-2">
<p>替换文本：在处理文本时，经常需要将某些内容替换为其他内容。正则表达式可以用来定义要匹配的模式，然后将其替换掉。例如，使用sed命令替换文件中的所有数字为"X"，可以使用命令<code>sed -i 's/ [0-9] */X/g' filename</code>。</p>
</li>
<li class="lvl-2">
<p>提取信息：有时候需要从大量数据中提取出特定的信息。例如，使用awk命令提取所有以"-"开头的行，可以使用命令<code>awk '/^-/ {print}' filename</code>。</p>
</li>
<li class="lvl-2">
<p>过滤空行和注释：在处理配置文件或其他类型的文本文件时，可能需要过滤掉空行和注释。例如，使用grep命令过滤掉以空格开头的行（即注释行），可以使用命令<code>grep -v '^\s' filename</code>。</p>
</li>
<li class="lvl-2">
<p>匹配手机号码：在处理用户输入或其他数据时，可能需要验证输入是否符合某种格式，比如手机号码。可以使用正则表达式来定义手机号码的模式，并检查输入是否符合该模式。</p>
</li>
<li class="lvl-2">
<p>去除注释行：在编辑配置文件或其他文档时，注释行可能会干扰脚本的执行。可以使用正则表达式来识别并去除这些注释行，以便专注于实际的内容。</p>
</li>
<li class="lvl-2">
<p>特殊字符和元字符的使用：正则表达式中包含多种特殊字符和元字符，如^用于匹配行首，$用于匹配行尾，.用于匹配任意单个字符等。这些特殊字符和元字符使得正则表达式能够灵活地描述复杂的匹配模式。</p>
</li>
</ul>
<p>总结来说，Shell的正则表达式提供了一种强大而灵活的方式来处理文本数据。通过学习和掌握正则表达式的各种特性和用法，可以在Shell脚本中实现复杂的文本处理任务。</p>
<h1 id="shi-li-shuo-ming">示例说明</h1>
<h2 id="ru-men-pian">入门篇</h2>
<p>.: 它匹配任何单个字符。例如，.ar可以匹配"car"中的‘car’，"bar"中的’bar’，"war"中的’war’等等。</p>
<pre><code class="language-bash">   echo "car bar war" | grep '.ar' 
   # 输出: car bar  war
</code></pre>
<p><em>: 它匹配零个或多个先前的字符。例如，ca</em>r可以匹配‘r’，‘car’，‘caar’，'caaar’等等。</p>
<pre><code class="language-bash">   echo "r car caar caaar" | grep 'ca*r' 
   # 输出: r car caar caaar
</code></pre>
<p>?: 它匹配零个或一个先前的字符。例如，ca?r可以匹配‘cr’，‘car’。</p>
<pre><code class="language-bash">   echo "cr car caar" | grep 'ca?r' 
   # 输出: cr car
</code></pre>
<p>[]: 它匹配括号内的任何字符。例如，c[ae]r可以匹配’car’或者’cer’。</p>
<pre><code class="language-bash">   echo "car cer" | grep 'c[ae]r' 
   # 输出: car cer
</code></pre>
<pre><code class="language-bash">   echo "car cer cor" | grep 'c[^ae]r' 
   # 输出: cor
</code></pre>
<p>-: 在方括号内用于指定范围。例如，[0-9]可以匹配任何数字，[a-z]可以匹配任何小写字母。</p>
<pre><code class="language-bash">   echo "123 abc" | grep '[0-9]' 
   # 输出: 123 abc
</code></pre>
<p>: 用于转义特殊字符。</p>
<pre><code class="language-bash">   echo "123 * abc" | grep '\*' 
   # 输出: 123 * abc
</code></pre>
<p>需要注意的是一些元字符*, ., ?在正则表达式中有特殊意义，如果你要匹配的字符串中就包含这些字符，那么需要在此字符前面添加\进行转义。以上正则表达式的运算符均假设你正在使用grep作为模式引擎。如果你使用sed或awk等别的工具，可能匹配的结果会略有不同。</p>
<h2 id="ji-chu-pian">基础篇</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>1.基本字符匹配</p>
</li>
</ul>
<p>使用场景：匹配包含特定字符的字符串。示例：</p>
<pre><code class="language-shell">echo "hello world" | grep "lo"
</code></pre>
<p>注释：上述命令会匹配包含 “lo” 的行。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>2.特殊字符</p>
</li>
</ul>
<p>使用场景：匹配特殊字符，如 .（任意单个字符）。示例：</p>
<pre><code class="language-shell">echo "hello.world" | grep "\."
</code></pre>
<p>注释：由于 . 在正则表达式中是特殊字符，表示任意单个字符，所以需要用反斜杠 \ 进行转义。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>3.字符类</p>
</li>
</ul>
<p>使用场景：匹配某一类字符，如 [abc]（a、b 或 c 中的任意一个）。示例：</p>
<pre><code class="language-shell">echo "apple, banana, cherry" | grep "[bc]herry"
</code></pre>
<p>注释：上述命令会匹配 “cherry” 或 “bherry”。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>4.范围匹配</p>
</li>
</ul>
<p>使用场景：匹配一个范围内的字符，如 [a-z]（任意小写字母）。示例：</p>
<pre><code class="language-shell">echo "Hello, World!" | grep "[A-Z]"
</code></pre>
<p>注释：上述命令会匹配包含大写字母的行。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>5.量词</p>
</li>
</ul>
<p>使用场景：指定字符出现的次数，如 *（零次或多次）。示例：</p>
<pre><code class="language-shell">echo "hello, helloo, hellooo" | grep "l*"
</code></pre>
<p>注释：上述命令会匹配所有包含 “l” 的行，无论 “l” 出现多少次。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>6.锚点</p>
</li>
</ul>
<p>使用场景：匹配字符串的开始或结束，如 ^（字符串开始）和 $（字符串结束）。示例：</p>
<pre><code class="language-shell">echo "first line
second line
third line" | grep "^second"
</code></pre>
<p>注释：上述命令会匹配以 “second” 开始的行。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>7.组合使用</p>
</li>
</ul>
<p>使用场景：组合使用多个正则表达式元素进行复杂匹配。示例：</p>
<pre><code class="language-shell">echo "user:x:1000:1000:User,,,:/home/user:/bin/bash" | grep -oP '(?&lt;=:)\d+(?=:)'
</code></pre>
<p>注释：上述命令使用 Perl 兼容正则表达式（-oP 选项）来匹配两个冒号之间的数字。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>8.扩展正则表达式（ERE）</p>
</li>
</ul>
<p>使用场景：使用扩展正则表达式进行更复杂的模式匹配。示例：</p>
<pre><code class="language-shell">echo "The quick brown fox" | grep -E "q.*f"
</code></pre>
<p>注释：-E 选项启用扩展正则表达式，上述命令会匹配 “q” 后面紧跟 “f” 的行，中间可以有任意字符。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>9.使用 sed 进行文本替换</p>
</li>
</ul>
<p>使用场景：使用 sed 命令进行文本替换。示例：</p>
<pre><code class="language-shell">echo "hello world" | sed 's/hello/hi/'
</code></pre>
<p>注释：上述命令将 “hello” 替换为 “hi”。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>10.使用 awk 进行模式匹配和字段处理</p>
</li>
</ul>
<p>使用场景：使用 awk 命令进行模式匹配和字段处理。示例：</p>
<pre><code class="language-shell">echo -e "apple:1\nbanana:2\ncherry:3" | awk '/^ba/ {print $2}'
</code></pre>
<p><strong>注释：</strong></p>
<p>上述命令会打印出以 “ba” 开头的行的第二字段。</p>
<p>这些是一些基本的正则表达式使用场景和示例。正则表达式的能力远不止这些，它们可以用于非常复杂的文本处理任务。</p>
<h2 id="jin-jie-pian">进阶篇</h2>
<p>在Shell脚本中使用正则表达式进行高级文本搜索，主要可以通过grep命令来实现。grep（global search regular expression and print out the line）是一个非常强大的文本搜索工具，它支持使用正则表达式来搜索文本，并将匹配的行打印出来。以下是一些基本的用法示例：</p>
<h3 id="ji-ben-sou-suo">基本搜索</h3>
<p>如果你想要查找包含特定字符串的行，可以简单地使用grep命令加上该字符串。例如，<code>grep "example"</code>会在当前目录下的所有文件中搜索包含"example"的行。</p>
<p>使用正则表达式进行复杂搜索：当需要进行更复杂的搜索时，可以利用正则表达式的强大功能。例如，如果你想查找所有以"word"开头，后面跟着任意数量的字符（包括零个字符），并且以"end"结尾的行，可以使用如下命令：</p>
<pre><code class="language-shell">grep '^\w*word.*end$'
</code></pre>
<p>这里，^和$分别表示行的开始和结束，\w*匹配任意数量的单词字符（等价于[a-zA-Z0-9_]），.*匹配任意数量的任意字符。</p>
<h3 id="hu-lue-da-xiao-xie-sou-suo">忽略大小写搜索</h3>
<p>有时可能需要忽略大小写的搜索结果。在grep命令中添加-i选项可以实现这一点。例如，<code>grep -i 'example'</code>会忽略大小写地搜索包含"example"的行。</p>
<p>搜索多个文件：如果想要在一个或多个特定的文件中搜索，可以直接在grep命令后指定文件名。如果想搜索当前目录及其子目录下的所有文本文件（.txt, .log, 等），可以使用通配符*和?，或者使用递归搜索的方法。例如：</p>
<pre><code class="language-shell">grep 'example' *.txt
grep 'example' .
</code></pre>
<h3 id="gao-liang-xian-shi-pi-pei-de-xing">高亮显示匹配的行</h3>
<p>虽然grep本身不直接支持高亮显示匹配的行，但可以通过管道传递给其他命令如less或grep | less -R来实现这一功能，这在处理大量数据时特别有用。</p>
<p>通过上述方法，可以在Shell脚本中有效地使用正则表达式进行高级文本搜索。需要注意的是，正则表达式的语法非常丰富和强大，因此建议深入学习正则表达式的相关知识，以便能够灵活地应用于各种复杂的搜索场景中。</p>
<h1 id="zheng-ze-biao-da-shi-zhong-de-te-shu-zi-fu-he-yuan-zi-fu-you-na-xie-ta-men-ge-zi-you-shi-yao-yong-tu">正则表达式中的特殊字符和元字符有哪些，它们各自有什么用途？</h1>
<p>正则表达式中的特殊字符和元字符是用于定义匹配字符串模式时具有特殊含义的字符。这些字符在正则表达式中扮演着重要的角色，使得一个正则表达式可以匹配字符串集合而不只是一个字符串。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>特殊字符：特殊字符定义了字符集合、子组匹配、模式重复次数等。例如，\d可以匹配0到9之间的任何数字。特殊字符还包括用于定义字符集合的方括号[ ]，它允许指定一系列特定的字符进行匹配。</p>
</li>
<li class="lvl-2">
<p>元字符：元字符不代表它们本身的字面意思，而是有特殊的含义。一些常见的元字符包括：<br>
\d：匹配数字（等同于 [0-9]）。<br>
\w：匹配字母或数字或下划线或汉字等。<br>
.：匹配任意单个字符除了换行符。<br>
*：表示前面的元素可以出现零次或多次。<br>
^：匹配输入字符串的开始位置。<br>
$：匹配输入字符串的结束位置。<br>
[]：用于定义字符集合，匹配方括号内的任意一个字符。<br>
()：用于捕获匹配的子串，可以后续引用。</p>
</li>
</ul>
<p>这些元字符和特殊字符的使用极大地扩展了正则表达式的功能，使得它们能够灵活地应用于各种文本处理任务中，如搜索、替换、验证等场景。通过组合这些元字符和特殊字符，可以构建出复杂的正则表达式来精确地描述所需的匹配模式。</p>
<h1 id="zai-shell-jiao-ben-zhong-ru-he-jie-he-grep-sed-he-awk-ming-ling-shi-yong-zheng-ze-biao-da-shi-jin-xing-fu-za-de-shu-ju-chu-li">在Shell脚本中，如何结合grep、sed和awk命令使用正则表达式进行复杂的数据处理？</h1>
<p>在Shell脚本中，结合grep、sed和awk命令使用正则表达式进行复杂的数据处理，可以通过以下步骤实现：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用grep筛选匹配模式的行：首先，可以利用grep命令根据正则表达式来筛选出需要处理的文本行。grep常用于字符串搜索功能，可以有效地筛选出需要的文本。</p>
</li>
<li class="lvl-2">
<p>使用sed进行文本替换、删除和插入：筛选出需要处理的行后，可以使用sed命令对这些行进行进一步的处理，如替换、删除或插入文本。sed以行为单位对文本进行处理，适用于简单的文本编辑任务。</p>
</li>
<li class="lvl-2">
<p>使用awk进行细粒度的文本处理：最后，可以使用awk命令对文本进行更细致的处理。awk允许指定分隔符将一行（一条记录）划分为多个字段，然后以字段为单位处理文本。这使得awk几乎可以实现grep和sed所能实现的所有功能，但提供了更高的灵活性和控制能力。</p>
</li>
</ul>
<p>例如，如果想要从一个包含大量行的文件中提取所有电子邮件地址，并删除它们末尾的域名部分，可以按照以下步骤操作：</p>
<p>使用grep配合正则表达式筛选出所有包含电子邮件地址的行。使用sed对这些行进行处理，例如使用<code>sed 's/.*@$.*$\..*/\1/'</code>命令来删除每个电子邮件地址末尾的域名部分。最后，使用awk对结果进行格式化或其他高级处理。</p>
<p>通过这种方式，结合使用这三个命令不仅可以提高数据处理的效率，还可以根据具体需求灵活地定制数据处理流程。每个命令都有其独特的功能和优势，合理地结合使用它们可以使Shell脚本在处理复杂数据时更加高效和强大。</p>
<h1 id="zheng-ze-biao-da-shi-zai-guo-lu-te-ding-ge-shi-shu-ju-ru-shou-ji-hao-ma-shi-de-zui-jia-shi-jian-shi-shi-yao">正则表达式在过滤特定格式数据（如手机号码）时的最佳实践是什么？</h1>
<p>在过滤特定格式数据（如手机号码）时，正则表达式的最佳实践包括以下几点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>明确目标：首先，需要明确你想要匹配的数据的格式。例如，对于手机号码，通常是以数字开头，长度为11位的纯数字。</p>
</li>
<li class="lvl-2">
<p>使用精确的字符集：为了精确匹配手机号码，可以使用\d来代表任何数字字符，这样可以确保只匹配数字部分，避免误匹配其他字符。</p>
</li>
<li class="lvl-2">
<p>考虑不同的地区格式：不同的国家和地区可能有不同的手机号码格式。因此，在设计正则表达式时，需要考虑到这些差异，并相应地调整正则表达式以匹配特定地区的格式。</p>
</li>
<li class="lvl-2">
<p>避免过度复杂化：虽然正则表达式非常强大，但过度复杂的表达式可能会导致难以理解和维护的问题。应该尽量保持正则表达式的简洁性，同时确保其能够准确匹配目标数据。</p>
</li>
<li class="lvl-2">
<p>测试和验证：在实际应用中，应该对正则表达式进行充分的测试，确保它能够正确匹配预期的数据。这包括测试各种边界情况和异常情况，以验证正则表达式的准确性和鲁棒性。</p>
</li>
<li class="lvl-2">
<p>避免常见的陷阱：在编写正则表达式时，需要注意避免一些常见的陷阱，比如贪婪匹配、非贪婪匹配的选择等。正确的选择可以帮助提高正则表达式的性能和可读性。</p>
</li>
</ul>
<p>总结来说，过滤特定格式数据（如手机号码）时，最佳实践包括明确目标、使用精确的字符集、考虑地区差异、避免过度复杂化、进行充分的测试和验证，以及避免常见的陷阱。通过遵循这些原则，可以有效地使用正则表达式来过滤和校验特定格式的数据。</p>
<h1 id="ru-he-you-hua-zheng-ze-biao-da-shi-de-xing-neng-te-bie-shi-zai-chu-li-da-liang-shu-ju-shi">如何优化正则表达式的性能，特别是在处理大量数据时？</h1>
<p>在处理大量数据时，优化正则表达式的性能是至关重要的。我们可以总结出以下几点建议：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用原始字符串：在Python中，使用原始字符串来表示正则表达式可以提高效率。</p>
</li>
<li class="lvl-2">
<p>使用缓存：如果正则表达式需要多次使用，将其缓存在变量中可以提高性能。</p>
</li>
<li class="lvl-2">
<p>使用非捕获组：非捕获组不会存储匹配项，这有助于提高正则表达式的性能。</p>
</li>
<li class="lvl-2">
<p>避免使用反向引用：反向引用可能会导致性能问题。</p>
</li>
<li class="lvl-2">
<p>少用贪婪模式：贪婪模式会引起回溯问题，使用独占模式来避免回溯可以提高性能。</p>
</li>
<li class="lvl-2">
<p>减少分支选择：尽量减少分支选择类型“(X|Y|Z)”的使用，以避免不必要的性能损耗。</p>
</li>
<li class="lvl-2">
<p>使用更精确的匹配方式：尽量避免使用通用的匹配方式，如使用具体的字符集合或具体的字符范围进行匹配，这样可以减少不必要的搜索空间，从而提高匹配效率。</p>
</li>
<li class="lvl-2">
<p>使用更为精确的字符：不随意使用 .* 来匹配字段，因为这个表达式包含了很大的搜索空间，容易发生误匹配，应该尽量避免。</p>
</li>
</ul>
<p>通过采用上述策略，可以在处理大量数据时显著提高正则表达式的性能。这些技巧不仅适用于特定编程语言（如Python和JavaScript），而且对于任何需要高效处理文本数据的场景都是适用的。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Monitor mds failed</title>
    <url>/2021/11/04/monitor_mds_failed/</url>
    <content><![CDATA[<h1 id="scripts">Scripts</h1>
<p><code>monitor_mds_failed.sh</code></p>
<pre><code class="language-shell">#!/bin/bash

if read -t 5 -p "WARN: Have you confirmed that the maximum number of active-mds has been set for VS? [y|n] :" yn
then
    if [[ $yn == [Yy] ]];then
        echo -e 'Running...'
    elif [[ $yn == [Nn] ]];then
        echo -e "\e[0;31;1mExit ...\e[0m"
        exit
    else [[ $yn != [YyNn] ]]
        echo -e "\e[0;33;1mPlease check what you input! Only can input y or n\e[0m"
        exit
    fi
else
    echo " "
    echo -e "\e[0;33;1mTimeOut ...\e[0m"
    exit
fi


log_file="mds_failed.log"

rm -rf ${log_file}

echo -e "  To stop all of btmds-agent for all enabled GW nodes"
onnode -p all '/usr/bin/python /usr/local/bin/btmds-agent stop'

for i in {1..1000}; 
do
    echo "--------------------------- ${i} ----------------------" &gt;&gt; ${log_file}
    date_time1=`date '+%Y-%m-%d %H:%M:%S'`
    echo -e "  --  [${date_time1}]  restart ceph-mds.target on all nodes" &gt;&gt; ${log_file}
    onnode -p all systemctl restart ceph-mds.target;sleep 5

    date_time2=`date '+%Y-%m-%d %H:%M:%S'`
    echo -e "  --  [${date_time2}]  Check mds failed status" &gt;&gt; ${log_file}
    for j in {0..100000}
    do
        res=`ceph -s | grep 'mds:'`
        if [[ ${res} =~ 'failed' ]];then
            date_time3=`date '+%Y-%m-%d %H:%M:%S'`
            msg="[${date_time3}]  [ERROR]  Find failed ceph-mds, exit!!"
            echo -e ${msg} 
            echo -e ${msg} &gt;&gt; ${log_file}
            exit
        else
            date_time4=`date '+%Y-%m-%d %H:%M:%S'`
            echo -e "--  [${date_time4}]  [${j}]time(s), not find failed mds, sleep 5s will try again" &gt;&gt; ${log_file}
            sleep 5
            if [[ ${j} -gt 19 ]];then
                break
            fi
        fi
    done
done

</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>ceph</tag>
        <tag>mds</tag>
      </tags>
  </entry>
  <entry>
    <title>ceph PG auto repair</title>
    <url>/2021/11/23/pg_auto_repair/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>From Nari, needs a script to help him to auto repair PG.</p>
<h1 id="script">script</h1>
<p><code>inconsistent_pg_repair.py</code></p>
<pre><code class="language-python">import os
import sys
import gzip
import json
import time
import errno
import select
import atexit
import socket
import logging
import commands
import traceback
import logging.handlers

from threading import Event
from fcntl import flock, LOCK_EX, LOCK_NB
from signal import signal, SIGTERM, SIGKILL, SIGUSR1


class Daemon(object):
    """
    A generic daemon class.

    Usage: subclass the Daemon class and override the run() method
    """
    def __init__(self, pidfile, stdin='/dev/null', stdout='/dev/null', stderr='/dev/null', kill_timeout=90):
        """
        Constructor.

        @param  pidfile:    path of the pid file
        @type   pidfile:    string
        @param  stdin:      path of the stdin
        @type   stdin:      string
        @param  stdout:     path of the stdout
        @type   stdout:     string
        @param  stderr:     path of the stderr
        @type   stderr:     string
        """
        self.stdin = stdin
        self.stdout = stdout
        self.stderr = stderr
        self.pidfile = pidfile
        self.lock_fd = -1
        self._kill_timeout = kill_timeout
        self._daemon_stopped = Event()
        self.first_loop = True

    def daemonize(self):
        """
        do the UNIX double-fork magic, see Stevens' "Advanced
        Programming in the UNIX Environment" for details (ISBN 0201563177)
        http://www.erlenstar.demon.co.uk/unix/faq_2.html#SEC16
        """
        try:
            pid = os.fork()
            if pid &gt; 0:
                # exit first parent
                sys.exit(0)
        except OSError as e:
            sys.stderr.write("fork #1 failed: %d (%s)\n" % (e.errno, e.strerror))
            sys.exit(1)

        # decouple from parent environment
        os.chdir("/")
        os.setsid()
        os.umask(0)

        # do second fork
        try:
            pid = os.fork()
            if pid &gt; 0:
                # exit from second parent
                sys.exit(0)
        except OSError as e:
            sys.stderr.write("fork #2 failed: %d (%s)\n" % (e.errno, e.strerror))
            sys.exit(1)

        # redirect standard file descriptors
        sys.stdout.flush()
        sys.stderr.flush()
        si = open(self.stdin, 'r')
        so = open(self.stdout, 'a+')
        se = open(self.stderr, 'a+b', 0)
        os.dup2(si.fileno(), sys.stdin.fileno())
        os.dup2(so.fileno(), sys.stdout.fileno())
        os.dup2(se.fileno(), sys.stderr.fileno())

        # write pidfile
        atexit.register(self.delpid)
        pid = str(os.getpid())
        open(self.pidfile,'w+').write("%s\n" % pid)

    def delpid(self):
        """
        Delete the pid file.
        """
        os.remove(self.pidfile)

    def lock_or_exit(self):
        try:
            self.lock_fd = os.open(self.pidfile, 
                                   os.O_CREAT|os.O_TRUNC|os.O_WRONLY|os.O_EXCL,
                                   0o666)
        except OSError as e:
            if e.errno == errno.EEXIST:
                self.lock_fd = os.open(self.pidfile,os.O_WRONLY)
            else:
                sys.stderr.write(
                    u"Can not create pidfile : {} error {} \n".format(
                        self.pidfile, str(e)
                    )
                )
                sys.exit(1)

        try:
            # flock can be  inherited by child process, even exec()
            flock(self.lock_fd, LOCK_EX | LOCK_NB)
        except IOError as e:
            if e.errno == errno.EAGAIN:
                sys.stderr.write(
                    u"pidfile {} is locked, Daemon already running?\n".format(
                        self.pidfile
                    )
                )
                sys.exit(0)
            else:
                sys.stderr.write(
                    u"failed to lock the pid file {} , error {}".format(
                        self.pidfile, str(e)
                    )
                )
                sys.exit(1)

    def start(self):
        """
        Start the daemon
        """

        self.lock_or_exit()

        # Start the daemon
        self.prepare_start()
        self.daemonize()
        signal(SIGTERM, self.handle_term)
        signal(SIGUSR1, self.handle_siguser1)
        daemon_name = self.__class__.__name__
        try:
            logger.info('Daemon {} start'.format(daemon_name))
            self.run()
            logger.info('Daemon {} stopped'.format(daemon_name))
        except Exception:
            logger.exception('Daemon {} terminates unexpectedly'.format(daemon_name))

    def get_pid(self):
        # Get the pid from the pidfile
        try:
            pid_str = (open(self.pidfile).read().strip())
            if len(pid_str):
                pid = int(pid_str)
            else:
                pid = None
        except IOError:
            pid = None
        return pid

    def stop(self):
        """
        Stop the daemon
        """
        pid = self.get_pid()

        if not pid:
            message = "pidfile %s does not exist. Daemon not running?\n"
            sys.stderr.write(message % self.pidfile)
            return  # not an error in a restart

        # Try killing the daemon process
        try:
            waiting_killed = 0
            while 1:
                if waiting_killed == 0:
                    os.kill(pid, SIGTERM)
                elif waiting_killed &lt; self._kill_timeout:
                    os.kill(pid, 0)
                else:
                    # Use kill pg to force kill all subprocess
                    os.killpg(os.getpgid(pid), SIGKILL)
                time.sleep(1)
                waiting_killed = waiting_killed + 1
        except OSError as err:
            err = str(err)
            if err.find("No such process") &gt; 0:
                if os.path.exists(self.pidfile):
                    os.remove(self.pidfile)
            else:
                print(str(err))
                sys.exit(1)

    def restart(self):
        """
        Restart the daemon
        """
        self.stop()
        self.start()

    def prepare_start(self):
        """
        You should override this method when you subclass Daemon. It will be called before the process has been
        daemonized by start() or restart().
        """

    def run(self):
        """
        You should override this method when you subclass Daemon. It will be called after the process has been
        daemonized by start() or restart().
        """

    def terminate(self):
        """
        You should override this method when you subclass Daemon. It will be called after the process has been
        daemonized by stop() or restart().
        """
    
    def user_signal_1(self):
        """
        You may override this method when you subclass Daemon.
        The default method toogle to change the loglevel from between debug and info
        """

        new_level = logging.INFO if EZLog.getLevel() == logging.DEBUG else logging.DEBUG
        EZLog.setLevel(new_level)
        logger.info('Daemon {} log level is chaged to {}'.format(
            self.__class__.__name__,
            'debug ' if new_level == logging.DEBUG else 'info'))

    def is_daemon_running(self, wait=0):
        # do not wait for first loop
        if self.first_loop and wait &gt; 0:
            wait = 0
            self.first_loop = False
        return not self._daemon_stopped.wait(wait)

    def handle_term(self, sig, frm):
        logger.info('Got signal: {}'.format(sig))
        if self.is_daemon_running():
            self._daemon_stopped.set()
            self.terminate()

    def handle_siguser1(self, sig, frm):
        logger.info('Got signal: {}'.format(sig))
        self.user_signal_1()


class BtLogger():

    def __init__(self, log_name, log_file_name, log_level=logging.DEBUG, max_bytes=5*1024*1024, backup_count=5):

        self.logger = logging.getLogger(log_name)
        self.logger.setLevel(logging.DEBUG)
        formatter = logging.Formatter('%(asctime)s %(filename)-8s[line:%(lineno)-4s] [%(levelname)-5s] %(message)s')

        self.h_rotating_file = logging.handlers.RotatingFileHandler(log_file_name, maxBytes=max_bytes, backupCount=backup_count)
        self.h_rotating_file.setFormatter(formatter)
        self.h_rotating_file.rotator = self._rotator
        self.h_rotating_file.namer = self._namer
        self.h_stream = logging.StreamHandler(sys.stdout)
        self.h_stream.setFormatter(formatter)

        self.h_rotating_file.setLevel(log_level)
        self.h_stream.setLevel(logging.INFO)
        self.logger.addHandler(self.h_rotating_file)
        self.logger.addHandler(self.h_stream)

    def _namer(self, name):
        return name + ".gz"

    def _rotator(self, source, dest):
        with open(source, "rb") as sf:
            data = sf.read()
            with gzip.open(dest, "wb") as gf:
                gf.write(data)
        os.remove(source)

    def get_logger(self):
        return self.logger


sleep_time = 1 * 60 * 1
logger = BtLogger(__name__, "/var/log/inconsistent_pg_repair.log", log_level=logging.DEBUG).get_logger()


class RepairDaemon(Daemon):
    """ Repari inconsistent PG in daemon  """

    @staticmethod
    def pg_not_health():
        unhealth_pg = ["scrubbing", "nearfull", "incomplete", "full", "backfill",
                       "degraded", "remapped", "stale", "recovering"]
        pg_stat = commands.getoutput('ceph pg stat').strip()
        for each_unhealth_pg in unhealth_pg:
            if each_unhealth_pg in pg_stat:
                logger.error("[ERROR]  Find unhealth PG : (%s), do nothing, exit!!!", each_unhealth_pg)
                sys.exit(2)

    @staticmethod
    def get_inconsistent_pg():
        inconsistent_pg = []
        res = commands.getoutput("/usr/bin/ceph --connect-timeout=10 health detail | "
                                 "grep inconsistent | grep acting").strip()

        if res:
            if 'failed_repair' in res:
                logger.error("[ERROR]  Find 'failed_repair' PG, do nothing, exit!!!")
                sys.exit(2)

            for each_element in res.split('\n'):
                inconsistent_pg.append(each_element.strip().split()[1])

            # Remove duplicate and None element
            inconsistent_pg = {}.fromkeys(inconsistent_pg).keys()
            inconsistent_pg = filter(None, inconsistent_pg)
            logger.debug("Find inconsistent PG : (%s)", inconsistent_pg)
            return inconsistent_pg
        else:
            logger.debug("Not find inconsistent PG.")
            return inconsistent_pg

    def auto_repair(self, pg_name):
        """
        Run 'ceph pg reapir pg_name', try to repair PG
        :param pg_name, string, a PG id
        """
        repair_cmd = "ceph pg repair {}".format(pg_name)
        logger.info("Starts to repair PG : (%s), command : (%s)", pg_name, repair_cmd)
        repair_res = commands.getoutput(repair_cmd)

        health_res = commands.getoutput('/usr/bin/ceph --connect-timeout=10 -s').strip()
        if 'failed_repair' in health_res:
            logger.error("[ERROR]  Repair PG :(%s) failed, please pay more attention!!!!!")
            sys.exit(1)
        else:
            logger.info("Repair PG : (%s) result : (%s), now sleep (%s)", pg_name, repair_res, sleep_time)
            time.sleep(sleep_time) 

    def list_inconsistent_obj_repair(self):
        """
        List inconsistent object for each inconsistent PG before, then repair
        """
        self.pg_not_health()

        inconsistent_pg = self.get_inconsistent_pg()
        if len(inconsistent_pg) &gt; 3:
            logger.warn("[WARN]  Found more than 3 abnormal PGs, suggest to repair manually, exits!!!")
            sys.exit(3)

        if len(inconsistent_pg):
            for each_pg in inconsistent_pg:
                list_cmd = "rados list-inconsistent-obj {} --format=json-pretty".format(each_pg)
                list_res = commands.getoutput(list_cmd)
                logger.debug("rados list-inconsistent-obj %s : (%s)", each_pg, list_res)
                if list_res and len(json.loads(list_res)['inconsistents']):
                    logging.warn("Find inconsistent PG : (%), now reapir "
                                 "(%s)",json.loads(list_res)['inconsistents'], each_pg)
                    self.auto_repair(each_pg)
                else:
                    logging.warn("PG in inconsistent, but list inconsistent object is None, skip to repair!!!")
        else:
            logger.info("Not find inconsistent PG, skip.")

    def run(self):
        logger.info("Repair inconsistent PG Daemon starts run")

        while self.is_daemon_running(wait=30):
            try:
                self.list_inconsistent_obj_repair()
            except Exception:
                logger.error("ezsnapsched exception: {}".format(traceback.format_exc()))


if __name__ == '__main__':
    daemon = RepairDaemon('/var/run/bt-repair.pid')
    if len(sys.argv) == 2:
        if 'start' == sys.argv[1]:
            daemon.start()
        elif 'stop' == sys.argv[1]:
            daemon.stop()
        elif 'restart' == sys.argv[1]:
            daemon.restart()
        else:
            print "Unknown command"
            sys.exit(2)
        sys.exit(0)
    else:
        print "usage: %s start|stop|restart" % sys.argv[0]
        sys.exit(2)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Delay the first auto start VM in PVE</title>
    <url>/2021/12/13/pve_vm_delay_boot/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>一直以来，认为PVE提供的“延时启动”是针对宿主机完成启动后的XX设定的时间后VM自动启动，直到看到如下链接的内容中：<br>
<a href="https://dannyda.com/2020/06/24/how-to-delay-the-first-auto-start-virtual-machinevm-guest-system-in-proxmox-ve-pve/">https://dannyda.com/2020/06/24/how-to-delay-the-first-auto-start-virtual-machinevm-guest-system-in-proxmox-ve-pve/</a></p>
<p>明确说明PVE VM boot delay并不是我们所想的：宿主机启动后XX秒再启动VM，而是：定义此VM启动与后续VM启动之间的间隔。说明第一台VM启动，依然存在失败问题（存储尚未ready，VM开始启动）。</p>
<h1 id="ui-she-ding-de-yan-shi-qi-dong">UI 设定的“延时启动”</h1>
<p>UI展示VM开机自启动，这里的设置来自qm指令</p>
<pre><code class="language-shell">root@node165:/etc/systemd/system/multi-user.target.wants# qm list
      VMID NAME                 STATUS     MEM(MB)    BOOTDISK(GB) PID       
       100 Scaler186            stopped    4096              32.00 0         
       101 scaler182            stopped    131072            64.00 0         
       103 Scaler103            running    131072            64.00 65598     
       106 Scaler106            running    131072            64.00 266948    
root@node165:/etc/systemd/system/multi-user.target.wants# qm set 106 -startup up=300
update VM 106: -startup up=300

root@node165:/etc/systemd/system/multi-user.target.wants#
</code></pre>
<p>做了上面的变更后，UI对应VM里的启动试验也跟着变（只是证明一下UI上的设定，来自指令qm set vmid -startup up=xx）。</p>
<h1 id="ru-he-zheng-que-she-zhi-vm-de-qi-dong-shi-yan">如何正确设置VM的启动时延？</h1>
<h2 id="fang-fa-1-shi-yong-startall-onboot-delay-she-zhi">方法1：使用 --startall-onboot-delay 设置</h2>
<p>指令参考如下：</p>
<pre><code class="language-shell">pvenode config set --startall-onboot-delay XXX

--startall-onboot-delay &lt;integer&gt; (0 - 300) ( default = 0 ) Initial delay in seconds, before starting all the Virtual Guests with on-boot enabled.
</code></pre>
<p>这个参数的设定，上限是300秒，如果想调整成更大的数值，可以修改如下文件(示例设置为400秒):</p>
<pre><code class="language-shell">root@node165:/etc/pve# grep -nri 400
nodes/node165/config:1:startall-onboot-delay: 400
</code></pre>
<h2 id="fang-fa-2-xiu-gai-pve-guests-service-pve-guests-zeng-jia-sleep">方法2：修改 pve-guests.service pve-guests，增加sleep</h2>
<pre><code class="language-shell">cat /etc/systemd/system/multi-user.target.wants/pve-guests.service pve-guests
</code></pre>
<p>会看到如下部分的内容（有省略）：</p>
<pre><code class="language-shell">[Service]
Environment="PVE_LOG_ID=pve-guests"
ExecStartPre=-/usr/share/pve-manager/helpers/pve-startall-delay
</code></pre>
<p>在如上内容中，增加如下内容（注意两个ExecStartPre的顺序）：</p>
<pre><code class="language-shell">[Service]
Environment="PVE_LOG_ID=pve-guests"
ExecStartPre=/bin/sleep 400
ExecStartPre=-/usr/share/pve-manager/helpers/pve-startall-delay
</code></pre>
]]></content>
      <categories>
        <category>PVE</category>
      </categories>
      <tags>
        <tag>PVE</tag>
        <tag>proxmox ve</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest allure详解</title>
    <url>/2021/11/04/pytest_allure/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文基于allure 2.13.2 版本介绍allure在pytest下的基本运用。</p>
<p>关于allure，详见官网： <code> https://github.com/allure-framework</code>。</p>
<h1 id="allure-gong-neng-jie-shao">allure功能介绍</h1>
<h2 id="allure-te-xing">allure 特性</h2>
<p>allure有如下特性：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;python
Python 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2021, 05:45:37) [MSC v.1934 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import allure
&gt;&gt;&gt; dir(allure)
['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'attach', 'attachment_type', 'description', 'description_html', 'dynamic', 'epic', 'feature', 'id', 'issue', 'label', 'link', 'manual', 'parameter_mode', 'parent_suite', 'severity', 'severity_level', 'step', 'story', 'sub_suite', 'suite', 'tag', 'testcase', 'title']
&gt;&gt;&gt;
</code></pre>
<p>介绍如下：</p>
<table>
<thead>
<tr>
<th>使用方法</th>
<th>参数值</th>
<th>参数说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>allure.attach()</td>
<td>添加附件</td>
<td>给测试用例添加附件</td>
</tr>
<tr>
<td>allure.attachment_type()</td>
<td>附件类型</td>
<td>支持txt/pdf/csv/html/xml/image/video等多种类型</td>
</tr>
<tr>
<td>allure.description()</td>
<td>用例描述</td>
<td>传递一个字符串参数用来描述测试用例</td>
</tr>
<tr>
<td>allure.description_html()</td>
<td>用例描述</td>
<td>传递一段HTML文本，这将在测试报告的"Description"部分渲染出来</td>
</tr>
<tr>
<td>allure.dynamic()</td>
<td>动态指定标题和描述</td>
<td>在测试用例执行过程中动态指定标题和描述等标签的方法，主要指：allure.dynamic.description 和 allure.dynamic.title</td>
</tr>
<tr>
<td>allure.epic()</td>
<td>epic描述</td>
<td>敏捷里的概念，定义史诗，相当于module级的标签</td>
</tr>
<tr>
<td>allure.feature()</td>
<td>模块名称</td>
<td>功能点的描述，往下是story</td>
</tr>
<tr>
<td><a href="http://allure.id">allure.id</a>()</td>
<td>人为给用例添加id</td>
<td>这个标识符将显示在 Allure 报告中，使得识别和引用这个具体的测试更加方便。</td>
</tr>
<tr>
<td>allure.issue()</td>
<td>缺陷链接</td>
<td>对应缺陷管理系统里的链接，如将JIRA里Bug的URL展示在html报告中</td>
</tr>
<tr>
<td>allure.label()</td>
<td>给用例添加label</td>
<td>指定多种类型的标签，例如功能、故事、严重性级别、测试用例ID、发行版本等。</td>
</tr>
<tr>
<td>allure.link()</td>
<td>链接</td>
<td>定义一个链接，在html报告中展示</td>
</tr>
<tr>
<td>allure.manual()</td>
<td>指示一个测试用例是手动执行的，而不是自动化测试</td>
<td>将手动测试用例纳入到自动生成的 Allure 测试报告中，从而在报告中提供一个更全面的测试覆盖视图</td>
</tr>
<tr>
<td>allure.parameter_mode()</td>
<td>处理多种输入条件</td>
<td>在测试用例中使用多组不同的输入参数，从而可以对同一个测试用例进行多次测试，每次使用不同的数据</td>
</tr>
<tr>
<td>allure.parent_suite()</td>
<td>测试套</td>
<td>测试套的三个级别，爷爷父亲儿子中的爷爷这个级别</td>
</tr>
<tr>
<td>allure.severity()</td>
<td>用例级别</td>
<td>测试用例的优先级别，blocker,critical,normal,minor,trivial 五个级别，使用方式：@allure.severity(“BLOCKER”)</td>
</tr>
<tr>
<td>allure.severity_level()</td>
<td>用例级别</td>
<td>测试用例的优先级别，blocker,critical,normal,minor,trivial 五个级别，使用方式：@allure.severity(allure.severity_level.CRITICAL)</td>
</tr>
<tr>
<td>allure.step()</td>
<td>操作步骤</td>
<td>测试用例的步骤，Step1，Step2，… StepN标记在用例中</td>
</tr>
<tr>
<td>allure.story()</td>
<td>用户故事</td>
<td>用户故事，往下是title</td>
</tr>
<tr>
<td>allure.sub_suite()</td>
<td>测试套</td>
<td>测试套的三个级别，爷爷父亲儿子中的儿子这个级别</td>
</tr>
<tr>
<td>allure.suite()</td>
<td>测试套</td>
<td>测试套的三个级别，爷爷父亲儿子中的父亲这个级别</td>
</tr>
<tr>
<td>allure.tag()</td>
<td>Tag</td>
<td>给用例增加tag</td>
</tr>
<tr>
<td>allure.testcase()</td>
<td>测试用例的链接</td>
<td>对应功能/性能测试用例系统里的test case URL，如testlink里的</td>
</tr>
<tr>
<td>allure.title()</td>
<td>用例的标题</td>
<td>展示在html报告中的测试用例的标题名称</td>
</tr>
</tbody>
</table>
<h2 id="allure-shi-jian">allure 实践</h2>
<h3 id="allure-wei-ce-shi-yong-li-tian-jia-fu-jian-attach">allure为测试用例添加附件（attach）</h3>
<h4 id="allure-attach-de-yong-fa">allure.attach的用法</h4>
<h5 id="yong-fa-yi">用法一</h5>
<p>语法：</p>
<p><code>allure.attach(body, name, attachment_type, extension)</code></p>
<p>参数解释：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>body：要写入附件的内容</p>
</li>
<li class="lvl-2">
<p>name：附件名字</p>
</li>
<li class="lvl-2">
<p>attachment_type：附件类型，是allure.attachment_type其中的一种</p>
</li>
<li class="lvl-2">
<p>extension：附件的扩展名</p>
</li>
</ul>
<h5 id="yong-fa-er">用法二</h5>
<p>语法：</p>
<pre><code class="language-shell">allure.attach.file(source, name, attachment_type, extension)
</code></pre>
<p>参数解释：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>source：文件路径，相当于传一个文件</p>
</li>
<li class="lvl-2">
<p>name：附件名字</p>
</li>
<li class="lvl-2">
<p>attachment_type：附件类型，是allure.attachment_type其中的一种</p>
</li>
<li class="lvl-2">
<p>extension：附件的扩展名</p>
</li>
</ul>
<h4 id="allure-attachment-type-de-suo-you-zhi">allure.attachment_type的所有值</h4>
<pre><code class="language-shell">    TEXT = ("text/plain", "txt")
    CSV = ("text/csv", "csv")
    TSV = ("text/tab-separated-values", "tsv")
    URI_LIST = ("text/uri-list", "uri")
    HTML = ("text/html", "html")

    XML = ("application/xml", "xml")
    JSON = ("application/json", "json")
    YAML = ("application/yaml", "yaml")
    PCAP = ("application/vnd.tcpdump.pcap", "pcap")
    PDF = ("application/pdf", "pdf")

    PNG = ("image/png", "png")
    JPG = ("image/jpg", "jpg")
    SVG = ("image/svg-xml", "svg")
    GIF = ("image/gif", "gif")
    BMP = ("image/bmp", "bmp")
    TIFF = ("image/tiff", "tiff")

    MP4 = ("video/mp4", "mp4")
    OGG = ("video/ogg", "ogg")
    WEBM = ("video/webm", "webm")
</code></pre>
<h4 id="allure-attach-shi-yong-ju-li">allure.attach使用举例</h4>
<h5 id="ce-shi-yong-li-zhong-tian-jia-wen-ben-fu-jian">测试用例中添加文本附件</h5>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure


@pytest.fixture()
def attach_for_text():
    allure.attach(body="前置条件，这是一段文本", name="Test文本01", attachment_type=allure.attachment_type.TEXT)
    yield
    allure.attach(body="后置条件，这是一段文本", name="Test文本02", attachment_type=allure.attachment_type.TEXT)


def test_attachment_text(attach_for_text):
    assert True
</code></pre>
<p>效果如下图所示：</p>
<img class="shadow" src="/img/in-post/allure/attach_text.png" width="1200">
<h5 id="ce-shi-yong-li-zhong-tian-jia-html-fu-jian">测试用例中添加html附件</h5>
<pre><code class="language-python">def test_mutiple_attachments():
    allure.attach.file(r"C:\Users\Wang\Pictures\OIP-C.jpg", attachment_type=allure.attachment_type.JPG)

    allure.attach("""&lt;!doctype html&gt;
&lt;html lang="en-US"&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8" /&gt;
    &lt;meta name="viewport" content="width=device-width" /&gt;
    &lt;title&gt;My test page&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;img src="https://ts1.cn.mm.bing.net/th/id/R-C.2c7e4d41fc29592168145efb4c27f825?rik=EfVURrooBsEe%2bg&amp;riu=http%3a%2f%2fimg.juimg.com%2ftuku%2fyulantu%2f110611%2f9120-110611114P085.jpg&amp;ehk=ruz2W6AZs%2bLUNeJ83%2ferKheRxWYQyYFYt5GGHhnu4BI%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" alt="My test image" /&gt;
  &lt;/body&gt;
&lt;/html&gt;
""",
attachment_type=allure.attachment_type.HTML)
</code></pre>
<p>效果如下图所示：</p>
<img class="shadow" src="/img/in-post/allure/attach_image.png" width="1200">
<p>如上图所示，html部分可以嵌套图片，也可以写静态文本。</p>
<h3 id="allure-tian-jia-ce-shi-yong-li-bu-zou-allure-step">allure添加测试用例步骤(allure.step)</h3>
<p>在编写自动化测试用例的时候经常会遇到需要编写流程性测试用例的场景，一般流程性的测试用例的测试步骤比较多，在测试用例中添加详细的步骤会<strong>提高测试用例的可阅读性</strong>。</p>
<p>allure提供的装饰器@allure.step()是allure测试报告框架非常有用的功能，它能帮助我们在测试用例中对测试步骤进行详细的描述。</p>
<p>代码示例：</p>
<pre><code class="language-python">    def test_566_rollback_snapshot(self):
        """  Sc-566:Snapshot can be rollbacked correctly  """
        with allure.step("Clean unavailable link device"):
            self.client_unlink_unavailable_device_link(self.client_ip_root_password, self.ssh_port, self.client_ip)

        with allure.step("Client umount mount point"):
            self.client_umount_san_device(gateway_group=self.gateway_group, target_id=self.target_id,
                                          iscsi_id=self.iscsi_id, password=self.client_ip_root_password,
                                          port=self.ssh_port, client_ip=self.client_ip,
                                          mount_point=self.mount_point, check_device=False)
        with allure.step("Client login target"):
            self.client_login_logout_target(self.client_ip_root_password, self.ssh_port,
                                            self.client_ip, self.target_id, op_type='logout')
            self.client_login_logout_target(self.client_ip_root_password, self.ssh_port,
                                            self.client_ip, self.target_id, op_type='login')

        with allure.step("Client mkfs the device, then input a file, and get the md5 for the file"):
            self.client_mkfs_san_device(gateway_group=self.gateway_group, target_id=self.target_id,
                                        iscsi_id=self.iscsi_id, password=self.client_ip_root_password,
                                        port=self.ssh_port, client_ip=self.client_ip)
            self.client_mount_san_device(gateway_group=self.gateway_group, target_id=self.target_id,
                                         iscsi_id=self.iscsi_id, password=self.client_ip_root_password,
                                         port=self.ssh_port, client_ip=self.client_ip,
                                         mount_point=self.mount_point)

        with allure.step("Copy some files to the mapped drive"):
            self.client_write_file_to_san(password=self.client_ip_root_password, port=self.ssh_port,
                                          client_ip=self.client_ip, mount_point=self.mount_point,
                                          file_name='before_snap.txt', file_content='before_snap')
        time.sleep(60)
        before_md5 = self.get_file_md5(password=self.client_ip_root_password, port=self.ssh_port,
                                       client_ip=self.client_ip, mount_point=self.mount_point,
                                       file_name='before_snap.txt')

        with allure.step("Take a snapshot"):
            self.create_snapshot(gateway_group=self.gateway_group, target_id=self.target_id,
                                 iscsi_id=self.iscsi_id, snap_name='pytest-snapshot02')

        with allure.step("Client umount mount point,"):
            #  if no this step, when logout target will raise in use error in centos
            self.client_umount_san_device(gateway_group=self.gateway_group, target_id=self.target_id,
                                          iscsi_id=self.iscsi_id, password=self.client_ip_root_password,
                                          port=self.ssh_port, client_ip=self.client_ip,
                                          mount_point=self.mount_point, check_device=False)

        with allure.step("Client disconnect the target"):
            self.client_login_logout_target(password=self.client_ip_root_password, port=self.ssh_port,
                                            client_ip=self.client_ip, target_id=self.target_id,
                                            op_type='logout')

        with allure.step("Disable the volume, then rollback snapshot"):
            self.disable_iscsi_volume(target_id=self.target_id, iscsi_id=self.iscsi_id)
            self.rollback_snap(gateway_group=self.gateway_group, target_id=self.target_id,
                               iscsi_id=self.iscsi_id)

        with allure.step("Enable the volume"):
            self.enable_iscsi_volume(gateway_group=self.gateway_group, target_id=self.target_id,
                                     iscsi_id=self.iscsi_id)

        with allure.step("Client connect to the target"):
            self.client_login_logout_target(password=self.client_ip_root_password, port=self.ssh_port,
                                            client_ip=self.client_ip, target_id=self.target_id,
                                            op_type='login')


            self.client_mount_san_device(gateway_group=self.gateway_group, target_id=self.target_id,
                                         iscsi_id=self.iscsi_id, password=self.client_ip_root_password,
                                         port=self.ssh_port, client_ip=self.client_ip,
                                         mount_point=self.mount_point)

        # Get file of md5
        after_md5 = self.get_file_md5(password=self.client_ip_root_password, port=self.ssh_port,
                                      client_ip=self.client_ip, mount_point=self.mount_point,
                                      file_name='before_snap.txt')

        with allure.step("Check md5"):
            errr_msg = "[ERROR]  before_md5 is : ({}), after_md5 is : ({}),  " \
                       "md5 is not same when reconnect to target : ({})".format(before_md5,
                                                                                after_md5,
                                                                                self.target_id)
            eq_(before_md5, after_md5, errr_msg)

        with allure.step("Client umount"):
            self.client_umount_san_device(gateway_group=self.gateway_group, target_id=self.target_id,
                                          iscsi_id=self.iscsi_id, password=self.client_ip_root_password,
                                          port=self.ssh_port, client_ip=self.client_ip,
                                          mount_point=self.mount_point)

        with allure.step("Client disconnect the target"):
            self.client_login_logout_target(password=self.client_ip_root_password, port=self.ssh_port,
                                            client_ip=self.client_ip, target_id=self.target_id,
                                            op_type='logout')

        with allure.step("Delete all snapshot"):
            self.delete_snapshot(gateway_group=self.gateway_group, target_id=self.target_id,
                                 iscsi_id=self.iscsi_id, delete_all_snap=True)
</code></pre>
<p>这里借助with allure.step() 来完成添加step动作。</p>
<p>上述这个示例代码能否再精简呢？答案是肯定的，如果精简？</p>
<p>这里提供一下思路：</p>
<p>如果这个py文件中含有很多的test case，每个test case都需要增加allure.step，且step里描述的内容相同，可以在被调用的各个函数里增加step动作，test case里完全是函数的调用。</p>
<p>示例如下：</p>
<p>比如上例中的 delete_snapshot 函数，可以将class中定义function时，增加allure.step步骤，参考如下：</p>
<pre><code class="language-python">    @allure.step("Delete snapshot")
    def delete_snapshot(self, gateway_group=None, target_id=None, iscsi_id=None, snap_name=None,
                        expected_return_code=None, delete_all_snap=None):
        """
        Delete a snapshot
        :param gateway_group, string, a gateway group name
        :param target_id, string, a target name
        :param iscsi_id, string, a iSCSI volume name
        :param expected_return_code, string, status code of return_code
        :param delete_all_snap, bool. True or False, default is False
        :param snapshot_name, string, snapshot name
        """
</code></pre>
<p>这样的话，在测试用例里调用此函数时，无需再额外增加@allure.step()步骤，有一定的用例编写简化作用。当然也可以在 delete_snapshot 函数里面定义内部的step，形成step的嵌套，这样阅读性会更高一些。</p>
<p>allure.step也<strong>支持添加描述且通过占位符传递参数</strong>，示例代码如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure


import pytest
import allure


@allure.step('Delete volume:"{0}" under Target:"{1}" from VirtualStoreage:"{2}"')
def step_title_with_delete_volume_name(arg1, arg2, arg3):
    pass


def test_delete_volume():
    step_title_with_delete_volume_name('iscsi-name01', 'iqn.2021-11.abc:1', 'Default')
    step_title_with_delete_volume_name('iscsi-name02', 'iqn.2021-11.target:ESXi', 'NewVS01')
    step_title_with_delete_volume_name('iscsi-name03', 'iqn.2021-11.target:PVE', 'NewVS02')
</code></pre>
<p>效果图如下：</p>
<img class="shadow" src="/img/in-post/allure/step_parameter.png" width="1200">
<p>也可以设置传递一个/多个可选参数，不传则为None，示例如下：</p>
<pre><code class="language-python">@allure.step('这是一个带描述语的step，并且通过占位符传递参数：positional = "{0}",keyword = "{key}"')
def step_title_with_placeholder(arg1, key=None):
    pass


def test_step_with_placeholder():
    step_title_with_placeholder(1, key="something")
    step_title_with_placeholder(2)
    step_title_with_placeholder(3, key="anything")
</code></pre>
<p><strong>小结：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>allure.step支持step嵌套，即step下可以嵌套step</p>
</li>
<li class="lvl-2">
<p>allure.step支持添加描述且通过占位符传递参数</p>
</li>
</ul>
<h3 id="allure-wei-ce-shi-yong-li-tian-jia-miao-shu-description">allure为测试用例添加描述（description）</h3>
<h4 id="allure-tian-jia-miao-shu-de-san-chong-fang-shi">allure添加描述的三种方式：</h4>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用装饰器@allure.description，传递一个字符串参数用来描述测试用例</p>
</li>
<li class="lvl-2">
<p>使用装饰器@allure.description_html，传递一段HTML文本，这将在测试报告的"Description"部分渲染出来</p>
</li>
<li class="lvl-2">
<p>直接在测试用例方法中通过编写文档注释的方式来添加描述</p>
</li>
</ul>
<p>我一般使用第三种，直接将Testlink上用例标题放在这里，即有title的效果，又有description效果。如果使用，具体看个人需要（如下所示）。</p>
<pre><code class="language-python">    @allure.severity('RAT')
    @allure.link(testlink_url+'?tprojectPrefix='+testlink_prefix+'&amp;item=testcase&amp;id='+testlink_prefix+'-432')
    def test_432_create_nfs_folder_mode_async(self):
        """  Sc-432:Create NFS share folder, mode is async  """
        folder_name = 'pytest-' + rand_low_ascii(6)
        self.create_share_folder(folder_name, nfs='true', mode='async')
        self.delete_folder(folder_name)
        self.mds_mgr.check_cluster_state()
</code></pre>
<h4 id="shi-li">示例</h4>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure


@allure.description("""
这是通过传递字符串参数的方式添加的一段描述语，
使用的是装饰器@allure.description，可以换行
""")
def test_description_provide_string():
    assert 1 &gt; 0


@allure.description_html("""
&lt;h1&gt;Test with some complicated html description&lt;/h1&gt;
&lt;table style="width:100%" border="1"&gt;
  &lt;tr&gt;
    &lt;th&gt;Name&lt;/th&gt;
    &lt;th&gt;Age&lt;/th&gt;
    &lt;th&gt;Sex&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr align="center"&gt;
    &lt;td&gt;Json&lt;/td&gt;
    &lt;td&gt;28&lt;/td&gt;
    &lt;td&gt;男&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr align="center"&gt;
    &lt;td&gt;Cathy&lt;/td&gt;
    &lt;td&gt;23&lt;/td&gt;
    &lt;td&gt;女&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
""")
def test_description_privide_html():
    assert 1 == 1


def test_description_docstring():
    """
    这是通过文本注释的方式添加的描述语
    同样支持多行描述
    大家好，我是Gavin
    """
    assert True
</code></pre>
<p>allure效果图展示如下：</p>
<img class="shadow" src="/img/in-post/allure/description_provide_string.png" width="1200">
<p>上面的测试报告是通过装饰器@allure.description传递字符串参数来添加描述语的方式。</p>
<img class="shadow" src="/img/in-post/allure/description_docstring.png" width="1200">
<p>上面的测试报告是通过直接在测试用例方法中编写文档注释来添加描述语的方式。</p>
<img class="shadow" src="/img/in-post/allure/description_privide_html.png" width="1200">
<p>上面的测试报告是通过装饰器@allure.description_html传递一段HTML文本来添加描述语的方式，这段HTML会渲染在报告的"Description"部分。</p>
<h4 id="allure-dong-tai-geng-xin-miao-shu-yu-allure-dynamic-description">allure动态更新描述语(allure.dynamic.description)</h4>
<pre><code class="language-python">@allure.description("这是更新前的描述内容，在使用allure.dynamic.description后将会被更新成新的描述内容")
def test_dynamic_description():
    assert True
    allure.dynamic.description("这是通过使用allure.dynamic.description更新后的描述内容")
</code></pre>
<p>allure html展示效果如下：</p>
<img class="shadow" src="/img/in-post/allure/dynamic_description.png" width="1200">
<p>如果assert失败或用例执行失败，是不会动态更新描述信息的：</p>
<img class="shadow" src="/img/in-post/allure/dynamic_description_failed.png" width="1200">
<h3 id="allure-wei-ce-shi-yong-li-tian-jia-biao-ti">allure为测试用例添加标题</h3>
<p>通过使用装饰器@allure.title可以为测试用例自定义一个更具有阅读性的易读的标题。</p>
<h4 id="allure-title-de-san-chong-shi-yong-fang-shi">allure.title的三种使用方式</h4>
<ul class="lvl-0">
<li class="lvl-2">
<p>直接使用@allure.title为测试用例自定义标题</p>
</li>
<li class="lvl-2">
<p>@allure.title支持通过占位符的方式传递参数，可以实现测试用例标题参数化，动态生成测试用例标题</p>
</li>
<li class="lvl-2">
<p>@allure.dynamic.title动态更新测试用例标题</p>
</li>
</ul>
<h4 id="allure-title-shi-yong-fang-shi-shi-li">allure.title使用方式示例</h4>
<h5 id="zhi-jie-shi-yong-allure-title-wei-ce-shi-yong-li-zi-ding-yi-biao-ti">直接使用@allure.title为测试用例自定义标题</h5>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure


@allure.title("自定义测试用例标题")
def test_case_with_title():
    assert True
</code></pre>
<p>这个最常用，也是最简单的方式。效果图如下：</p>
<img class="shadow" src="/img/in-post/allure/step_title.png" width="1200">
<h5 id="allure-title-zhan-wei-fu-chuan-di-can-shu-can-shu-hua-ce-shi-yong-li-biao-ti">allure.title占位符传递参数，参数化测试用例标题</h5>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure


@allure.title("参数化测试用例标题：参数1 = {param1} and 参数2 = {param2}")
@pytest.mark.parametrize("param1, param2, expected", [(1, 1, 2), (1, 3, 5)])
def test_with_parametrize_title(param1, param2, expected):
    assert param1 + param2 == expected
</code></pre>
<p>展示效果如下：</p>
<img class="shadow" src="/img/in-post/allure/step_title_parameter.png" width="1200">
<h5 id="allure-dynamic-title-dong-tai-geng-xin-biao-ti">allure.dynamic.title动态更新标题</h5>
<pre><code class="language-python">@allure.title("这个标题将会被成功执行的测试用例中的标题替所代替")
def test_with_dynamic_title():
    assert True
    allure.dynamic.title("断言成功后，标题将会被替换成这个标题")
</code></pre>
<p>效果图如下：</p>
<img class="shadow" src="/img/in-post/allure/step_dynamic_title.png" width="1200">
<h4 id="allure-ji-cheng-que-xian-guan-li-xi-tong-he-ce-shi-guan-li-xi-tong-allure-link-allure-issue-allure-testcase">allure集成缺陷管理系统和测试管理系统(allure.link、allure.issue、allure.testcase)</h4>
<p>allure测试报告框架提供了@allure.link、@allure.issue、@allure.testcase 这三个装饰器，可以用来与缺陷管理系统和测试管理系统集成，做到更好的自动化管理。</p>
<p>这三个装饰器，使用方法基本一致，但仍然不建议混用，用例相关用@allure.testcase，Bug相关用@allure.issue，其他则使用@allure.link，形成习惯。</p>
<p>代码示例：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure

@allure.link("http://47.99.40.56:8721/List_of_Functional_Requirements-V1.2.html")
def test_with_link():
    """
    @allure.link() 指定与测试用例关联的链接，直接贴上对应的URL即可
    :return:
    """
    assert True


@allure.link("http://47.99.40.56:8721/List_of_Functional_Requirements-V1.2.html", name="需求列表V1.2的链接，点击访问")
def test_with_link_named():
    """
    @allure.link() 通过指定name的方式来指定关联链接，测试报告中用name替换实际URL展示
    :return:
    """
    assert True


@allure.issue("http://47.99.40.56:8721/bug-view-1446.html")
def test_with_issue_link():
    """
    @allure.issue() 可以与缺陷管理系统相关联，指定与该测试用例相关联的bug链接地址
    :return:
    """
    assert True


@allure.testcase("http://47.99.40.56:8721/test-case-2166.html")
def test_with_testcase_link():
    """
    @allure.testcase() 可以与测试用例管理工具相关联，指定与该测试用例关联的测试用例地址
    :return:
    """
    assert True
</code></pre>
<p>效果如下：</p>
<img class="shadow" src="/img/in-post/allure/allure_link.png" width="1200">
<p>上图是allure.link的效果。</p>
<img class="shadow" src="/img/in-post/allure/allure_issue.png" width="1200">
<p>上图是allure.issue的效果，用于提示是一个Bug。</p>
<img class="shadow" src="/img/in-post/allure/allure_testcase.png" width="1200">
<p>上图显示allure.testcase的链接，会有一个类似存储的icon。</p>
<p>这几个装饰器的相同点都显示在“Links”下方展示，除了allure.link没有图标外，其他两个都有图标。</p>
<h4 id="allure-de-tag-biao-ji-allure-story-allure-feature-severity">allure的Tag标记(allure.story、allure.feature、severity)</h4>
<p>执行测试用例时，希望能够更加灵活的指定执行某些测试用例（如指定测试用例的级别，用例路径，用例标签/标记等），pytest支持我们通过使用marker装饰器@pytest.mark来实现这个需求，而allure也同样提供了三种类似的方法来实现这个需求。</p>
<h5 id="allure-de-san-chong-fang-shi">allure的三种方式</h5>
<p>Allure 则提供了 3 种类型的标记装饰器来标记测试，并且可以同步展示到测试报告内：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>BDD（行为驱动开发）风格的标签</p>
</li>
<li class="lvl-2">
<p>严重程度（Severity）的标签</p>
</li>
<li class="lvl-2">
<p>自定义的标签（allure.title）</p>
</li>
</ul>
<p>​</p>
<h5 id="bdd-feng-ge-de-biao-qian">BDD风格的标签</h5>
<ul class="lvl-0">
<li class="lvl-2">
<p>@allure.epic：敏捷里面的概念，定义史诗，相当于module级的标签</p>
</li>
<li class="lvl-2">
<p>@allure.feature：功能点的描述，可以理解成模块，相当于class级的标签</p>
</li>
<li class="lvl-2">
<p>@allure.story：故事，可以理解为场景，相当于method级的标签</p>
</li>
</ul>
<p>allure提供的两个装饰器：@allure.feature和@allure.story，可以将用例根据Feature和Story分类，通过将name使用epic_ 开头的前缀就能够指定Feature和Story属于哪一个epic。</p>
<p>他俩的关系：</p>
<p>epic是feature父级，feature是story父级，是包含关系，效果跟书籍的目录或者项目结构相似。</p>
<p>如果使用allure和pytest来组织的自动化框架，<strong>推荐使用allure的标记来标记用例，替换@pytest.mark.xxx</strong>，因为功能一致，且allure 标记功能可以直接<strong>展示到html报告</strong>内</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure


def test_without_any_annotations_that_wont_be_executed():
    """
    没有任何注解
    :return:
    """
    pass


@allure.story('epic_1')
def test_with_epic_1():
    """
    通过指定name为epic_前缀的方式来指定story属于哪一个epic
    :return:
    """
    pass


@allure.story('story_1')
def test_with_story_1():
    """
    指定该测试用例属于的story
    :return:
    """
    pass


@allure.story('story_2')
def test_with_story_2():
    """
    指定该测试用例属于的story
    :return:
    """
    pass


@allure.feature('feature_2')
@allure.story('story_2')
def test_with_story_2_and_feature_2():
    """
    指定该测试用例属于的feature和story
    :return:
    """
    pass
</code></pre>
<p><strong>拓展：命令行方式</strong></p>
<p>与@pytest.mark.xxx相同，也可以通过命令行来运行指定epic、feature、story标记的用例：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>–allure-epics</p>
</li>
<li class="lvl-2">
<p>–allure-features</p>
</li>
<li class="lvl-2">
<p>–allure-stories</p>
</li>
</ul>
<p><strong>只运行 epic 名为 epic1 的测试用例</strong></p>
<p><code>pytest --alluredir ./report/allure --allure-epics=epic1</code></p>
<p><strong>只运行 feature 名为 模块级 的测试用例</strong></p>
<p><code>pytest --alluredir ./report/allure --allure-features=模块级</code></p>
<p><strong>只运行 story1、story2 的测试用例（也可以不用=号 空格即可）</strong></p>
<p><code> pytest tests.py --allure-stories story1,story2</code></p>
<p><strong>指定 feature和story</strong></p>
<p><code>pytest tests.py --allure-features feature1,feature2 --allure-stories story1</code></p>
<h5 id="severity-markers">Severity markers</h5>
<p>使用@allure.severity来标识测试用例的严重等级，严重等级是allure.severity_level枚举中的一个。</p>
<p>allure划分用例等级为5个：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>blocker：阻塞缺陷（功能未实现，无法下一步）</p>
</li>
<li class="lvl-2">
<p>critical：严重缺陷（功能点缺失）</p>
</li>
<li class="lvl-2">
<p>normal：一般缺陷（边界情况，格式错误）</p>
</li>
<li class="lvl-2">
<p>minor：次要缺陷（界面错误与ui需求不符）</p>
</li>
<li class="lvl-2">
<p>trivial：轻微缺陷（必须项无提示，或者提示不规范）</p>
</li>
</ul>
<p><strong>说明：</strong></p>
<p>​    一些手工用例编写平台，如testlink，它里面定义的测试用例的级别名称，和allure指定的这五种名称是不一样的，是无法直接使用外部的用例级别的，只能使用上面的测试用例的级别。</p>
<p>示例：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import pytest
import allure


def test_with_no_severity_label():
    """
    不定义任何severity标签
    :return:
    """
    pass


@allure.severity(allure.severity_level.BLOCKER)
def test_with_blocker_severity():
    """
    定义severity标签为BLOCKER
    :return:
    """
    pass


@allure.severity(allure.severity_level.CRITICAL)
def test_with_critical_severity():
    """
    定义severity标签为CRITICAL
    :return:
    """
    pass


@allure.severity(allure.severity_level.TRIVIAL)
def test_with_trivial_severity():
    """
    定义severity标签为TRIVIAL
    :return:
    """
    pass


@allure.severity(allure.severity_level.NORMAL)
def test_with_normal_severity():
    """
    定义severity标签为NORMAL
    :return:
    """
    pass


@allure.severity(allure.severity_level.MINOR)
def test_with_minior_severity():
    """
    定义severity标签为MINOR
    :return:
    """
    pass

@allure.severity(allure.severity_level.NORMAL)
class TestClassWithNormalSeverity(object):
    """
    定义类的severity标签为NORMAL
    """

    def test_inside_the_normal_severity_test_class(self):
        pass

    @allure.severity(allure.severity_level.CRITICAL)
    def test_inside_the_normal_severity_test_class_with_overriding_critical_severity(self):
        pass
</code></pre>
<p>severity装饰器可以用在函数、方法和类上面。</p>
<p>通过使用–allure-severities 命令行选项指定运行哪些测试用例，如果命令行选项的值有多个就用逗号分隔。</p>
<p>比如：</p>
<img class="shadow" src="/img/in-post/allure/allure_level.png" width="1200">
<h2 id="zong-he-shi-li">综合示例</h2>
<p>从网上找了个示例(<a href="https://zhuanlan.zhihu.com/p/652835522">https://zhuanlan.zhihu.com/p/652835522</a>)，做参考一下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import allure
import pytest
from allure_commons.types import LinkType, Severity


@allure.parent_suite('我是parent_suite')
@allure.suite('我是suite')
@allure.sub_suite('我是sub_suite')
@allure.epic('我是epic')
@allure.feature('我是feature')
@allure.story('我是story')
class TestAllureDemo:
    @allure.id('我是id')
    @allure.title('我是title')
    @allure.link('百度一下，你就知道', LinkType.ISSUE, '我是link_ISSUE')
    @allure.label('我是label')
    @allure.issue('百度一下，你就知道', '我是issue')
    @allure.description('我是description')
    @allure.severity(Severity.BLOCKER)
    @allure.tag('我是tag')
    @allure.testcase('百度一下，你就知道', 'testcase')
    def test_01(self):
        self.assert_one(1, 1)

    @allure.step('我是断言')
    def assert_one(self, a, b):
        assert a == b

    @allure.id('我是id')
    @allure.title('我是title')
    @allure.link('百度一下，你就知道', LinkType.LINK, '我是link')
    @allure.label('我是label')
    @allure.issue('百度一下，你就知道', '我是issue')
    @allure.description('我是description')
    @allure.severity('我是severity')
    @allure.tag('我是tag')
    @allure.testcase('百度一下，你就知道', '我是testcase')
    def test_02(self):
        allure.dynamic.mro()
        allure.dynamic.title('我是修改后的title')
        allure.dynamic.link('百度一下，你就知道', LinkType.LINK, '我是修改后的link')
        allure.dynamic.label('我是修改后的label')
        allure.dynamic.issue('百度一下，你就知道', '我是修改后的issue')
        allure.dynamic.description('我是修改后的description')
        allure.dynamic.severity('我是修改后的severity')
        allure.dynamic.tag('我是修改后的tag')
        allure.dynamic.testcase('百度一下，你就知道', '我是修改后的testcase')
        assert 1 &gt; 1
</code></pre>
<p>allure html report 显示效果如下：</p>
<img class="shadow" src="/img/in-post/allure/allure_full_example.png" width="1200">
<h1 id="bang-zhu-help">帮助 --help</h1>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>generate</td>
<td>根据给定的allure结果目录生成报告</td>
</tr>
<tr>
<td>serve</td>
<td>启动报告，可在浏览器中查看生成的报告</td>
</tr>
<tr>
<td>open</td>
<td>打开生成的报告，默认使用浏览器</td>
</tr>
<tr>
<td>plugin</td>
<td>生成插件报告</td>
</tr>
<tr>
<td>–help</td>
<td>打印命令行的帮助信息</td>
</tr>
<tr>
<td>-q,–quite</td>
<td>开启静默模式，减少信息的输出</td>
</tr>
<tr>
<td>-v,–verbose</td>
<td>开启详细模式，增加输出信息</td>
</tr>
<tr>
<td>–version</td>
<td>显示当前allure的版本信息</td>
</tr>
</tbody>
</table>
<p>详细帮助参考下图：</p>
<img class="shadow" src="/img/in-post/allure/allure_help.png" width="1200">
<h2 id="bao-gao-da-kai">报告打开</h2>
<h3 id="xi-tong-mo-ren-mu-lu-xia-sheng-cheng-ce-shi-bao-gao-bing-da-kai">系统默认目录下生成测试报告并打开</h3>
<pre><code class="language-shell">allure serve path
</code></pre>
<p>示例如下：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;allure serve report/json -o report/html
Generating report to temp directory...
-o does not exists
report\html does not exists
Report successfully generated to C:\Users\Wang\AppData\Local\Temp\8019254791336321592\allure-report
Starting web server...
2021-11-04 11:13:00.556:INFO::main: Logging initialized @1698ms to org.eclipse.jetty.util.log.StdErrLog
Server started at &lt;http://192.168.2.178:2970/&gt;. Press &lt;Ctrl+C&gt; to exit
^C终止批处理操作吗(Y/N)? y
</code></pre>
<h3 id="zai-zhi-ding-mu-lu-xia-sheng-cheng-ce-shi-bao-gao-shi-yong-open-da-kai">在指定目录下生成测试报告，使用open打开</h3>
<pre><code class="language-shell">allure generate “存储结果的path” -c -o  “在path生成html报告”
allure open “在path生成的html报告”
</code></pre>
<p>示例如下：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;allure generate report/json -o report/html
Report successfully generated to report\html
C:\Users\Wang&gt;allure open report\html
Starting web server...
2021-11-04 11:17:37.560:INFO::main: Logging initialized @160ms to org.eclipse.jetty.util.log.StdErrLog
Server started at &lt;http://192.168.2.178:2999/&gt;. Press &lt;Ctrl+C&gt; to exit
</code></pre>
<h2 id="environment">Environment</h2>
<p>环境变量参数，设置运行环境参数，比如可以显示被测版本信息，什么时间开始测试，什么时间测试结束，耗时多久之类的信息。默认为空，需要创建environment.properties文件，或者environment.xml文件，并把文件存放<code>存储结果的path</code>中。</p>
<img class="shadow" src="/img/in-post/allure/environment_empty.png" width="1200">
<h3 id="environment-properties">environment.properties</h3>
<pre><code class="language-shell">PRODUCT_VERSION=VirtualStor Scaler V8.0-269
START_TIME=2021-11-03 21:36:57
END_TIME=2021-11-04 06:29:46
TEST_COUNTS=2596
TEST_PASS=2537
TEST_FAIL=31
TEST_SKIP=27
TEST_BROKEN=1
TEST_UNKNOW=0
TIME_DURATION=31969
</code></pre>
<h3 id="environment-xml">environment.xml</h3>
<pre><code class="language-shell">&lt;environment&gt;
    &lt;parameter&gt;
        &lt;key&gt;PRODUCT_VERSION&lt;/key&gt;
        &lt;value&gt;VirtualStor Scaler V8.0-269&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;START_TIME&lt;/key&gt;
        &lt;value&gt;2021-11-03 21:36:572&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;END_TIME&lt;/key&gt;
        &lt;value&gt;2021-11-04 06:29:46&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;TEST_COUNTS&lt;/key&gt;
        &lt;value&gt;2596&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;TEST_PASS&lt;/key&gt;
        &lt;value&gt;2537&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;TEST_FAIL&lt;/key&gt;
        &lt;value&gt;31&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;TEST_SKIP&lt;/key&gt;
        &lt;value&gt;27&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;TEST_BROKEN&lt;/key&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;TEST_UNKNOW&lt;/key&gt;
        &lt;value&gt;0&lt;/value&gt;
    &lt;/parameter&gt;
    &lt;parameter&gt;
        &lt;key&gt;TIME_DURATION&lt;/key&gt;
        &lt;value&gt;31969&lt;/value&gt;
    &lt;/parameter&gt;
&lt;/environment&gt;
</code></pre>
<h2 id="categories">Categories</h2>
<p>将测试用例结果进行分类,默认情况下，有两类缺陷：</p>
<ol>
<li class="lvl-3">
<p>Product defects 产品缺陷（测试结果：failed）</p>
</li>
<li class="lvl-3">
<p>Test defects 测试缺陷（测试结果：error/broken）</p>
</li>
</ol>
<p>可以创建自定义缺陷分类的，将 categories.json 文件添加到allure-results目录即可（和上面environment.properties放同一个目录），示例参考如下：</p>
<pre><code class="language-shell">[
  {
    "name": "Ignored tests", 
    "matchedStatuses": ["skipped"] 
  },
  {
    "name": "Infrastructure problems",
    "matchedStatuses": ["broken", "failed"],
    "messageRegex": ".*bye-bye.*" 
  },
  {
    "name": "Outdated tests",
    "matchedStatuses": ["broken"],
    "traceRegex": ".*FileNotFoundException.*" 
  },
  {
    "name": "Product defects",
    "matchedStatuses": ["failed"]
  },
  {
    "name": "Test defects",
    "matchedStatuses": ["broken"]
  }
]
</code></pre>
<p>参数的含义</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>name</strong>：分类名称，可以是中文</p>
</li>
<li class="lvl-2">
<p><strong>matchedStatuses</strong>：测试用例的运行状态，默认[“failed”, “broken”, “passed”, “skipped”, “unknown”]</p>
</li>
<li class="lvl-2">
<p><strong>messageRegex</strong>：测试用例运行的错误信息，默认是 .* ，是通过正则去匹配的</p>
</li>
<li class="lvl-2">
<p><strong>traceRegex</strong>：测试用例运行的错误堆栈信息，默认是 .* ，也是通过正则去匹配的</p>
</li>
</ul>
<p>结合上面文件后，放在report原始文件目录下，生成的可视化报告参考如下：</p>
<img class="shadow" src="/img/in-post/allure/environment_OK.png" width="1200">
<h1 id="jie-yu">结语</h1>
<h2 id="she-zhi-ce-shi-tao-zhong-xian-shi-nei-rong">设置测试套中显示内容</h2>
<p>@allure.parent_suite,@allure.suite,@allure.sub_suite对应的是allure报告中的测试套的三个级别.爷爷父亲儿子.然后下一级就是测用例的标题。</p>
<p>由于@allure.epic, @allure.feature, @allure.story,@allure.title的存在，上面这三个装饰器很少使用。</p>
<h2 id="she-zhi-bao-gao-zhong-gong-neng-xiang-xian-shi-nei-rong">设置报告中功能项显示内容</h2>
<p>@allure.epic, @allure.feature, @allure.story,@allure.title对应功能中的一级菜单,二级菜单,三级菜单,用例标题</p>
<h2 id="she-zhi-ju-ti-yong-li-xian-shi-nei-rong">设置具体用例显示内容</h2>
<p>@allure.id 用例id,@allure.link 用例的超链接,@allure.label 用例的标签<br>
@allure.issue 记录用例的问题(超链接),@allure.description 用例的描述<br>
@allure.severity 用例的优先级,@allure.tag 用例的标记,@allure.testcase 记录用例的地址(超链接)<br>
@allure.description_html 用例的描述的网址(超链接),若存在description_html则@allure.description不显示</p>
<h2 id="she-zhi-yong-li-ji-bie">设置用例级别</h2>
<p>@allure.severity的参数说明，‘blocker’、 ‘critical’、‘normal’、‘minor’、‘trivial’，从左到右言级别依次降低</p>
<h1 id="can-kao-lian-jie">参考链接</h1>
<p><a href="https://github.com/allure-framework">https://github.com/allure-framework</a></p>
<p><a href="https://qualitysphere.gitee.io/ext/allure/">https://qualitysphere.gitee.io/ext/allure/</a></p>
<p><a href="https://github.com/orgs/allure-framework/discussions">https://github.com/orgs/allure-framework/discussions</a></p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
        <category>Allure</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
        <tag>Allure</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下显示文件隶属于哪个包</title>
    <url>/2022/02/08/show_which_package_the_file_belongs_to/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>RD在定位问题的时候，需要QA告知当前文件隶属于哪个包，方便到对应包下查询源码来定位问题，故本文介绍一下Ubuntu和CentOS两种OS下查看文件隶属于哪个包。</p>
<h1 id="cha-kan-dang-qian-wen-jian-li-shu-yu-na-ge-package">查看当前文件隶属于哪个package</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>CentOS</p>
</li>
</ul>
<pre><code class="language-shell">[root@83fc1 bin]# rpm -qf zerocopy_setup.py 
ezgateway-8.3-211.git09ae02f.x86_64
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>Ubuntu</p>
</li>
</ul>
<pre><code class="language-shell">root@CVM01:/usr/local/bin# dpkg -S ezcopy
ezgateway: /usr/local/bin/ezcopy
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>S3 单一Bucket下写4K数据性能衰减验证</title>
    <url>/2021/10/11/s3_performance_millions_of_objects/</url>
    <content><![CDATA[<h1 id="ce-shi-huan-jing">测试环境</h1>
<h2 id="ce-shi-huan-jing-xin-xi">测试环境信息</h2>
<p><strong>存储端</strong></p>
<table>
<thead>
<tr>
<th><strong>被测版本</strong></th>
<th>v8.2-211  (a243210)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>节点数</strong></td>
<td>6 nodes，NJ Lab 技嘉4U36B设备</td>
</tr>
<tr>
<td><strong>CPU</strong></td>
<td>node1~node3: Intel® Xeon® Gold 5118 CPU @ 2.30GHz <br>node4~node6:  Intel® Xeon® Silver 4114 CPU @ 2.20GHz</td>
</tr>
<tr>
<td><strong>Memory</strong></td>
<td>256G(16G*16)</td>
</tr>
<tr>
<td><strong>Disk</strong></td>
<td>希捷 SATA  8T*36    <br>Intel S4510 SSD: 240G*1     <br>node1~node6： 威刚ADATA SR2000CP NVMe 4T*1     <br>node1~node3： NVMe P4500/P4600 4T*1</td>
</tr>
<tr>
<td><strong>Network</strong></td>
<td>QLogic  Corp. FastLinQ QL41000 Series 10/25/40/50GbE Controller *2 Ports     <br>Intel Corporation 82599ES 10-Gigabit SFI/SFP+ Network Connection *2 Ports</td>
</tr>
<tr>
<td><strong>集群信息</strong></td>
<td>2块SATA盘组RAID0，每个node 18个OSD，一块ADATA NVME SSD作为OSD Journal&amp;Cache，加入s3-data-pool<br>node1~node3，每个node的一块P4510/4610 NVME SSD作OSD，加入s3-index-pool<br>配置S3 placement， data pool选择s3-data-pool， index pool选择s3-index-pool<br>对metadata，s3-data-pool 和 s3-data-pool 启用PG split功能，并确保PG均衡<br>UI创建S3 账号，并创建bucket<br>参数调优部分，参考下文“参数调优”章节</td>
</tr>
</tbody>
</table>
<p>说明：</p>
<p>​    最初node1~node3上是两块ADATA NVME SSD，后来才和node4~node6互换SSD，对应测试章节为本文的“Lab最终测试”</p>
<p><strong>客户端</strong></p>
<p>​    6台VM，CentOS7，走10G网络向存储端的6个radosgw 发起请求。</p>
<pre><code class="language-shell">[root@centos-1 ~]# hostnamectl 
   Static hostname: centos-1
         Icon name: computer-vm
           Chassis: vm
        Machine ID: b398080741c04f70b049ebe588c5ffde
           Boot ID: e114313e62ff4e6b9e4d24a711d9ed82
    Virtualization: vmware
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-693.el7.x86_64
      Architecture: x86-64
</code></pre>
<p><strong>cosbench task config</strong></p>
<p>内容参考如下：</p>
<pre><code class="language-shell">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;workload name="5" description="1200million_4k_data_filling"&gt;
&lt;storage type="s3" config="accesskey=YGWTYZEPDQVCPX44F6BA;secretkey=ze7bpgdY81wbHYehpzAaM2Y5RyO5rOh99YbH9NCj;endpoint=http://10.16.172.161/" /&gt;

  &lt;workflow&gt;
    &lt;workstage name="1200million_4k_data_filling-init"&gt;
        &lt;work name="1200million_4k_data_filling-init" type="init" workers="1" interval="10" division="container" runtime="0" rampup="0" rampdown="0" driver="driver1"  config="cprefix=bigtera;containers=r(1,1)" /&gt;
    &lt;/workstage&gt;
    &lt;workstage name="1200million_4k_data_filling-write"&gt;
        &lt;work name="datafile-write1" type="write" workers="96" interval="10" division="object" totalOps="200000000" rampup="0" rampdown="0" driver="driver1"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=YGWTYZEPDQVCPX44F6BA;secretkey=ze7bpgdY81wbHYehpzAaM2Y5RyO5rOh99YbH9NCj;endpoint=http://10.16.172.161/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigtera;oprefix=4KB_;containers=s(1,1);objects=r(1,200000000);sizes=c(4)KB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="datafile-write2" type="write" workers="96" interval="10" division="object" totalOps="200000000" rampup="0" rampdown="0" driver="driver2"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=YGWTYZEPDQVCPX44F6BA;secretkey=ze7bpgdY81wbHYehpzAaM2Y5RyO5rOh99YbH9NCj;endpoint=http://10.16.172.162/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigtera;oprefix=4KB_;containers=s(1,1);objects=r(200000001,400000000);sizes=c(4)KB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="datafile-write3" type="write" workers="96" interval="10" division="object" totalOps="200000000" rampup="0" rampdown="0" driver="driver3"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=YGWTYZEPDQVCPX44F6BA;secretkey=ze7bpgdY81wbHYehpzAaM2Y5RyO5rOh99YbH9NCj;endpoint=http://10.16.172.163/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigtera;oprefix=4KB_;containers=s(1,1);objects=r(400000001,600000000);sizes=c(4)KB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="datafile-write3" type="write" workers="96" interval="10" division="object" totalOps="200000000" rampup="0" rampdown="0" driver="driver4"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=YGWTYZEPDQVCPX44F6BA;secretkey=ze7bpgdY81wbHYehpzAaM2Y5RyO5rOh99YbH9NCj;endpoint=http://10.16.172.164/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigtera;oprefix=4KB_;containers=s(1,1);objects=r(600000001,800000000);sizes=c(4)KB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="datafile-write3" type="write" workers="96" interval="10" division="object" totalOps="200000000" rampup="0" rampdown="0" driver="driver5"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=YGWTYZEPDQVCPX44F6BA;secretkey=ze7bpgdY81wbHYehpzAaM2Y5RyO5rOh99YbH9NCj;endpoint=http://10.16.172.165/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigtera;oprefix=4KB_;containers=s(1,1);objects=r(800000001,1000000000);sizes=c(4)KB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
        &lt;work name="datafile-write3" type="write" workers="96" interval="10" division="object" totalOps="200000000" rampup="0" rampdown="0" driver="driver6"&gt;
            &lt;auth type="none" config="" /&gt;
            &lt;storage type="s3" config="accesskey=YGWTYZEPDQVCPX44F6BA;secretkey=ze7bpgdY81wbHYehpzAaM2Y5RyO5rOh99YbH9NCj;endpoint=http://10.16.172.166/" /&gt;
            &lt;operation type="write" ratio="100" division="object" config="cprefix=bigtera;oprefix=4KB_;containers=s(1,1);objects=r(1000000001,1200000000);sizes=c(4)KB;createContainer=false;" id="none" /&gt;
        &lt;/work&gt;
    &lt;/workstage&gt;
    &lt;/workflow&gt;

&lt;/workload&gt;
</code></pre>
<h2 id="can-shu-diao-you">参数调优</h2>
<h3 id="xiu-gai-bucket-shards-mo-ren-128-gai-cheng-1000">修改bucket shards，默认128，改成1000</h3>
<pre><code class="language-shell">radosgw-admin bucket reshard --bucket=bigtera1 --num-shards=1000
</code></pre>
<p>说明：</p>
<p>​      此操作，请务必放在修改了s3 placement，并创建好bucket后再执行。</p>
<h3 id="diao-zheng-rgw-xiang-guan-can-shu">调整rgw相关参数</h3>
<pre><code class="language-shell">rgw ecsoc bundle shards = 512
rgw gc max objs = 32
rgw gc obj min wait = 300
rgw gc processor max_time = 300
rgw gc processor period = 300
rgw init timeout = 3000
</code></pre>
<h3 id="diao-zheng-bigterastore-cache">调整bigterastore cache</h3>
<p>默认100万，调整成1000万，尽量避免bigterastore flush cache</p>
<pre><code class="language-shell">be_cache_max_objs = 10000000
</code></pre>
<p>说明：</p>
<p>​    建议写入每个node的ceph.conf [osd]处；</p>
<p>​    本文 EC 4+2 灌12亿对象场景，不调整此参数。</p>
<h3 id="bi-mian-inode-hao-jin">避免inode耗尽</h3>
<pre><code class="language-shell">ceph tell osd.* injectargs '--bigterastore_obj_meta_size 1024'
</code></pre>
<p>建议写入每个node的ceph.conf [osd]处。</p>
<h3 id="pg-xiang-guan">PG相关</h3>
<p>metadata pool 启用PG split，避免OSD数量过多（默认512 PG数太少）和 bucket中objects数量较多情况下出现osd metaata pool full，引发性能衰减；</p>
<p>s3-data-pool启用PG split；</p>
<p>确保metadata pool 和 s3-data-pool的PG分布是均衡的。</p>
<p>说明：</p>
<p>以本次测试环境为例，虽然产品有deamon /usr/local/bin/bt-pool-reweight-agent.py 来做reweight PG，但整个执行周期有些慢，迟迟没有调整好，所以手工干预了一下，操作步骤大致如下：</p>
<p>（1）   ceph df 获取要调整的pool id  # 主要是3个pool，一个是metadata pool，一个是s3 data pool 和s3 index pool</p>
<p>（2）   获取pool预期OSD PG分布crush信息 # 以metadata pool id=10为示例：</p>
<pre><code class="language-shell">crush_reweight_tool -p 10 -o 10_crush.bin -t 1
ceph osd setcrushmap -i 10_crush.bin
</code></pre>
<p>上面是理想状态，-t 1表示每个OSD上分布的PG相差1，比如计算出来的每个OSD 分布的PG数平均值为150，预计调整后的状态是：有的OSD 分布的PG数是151，有的是150，有的是152；</p>
<p>如果-t 1中无法达到预期调整效果，特别是在现有PG分布非常不均衡状态下，放大这个数值，先从差值较大来做调整，然后缩小范围，示例如下：</p>
<pre><code class="language-shell">crush_reweight_tool -p 10 -o 10_crush.bin -t 30；
ceph osd setcrushmap -i 10_crush.bin
</code></pre>
<p>apply下去后：</p>
<pre><code class="language-shell">crush_reweight_tool -p 10 -o 10_crush.bin -t 10；
ceph osd setcrushmap -i 10_crush.bin
</code></pre>
<p>然后</p>
<pre><code class="language-shell">crush_reweight_tool -p 10 -o 10_crush.bin -t 4；
ceph osd setcrushmap -i 10_crush.bin

crush_reweight_tool -p 10 -o 10_crush.bin -t 2；
ceph osd setcrushmap -i 10_crush.bin

crush_reweight_tool -p 10 -o 10_crush.bin -t 1；
ceph osd setcrushmap -i 10_crush.bin
</code></pre>
<p>类似上面的操作，如果-t 1达不到预计效果，终止调整。</p>
<p>3个Pool的PG调整好后，检查一下PG分布，确保没有问题，具体检查方法，请执行附件提供的脚本：pg_allocate.py，输出参考如下：</p>
<pre><code class="language-shell">root@node166:~# ./pg_allocate.py 
dumped all

pool  : 1      10     11     12     13     2      3      4      5      6      7      8      9      | SUM
--------------------------------------------------------------------------------------------------------------

osd.0   5      153    115    2      0      2      7      3      3      21     18     8      3      | 340   
osd.1   5      153    115    8      0      4      4      5      5      26     14     7      2      | 348   
osd.2   5      153    113    5      0      3      2      4      5      27     17     6      3      | 343   
osd.3   3      153    113    5      0      3      8      8      5      13     34     5      3      | 353   
osd.4   3      152    114    4      0      1      12     6      7      19     16     6      5      | 345   
osd.5   5      152    115    5      0      2      6      4      2      20     22     3      9      | 345   
osd.6   4      150    115    4      0      2      5      5      3      23     27     5      6      | 349   
osd.7   5      152    113    4      0      3      11     8      7      22     13     7      5      | 350   
osd.8   1      151    114    1      0      4      5      2      7      17     27     1      6      | 336   
osd.9   3      152    115    1      0      7      5      6      5      12     16     2      4      | 328   
osd.10  4      150    113    6      0      4      4      5      3      17     12     7      6      | 331   
osd.11  4      150    115    3      0      5      2      4      9      22     15     0      4      | 333   
osd.12  2      153    114    5      0      6      8      4      6      18     20     3      3      | 342   
osd.13  6      151    115    4      0      7      4      5      5      18     26     8      6      | 355   
osd.14  7      153    113    4      0      3      2      7      2      19     14     9      6      | 339   
osd.15  6      152    114    2      0      7      5      4      6      20     16     11     6      | 349   
osd.16  7      151    113    5      0      3      1      5      3      16     15     4      7      | 330   
osd.17  2      152    113    13     0      7      8      9      3      21     17     4      3      | 352   
osd.18  6      151    112    6      0      4      4      3      3      25     22     2      3      | 341   
osd.19  6      152    113    2      0      3      9      4      5      21     11     1      4      | 331   
osd.20  3      152    112    7      0      7      5      6      5      18     21     5      3      | 344   
osd.21  4      150    114    3      0      5      1      5      3      18     14     4      5      | 326   
osd.22  7      150    114    3      0      5      9      7      3      14     18     4      7      | 341   
osd.23  9      152    115    9      0      4      5      2      6      17     7      5      3      | 334   
osd.24  6      152    114    6      0      4      5      4      2      17     16     6      4      | 336   
osd.25  3      150    112    5      0      4      5      0      6      18     13     5      6      | 327   
osd.26  3      153    113    5      0      3      5      4      4      20     31     3      6      | 350   
osd.27  6      150    113    4      0      4      8      5      6      19     22     3      10     | 350   
osd.28  1      153    113    0      0      4      4      2      3      11     14     7      5      | 317   
osd.29  7      153    113    9      0      7      4      3      3      34     19     5      4      | 361   
osd.30  3      151    114    10     0      7      5      5      2      11     35     4      10     | 357   
osd.31  3      150    115    1      0      5      7      9      2      17     17     5      3      | 334   
osd.32  2      152    114    2      0      5      4      5      4      19     18     7      5      | 337   
osd.33  6      151    115    6      0      7      7      7      2      12     19     3      4      | 339   
osd.34  4      152    115    7      0      8      3      3      7      25     15     3      6      | 348   
osd.35  5      152    112    4      0      6      4      4      8      20     21     2      5      | 343   
osd.36  7      153    115    3      0      4      6      2      4      18     21     7      3      | 343   
osd.37  1      152    114    3      0      1      7      2      5      18     23     3      5      | 334   
osd.38  6      153    115    9      0      2      5      6      2      14     13     4      2      | 331   
osd.39  4      151    114    6      0      6      6      2      6      24     22     2      5      | 348   
osd.40  3      152    115    3      0      4      7      7      6      18     15     4      4      | 338   
osd.41  4      152    114    4      0      3      3      4      4      24     23     4      4      | 343   
osd.42  1      152    113    6      0      4      4      7      4      16     16     6      2      | 331   
osd.43  5      151    115    5      0      7      3      2      2      14     23     5      3      | 335   
osd.44  5      152    112    7      0      3      3      5      11     17     26     8      4      | 353   
osd.45  5      153    115    7      0      5      1      7      7      22     18     5      5      | 350   
osd.46  5      151    114    6      0      2      7      5      8      16     20     4      6      | 344   
osd.47  4      153    114    6      0      6      2      9      3      21     19     2      9      | 348   
osd.48  8      151    114    1      0      4      2      4      5      17     19     1      7      | 333   
osd.49  5      152    114    4      0      4      4      4      4      22     18     2      4      | 337   
osd.50  8      153    115    4      0      6      5      4      1      20     19     4      1      | 340   
osd.51  5      153    115    5      0      4      4      7      6      15     15     3      8      | 340   
osd.52  9      152    114    4      0      4      2      2      6      12     18     6      3      | 332   
osd.53  5      153    113    7      0      5      4      6      1      28     21     3      8      | 354   
osd.54  3      151    114    8      0      5      8      7      7      13     14     3      5      | 338   
osd.55  8      152    113    9      0      2      5      5      4      20     24     12     1      | 355   
osd.56  7      153    113    1      0      3      6      1      7      23     26     6      1      | 347   
osd.57  8      151    115    5      0      6      1      10     10     23     26     5      4      | 364   
osd.58  7      153    113    3      0      5      5      4      3      15     22     6      7      | 343   
osd.59  4      150    115    7      0      5      3      5      10     17     11     5      6      | 338   
osd.60  4      152    115    7      0      6      4      1      2      16     10     2      5      | 324   
osd.61  5      152    113    4      0      7      3      1      8      22     21     8      4      | 348   
osd.62  8      150    113    2      0      4      1      5      2      11     21     4      9      | 330   
osd.63  4      150    113    5      0      1      5      7      5      27     21     3      3      | 344   
osd.64  4      151    115    5      0      6      6      5      7      14     25     5      9      | 352   
osd.65  5      150    113    3      0      7      6      5      3      18     18     6      6      | 340   
osd.66  5      151    112    6      0      4      3      4      4      17     20     3      4      | 333   
osd.67  4      153    113    8      0      7      2      7      3      19     13     5      3      | 337   
osd.68  7      153    115    3      0      6      3      5      0      14     12     2      5      | 325   
osd.69  5      151    114    3      0      8      3      5      3      16     21     3      5      | 337   
osd.70  5      152    113    7      0      3      4      8      5      24     16     2      6      | 345   
osd.71  3      151    112    2      0      8      6      3      7      18     22     5      5      | 342   
osd.72  8      151    112    7      0      4      5      5      5      13     18     8      6      | 342   
osd.73  4      151    114    2      0      13     6      6      3      23     18     5      2      | 347   
osd.74  3      153    114    7      0      3      1      3      6      24     11     6      3      | 334   
osd.75  3      150    115    1      0      9      5      6      4      19     21     1      7      | 341   
osd.76  5      153    115    4      0      5      6      5      3      26     21     4      3      | 350   
osd.77  2      153    114    5      0      12     4      4      7      22     23     4      3      | 353   
osd.78  5      153    114    4      0      2      8      5      5      26     22     7      5      | 356   
osd.79  2      152    113    5      0      5      3      2      5      22     23     9      4      | 345   
osd.80  7      150    113    7      0      5      3      4      2      23     17     3      2      | 336   
osd.81  3      152    114    2      0      4      4      4      4      24     13     4      4      | 332   
osd.82  5      151    112    5      0      6      1      7      7      24     26     4      8      | 356   
osd.83  5      151    112    2      0      7      5      6      6      24     24     5      6      | 353   
osd.84  1      153    114    6      0      4      6      2      4      13     9      9      3      | 324   
osd.85  5      151    112    4      0      4      8      8      6      11     10     7      4      | 330   
osd.86  7      150    112    8      0      4      5      4      2      19     22     4      4      | 341   
osd.87  5      152    115    4      0      5      4      5      3      15     18     7      9      | 342   
osd.88  3      150    112    2      0      4      3      7      4      15     21     1      4      | 326   
osd.89  6      151    114    4      0      7      5      3      4      23     22     4      2      | 345   
osd.90  1      151    114    1      0      0      4      3      3      22     22     8      4      | 333   
osd.91  3      150    115    8      0      3      6      7      3      16     19     5      6      | 341   
osd.92  6      152    115    3      0      4      2      3      5      24     20     4      4      | 342   
osd.93  4      153    114    5      0      6      2      6      8      18     15     5      4      | 340   
osd.94  8      153    115    8      0      3      6      5      4      15     14     6      2      | 339   
osd.95  7      152    114    3      0      4      5      7      6      23     25     2      3      | 351   
osd.96  3      150    115    2      0      4      6      8      7      24     20     5      7      | 351   
osd.97  10     150    115    2      0      3      7      5      5      12     15     5      8      | 337   
osd.98  4      153    115    5      0      5      8      4      6      20     14     5      4      | 343   
osd.99  6      152    115    6      0      2      5      7      2      18     19     4      4      | 340   
osd.100 3      151    113    5      0      8      8      5      6      18     17     5      4      | 343   
osd.101 5      152    113    7      0      3      2      2      9      14     27     11     6      | 351   
osd.102 6      152    113    2      0      2      4      4      4      14     17     5      7      | 330   
osd.103 1      152    112    8      0      6      2      2      3      16     19     6      4      | 331   
osd.104 6      153    113    1      0      2      5      5      8      21     18     3      4      | 339   
osd.105 3      153    113    6      0      7      5      0      5      22     23     5      4      | 346   
osd.106 7      152    115    6      0      3      8      6      6      13     18     2      4      | 340   
osd.107 3      152    114    7      0      12     3      2      7      22     23     6      3      | 354   
osd.108 0      0      0      0      171    0      0      0      0      0      0      0      0      | 171   
osd.109 0      0      0      0      170    0      0      0      0      0      0      0      0      | 170   
osd.110 0      0      0      0      171    0      0      0      0      0      0      0      0      | 171   

--------------------------------------------------------------------------------------------------------------

SUM   : 512    16384  12288  512    512    512    512    512    512    2048   2048   512    512    |
root@node166:~# 
</code></pre>
<h2 id="ke-xing-xing-yan-zheng">可行性验证</h2>
<h3 id="ec-4-2-2-pan-zu-raid-0">EC 4+2， 2盘组RAID0</h3>
<p>2021-09-09</p>
<p>01:52集群异常，是因为忘记调整obj meta size，导致默认值情况下计算的inode耗尽，如下图所示：</p>
<img class="shadow" src="/img/in-post/clip_image001-16316766830863.png" width="600">
<p>当时数据已经写了3.2亿左右，没有截图，早上上班时候，发现此问题，调整了参数，继续灌数据：</p>
<img class="shadow" src="/img/in-post/clip_image002-16316766830874.png" width="600">
<p>从上面图可以看出来，凌晨2点48前后，集群没有流量了：</p>
<img class="shadow" src="/img/in-post/clip_image003-16316766829691.png" width="600">
<p>出现了Near full 和backfillfull，此时还是可以继续写入的，只是接着出现了FULL，97%了，导致数据无法写入：</p>
<img class="shadow" src="/img/in-post/clip_image004-16316766829702.png" width="600">
<p>早上到Office后，调整了参数，让数据继续灌，不打算终止重新跑，因为只要此刻开始，后面只要写入的数据是平稳的，没有衰减，目的就达到了，持续观察中（下面是灌了4.98亿对象时看到的状况截图）：</p>
<img class="shadow" src="/img/in-post/clip_image005.png" width="600">
<img class="shadow" src="/img/in-post/clip_image006.png" width="600">
<img class="shadow" src="/img/in-post/clip_image007.png" width="600">
<img class="shadow" src="/img/in-post/clip_image008.png" width="600">
<p>后面3个节点，相较前3个节点， NVME SSD比较弱了。</p>
<p>重做集群（2021-09-11）：</p>
<img class="shadow" src="/img/in-post/clip_image009.png" width="600">
<p>写了5.7亿，pool出现 near full，衰减的厉害。</p>
<img class="shadow" src="/img/in-post/clip_image010.png" width="600">
<h3 id="ec-4-2-2-pan-raid-0-dan-mei-ge-node-shi-yong-10-zu-raid-zuo-osd">EC 4+2 2盘RAID0, 但每个node使用10组RAID做OSD</h3>
<p>2021-09-12</p>
<img class="shadow" src="/img/in-post/clip_image011.png" width="600">
<img class="shadow" src="/img/in-post/clip_image012.png" width="600">
<p>出现OSD near full，之后写性能下降。</p>
<h3 id="6-pan-zu-raid-0-mei-ge-node-6-ge-osd">6盘组RAID0，每个node 6个OSD</h3>
<p>2021-09-13</p>
<p>前3个node，用一块 Nvme 做ssd osd pool</p>
<img class="shadow" src="/img/in-post/clip_image013.png" width="600">
<img class="shadow" src="/img/in-post/clip_image014.png" width="600">
<p>还是出现了metadata pool full，与osd full的问题</p>
<p>2021-09-14</p>
<p>考虑到上面没有多metadata pool做PG split，PG数量太少，objects数量太多，有可能引发osd metadata near full问题，导致性能下降。</p>
<p>重做环境，继续观察。</p>
<h1 id="lab-ji-xu-hou-xu-ce-shi">Lab 继续后续测试</h1>
<h2 id="chang-jing-1-enable-rack-awareness-ec-2-1-kong-tong-zhuang-kuang-xia-shang-chuan-7-2-yi-4-k-xiao-dui-xiang">场景1 Enable Rack Awareness， EC 2+1，空桶状况下上传7.2亿4K小对象</h2>
<h3 id="cun-chu-duan-xin-xi">存储端信息</h3>
<p>灌的object量：</p>
<img class="shadow" src="/img/in-post/image-20210915120446571.png" width="600">
<p>集群统计信息：</p>
<img class="shadow" src="/img/in-post/image-20210915115732869.png" width="600">
<img class="shadow" src="/img/in-post/image-20210915120241981.png" width="600">
<h3 id="cosbench-duan-tong-ji-xin-xi">cosbench端统计信息</h3>
<img class="shadow" src="/img/in-post/image-20210915120102542.png" width="600">
<img class="shadow" src="/img/in-post/image-20210915120139930.png" width="600">
<h3 id="xing-neng-ping-jing">性能瓶颈</h3>
<p>如下为node4~node6的NVME atop信息片断，这3个节点NVME SSD要表node1~node3的NVME SSD弱一个档次。</p>
<h4 id="node-166">node 166</h4>
<img class="shadow" src="/img/in-post/clip_image015.png" width="600">
<img class="shadow" src="/img/in-post/clip_image016.png" width="600">
<img class="shadow" src="/img/in-post/clip_image017.png" width="600">
<h4 id="node-165">node 165</h4>
<img class="shadow" src="/img/in-post/clip_image018.png" width="600">
<img class="shadow" src="/img/in-post/clip_image019.png" width="600">
<h4 id="node-164">node 164</h4>
<img class="shadow" src="/img/in-post/clip_image020.png" width="600">
<h3 id="yi-wen">疑问</h3>
<p>整个过程中没有看到HDD忙，考虑到NVME SSD空间比较大，而且调整过bigterastore object cache size为1000万，总共是108个HDD OSD和 3 个NVME OSD，SSD 能够容纳的对象数是11亿左右(1000万*111个OSD)，上面总共灌了7.2亿对象，这些对象在SSD里，所以没有看到衰减迹象。</p>
<p>下个场景，改变一下测试策略，不再调整object cache size，使用默认值（100万）。</p>
<h2 id="chang-jing-2-ec-4-2-kong-tong-zhuang-kuang-xia-shang-chuan-12-yi-4-k-xiao-dui-xiang">场景2 EC 4+2，空桶状况下上传12亿4k小对象</h2>
<p>使用默认的be cache max objs参数，灌12亿对象到单一bucket中，但灌到8亿的时候出现osd near full，再继续灌下去，出现osd full，然后性能开始下降了，所以先记录数据，终止测试，下一轮次依然是12亿的目标，但会将metadata pool 和s3 data pool的PG数放大验证看看。</p>
<h3 id="tong-ji-xin-xi">统计信息</h3>
<h4 id="cun-chu-ui-duan">存储UI端</h4>
<img class="shadow" src="/img/in-post/image-20210916194250670.png" width="600">
<h4 id="cun-chu-hou-duan">存储后端</h4>
<img class="shadow" src="/img/in-post/image-20210916194313663.png" width="600">
<h4 id="cosbench-tong-ji">cosbench 统计</h4>
<img class="shadow" src="/img/in-post/image-20210916194358253.png" width="600">
<img class="shadow" src="/img/in-post/image-20210916194428439.png" width="600">
<h3 id="ying-jian-zi-yuan-kai-xiao">硬件资源开销</h3>
<p>如果是在灌了5.4+亿对象后截屏信息</p>
<img class="shadow" src="/img/in-post/image-20210916091341852.png" width="600">
<h4 id="atop-xin-xi">atop信息</h4>
<p>node161</p>
<img class="shadow" src="/img/in-post/image-20210916091729055.png" width="600">
<p>node162</p>
<img class="shadow" src="/img/in-post/image-20210916091738876.png" width="600">
<p>node163</p>
<img class="shadow" src="/img/in-post/image-20210916091749509.png" width="600">
<p>node164</p>
<img class="shadow" src="/img/in-post/image-20210916091759035.png" width="600">
<p>node165</p>
<img class="shadow" src="/img/in-post/image-20210916091809408.png" width="600">
<p>node166</p>
<img class="shadow" src="/img/in-post/image-20210916091824733.png" width="600">
<h4 id="iostat-xin-xi">iostat信息</h4>
<p>node161</p>
<img class="shadow" src="/img/in-post/image-20210916091114070.png" width="600">
<p>node162</p>
<img class="shadow" src="/img/in-post/image-20210916091512154.png" width="600">
<p>node163</p>
<img class="shadow" src="/img/in-post/image-20210916091522315.png" width="600">
<p>node164</p>
<img class="shadow" src="/img/in-post/image-20210916091545140.png" width="600">
<p>node165</p>
<img class="shadow" src="/img/in-post/image-20210916091555478.png" width="600">
<p>node166</p>
<img class="shadow" src="/img/in-post/image-20210916091604747.png" width="600">
<p>注意点：</p>
<p>在灌了7.6亿对象情况下，发现部分osd的metadata usage 接近near full阈值（0.85），下图是设置bigterastore_obj_meta_size=1024下看到的信息：</p>
<img class="shadow" src="/img/in-post/image-20210916172730569.png" width="600">
<p>现在调整bigterastore_obj_meta_size=512，执行上面的脚本获取osd的metadata usage并没有发生变化。</p>
<h3 id="zai-ci-ce-shi">再次测试</h3>
<p>2021-09-16</p>
<p>放大metadata 和 s3-data-pool的PG numbers</p>
<pre><code class="language-shell">root@node166:~# ceph osd pool get s3-data-pool pg_num
pg_num: 2048
root@node166:~# ceph osd pool get metadata pg_num
pg_num: 8192
</code></pre>
<pre><code class="language-shell">root@node166:~# cat enlarge_pg.sh 
# pool_name='s3-data-pool'
pool_name='metadata'
cur_pg_num=`ceph osd pool get ${pool_name} pg_num |awk -F ':' '{{print $NF}}'`
target_pg_num=`expr ${cur_pg_num} \* 3`

for i in {1..256}; do
    cur_pg_num=`ceph osd pool get ${pool_name} pg_num |awk -F ':' '{{print $NF}}'`
    new_pg_num=`expr ${cur_pg_num} + 128`
    ceph osd pool set ${pool_name} pg_num ${new_pg_num}
    ceph osd pool set ${pool_name} pgp_num ${new_pg_num}
    sleep 0.2
    if [[ ${new_pg_num} -eq ${target_pg_num} ]]; then
        break
    fi
done
root@node166:~# 
</code></pre>
<p>当灌到4.4亿的时候，查看了各个osd的matedata usage，发现前3个node与后3个node的用量还是有蛮大差距：</p>
<img class="shadow" src="/img/in-post/image-20210917163813310-16318678940801.png" width="600">
<img class="shadow" src="/img/in-post/image-20210917163853593.png" width="600">
<pre><code class="language-shell">root@node163:~# ceph daemon osd.48 perf dump bigterastore
{
    "bigterastore": {
        "bt_js_coll_num": 877,
        "bt_js_obj_num": 280268,
        "bt_js_attrs_bytes": 154207729,
        "bt_js_attrs_num": 1610103,
        "bt_js_attrs_rm_num": 0,
        "bt_js_omap_bytes": 5580884,
        "bt_js_omap_num": 92452,
        "bt_js_omap_rm_num": 90618,
        "bt_bc_coll_num": 877,
        "bt_bc_obj_num": 1573011,
        "bt_bc_dirty_obj_num": 1572988,
       "bt_bc_obj_reads": 53,
        "bt_bc_obj_writes": 64191,
        "bt_bc_obj_read_miss": 22,
        "bt_bc_dirty_size": 37119551,
        "bt_bj_transaction_wait_buf": 0,
        "bt_bj_transaction_wait_aio": 0,
        "bt_bj_transaction_in_flight": 0,
        "bt_bj_flusher_s_dispt": 0,
        "bt_bj_flusher_o_dispt": 0,
        "bt_bj_flusher_segments": 0,
        "bt_bj_flusher_objs": 0,
        "bt_bj_segment_head": 2,
        "bt_bj_segment_flushed": 15,
        "bt_bj_segment
        }
}

root@node164:~# ceph daemon osd.56 perf dump bigterastore
{
    "bigterastore": {
        "bt_js_coll_num": 867,
        "bt_js_obj_num": 250467,
        "bt_js_attrs_bytes": 119715269,
        "bt_js_attrs_num": 1249755,
        "bt_js_attrs_rm_num": 0,
        "bt_js_omap_bytes": 4524222,
        "bt_js_omap_num": 74818,
        "bt_js_omap_rm_num": 73086,
        "bt_bc_coll_num": 867,
        "bt_bc_obj_num": 7830607,
        "bt_bc_dirty_obj_num": 7830443,
        "bt_bc_obj_reads": 15,
        "bt_bc_obj_writes": 70003,
        "bt_bc_obj_read_miss": 2,
        "bt_bc_dirty_size": 81089512,
        "bt_bj_transaction_wait_buf": 0,
        "bt_bj_transaction_wait_aio": 0,
        "bt_bj_transaction_in_flight": 37,
        "bt_bj_flusher_s_dispt": 0,
        "bt_bj_flusher_o_dispt": 0,
        "bt_bj_flusher_segments": 0,
        "bt_bj_flusher_objs": 0,
        "bt_bj_segment_head": 12,
        "bt_bj_segment_flushed": 9,
        "bt_bj_segment_trimmed": 6
    }
}
</code></pre>
<p>Big帮忙确认了一下：</p>
<p>前3个node的nvme性能比较强悍，object flush&amp;evict比较快，所以HDD的空间消耗也明显比后面3个节点多，前3个node cache object也少于后面的3台，建议各个node统一下NVME SSD。</p>
<h2 id="lab-zui-zhong-ce-shi">Lab最终测试</h2>
<p>2021-09-17</p>
<p>说明：</p>
<p>​       如下场景的测试，各个node均有一块ADATA NVME SSD，确保各个node Bigterastore Cache FS inode 均衡，不会因NVME SSD性能不同造成flush/evict不同，引发各个node的Bigterastore Cache FS inode消耗不均衡。</p>
<h3 id="yi-bei-fang-da-pg-shu">一倍放大PG数</h3>
<p>每个node使用相同的NVME SSD(ADATA)做OSD的Journal&amp;Cache;</p>
<p>即将原来node161~163上的一块ADATA NVME SSD替换到node164<sub>166上，确保node161</sub>166 6个node都有一块ADATA NVME SSD；</p>
<p>将node164~166上的P4510/4610 NVME SSD，给node161~163使用，做nvme ssd pool as s3 index pool，因为这3个node的CPU更强悍。</p>
<p>虽然Big说不再放大PG数，考虑到对象数据较大，本次测试还是放大了一倍看看效果如何，metadata pool 、s3-data-pool和 s3-index-pool均有放大一倍：</p>
<img class="shadow" src="/img/in-post/image-20210917180327779.png" width="600">
<p>说明：</p>
<p>​    32768为2副本的metadata pool；</p>
<p>​    24576为4+2EC s3-data-pool；</p>
<p>​    1024为2副本s3-index-pool</p>
<p>整个测试期间，瓶颈在NVME(不是S3 index pool对应的 NVME SSD):</p>
<p>node161</p>
<img class="shadow" src="/img/in-post/image-20210918093146977.png" width="600">
<p>node162</p>
<img class="shadow" src="/img/in-post/image-20210918092754619.png" width="600">
<p>node163</p>
<img class="shadow" src="/img/in-post/image-20210918093206742.png" width="600">
<p>node164</p>
<img class="shadow" src="/img/in-post/image-20210918093216922.png" width="600">
<p>node165</p>
<img class="shadow" src="/img/in-post/image-20210918093230042.png" width="600">
<p>node166</p>
<img class="shadow" src="/img/in-post/image-20210918093239165-16319287600391.png" width="600">
<p>2021-09-18</p>
<p>写了6.2个亿对象</p>
<img class="shadow" src="/img/in-post/image-20210918172307957.png" width="600">
<p>此时UI统计信息：</p>
<img class="shadow" src="/img/in-post/image-20210918172246927.png" width="600">
<p>这里有波动，基本上一个小时出现一次，推测是flush/evict造成，尚未找到具体证据。</p>
<p>2021-09-19</p>
<img class="shadow" src="/img/in-post/image-20210919071321059.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919071510301.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919071335003.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919071413716.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919071413716.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919071529108.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919074457366.png" width="600">
<p>至此之后，性能直线衰减。</p>
<p>停掉cosbench task，此后各个node持续flush/evict object到HDD：</p>
<img class="shadow" src="/img/in-post/image-20210919072945984.png" width="600">
<p>cosbench停掉10余个小时后：</p>
<img class="shadow" src="/img/in-post/image-20210919212209412.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919212310757.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919212355948.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919212405803.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919212419913.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919212430537.png" width="600">
<p>各个node 的cache inode消耗：</p>
<img class="shadow" src="/img/in-post/image-20210919073449099.png" width="600">
<p>各个节点HDD inode消耗：</p>
<img class="shadow" src="/img/in-post/image-20210919074234373.png" width="600">
<p>说明flush/evich比较慢，停掉cosbench task 大约7个小时候，各个node的osd与cache inode消耗情况如下：</p>
<img class="shadow" src="/img/in-post/image-20210919160536018.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919160704064.png" width="600">
<p>从这个角度讲，存储能写多少4k的小object，取决于2方面：</p>
<ol>
<li class="lvl-3">
<p>产品默认支持计算出来的inode是否能够满足实际需要；</p>
</li>
<li class="lvl-3">
<p>ssd flush/evict是否足够快，HDD能够支撑住如此快的flush/evict</p>
</li>
</ol>
<p>考虑到我验证的场景是验证不会随着bucket中对象数的增多而出现衰减，所以考虑重新测试，降低cosbench写速度，避免因写的太快而flush/evict太慢造成osd cache inode提早耗尽出现性能断崖式衰减。</p>
<p>继续在灌了10亿基础上，等待cache inode消耗减低至0.5以下后，写3亿4K小对象，观察有10亿基础数据情况下，这3亿对象写期间性能是否会衰减</p>
<img class="shadow" src="/img/in-post/image-20210919224911546.png" width="600">
<img class="shadow" src="/img/in-post/image-20210919224922984.png" width="600">
<p>期间node164 因memory 耗尽出现osd down，始终无法恢复，重启机器与只启用部分osd（18个osd启用15个），无法恢复；第三次重启机器后，只启用了一半的osd，且等待cache inode 消耗降低到1%情况下：</p>
<img class="shadow" src="/img/in-post/image-20210922120820942.png" width="600">
<p>然后逐步启用余下的osd：</p>
<img class="shadow" src="/img/in-post/image-20210922144652265.png" width="600">
<p>但osd pg log占用太多memory，只能等PG状态全部是active+clean情况下，才会释放多余的pg log所占用的memory：</p>
<img class="shadow" src="/img/in-post/image-20210922183619848.png" width="600">
<p>最终还是没法启动所有的osd，只能停用node164上的部分osd，在PG处于如下状态，灌1亿4Kobjects：</p>
<img class="shadow" src="/img/in-post/image-20210923092445769.png" width="600">
<p>期间NVME 与 HDD 都非常忙，重点是NVME，有做Bigterastore cache，新写入的数据会先到Cache里：</p>
<img class="shadow" src="/img/in-post/image-20210923092826977.png" width="600">
<p>调整过be_cache_paused_flusher_qsize到32（默认1），cosbench展示的各个driver的OPS波动比较大了，之后又恢复默认值：</p>
<img class="shadow" src="/img/in-post/image-20210923104645353.png" width="600">
<p>之后碰到cache写满导致osd crash</p>
<img class="shadow" src="/img/in-post/image-20210923120045816.png" width="600">
<img class="shadow" src="/img/in-post/image-20210923120106531.png" width="600">
<img class="shadow" src="/img/in-post/image-20210923120134914.png" width="600">
<p>集群测统计信息：</p>
<img class="shadow" src="/img/in-post/image-20210923120004636.png" width="600">
<img class="shadow" src="/img/in-post/image-20210923120013254.png" width="600">
<p>cosbench统计信息：</p>
<img class="shadow" src="/img/in-post/image-20210923120217426.png" width="600">
<p>各个node的inode消耗情况：</p>
<img class="shadow" src="/img/in-post/image-20210923125119637.png" width="600">
<p>说明：</p>
<p>node164 有部分osd down，因memory不足无法启动起来，后来停用了这个node上的一批osd，所以会存在部分cache FS inode消耗明显高很多的状况。</p>
<p>结论：</p>
<p>​    从UI统计折线图看，无需手工放大PG数，产品Enable PG Split所分裂出来的PG数更优异。</p>
<h4 id="shi-yong-qi-yong-pg-split-gong-neng-hou-de-pg-shu-guan-4-k-1200-million-dui-xiang-jiang-di-cosbench-xie-su-du">使用启用PG Split功能后的PG数，灌4K 1200Million 对象，降低cosbench写速度</h4>
<pre><code class="language-shell">root@node166:~# ./pg_allocate.py 
dumped all

pool  : 1      10     12     13     14     2      3      4      5      6      7      8      9      | SUM
--------------------------------------------------------------------------------------------------------------
osd.0   8      152    5      113    0      2      5      6      4      17     21     8      5      | 346   
osd.1   4      151    7      112    0      4      4      5      5      17     16     4      2      | 331   
osd.2   5      153    6      112    0      4      2      6      8      23     19     3      4      | 345   
osd.3   2      153    7      113    0      2      6      7      5      15     21     4      6      | 341   
osd.4   4      151    1      114    0      5      9      5      4      13     19     7      2      | 334   
osd.5   4      153    4      115    0      3      8      3      3      16     21     3      3      | 336   
osd.6   7      152    3      115    0      1      3      4      3      21     25     6      3      | 343   
osd.7   7      153    6      115    0      5      4      6      4      23     19     8      4      | 354   
osd.8   3      152    3      112    0      1      5      4      6      13     23     2      5      | 329   
osd.9   6      150    1      114    0      6      3      4      4      25     14     3      3      | 333   
osd.10  6      152    4      113    0      2      3      5      0      21     11     8      2      | 327   
osd.11  3      150    3      114    0      9      5      4      7      22     16     2      5      | 340   
osd.12  4      152    6      115    0      7      8      4      3      18     23     4      4      | 348   
osd.13  4      153    2      113    0      7      6      4      5      22     17     9      6      | 348   
osd.14  6      151    9      115    0      3      8      6      1      22     21     9      2      | 353   
osd.15  7      151    1      114    0      4      3      8      5      18     21     5      10     | 347   
osd.16  4      153    8      115    0      7      2      9      5      14     12     6      8      | 343   
osd.17  4      151    6      114    0      6      8      5      5      14     23     6      7      | 349   
osd.18  7      150    6      112    0      3      7      4      2      23     21     1      5      | 341   
osd.19  5      153    6      114    0      4      5      8      8      17     16     6      4      | 346   
osd.20  1      152    4      115    0      5      3      2      4      12     16     5      5      | 324   
osd.21  5      150    4      113    0      4      3      5      6      25     21     2      9      | 347   
osd.22  5      152    8      114    0      8      2      6      6      15     19     1      7      | 343   
osd.23  5      151    6      112    0      9      3      5      6      21     25     5      5      | 353   
osd.24  3      153    11     114    0      2      9      6      8      24     24     5      2      | 361   
osd.25  4      151    5      114    0      6      4      4      3      14     26     5      6      | 342   
osd.26  4      151    3      115    0      3      9      5      3      20     21     4      9      | 347   
osd.27  3      153    1      114    0      5      9      2      3      20     22     6      4      | 342   
osd.28  5      153    4      115    0      6      5      5      6      19     17     5      6      | 346   
osd.29  6      151    6      114    0      5      2      3      4      22     24     6      0      | 343   
osd.30  5      151    6      114    0      6      7      4      6      15     21     4      3      | 342   
osd.31  2      152    1      113    0      4      1      4      7      16     16     7      6      | 329   
osd.32  3      153    7      114    0      8      6      9      10     20     18     2      5      | 355   
osd.33  6      150    4      114    0      7      3      2      3      21     18     2      6      | 336   
osd.34  3      153    2      114    0      3      3      4      4      14     13     5      7      | 325   
osd.35  4      151    5      113    0      7      3      5      5      18     17     6      4      | 338   
osd.36  4      151    7      115    0      4      5      3      5      20     20     2      5      | 341   
osd.37  2      153    4      114    0      4      5      3      2      20     11     5      4      | 327   
osd.38  3      153    1      115    0      4      4      4      8      16     14     6      4      | 332   
osd.39  3      151    9      115    0      2      3      1      3      17     26     4      6      | 340   
osd.40  4      151    6      115    0      0      7      5      4      28     20     2      4      | 346   
osd.41  5      151    7      114    0      3      4      2      5      20     19     10     4      | 344   
osd.42  3      151    6      112    0      5      6      4      4      16     12     7      1      | 327   
osd.43  0      150    5      115    0      5      4      6      2      23     16     4      7      | 337   
osd.44  4      151    6      114    0      3      4      6      6      13     19     4      3      | 333   
osd.45  6      150    7      114    0      7      4      7      3      21     23     4      8      | 354   
osd.46  7      152    5      113    0      4      6      5      6      32     15     5      6      | 356   
osd.47  10     151    5      112    0      4      2      5      3      12     26     5      1      | 336   
osd.48  8      153    5      114    0      4      6      4      4      24     21     4      3      | 350   
osd.49  3      151    6      113    0      6      2      2      11     11     19     6      5      | 335   
osd.50  2      153    4      113    0      6      4      4      6      13     20     4      5      | 334   
osd.51  7      150    2      113    0      3      10     5      5      23     17     2      3      | 340   
osd.52  7      151    5      113    0      4      12     1      3      18     26     5      3      | 348   
osd.53  4      152    3      114    0      6      6      5      3      17     16     6      9      | 341   
osd.54  5      152    6      115    0      6      6      5      4      22     20     4      7      | 352   
osd.55  3      151    6      113    0      1      3      2      6      28     20     4      8      | 345   
osd.56  4      153    3      112    0      5      5      6      7      23     16     4      4      | 342   
osd.57  8      153    5      114    0      4      4      8      8      14     15     1      5      | 339   
osd.58  6      152    5      114    0      4      7      5      3      22     16     7      4      | 345   
osd.59  5      153    9      114    0      2      3      4      7      23     21     5      3      | 349   
osd.60  6      152    5      115    0      6      3      1      4      18     25     5      5      | 345   
osd.61  4      153    7      113    0      4      6      2      5      13     17     4      5      | 333   
osd.62  5      150    4      112    0      5      3      2      6      12     19     6      1      | 325   
osd.63  4      150    3      115    0      5      4      11     5      14     20     7      4      | 342   
osd.64  7      153    9      114    0      8      3      2      7      15     15     5      3      | 341   
osd.65  2      153    4      115    0      3      3      3      3      15     24     3      8      | 336   
osd.66  7      153    4      114    0      2      2      6      3      17     11     7      5      | 331   
osd.67  7      151    4      114    0      6      3      7      5      23     19     4      5      | 348   
osd.68  9      153    7      113    0      3      5      6      3      21     24     9      2      | 355   
osd.69  1      152    4      114    0      4      8      1      5      24     14     2      8      | 337   
osd.70  6      150    5      114    0      1      6      6      4      16     20     2      4      | 334   
osd.71  7      152    7      113    0      5      6      2      7      22     17     6      7      | 351   
osd.72  4      152    3      114    0      4      8      5      6      9      18     9      6      | 338   
osd.73  7      153    5      113    0      12     5      5      2      23     18     6      6      | 355   
osd.74  2      151    9      114    0      2      3      2      3      26     13     2      1      | 328   
osd.75  6      153    3      113    0      7      6      1      4      14     15     4      6      | 332   
osd.76  5      153    2      114    0      4      8      8      3      23     22     3      2      | 347   
osd.77  6      153    6      115    0      10     5      5      8      20     25     3      4      | 360   
osd.78  4      151    3      113    0      0      6      6      3      19     23     5      4      | 337   
osd.79  5      151    7      115    0      6      6      5      5      26     18     5      2      | 351   
osd.80  6      151    6      114    0      8      6      5      2      28     24     4      5      | 359   
osd.81  4      150    4      113    0      4      5      4      7      21     12     6      5      | 335   
osd.82  5      150    5      114    0      10     2      5      3      23     21     2      8      | 348   
osd.83  3      152    4      113    0      7      3      6      2      22     21     4      3      | 340   
osd.84  5      152    7      114    0      5      5      7      7      12     10     3      4      | 331   
osd.85  6      150    6      114    0      7      4      5      6      12     9      6      5      | 330   
osd.86  5      153    7      114    0      8      3      5      4      23     19     6      5      | 352   
osd.87  9      151    2      113    0      6      4      6      5      12     18     9      9      | 344   
osd.88  6      152    3      114    0      3      4      5      3      19     19     1      4      | 333   
osd.89  5      152    4      114    0      3      6      6      6      18     27     4      5      | 350   
osd.90  6      151    1      112    0      4      3      5      6      20     21     5      3      | 337   
osd.91  3      152    4      114    0      7      9      5      8      24     24     4      7      | 361   
osd.92  3      153    6      114    0      4      5      2      6      23     22     3      3      | 344   
osd.93  5      150    3      113    0      4      4      6      5      22     18     10     6      | 346   
osd.94  7      153    2      114    0      2      2      4      7      15     15     5      3      | 329   
osd.95  5      152    4      114    0      4      3      5      4      17     27     2      2      | 339   
osd.96  5      150    5      114    0      4      2      4      4      22     15     4      7      | 336   
osd.97  6      152    3      115    0      4      5      5      3      12     14     4      2      | 325   
osd.98  2      153    3      114    0      2      3      12     5      18     23     3      5      | 343   
osd.99  1      151    6      113    0      7      1      4      2      19     23     5      3      | 335   
osd.100 3      151    5      112    0      7      5      3      8      24     13     3      6      | 340   
osd.101 9      150    0      114    0      5      5      8      3      20     19     8      3      | 344   
osd.102 4      151    5      112    0      3      7      5      1      13     20     9      6      | 336   
osd.103 3      152    5      115    0      3      1      3      2      21     13     5      6      | 329   
osd.104 7      153    4      114    0      5      5      7      6      14     24     3      8      | 350   
osd.105 2      153    3      115    0      6      3      3      7      20     15     1      6      | 334   
osd.106 1      151    3      114    0      3      4      6      7      17     18     9      7      | 340   
osd.107 5      152    3      115    0      11     6      5      3      21     22     3      2      | 348   
osd.108 0      0      0      0      170    0      0      0      0      0      0      0      0      | 170   
osd.109 0      0      0      0      171    0      0      0      0      0      0      0      0      | 171   
osd.110 0      0      0      0      171    0      0      0      0      0      0      0      0      | 171   

--------------------------------------------------------------------------------------------------------------

SUM   : 512    16384  512    12288  512    512    512    512    512    2048   2048   512    512    |
root@node166:~# ceph df
GLOBAL:
    SIZE        AVAIL       RAW USED     %RAW USED 
    1.55PiB     1.55PiB      3.73GiB             0 
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS 
    .rgw.root                     1      1.07KiB         0        354TiB           4 
    default.rgw.control           2           0B         0        295TiB           8 
    default.rgw.meta              3      2.13KiB         0        295TiB          15 
    default.rgw.log               4           0B         0        295TiB         192 
    .ezs3                         5           0B         0        322TiB           1 
    data                          6           0B         0        443TiB           0 
    default.rgw.buckets.data      7           0B         0        525TiB           0 
    .ezs3.central.log             8       130KiB         0        354TiB           4 
    .ezs3.statistic               9      44.4MiB         0        354TiB         760 
    metadata                      10          0B         0        740TiB           0 
    default.rgw.buckets.index     12          0B         0        322TiB           0 
    s3-data-pool                  13          0B         0        985TiB           0 
    s3-index-pool                 14          0B         0       5.13TiB        1134 
root@node166:~# 

</code></pre>
<p>经过几天持续的灌入，后期（大约最后一亿的对象）由于cosbench task部分workers与部分driver还在持续运行中，如下图所示：</p>
<img class="shadow" src="/img/in-post/image-20210929134618041.png" width="600">
<p>部分workers已经结束，但对应driver的部分worker下的mission还在持续运行中：</p>
<img class="shadow" src="/img/in-post/image-20210929134755657.png" width="600">
<img class="shadow" src="/img/in-post/image-20210929134818421.png" width="600">
<p>导致cosbench客户端压力不足，整体性能衰减，不应理解为产品问题。</p>
<p>最终灌12亿对象的效果如下：</p>
<p>存储端：</p>
<img class="shadow" src="/img/in-post/image-20210929203936269.png" width="600">
<img class="shadow" src="/img/in-post/image-20210929204018898.png" width="600">
<img class="shadow" src="/img/in-post/image-20210929204227169.png" width="600">
<p>​    由于测试到尾声的时候，cosbench task对应driver里有部分的workers结束，有的整个driver结束，导致后期cosbench 压测的压力不足，所以性能衰减，可以参考28号6:00之前的数据，整体看有衰减，但衰减波动幅度不大。</p>
<p>只看前11亿数据：</p>
<img class="shadow" src="/img/in-post/image-20210930053341048.png" width="600">
<img class="shadow" src="/img/in-post/image-20210930053415952.png" width="600">
<p>cosbench task信息：</p>
<img class="shadow" src="/img/in-post/image-20210930192626096.png" width="600">
<p>cosbench绘制不了折线图了，这里以driver1显示的速度做标记，最初是500ops，跑到结束的时候大约300+，平均下来400+的ops：</p>
<img class="shadow" src="/img/in-post/image-20210930194736058.png" width="600">
<h2 id="ji-chu-shu-ju-10-yi-xia-guan-yi-yi-4-k">基础数据10亿下灌一亿4k</h2>
<p>PG split功能开启，创建s3-data-pool&amp;s3-index-pool，PG分布均衡，做了上面的参数优化</p>
<p>单一bucket，存在10.2亿数据，持续灌1亿4K对象</p>
<p>开始是有10.2亿数据：</p>
<img class="shadow" src="/img/in-post/Base on 102 Million, start to write 10 Million-start.png" width="600">
<p>然后灌1亿对象：</p>
<img class="shadow" src="/img/in-post/image-20211009122645425.png" width="600">
<img class="shadow" src="/img/in-post/Base on 102 Million, start to write 10 Million-end.png" width="600">
<p>cosbench task信息：</p>
<img class="shadow" src="/img/in-post/image-20211009122521049.png" width="600">
<h1 id="jie-shu-yu">结束语</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>metadata pool， s3 data pool 需要启用PG Split功能</p>
</li>
<li class="lvl-2">
<p>确保 metadata pool， s3 data pool，s3 index pool PG分布均衡</p>
</li>
<li class="lvl-2">
<p>无需人为再次放大metadata pool，s3 data pool, s3 index pool 的 pg_num&amp;pgp_num，放大后并不能提升性能，反而出现间歇性的性能衰减</p>
</li>
<li class="lvl-2">
<p>集群中各个节点的硬件规格一致，特别在有NVME SSD做OSD Bigterastore Cache情况下，NVME SSD 规格要一致</p>
<ul class="lvl-2">
<li class="lvl-5">如存在有Bigterastore Cache对应SSD性能弱情况下，使得性能弱的SSD所在disk inode的消耗过多（cosbench写的快，但flush/evict慢），会提早出现pool full问题造成性能断崖式衰减</li>
</ul>
</li>
<li class="lvl-2">
<p>针对客户POC性能测试场景，测试时需区别对待</p>
<ul class="lvl-2">
<li class="lvl-4">
<p>关注性能指标，有明确OPS要求的场景</p>
<ul class="lvl-4">
<li class="lvl-6">
<p>如要求OPS为5000的，建议空桶状态下测试，可适当放大cosbench work对应workers数量来压测，比如workers=48</p>
</li>
<li class="lvl-6">
<p>如要求bucket中有一定数据量，比如bucket下已有5亿对象，确保Bigterastroe Cache所在文件系统的inode消耗处于比较低的水位（e.g:df -f /data/cache/osd-name*）情况下压测，避免在inode处于高消耗状态下压测更多数据，这样只会引发pool full造成断崖式性能下跌</p>
</li>
</ul>
</li>
<li class="lvl-4">
<p>关注持续稳定不出现性能衰减场景</p>
<ul class="lvl-4">
<li class="lvl-6">
<p>如要求业务不中断情况下，持续从0~10亿不出现性能衰减，则使用较小的cosbench workers来压测<br>
Lab的这套6节点环境验证过如下workers值：</p>
<ul class="lvl-6">
<li class="lvl-9">
<p>workers=96，每个driver可以达到1500+ OPS</p>
</li>
<li class="lvl-9">
<p>workers=8，每个driver可以达到1000 OPS左右</p>
</li>
<li class="lvl-9">
<p>workers=2，每个driver可以达到200 OPS左右</p>
</li>
<li class="lvl-9">
<p>workers=3，每个driver可以达到400 OPS左右</p>
</li>
<li class="lvl-9">
<p>workers=4，每个driver可以达到500 OPS左右</p>
<p>所以Lab里测试0~12亿对象，持续写验证不出现性能瓶颈的场景，使用的是workers=4来验证，在cosbench写入速度与flush/evict object 到HDD之间寻找一个平衡点，避免因cosbench写的太快，flush/evict太慢造成Bigterastore Cache所在文件系统的inode过早被消耗殆尽而出现性能断崖式衰减</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="lvl-2">
<p>暂无法根据现有硬件来推算出集群单一bucket中最大能支持存放多少S3 objects</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
        <category>performance</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux 输出格式化成Json</title>
    <url>/2022/02/09/linux_json_format_output/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>工作中经常会将Linux输出进行格式化，方便阅读。本文罗列几个常用的将输出转换为Json格式的方法。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="fang-fa-1-code-python-mjson-tool-code">方法1 <code>python -mjson.tool</code></h2>
<p>此适用于多种OS</p>
<p><code>ceph config-key get gateway_groups | python -mjson.tool</code></p>
<h2 id="fang-fa-2-code-json-pp-code-or-code-jq-code">方法2 <code>json_pp</code> or <code>jq</code></h2>
<p>适用于Debin系OS</p>
<p><code>ceph config-key get gateway_groups | json_pp</code></p>
<p>适用于RedHat系OS，带颜色</p>
<p><code>ceph config-key get gateway_groups | jq</code></p>
<p>e.g:</p>
<pre><code class="language-shell">root@CVM01:~# ceph config-key get gateway_groups | json_pp
obtained 'gateway_groups'
{
   "groups" : {
      "Default" : {
         "member" : [
            "10.10.101.102",
            "10.10.101.103",
            "10.10.101.101",
            "10.10.101.104"
         ],
         "type" : "standard",
         "zerocopy" : false
      },
      "!!!not used!!!" : {
         "type" : "standard",
         "member" : []
      }
   },
   "virtual_gateways" : {},
   "_ver" : "5.2"
}
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>自动化交互式格式化文件系统</title>
    <url>/2022/02/10/auto_yes_to_mkfs/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>当格式化文件系统时，尤其是在脚本或代码中做这个操作，一旦出现需要输入’y’的时候，脚本或者代码就会卡住或者timeout，造成程序失败。</p>
<p>本文介绍几种方法，在format时自动填写yes or y，让format持续进行下去.</p>
<h1 id="shi-jian">实践</h1>
<h2 id="fang-fa-1">方法1</h2>
<p><code>yes | mkfs.ext4 /dev/sdb</code></p>
<h2 id="fang-fa-2">方法2</h2>
<p><code>echo -e "y\n" | mkfs.ext4 /dev/sdx</code></p>
<h2 id="fang-fa-3">方法3</h2>
<p><code>mkfs.ext4 -F /dev/sdb</code></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Get memchche socket connection numbers</title>
    <url>/2022/03/21/calc_memchche_socket_connection_numbers/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Recently, during the testing process, we encountered the memory leak issue, and RD located that the number of connections established by the memcache socket was too many and could not be released normally, which led to memory leak over time.</p>
<p>So wrote a test script to run continuously in the cluster environment to monitor the status of the memcache socket connections.</p>
<h1 id="script-of-check-con-socket-numbers-py">Script of check_con-socket_numbers.py</h1>
<pre><code class="language-python">#!/usr/bin/python3
# -*- coding: utf-8 -*-

import re
import subprocess
from collections import defaultdict
from operator import itemgetter

command = "ss -t4pH '( dport = :memcache )'"
output = subprocess.run(command, shell=True, stdout=subprocess.PIPE, encoding="utf-8")
stats = defaultdict(int)
sum = 0
for line in output.stdout.splitlines():
    process = line.split()[-1]
    if not process.startswith("users"):
        continue
    pname = process.split('"')[1]
    stats[pname] += 1
    sum += 1

print("Connections:")
for stat in sorted(stats.items(), key=itemgetter(1), reverse=True):
    print("{:&gt;15}: {}".format(stat[0], stat[1]))

print("{:&gt;15}: {}".format("summary", sum))
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>解决 Log output is incomplete or unavailable 问题</title>
    <url>/2022/04/08/log_output_is_incomplete_or_unavailable/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天碰到客户反馈通过systemctl status 查看某daemon状态时，显示如下图所示：</p>
<img class="shadow" src="/img/in-post/daemon_journal_log_warn.jpg" width="1200">
<p>客户询问，这个warn是否有影响？</p>
<h1 id="gen-yin">根因</h1>
<p>客户现场的这个daemon已经长久运行有些年头了，journal会统计log大小，到了某种程度就自动删掉。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>放大journal，比如：</p>
<p><code>journalctl --vacuum-size=1G</code></p>
<p>示例的意思是：最大可存放1GB journal。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>获取OSD与CPU绑定关系</title>
    <url>/2022/05/19/bind_relationship_between_osd_cpus/</url>
    <content><![CDATA[<h1 id="dai-ma">代码</h1>
<p>这里代码转自(<a href="https://blog.51cto.com/zphj1987/3212869">https://blog.51cto.com/zphj1987/3212869</a>)，在它基础上增加了+号的颜色显示(高亮)，表明当前ceph-osd运行在对应On-line CPU(s)上.</p>
<h2 id="cpu-xin-xi">CPU信息</h2>
<pre><code class="language-shell">[root@node163 ~]# lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                48
On-line CPU(s) list:   0-47
Thread(s) per core:    2
Core(s) per socket:    12
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 85
Model name:            Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz
Stepping:              4
CPU MHz:               2244.518
BogoMIPS:              4600.00
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              1024K
L3 cache:              16896K
NUMA node0 CPU(s):     0-11,24-35
NUMA node1 CPU(s):     12-23,36-47
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts pku ospke md_clear flush_l1d
</code></pre>
<p>代码块</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: UTF-8 -*-
import os
import sys
import json
import psutil
import commands
from prettytable import PrettyTable

def main():
    if len(sys.argv) == 1:
        printosdcputable("process")
    elif sys.argv[1] == 't':
        printosdcputable("thread")

def printosdcputable(choose):
    print choose
    row = PrettyTable()
    row.header = True
    cpulist = ["OSD\CPU"]
    corelist=["Core ID"]
    phylist = ["Physical ID"]
    emplist=["-----------"]
    for cpupro in range(psutil.cpu_count()):
        cpulist.append("%s" %cpupro )

        coreid=commands.getoutput('egrep \'processor|physical id|core id\' /proc/cpuinfo | cut -d : -f 2 | paste - - -  | awk  \'$1==%s {print $3 }\'' %cpupro)
        corelist.append("%s" %coreid)

        phyid = commands.getoutput('egrep \'processor|physical id|core id\' /proc/cpuinfo | cut -d : -f 2 | paste - - -  | awk  \'$1==%s {print $2 }\'' % cpupro)
        phylist.append("%s" %phyid)
        emplist.append("--")

    row.field_names = cpulist
    row.add_row(corelist)
    row.add_row(phylist)
    row.add_row(emplist)

    for root, dirs, files in os.walk('/var/run/ceph/'):
        for name in files:
            if "osd"  in name and "pid" in name :
                osdlist = []
                osdthlist=[]
                for osdcpu in range(psutil.cpu_count()):
                    osdlist.append(" ")
                    osdthlist.append("0")
                pidfile=root + name
                osdid=commands.getoutput('ls  %s|cut -d "." -f 2 2&gt;/dev/null'  %pidfile )
                osdpid = commands.getoutput('cat %s  2&gt;/dev/null' %pidfile)
                osd_runcpu = commands.getoutput('ps -o  psr -p %s |grep -v PSR 2&gt;/dev/null' %osdpid)
                th_list = commands.getoutput('ps -o  psr -L  -p %s |grep -v PSR|awk \'gsub(/^ *| *$/,"")\'  2&gt;/dev/null' % osdpid)

                osdname="osd."+osdid
                osdlist[int(osd_runcpu)]="\033[31m+\033[0m"
                for osdth in th_list.split('\n'):
                    osdthlist[int(osdth)] = int(osdthlist[int(osdth)])+1
                osdlist.insert(0,osdname)
                osdthlist.insert(0,osdname)
                if choose == "process":
                    row.add_row(osdlist)
                elif choose == "thread":
                    row.add_row(osdthlist)
    print row

if __name__ == '__main__':
    main()
</code></pre>
<h1 id="yun-xing-jie-guo">运行结果</h1>
<img class="shadow" src="/img/in-post/osd_cpu_bind_relationship.png" width="1200">
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>获取ceph PG 分布</title>
    <url>/2022/05/19/ceph_pg_allocate/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<h1 id="di-yi-ban">第一版</h1>
<pre><code class="language-shell">#!/bin/bash

ceph_version=`ceph -v | awk '\{\{print \$3\}\}'`

if [[ ${ceph_version} =~ '10.' ]]; then
    pg_stat="pg_stat"
    up="up"
elif [[ ${ceph_version} =~ '12.' ]]; then
    pg_stat="PG_STAT"
    up="UP"
fi

ceph pg dump | egrep -v "^[0-9]*  " | awk '
/^'$pg_stat'/ { col=1; while($col!="'"$up"'") {col++}; col++ }
/^[0-9a-f]+.[0-9a-f]+/ { match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;
up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) { osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) }
for(i in osds) {array[osds[i],pool]++; osdlist[osds[i]];}
}
END {
printf("\n");
printf("pool :\t"); for (i in poollist) printf("%s\t",i); printf("| SUM \n");
for (i in poollist) printf("--------"); printf("-------------\n");
for (i in osdlist) { printf("osd.%i\t", i); sum=0;
for (j in poollist) { printf("%i\t", array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] }; printf("| %i\n",sum) }
for (i in poollist) printf("--------"); printf("--------------\n");
printf("SUM :\t"); for (i in poollist) printf("%s\t",poollist[i]); printf("|\n");
}'
</code></pre>
<p>结果展示如下：</p>
<img class="shadow" src="/img/in-post/pg_allocate_v1.png" width="1200">
<h1 id="di-er-ban">第二版</h1>
<pre><code class="language-shell">#!/bin/bash

ceph_version=`ceph -v | awk '\{\{print \$3\}\}'`

if [[ ${ceph_version} =~ '10.' ]]; then
    pg_stat="pg_stat"
    up="up"
elif [[ ${ceph_version} =~ '12.' ]]; then
    pg_stat="PG_STAT"
    up="UP"
fi

ceph pg dump | awk '
 /^'$pg_stat'/ { col=1; while($col!="UP") {col++}; col++ }
 /^[0-9a-f]+\.[0-9a-f]+/ { match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;
 up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) { osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) }
 for(i in osds) {array[osds[i],pool]++; osdlist[osds[i]];}
}
END {
 printf("\n");
 slen=asorti(poollist,newpoollist);
 printf("pool :\t");for (i=1;i&lt;=slen;i++) {printf("%s\t", newpoollist[i])}; printf("| SUM \n");
 for (i in poollist) printf("--------"); printf("----------------\n");
 slen1=asorti(osdlist,newosdlist)
 delete poollist;
 for (j=1;j&lt;=slen;j++) {maxpoolosd[j]=0};
 for (j=1;j&lt;=slen;j++) {for (i=1;i&lt;=slen1;i++){if (array[newosdlist[i],newpoollist[j]] &gt;0  ){minpoolosd[j]=array[newosdlist[i],newpoollist[j]] ;break } }}; 
 for (i=1;i&lt;=slen1;i++) { printf("osd.%i\t", newosdlist[i]); sum=0; 
 for (j=1;j&lt;=slen;j++)  { printf("%i\t", array[newosdlist[i],newpoollist[j]]); sum+=array[newosdlist[i],newpoollist[j]]; poollist[j]+=array[newosdlist[i],newpoollist[j]];if(array[newosdlist[i],newpoollist[j]] != 0){poolhasid[j]+=1 };if(array[newosdlist[i],newpoollist[j]]&gt;maxpoolosd[j]){maxpoolosd[j]=array[newosdlist[i],newpoollist[j]];maxosdid[j]=newosdlist[i]};if(array[newosdlist[i],newpoollist[j]] != 0){if(array[newosdlist[i],newpoollist[j]]&lt;=minpoolosd[j]){minpoolosd[j]=array[newosdlist[i],newpoollist[j]];minosdid[j]=newosdlist[i]}}}; printf("| %i\n",sum)} for (i in poollist) printf("--------"); printf("----------------\n");
 slen2=asorti(poollist,newpoollist);
 printf("SUM :\t"); for (i=1;i&lt;=slen;i++) printf("%s\t",poollist[i]); printf("|\n");
 printf("Osd :\t"); for (i=1;i&lt;=slen;i++) printf("%s\t",poolhasid[i]); printf("|\n");
 printf("AVE :\t"); for (i=1;i&lt;=slen;i++) printf("%.2f\t",poollist[i]/poolhasid[i]); printf("|\n");
 printf("Max :\t"); for (i=1;i&lt;=slen;i++) printf("%s\t",maxpoolosd[i]); printf("|\n");
 printf("Osdid :\t"); for (i=1;i&lt;=slen;i++) printf("osd.%s\t",maxosdid[i]); printf("|\n");
 printf("per:\t"); for (i=1;i&lt;=slen;i++) printf("%.1f%\t",100*(maxpoolosd[i]-poollist[i]/poolhasid[i])/(poollist[i]/poolhasid[i])); printf("|\n");
 for (i=1;i&lt;=slen2;i++) printf("--------");printf("----------------\n");
 printf("min :\t"); for (i=1;i&lt;=slen;i++) printf("%s\t",minpoolosd[i]); printf("|\n");
 printf("osdid :\t"); for (i=1;i&lt;=slen;i++) printf("osd.%s\t",minosdid[i]); printf("|\n");
 printf("per:\t"); for (i=1;i&lt;=slen;i++) printf("%.1f%\t",100*(minpoolosd[i]-poollist[i]/poolhasid[i])/(poollist[i]/poolhasid[i])); printf("|\n");
}'
</code></pre>
<p>结果显示如下图：</p>
<img class="shadow" src="/img/in-post/PG_ALLOCATE_V2.png" width="1200">
<h1 id="yu-fa-de-jie-shi">语法的解释</h1>
<p><code>/^pg_stat/ { col=1; while($col!="up") {col++}; col++ } </code></p>
<p>这个是匹配pg dump 的输出结果里面pg_stat那个字段，开始计数为1，不是up值就将col的值加1，这个匹配到的就是我们经常看到的[1,10]这个值最后的col++是将col值+1,因为字段里面有up,up_primary,我们需要的是up_primary</p>
<p><code>/?[1]+.[0-9a-f]+/ { match($0,/?[2]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;</code></p>
<p>这个是匹配前面的 1.17a pg号 ，使用自带的match函数 做字符串的过滤统计匹配.号前面的存储池ID， 并得到 RSTART, RLENGTH 值，这个是取到前面的存储池ID，使用substr 函数，就可以得到pool的值了，poollist[pool]=0，是将数组的值置为0</p>
<p><code>up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) { osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) }</code></p>
<p>先将变量置0，然后将osd编号一个个输入到osds[i]的数组当中去</p>
<p><code>for(i in osds) {array[osds[i],pool]++; osdlist[osds[i]];}</code></p>
<p>将osds数组中的值输入到数组当中去，并且记录成osdlist，和数组array[osd[i],pool]</p>
<pre><code class="language-shell">printf("\n");
printf("pool :\t"); for (i in poollist) printf("%s\t",i); printf("| SUM \n");
</code></pre>
<p>打印osd pool的编号</p>
<p><code>for (i in poollist) printf("--------"); printf("----------------\n");</code></p>
<p>根据osd pool的长度打印----</p>
<p><code>for (i in osdlist) { printf("osd.%i\t", i); sum=0;</code></p>
<p>打印osd的编号</p>
<p><code>for (j in poollist) { printf("%i\t", array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] }; printf("| %i\n",sum) }</code><br>
打印对应的osd的pg数目，并做求和的统计</p>
<pre><code class="language-shell">for (i in poollist) printf("--------"); printf("----------------\n");
printf("SUM :\t"); for (i in poollist) printf("%s\t",poollist[i]); printf("|\n");
</code></pre>
<p>打印新的poollist里面的求和的值,修改版本里面用到的函数</p>
<p><code>slen1=asorti(osdlist,newosdlist)</code></p>
<p>这个是将数组里面的下标进行排序，这里是对osd和poollist的编号进行排序 slen1是拿到数组的长度，使用for进行遍历输出</p>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>在linux中查看端口号是哪个进程在占用</title>
    <url>/2022/06/02/get_port_used_by_which_process/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天升级一套存储，碰到了80端口被占用，导致RGW bind 80 port时bind失败，最终导致RGW服务启用失败，造成S3 业务不可用问题。</p>
<h1 id="cha-kan-duan-kou-xin-xi">查看端口信息</h1>
<p>Linux 上的 /etc/services 文件可以查看到更多关于保留端口的信息。</p>
<p>可以使用以下三种方法查看端口信息。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>ss：可以用于转储套接字统计信息</p>
</li>
<li class="lvl-2">
<p>netstat：可以显示打开的套接字列表</p>
</li>
<li class="lvl-2">
<p>lsof：可以列出打开的文件。</p>
</li>
</ul>
<p>以下我们将找出端口号为80,被哪个守护进程所使用。</p>
<h2 id="fang-fa-1-shi-yong-ss-ming-ling">方法1：使用 ss 命令</h2>
<pre><code class="language-shell">root@node167:/var/log/ceph# ss -tlnp | grep ':80'
LISTEN     0      128          *:8080                     *:*                   users:(("apache2",pid=2771,fd=3),("apache2",pid=2770,fd=3),("apache2",pid=2769,fd=3),("apache2",pid=2768,fd=3),("apache2",pid=2767,fd=3),("apache2",pid=2760,fd=3))
LISTEN     0      128          *:80                       *:*                   users:(("haproxy",pid=2473,fd=4))
</code></pre>
<h2 id="fang-fa-2-shi-yong-netstat-ming-ling">方法2：使用 netstat 命令</h2>
<pre><code class="language-shell">root@node167:/var/log/ceph# netstat -lntp | grep ':80'
tcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN      2760/apache2    
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      2473/haproxy    
root@node167:/var/log/ceph# 
</code></pre>
<h2 id="fang-fa-3-shi-yong-lsof-ming-ling">方法3：使用 lsof 命令</h2>
<pre><code class="language-shell">root@node167:/var/log/ceph# lsof -i:80
COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
haproxy 2473 root    4u  IPv4   1766      0t0  TCP *:http (LISTEN)
root@node167:/var/log/ceph# 
</code></pre>
<h1 id="ci-ci-shi-gu-gai-shu">此次事故概述</h1>
<p>此次碰到的问题，是升级过程中未对新增功能相关port bind做处理，详情如下：</p>
<p>Parts of ceph-client.radosgw.0.log:</p>
<pre><code class="language-shell">2022-06-02 17:05:38.709761 7fec78874040  0 deferred set uid:gid to 0:0 (root:root)
2022-06-02 17:05:38.709778 7fec78874040  0 ceph version 12.2.10-903-g0149c5ceafe (0149c5ceafe1c541f0a5044e1c5c9e4fbc71c64e) luminous (stable), process radosgw, pid 104451
2022-06-02 17:05:38.713450 7fec78874040  0 stack NetworkStack max thread limit is 24, switching to this now. Higher thread values are unnecessary and currently unsupported.
2022-06-02 17:05:38.807429 7fec78874040  0 starting handler: civetweb
2022-06-02 17:05:38.808117 7fec78874040  0 civetweb: 0x55d2cd1be0c0: cannot bind to 80: 98 (Address already in use)
2022-06-02 17:05:38.808143 7fec78874040  0 civetweb: 0x55d2cd1be0c0: cannot bind to 443s: 98 (Address already in use)
2022-06-02 17:05:38.808175 7fec78874040 -1 ERROR: failed run
</code></pre>
<p>Other log:</p>
<pre><code class="language-shell">root@node167:/var/log/ceph# netstat -tnlp | grep ':80'
tcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN      2760/apache2    
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      2473/haproxy    
root@node167:/var/log/ceph# cat /etc/ceph/ceph.conf | grep -i 'rgw frontends'
rgw frontends = civetweb port=80+443s ssl_certificate=/etc/ezs3/ssl/ezs3_server.pem num_threads=1024 ssl_cipher_list=HIGH:!aNULL:!MD5:!3DES ssl_protocol_version=4
rgw frontends = civetweb port=80+443s ssl_certificate=/etc/ezs3/ssl/ezs3_server.pem num_threads=1024 ssl_cipher_list=HIGH:!aNULL:!MD5:!3DES ssl_protocol_version=4
root@node167:/var/log/ceph# cat /etc/haproxy/haproxy.cfg
frontend https
        bind *:80
        bind *:443 ssl crt /etc/ezs3/ssl/ezs3_server.pem
        mode http
        option http-keep-alive
        option http-server-close
        timeout http-keep-alive 10s
        option forwardfor
        reqadd X-Forwarded-Proto:\ https
        default_backend rgw_cluster

backend rgw_cluster
        mode http
        balance roundrobin
       server localhost 127.0.0.1:7480 check
root@node167:/var/log/ceph# 
</code></pre>
<p>这里可以清晰看到，haproxy占用了RGW的80端口， /etc/haproxy/haproxy.cfg中</p>
<pre><code class="language-shell">server localhost 127.0.0.1:7480 check
</code></pre>
<p>是告知ceph.conf中的rgw，你要使用的是7480这个port，而不是/etc/ceph/ceph.conf使用的却是80 port</p>
<pre><code class="language-shell">rgw frontends = civetweb port=80+443s ssl_certificate=/etc/ezs3/ssl/ezs3_server.pem num_threads=1024 ssl_cipher_list=HIGH:!aNULL:!MD5:!3DES ssl_protocol_version=4
</code></pre>
<p>问题的解决方法是修改/etc/ceph/ceph.conf中的80 port为 7480。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7设置netconsole</title>
    <url>/2022/06/08/centos7_config_netconsole/</url>
    <content><![CDATA[<h1 id="netconsole-jian-shu">Netconsole简述</h1>
<p>将内核打印的日志信息通过UDP方式发送至另一台服务器。</p>
<p>本文概述的是基于CentOS7的配置设定，Ubuntu的设定会右差别，请参考之前的另外一篇博文。</p>
<h1 id="pei-zhi-nei-he-ri-zhi-fa-song-duan-client-duan">配置内核日志发送端（Client端）</h1>
<p>说明：</p>
<p>这里的client端，表明的是当前哪台机器要将kernel log上报到rsyslog server去。</p>
<h2 id="xie-ru-etc-rc-local-zhong-kai-ji-zi-dong-she-zhi">写入/etc/rc.local中，开机自动设置</h2>
<pre><code class="language-shell">dmesg -n 7
modprobe configfs
modprobe netconsole
</code></pre>
<h2 id="pei-zhi-netconsole">配置netconsole</h2>
<p>Server端，配置远程接收ip地址、远程接收端口（默认514）、远程接收MAC（可选）、本地发送设备名、本地发送端口</p>
<p><code>vi /etc/sysconfig/netconsole</code></p>
<pre><code class="language-shell"># 取消SYSLOGPORT、SYSLOGPORT、SYSLOGMACADDR注释并添加相关参数
#--------------------------------------------------------
#也可执行如下命令插入所需的ip、port、mac
#端口为接收端服务器rsyslog服务的接收端口
ip="192.168.1.161"
echo -e "SYSLOGADDR=$ip\nSYSLOGPORT=514\nSYSLOGMACADDR=$(ping -c 1 $ip&gt;/dev/null&amp;&amp;arp|grep $ip|tr -s ' '|cut -f3 -d ' ')"&gt;&gt;/etc/sysconfig/netconsole
</code></pre>
<h2 id="pei-zhi-etc-sysconfig-netconsole-zhong-dev-she-bei">配置/etc/sysconfig/netconsole 中DEV设备</h2>
<p><code>vi /etc/sysconfig/netconsole</code></p>
<p>修改上述配置文件中的 DEV的值，如果配置了bond，需设置为bondX;否则设置为具体网口名称。</p>
<h2 id="zhong-qi-netconsole-fu-wu">重启netconsole服务</h2>
<pre><code class="language-shell">systemctl restart netconsole
</code></pre>
<h2 id="qi-yong-netconsole-zi-qi-dong">启用netconsole自启动</h2>
<pre><code class="language-shell">systemctl enable netconsole
</code></pre>
<h1 id="pei-zhi-nei-he-ri-zhi-jie-shou-duan-server-duan">配置内核日志接收端（Server端）</h1>
<h2 id="xiu-gai-rsyslog-pei-zhi-wen-jian-jie-shou-lai-zi-udp-de-ri-zhi">修改rsyslog配置文件接收来自UDP的日志</h2>
<p><code>vi /etc/rsyslog.conf</code></p>
<pre><code class="language-shell">#取消$ModLoad imudp和$UDPServerRun 514注释并修改514为需要监听接收udp的端口
#或者执行如下命令
sed -i 's/^#$Mod.*udp$/$ModLoad imudp/g;s/^#$UDP.*/$UDPServerRun 514/g' /etc/rsyslog.conf	#端口替换为自己所需要的
</code></pre>
<h2 id="zhong-qi-rsyslog-fu-wu">重启rsyslog服务</h2>
<pre><code class="language-shell">systemctl restart rsyslog

</code></pre>
<h2 id="jian-cha-shi-fou-zheng-chang-jian-ting-zhi-ding-duan-kou">检查是否正常监听指定端口</h2>
<pre><code class="language-shell">lsof -i:514
</code></pre>
<p>如下所示即为正常监听中:</p>
<pre><code class="language-shell">[root@centos-7 ~]# lsof -i:514
COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
rsyslogd 1735 root    3u  IPv4  43816      0t0  UDP *:syslog 
rsyslogd 1735 root    4u  IPv6  43817      0t0  UDP *:syslog 
[root@centos-7 ~]# 
</code></pre>
<h1 id="cha-kan-lai-zi-yuan-cheng-fu-wu-qi-fa-song-de-nei-he-ri-zhi">查看来自远程服务器发送的内核日志</h1>
<p>在Client端，尝试down与up某个网口，然后在Server端，执行</p>
<pre><code class="language-shell">tail -f /var/log/messages
</code></pre>
<p>来跟踪日志，检查Client端的kernel log是否将kernel log 上报到当然rsyslog server的messages 文件中</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>netconsole</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>netconsole</tag>
      </tags>
  </entry>
  <entry>
    <title>使用edac工具来检测服务器内存故障</title>
    <url>/2022/06/08/edac_to_check_memory/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>随着虚拟化，Redis,BDB内存数据库等应用的普及，现在越来越多的服务器配置了大容量内存，拿DELL的R620来说在配置双路CPU下，其24个内存插槽，支持的内存高达960GB。对于ECC,REG这些带有纠错功能的内存故障检测是一件很头疼的事情，出现故障，还是可以连续运行几个月甚至几年，但如果运气不好，随时都会挂掉，好在linux中提供了一个edac-utils 内存纠错诊断工具，可以用来检查服务器内存潜在的故障。</p>
<h1 id="shi-zhan">实战</h1>
<p>下面以CentOS为例，介绍下edac-utils 工具的使用。</p>
<p>在使用edac-utils 工具之前，需要先了解服务器的硬件架构，以DELL R620为例，(其它如HP DL360P G8，IBM X3650 M4 机型都使用了 E5-2600 系列CPU，C600 系列芯片组.大致相同)  其CPU内存控制器对应通道，内存槽关系，如下所示。</p>
<pre><code class="language-shell">处理器0 (对应一个内存控制器)
通道0：内存插槽A1、A5 和A9
通道1：内存插槽A2、A6 和A10
通道2：内存插槽A3、A7 和A11
通道3：内存插槽A4、A8 和A12

处理器1 (对应一个内存控制器)
通道0：内存插槽B1、B5 和B9
通道1：内存插槽B2、B6 和B10
通道2：内存插槽B3、B7 和B11
通道3：内存插槽B4、B8 和B12
</code></pre>
<h2 id="an-zhuang-edac-utils-gong-ju">安装 edac-utils 工具</h2>
<pre><code class="language-shell">yum install -y libsysfs edac-utils
</code></pre>
<h2 id="xing-jian-ce-ming-ling-ke-cha-kan-jiu-cuo-ti-shi-ru-xia">行检测命令，可查看纠错提示如下</h2>
<pre><code class="language-shell">[root@dbhost ~]# edac-util -v
mc0: 0 Uncorrected Errors with no DIMM info
mc0: 0 Corrected Errors with no DIMM info
mc0: csrow0: 0 Uncorrected Errors
mc0: csrow0: CPU_SrcID#0_Channel#0_DIMM#0: 6312 Corrected Errors    A1槽
mc0: csrow1: 0 Uncorrected Errors
mc0: csrow1: CPU_SrcID#0_Channel#0_DIMM#1: 0 Corrected Errors         A5槽
mc0: csrow2: 0 Uncorrected Errors
mc0: csrow2: CPU_SrcID#0_Channel#1_DIMM#0: 0 Corrected Errors         A2槽
mc0: csrow3: 0 Uncorrected Errors
mc0: csrow3: CPU_SrcID#0_Channel#1_DIMM#1: 0 Corrected Errors         A6槽
mc0: csrow4: 0 Uncorrected Errors
mc0: csrow4: CPU_SrcID#0_Channel#2_DIMM#0: 0 Corrected Errors         A3槽
mc0: csrow5: 0 Uncorrected Errors
mc0: csrow5: CPU_SrcID#0_Channel#2_DIMM#1: 0 Corrected Errors         A7槽
mc0: csrow6: 0 Uncorrected Errors
mc0: csrow6: CPU_SrcID#0_Channel#3_DIMM#0: 0 Corrected Errors         A4槽
mc1: 0 Uncorrected Errors with no DIMM info
mc1: 0 Corrected Errors with no DIMM info
mc1: csrow0: 0 Uncorrected Errors
mc1: csrow0: CPU_SrcID#1_Channel#0_DIMM#0: 6459 Corrected Errors     B1槽
mc1: csrow1: 0 Uncorrected Errors
mc1: csrow1: CPU_SrcID#1_Channel#0_DIMM#1: 0 Corrected Errors          B5槽
mc1: csrow2: 0 Uncorrected Errors
mc1: csrow2: CPU_SrcID#1_Channel#1_DIMM#0: 0 Corrected Errors          B2槽
mc1: csrow3: 0 Uncorrected Errors
mc1: csrow3: CPU_SrcID#1_Channel#1_DIMM#1: 0 Corrected Errors          B6槽
mc1: csrow4: 0 Uncorrected Errors
mc1: csrow4: CPU_SrcID#1_Channel#2_DIMM#0: 535 Corrected Errors       B3槽
mc1: csrow5: 0 Uncorrected Errors
mc1: csrow5: CPU_SrcID#1_Channel#2_DIMM#1: 0 Corrected Errors          B7槽
mc1: csrow6: 0 Uncorrected Errors
mc1: csrow6: CPU_SrcID#1_Channel#3_DIMM#0: 0 Corrected Errors          B4槽
[root@dbhost ~]#
</code></pre>
<p>其中 mc0 表示 表示内存控制器0,  CPU_Src_ID#0表示源CPU0 , Channel#0 表示通道0<br>
DIMM#0 标示内存槽0，Corrected Errors 代表已经纠错的次数，根据前面列出的CPU通道和内存槽对应关系即可给edac-utils 返回的信息进行编号。即可得出 A1槽 6312 次纠错，B1槽 6459次纠错，B3槽 535次纠错. 3条内存出现潜在故障，接下来联系供应商进行更换即可。</p>
<p>如果没有侦测到错误，显示信息如下：</p>
<pre><code class="language-shell">[root@node163 ~]# edac-util -v
mc0: 0 Uncorrected Errors with no DIMM info
mc0: 0 Corrected Errors with no DIMM info
mc0: csrow0: 0 Uncorrected Errors
mc0: csrow0: mc#0memory#0: 0 Corrected Errors
mc0: csrow10: 0 Uncorrected Errors
mc0: csrow10: mc#0memory#10: 0 Corrected Errors
mc0: csrow12: 0 Uncorrected Errors
mc0: csrow12: mc#0memory#12: 0 Corrected Errors
mc0: csrow14: 0 Uncorrected Errors
mc0: csrow14: mc#0memory#14: 0 Corrected Errors
mc0: csrow2: 0 Uncorrected Errors
mc0: csrow2: mc#0memory#2: 0 Corrected Errors
mc0: csrow4: 0 Uncorrected Errors
mc0: csrow4: mc#0memory#4: 0 Corrected Errors
mc0: csrow6: 0 Uncorrected Errors
mc0: csrow6: mc#0memory#6: 0 Corrected Errors
mc0: csrow8: 0 Uncorrected Errors
mc0: csrow8: mc#0memory#8: 0 Corrected Errors
mc1: 0 Uncorrected Errors with no DIMM info
mc1: 0 Corrected Errors with no DIMM info
edac-util: No errors to report.
[root@node163 ~]# 
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>edac</tag>
      </tags>
  </entry>
  <entry>
    <title>分片上传2T大小的一个S3对象</title>
    <url>/2022/06/27/multipart_upload_2t_s3_object/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>客户询问，对于2T大小的一个S3对象，我司产品是否支持。</p>
<p>原本计划使用GUI工具，诸如S3Browser，CloudBerry这样的可视化工具上传一下验证看看，考虑到本地磁盘大小无法容纳2T大小的文件，只能放弃，改成使用python code来上传看看。</p>
<h1 id="cao-zuo-bu-zou">操作步骤</h1>
<h2 id="zhun-bei-yi-ge-2-t-da-xiao-de-dui-xiang-wen-jian">准备一个2T大小的对象文件</h2>
<p><code>fallocate -l 2T 2T.file</code></p>
<p>快速生成一个含有大量hole的文件，存放在某个osd的挂载点（物理磁盘，RAID组，空间比较大，放的下这么大的文件了）</p>
<h2 id="zhun-bei-ce-shi-jiao-ben">准备测试脚本</h2>
<pre><code class="language-python">#!/usr/bin/env python

import shutil
import math
import string
import io
from io import BytesIO
import os
from os import path
import sys
import traceback
import boto
import boto.s3.connection
from filechunkio import FileChunkIO
import threading
import Queue
import time

class Chunk:
    num = 0
    offset = 0
    len = 0
    def __init__(self, n, o, l):  
        self.num = n
        self.offset = o
        self.len = l

chunksize = 8 &lt;&lt; 20

def init_queue(filesize):
    chunkcnt = int(math.ceil(filesize*1.0/chunksize))
    q = Queue.Queue(maxsize = chunkcnt)
    for i in range(0,chunkcnt):
        offset = chunksize*i
        len = min(chunksize, filesize-offset)
        c = Chunk(i+1, offset, len)
        q.put(c)
    return q

def upload_chunk(filepath, mp, q, id):
    while (not q.empty()):
        chunk = q.get()
        fp = FileChunkIO(filepath, 'r', offset=chunk.offset, bytes=chunk.len)
        mp.upload_part_from_file(fp, part_num=chunk.num)
        fp.close()
        q.task_done()

def upload_file_multipart(filepath, keyname, bucket, threadcnt=8):
    enable_debug_log_cmd = "ceph daemon client.radosgw.0 config set debug_rgw 20/20"
    disable_debug_log_cmd = "ceph daemon client.radosgw.0 config set debug_rgw 0/0"
    get_debug_log_cmd = "ceph daemon client.radosgw.0 config get debug_rgw"

    filesize = os.stat(filepath).st_size
    mp = bucket.initiate_multipart_upload(keyname)
    q = init_queue(filesize)
    for i in range(0, threadcnt):
        t = threading.Thread(target=upload_chunk, args=(filepath, mp, q, i))
        t.setDaemon(True)
        t.start()
    q.join()
    print("--  enable rgw debug log")
    res1 = commands.getoutput(enable_debug_log_cmd)
    res2 = commands.getoutput(get_debug_log_cmd)
    print res1, res2
    mp.complete_upload()
    print("--  disable rgw debug log")
    res3 = commands.getoutput(disable_debug_log_cmd)
    res4 = commands.getoutput(get_debug_log_cmd)
    print res3, res4

def download_chunk(filepath, bucket, key, q, id):
    while (not q.empty()):
        chunk = q.get()
        offset = chunk.offset
        len = chunk.len
        resp = bucket.connection.make_request("GET", bucket.name, key.name, headers={"Range":"bytes=%d-%d" % (offset, offset+len)})
        data = resp.read(len)
        fp = FileChunkIO(filepath, 'r+', offset=offset, bytes=len)
        fp.write(data)
        fp.close()
        q.task_done()

def download_file_multipart(key, bucket, filepath, threadcnt=8):
    if type(key) == str:
        key=bucket.get_key(key)
    filesize=key.size
    if os.path.exists(filepath):
        os.remove(filepath)
    os.mknod(filepath)
    q = init_queue(filesize)
    for i in range(0, threadcnt):
        t = threading.Thread(target=download_chunk, args=(filepath, bucket, key, q, i))
        t.setDaemon(True)
        t.start()
    q.join()

access_key = "YGZTOFN14AEVFGFCX5VA"
secret_key = "Dyt9GlnQ8XPexUzd9iEnFNdUuDpY8vuHvde5DVxl"
host = "10.16.72.161"

filepath = "/data/osd.2/2T.file"
keyname = "2T.file"

threadcnt = 8

conn = boto.connect_s3(
    aws_access_key_id = access_key,
    aws_secret_access_key = secret_key,
    host = host,
    is_secure=False,
    calling_format = boto.s3.connection.OrdinaryCallingFormat(),
    )

bucket = conn.get_bucket("test")

time1= time.time()
upload_file_multipart(filepath, keyname, bucket, threadcnt)
time2= time.time()
print "upload %s with %d threads use %d seconds" % (keyname, threadcnt, time2-time1)

key = bucket.get_key(keyname)

download_filepath = path.join(".", keyname)
time1= time.time()
download_file_multipart(key, bucket, download_filepath, threadcnt)
time2= time.time()
print "download %s with %d threads use %d seconds" % (keyname, threadcnt, time2-time1)

</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>说明：这里将2T对象，8个thread并发上传, 每个分片大小是8MiB</p>
</li>
</ul>
<h2 id="ce-shi-jie-guo">测试结果</h2>
<p>脚本output:</p>
<pre><code class="language-shell">root@node224:~# python s3_upload.py            
--  enable rgw debug log                       
{                                              
    "success": ""                              
} {                                            
    "debug_rgw": "20/20"                       
}                                              
--  disable rgw debug log                      
{                                              
    "success": ""                              
} {                                            
    "debug_rgw": "0/0"                         
}                                              
upload 1T.file with 32 threads use 8907 seconds
</code></pre>
]]></content>
      <categories>
        <category>ceph</category>
        <category>S3</category>
      </categories>
      <tags>
        <tag>S3</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>S3 分片上传对象报416错误码</title>
    <url>/2022/06/30/multipart_upload_return_416/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>python boto上传一个2T大小的对象，产品报HTTP 416 错误码, Requested Range Not Satisfiable， 如下所示：</p>
<pre><code class="language-shell">root@node224:~# time python s3_upload.py                                                                                         
[DEBUG]  Enable rgw debug log
{
    "success": ""
} {
    "debug_rgw": "20/20"
}
Traceback (most recent call last):
  File "s3_upload.py", line 118, in &lt;module&gt;
    upload_file_multipart(filepath, keyname, bucket, threadcnt)
  File "s3_upload.py", line 66, in upload_file_multipart
    mp.complete_upload()
  File "/usr/local/lib/python2.7/dist-packages/boto/s3/multipart.py", line 319, in complete_upload
    self.id, xml)
  File "/usr/local/lib/python2.7/dist-packages/boto/s3/bucket.py", line 1807, in complete_multipart_upload
    response.status, response.reason, body)
boto.exception.S3ResponseError: S3ResponseError: 416 Requested Range Not Satisfiable
&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Error&gt;&lt;Code&gt;InvalidRange&lt;/Code&gt;&lt;BucketName&gt;test&lt;/BucketName&gt;&lt;RequestId&gt;tx000000000000000003210-0062bd5539-102b2-default&lt;/RequestId&gt;&lt;HostId&gt;102b2-default-default&lt;/HostId&gt;&lt;/Error&gt;
real    12m45.518s
user    15m8.592s
sys     11m23.152s
root@node224:~#
</code></pre>
<h1 id="wen-ti-guo-cheng-ji-lu">问题过程记录</h1>
<h2 id="xiu-gai-can-shu">修改参数</h2>
<pre><code class="language-shell">root@node224:/var/log/ceph# ceph daemon client.radosgw.0 config show | grep multipart
    "rgw_multipart_min_part_size": "5242880",
    "rgw_multipart_part_upload_limit": "600000",
</code></pre>
<p>这里调整了产品的两个参数，一个是最小分片大小(5MiB)，另外一个是允许的分片数上限(默认10000)</p>
<h2 id="ce-shi-guo-cheng">测试过程</h2>
<p>经过测试，分片上传2T， 50G 和 100G, 50G的成功，100G的就失败了，由此推算出 按8M一个分片上传，单个文件大小介于50G到100G之间，会出现失败，至于文件大小临界点，下文介绍到。</p>
<h2 id="wen-ti-mo-suo">问题摸索</h2>
<p>按8M一个分片上传，通过上传 50G 、 100G 和 2T文件，开启RGW debug情况下，看到如下信息：</p>
<p>50G：</p>
<pre><code class="language-shell">2022-06-30 16:58:45.321050 7f3da254a700 20  bucket index object: .dir.1ed581f4-fc6f-4b86-88e4-b6895841272b.4373.1.54
2022-06-30 16:58:45.323798 7f3da254a700  2 req 23325:0.004960:s3:POST /test/50G.file:init_multipart:completing
2022-06-30 16:58:45.324043 7f3da254a700  2 req 23325:0.005205:s3:POST /test/50G.file:init_multipart:op status=0
2022-06-30 16:58:45.324081 7f3da254a700  2 req 23325:0.005243:s3:POST /test/50G.file:init_multipart:http status=200
2022-06-30 16:58:45.324091 7f3da254a700  1 ====== req done req=0x7f3da25437d0 op status=0 http_status=200 ======
2022-06-30 16:58:47.857037 7f3da254a700 20 CONTENT_LENGTH=8388608
2022-06-30 16:58:47.857060 7f3da254a700 20 CONTENT_TYPE=application/octet-stream
2022-06-30 16:58:47.857063 7f3da254a700 20 HTTP_ACCEPT_ENCODING=identity
2022-06-30 16:58:47.857067 7f3da254a700 20 HTTP_AUTHORIZATION=AWS N2Z4LERBO87Y8G743FZ2:X4b9snKTcsc1uJs5z+N0w/OActc=
2022-06-30 16:58:47.857070 7f3da254a700 20 HTTP_CONTENT_MD5=lplbWNTL9qqpBBtPAMf2rg==
2022-06-30 16:58:47.857077 7f3da254a700 20 HTTP_DATE=Thu, 30 Jun 2022 08:58:47 GMT
2022-06-30 16:58:47.857080 7f3da254a700 20 HTTP_EXPECT=100-Continue
2022-06-30 16:58:47.857082 7f3da254a700 20 HTTP_HOST=172.17.73.178
2022-06-30 16:58:47.857085 7f3da254a700 20 HTTP_USER_AGENT=Boto/2.49.0 Python/2.7.5 Linux/4.14.148-202204291725.git90deb91
2022-06-30 16:58:47.857090 7f3da254a700 20 HTTP_VERSION=1.1
2022-06-30 16:58:47.857093 7f3da254a700 20 QUERY_STRING=uploadId=2~yqR7SqXx1aeg1QMqrrjJMdfNWqqw-cE&amp;partNumber=15
2022-06-30 16:58:47.857108 7f3da254a700 20 REMOTE_ADDR=172.17.73.178
2022-06-30 16:58:47.857110 7f3da254a700 20 REQUEST_METHOD=PUT
2022-06-30 16:58:47.857112 7f3da254a700 20 REQUEST_URI=/test/50G.file
2022-06-30 16:58:47.857116 7f3da254a700 20 SCRIPT_URI=/test/50G.file
2022-06-30 16:58:47.857118 7f3da254a700 20 SERVER_PORT=80
2022-06-30 16:58:47.857122 7f3da254a700  1 ====== starting new request req=0x7f3da25437d0 =====
</code></pre>
<p>100G:</p>
<pre><code class="language-shell">2022-06-30 15:48:03.980991 7f54d680a700  2 RGWDataChangesLog::ChangesRenewThread: start
2022-06-30 15:48:09.436299 7f54bd7d8700 20 CONTENT_LENGTH=1345746
2022-06-30 15:48:09.436313 7f54bd7d8700 20 CONTENT_TYPE=text/xml
2022-06-30 15:48:09.436314 7f54bd7d8700 20 HTTP_ACCEPT_ENCODING=identity
2022-06-30 15:48:09.436315 7f54bd7d8700 20 HTTP_AUTHORIZATION=AWS KAGC5XL83YICQXP0THTQ:tRoonm2iXmUKxPQPVbGzeQRG9g0=
2022-06-30 15:48:09.436317 7f54bd7d8700 20 HTTP_DATE=Thu, 30 Jun 2022 07:48:08 GMT
2022-06-30 15:48:09.436318 7f54bd7d8700 20 HTTP_HOST=10.16.172.224
2022-06-30 15:48:09.436319 7f54bd7d8700 20 HTTP_USER_AGENT=Boto/2.49.0 Python/2.7.12 Linux/4.14.148-202204291725.git90deb91
2022-06-30 15:48:09.436320 7f54bd7d8700 20 HTTP_VERSION=1.1
2022-06-30 15:48:09.436321 7f54bd7d8700 20 QUERY_STRING=uploadId=2~J7YByyru1yeZVWpAHEc4mqbC-tsTkhT
2022-06-30 15:48:09.436325 7f54bd7d8700 20 REMOTE_ADDR=10.16.172.224
2022-06-30 15:48:09.436325 7f54bd7d8700 20 REQUEST_METHOD=POST
2022-06-30 15:48:09.436326 7f54bd7d8700 20 REQUEST_URI=/test/100G.file
2022-06-30 15:48:09.436328 7f54bd7d8700 20 SCRIPT_URI=/test/100G.file
2022-06-30 15:48:09.436328 7f54bd7d8700 20 SERVER_PORT=80
2022-06-30 15:48:09.436329 7f54bd7d8700  1 ====== starting new request req=0x7f54bd7d1860 =====
</code></pre>
<p>1T</p>
<pre><code class="language-shell">2022-06-30 17:29:15.016098 7f0ef6d31700 20 Read xattr: user.rgw.source_zone
2022-06-30 17:29:15.016102 7f0ef6d31700 15 Encryption mode:
2022-06-30 17:29:15.049927 7f0ef6530700 20 CONTENT_LENGTH=15728640
2022-06-30 17:29:15.049948 7f0ef6530700 20 CONTENT_TYPE=application/octet-stream
2022-06-30 17:29:15.049949 7f0ef6530700 20 HTTP_ACCEPT_ENCODING=identity
2022-06-30 17:29:15.049951 7f0ef6530700 20 HTTP_AUTHORIZATION=AWS KAGC5XL83YICQXP0THTQ:JIsSkMsbsOSEQCouHX9ZuRFCIWc=
2022-06-30 17:29:15.049954 7f0ef6530700 20 HTTP_CONTENT_MD5=FLFyNOI3UFQhtkkrjXV1Bw==
2022-06-30 17:29:15.049955 7f0ef6530700 20 HTTP_DATE=Thu, 30 Jun 2022 09:29:14 GMT
2022-06-30 17:29:15.049956 7f0ef6530700 20 HTTP_EXPECT=100-Continue
2022-06-30 17:29:15.049957 7f0ef6530700 20 HTTP_HOST=10.16.172.224
2022-06-30 17:29:15.049958 7f0ef6530700 20 HTTP_USER_AGENT=Boto/2.49.0 Python/2.7.12 Linux/4.14.148-202204291725.git90deb91
2022-06-30 17:29:15.049959 7f0ef6530700 20 HTTP_VERSION=1.1
2022-06-30 17:29:15.049961 7f0ef6530700 20 QUERY_STRING=uploadId=2~1ZV5udTDBC-xcHWguk3Wr4_9U2awOKf&amp;partNumber=4183
2022-06-30 17:29:15.049969 7f0ef6530700 20 REMOTE_ADDR=10.16.172.224
2022-06-30 17:29:15.049970 7f0ef6530700 20 REQUEST_METHOD=PUT
2022-06-30 17:29:15.049971 7f0ef6530700 20 REQUEST_URI=/test/1T.file
2022-06-30 17:29:15.049972 7f0ef6530700 20 SCRIPT_URI=/test/1T.file
2022-06-30 17:29:15.049973 7f0ef6530700 20 SERVER_PORT=80
2022-06-30 17:29:15.049975 7f0ef6530700  1 ====== starting new request req=0x7f0ef6529860 =====
</code></pre>
<p>2T</p>
<pre><code class="language-shell">2022-06-30 14:30:21.497960 7fc3b4ecd700 20  bucket index object: .dir.a36a7e3f-2952-4680-9b9c-8497fa9a2c73.5279.1.70
2022-06-30 14:30:21.500356 7fc3b4ecd700 15 omap_set obj=default.rgw.buckets.non-ec:a36a7e3f-2952-4680-9b9c-8497fa9a2c73.5279.1__multipart_2T.file.2~i1zS2MRnaC6rvPxD36aRh-rsRPnkJHW.meta key=part.00015316
2022-06-30 14:30:21.501809 7fc3b4ecd700  2 req 15319:13.402100:s3:PUT /test/2T.file:put_obj:completing
2022-06-30 14:30:21.501872 7fc3b4ecd700  2 req 15319:13.402162:s3:PUT /test/2T.file:put_obj:op status=0
2022-06-30 14:30:21.501876 7fc3b4ecd700  2 req 15319:13.402167:s3:PUT /test/2T.file:put_obj:http status=200
2022-06-30 14:30:21.501890 7fc3b4ecd700  1 ====== req done req=0x7fc3b4ec6820 op status=0 http_status=200 ======
2022-06-30 14:30:21.501944 7fc3b4ecd700  1 civetweb: 0x55556651f620: 10.16.172.224 - - [30/Jun/2022:14:30:08 +0800] "PUT /test/2T.file?uploadId=2~i1zS2MRnaC6rvPxD36aRh-rsRPnkJHW&amp;partNumber=15316 HTTP/1.1" 200 231 - Boto/2.49.0 Python/2.7.12 Linux/4.14.148-202204291725.git90deb91
2022-06-30 14:30:22.031011 7fc3b2ec9700  5 NOTICE: call to do_aws4_auth_completion
2022-06-30 14:30:22.031098 7fc3b2ec9700  5 NOTICE: call to do_aws4_auth_completion
2022-06-30 14:30:22.139835 7fc3b96d6700 20 CONTENT_LENGTH=134217728
2022-06-30 14:30:22.139849 7fc3b96d6700 20 CONTENT_TYPE=application/octet-stream
2022-06-30 14:30:22.139849 7fc3b96d6700 20 HTTP_ACCEPT_ENCODING=identity
2022-06-30 14:30:22.139851 7fc3b96d6700 20 HTTP_AUTHORIZATION=AWS KAGC5XL83YICQXP0THTQ:eGNkLYW1iOtm1x6l5boBiMy+/Co=
2022-06-30 14:30:22.139853 7fc3b96d6700 20 HTTP_CONTENT_MD5=/enggYKBg25PwO3+3iuHYg==
2022-06-30 14:30:22.139855 7fc3b96d6700 20 HTTP_DATE=Thu, 30 Jun 2022 06:30:21 GMT
2022-06-30 14:30:22.139856 7fc3b96d6700 20 HTTP_EXPECT=100-Continue
2022-06-30 14:30:22.139857 7fc3b96d6700 20 HTTP_HOST=10.16.172.224
2022-06-30 14:30:22.139858 7fc3b96d6700 20 HTTP_USER_AGENT=Boto/2.49.0 Python/2.7.12 Linux/4.14.148-202204291725.git90deb91
2022-06-30 14:30:22.139859 7fc3b96d6700 20 HTTP_VERSION=1.1
2022-06-30 14:30:22.139864 7fc3b96d6700 20 QUERY_STRING=uploadId=2~i1zS2MRnaC6rvPxD36aRh-rsRPnkJHW&amp;partNumber=15335
2022-06-30 14:30:22.139869 7fc3b96d6700 20 REMOTE_ADDR=10.16.172.224
2022-06-30 14:30:22.139870 7fc3b96d6700 20 REQUEST_METHOD=PUT
2022-06-30 14:30:22.139871 7fc3b96d6700 20 REQUEST_URI=/test/2T.file
2022-06-30 14:30:22.139871 7fc3b96d6700 20 SCRIPT_URI=/test/2T.file
2022-06-30 14:30:22.139872 7fc3b96d6700 20 SERVER_PORT=80
2022-06-30 14:30:22.139874 7fc3b96d6700  1 ====== starting new request req=0x7fc3b96cf820 =====
</code></pre>
<table>
<thead>
<tr>
<th>file size</th>
<th>chunk size</th>
<th>content length</th>
</tr>
</thead>
<tbody>
<tr>
<td>50G</td>
<td>8M</td>
<td>670945(约0.64MiB)</td>
</tr>
<tr>
<td>100G</td>
<td>8M</td>
<td>1345746(约1.28MiB)</td>
</tr>
<tr>
<td>1T</td>
<td>8M</td>
<td>64MiB</td>
</tr>
<tr>
<td>1T</td>
<td>15M</td>
<td>34.133MiB</td>
</tr>
<tr>
<td>2T</td>
<td>8M</td>
<td>134217728(128MiB)</td>
</tr>
</tbody>
</table>
<h1 id="zong-jie">总结</h1>
<p>如果上传较大文件，为了确保成功率，需做如下调整：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Client端上传时，放大单个分片大小</p>
</li>
<li class="lvl-2">
<p>ceph 开放参数<code>rgw_max_put_param_size</code> 的设置，配置content buffer 的大小，默认是1MB</p>
</li>
</ul>
<p>但参数<code>rgw_max_put_param_size</code> 目前是写死在代码里的，更改ceph的这个参数设置是无效的（有实测）。</p>
<p>最终解决方法是：</p>
<p>​     RD更改了 RGWCompleteMultipart 代码，统一了POST 与 GET传参（int RGWCompleteMultipart_ObjStore::post_params()  和 int RGWCompleteMultipart_ObjStore::get_params()），即让Get也听从传递的参数rgw_max_put_param_size；同时将rgw_max_put_param_size参数默认值放大50倍（默认值是 1 * 1024 * 1024）。</p>
<p>在未修改之前，如果要上传1T大小的对象，单个chunk size=8MiB，最低分片大小是 1 * 1024 * 1024 * 1024 / (1 * 1024 * 1024) = 1GiB (因为rgw_max_put_param_size=1 * 1024 * 1024)</p>
<h1 id="zi-liao-can-kao">资料参考</h1>
<p><a href="https://blog.csdn.net/wuyan6293/article/details/82115584">https://blog.csdn.net/wuyan6293/article/details/82115584</a></p>
<h1 id="jie-yu">结语</h1>
<p>8.0 8.2的旧版本，对于分片上传，代码写死为10000片，这限制了分片上传的文件大小。<br>
S3Browser等工具，默认分配大小为8M，按照旧版本的10000片，最大80GB的file大小。</p>
<p>当前我们将如下参数改为128000片，S3browser可支持到1000GiB，如果需要上传更大的文件，则需要调整分片上传，每个分片的大小，测试验证后确认每个分配64MB可以传6T的文件。</p>
<p>为什么将总分片数限制在128000，而不是更大。原因是BigteraJournal的transaction有个限制MaxTransactionNumOps，最大128K个op，再大会crash。而且标准AWS，支持单个对象最大5TB，再大也就不支持了。</p>
<pre><code class="language-shell">    self.set(section, 'rgw multipart part upload limit', '128000')
    self.set(section, 'rgw max put param size', '52428800')
</code></pre>
<p>最终，在上述调整情况下， 上传了一个2T(48MiB分片大小)， 3.6T(64MiB分片大小)， 4T(64MiB分片大小) 和 6T(64MiB分片大小)的单个大小的文件，均上传OK：</p>
<p><img class="shadow" src="/img/in-post/big_object_upload.png" width="1200"></p>
<p><img class="shadow" src="/img/in-post/ui_shows_big_object.png" width="1200"></p>
]]></content>
      <categories>
        <category>ceph</category>
        <category>S3</category>
      </categories>
      <tags>
        <tag>S3</tag>
      </tags>
  </entry>
  <entry>
    <title>自动部署cosbench并提交任务与结果处理解析</title>
    <url>/2022/01/28/auto_deploy_submit_analyser_cosbench_task/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>每次跑S3 Performance时，总要花费蛮多时间在构造xml以及xml调测上，避免xml内容有误影响测试。</p>
<p>此次直接将整个过程（部署jre，部署cosbench，提交任务，自动收集存储信息以及对cosbench测试结果处理），整合成一套完整测试script，提高下工作效率。</p>
<h2 id="script-directory-structure">Script directory structure</h2>
<pre><code class="language-shell">[root@node243 bak_cosbench]# tree ./
./
├── 00_run.sh
├── 01_check_expect_installed.sh
├── 02_deploy_jre.sh
├── 03_deploy_cosbench.sh
├── 04_deplay_nmon.sh
├── 05_submit_cosbench_task.sh
├── 06_collect_result.sh
├── 07_analyser_cosbench_result.sh
├── 08_restart_cosbench.sh
├── config
│&nbsp;&nbsp; ├── 100M_size_object_write_read_mix_files.xml.ini
│&nbsp;&nbsp; ├── 10M_size_object_write_read_mix_files.xml.ini
│&nbsp;&nbsp; ├── 120Million_only_write.xml.ini
│&nbsp;&nbsp; ├── 1G_size_object_write_read_mix_files.xml.ini
│&nbsp;&nbsp; ├── 1M_size_object_write_read_mix_files.xml.ini
│&nbsp;&nbsp; ├── 500M_size_object_write_read_mix_files.xml.ini
│&nbsp;&nbsp; ├── controller_template.conf
│&nbsp;&nbsp; ├── dry_run.xml
│&nbsp;&nbsp; ├── parameters.conf
│&nbsp;&nbsp; └── small_object_write_read_mix_files.xml.ini
├── packages
│&nbsp;&nbsp; ├── 0.4.2.c4.tar.gz
│&nbsp;&nbsp; ├── binfmt-support_2.1.6-1_amd64.deb
│&nbsp;&nbsp; ├── expect-5.44.1.15-5.el6_4.x86_64.rpm
│&nbsp;&nbsp; ├── jre-8u171-linux-x64.tar.gz
│&nbsp;&nbsp; ├── ksh-20120801-143.el7_9.x86_64.rpm
│&nbsp;&nbsp; ├── ksh-2020.0.0-4.ky10.x86_64.rpm
│&nbsp;&nbsp; ├── ksh_93u+20120801-2ubuntu0.16.04.1_amd64.deb
│&nbsp;&nbsp; ├── nmon_14g+debian-1build1_amd64.deb
│&nbsp;&nbsp; ├── nmon-16g-3.el7.x86_64.rpm
│&nbsp;&nbsp; ├── nmonchart40.tar
│&nbsp;&nbsp; └── tcl-8.5.7-6.el6.x86_64.rpm
├── README.md
├── subin
│&nbsp;&nbsp; ├── expect_scp.sh
│&nbsp;&nbsp; └── expect_ssh.sh
└── xml_files
    └── 60workers_4KB_workload.xml

4 directories, 34 files
</code></pre>
<h1 id="sop">SOP</h1>
<ol>
<li class="lvl-3">
<p>Prepare test environment</p>
</li>
</ol>
<ul class="lvl-0">
<li class="lvl-4">
<p>Install Kylin V10 or CentOS 7 or Ubuntu 16.04 as clients, client number is suggested same as that of gateways</p>
</li>
<li class="lvl-4">
<p>The IP address of clients must be sequential</p>
</li>
<li class="lvl-4">
<p>Yum/apt-get install some packages, including expect under packages dir(00_run.sh done)</p>
</li>
<li class="lvl-4">
<p>Install nmon,ksh on each storage nodes(00_run.sh done)</p>
</li>
</ul>
<ol start="2">
<li class="lvl-3">
<p>Create a S3 account in web UI</p>
</li>
</ol>
<ul class="lvl-0">
<li class="lvl-4">
<p>Only support S3</p>
</li>
</ul>
<ol start="3">
<li class="lvl-3">
<p>Create a pool, then set as S3 pool</p>
</li>
</ol>
<ul class="lvl-0">
<li class="lvl-4">
<p>Not care EC pool or Replicate pool</p>
</li>
</ul>
<ol start="4">
<li class="lvl-3">
<p>Enable ssh for root on Storage nodes</p>
</li>
</ol>
<ul class="lvl-0">
<li class="lvl-4">
<p>vim /etc/ssh/sshd_config to enable ssh for root(Default, after create cluster, forbidden root account to ssh)</p>
</li>
</ul>
<h1 id="content">Content</h1>
<h2 id="parameter-conf">parameter.conf</h2>
<p>This conf defines items below:</p>
<ol>
<li class="lvl-3">
<p>Info of clients and storage nodes</p>
</li>
<li class="lvl-3">
<p>Config nmonchart result path</p>
</li>
<li class="lvl-3">
<p>Some parameter for generating cosbench XML, such as workers, runtime, ini xml files, mix ratio and so on</p>
</li>
<li class="lvl-3">
<p>S3 AKEY&amp;SKEY</p>
</li>
</ol>
<h2 id="script-info">Script info</h2>
<p>Scripts are usually executed by order of the number prefixed to the filename.</p>
<h3 id="00-run-sh">00_run.sh:</h3>
<p>This script can be treated as a set which is constituted by the following scripts. You can modify the steps to fill the concrete requirements.</p>
<h3 id="01-check-expect-installed-sh">01_check_expect_installed.sh</h3>
<p>This scripe is used to install some packages on each cosbench client, such as expect, tcl, nc, net-tools and sshpass.</p>
<h3 id="02-deploy-jre-sh">02_deploy_jre.sh</h3>
<p>This script is used to copy jre(jre-8u171-linux-x64.tar.gz) to all clients according to parameter.conf.<br>
Since this script uses expect to interact, it is requested to install expect has not been installed on this client.</p>
<h3 id="03-deploy-cosbench-sh">03_deploy_cosbench.sh</h3>
<p>Execute it to install cosbench on all clients if have no cosbench installed before.<br>
If has been installed cosbench, if cosbench in running status, do nothing; if not running, will replace controller.conf then start cosbench.<br>
The first client as cosbench controller and driver, other nodes run driver.<br>
Will stop and disable firewall, if firewall in running status, each cosbench node can’t connect to each other.</p>
<h3 id="04-deplay-nmon-sh">04_deplay_nmon.sh</h3>
<p>Execute it to install nmon,ksh,nmonchart on all clients if have no nmon installed before.<br>
Use nmon to collect monitor data from each storage node.<br>
nmonchart needs ksh, so install ksh on each storage node.<br>
Use nmonchart to chart nmon data on each storage node.<br>
(1) After charted, mush be opened by Google browser<br>
(2) Needs to be able to access Google because needs Google plug-ins online(Can use nmon analyser to save excel)</p>
<h3 id="05-submit-cosbench-task-sh">05_submit_cosbench_task.sh</h3>
<p>Execute it to generate cosbench xml, then submit cosbench task, then run nmon to monitor storage on each storage node.<br>
Support dry run or not, suggest to dry run, prevent problems in direct running, and run completely after ensuring that there are no problems in the whole process.</p>
<h3 id="06-collect-result-sh">06_collect_result.sh</h3>
<p>Execute it to collect nmon result from storage nodes</p>
<h3 id="07-analyser-cosbench-result-sh">07_analyser_cosbench_result.sh</h3>
<p>Execute it to analyser cosbench rest result on cosbench controller node</p>
<h3 id="08-restart-cosbench-sh">08_restart_cosbench.sh</h3>
<p>If wants to restart all of cosbench service, you can run this script to do it.<br>
This action will not clean archive and log on each cosbench node by default, if to delete archive or log dir, should pass a parameter to shell, like as:./08_restart_cosbench.sh del.</p>
<h3 id="config">config/</h3>
<pre><code class="language-shell">controller_template.conf --&gt; Generate controller.conf then sync to the controller node
dry_run.xml                                    --&gt; For dry run
1M_size_object_write_read_mix_files.xml.ini    --&gt; Template of cosbench xml to generate cosbench task of xml files (Under xml_files)
10M_size_object_write_read_mix_files.xml.ini   --&gt; Template of cosbench xml to generate cosbench task of xml files (Under xml_files)
100M_size_object_write_read_mix_files.xml.ini  --&gt; Template of cosbench xml to generate cosbench task of xml files (Under xml_files)
500M_size_object_write_read_mix_files.xml.ini  --&gt; Template of cosbench xml to generate cosbench task of xml files (Under xml_files)
1G_size_object_write_read_mix_files.xml.ini    --&gt; Template of cosbench xml to generate cosbench task of xml files (Under xml_files)
120Million_only_write.xml.ini                  --&gt; Template of cosbench xml to generate cosbench task of xml files (Under xml_files)
small_object_write_read_mix_files.xml.ini      --&gt; Template of cosbench xml to generate cosbench task of xml files (Under xml_files)
</code></pre>
<p>For cosbench xml files(under xml_files), can decide the running sequence by specfying proper filename.</p>
<h3 id="packages">packages/</h3>
<p>Include expect, nmon, nmonchart, ksh and other tools.</p>
<h4 id="subin">subin/</h4>
<p>Some internal functions used by scripts.</p>
<h1 id="an-example-of-script-output">An example of script output</h1>
<pre><code class="language-shell">root@node243:~/cosbench# ./06_analyser_cosbench_result.sh 

----------------------------------------------------------------------------------- 
w1-QA_30workers_4K_30M_files_mix, cost_time:6H:22M:54S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4844.17         19.8417         6.05333              6.05333             
READ         3750.24         15.361          7.99                 7.94                
MIX_WRITE    1615.27         6.61614         10.1133              10.1133             
MIX_READ     1615.91         6.61874         8.31667              8.26333             
MIX_SUM      3231.18         13.2349         9.215                9.18833             

----------------------------------------------------------------------------------- 
w2-QA_30workers_100K_30M_files_mix, cost_time:6H:42M:30S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4020.6          411.709         7.32333              6.24667             
READ         3060.55         313.4           9.79667              8.9                 
MIX_WRITE    1378.69         141.178         11.5067              10.3833             
MIX_READ     1380.04         141.316         10.1067              9.17667             
MIX_SUM      2758.73         282.494         10.8067              9.78                

----------------------------------------------------------------------------------- 
w3-QA_30workers_200K_30M_files_mix, cost_time:7H:27M:26S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        3300.63         675.969         8.96333              7.02333             
READ         2171.91         444.807         13.8033              12.14               
MIX_WRITE    1103.61         226.021         13.14                11.0667             
MIX_READ     1103.17         225.929         13.9167              12.15               
MIX_SUM      2206.78         451.95          13.5283              11.6083             

----------------------------------------------------------------------------------- 
w4-QA_30workers_1024K_1M_Size_file_mix, cost_time:1H:46M:52S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        1377.91         1444.84         21.67                12.9667             
READ         1131.47         1186.44         26.5067              18.1567             
MIX_WRITE    555.8           582.804         25.1833              17.31               
MIX_READ     553.6           580.493         28.79                20.2333             
MIX_SUM      1109.4          1163.3          26.9867              18.7717             

----------------------------------------------------------------------------------- 
w5-QA_30workers_10240K_10M_Size_file_mix, cost_time:1H:13M:25S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        204.93          2148.8          146.457              90.3733             
READ         264.15          2769.83         113.58               60.35               
MIX_WRITE    108.17          1134.28         155.517              107.767             
MIX_READ     108.23          1134.85         121.68               70.4                
MIX_SUM      216.4           2269.13         138.598              89.0833             

----------------------------------------------------------------------------------- 
w6-QA_30workers_1048576K_1G_Size_file_mix, cost_time:1H:0M:43S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        3.02            3242.78         9933.77              595.353             
READ         5.64            6063.25         5313.1               173.7               
MIX_WRITE    1.97            2113.94         10108.3              656.83              
MIX_READ     1.98            2128.27         5094.47              188.393             
MIX_SUM      3.95            4242.21         7601.37              422.612             

----------------------------------------------------------------------------------- 
w7-QA_60workers_4K_30M_files_mix, cost_time:5H:46M:56S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        7500.32         30.7213         7.86333              7.86                
READ         6762.72         27.7001         8.86667              8.81333             
MIX_WRITE    2714.85         11.12           13.1667              13.1667             
MIX_READ     2714.38         11.1181         8.8                  8.74667             
MIX_SUM      5429.23         22.2381         10.9833              10.9567             

----------------------------------------------------------------------------------- 
w8-QA_60workers_100K_30M_files_mix, cost_time:6H:5M:42S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        5878.1          601.918         10.07                8.96                
READ         5407.74         553.752         11.0867              10.19               
MIX_WRITE    2345.29         240.157         14.3533              13.25               
MIX_READ     2342.65         239.887         11.1033              10.17               
MIX_SUM      4687.94         480.044         12.7283              11.71               

----------------------------------------------------------------------------------- 
w9-QA_60workers_200K_30M_files_mix, cost_time:6H:35M:58S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4841.97         991.636         12.2533              10.0967             
READ         3732.87         764.49          16.0667              14.4033             
MIX_WRITE    1911.44         391.463         15.9167              13.9                
MIX_READ     1910.73         391.317         15.3533              13.6167             
MIX_SUM      3822.17         782.78          15.635               13.7583             

----------------------------------------------------------------------------------- 
w10-QA_60workers_1024K_1M_Size_file_mix, cost_time:1H:32M:31S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        2286.75         2397.82         26.1367              17.3733             
READ         2057.05         2156.98         29.1633              21.0633             
MIX_WRITE    970.74          1017.9          28.4233              20.61               
MIX_READ     971.96          1019.17         33.2367              25.2167             
MIX_SUM      1942.7          2037.07         30.83                22.9133             

----------------------------------------------------------------------------------- 
w11-QA_60workers_10240K_10M_Size_file_mix, cost_time:1H:2M:21S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        351.36          3684.35         170.743              112.857             
READ         463.98          4865.07         129.313              74.13               
MIX_WRITE    181.99          1908.39         185.35               133.583             
MIX_READ     181.88          1907.17         144.337              89.06               
MIX_SUM      363.87          3815.56         164.843              111.322             

----------------------------------------------------------------------------------- 
w12-QA_60workers_1048576K_1G_Size_file_mix, cost_time:0H:54M:29S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4.88            5244.88         12283.6              796.11              
READ         8.17            8773.49         7343.07              289.537             
MIX_WRITE    3.08            3309.76         12663.9              908.077             
MIX_READ     3.07            3298.88         6822.43              307.493             
MIX_SUM      6.15            6608.64         9743.18              607.785             

----------------------------------------------------------------------------------- 
w13-QA_90workers_4K_30M_files_mix, cost_time:5H:43M:51S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        8321.29         34.084          10.6733              10.6733             
READ         9075.99         37.1753         9.90667              9.85333             
MIX_WRITE    3224.43         13.2073         18.1733              18.1733             
MIX_READ     3223.7          13.2043         9.60667              9.55333             
MIX_SUM      6448.13         26.4116         13.89                13.8633             

----------------------------------------------------------------------------------- 
w14-QA_90workers_100K_30M_files_mix, cost_time:5H:50M:24S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6638.6          679.793         13.4167              12.3433             
READ         7174.2          734.637         12.5367              11.6167             
MIX_WRITE    2848.65         291.702         19.08                17.94               
MIX_READ     2847.38         291.571         12.3867              11.43               
MIX_SUM      5696.03         583.273         15.7333              14.685              

----------------------------------------------------------------------------------- 
w15-QA_90workers_200K_30M_files_mix, cost_time:6H:27M:17S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        5517.32         1129.95         16.1767              14.0433             
READ         4825.51         988.266         18.6433              16.97               
MIX_WRITE    2412.23         494.026         20.0233              17.95               
MIX_READ     2410.53         493.676         17.1667              15.38               
MIX_SUM      4822.76         987.702         18.595               16.665              

----------------------------------------------------------------------------------- 
w16-QA_90workers_1024K_1M_Size_file_mix, cost_time:1H:28M:31S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        2749.42         2882.99         32.6367              24.3267             
READ         2716.61         2848.58         33.1233              25.18               
MIX_WRITE    1261.77         1323.06         33.17                25.36               
MIX_READ     1260.83         1322.08         38.08                30.1033             
MIX_SUM      2522.6          2645.14         35.625               27.7317             

----------------------------------------------------------------------------------- 
w17-QA_90workers_10240K_10M_Size_file_mix, cost_time:0H:59M:48S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        441.86          4633.24         203.613              146.33              
READ         618.08          6481.08         145.607              88.1033             
MIX_WRITE    229.29          2404.25         226.43               173.55              
MIX_READ     228.46          2395.61         166.75               109.23              
MIX_SUM      457.75          4799.86         196.59               141.39              

----------------------------------------------------------------------------------- 
w18-QA_90workers_1048576K_1G_Size_file_mix, cost_time:0H:52M:54S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        5.79            6215.07         15550.1              1077.36             
READ         8.92            9568.5          10100.1              395.867             
MIX_WRITE    3.57            3834.26         16124.7              1270.8              
MIX_READ     3.54            3798.35         9215.03              424.67              
MIX_SUM      7.11            7632.61         12669.9              847.737             

----------------------------------------------------------------------------------- 
w19-QA_120workers_4K_30M_files_mix, cost_time:5H:39M:31S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        8870.99         36.3356         13.39                13.39               
READ         10861.7         44.4896         11.04                10.99               
MIX_WRITE    3566.18         14.6071         23.3                 23.3                
MIX_READ     3564            14.5982         10.22                10.16               
MIX_SUM      7130.18         29.2053         16.76                16.73               

----------------------------------------------------------------------------------- 
w20-QA_120workers_100K_30M_files_mix, cost_time:5H:49M:25S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        7035.11         720.395         16.9133              15.81               
READ         8539.16         874.411         14.0433              13.1233             
MIX_WRITE    3174.51         325.07          24.3433              23.2233             
MIX_READ     3175.41         325.162         13.32                12.3567             
MIX_SUM      6349.92         650.232         18.8317              17.79               

----------------------------------------------------------------------------------- 
w21-QA_120workers_200K_30M_files_mix, cost_time:6H:20M:43S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        5936.71         1215.84         20.0867              18.08               
READ         5625.23         1152.05         21.3233              19.6533             
MIX_WRITE    2737.41         560.621         25.1433              23.0967             
MIX_READ     2732.54         559.625         18.5967              16.7933             
MIX_SUM      5469.95         1120.25         21.87                19.945              

----------------------------------------------------------------------------------- 
w22-QA_120workers_1024K_1M_Size_file_mix, cost_time:1H:26M:48S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        3042.73         3190.53         39.3433              31.2733             
READ         3240.65         3398.06         37.02                29.3                
MIX_WRITE    1461.43         1532.42         39.86                32.18               
MIX_READ     1459.29         1530.18         42.2033              34.4067             
MIX_SUM      2920.72         3062.6          41.0317              33.2933             

----------------------------------------------------------------------------------- 
w23-QA_120workers_10240K_10M_Size_file_mix, cost_time:0H:58M:43S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        485.49          5090.78         247.103              191.573             
READ         721.01          7560.35         166.423              106.4               
MIX_WRITE    258.56          2711.11         274.45               220.973             
MIX_READ     259.18          2717.8          189.177              129.63              
MIX_SUM      517.74          5428.91         231.813              175.302             

----------------------------------------------------------------------------------- 
w24-QA_120workers_1048576K_1G_Size_file_mix, cost_time:0H:52M:30S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6.16            6618.53         19470.7              1419.07             
READ         9.43            10130.3         12720.5              486.747             
MIX_WRITE    3.65            3928.62         20438.5              1707.93             
MIX_READ     3.8             4079.41         11920.9              535.357             
MIX_SUM      7.45            8008.03         16179.7              1121.64             

[WARN]  Task : (w25-1200million_4k_data_filling) status is not finished, but : (terminated), please pay more attention 


[WARN]  Task : (w26-1200million_4k_data_filling) status is not finished, but : (terminated), please pay more attention 


[WARN]  Task : (w27-120million_4k_data_filling) status is not finished, but : (terminated), please pay more attention 


[WARN]  Task : (w28-120million_4k_data_filling) status is not finished, but : (cancelled), please pay more attention 


Task: (w29-120million_4k_data_filling), write total objects: (120000000), cost time: (14195(s)), write speed: (8453.68) 


[WARN]  Task : (w30-QA_120workers_4K_30M_files_mix) status is not finished, but : (cancelled), please pay more attention 


----------------------------------------------------------------------------------- 
w31-QA_120workers_4K_30M_files_mix, cost_time:6H:3M:26S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        5388.65         22.0719         22.1933              22.1933             
READ         11093.4         45.4386         10.81                10.76               
MIX_WRITE    3714.16         15.2132         22.7667              22.7667             
MIX_READ     3711.56         15.2025         9.40333              9.35                
MIX_SUM      7425.72         30.4157         16.085               16.0583             

----------------------------------------------------------------------------------- 
w32-QA_120workers_100K_30M_files_mix, cost_time:5H:27M:24S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        7803.41         799.069         15.2333              14.1267             
READ         8556.41         876.177         14.0167              13.1067             
MIX_WRITE    3406.95         348.871         22.28                21.1367             
MIX_READ     3406.42         348.817         12.8033              11.8367             
MIX_SUM      6813.37         697.688         17.5417              16.4867             

----------------------------------------------------------------------------------- 
w33-QA_120workers_200K_30M_files_mix, cost_time:5H:54M:16S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6372.15         1305.02         18.6967              16.5867             
READ         5594.51         1145.76         21.4433              19.7367             
MIX_WRITE    2853.54         584.404         23.5533              21.4633             
MIX_READ     2849.95         583.669         18.3933              16.5333             
MIX_SUM      5703.49         1168.07         20.9733              18.9983             

----------------------------------------------------------------------------------- 
w34-QA_120workers_1024K_1M_Size_file_mix, cost_time:1H:20M:49S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        3349.24         3511.92         35.7333              27.55               
READ         3228.21         3385.03         37.1633              29.3633             
MIX_WRITE    1532.84         1607.3          34.9367              27.1433             
MIX_READ     1537.16         1611.83         43.1167              35.1867             
MIX_SUM      3070            3219.13         39.0267              31.165              

----------------------------------------------------------------------------------- 
w35-QA_120workers_10240K_10M_Size_file_mix, cost_time:0H:55M:8S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        537.52          5636.43         223.167              164.657             
READ         738.94          7748.37         162.39               102.293             
MIX_WRITE    251.73          2639.46         276.8                221.483             
MIX_READ     252.38          2646.39         199.35               138.473             
MIX_SUM      504.11          5285.85         238.075              179.978             

----------------------------------------------------------------------------------- 
w36-QA_120workers_1048576K_1G_Size_file_mix, cost_time:0H:50M:14S                    
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6.91            7414.56         17379.5              1282.79             
READ         9.36            10045           12829.2              436.01              
MIX_WRITE    3.79            4072.14         19156.8              1636.76             
MIX_READ     3.92            4208.96         12083.9              543.213             
MIX_SUM      7.71            8281.1          15620.4              1089.99             

Task: (w37-120million_4k_data_filling), write total objects: (120000000), cost time: (13965(s)), write speed: (8592.91) 


----------------------------------------------------------------------------------- 
w40-QA_DRY_RUN_30workers_4K_30M_files_mix, cost_time:0H:2M:9S                      
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4098.54         16.7876         6.97333              6.97333             
READ         10856.8         44.4696         2.75667              2.69667             
MIX_WRITE    2143.91         8.78142         7.10667              7.10667             
MIX_READ     5025.76         20.5855         2.87333              2.82                
MIX_SUM      7169.67         29.3669         4.99                 4.96333             

----------------------------------------------------------------------------------- 
w41-QA_DRY_RUN_30workers_100K_30M_files_mix, cost_time:0H:2M:12S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4688.9          480.144         6.24667              5.12333             
READ         8137.48         833.279         3.68                 2.85333             
MIX_WRITE    1670.89         171.099         8.70667              7.66                
MIX_READ     3881.14         397.428         3.91667              3.04667             
MIX_SUM      5552.03         568.527         6.31167              5.35333             

----------------------------------------------------------------------------------- 
w43-QA_DRY_RUN_30workers_4K_30M_files_mix, cost_time:0H:2M:12S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6433.48         26.3515         4.53                 4.53                
READ         11056.4         45.2869         2.70667              2.65333             
MIX_WRITE    2145.06         8.78618         7.1                  7.1                 
MIX_READ     5018.76         20.5568         2.88                 2.82667             
MIX_SUM      7163.82         29.343          4.99                 4.96333             

----------------------------------------------------------------------------------- 
w48-QA_DRY_RUN_30workers_4K_30M_files_mix, cost_time:0H:2M:16S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6500.63         26.6266         4.47333              4.47333             
READ         11065           45.3222         2.70333              2.65333             
MIX_WRITE    2131.74         8.73162         7.17333              7.17333             
MIX_READ     4972.22         20.3662         2.89                 2.83333             
MIX_SUM      7103.96         29.0978         5.03167              5.00333             

----------------------------------------------------------------------------------- 
w49-QA_DRY_RUN_30workers_4K_30M_files_mix, cost_time:0H:2M:14S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6492.76         26.5944         4.48                 4.48                
READ         11006.1         45.0812         2.71333              2.66                
MIX_WRITE    2126.64         8.71073         7.17333              7.17333             
MIX_READ     4988.68         20.4336         2.89                 2.83333             
MIX_SUM      7115.32         29.1443         5.03167              5.00333             

----------------------------------------------------------------------------------- 
w50-QA_DRY_RUN_30workers_100K_30M_files_mix, cost_time:0H:2M:17S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4912.96         503.087         5.97                 4.88333             
READ         8085.7          827.976         3.70333              2.89                
MIX_WRITE    1668.04         170.808         8.7                  7.65333             
MIX_READ     3904.94         399.866         3.90333              3.03                
MIX_SUM      5572.98         570.674         6.30167              5.34167             

----------------------------------------------------------------------------------- 
w51-QA_DRY_RUN_30workers_200K_30M_files_mix, cost_time:0H:2M:19S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        3957.27         810.449         7.45333              5.58667             
READ         6894.38         1411.97         4.34333              2.94667             
MIX_WRITE    1386.41         283.936         10.4267              8.61                
MIX_READ     3239.48         663.446         4.74                 3.18                
MIX_SUM      4625.89         947.382         7.58333              5.895               

----------------------------------------------------------------------------------- 
w52-QA_DRY_RUN_30workers_1024K_30M_files_mix, cost_time:0H:2M:18S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        1434.56         1504.25         20.8067              12.1233             
READ         2703.91         2835.25         11.0867              4.41                
MIX_WRITE    601.08          630.281         22.06                14.8167             
MIX_READ     1412.91         1481.54         11.8                 4.75667             
MIX_SUM      2013.99         2111.82         16.93                9.78667             

----------------------------------------------------------------------------------- 
w53-QA_DRY_RUN_30workers_10240K_30M_files_mix, cost_time:0H:2M:33S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        198.32          2079.51         151.25               87.06               
READ         335.44          3517.29         89.4633              27.0367             
MIX_WRITE    89.43           937.714         145.71               96.7367             
MIX_READ     218.16          2287.54         77.7433              25.52               
MIX_SUM      307.59          3225.25         111.727              61.1283             

----------------------------------------------------------------------------------- 
w54-QA_DRY_RUN_30workers_4K_30M_files_mix, cost_time:0H:2M:17S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        6181.75         25.3205         4.71                 4.71                
READ         11059.2         45.2983         2.70667              2.65667             
MIX_WRITE    2117.66         8.67393         7.29333              7.29333             
MIX_READ     4926.28         20.178          2.88                 2.83333             
MIX_SUM      7043.94         28.8519         5.08667              5.06333             

----------------------------------------------------------------------------------- 
w55-QA_DRY_RUN_30workers_100K_30M_files_mix, cost_time:0H:2M:19S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4950.13         506.893         5.92333              4.83                
READ         8129.49         832.46          3.68333              2.85333             
MIX_WRITE    1650.2          168.981         8.92                 7.87                
MIX_READ     3839.86         393.201         3.92                 3.04                
MIX_SUM      5490.06         562.182         6.42                 5.455               

----------------------------------------------------------------------------------- 
w56-QA_DRY_RUN_30workers_200K_30M_files_mix, cost_time:0H:2M:20S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        4048.56         829.145         7.28                 5.38667             
READ         6835.65         1399.94         4.38333              2.95                
MIX_WRITE    1395.3          285.759         10.3233              8.49333             
MIX_READ     3263.39         668.343         4.72333              3.15333             
MIX_SUM      4658.69         954.102         7.52333              5.82333             

----------------------------------------------------------------------------------- 
w57-QA_DRY_RUN_30workers_1024K_30M_files_mix, cost_time:0H:2M:21S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        1470.29         1541.7          20.3033              11.7467             
READ         2693.39         2824.22         11.1367              4.42333             
MIX_WRITE    602.11          631.362         22.18                14.8933             
MIX_READ     1401.31         1469.38         11.8333              4.77667             
MIX_SUM      2003.42         2100.74         17.0067              9.835               

----------------------------------------------------------------------------------- 
w58-QA_DRY_RUN_30workers_10240K_30M_files_mix, cost_time:0H:2M:35S                     
             IOPS            BW(MB/s)        avg_res_time(ms)     avg_proc_time(ms)   
WRITE        200.65          2103.96         149.527              85.38               
READ         339.92          3564.32         88.26                27.0233             
MIX_WRITE    92.2            966.762         146.957              96.5833             
MIX_READ     208.41          2185.4          78.9067              25.44               
MIX_SUM      300.61          3152.16         112.932              61.0117             
root@node243:~/cosbench# 

</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>performance</category>
        <category>shell</category>
        <category>cosbench</category>
      </categories>
      <tags>
        <tag>performance</tag>
        <tag>shell</tag>
        <tag>cosbench</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次根据epoch查找问题触发时间点</title>
    <url>/2022/07/11/base_on_epoch_find_issue_occured_time/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>自动化用例执行期间，碰到crushmap中有一个Default pool，还有一个default pool，只是首字母大小写不一样，如下所示：</p>
<pre><code class="language-shell">root@pytest-83-12:~/workspace@2/src# ceph -s
  cluster:
    id:     5d8a5c28-48e7-4f2b-bab5-fd3d1f576b12
    health: HEALTH_OK
 
  services:
    mon: 3 daemons, quorum zvdtw,sufih,rlxot
    mgr: zvdtw(active), standbys: sufih, rlxot
    mds: cephfs-3/3/3 up  {0=cephfs.1.1.1.11.10=up:active,1=cephfs.1.1.1.11.12=up:active,2=cephfs.1.1.1.11.11=up:active}, 5 up:standby
    osd: 3 osds: 3 up, 3 in
    rgw: 1 daemon active
 
  data:
    pools:   12 pools, 6144 pgs
    objects: 627 objects, 6.20MiB
    usage:   8.17GiB used, 96.7GiB / 105GiB avail
    pgs:     6144 active+clean
 
  io:
    client:   168B/s rd, 0B/s wr, 0op/s rd, 0op/s wr
 
root@pytest-83-12:~/workspace@2/src# ceph osd tree
ID  CLASS WEIGHT  TYPE NAME                  STATUS REWEIGHT PRI-AFF 
-26       0.02119 pool Default                                       
-31             0     host Default_1.1.1.11                          
-25       0.02119     host Default_1.1.1.12                          
  1   hdd 0.02119         osd.1                  up  1.00000 1.00000 
-29             0     host Default_1.1.1.13                          
 -2       0.08488 pool metadata                                      
 -7       0.03555     host metadata_1.1.1.11                         
  0   hdd 0.03555         osd.0                  up  1.00000 1.00000 
-11       0.01575     host metadata_1.1.1.12                         
  1   hdd 0.01575         osd.1                  up  1.00000 1.00000 
-15       0.03358     host metadata_1.1.1.13                         
  2   hdd 0.03358         osd.2                  up  1.00000 1.00000 
-19             0     host metadata_1.1.1.14                         
 -1       0.10237 pool default                                       
 -5       0.04059     host default_1.1.1.11                          
  0   hdd 0.04059         osd.0                  up  1.00000 1.00000 
 -9       0.02119     host default_1.1.1.12                          
  1   hdd 0.02119         osd.1                  up  1.00000 1.00000 
-13       0.04059     host default_1.1.1.13                          
  2   hdd 0.04059         osd.2                  up  1.00000 1.00000 
-17             0     host default_1.1.1.14                          
root@pytest-83-12:~/workspace@2/src# 
</code></pre>
<p>表面看，ceph集群是健康的，但UI上的一些操作会报错，报错的原因是无法从Default pool中获取到对应的osd.x中的x，即osd的index id无法获取到，进而导致UI上的涉及Pool和OSD的相关动作，都会报错。</p>
<h1 id="wen-ti-zhui-zong">问题追踪</h1>
<h2 id="ru-he-que-ding-wen-ti-fa-sheng-de-di-yi-shi-jian-dian">如何确定问题发生的第一时间点？</h2>
<p>先获取当前epoch，如下文所示：</p>
<pre><code class="language-shell">root@pytest-83-12:~# ceph osd dump
epoch 716
fsid 5d8a5c28-48e7-4f2b-bab5-fd3d1f576b12
created 2022-07-09 12:52:54.101136
modified 2022-07-10 15:34:46.768843
flags sortbitwise,recovery_deletes,purged_snapdirs
crush_version 278
full_ratio 0.95
backfillfull_ratio 0.9
nearfull_ratio 0.85
require_min_compat_client jewel
min_compat_client jewel
require_osd_release luminous
pool 1 '.rgw.root' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 5 flags hashpspool stripe_width 0 application rgw
pool 2 'default.rgw.control' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 15 flags hashpspool stripe_width 0 application rgw
pool 3 '.ezs3' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 17 flags hashpspool,nodelete stripe_width 0 application internal
pool 4 'default.rgw.meta' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 17 flags hashpspool stripe_width 0 application rgw
pool 5 'default.rgw.log' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 19 flags hashpspool stripe_width 0 application rgw
pool 6 'data' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 1024 pgp_num 1024 last_change 76 flags hashpspool,nodelete stripe_width 0 application cephfs
pool 7 'default.rgw.buckets.data' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 1024 pgp_num 1024 last_change 22 flags hashpspool,nodelete stripe_width 0 application rgw
pool 8 '.ezs3.central.log' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 25 flags hashpspool,nodelete stripe_width 0 application internal
pool 9 '.ezs3.statistic' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 28 flags hashpspool,nodelete stripe_width 0 application internal
pool 10 'metadata' replicated size 2 min_size 1 crush_rule 1 object_hash rjenkins pg_num 1024 pgp_num 1024 last_change 76 flags hashpspool,nodelete stripe_width 0 application cephfs
pool 11 'default.rgw.buckets.index' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 256 pgp_num 256 last_change 34 flags hashpspool stripe_width 0 application rgw
pool 12 'rbd' replicated size 2 min_size 1 crush_rule 0 object_hash rjenkins pg_num 1024 pgp_num 1024 last_change 71 flags hashpspool,nodelete stripe_width 0 application rbd
max_osd 5
osd.0 up in weight 1 recovery_weight 1 up_from 706 up_thru 706 down_at 704 last_clean_interval [395,705) 1.1.1.11:6800/834186 1.1.1.11:6808/1834186 1.1.1.11:6809/1834186 1.1.1.11:6810/1834186 exists,up 89da3846-5336-4b17-8dfd-b919e4371e4c
osd.1 up in weight 1 recovery_weight 1 up_from 232 up_thru 706 down_at 227 last_clean_interval [37,229) 1.1.1.12:6801/15674 1.1.1.12:6806/1015674 1.1.1.12:6807/1015674 1.1.1.12:6808/1015674 exists,up 5933b7c5-bbd8-4e74-984b-9f6961799a5b
osd.2 up in weight 1 recovery_weight 1 up_from 403 up_thru 706 down_at 0 last_clean_interval [0,0) 1.1.1.13:6800/755654 1.1.1.13:6801/755654 1.1.1.13:6802/755654 1.1.1.13:6803/755654 exists,up d50d1d3b-ee0c-4e34-9e09-c187fc7bbec4
</code></pre>
<p>当前epoch是716</p>
<h2 id="cha-xun-epoch-716-de-crush-map-zhong-shi-fou-cun-zai-default">查询epoch=716的crush map中是否存在Default</h2>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=716;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt
got osdmap epoch 716
osdmaptool: osdmap file 'osdmap.716'
osdmaptool: exported crush map to crush.716
root@pytest-83-12:/home/btadmin# cat crush.716.txt |grep Default
host Default_1.1.1.12 {
host Default_1.1.1.13 {
host Default_1.1.1.11 {
pool Default {
	item Default_1.1.1.12 weight 0.021
	item Default_1.1.1.13 weight 0.000
	item Default_1.1.1.11 weight 0.000
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>发现epoch716里含有；利用二分法，对半分，来查找：</p>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=358;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 358
osdmaptool: osdmap file 'osdmap.358'
osdmaptool: exported crush map to crush.358
host Default_1.1.1.12 {
host Default_1.1.1.13 {
host Default_1.1.1.11 {
pool Default {
	item Default_1.1.1.12 weight 0.021
	item Default_1.1.1.13 weight 0.041
	item Default_1.1.1.11 weight 0.041
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>epoch 358里也含有，继续二分法找:</p>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=179;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 179
osdmaptool: osdmap file 'osdmap.179'
osdmaptool: exported crush map to crush.179
host Default_1.1.1.12 {
host Default_1.1.1.13 {
host Default_1.1.1.11 {
pool Default {
	item Default_1.1.1.12 weight 0.021
	item Default_1.1.1.13 weight 0.041
	item Default_1.1.1.11 weight 0.041
root@pytest-83-12:/home/btadmin# 
</code></pre>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=89;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 89
osdmaptool: osdmap file 'osdmap.89'
osdmaptool: exported crush map to crush.89
root@pytest-83-12:/home/btadmin# systemctl restart ceph.target;systemctl restart ceph-radosgw@radosgw.0.service;systemctl restart ezrpc.service;systemctl restart httpd.service
Failed to restart httpd.service: Unit httpd.service not found.
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>发现epoch 89里并没有涵盖Default pool，说明在epoch 89<sub>179之间的某个epoch，继续缩小范围(查找89</sub>179的中间值，134)：</p>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=134;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 134
osdmaptool: osdmap file 'osdmap.134'
osdmaptool: exported crush map to crush.134
host Default_1.1.1.12 {
host Default_1.1.1.13 {
pool Default {
	item Default_1.1.1.12 weight 0.021
	item Default_1.1.1.13 weight 0.041
host Default_1.1.1.11 {
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>epoch 134含有，说明在epoch 89<sub>134之间的某个epoch，继续缩小范围（取89</sub>134的中间值111）：</p>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=111;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 111
osdmaptool: osdmap file 'osdmap.111'
osdmaptool: exported crush map to crush.111
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>epoch 111不含有，说明在epoch 111<sub>134之间的某个epoch，继续缩小范围（取111</sub>134的中间值122）：</p>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=122;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 122
osdmaptool: osdmap file 'osdmap.122'
osdmaptool: exported crush map to crush.122
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>epoch 122不含有，说明在epoch 122<sub>134之间的某个epoch，继续缩小范围（取122</sub>134的中间值128）：</p>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=128;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 128
osdmaptool: osdmap file 'osdmap.128'
osdmaptool: exported crush map to crush.128
host Default_1.1.1.12 {
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>epoch 128含有了，说明在epoch 122<sub>128之间的某个epoch，这样范围逐步缩小了，接下来就是挨个从(122,128)之间找123</sub>127 epoch</p>
<pre><code class="language-shell">root@pytest-83-12:/home/btadmin# i=127;ceph osd getmap $i -o osdmap.$i;osdmaptool --export-crush crush.$i  osdmap.$i;crushtool -d crush.$i -o crush.$i.txt;cat crush.$i.txt |grep Default
got osdmap epoch 127
osdmaptool: osdmap file 'osdmap.127'
osdmaptool: exported crush map to crush.127
root@pytest-83-12:/home/btadmin# 
</code></pre>
<p>很巧，epoch 127不含，说明epoch 128是第一次出现Default pool，那就追epoch 128:</p>
<pre><code class="language-shell">root@pytest-83-12:/var/log/ceph# zgrep -n "osd crush link" ceph.audit.log.2.gz |grep 'Default'
316910:2022-07-09 13:47:44.051329 mon.klavr mon.1 1.1.1.12:6789/0 208638 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.12"}]: dispatch
316937:2022-07-09 13:47:44.130734 mon.gfbvr mon.0 1.1.1.11:6789/0 724 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.12"}]: dispatch
317003:2022-07-09 13:47:45.108711 mon.gfbvr mon.0 1.1.1.11:6789/0 731 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.12"}]': finished
317129:2022-07-09 13:47:47.106794 mon.klavr mon.1 1.1.1.12:6789/0 208785 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.13"}]: dispatch
317140:2022-07-09 13:47:47.182459 mon.gfbvr mon.0 1.1.1.11:6789/0 755 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.13"}]: dispatch
317153:2022-07-09 13:47:47.248437 mon.gfbvr mon.0 1.1.1.11:6789/0 760 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.13"}]': finished
317338:2022-07-09 13:47:49.261214 mon.klavr mon.1 1.1.1.12:6789/0 208913 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.11"}]: dispatch
317348:2022-07-09 13:47:49.336716 mon.gfbvr mon.0 1.1.1.11:6789/0 788 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.11"}]: dispatch
317548:2022-07-09 13:47:50.338830 mon.gfbvr mon.0 1.1.1.11:6789/0 793 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.11"}]': finished
root@pytest-83-12:/var/log/ceph# 
</code></pre>
<pre><code class="language-shell">root@pytest-83-12:/var/log/ceph# zgrep -n "osd crush link" ceph.audit.log.2.gz |grep '13:47:'
313387:2022-07-09 13:47:09.208853 mon.klavr mon.1 1.1.1.12:6789/0 206827 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.12"}]: dispatch
313402:2022-07-09 13:47:09.286625 mon.gfbvr mon.0 1.1.1.11:6789/0 445 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.12"}]: dispatch
313478:2022-07-09 13:47:10.259098 mon.gfbvr mon.0 1.1.1.11:6789/0 454 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.12"}]': finished
313778:2022-07-09 13:47:12.168383 mon.klavr mon.1 1.1.1.12:6789/0 206954 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.13"}]: dispatch
313787:2022-07-09 13:47:12.258398 mon.gfbvr mon.0 1.1.1.11:6789/0 474 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.13"}]: dispatch
313898:2022-07-09 13:47:13.336983 mon.gfbvr mon.0 1.1.1.11:6789/0 485 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.13"}]': finished
314138:2022-07-09 13:47:15.325649 mon.klavr mon.1 1.1.1.12:6789/0 207164 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.11"}]: dispatch
314146:2022-07-09 13:47:15.402601 mon.gfbvr mon.0 1.1.1.11:6789/0 510 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.11"}]: dispatch
314194:2022-07-09 13:47:16.406330 mon.gfbvr mon.0 1.1.1.11:6789/0 515 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=pytest-sds-pool"], "name": "pytest-sds-pool_1.1.1.11"}]': finished
316910:2022-07-09 13:47:44.051329 mon.klavr mon.1 1.1.1.12:6789/0 208638 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.12"}]: dispatch
316937:2022-07-09 13:47:44.130734 mon.gfbvr mon.0 1.1.1.11:6789/0 724 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.12"}]: dispatch
317003:2022-07-09 13:47:45.108711 mon.gfbvr mon.0 1.1.1.11:6789/0 731 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.12"}]': finished
317129:2022-07-09 13:47:47.106794 mon.klavr mon.1 1.1.1.12:6789/0 208785 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.13"}]: dispatch
317140:2022-07-09 13:47:47.182459 mon.gfbvr mon.0 1.1.1.11:6789/0 755 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.13"}]: dispatch
317153:2022-07-09 13:47:47.248437 mon.gfbvr mon.0 1.1.1.11:6789/0 760 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.13"}]': finished
317338:2022-07-09 13:47:49.261214 mon.klavr mon.1 1.1.1.12:6789/0 208913 : audit [INF] from='client.5074 1.1.1.12:0/4225613905' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.11"}]: dispatch
317348:2022-07-09 13:47:49.336716 mon.gfbvr mon.0 1.1.1.11:6789/0 788 : audit [INF] from='client.5074 -' entity='client.admin' cmd=[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.11"}]: dispatch
317548:2022-07-09 13:47:50.338830 mon.gfbvr mon.0 1.1.1.11:6789/0 793 : audit [INF] from='client.5074 -' entity='client.admin' cmd='[{"prefix": "osd crush link", "args": ["pool=Default"], "name": "Default_1.1.1.11"}]': finished
root@pytest-83-12:/var/log/ceph# 
</code></pre>
<p>这里能够看出，13:47时，有创建一个Default pool.</p>
<p>既然找到时间点了，找一下自动化用例，那个时刻在做什么：</p>
<pre><code class="language-shell">2022-07-09 13:47:42 [pool.py:67  ] [ INFO] [Success]  Get all OSD success which state is UP and IN, osd_up_in is : ([0, 1, 2])
2022-07-09 13:47:42 [pool.py:169 ] [ INFO] [Action]   Assign osd : (0 1 2) into pool : (Default)
2022-07-09 13:47:42 [connectionpool.py:243 ] [DEBUG] Resetting dropped connection: localhost
</code></pre>
<p>在assign OSD into Default pool，找到这里，就找到那个时间点被执行到的用例：</p>
<pre><code class="language-shell">2022-07-09 13:47:00 [test_01_SDS_admin_account_settings.py:46  ] [ INFO] ------------------------  Testsuite setup  ------------------------
2022-07-09 13:47:00 [test_01_SDS_admin_account_settings.py:47  ] [ INFO] [SetUp]     Class setup to create pool : (pytest-sds-pool), VS : (pytest-sds-vs)
2022-07-09 13:47:00 [virtual_storage.py:306 ] [ INFO] [Action]   Start to get all nodes information
2022-07-09 13:47:00 [connectionpool.py:243 ] [DEBUG] Resetting dropped connection: localhost
2022-07-09 13:47:00 [connectionpool.py:396 ] [DEBUG] https://localhost:8080 "GET /vs/Default/host HTTP/1.1" 200 139
.......................................... 省略 .......................................
2022-07-09 13:50:06 [bigtera_cluster.py:1422] [ INFO] [Check]    Success, ctdb health is OK
2022-07-09 13:50:06 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2022-07-09 13:50:06 [conftest.py:18  ] [ INFO] Current test case name : (test_01_test_ads_admin_login)
2022-07-09 13:50:06 [test_01_SDS_admin_account_settings.py:24  ] [ INFO] [Check]    Start to check cluster health, file name : (/root/workspace@2/src/testcase/Function_Test/case_02_Accounts/test_01_SDS_admin_account_settings.py)
2022-07-09 13:50:06 [bigtera_cluster.py:1408] [ INFO] [Check]    Check ctdb health status from file of : (/root/workspace@2/src/common/bigtera_cluster.pyc)
2022-07-09 13:50:06 [command.py:102 ] [DEBUG] command 'ctdb status | grep pnn | sed 's/(THIS NODE)//g' | awk '{print $NF}' | grep OK | wc -l' (timeout=0, force=False)
2022-07-09 13:50:06 [command.py:177 ] [DEBUG] command 'ctdb status | grep pnn | sed 's/(THIS NODE)//g' | awk '{print $NF}' | grep OK | wc -l' returns '3

</code></pre>
<p>至此找出是哪个用例的执行，触发了bug。</p>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>获取ceph large omap object</title>
    <url>/2022/07/20/large_omap_objects/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>前几天客户报自己的一套原生ceph集群出现 'Large omap objects’告警，请我们免费技术支持一下解决这个告警。</p>
<p>告警信息如下所示：</p>
<img class="shadow" src="/img/in-post/Large_omap_objects.jpg" width="1200">
<h1 id="guo-cheng">过程</h1>
<p>获取到具体哪个Object omap较大，脚本内容参考如下：</p>
<pre><code class="language-python">#!/usr/bin/env python

import os
import sys
import time
import json
import rados
import rbd

ceph_conf_path = '/etc/ceph/ceph.conf'
rados_connect_timeout = 5

if not os.path.exists(ceph_conf_path):
    print("[ERROR] Incorrect path of ceph.conf, exit!!!")
    sys.exit(1)

class RADOSClient(object):
    def __init__(self,driver,pool=None):
        self.driver = driver
        self.client, self.ioctx = driver._connect_to_rados(pool)
    def __enter__(self):
        return self
    def __exit__(self, type_, value, traceback):
        self.driver._disconnect_from_rados(self.client, self.ioctx)

class RBDDriver(object):
    def __init__(self,ceph_conf_path,rados_connect_timeout,pool=None):
        self.ceph_conf_path = ceph_conf_path
        self.rados_connect_timeout = rados_connect_timeout
        self.pool = pool
    def _connect_to_rados(self, pool=None):
        client = rados.Rados(conffile=self.ceph_conf_path)
        try:
            if self.rados_connect_timeout &gt;= 0:
                client.connect(timeout=self.rados_connect_timeout)
            else:
                client.connect()
            if self.pool == None:
                ioctx = None
            else:
                ioctx = client.open_ioctx(self.pool)
            return client, ioctx
        except rados.Error:
            msg = "Error connecting to ceph cluster."
            client.shutdown()
            raise msg

    def _disconnect_from_rados(self, client, ioctx=None):
        if ioctx == None:
            client.shutdown()
        else:
            ioctx.close()
            client.shutdown()

class cmd_manager():
    def get_large_omap_obj_pool_name(self):
        with RADOSClient(RBDDriver(ceph_conf_path,rados_connect_timeout)) as dr:
            result = ''
            cmd = '{"prefix": "health", "detail": "detail", "format": "json"}'
            result = dr.client.mon_command(cmd,result)
            if result[0] == 0:
                res_ = json.loads(result[1])
                if len(res_["checks"]) and res_["checks"].has_key("LARGE_OMAP_OBJECTS"):
                    return res_["checks"]['LARGE_OMAP_OBJECTS']['detail'][0]['message'].split("'")[1]
            else:
                return False
    def get_pg_list_by_pool(self, pool_name):
        with RADOSClient(RBDDriver(ceph_conf_path, rados_connect_timeout)) as dr:
            result = ''
            cmd = '{"prefix": "pg ls-by-pool", "poolstr": "' + pool_name + '", "format": "json"}'
            result = dr.client.mon_command(cmd,result)
            if result[0] == 0:
                return json.loads(result[1])
            else:
                return False

cmd_ = cmd_manager()
pool_name =  cmd_.get_large_omap_obj_pool_name()
if pool_name:
    print "Large omap objects pool_name = {0}".format(pool_name)
    res =  cmd_.get_pg_list_by_pool(pool_name)
    for i in res:
        num_large_objs = i["stat_sum"]["num_large_omap_objects"]
        if num_large_objs != 0:
            print "pgid={0} OSDs={1} num_large_omap_objects={2}".format(i["pgid"], i["acting"], num_large_objs)
else:
    print "[Cool] Not find objects pool_name, as expected, so exit."
</code></pre>
<h1 id="wen-ti-jie-jue">问题解决</h1>
<p>客户的这个问题解决，归根结底是 RGW reshard 太小导致的（关闭了auto reshard功能），单个bucket中objects数量超过了20万(osd_deep_scrub_large_omap_object_key_threshold),放大这个告警阈值（ ceph daemon osd.* injectargs “–osd_deep_scrub_large_omap_object_key_threshold 300000”）虽然能解决客户问题，但客户坚持不修改，说是要遵守规则，不能惯着业务端的人，至此唯一的解决方法就是迁移走bucket中的一部分数据，然后执行deep scrub来解决了（放大shard能解决，但部分index无法落到SSD上，影响整体性能）。</p>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>python max 函数介绍</title>
    <url>/2022/08/22/python_max_function/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>max()函数用于获得给定的可迭代对象中的最大值。</p>
<p>key是max()函数的一个参数，它辅助max函数找到最大元素。当max() 函数中有 key 参数时，求的是 value 的最大值，当没有 key 参数时，求的是 key 的最大值。</p>
<p>key可以对要比较的对象进行一些处理，以达到对对象进行特定规则的比较。</p>
<p>要在比较之前修改对象，或基于特定的属性/索引进行比较，必须使用key参数。</p>
<p>语法如下：</p>
<pre><code class="language-shell">root@scaler80:~# python
Python 2.7.12 (default, Mar  1 2021, 11:38:31) 
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; help(max)
Help on built-in function max in module __builtin__:

max(...)
    max(iterable[, key=func]) -&gt; value
    max(a, b, c, ...[, key=func]) -&gt; value
    
    With a single iterable argument, return its largest item.
    With two or more arguments, return the largest argument.
(END)
</code></pre>
<h1 id="common-example">Common example</h1>
<p>获取list中最大值(元祖类似)</p>
<pre><code class="language-python">&gt;&gt;&gt; max([1,2,3,6,10,60])
60
</code></pre>
<p>获取字典中key的最大值</p>
<pre><code class="language-python">dict1 = {'a': '11', 'c': '22', 'b': '33'}
print(max(dict1))
print(max(dict1.keys()))
</code></pre>
<p>获取字典中最大value对应的key值</p>
<pre><code class="language-python">dict1 = {'a': '11', 'c': '22', 'b': '33'}
print(max(dict1, key=dict1.get))
print(max(dict1, key=lambda x: dict1[x]))
</code></pre>
<p>获取字典中最大value的值</p>
<pre><code class="language-python">dict1 = {'a': '11', 'c': '22', 'b': '33'}
print(max(dict1.values()))
</code></pre>
<p>获取句子中的最长单词</p>
<pre><code class="language-python">str3 = "Life is short , I use python"
print(str3.split())
print(max(str3.split(), key=len))
</code></pre>
<p>获取list中的最大值</p>
<pre><code class="language-python">list1 = ['11', 'zzz', '22', 'eee']
print(max(list1))
</code></pre>
<p>获取list中的最大数值</p>
<pre><code class="language-python">list2 = ['11', '3', '222', '67']
print(max(list2, key=lambda x: int(x)))
</code></pre>
<p>获取list中的绝对值最大的值</p>
<pre><code class="language-python">list3 = ['11', '-399', '222', '67']
print(max(list2, key=lambda x: abs(int(x))))
</code></pre>
<p>获取元组list中指定索引的最大值</p>
<pre><code class="language-python">list4 = [(1, 'a'), (3, 'c'), (4, 'e'), (-1, 'z')]
print(max(list4, key=lambda x: x[1]))
</code></pre>
<h1 id="other-code-example">Other Code example</h1>
<pre><code class="language-python">#!/usr/bin/env python
#-*-coding:UTF-8 -*-

import os
import sys
import glob


def check_path_exist_or_not(path):
    """
    Check the path exist or not, if not exist, exit
    :param path, string, a folder path
    """
    if not os.path.exists(path):
        print('[ERROR]  Has no path : ({}), exit!!!'.format(path))
        sys.exit(1)


def get_latest_file(path, file_prefix_suffix):
    """
    Get the latest file from mtime
    If match, return a list of file full path; else return []
    :param path, string, which folde's file to get the latest file
    :param file_prefix_suffix string, file's name or prefix or suffix, such as *.iso, or 20230819*
    """
    check_path_exist_or_not(path)

    search_path = path + os.sep + file_prefix_suffix
    list_of_files = glob.glob(search_path)

    return max(list_of_files, key=os.path.getmtime)


def get_latest_folder(path):
    """
        Get the latest file from mtime
        If match, return a list of file full path; else return []
        args:
            - path  Which folde's file to get the latest file
    """
    check_path_exist_or_not(path)

    all_subdirs = [path + os.sep + d for d in os.listdir(path) if os.path.isdir(path + os.sep + d)]
    if len(all_subdirs):
        latest_subdir = max(all_subdirs, key=os.path.getmtime)
        return latest_subdir

if __name_ == '__main__':
    path = "/home/btadmin/image"
    print get_latest_folder(path)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python any() 与 all() 函数介绍</title>
    <url>/2022/08/16/python_all_any/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近碰到python的一个知识点盲区（any 与 all 函数相关），基础知识没有扎实，这里记录一下python的any 与 all 函数，填补一下部分盲区。</p>
<h1 id="jian-dan-li-jie">简单理解</h1>
<p>all() 函数： 全部为真，一假为假</p>
<p>any() 函数：一真为真，全假为假</p>
<h1 id="for-xun-huan-de-any-han-shu">for循环的any()函数</h1>
<p>使用生成器表达式动态地创建一个迭代，并将其传递到 any() 函数中。这可以称为 “带有for循环的any()函数”。</p>
<pre><code class="language-python">&gt;&gt;&gt; print(any(x**2 == 16 for x in range(10)))
True
&gt;&gt;&gt;
</code></pre>
<p>上面举例代码使用的条件是x**2==16，它只对x=4有效。</p>
<p>当通过使用range()函数将这个表达式应用于从0到9（包括）的所有x值时，它大多返回False。由于短路，any()函数在评估第五个元素x=4后返回True。</p>
<h1 id="all-han-shu">all() 函数</h1>
<h2 id="miao-shu">描述</h2>
<p>all() 函数用于判断给定的可迭代参数iterable中的所有元素是否都为True，如果是则返回True，否则返回False。</p>
<p>元素除了0，空，None，False外，都算True。</p>
<h2 id="yu-fa">语法</h2>
<pre><code class="language-python">all(iterable)
</code></pre>
<h2 id="fan-hui-zhi">返回值</h2>
<p>如果iterable的所有元素不为 0, ‘’, False或者iterable为空，all(iterable) 返回True，否则返回False。</p>
<p><strong>注意：</strong></p>
<p>​    空元组，空列表返回True，这里需要特别注意。</p>
<h2 id="shi-li">示例</h2>
<pre><code class="language-python">&gt;&gt;&gt; all(['a', 'b', 'c'])   # 列表list，元素都不为空或0
True
&gt;&gt;&gt; all(['a', 'b', ''])    # 列表list，存在一个为空的元素
False
&gt;&gt;&gt; all([0,1,2,3])         # 列表list，存在一个为0的元素
False
&gt;&gt;&gt; all(('a', 'b', ''))    # 元组tuple，存在一个为空的元素
False
&gt;&gt;&gt; all(('a', 'b', 'c'))   # 元组tuple，元素不存在为空或0的元素
True
&gt;&gt;&gt; all((0,1,2,3))         # 元组tuple，元素存在一个为0的元素
False
&gt;&gt;&gt; all([])                # 空列表list
True
&gt;&gt;&gt; all(())                # 空元组tuple
True
&gt;&gt;&gt;
</code></pre>
<h1 id="any-han-shu">any() 函数</h1>
<h2 id="miao-shu-1">描述</h2>
<p>any() 函数用于判断给定的可迭代参数iterable是否全部为false，则返回False；如果有一个为True，则返回True。</p>
<h2 id="yu-fa-1">语法</h2>
<pre><code class="language-python">any(iterable)
</code></pre>
<h2 id="fan-hui-zhi-1">返回值</h2>
<p>如果都为空，0， false，则返回False；如果不都为空，0，False，则返回True。</p>
<h2 id="shi-li-1">示例</h2>
<pre><code class="language-python">&gt;&gt;&gt; any((['a', 'b', 'c']))     # 列表list，元素都不为空或0
True
&gt;&gt;&gt; any((['a', 'b', '']))      # 列表list，存在一个为空的元素
True
&gt;&gt;&gt; any([0, '', False])        # 列表list，全部为0， ''， False
False
&gt;&gt;&gt; any((('a', 'b', 'c')))     # 元组tuple，元素都不为空或0
True
&gt;&gt;&gt; any((('a', 'b', '')))      # 元组tuple，存在一个为空的元素
True
&gt;&gt;&gt; any((0, '', False))        # 元组tuple，全部为0， ''， False
False
&gt;&gt;&gt; any([])                    # 空列表list 
False
&gt;&gt;&gt; any(())                    # 空元组tuple
False
&gt;&gt;&gt;
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Bash中的here document</title>
    <url>/2022/09/02/bash_shell_here_document/</url>
    <content><![CDATA[<h1 id="yin-yan">引言</h1>
<p>bash经常有这种需求，需要增加多行文字到某文件。当然可以采用如下的命令去做：</p>
<pre><code class="language-shell">    echo "This is line 1 " &gt;&gt;dest.conf
    echo "This is line 2 " &gt;&gt;dest.conf
    echo "This is line 3 " &gt;&gt;dest.conf
</code></pre>
<p>这样当然是可以的，但是显得很low，尤其是加入一段code 进某文件的时候，看起来特别扎眼。</p>
<p>here文档就是解决这个问题的。一直用，也没有理解，导致经常忘，这次将原理补上，很好的理解才能灵活的运用</p>
<h1 id="here-docement">Here Docement</h1>
<p>Here 文档，又称为heredoc，hereis，维基百科的介绍在此，<a href="https://zh.wikipedia.org/wiki/Here%E6%96%87%E6%A1%A3">点击跳转</a>。</p>
<p>简单地说，<code>here document</code>用于定义一个有复杂格式的字符串。如果你的字符串是有格式的，比如说有换行，有缩进，这时候，就是<code>here document</code>发挥作用了。<br>
here文档最通用的语法是&lt;&lt;紧跟一个标识符，从下一行开始是想要引用的文字，然后再在单独的一行用相同的标识符关闭</p>
<p>对于上面的需求，就可以简单地这样是做：</p>
<pre><code class="language-shell">    cat &gt;&gt;dest.conf &lt;&lt; EOF
    This is line 1
    This is line 3
    This is line 3
    EOF
</code></pre>
<p>下面看下实际情况：</p>
<pre><code class="language-shell">    root@node-191:/tmp# cat  &gt;&gt;dest.conf  &lt;&lt; EOF
    &gt; This is line 1 
    &gt; This is line 2
    &gt; This is line 3
    &gt; EOF
    root@node-191:/tmp# cat dest.conf 
    This is line 1
    This is line 2
    This is line 3
</code></pre>
<p>&lt;&lt; EOF 可以看作是起始最末尾的EOF可以看作是字符串结束，两者之间的内容，要原封不动地写入文件，换行缩进都要保持。</p>
<h1 id="ying-yong-chang-jing">应用场景</h1>
<p>对于没有格式要求的场景，echo也可以，但是对于代码这种有格式要求的，在shell脚本中echo就特别不合时宜。看如下shell脚本的片段，即完成了任务，有没有破坏代码的结构。</p>
<pre><code class="language-shell">    cat &gt;&gt; /etc/default/functions  &lt;&lt;EOF
    ctdb_check_counter_limit () {
        _ctdb_counter_common
        _limit="${1:-${service_fail_limit}}"
        _quiet="$2"
        
        # unary counting!
        _size=$(stat -c "%s" "$_counter_file" 2&gt;/dev/null || echo 0)
        if [ $_size -ge $_limit ] ; then
            echo "ERROR: more than $_limit consecutive failures for $service_name, marking cluster unhealthy"
            exit 1
        elif [ $_size -gt 0 -a -z "$_quiet" ] ; then
            echo "WARNING: less than $_limit consecutive failures ($_size) for $service_name, not unhealthy yet"
        fi
    }
    EOF
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
        <tag>here document</tag>
      </tags>
  </entry>
  <entry>
    <title>移除pool时提示&#39;must unset nodelete flag&#39;</title>
    <url>/2022/08/25/remove_pool_raise_error/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>UI移除pool时没有发生报错，执行ceph df时却发现有一个pool残留，没有被清理掉，但UI上已经不显示这个pool了。尝试手工删除之，发生错误，如下文所述。</p>
<h1 id="xian-xiang">现象</h1>
<pre><code class="language-shell">[root@node224 ~]# ceph df
GLOBAL:
    SIZE        AVAIL       RAW USED     %RAW USED 
    7.72TiB     7.39TiB       343GiB          4.34 
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS 
    .rgw.root                     1      1.09KiB         0       2.55TiB           4 
    default.rgw.control           2           0B         0       2.51TiB           8 
    default.rgw.meta              3      3.30KiB         0       2.22TiB          19 
    default.rgw.log               4           0B         0       2.58TiB         192 
    .ezs3                         5      4.52KiB         0       2.80TiB           2 
    data                          6           0B         0       2.54TiB           0 
    default.rgw.buckets.data      7       166GiB      5.84       2.61TiB     1068754 
    .ezs3.central.log             8       765KiB         0       2.69TiB         296 
    .ezs3.statistic               9      15.4MiB         0       2.91TiB         168 
    metadata                      10     12.1MiB         0       3.46TiB          26 
    default.rgw.buckets.index     11          0B         0       2.80TiB         512 
    rbd                           12         19B         0       2.58TiB           3 
    pool-vs0fs1-data              44          0B         0       3.44TiB           0 
[root@node224 ~]# ceph osd pool rm pool-vs0fs1-data pool-vs0fs1-data --yes-i-really-really-mean-it
Error EPERM: pool deletion is disabled; you must first set the mon_allow_pool_delete config option to true before you can destroy a pool
[root@node224 ~]# 
</code></pre>
<p>修改参数后：</p>
<pre><code class="language-shell">[root@node224 ~]# ceph tell mon.* injectargs '--mon_allow_pool_delete true'
Error EINVAL: injectargs: failed to parse arguments: true
mon_allow_pool_delete = 'true' (not observed, change may require restart) 
mon.zjohe: injectargs: failed to parse arguments: true
mon_allow_pool_delete = 'true' (not observed, change may require restart) 
Error EINVAL: injectargs: failed to parse arguments: true
mon_allow_pool_delete = 'true' (not observed, change may require restart) 
mon.uzhal: injectargs: failed to parse arguments: true
mon_allow_pool_delete = 'true' (not observed, change may require restart) 
Error EINVAL: injectargs: failed to parse arguments: true
mon_allow_pool_delete = 'true' (not observed, change may require restart) 
mon.emrqu: injectargs: failed to parse arguments: true
mon_allow_pool_delete = 'true' (not observed, change may require restart) 
[root@node224 ~]# 
[root@node224 ~]# 
[root@node224 ~]# 
[root@node224 ~]# ceph osd pool rm pool-vs0fs1-data pool-vs0fs1-data --yes-i-really-really-mean-it
Error EPERM: pool deletion is disabled; you must unset nodelete flag for the pool first
[root@node224 ~]# 
</code></pre>
<p>解决方法：</p>
<pre><code class="language-shell">[root@node224 ~]# ceph osd pool set pool-vs0fs1-data nodelete false
set pool 44 nodelete to false
[root@node224 ~]# ceph osd pool rm pool-vs0fs1-data pool-vs0fs1-data --yes-i-really-really-mean-it
pool 'pool-vs0fs1-data' removed
[root@node224 ~]# 
</code></pre>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows下python fnctl</title>
    <url>/2022/10/03/windows_python_fnctl/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>fcntl函数是linux下的一个文件锁函数，用以加密文件，给文件上锁，防止文件同时被多个进程操作。但是在windows下执行时发现并没有这个函数，不支持，所以就去找了各种方法来代替。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<p>有位网友，借助 pywin32 来解决这个问题， 参考链接：<a href="https://www.jianshu.com/p/4a0fa333c562">https://www.jianshu.com/p/4a0fa333c562</a></p>
<p>本文介绍另外一种方法，直接将linux下fnctl.py文件，放在python安装路径下的lib目录下，如我的环境： C:\Python27\Lib\ 下。</p>
<h1 id="fnctl-py-wen-jian-nei-rong">fnctl.py文件内容</h1>
<pre><code class="language-python">F_GETFD = 0
F_SETFD = 0
FD_CLOEXEC = 0
LOCK_EX = 1
LOCK_UN = 0

def fcntl(fd, op, arg=0):
    return 0


def ioctl(fd, op, arg=0, mutable_flag=True):
    if mutable_flag:
        return 0
    else:
        return ""


def flock(fd, op):
    return


def lockf(fd, operation, length=0, start=0, whence=0):
    return
</code></pre>
<p>如上文件内容做记录保留下来，防止哪天OS损坏，有地方可以找到。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>systemtap部署与实战</title>
    <url>/2022/10/26/systemtap/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍如何借助systemtap给磁盘注入时延，验证产品慢盘检测功能。</p>
<h1 id="an-zhuang-yu-bu-shu">安装与部署</h1>
<h2 id="an-zhuang-linux-debug-symbols">安装Linux debug symbols</h2>
<p>挂载安装Virtual Scaler ISO到机器上，然后从后台运行以下命令：</p>
<pre><code class="language-shell">mkdir /mnt/cdrom
mount /dev/cdrom /mnt/cdrom
cd /mnt/cdrom/pools/extra
dpkg -i linux-image-4.14.148-dbg_4.14.148-202009221212.git33a12c4_amd64.deb
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>此处.deb 请替换成ISO中相应版本的文件，类似linux-image-4.14.148-dbg_***.deb。</p>
</li>
</ul>
<h2 id="qi-ta-package-de-an-zhuang">其他package的安装</h2>
<p>直接运行安装包下的install_systemtap.sh:</p>
<pre><code class="language-shell">chmod a+x install_systemtap.sh;
./ install_systemtap.sh
</code></pre>
<p>或</p>
<pre><code class="language-shell">dpkg -i zlib1g-dev_1%3a1.2.8.dfsg-2ubuntu4.3_amd64.deb;
dpkg -i liblzma-dev_5.1.1alpha+20120614-2ubuntu2_amd64.deb;
dpkg -i libelf1_0.170-0.4ubuntu0.1_amd64.deb;
dpkg -i libelf-dev_0.170-0.4ubuntu0.1_amd64.deb;
dpkg -i libdw1_0.170-0.4ubuntu0.1_amd64.deb;
dpkg -i libdw-dev_0.170-0.4ubuntu0.1_amd64.deb;
dpkg -i libasm1_0.170-0.4ubuntu0.1_amd64.deb;
dpkg -i libasm-dev_0.170-0.4ubuntu0.1_amd64.deb;
dpkg -i libasprintf-dev_0.19.7-2ubuntu3.1_amd64.deb;
dpkg -i elfutils_0.170-0.4ubuntu0.1_amd64.deb;
</code></pre>
<p>Centos:</p>
<pre><code class="language-shell">yum install elfutils-devel
https://sourceware.org/systemtap/wiki/SystemTapOnCentOS
</code></pre>
<p>解压systemtap并编译安装</p>
<pre><code class="language-shell">tar zxvf systemtap-4.3.tar.gz
cd systemtap-4.3/
./configure --prefix=/usr/;
make &amp;&amp; make install
</code></pre>
<p>测试systemtap是否安装成功</p>
<p>如果安装成功，运行以下命令稍候会打印hello world:</p>
<pre><code class="language-shell">stap -e 'probe kernel.function("sys_open") {log("hello world") exit()}'

</code></pre>
<h1 id="shu-chu-dang-qian-du-xie-ci-pan-de-jin-cheng">输出当前读写磁盘的进程</h1>
<p>创建disk.stp文件，输入以下内容：</p>
<pre><code class="language-shell">#!/usr/bin/env stap 
#
# Copyright (C) 2007 Oracle Corp.
#
# Get the status of reading/writing disk every 5 seconds,
# output top ten entries 
#
# This is free software,GNU General Public License (GPL);
# either version 2, or (at your option) any later version.
#
# Usage:
#  ./disktop.stp
#

global io_stat,device
global read_bytes,write_bytes

probe vfs.read.return {
  if (returnval()&gt;0) {
    if (devname!="N/A") {/*skip read from cache*/
      io_stat[pid(),execname(),uid(),ppid(),"R"] += returnval()
      device[pid(),execname(),uid(),ppid(),"R"] = devname
      read_bytes += returnval()
    }
  }
}

probe vfs.write.return {
  if (returnval()&gt;0) {
    if (devname!="N/A") { /*skip update cache*/
      io_stat[pid(),execname(),uid(),ppid(),"W"] += returnval()
      device[pid(),execname(),uid(),ppid(),"W"] = devname
      write_bytes += returnval()
    }
  }
}

probe timer.ms(5000) {
  /* skip non-read/write disk */
  if (read_bytes+write_bytes) {

    printf("\n%-25s, %-8s%4dKb/sec, %-7s%6dKb, %-7s%6dKb\n\n",
           ctime(gettimeofday_s()),
           "Average:", ((read_bytes+write_bytes)/1024)/5,
           "Read:",read_bytes/1024,
           "Write:",write_bytes/1024)

    /* print header */
    printf("%8s %8s %8s %25s %8s %4s %12s\n",
           "UID","PID","PPID","CMD","DEVICE","T","BYTES")
  }
  /* print top ten I/O */
  foreach ([process,cmd,userid,parent,action] in io_stat- limit 10)
    printf("%8d %8d %8d %25s %8s %4s %12d\n",
           userid,process,parent,cmd,
           device[process,cmd,userid,parent,action],
           action,io_stat[process,cmd,userid,parent,action])

  /* clear data */
  delete io_stat
  delete device
  read_bytes = 0
  write_bytes = 0  
}

probe end{
  delete io_stat
  delete device
  delete read_bytes
  delete write_bytes
}

</code></pre>
<p>给该文件运行的权限并执行：</p>
<pre><code class="language-shell">chmod a+x disk.stp
./disk.stp

</code></pre>
<p>输出如下结果：</p>
<img class="shadow" src="/img/in-post/disk_stp.png" width="1200">
<h1 id="mo-ni-ci-pan-yan-chi">模拟磁盘延迟</h1>
<p>推荐将RAID设置成write back模式。</p>
<p>使用oceanfile以512k的bs来写数据: <code>oceanfile -d . -p 40 -a 8,20,100,100 -s 10M -b 512K  -i 1</code></p>
<p>创建以下systemtap文件inject_ka.stp, 并输入以下内容：</p>
<pre><code class="language-shell">global cnt = 0 ;
probe module("sd_mod").function("sd_init_command") !,
      kernel.function("sd_init_command")
{
    device = kernel_string(@choose_defined($cmd, $SCpnt)-&gt;request-&gt;rq_disk-&gt;disk_name)
    if(device == @1)
    {
        mdelay($2);
        if(cnt % 100 == 0)
        { 
             printf("%s inject delay %4d times %7d\n", device,$2, cnt)
        }
        cnt++ ;
    }
    #printf("device %s sd_init_command\n", device);
}

 


probe begin{
  println("inject_scsi_delay module begin");
}

</code></pre>
<p>以如下格式运行：</p>
<pre><code class="language-shell">#stap -g -DMAXSKIPPED=99999999 inject_ka.stp sdb 10
</code></pre>
<p>或</p>
<pre><code class="language-shell">#stap -p4 -DMAXSKIPPED=99999999 -m ik -g inject_ka.stp sdb 10
#staprun ik.ko
</code></pre>
<p>运行之后，sdc盘的svctm就会在当前数值基本上增加10.</p>
<img class="shadow" src="/img/in-post/sdc_svctm.png" width="1200">
<p>参考：</p>
<p><a href="https://sourceware.org/systemtap/examples/io/iostat-scsi.stp">https://sourceware.org/systemtap/examples/io/iostat-scsi.stp</a><br>
<a href="https://sourceware.org/systemtap/examples/io/iostat-scsi.txt">https://sourceware.org/systemtap/examples/io/iostat-scsi.txt</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>使用rsyslog 配置netconsole记录dmesg</title>
    <url>/2022/10/22/rsyslog_netconsole/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>ENV Info：</p>
<pre><code class="language-shell">Server ：127.71.57.11
Log Reciver： 127.71.57.13
</code></pre>
<p>OS Info：</p>
<pre><code class="language-shell">root@pytest-11:~# hostnamectl 
   Static hostname: pytest-11
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 61c34f4154784f019254f8033d92d9cf
           Boot ID: 4be228ed0f824e40bb0a2155928f4c60
    Virtualization: qemu
  Operating System: Ubuntu 16.04.7 LTS
            Kernel: Linux 4.14.148-202207281639.git553ed7f
      Architecture: x86-64
root@pytest-11:~#
</code></pre>
<h1 id="practices">Practices</h1>
<h2 id="shell-script">Shell script</h2>
<pre><code class="language-shell">root@pytest-11:~# cat net_console.sh 
#!/bin/bash
senddev=bond0
receive_ip=127.71.57.13
receive_port=6666
mac=
gateway=$(ip -4 -o route get $receip|/usr/bin/cut -f 3 -d ' ')
if echo $gateway|/bin/grep -q '^[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+$'
then
    mac=$(ip -4 neigh show $gateway|/usr/bin/cut -f 5 -d ' ')
else
    /bin/ping -c 2 $receip &gt; /dev/null
    mac=$(ip -4 neigh show $receip|/usr/bin/cut -f 5 -d ' ')
fi
if [[ x$mac = x"" ]]; then
    exit 0
fi
echo 7 &gt; /proc/sys/kernel/printk
/sbin/modprobe -r netconsole
/sbin/modprobe netconsole netconsole=@/$senddev,$receive_port@$receive_ip/$mac
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>Description</p>
<ul class="lvl-2">
<li class="lvl-6">Script run in Server.</li>
</ul>
</li>
</ul>
<h2 id="configuration-of-the-log-receiver">Configuration of the Log Receiver</h2>
<p>If not config this, log will record in kern.log by efault.</p>
<h3 id="create-a-xxx-conf-file">Create a ‘xxx.conf’ file</h3>
<pre><code class="language-shell">root@pytest-83-13:/etc/rsyslog.d# cat net-console.conf 
$ModLoad imudp
$UDPServerRun 6666
$template NetconleFile,"/var/log/%fromhost-ip%.log"
if $fromhost-ip startswith '172.17.' then ?NetconleFile
&amp; ~
root@pytest-83-13:/etc/rsyslog.d# 
</code></pre>
<h3 id="restart-rsyslog-service">Restart rsyslog service</h3>
<p><code>systemctl restart rsyslog</code></p>
<h1 id="how-to-use">How to use</h1>
<h2 id="add-executable-permissions">Add Executable Permissions</h2>
<p><code>chmod +x net_console.sh</code></p>
<h2 id="write-to-boot-up">Write to boot-up</h2>
<p><code>echo /root/net_console.sh &gt;&gt; /etc/rc.local</code></p>
<h2 id="run-script-to-config-netconsole">Run script to config netconsole</h2>
<p><code>bash net_console.sh</code></p>
<h2 id="check-dmesg">Check dmesg</h2>
<p><code>dmesg|grep console</code>, output like the fallowing:</p>
<pre><code class="language-shell">Jan  9 18:36:29 pytest-11 kernel: [ 2639.892808] console [netcon0] enabled
Jan  9 18:36:29 pytest-11 kernel: [ 2639.892872] netconsole: network logging started
Jan  9 18:36:30 pytest-11 kernel: [ 2641.324336] netpoll: netconsole: local port 6665
Jan  9 18:36:30 pytest-11 kernel: [ 2641.324388] netpoll: netconsole: local IPv4 address 127.71.57.11
Jan  9 18:36:30 pytest-11 kernel: [ 2641.324438] netpoll: netconsole: interface 'eth0'
Jan  9 18:36:30 pytest-11 kernel: [ 2641.324484] netpoll: netconsole: remote port 6666
Jan  9 18:36:30 pytest-11 kernel: [ 2641.324532] netpoll: netconsole: remote IPv4 address 127.71.57.13
Jan  9 18:36:30 pytest-11 kernel: [ 2641.324587] netpoll: netconsole: remote ethernet address ff:ff:ff:ff:ff:ff
Jan  9 18:36:30 pytest-11 kernel: [ 2641.324646] netpoll: netconsole: eth0 doesn't exist, aborting
Jan  9 18:38:13 pytest-11 kernel: [ 2743.844684] netpoll: netconsole: local port 6665
Jan  9 18:38:13 pytest-11 kernel: [ 2743.844735] netpoll: netconsole: local IPv4 address 127.71.57.11
Jan  9 18:38:13 pytest-11 kernel: [ 2743.844777] netpoll: netconsole: interface 'eth0'
Jan  9 18:38:13 pytest-11 kernel: [ 2743.844811] netpoll: netconsole: remote port 6666
</code></pre>
<h2 id="check-if-the-receiving-end-has-received-log-messages">Check if the receiving end has received log messages</h2>
<pre><code class="language-shell">root@pytest-83-13:/var/log# cat /var/log/127.71.57.11.log 
Jan 10 10:47:17 pytest-11.local [56833.474232] memory_corrupted,adsjkfjlasjdkf
root@pytest-83-13:/var/log# 
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>Description</p>
<ul class="lvl-2">
<li class="lvl-6">As above log is simulated by injecting messages to Kernel with the help of syslog-tool tool (self-developed).</li>
<li class="lvl-6">Of course, it can be simulated by restarting the Server side (too heavy action), or simulating the NIC down/up. e.g:</li>
</ul>
</li>
</ul>
<pre><code class="language-shell">Jan 10 10:54:17 pytest-11.local [57253.352107] bond1: link status definitely down for interface ens19, disabling it
Jan 10 10:54:17 pytest-11.local [57253.352950] bond1: now running without any active interface!
Jan 10 10:54:30 pytest-11.local [57266.124671] 8021q: adding VLAN 0 to HW filter on device ens19
Jan 10 10:54:30 pytest-11.local [57266.143120] bond1: link status definitely up for interface ens19, 0 Mbps full duplex
Jan 10 10:54:30 pytest-11.local [57266.143728] bond1: making interface ens19 the new active one
Jan 10 10:54:30 pytest-11.local [57266.145527] bond1: first active interface up!
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>netconsole</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>netconsole</tag>
      </tags>
  </entry>
  <entry>
    <title>部署k8s</title>
    <url>/2022/09/21/deploy_k8s/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>公司的Scaler产品有对接k8s，R&amp;D提供了一个CSI Driver包，部署在存储集群中各个节点上，发布k8s相关命令，创建 ceph 集群 rbd 或 NAS目录，并使用rbd或NAS Folder。</p>
<p>本文概述一下k8s的安装与部署。</p>
<h1 id="shi-jian">实践</h1>
<p>说明：</p>
<p>事先准备好2台安装了CentOS的VM（16G Memory， 4*4 cores VCPU, 64G OS Disk），并配置好静态IP与yum源。</p>
<h2 id="k-8-s-ji-qun-da-jian">K8S集群搭建</h2>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>从1.1到1.6，所有机器都执行</p>
</li>
<li class="lvl-2">
<p>1.7和1.8只在主节点上执行</p>
</li>
<li class="lvl-2">
<p>1.9的kube join只在从节点上执行(测试kubectl get nodes在主节点上执行，因为从节点没有.kube/，无法通过kubectl操作k8s集群)</p>
</li>
<li class="lvl-2">
<p>1.10集群新建pod测试，在主节点上执行，因为从节点没有.kube/，无法通过kubectl操作k8s集群</p>
</li>
</ul>
<h3 id="1-1-geng-xin-yum">1.1 更新yum</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>3台机器都需要执行</p>
</li>
</ul>
<pre><code class="language-shell">yum -y update
yum install -y conntrack ipvsadm ipset jq sysstat curl iptables libseccomp
</code></pre>
<h3 id="1-2-an-zhuang-docker">1.2 安装Docker</h3>
<p>在每一台机器上都安装好Docker，版本为18.09.0</p>
<p>01 安装必要的依赖</p>
<pre><code class="language-shell">sudo yum install -y yum-utils \
device-mapper-persistent-data \
lvm2
</code></pre>
<p>02 设置docker仓库</p>
<pre><code class="language-shell">sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre>
<p>然后设置一下阿里云镜像加速器</p>
<pre><code class="language-shell">sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'
{
"registry-mirrors": ["https://orptaaqe.mirror.aliyuncs.com"]
}
EOF
sudo systemctl daemon-reload
</code></pre>
<p>03 安装docker</p>
<pre><code class="language-shell">yum install -y docker-ce-18.09.0 docker-ce-cli-18.09.0 containerd.io
</code></pre>
<p>04 启动docker</p>
<pre><code class="language-shell">sudo systemctl start docker &amp;&amp; sudo systemctl enable docker
</code></pre>
<p>05 检查docker是否安装并启动好了</p>
<pre><code class="language-shell">ps -ef|grep docker
</code></pre>
<h3 id="1-3-xiu-gai-hosts-wen-jian">1.3 修改hosts文件</h3>
<p>01 机器192.168.100.150执行两句</p>
<pre><code class="language-shell">sudo hostnamectl set-hostname m
</code></pre>
<pre><code class="language-shell">vi /etc/hosts
192.168.100.150 m
192.168.100.151 w1
</code></pre>
<p>02 机器192.168.100.151执行两句</p>
<pre><code class="language-shell">sudo hostnamectl set-hostname w1
</code></pre>
<pre><code class="language-shell">vi /etc/hosts
192.168.100.150 m
192.168.100.151 w1
</code></pre>
<p>03 每天机器上都要测试</p>
<pre><code class="language-shell">ping m  
ping w1
</code></pre>
<p>每个步骤配置完成之后，都要局部测试，这样才不会出问题</p>
<h3 id="1-4-xi-tong-ji-chu-qian-ti-pei-zhi">1.4 系统基础前提配置</h3>
<p>每个机器上都要执行（机器192.168.100.150 和 机器192.168.100.151），如下：</p>
<h4 id="1-guan-bi-fang-huo-qiang">(1)关闭防火墙</h4>
<pre><code class="language-shell">systemctl stop firewalld &amp;&amp; systemctl disable firewalld
</code></pre>
<h4 id="2-guan-bi-selinux">(2)关闭selinux</h4>
<pre><code class="language-shell">setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
</code></pre>
<h4 id="3-guan-bi-swap">(3)关闭swap</h4>
<pre><code class="language-shell">swapoff -a
sed -i '/swap/s/^\(.*\)$/#\1/g' /etc/fstab
</code></pre>
<h4 id="4-pei-zhi-iptables-de-accept-gui-ze">(4)配置iptables的ACCEPT规则</h4>
<pre><code class="language-shell">iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -F -t nat &amp;&amp; iptables -X -t nat &amp;&amp; iptables -P FORWARD ACCEPT
</code></pre>
<h4 id="5-she-zhi-xi-tong-can-shu">(5)设置系统参数</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

sysctl --system
</code></pre>
<h3 id="1-5-an-zhuang-kubeadm-kubelet-and-kubectl">1.5 安装 kubeadm, kubelet and kubectl</h3>
<p>每个机器上都要执行（机器192.168.100.150 和 机器192.168.100.151），如下：</p>
<h4 id="1-pei-zhi-yum-yuan">(1)配置yum源</h4>
<pre><code class="language-shell">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
</code></pre>
<h4 id="2-an-zhuang-kubeadm-amp-kubelet-amp-kubectl">(2)安装kubeadm&amp;kubelet&amp;kubectl</h4>
<pre><code class="language-shell">yum install -y kubectl-1.14.0-0
yum install -y kubelet-1.14.0-0
yum install -y kubeadm-1.14.0-0
</code></pre>
<p>这三个东西一定要保证版本统一，一定要安装这个安装顺序来完成</p>
<p>因为kubeadm依赖kubelet，如果先安装kubeadm，则kubelet的1.23版本就会被安装上去，然后再执行 <code>yum install -y kubelet-1.14.0-0</code> 会安装不上去，然后版本不统一，主节点初始化init报错</p>
<img class="shadow" src="/img/in-post/k8s-1.png" width="1200">
<p>如下才是正确的:</p>
<img class="shadow" src="/img/in-post/k8s-2.png" width="1200">
<p>及时测试：</p>
<pre><code class="language-shell">kubectl version
kubelet --version
kubeadm version
</code></pre>
<p>版本必须都是 1.4.0，如果版本错了要删除</p>
<pre><code class="language-shell">yum -y remove kubelet
yum -y remove kubectl 
yum -y remove kubeadm
</code></pre>
<h4 id="3-docker-he-k-8-s-she-zhi-tong-yi-ge-cgroup">(3) docker和k8s设置同一个cgroup</h4>
<pre><code class="language-shell"># 编辑docker的daemon.json文件,每个节点都要执行
vi /etc/docker/daemon.json
    "exec-opts": ["native.cgroupdriver=systemd"],
    
systemctl restart docker
    
# kubelet，这边如果发现输出directory not exist，也说明是没问题的，大家继续往下进行即可
sed -i "s/cgroup-driver=systemd/cgroup-driver=cgroupfs/g" /etc/systemd/system/kubelet.service.d/10-kubeadm.conf

systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre>
<h3 id="1-6-pei-zhi-guo-nei-jing-xiang">1.6 配置国内镜像</h3>
<h4 id="1-chuang-jian-kubeadm-sh-jiao-ben-yong-yu-la-qu-jing-xiang-da-tag-shan-chu-yuan-you-jing-xiang">(1) 创建kubeadm.sh脚本，用于拉取镜像/打tag/删除原有镜像</h4>
<pre><code class="language-shell">#!/bin/bash

set -e

KUBE_VERSION=v1.14.0
KUBE_PAUSE_VERSION=3.1
ETCD_VERSION=3.3.10
CORE_DNS_VERSION=1.3.1

GCR_URL=k8s.gcr.io
ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers

images=(kube-proxy:${KUBE_VERSION}
kube-scheduler:${KUBE_VERSION}
kube-controller-manager:${KUBE_VERSION}
kube-apiserver:${KUBE_VERSION}
pause:${KUBE_PAUSE_VERSION}
etcd:${ETCD_VERSION}
coredns:${CORE_DNS_VERSION})

for imageName in ${images[@]} ; do
  docker pull $ALIYUN_URL/$imageName
  docker tag  $ALIYUN_URL/$imageName $GCR_URL/$imageName
  docker rmi $ALIYUN_URL/$imageName
done
</code></pre>
<h4 id="2-yun-xing-jiao-ben-he-cha-kan-jing-xiang">(2) 运行脚本和查看镜像</h4>
<p>运行脚本</p>
<pre><code class="language-shell">sh ./kubeadm.sh
</code></pre>
<p>查看镜像</p>
<pre><code class="language-shell">docker images
</code></pre>
<p>至此，上面的1.1到1.6是每个节点都要执行的，就是机器 192.168.100.150 和 192.168.100.151 都要同时执行的，在Xshell里面，通过</p>
<h3 id="1-7-kube-init-chu-shi-hua-master">1.7 kube init初始化master</h3>
<p>到此为止，两个机器 192.168.100.150 和 192.168.100.151 还需要没有主次之分，还没有说哪个是k8s的主节点，现在 1.7 这个步骤只需要在 192.168.100.150 节点执行，让这个机器成为k8s主节点。</p>
<h4 id="1-chu-shi-hua-master-jie-dian">(1)初始化master节点</h4>
<pre><code class="language-shell">kubeadm init --kubernetes-version=1.14.0 --apiserver-advertise-address=192.168.100.150 --pod-network-cidr=10.244.0.0/16
</code></pre>
<p>在 192.168.100.150 机器上执行，然后这个 --apiserver-advertise-address=192.168.100.150 这样写会得到一句</p>
<pre><code class="language-shell">kubeadm join 192.168.100.150:6443 --token 7oahxf.bk0rywevgu0xjouy

–discovery-token-ca-cert-hash sha256:4f84a48cc41343848d0b2f807c38937bc96d3d43e821f06b0c143a5282a38204
</code></pre>
<p>一定要复制粘贴出来，下一个步骤在 192.168.100.151 机器上执行这句。</p>
<p>初始化完成执行后，继续只在 主节点 上执行，这三句，如下：</p>
<pre><code class="language-shell">mkdir -p $HOME/.kube
cd .kube/
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>注意:</p>
</li>
</ul>
<p>我们所说的只有主节点才能通过 kubectl 命令操作k8s集群是因为，只有主节点上才完成这三步操作，才有 .kube 目录，如果从节点上也完成了这三句，也有 .kube 目录，也是可以通过 kubectl 命令操作k8s集群的。</p>
<h4 id="2-ce-shi">(2) 测试</h4>
<p>验证pod和健康检查（这两句也是只在master节点上执行）</p>
<pre><code class="language-shell"># 验证pod
kubectl get pods -n kube-system
# 健康检查（不要怀疑，就是healthz）
curl -k https://localhost:6443/healthz
</code></pre>
<h3 id="1-8-bu-shu-calico-wang-luo-cha-jian">1.8 部署calico网络插件</h3>
<p>k8s中，网络插件是为了k8s集群内部通信，所以必须安装一个网络插件，有很多选择，这里选择calico，同样在master节点上操作</p>
<pre><code class="language-shell"># 在k8s中安装calico（这条命令很快的）
kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml

# 确认一下calico是否安装成功  -w可以实时变化（看到calico都好了表示网络插件好了）
kubectl get pods --all-namespaces -w
</code></pre>
<p>测试验证是否安装成功，这里的calico两个显示Running就表示安装成功了。</p>
<img class="shadow" src="/img/in-post/k8s-3.png" width="1200">
<p>从1.1到1.6，所有机器都执行，1.7和1.8只在主节点上执行，接下来的1.9的kube join只在从节点上执行(测试kubectl get nodes在主节点上执行，因为从节点没有.kube/，无法通过kubectl操作k8s集群)</p>
<h3 id="1-9-kube-join">1.9 kube join</h3>
<h4 id="1-zai-cong-jie-dian-shang-zhi-xing-kube-join-ming-ling">(1) 在从节点上执行kube join命令</h4>
<p>如下</p>
<pre><code class="language-shell">kubeadm join 192.168.100.150:6443 --token 7oahxf.bk0rywevgu0xjouy \
    --discovery-token-ca-cert-hash sha256:4f84a48cc41343848d0b2f807c38937bc96d3d43e821f06b0c143a5282a38204
</code></pre>
<p>记得保存初始化master节点的最后打印信息，注意这边大家要自己的，下面我的只是一个参考</p>
<h4 id="2-zai-master-jie-dian-shang-jian-cha-ji-qun-xin-xi">(2)在master节点上检查集群信息</h4>
<p>node的正常状态是ready,pod的正常状态是running</p>
<pre><code class="language-shell">kubectl get nodes
</code></pre>
<p>当每个节点都是Ready，表示完成。</p>
<h3 id="1-10-xin-jian-pod-ce-shi-zheng-ge-ji-qun">1.10 新建Pod测试整个集群</h3>
<h4 id="1-ding-yi-pod-yml-wen-jian-bi-ru-pod-nginx-rs-yaml">(1)定义pod.yml文件，比如pod_nginx_rs.yaml</h4>
<pre><code class="language-shell">cat &gt; pod_nginx_rs.yaml &lt;&lt;EOF
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx
  labels:
    tier: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      name: nginx
      labels:
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
EOF
</code></pre>
<h4 id="2-gen-ju-pod-nginx-rs-yml-wen-jian-chuang-jian-pod">(2)根据pod_nginx_rs.yml文件创建pod</h4>
<pre><code class="language-shell">kubectl apply -f pod_nginx_rs.yaml
</code></pre>
<h4 id="3-cha-kan-pod">(3)查看pod</h4>
<pre><code class="language-shell">kubectl get pods
kubectl get pods -o wide
kubectl describe pod nginx
</code></pre>
<h4 id="4-gan-shou-tong-guo-rs-jiang-pod-kuo-rong">(4)感受通过rs将pod扩容</h4>
<pre><code class="language-shell">kubectl scale rs nginx --replicas=5
kubectl get pods -o wide
</code></pre>
<h4 id="5-shan-chu-pod">(5)删除pod</h4>
<pre><code class="language-shell">kubectl delete -f pod_nginx_rs.yaml
</code></pre>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker介绍</title>
    <url>/2022/11/16/docker/</url>
    <content><![CDATA[<h1 id="yi-docker-shi-shi-yao">一、Docker是什么</h1>
<h2 id="1-jian-jie">1、简介</h2>
<p>Docker 是一个开源的<strong>应用容器引擎</strong>，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的Linux机器或Windows机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。</p>
<p>物理机必须要内核3.8以上才能支持docker</p>
<h2 id="2-te-dian">2、特点</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>服务彼此之间相互独立（服务之间的解耦）</p>
</li>
<li class="lvl-2">
<p>服务可以灵活迁移（Docker引擎 docker-ce）</p>
</li>
</ul>
<p><strong>耦合</strong>是指两个或两个以上的体系或两种运动形式间通过相互作用而彼此影响以至联合起来的现象。</p>
<p><strong>解耦</strong>就是用<a href="https://baike.baidu.com/item/%E6%95%B0%E5%AD%A6%E6%96%B9%E6%B3%95/1747958">数学方法</a>将两种运动分离开来处理问题，常用解耦方法就是忽略或简化对所研究问题影响较小的一种运动，只分析主要的运动。（便于管理，防止数据过多的积累在一个文件中）</p>
<h2 id="3-yu-xu-ni-ji-de-qu-bie">3、与虚拟机的区别</h2>
<p>虚拟机容量占用大，容器不需要装系统，占用容量小</p>
<p>虚拟机安全，容器不安全（共享内核资源），攻击一个内核，其他全部瘫痪，可隔开，做资源控制</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>虚拟机</th>
<th>容器</th>
</tr>
</thead>
<tbody>
<tr>
<td>隔离级别</td>
<td>操作系统级</td>
<td>进程级</td>
</tr>
<tr>
<td>系统策略</td>
<td>Hypervisor</td>
<td>CGroups</td>
</tr>
<tr>
<td>系统资源</td>
<td>5~15%</td>
<td>0~5%</td>
</tr>
<tr>
<td>启动时间</td>
<td>分钟级</td>
<td>秒级</td>
</tr>
<tr>
<td>镜像存储</td>
<td>GB-TB</td>
<td>KB-MB</td>
</tr>
<tr>
<td>群集规模</td>
<td>上百</td>
<td>上万</td>
</tr>
<tr>
<td>高可用策略</td>
<td>备份、容灾、迁移</td>
<td>弹性、负载、动态</td>
</tr>
</tbody>
</table>
<h1 id="er-docker-san-yao-su">二、Docker三要素</h1>
<p>●镜像：一个面向Docker容器引擎的只读模板</p>
<p>●容器：从镜像创建的运行实例</p>
<p>●仓库：集中保存镜像的地方；分公有和私有仓库</p>
<h1 id="san-docker-ji-chu-ming-ling">三、Docker基础命令</h1>
<h2 id="1-docker-rong-qi-he-ben-di-hu-chuan-wen-jian">1、docker容器和本地互传文件</h2>
<p><strong>本地向docker容器传送文件</strong></p>
<p>docker cp 本机保存文件的全路径 container_id:docker容器内的文件全路径</p>
<p>docker cp index.jsp 容器<a href="http://id/usr/local/tomcat/webapps/ROOT">id:/usr/local/tomcat/webapps/ROOT</a></p>
<p><strong>docker容器向本机传送文件</strong></p>
<p>docker cp container_id:docker容器内的文件全路径 本机保存文件的全路径</p>
<pre><code class="language-shell">docker cp [4a2f08d2c1f8:/data1/configure.txt](http://4a2f08d2c1f8/data1/configure.txt) E:\PHP\configure.txt
</code></pre>
<h2 id="2-jing-xiang-cao-zuo">2、镜像操作</h2>
<p>●查看docker版本：docker version</p>
<p>●搜索nginx镜像（公有仓库)：docker search nginx</p>
<p>●下载nginx镜像：docker pull nginx；下载后存放在/var/lib/docker</p>
<p>●查看镜像列表</p>
<p>docker images    #查看下载镜像信息列表      docker inspect nginx:latest    #获取镜像详细信息</p>
<p>展示信息说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>REPOSITORY：镜像所在的仓库名称</p>
</li>
<li class="lvl-2">
<p>TAG：镜像标签</p>
</li>
<li class="lvl-2">
<p>IMAGE ID：镜像ID</p>
</li>
<li class="lvl-2">
<p>CREATED：镜像的创建日期（不是获取该镜像的日期）</p>
</li>
<li class="lvl-2">
<p>SIZE：镜像大小  这些镜像都是存储在Docker宿主机的/var/lib/docker目录下</p>
</li>
</ul>
<p>●为镜像添加新标签</p>
<p><code>docker tag nginx:latest nginx:web</code></p>
<p>●两种方式删除镜像</p>
<p>注意：删除某一个镜像时，只要有容器在使用某一个镜像，必须先删除容器，才能删除镜像。</p>
<p>（1）删除单个镜像</p>
<p>​    docker rmi IMAGE_NAME_OR_ID</p>
<p>其中，<code>IMAGE_NAME_OR_ID</code>是要删除的镜像的名称或ID。例如，要删除名为<code>my_image</code>的镜像，可以运行以下命令：</p>
<p>​    docker rmi my_image</p>
<p>（2）删除镜像id</p>
<p>注意：只有当镜像id对应标签仅剩一个时，才能使用镜像id的方式进行删除；否则出现如下报错</p>
<p>或者也可以在最后加上-f选项，一次性删除【强制性删除】</p>
<p>docker rmi -f IMAGE_NAME_OR_ID      docker rmi -f my_image</p>
<p>（3）一次性删除所有镜像</p>
<p>​    docker rmi -f $(docker images -aq)<br>
请注意，删除所有镜像将不可逆转，并且将删除系统中所有镜像，包括中间镜像。</p>
<p>●保存导出镜像并命名为nginx，存到/opt目录下</p>
<pre><code class="language-shell">docker save -o /opt/nginx.tar nginx:latest
</code></pre>
<p>●载入镜像</p>
<p>docker load &lt; /opt/nginx<br>
docker load -i 镜像保存文件位置</p>
<h2 id="3-rong-qi-cao-zuo">3、容器操作</h2>
<p>●创建容器</p>
<pre><code class="language-shell">docker create -it nginx:latest /bin/bash
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>-i：让容器的标准输入保持打开</p>
</li>
<li class="lvl-2">
<p>-t：让Docker分配一个伪终端</p>
</li>
</ul>
<p>●查看容器运行状态</p>
<pre><code class="language-shell">docker ps -a     -a：列出所有的容器，包括未运行的容器

Created：已创建；   Up：运行中
</code></pre>
<p>●启动执行命令查看系统根目录</p>
<p>一般启动容器流程：</p>
<pre><code class="language-shell">（1）docker pull centos   --下载镜像

（2）docker create -it centos:latest /bin/bash

（3）docker start d4a99affa677
</code></pre>
<p>通过run命令启动：（先去查找现有的镜像中有没有，没有先下载，再启动）</p>
<pre><code class="language-shell">docker run centos:latest /usr/bin/bash -c ls /
</code></pre>
<p>执行完成会关闭，状态是Exited（容器可以做一次性的处理，处理完就释放资源，做到了最小成本控制）</p>
<p>容器持续在后台执行（通过执行死循环）</p>
<pre><code class="language-shell">docker run -d centos:latest /bin/bash -c "while true;do echo hello;done"
</code></pre>
<p>使用 <strong>docker logs 容器id</strong> 命令，可以查看容器内的标准输出</p>
<p>●终止容器运行</p>
<pre><code class="language-shell">docker stop 0401f589d5ed（CONTAINER ID）
</code></pre>
<p>●进入容器（该容器一定要在Up状态）</p>
<pre><code class="language-shell">docker exec -it 0f0ba9207b21 /bin/bash
</code></pre>
<p>●导出容器</p>
<pre><code class="language-shell">docker export cc4a8b1d428c &gt; /opt/nginx_bak
</code></pre>
<p>●导入容器（会生成镜像，而不会创建容器）</p>
<pre><code class="language-shell">cat /opt/nginx_bak | docker import - nginx:bak
</code></pre>
<p>●删除容器（容器必须为停止状态）</p>
<pre><code class="language-shell">docker stop e885c37fb2eb

docker rm e885c37fb2eb
</code></pre>
<p>●批量删除容器</p>
<pre><code class="language-shell">docker ps -a | awk '{print "docker rm "$1}' | bash
</code></pre>
<pre><code class="language-shell">docker ps -a | sed -n '2,$p' | awk '{print "docker rm "$1}' | bash
</code></pre>
<h1 id="si-docker-jing-xiang-de-gou-jian">四、Docker镜像的构建</h1>
<h2 id="1-docker-jing-xiang-de-fen-ceng">1、Docker镜像的分层</h2>
<p>自下而上制作镜像</p>
<p>1.from 后面跟基础镜像</p>
<p>2.add脚本</p>
<p>3.挂载共享空间 数据卷</p>
<p>4.CMD命令执行脚本</p>
<h2 id="2-ji-yu-yi-you-jing-xiang-rong-qi-chuang-jian">2、基于已有镜像容器创建</h2>
<pre><code class="language-shell">1、docker create -it 原镜像名 /bin/bash



2、docker commit -m "new" -a "chen" 已有容器id 新镜像名:标签

-m：说明信息

-a：作者信息

-p：生成过程中停止容器的运行

docker images | grep 标签
</code></pre>
<h2 id="3-ji-yu-ben-di-mo-ban-chuang-jian">3、基于本地模板创建</h2>
<p>1.导入本地镜像debian-7.0-x86-minimal.tar.gz</p>
<p>2.cat debian-7.0-x86-minimal.tar.gz | docker import - 镜像名:标签</p>
<p>3.docker images | grep 标签</p>
<h2 id="4-ji-yu-dockerfile-chuang-jian">4、基于Dockerfile创建</h2>
<p>●Dockerfile是由一组指令组成的文件</p>
<p>●Dockerfile结构四部分</p>
<p>基础镜像信息</p>
<p>维护者信息</p>
<p>镜像操作指令</p>
<p>容器启动时执行指令</p>
<p>●Dockerfile每行支持一条指令，每条指令可携带多个参数，支持使用以“#”号开头的注释</p>
<p>●Dockerfile操作指令</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>FROM 镜像</td>
<td>指定新镜像所基于的镜像，第一条指令必须为FROM指令，每创建一个镜像就需要一条FROM指令。</td>
</tr>
<tr>
<td>MAINTAINER 名字</td>
<td>说明新镜像的维护人信息</td>
</tr>
<tr>
<td>RUN命令</td>
<td>在所基于的镜像上执行命令，并提交到新的镜像中</td>
</tr>
<tr>
<td>CMD [“要运行的程序”,“参数1”,“参数2”]</td>
<td>指令启动容器时要运行的命令或者脚本，Dockerfile只能有一条CMD命令，如果指定多条则只能最后一条被执行</td>
</tr>
<tr>
<td>EXPOSE 端口号</td>
<td>指定新镜像加载到Docker时要开启的端口（EXPOSE暴露的是容器内部端口，需要再映射到一个外部端口上）</td>
</tr>
<tr>
<td>ENV 环境变量 变量值</td>
<td>设置一个环境变量的值，会被后面的RUN使用</td>
</tr>
<tr>
<td>ADD 源文件/目录 目标文件/目录</td>
<td>将源文件复制到目标文件（与COPY的区别是将本地tar文件解压到镜像中）</td>
</tr>
<tr>
<td>COPY 源文件/目录 目标文件/目录</td>
<td>将本地主机上的文件/目录复制到目标地点，源文件/目录要与Dockerfile在相同的目录中</td>
</tr>
<tr>
<td>VOLUME [“目录”]</td>
<td>在容器中创建一个挂载点（VOLUME是宿主机中的某一个目录挂载到容器中）</td>
</tr>
<tr>
<td>USER 用户名/UID</td>
<td>指定运行容器时的用户</td>
</tr>
<tr>
<td>WORKDIR 路径</td>
<td>为后续的RUN、CMD、ENTRYPOINT指定工作目录（WORKDIR类似于cd，但是只切换目录一次，后续的RUN命令就可以写相对路径了）</td>
</tr>
<tr>
<td>ONBUILD 命令</td>
<td>指定所生成的镜像作为一个基础镜像时所要运行的命令</td>
</tr>
<tr>
<td>HEALTHCHECK</td>
<td>健康检查</td>
</tr>
</tbody>
</table>
<p>CMD指令可以指定容器启动时默认执行的命令，但它可以被docker run命令的参数覆盖掉。</p>
<p>ENTRYPOINT  指令和CMD类似，它也是用户指定容器启动时要执行的命令，但如果dockerfile中也有CMD指令，CMD中的参数会被附加到ENTRYPOINT指令的后面。 如果这时docker run命令带了参数，这个参数会覆盖掉CMD指令的参数，并也会附加到ENTRYPOINT 指令的后面。</p>
<p>这样当容器启动后，会执行ENTRYPOINT 指令的参数部分。</p>
<p>可以看出，相对来说ENTRYPOINT指令优先级更高。</p>
<p>对于目录而言，COPY 和 ADD 命令具有相同的特点：<strong>只复制目录中的内容而不包含目录自身</strong></p>
<h4 id="cmd-he-entrypoint-de-qu-bie">CMD和ENTRYPOINT的区别</h4>
<p>CMD指令可以指定容器启动时默认执行的命令，但它可以被docker run命令的参数覆盖掉。</p>
<p>ENTRYPOINT  指令和CMD类似，它也是用户指定容器启动时要执行的命令，但如果dockerfile中也有CMD指令，CMD中的参数会被附加到ENTRYPOINT指令的后面。 如果这时docker run命令带了参数，这个参数会覆盖掉CMD指令的参数，并也会附加到ENTRYPOINT 指令的后面。</p>
<p>这样当容器启动后，会执行ENTRYPOINT 指令的参数部分。</p>
<p>可以看出，相对来说ENTRYPOINT指令优先级更高。</p>
<p>优先级：ENTRYPOINT&gt;CMD&gt;docker run</p>
<h4 id="dockerfile-wen-jian-sheng-cheng-apache-jing-xiang-shi-li">Dockerfile文件生成apache镜像实例：</h4>
<pre><code class="language-shell">1.vim Dockerfile （Dockerfile名字不可更改）
#新镜像基于的基础镜像（基础镜像未下载会先下载）
FROM centos:7
#维护镜像的用户信息
MAINTAINER This is chen
#镜像操作指令安装apache软件
RUN yum -y update
RUN yum -y install httpd
#开启80端口
EXPOSE 80
#复制网址首页文件
ADD index.html /var/www/html/index.html
#将执行脚本复制到镜像中
ADD run.sh /run.sh
RUN chmod 755 /run.sh
#启动容器时执行脚本
CMD ["/run.sh"]
</code></pre>
<p>此处注意一个细节：每加载一步会生成一个临时的容器，加载完后会删除</p>
<p>2.vim <a href="http://run.sh">run.sh</a>  #和Dockerfile文件位于相同目录下</p>
<pre><code class="language-shell">#!/bin/bash

rm -rf /run/httpd/*   #删除进程文件

exec /usr/sbin/apachectl -D FOREGROUND #启动apache


</code></pre>
<p>3.vim index.html   #编辑首页文件</p>
<pre><code class="language-txt">&lt;h1&gt;this is web&lt;/h1&gt;
</code></pre>
<p>4.生成镜像</p>
<pre><code class="language-shell">docker build -t httpd:test . （注意别忘了末尾有"."）
</code></pre>
<p>5.新镜像运行容器</p>
<pre><code class="language-shell">docker run -d -p 1216:80 httpd:test
</code></pre>
<p>-p：映射到宿主机指定端口</p>
<p>-P：映射到宿主机随机端口</p>
<p>6.测试容器是否成功运行</p>
<h1 id="wu-docker-de-si-chong-wang-luo-mo-shi">五、Docker的四种网络模式</h1>
<p><a href="https://blog.csdn.net/lilygg/article/details/88616218">https://blog.csdn.net/lilygg/article/details/88616218</a></p>
<h2 id="1-shi-xian-yuan-li">1、实现原理</h2>
<p>Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。</p>
<p>Docker网桥是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络是无法寻址到的，这也意味着外部网络无法通过直接Container-IP访问到容器。如果容器希望外部访问能够访问到，可以通过映射容器端口到宿主主机（端口映射），即docker run创建容器时候通过 -p 或 -P 参数来启用，访问容器的时候就通过[宿主机IP]:[容器端口]访问容器。</p>
<h2 id="2-wang-luo-xiang-jie">2、网络详解</h2>
<pre><code class="language-shell">[root@localhost ~]# docker network ls

NETWORK ID     NAME        DRIVER       SCOPE

f9ad4320a5f2    bridge       bridge       local

894917639bf3    host        host        local

39da54945dad    none        null        local
</code></pre>
<p>#安装docker时，它会自动创建三个网络，bridge（创建容器默认连接到该网络）、none和host</p>
<table>
<thead>
<tr>
<th>Docker网络模式</th>
<th>配置</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>host模式</td>
<td>–net=host</td>
<td>容器和宿主机共享Network namespace。</td>
</tr>
<tr>
<td>container模式</td>
<td>–net=container:NAME_or_ID</td>
<td>容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。</td>
</tr>
<tr>
<td>none模式</td>
<td>–net=none</td>
<td>容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair 和网桥连接，配置IP等。</td>
</tr>
<tr>
<td>bridge模式</td>
<td>–net=bridge</td>
<td>（默认为该模式）</td>
</tr>
</tbody>
</table>
<h3 id="1-host-mo-shi">1）、host模式</h3>
<p>容器将不会获得一个独立的Network Namespace（网络命令空间），而是和宿主机共用一个Network  Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口，（也就是说如果容器是个web，那直接访问宿主机:端口，不需要做NAT转换，跟在宿主机跑web一样。容器中除了网络，其他都还是隔离的。）</p>
<p>使用host模式的容器可以直接使用宿主机的IP地址与外界通信，容器内部的服务端口也可以使用宿主机的端口，不需要进行NAT，host最大的优势就是网络性能比较好，但是docker host上已经使用的端口就不能再用了，网络的隔离性不好。</p>
<h3 id="2-container-mo-shi">2）、Container模式</h3>
<p>这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享  IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信.</p>
<h3 id="3-none-mo-shi">3）、none模式</h3>
<p>使用none模式，Docker容器拥有自己的Network  Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。该模式关闭了容器的网络功能</p>
<p>这种网络模式下容器只有lo回环网络，没有其他网卡。none模式可以在容器创建时通过–network=none来指定。这种类型的网络没有办法联网，封闭的网络能很好的保证容器的安全性。</p>
<h3 id="4-bridge-mo-shi">4）、bridge模式</h3>
<p>此模式会为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，通过docker0网桥以及iptables nat表配置与宿主机通信</p>
<p>##当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。</p>
<p>从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth  pair设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中。可以通过brctl show命令查看。</p>
<p>bridge模式是docker的默认网络模式，不写–net参数，就是bridge模式。使用docker run -p时，docker实际是在iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnL查看。</p>
<h2 id="3-zi-ding-yi-wang-luo-ru-he-pei-zhi">3、自定义网络如何配置</h2>
<p>#创建容器时默认使用的是桥接模式，但是使用bridge不支持为容器指定IP</p>
<pre><code class="language-shell">[root@localhost ~]# docker run -itd --name test1 --network bridge --ip 172.17.0.10 centos:7 /bin/bash

20dc45293929f81013a60391bef2626f581a8d3d4f29b8a87ac8b1f9b585ab2a

docker: Error response from daemon: user specified IP address is supported on  user defined networks only.  #提示想要为容器指定IP只能在用户自定义的网络中才行
</code></pre>
<p>#配置自定义固定IP</p>
<pre><code class="language-shell">[root@localhost ~]# docker network create --subnet=172.31.0.0/24 test  

#创建自定义网络test

[root@localhost ~]# docker run -itd --name web1 --net test --ip 172.31.0.10 centos:7 /bin/bash   
</code></pre>
<h1 id="liu-docker-shu-ju-guan-li">六、Docker数据管理</h1>
<h2 id="1-wei-shi-yao-yao-jin-xing-shu-ju-guan-li-cao-zuo">1、为什么要进行数据管理操作</h2>
<p>●方便查看容器内产生的数据</p>
<p>●多容器间实现数据共享</p>
<p>例如：需要给多个容器中的网站站点上传网页内容时，可以高效的部署网页。</p>
<h2 id="2-liang-chong-guan-li-fang-shi">2、两种管理方式</h2>
<p>●数据卷</p>
<p>数据卷是容器和宿主之间的数据共享</p>
<p>●数据卷容器</p>
<p>数据卷容器是容器和容器之间的数据共享</p>
<h2 id="3-shu-ju-juan-cao-zuo-shi-li">3、数据卷操作实例</h2>
<p>1.将宿主机目录中的/var/www挂载到容器中的/data1中（如果目录不存在都会自动创建）</p>
<pre><code class="language-shell">docker run -v /var/[www:/data1](http://www/data1) --name web1 -it centos:7 /bin/bash
</code></pre>
<p>2.在容器中/data1目录下创建文件进行测试</p>
<pre><code class="language-shell">[root@bb58030283e7 /]# cd /data1/

[root@bb58030283e7 data1]# touch 123.txt
</code></pre>
<p>3.回到宿主机/var/www查看</p>
<pre><code class="language-shell">[root@node1 ~]# cd /var/www/

[root@node1 www]# ls

123.txt
</code></pre>
<h2 id="4-shu-ju-juan-rong-qi-cao-zuo-shi-li">4、数据卷容器操作实例</h2>
<p>1.创建数据卷容器web10</p>
<pre><code class="language-shell">docker run --name web10 -v /data1 -v /data2 -it centos:7 /bin/bash
</code></pre>
<p>2.新容器web100挂载数据卷容器web10</p>
<pre><code class="language-shell">docker run -it --volumes-from web10 --name web100 centos:7 /bin/bash

（web100容器会自动关联web10容器中的数据卷）
</code></pre>
<p>3.在新容器web100的/data1中创建文件进行测试</p>
<pre><code class="language-shell">[root@2ad42960c2aa data1]# cd /data1/

[root@2ad42960c2aa data1]# ls

[root@2ad42960c2aa data1]# touch 1.txt
</code></pre>
<p>4.回到数据卷容器web10的/data1中查看</p>
<pre><code class="language-shell">[root@b10f5d5ae9d5 /]# cd data1/

[root@b10f5d5ae9d5 data1]# ls

1.txt
</code></pre>
<h2 id="5-si-you-cang-ku-jian-li-bu-zou">5、私有仓库建立步骤</h2>
<p>1、下载registry镜像</p>
<p>2、客户端设置daemon.json文件，指定私有仓库位置；</p>
<pre><code class="language-shell"> "insecure-registries": ["14.0.0.10:5000"],
</code></pre>
<p>3、生成registry容器，开放5000端口</p>
<pre><code class="language-shell">docker run -d -p 5000:5000 -v /[registry:/data/registry](http://registry/data/registry) registry
</code></pre>
<p>4、给要上传的镜像打上标签</p>
<p>5、上传镜像</p>
<p>6、获取私有仓库列表查看是否上传成功</p>
<p>7、测试私有仓库下载镜像</p>
<p>#–privileged 让容器内的root拥有真正的root权限。否则，container内的root只是外部的一个普通用户权限。</p>
<pre><code class="language-shell">[root@localhost systemctl]# docker run --privileged -it -v /sys/fs/[cgroup:/sys/fs/cgroup:ro](http://cgroup/sys/fs/cgroup:ro) 
</code></pre>
<h1 id="qi-docker-compose-rong-qi-bian-pai">七、Docker Compose容器编排</h1>
<h2 id="1-docker-compose-jian-jie">1、Docker Compose简介</h2>
<p>●一个定义及运行多个Docker容器的工具</p>
<p>●Docker Compose非常适合组合使用多个容器进行开发的场景</p>
<p>3.2Docker Compose文件格式及编写注意事项</p>
<p>●YAML是一种标记语言很直观的数据序列化格式</p>
<p>●文件格式及编写注意事项</p>
<p>不支持制表符tab键缩进，需要使用空格缩进</p>
<p>通常开头缩进2个空格</p>
<p>字符后缩进1个空格，如冒号、逗号、横杆</p>
<p>用#号注释</p>
<p>如果包含特殊字符用单引号引起来</p>
<p>布尔值必须用引号括起来</p>
<h2 id="2-compose-ming-ling-shuo-ming">2、Compose命令说明</h2>
<p>●基本的使用格式</p>
<pre><code class="language-shell"> docker-compose [options] [COMMAND] [ARGS]
</code></pre>
<p>●docker-compose选项</p>
<pre><code class="language-shell"> --verbose 输出更多调试信息

 --version 打印版本并退出

 -f，--file FILE 使用特定的compose模板文件，默认为docker-compose.yml

 -p，--project-name NAME 指定项目名称，默认使用目录名称
</code></pre>
<h2 id="3-compose-bu-shu">3、compose部署</h2>
<p>#以docker-ce为基础</p>
<p>上传docker-compose命令包到/usr/local/bin目录下</p>
<pre><code class="language-shell">chmod +x /usr/local/bin/docker-compose
</code></pre>
<p>#在/root目录下创建compose_tomcat目录</p>
<p>[root@localhost ~]# mkdir compose_tomcat/</p>
<h3 id="docker-compose-yml-pei-zhi-wen-jian-xiang-jie">docker-compose.yml配置文件详解：</h3>
<p><a href="https://www.jianshu.com/p/2217cfed29d7">https://www.jianshu.com/p/2217cfed29d7</a></p>
<p>一份标准配置文件应该包含 version、services、networks 三大部分，其中最关键的就是 services 和 networks 两个部分</p>
<pre><code class="language-shell">[root@localhost compose_tomcat]# vim docker-compose.yml

version: '3'

services:

 tomcat:

  hostname: tomcat

  build:   #基于一份 Dockerfile创建容器

   context: ./tomcat

   dockerfile: Dockerfile

  ports:

   - 8080:8080

  networks:

   - tomcat

  volumes:

   - ./[wwwroot:/usr/local/tomcat/webapps/ROOT](http://wwwroot/usr/local/tomcat/webapps/ROOT)  #注意tomcat站点位置

 nginx:

  hostname: nginx

  build:

   context: ./nginx

   dockerfile: Dockerfile

  ports:

   - 1216:80

   - 1226:443

  networks:

   - nginx

  volumes:

   - ./[nginxroot:/usr/local/nginx/html](http://nginxroot/usr/local/nginx/html)

networks:

 tomcat:

 nginx:

[root@localhost compose_tomcat]# docker-compose -f docker-compose.yml up -d
</code></pre>
<h1 id="ba-harbor-si-you-cang-ku">八、Harbor私有仓库</h1>
<p>Harbor私有仓库部署与管理</p>
<p>Harbor的每个组件都是以Docker容器的形式构建的，使用docker-compose来对它进行部署</p>
<p>Docker harbor有可视化的web管理界面，可以方便管理Docker镜像，又提供了多个项目的镜像权限管理及控制功能</p>
<p>使用 Docker 命令在本地通过 127.0.0.1 来登录和推送镜像</p>
<p>默认情况下，Register 服务器在端口 80 上侦听。</p>
<p>//登录</p>
<pre><code class="language-shell">docker login -u admin -p Harbor12345 [http://127.0.0.1](http://127.0.0.1/)
</code></pre>
<p>//下载镜像进行测试 下载镜像进行测试</p>
<pre><code class="language-shell">docker pull nginx
</code></pre>
<p>//镜像打标签 （网页上也会有提示、模板）</p>
<pre><code class="language-shell">docker tag nginx 127.0.0.1/myimages/nginx:v1
</code></pre>
<p>//上传镜像到 上传镜像到 Harbor</p>
<pre><code class="language-shell">docker push 127.0.0.1/myimages/nginx:v1
</code></pre>
<p>使用Harbor仓库时遇到的故障：</p>
<p>以上操作都是在 Harbor 服务器本地操作。如果其他客户端上传镜像到 Harbor，就会报</p>
<p>如下错误。</p>
<p>出现这问题的原因 Docker Registry 交互默认使用的是 HTTPS，但是搭建私有镜像默认使用的是 HTTP 服务，所以与私有镜像交互时出现以下错误。</p>
<pre><code class="language-shell">[root@localhost ~]# docker login -u admin -p Harbor12345 [http://14.0.0.20](http://14.0.0.20/)

WARNING! Using --password via the CLI is insecure. Use --password-stdin.

Error response from daemon: Get https://14.0.0.20/v2/: dial tcp 14.0.0.20:443: connect: connection refused
</code></pre>
<p>如何解决：</p>
<pre><code class="language-shell">[root@client ~]# vim /usr/lib/systemd/system/docker.service

ExecStart=/usr/bin/dockerd -H fd:// --insecure-registry 14.0.0.20 -- containerd=/run/containerd/containerd.sock

[root@client ~]# systemctl daemon-reload 

[root@client ~]# systemctl restart docker
</code></pre>
<p>要更改 Harbor 的配置文件时，请先停止现有的 Harbor 实例并更新 Harbor.cfg；然后运行 prepare 脚本来填充配置；最后重新创建并启动 Harbor 的实例。</p>
<p>1.停止现有的 Harbor 实例</p>
<pre><code class="language-shell">docker-compose down -v

[root@localhost harbor]# pwd

/usr/local/harbor

[root@localhost harbor]# ls

common           docker-compose.yml   harbor.v1.2.2.tar.gz NOTICE

docker-compose.clair.yml  harbor_1_1_0_template install.sh      prepare

docker-compose.notary.yml harbor.cfg       LICENSE        upgrade
</code></pre>
<p>2.更新 Harbor.cfg</p>
<pre><code class="language-shell">[root@localhost harbor]# vim Harbor.cfg
</code></pre>
<p>3.运行 prepare 脚本来填充配置</p>
<pre><code class="language-shell">[root@localhost harbor]# ./prepare
</code></pre>
<p>4.重新创建并启动 Harbor 的实例</p>
<p>如果出现如下报错： docker-compose up -d</p>
<h1 id="jiu-docker-consul-rong-qi-fu-wu-geng-xin-yu-fa-xian">九、Docker consul容器服务更新与发现</h1>
<h2 id="1-consul-de-jie-shao">1、consul的介绍</h2>
<p>由HashiCorp公司使用go语言开发的一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件（开源）。</p>
<p>主要特点：</p>
<p>服务发现及配置；</p>
<p>支持健康检查，并且运行HTTP、GTPC和DNS协议调用API存储键值对；</p>
<p>采用Raft算法，保证服务的高可用</p>
<p>支持安全服务通信；</p>
<p>支持多数据中心；</p>
<h2 id="2-consul-agent">2、consul agent</h2>
<p>consul通过agent来运行的，agent分为server 和client两种类型，这两种类型基本上没有什么区别，server agent是将服务的消息存储，一般来说为了防止单点故障推荐使用3到5个来构建集群架构。</p>
<p>而client agent主要用于注销服务、健康检查及转发server agent的查询等，相当于一个代理，因此它必须要在集群的每台主机上运行。</p>
<p>一种服务或软件工具的产生必然有其使用场景和其优势，否则哪有其立足之地？</p>
<h2 id="3-consul-shi-yong-de-chang-jing">3、consul使用的场景</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>Docker 容器的注册与配置共享</p>
</li>
<li class="lvl-2">
<p>Coreos 实例的注册与配置共享</p>
</li>
<li class="lvl-2">
<p>SaaS 应用的配置共享、服务发现和健康检查。</p>
</li>
<li class="lvl-2">
<p>vitess 集群</p>
</li>
<li class="lvl-2">
<p>与 confd 服务集成，动态生成 nginx 和 haproxy 配置文件</p>
</li>
</ul>
<h2 id="4-docker-consul-rong-qi-fu-wu-geng-xin-yu-fa-xian-yuan-li">4、Docker Consul容器服务更新与发现原理</h2>
<pre><code class="language-shell">1. Consul Cluster由部署和运行了Consul Agent的节点组成。 在Cluster中有两种角色:Server和 Client。
2. Server和Client的角色和Consul Cluster上运行的应用服务无关, 是基于Consul层面的一种角色划分.
3. Consul Server: 用于维护Consul Cluster的状态信息， 实现数据一致性， 响应RPC请求。官方建议是:  至少要运行3个或者3个以上的Consul Server。 多个server之中需要选举一个leader,  这个选举过程Consul基于Raft协议实现. 多个Server节点上的Consul数据信息保持强一致性。  在局域网内与本地客户端通讯，通过广域网与其他数据中心通讯。Consul Client: 只维护自身的状态,  并将HTTP和DNS接口请求转发给服务端。
4. Consul 支持多数据中心， 多个数据中心要求每个数据中心都要安装一组Consul cluster，多个数据中心间基于gossip protocol协议来通讯， 使用Raft算法实现一致性
</code></pre>
<h2 id="5-gong-zuo-liu-cheng">5、工作流程：</h2>
<p>当后面容器增加时，registrator注册容器中的服务—》通知consul server更新—》consul template模板进行更新，自动修改nginx.conf中的upstream参数</p>
<p>Registrator监控新建的Docker容器，并且检查判定这些容器提供的服务。从我们的目的出发，任何监听在某个端口的程序都是服务。Registrator在容器内发现的任务服务，都将被添加到一个服务注册端，比如Consul或etcd</p>
<p>准备template nginx模板文件，参数以变量形式写入</p>
<p>在consul服务器节点上操作</p>
<pre><code class="language-shell">[root@localhost consul]# vim /root/consul/nginx.ctmpl

upstream http-server {

 {{range service "nginx"}}

 server {{.Address}}:{{.Port}};

 {{end}}

}
</code></pre>
<p>consul-template是一个守护进程，用于实时查询consul集群信息，并更新文件系统上任意数量的指定模板，生成配置文件。更新完成后，可以选择运行shell命令执行更新操作，重新加载nginx。这种强大的抽象功能和查询语言模板可以使consul-template特别适合动态的创建配置文件。例如：创建nginx反向代理。</p>
<h1 id="shi-zi-yuan-fen-pei">十、资源分配</h1>
<h2 id="1-wei-shi-yao-yao-zuo-zi-yuan-fen-pei">1、为什么要做资源分配？</h2>
<p>容器和虚拟机的区别：</p>
<p>虚拟机不需要做，因为虚拟机在创建的时候已经做了资源分配（配额），（虚拟CPU,虚拟内存,虚拟磁盘等）</p>
<p>而容器共享内核资源，所以需要做Cgroup，可以按照往年监控的数据，查看cpu等资源的耗用情况来进行分配</p>
<h2 id="2-cgroup-zi-yuan-pei-zhi-fang-fa">2、Cgroup资源配置方法</h2>
<p>Docker是通过Cgroup来控制容器使用的资源配额，包括CPU、内存、磁盘i/o三大方面，基本覆盖了常见的资源配额和使用量控制。</p>
<p>Cgroup是Control  Groups的缩写，是Linux内核提供的一种可以限制、记录、隔离进程组所使用的物理资源（如CPU、内存、磁盘IO等）的机制，被docker等很多项目用于实现进程资源控制。Cgroup本身是提供将进程进行分组化管理的功能和接口的基础结构，I/O或内存的分配控制等具体的资源管理功能。这些具体的资源管理功能称为Cgroup子系统，有以下几大子系统实现：</p>
<p>blkio：设置限制每个块设备的输入输出控制。例如：磁盘，usb等</p>
<p>CPU：使用调度程序为cgroup任务提供CPU的访问。</p>
<p>cpuacct：产生cgroup任务的CPU资源报告。</p>
<p>cpuset：如果是多核心的cpu，这个子系统会为cgroup任务分配单独的CPU和内存。</p>
<p>devices：允许或拒绝cgroup任务对设备的访问。</p>
<p>freezer：暂停和恢复cgroup任务。</p>
<p>memory：设置每个cgroup的内存限制以及产生内存资源报告。</p>
<p>net_cls：标记每个网络包以供cgroup方便使用。</p>
<p>ns：命名空间子系统。</p>
<p>perf_event：增加了对每个group的监测跟踪的能力，可以监测属于某个特定的group的所有线程以及运行在特定CPU上的线程。</p>
<h2 id="3-cpu-zhou-qi-xian-zhi">3、CPU周期限制</h2>
<p>Docker提供了–cpu-period、–cpu-quota两个参数控制容器可以分配到的CPU时钟周期。</p>
<p>–cpu-period是用来指定容器对CPU的使用要在多长时间内做一次重新分配。</p>
<p>–cpu-quota是用来指定在这个周期内，最多可以有多少时间来跑这个容器。</p>
<p>与–cpu-shares不同的是，这种配置是指定一个绝对值，容器对CPU资源的使用绝对不会超过配置的值。</p>
<p>cpu-period和cpu-quota的单位为微秒（μs）。cpu-period的最小值为1000微秒，最大值为1秒，默认值为0.1秒（100000μs）</p>
<p>cpu-quota的值默认为-1，表示不做控制。cpu-period和cpu-quota参数一般联合使用。</p>
<p>例如：容器进程需要每1秒使用单个cpu的0.2秒时间，可以将cpu-period设置为1000000即1秒，cpu-quota设置为200000（0.2秒）。</p>
<p>在多核情况下，如果允许容器进程完全占用两个cpu，则可以将cpu-period设置为100000即0.1秒，cpu-quota设置为200000即0.2秒</p>
<pre><code class="language-shell">[root@localhost ~]# docker run -itd --cpu-period 100000 --cpu-quota 200000 centos:stress

[root@localhost ~]# docker exec -it 16b6689aabc6 /bin/bash

[root@16b6689aabc6 /]# cd /sys/fs/cgroup/

[root@16b6689aabc6 cgroup]# ls

blkio    cpuacct freezer net_cls      perf_event

cpu     cpuset  hugetlb net_cls,net_prio pids

cpu,cpuacct devices memory  net_prio     systemd

[root@16b6689aabc6 cgroup]# cd cpu

[root@16b6689aabc6 cpu]# ls

cgroup.clone_children cpu.rt_period_us  cpuacct.usage

cgroup.event_control  cpu.rt_runtime_us cpuacct.usage_percpu

cgroup.procs      cpu.shares     notify_on_release

cpu.cfs_period_us   cpu.stat      tasks

cpu.cfs_quota_us    cpuacct.stat

[root@16b6689aabc6 cpu]# cat cpu.cfs_period_us

100000

[root@16b6689aabc6 cpu]# cat cpu.cfs_quota_us

200000
</code></pre>
<h2 id="4-cpu-core-kong-zhi">4、CPU Core控制</h2>
<p>对多核CPU的服务器，Docker还可以控制容器运行使用哪些CPU内核，即使用–cpuset-cpus参数。这对具有多CPU的服务器尤其有用，可以对需要高性能计算的容器进行性能最优的配置。</p>
<pre><code class="language-shell">[root@localhost ~]# docker run -itd --name cpu1 --cpuset-cpus 1-2 centos:stress
</code></pre>
<p>#执行以上命令表示创建的容器只能用1、2两个cpu。最终生成的cgroup的cpu内核配置如下：</p>
<pre><code class="language-shell">[root@localhost ~]# docker exec -it 75be98d74dcc /bin/bash

top - 07:34:23 up 45 min, 0 users, load average: 0.00, 0.01, 0.04

[root@75be98d74dcc /]# cat /sys/fs/cgroup/cpuset/cpuset.cpus #cpuset：cpu集合

1-2

[root@75be98d74dcc /]# stress -c 5 &amp;  #让容器产生5个子函数进程，并在后台运行

[root@75be98d74dcc /]# top  #使用top命令查看cpu工作情况（top进去后按1，显示每个cpu的工作情况）
</code></pre>
<p>#通过下面指令可以看到容器中进程与cpu内核的绑定关系</p>
<pre><code class="language-shell">[root@localhost ~]# docker exec 75be98d74dcc taskset -c -p 1 #-p 1 表示容器中第一个进程pid为1被绑定到cpu1和2上

pid 1's current affinity list: 1,2
</code></pre>
<h1 id="shi-yi-docker-tls-jia-mi-tong-xun">十一、Docker-TLS加密通讯</h1>
<h2 id="1-shi-yong-tls-jia-mi-tong-xun-yuan-yin">1、使用TLS加密通讯原因</h2>
<p>为了防止链路劫持、会话劫持等问题导致Docker通信时被中间人攻击，c/s两端应该通过加密方式通讯。</p>
<h2 id="2-ji-chu-zhi-shi">2、基础知识</h2>
<p>1.对称密钥，例如DES、3DES、AES，长度不同，长度越长安全越高，解密速度越慢。</p>
<p>2.非对称密钥，分为公钥和私钥，例如RSA 公钥：所有人可知（锁），私钥（钥匙）个人身份信息，不可抵赖。</p>
<p>3.封装在证书中：个人信息，密钥，有效期</p>
<p><a href="http://4.ca/">4.ca</a>：证书颁发机构 ca证书</p>
<p>密钥key–》身份签名（csr）–》服务器/客户端（结合）制作证书pem</p>
<p>证书pem发送给客户端，客户端通过证书验证才能访问容器</p>
<h2 id="3-tls-jia-mi-tong-xun-bu-shu-guo-cheng">3、TLS加密通讯部署过程：</h2>
<p>1.修改服务器主机名为server，并添加到本地解析文件</p>
<pre><code class="language-shell">[root@localhost ~]# hostnamectl set-hostname server

[root@localhost ~]# su

[root@server ~]# vim /etc/hosts

127.0.0.1 server
</code></pre>
<p>2.创建ca密钥（ca-key.pem）</p>
<pre><code class="language-shell">[root@server ~]# openssl genrsa -aes256 -out ca-key.pem 4096 #256为密钥长度；4096为字节数

Generating RSA private key, 4096 bit long modulus

.......++

...............++

e is 65537 (0x10001)

Enter pass phrase for ca-key.pem:    #输入密码123123（自定义）

Verifying - Enter pass phrase for ca-key.pem:   #确认密码123123
</code></pre>
<p>3.创建ca根证书文件（ca.pem）</p>
<pre><code class="language-shell">[root@server ~]# openssl req -new -x509 -days 1000 -key ca-key.pem -sha256 -subj  "/CN=*" -out ca.pem  #req：签名；x509：国际标准；sha256：指定哈希256位加密算法；subj：项目名称

Enter pass phrase for ca-key.pem:   #输入123123
</code></pre>
<hr>
<p>4.创建服务器私钥</p>
<pre><code class="language-shell">[root@server ~]# openssl genrsa -out server-key.pem 4096  #genrsa：非对称密钥

Generating RSA private key, 4096 bit long modulus

.....................................................................................++

..............................................................++

e is 65537 (0x10001)


[root@server ~]# ls

anaconda-ks.cfg ca.pem        server-key.pem 公共 视频 文档 音乐

ca-key.pem    initial-setup-ks.cfg stress     模板 图片 下载 桌面
</code></pre>
<p>5.签名私钥</p>
<pre><code class="language-shell">[root@server ~]# openssl req -subj "/CN=*" -sha256 -new -key server-key.pem -out server.csr
</code></pre>
<p>6.使用ca证书与私钥证书签名</p>
<pre><code class="language-shell">[root@server ~]# openssl x509 -req -days 1000 -sha256 -in server.csr -CA  ca.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem

Signature ok

subject=/CN=*

Getting CA Private Key

Enter pass phrase for ca-key.pem:   #输入123123

[root@server ~]# ls

anaconda-ks.cfg ca.srl        server.csr   公共 图片 音乐

ca-key.pem    initial-setup-ks.cfg server-key.pem 模板 文档 桌面

ca.pem      server-cert.pem    stress     视频 下载
</code></pre>
<hr>
<p>7.生成客户端密钥</p>
<pre><code class="language-shell">[root@server ~]# openssl genrsa -out key.pem 4096

Generating RSA private key, 4096 bit long modulus

....................................++

.......................................................................++

e is 65537 (0x10001)
</code></pre>
<p>8.签名客户端</p>
<pre><code class="language-shell">[root@server ~]# openssl req -subj "/CN=client" -new -key key.pem -out client.csr
</code></pre>
<p>9.创建配置文件</p>
<pre><code class="language-shell">[root@server ~]# echo extendedKeyUsage=clientAuth &gt; extfile.cnf
</code></pre>
<p>10.签名证书，输入123123，需要（签名客户端，ca证书，ca密钥）</p>
<pre><code class="language-shell">[root@server ~]# openssl x509 -req -days 1000 -sha256 -in client.csr -CA ca.pem  -CAkey ca-key.pem -CAcreateserial -out cert.pem -extfile extfile.cnf

Signature ok

subject=/CN=client

Getting CA Private Key

Enter pass phrase for ca-key.pem:

---------------------------------------------------------------------------------------------------------------------------------

</code></pre>
<p>11.删除多余文件</p>
<pre><code class="language-shell">[root@server ~]# rm -rf ca.srl client.csr extfile.cnf server.csr
</code></pre>
<p>12.修改docker服务文件文件</p>
<pre><code class="language-shell">[root@server ~]# vim /lib/systemd/system/docker.service
</code></pre>
<pre><code class="language-shell">[root@server ~]# mkdir /tls

[root@server ~]# mv ca.pem /tls

[root@server ~]# mv server-cert.pem /tls

[root@server ~]# mv server-key.pem /tls/

[root@server ~]# mv cert.pem /tls/

[root@server ~]# mv key.pem /tls/

[root@server ~]# ls /tls/

ca.pem cert.pem key.pem server-cert.pem server-key.pem
</code></pre>
<p>13.重载进程，重启docker服务</p>
<pre><code class="language-shell">[root@server ~]# systemctl daemon-reload

[root@server ~]# systemctl restart docker
</code></pre>
<p>14.将/tls目录下的ca.pem、cert.pem、key.pem三个文件复制给客户端</p>
<pre><code class="language-shell">[root@server tls]# scp ca.pem [root@14.0.0.30](mailto:root@14.0.0.30):/etc/docker/

[root@server tls]# scp cert.pem [root@14.0.0.30](mailto:root@14.0.0.30):/etc/docker/

[root@server tls]# scp key.pem [root@14.0.0.30](mailto:root@14.0.0.30):/etc/docker/
</code></pre>
<hr>
<p>15.到客户端14.0.0.30进行测试</p>
<pre><code class="language-shell">[root@localhost docker]# vim /etc/hosts

加入：14.0.0.20 server

[root@localhost ~]# cd /etc/docker/  #注意要切换到服务端传证书文件的目录下

[root@localhost docker]# docker --tlsverify --tlscacert=ca.pem --tlscert=cert.pem --tlskey=key.pem -H [tcp://server:2376](tcp://server:2376) ps -a    #测试成功，成功访问服务端容器

CONTAINER  ID    IMAGE        COMMAND       CREATED       STATUS              PORTS        NAMES

327038e98aa4    centos:stress    "stress -c 1"    About an hour ago  Exited (137) About an hour  ago            cpu4

4eb80db7a397    centos:stress    "stress -c 1"    About an hour ago  Exited (137) About an hour  ago            cpu3
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS下安装wareshark</title>
    <url>/2023/01/09/install_wireshare_in_centos/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>How to install wireshare in CentOS? This document briefly describes it.</p>
<h1 id="installation-on-cent-os">Installation on CentOS</h1>
<pre><code class="language-shell">yum install gcc gcc-c++ bison flex libpcap-devel qt-devel gtk3-devel rpm-build libtool c-ares-devel qt5-qtbase-devel qt5-qtmultimedia-devel qt5-linguist desktop-file-utils
yum install wireshark wireshark-qt
yum install wireshark-gnome
</code></pre>
<p>启动:在Application/internet下。</p>
<p>启动后提示：</p>
<pre><code class="language-shell">Couldn't run /usr/sbin/dumpcap in child process: Permission denied

Are you member of 'wireshark' group? Try running 'usermod -a -G wireshark &lt;username&gt;' as root.

</code></pre>
<p>同时，也沒有interface列出來。</p>
<p>按照提示增加普通使用者到组以后，还是提示许可证问题。</p>
<p>于是，將/usr/sbin/dumpcap的组改为普用使用者的组，再执行，沒有那个提示了，但是还是沒有interface列出來。</p>
<p>workaround</p>
<pre><code class="language-shell">[root@pool-100-0-1-54 windipv6]# sudo usermod -a -G wireshark windipv6

setcap cap_net_raw,cap_net_admin+eip /usr/sbin/dumpcap

</code></pre>
<p>Reference Link:</p>
<p><code>https://linuxtechlab.com/install-wireshark-linux-centosubuntu/</code></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>wireshark</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title>修改主机名</title>
    <url>/2022/12/28/modify_hostname/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>2022年就这么结束了，一年没什么输出，凑个数收个尾，简单mark下Ubuntu下如何更改主机名…</p>
<h1 id="shi-zuo">实作</h1>
<h2 id="fang-fa-1-re-gai">方法1： 热改</h2>
<pre><code class="language-shell">hostname new_host_name
</code></pre>
<p>简单粗暴有效，重启机器失效。</p>
<h2 id="fang-fa-2-yong-jiu-xiu-gai">方法2： 永久修改</h2>
<p>方案1: 热改+静态配置文件的修改</p>
<pre><code class="language-shell">vim /etc/hosts
vim /etc/hostname
</code></pre>
<p>然后执行</p>
<pre><code class="language-shell">hostname new_host_name
</code></pre>
<p>经过上述步骤后，下次重启永久生效</p>
<p>方案2：hostnamectl 指令修改</p>
<pre><code class="language-shell">hostnamectl set-hostname {name}
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Sync ISO script from SFTP Server</title>
    <url>/2023/01/11/sync_iso_from_sftp_server/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Because Build Man is not in Nanjing, I need to synchronize ISO to NJ Lab from the corresponding server in other cities of the company, so I wrote a script.<br>
In the early days, it was automatically synced from the source to NJ, but later, due to the company’s network security reinforcement, it could only be synced from the intranet, and in the sftp way.</p>
<h1 id="files-list">Files list</h1>
<pre><code class="language-shell">8.x_iso_scp.sh
for_sftp_sync_fstab
sftp_iso.sh
</code></pre>
<h1 id="scripts">Scripts</h1>
<h2 id="modify-etc-fstab">Modify /etc/fstab</h2>
<pre><code class="language-shell">10.16.172.102:/vol/share/Builds/buildwindow/centos7/virtualstor_scaler_8.2 /mnt/centos7/8.2    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/centos7/virtualstor_scaler_8.3 /mnt/centos7/8.3    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/centos7/virtualstor_scaler_8.0 /mnt/centos7/8.0    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_8.2 /mnt/xenial/8.2    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_8.3 /mnt/xenial/8.3    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_8.0 /mnt/xenial/8.0    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.2 /mnt/cone/1.2    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.2_oem_putian /mnt/cone/1.2_oem_putian    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.3 /mnt/cone/1.3    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_oem_putian_8.0 /mnt/xenial/8.0_oem_putian    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_oem_fiberhome_8.0 /mnt/xenial/8.0_oem_fiberhome    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_oem_fiberhome_8.2 /mnt/xenial/8.2_oem_fiberhome    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_oem_thinkingdata_8.2 /mnt/xenial/8.2_oem_thinkingdata    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.2_oem_fiberhome /mnt/cone/1.2_oem_fiberhome    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.2_oem_thinkingdata /mnt/cone/1.2_oem_thinkingdata    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.2_oem_xinzhe /mnt/cone/1.2_oem_xinzhe    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.2_oem_xinzhe_dark /mnt/cone/1.2_oem_xinzhe_dark    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.3_oem_fiberhome /mnt/cone/1.3_oem_fiberhome    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/cone/1.3_oem_thinkingdata /mnt/cone/1.3_oem_thinkingdata    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_oem_hygon_8.0 /mnt/xenial/8.0_oem_hygon    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_oem_chaoyun_8.2 /mnt/xenial/8.2_oem_chaoyun    nfs    defaults        0 0
10.16.172.102:/vol/share/Builds/buildwindow/xenial/virtualstor_scaler_oem_srie_8.0 /mnt/xenial/8.0_oem_srie    nfs    defaults        0 0
10.16.172.103:/vol/share/Builds/buildwindow/cone/1.4 /mnt/cone/1.4    nfs    defaults        0 0
10.16.172.104:/vol/share/Builds/buildwindow/cone/1.4_oem_daasbank /mnt/cone/1.4_oem_daasbank    nfs    defaults        0 0
10.16.172.104:/vol/share/Builds/buildwindow/cone/2.1 /mnt/cone/2.1    nfs    defaults        0 0
</code></pre>
<p>mount point下内容：</p>
<pre><code class="language-shell">root@apidoc:/mnt$ ll
total 0
drwxr-xr-x.  3 root root           17 Dec 29  2021 arm
drwxr-xr-x.  5 root root           39 May 28  2021 centos7
drwxr-xr-x. 16 root root          286 Jan  6 10:25 cone
drwxr-xr-x.  1 1000 1000 820255811108 Jan  5 12:01 kylin
drwxr-xr-x. 12 root root          203 Feb 23  2022 xenial
root@apidoc:/mnt$ cd xenial/
root@apidoc:/mnt/xenial$ ll
total 0
drwxrwxr-x. 1 nfsnobody nfsnobody 131011422392 Aug 16  2021 8.0
drwxrwxr-x. 1 nfsnobody nfsnobody   4225724416 Jun 25  2021 8.0_oem_fiberhome
drwxrwxr-x. 1 nfsnobody nfsnobody   4222875648 Nov 10  2021 8.0_oem_hygon
drwxrwxr-x. 1 nfsnobody nfsnobody   8437528576 Jun 25  2021 8.0_oem_putian
drwxrwxr-x. 1 nfsnobody nfsnobody   4225492992 Feb 23  2022 8.0_oem_srie
drwxrwxr-x. 1 nfsnobody nfsnobody 338626134376 Aug 16  2021 8.2
drwxrwxr-x. 1 nfsnobody nfsnobody   9681530880 Nov 10  2021 8.2_oem_chaoyun
drwxrwxr-x. 1 nfsnobody nfsnobody  29034631168 Sep  7  2021 8.2_oem_fiberhome
drwxrwxr-x. 1 nfsnobody nfsnobody   9652283392 Jul  5  2021 8.2_oem_thinkingdata
drwxrwxr-x. 1 nfsnobody nfsnobody 518908765624 Aug 16  2021 8.3
root@apidoc:/mnt/xenial$ 
root@apidoc:/mnt/xenial$

root@apidoc:/mnt/cone$ 
root@apidoc:/mnt/cone$ ll
total 0
drwxr-xr-x. 3 root      root                18 Jan  6 15:32 1.0
drwxrwxr-x. 1 nfsnobody nfsnobody   5272838144 Jun 21  2021 1.2
drwxrwxr-x. 1 nfsnobody nfsnobody   5262286848 Oct 11  2021 1.2_oem_fiberhome
drwxrwxr-x. 1 nfsnobody nfsnobody   5264971776 Jun 21  2021 1.2_oem_putian
drwxrwxr-x. 1 nfsnobody nfsnobody 232057397248 Oct 11  2021 1.2_oem_thinkingdata
drwxrwxr-x. 1 nfsnobody nfsnobody   5270681600 Oct 11  2021 1.2_oem_xinzhe
drwxrwxr-x. 1 nfsnobody nfsnobody   5285871616 Oct 11  2021 1.2_oem_xinzhe_dark
drwxrwxr-x. 1 nfsnobody nfsnobody  21246191616 Jan  6 15:31 1.3
drwxrwxr-x. 1 nfsnobody nfsnobody  10607448064 Apr  5  2022 1.3_oem_fiberhome
drwxrwxr-x. 1 nfsnobody nfsnobody   5314854912 Oct 12  2021 1.3_oem_thinkingdata
drwxrwxr-x. 1 nfsnobody nfsnobody 429528580220 Aug 25 12:42 1.4
drwxrwxr-x. 1 nfsnobody nfsnobody   9762013184 Aug 25 16:42 1.4_oem_daasbank
drwxr-xr-x. 3 root      root                18 Sep  2 10:46 1.4_oem_dassbank
drwxrwxr-x. 1 nfsnobody nfsnobody  11154866176 Jan  6 17:17 2.1
root@apidoc:/mnt/cone$ 

root@apidoc:/mnt$ cd centos7/
root@apidoc:/mnt/centos7$ ll
total 0
drwxrwxr-x. 1 nfsnobody nfsnobody 139628591104 Aug 16  2021 8.0
drwxrwxr-x. 1 nfsnobody nfsnobody 413614030848 Aug 16  2021 8.2
drwxrwxr-x. 1 nfsnobody nfsnobody 443107670532 Jan  6 15:47 8.3
root@apidoc:/mnt/centos7$ cd 8.3/
root@apidoc:/mnt/centos7/8.3$ ll
total 0
drwxr-xr-x. 1 nfsnobody nfsnobody            0 Dec  2  2021 converger
drwxr-xr-x. 1 nfsnobody nfsnobody 453293586948 Jan 10 06:09 scaler
root@apidoc:/mnt/centos7/8.3$ 
</code></pre>
<h2 id="code-8-x-iso-scp-sh-code"><code>8.x_iso_scp.sh</code></h2>
<pre><code class="language-shell">#!/bin/bash

all_versions=(8.3 8.2 8.0)
scp_shell="/root/sftp_iso.sh"
iso_sync_file="/tmp/iso_sync.txt"
log_file="/var/log/sftp_sync_is.log"

if [  ! -f ${scp_shell} ]; then
   echo "[ERROR] scp_iso.sh not exist, exit!!!"
   exit 1
fi

if [  -f ${iso_sync_file} ]; then
    rm -rf ${iso_sync_file}
fi

LOCK_FILE=/tmp/iso_sync.lock
exec 100&gt;"$LOCK_FILE"
flock -n 100
if [ "$?" != 0 ]; then
    echo "[Process Check] $0 This Script Has Old Process Running, exit..."
    exit 1
fi
# 因primjs markdown的渲染问题，这里井号前加了\，实际使用需要拿掉\
for(( i=0;i&lt;${\#all_versions[@]};i++)) 
do
    echo "Srart to sync ${all_versions[i]}"
    bash ${scp_shell} scaler xenial ${all_versions[i]}
    bash ${scp_shell} scaler centos7 ${all_versions[i]}
done;

# bash ${scp_shell} cone cone 1.2
# bash ${scp_shell} cone cone 1.2_oem_putian
# bash ${scp_shell} cone cone 1.2_oem_fiberhome
# bash ${scp_shell} cone cone 1.2_oem_thinkingdata
# bash ${scp_shell} cone cone 1.2_oem_xinzhe
# bash ${scp_shell} cone cone 1.2_oem_xinzhe_dark
bash ${scp_shell} cone cone 1.3
# bash ${scp_shell} cone cone 1.3_oem_fiberhome
# bash ${scp_shell} cone cone 1.3_oem_thinkingdata
# bash ${scp_shell} scaler xenial 8.0_oem_fiberhome
# bash ${scp_shell} scaler xenial 8.0_oem_putian
# bash ${scp_shell} scaler xenial 8.2_oem_fiberhome
# bash ${scp_shell} scaler xenial 8.2_oem_thinkingdata
# bash ${scp_shell} scaler xenial 8.2_oem_chaoyun
# bash ${scp_shell} scaler xenial 8.0_oem_hygon
# bash ${scp_shell} scaler xenial 8.0_oem_srie
bash ${scp_shell} cone cone 1.4
# bash ${scp_shell} cone cone 1.4_oem_Dassbank
bash ${scp_shell} cone cone 2.1


function wait_task_finished(){
if [ -f ${iso_sync_file} ]; then
    while [ "1" = "1" ]
        do
            current_time=`date "+%Y-%m-%d %H:%M:%S"`
            iso_sync_res=`cat ${iso_sync_file} | awk '{{print $NF}}' | grep -vi md5`
            array=(${iso_sync_res// / })
            for var in ${array[@]}
            do
                ps_res=`ps -ef | grep ${var} |grep -v grep`
                if [[ ! ${ps_res} ]]; then
                    echo -e "[${current_time}]  Finished to sync : ${var}" | tee -a ${log_file}
                    sed -i "/${var}/d" ${iso_sync_file}
                else
                    echo -e "[${current_time}]  ISO : (${var}) sync ongoing" | tee -a ${log_file}
                fi
            done
            sleep 60
        done
else
    current_time=`date "+%Y-%m-%d %H:%M:%S"`
    echo -e "[${current_time}]  [ERROR]  Not find file : (${iso_sync_file}), no need to check ISO sync stats. exit!!!" | tee -a ${log_file}
    exit 8
fi
}

wait_task_finished
</code></pre>
<h2 id="code-sftp-iso-sh-code"><code>sftp_iso.sh</code></h2>
<pre><code class="language-shell">#!/bin/bash

if [ ! -n "$3" ] ;
then
    echo -e "\033[33musage: sftp_iso.sh [scaler/converger/cone] [centos7/xenial/cone] [version]"
    exit 0
fi

sftp_host="21.22.26.12"
sftp_user="ftpusername"
sftp_password="ftpuserpassword"
sftp_port=22
log_file="/var/log/sftp_sync_is.log"
iso_sync_file="/tmp/iso_sync.txt"

product=$1
product_type=$2
product_version=$3

case $product in
         scaler | converger | cone)
           current_time=`date "+%Y-%m-%d %H:%M:%S"`
           echo -e "\n======================================================  [${current_time}]  =================================================" | tee -a ${log_file}
           echo -e "[${current_time}]  Product is $product." | tee -a ${log_file}
         ;;
         *)
           echo "[${current_time}]  [ERROR]  Product must be scaler/converger/cone, script exits!"
           exit 1
         ;;
esac


case ${product_version} in
         8.0 | 8.2 | 8.3 | 1.0 | 1.2 | 1.2_oem_putian | 1.2_oem_fiberhome | 1.2_oem_thinkingdata | 1.2_oem_xinzhe | 1.2_oem_xinzhe_dark | 1.3 | 1.3_oem_fiberhome | 1.3_oem_thinkingdata | 1.4 | 1.4_oem_daasbank | 2.1 | 8.0_oem_fiberhome | 8.0_oem_putian | 8.2_oem_thinkingdata | 8.2_oem_fiberhome | 8.2_oem_chaoyun | 8.0_oem_hygon | 8.0_oem_srie)
           current_time=`date "+%Y-%m-%d %H:%M:%S"`
           echo -e "[${current_time}]  Version is ${product_version}" | tee -a ${log_file}
         ;;
         *)
           echo -e "\033[31mVersion must be 8.0 8.2 8.3 1.2 1.2_oem_putian 1.2_oem_fiberhome 1.2_oem_thinkingdata 1.2_oem_xinzhe 1.2_oem_xinzhe_dark 1.3 1.3_oem_fiberhome 1.3_oem_thinkingdata 1.4 1.4_oem_daasbank 8.0_oem_fiberhome 8.0_oem_putian 8.2_oem_thinkingdata 8.2_oem_fiberhome 8.2_oem_chaoyun 8.0_oem_hygon 8.0_oem_srie, script exits!!! "
           exit 6
         ;;
esac


function check_mount_point(){
    if [ ! -d "$1" ]; then
        echo -e "[ERROR]  Path : ($1 not exist, exit!!!) "
        exit 2
    else
       mnt_res=`mountpoint $1`
       if [[ ${mnt_res} =~ "is not a" ]]; then
           echo -e "[ERROR]  Path : ($1) is not a mountpoint, exit!!! "
           exit 3
       fi
    fi
}


function iso_download()
{
    list_build_id_res="/tmp/ls_build_id.output"
    list_builds_res="/tmp/ls_builds.output"

    if [ X${product} = X"scaler" ]; then
        if [ X${product_version} = X"8.0" ]; then
            remote_path="scaler/virtualstor_8.0/builds"
            if [ X${product_type} = X'xenial' ]; then
                mnt_path="/mnt/xenial/8.0"
                local_path="${mnt_path}/scaler"
            elif [ X${product_type} = X'centos7' ]; then
                mnt_path="/mnt/centos7/8.0"
                local_path="${mnt_path}/scaler"
            fi
            check_mount_point ${mnt_path}
        elif [ X${product_version} = X"8.2" ]; then
            remote_path="scaler/virtualstor_8.2/builds"
            if [ X${product_type} = X'xenial' ]; then
                mnt_path="/mnt/xenial/8.2"
                local_path="${mnt_path}/scaler"
            elif [ X${product_type} = X'centos7' ]; then
                mnt_path="/mnt/centos7/8.2"
                local_path="${mnt_path}/scaler"
            fi
            check_mount_point ${mnt_path}
        elif [ X${product_version} = X"8.3" ]; then
            remote_path="scaler/virtualstor_8.3/builds"
            if [ X${product_type} = X'xenial' ]; then
                mnt_path="/mnt/xenial/8.3"
                local_path="${mnt_path}/scaler"
            elif [ X${product_type} = X'centos7' ]; then
                mnt_path="/mnt/centos7/8.3"
                local_path="${mnt_path}/scaler"
            fi
            check_mount_point ${mnt_path}
        fi
    fi

    if [ X${product} = X"cone" ]; then
        if [ X${product_version} = X"1.0" ]; then
            remote_path="cone/virtualstor_converger_one_1.0/builds"
            mnt_path="/mnt/cone/1.0"
            local_path="${mnt_path}/cone"
            check_mount_point ${mnt_path}
        elif [ X${product_version} = X"1.2" ]; then
            remote_path="cone/virtualstor_converger_one_1.2/builds"
            mnt_path="/mnt/cone/1.2"
            local_path="${mnt_path}/cone"
            check_mount_point ${mnt_path}
        elif [ X${product_version} = X"1.3" ]; then
            remote_path="cone/virtualstor_converger_one_1.3/builds"
            mnt_path="/mnt/cone/1.3"
            local_path="${mnt_path}/cone"
            check_mount_point ${mnt_path}
        elif [ X${product_version} = X"1.4" ]; then
            remote_path="cone/virtualstor_converger_one_1.4/builds"
            mnt_path="/mnt/cone/1.4"
            local_path="${mnt_path}/cone"
            check_mount_point ${mnt_path}
        elif [ X${product_version} = X"2.1" ]; then
            remote_path="cone/virtualstor_converger_one_2.1/builds"
            mnt_path="/mnt/cone/2.1"
            local_path="${mnt_path}/cone"
            check_mount_point ${mnt_path}
        fi
    fi

    current_time=`date "+%Y-%m-%d %H:%M:%S"`
    echo -e "[${current_time}]  Will to get latest ISO file for : (${product} ${product_version} ${product_type}) from remote path : (${remote_path})" | tee -a ${log_file}

    # If file exist, delete it first
    if [ -f "${list_build_id_res}" ]; then
        rm -rf ${list_build_id_res}
    fi

    lftp sftp://${sftp_user}:${sftp_password}@${sftp_host} -e "ls ${remote_path} | grep -v latest; bye" | tee ${list_build_id_res}
    if [ ! -f "${list_build_id_res}" ]; then
        current_time=`date "+%Y-%m-%d %H:%M:%S"`
        echo -e "[${current_time}]  [ERROR]  Not get build id info to local, please to check lftp command, exit!!!" | tee -a ${log_file}
        exit 4
    fi

    latest_build_id=`awk '{print $NF}' ${list_build_id_res} | grep -v '\.' | sort -nr | head -n1`
    latest_build_id=${latest_build_id//$'\r'}
    current_time=`date "+%Y-%m-%d %H:%M:%S"`
    echo -e "[${current_time}]  Latest Build id : ${latest_build_id}" | tee -a ${log_file}

    # If builds info of file exist, delete it
    if [ -f "${list_builds_res}" ]; then
        rm -rf ${list_builds_res}
    fi

    lftp sftp://${sftp_user}:${sftp_password}@${sftp_host} -e "ls ${remote_path}/${latest_build_id}; bye" | tee ${list_builds_res}
    
    if [ ! -f "${list_builds_res}" ]; then
        current_time=`date "+%Y-%m-%d %H:%M:%S"`
        echo -e "[${current_time}]  [ERROR]  Not get builds info to local, please to check lftp command, exit!!!" | tee -a ${log_file}
        exit 5
    fi

    if [ X${product_type} = X"cone" ]; then
        if [[ X${product_version} = X"1.4" ]]; then
            current_time=`date "+%Y-%m-%d %H:%M:%S"`
            echo -e "[${current_time}]  ConevergerOne Product and version is 1.4" | tee -a ${log_file}
            build_day_str_lines=`cat ${list_builds_res} | awk '{{print $NF}}' | grep iso | awk -F '~' '{{print $2}}' | uniq | cut -b 1-8 | uniq | awk '{print NF}'`
            build_day_str=`cat ${list_builds_res} | awk '{{print $NF}}' | grep iso | awk -F '~' '{{print $2}}' | uniq | cut -b 1-8 | uniq`
        elif [[ X${product_version} &gt; X"2.0" ]]; then
            current_time=`date "+%Y-%m-%d %H:%M:%S"`
            echo -e "[${current_time}]  ConevergerOne Product and version is &gt;= 2.1" | tee -a ${log_file}
            build_day_str_lines=`cat ${list_builds_res} | awk '{{print $NF}}' | grep iso | awk -F '-' '{{print $6}}' | uniq | cut -b 1-8 | uniq | awk '{print NF}'`
            build_day_str=`cat ${list_builds_res} | awk '{{print $NF}}' | grep iso | awk -F '-' '{{print $6}}' | uniq | cut -b 1-8 | uniq`
        else
            current_time=`date "+%Y-%m-%d %H:%M:%S"`
            echo -e "[${current_time}]  ConevergerOne Product and version is &lt;=1.3" | tee -a ${log_file}
            build_day_str_lines=`cat ${list_builds_res} | grep iso | awk '{{print $NF}}' | awk -F '~' '{{print $2}}' | cut -b 1-8 | uniq | awk '{print NF}'`
            build_day_str=`cat ${list_builds_res} | grep iso | awk '{{print $NF}}' | awk -F '~' '{{print $2}}' | cut -b 1-8 | uniq`
        fi
    else
        current_time=`date "+%Y-%m-%d %H:%M:%S"`
        echo -e "[${current_time}]  Scaler Product" | tee -a ${log_file}
        build_day_str_lines=`cat ${list_builds_res} | grep iso | awk '{{print $NF}}' | awk -F '~' '{{print $2}}' | cut -b 1-8 | uniq | awk '{print NF}'`
        build_day_str=`cat ${list_builds_res} | grep iso | awk '{{print $NF}}' | awk -F '~' '{{print $2}}' | cut -b 1-8 | uniq`
    fi

    if [[ ${build_day_str_lines} -gt 1 ]]; then
        current_time=`date "+%Y-%m-%d %H:%M:%S"`
        echo -e "[${current_time}]  [ERROR]  Find different days from path of ($(remote_path)), exit!!!" | tee -a ${log_file}
        echo -e "[Debug] ${build_day_str}" | tee -a ${log_file}
        exit 6
    fi

    # build_day_str, like this: 20230106
    year=`echo ${build_day_str} | cut -b 1-4`
    month=`echo ${build_day_str} | cut -b 5-6`
    day=`echo ${build_day_str} | cut -b 7-8`
    daily_folder="${year}-${month}-${day}"
    if [[ ${daily_folder} =~ "--" ]]; then
        current_time=`date "+%Y-%m-%d %H:%M:%S"`
        echo -e "[${current_time}]  [ERROR]  Wrong type of daily folder name, exit!!!"
        exit 7
    fi

    if [ ! -d "${local_path}/${daily_folder}" ]; then
        current_time=`date "+%Y-%m-%d %H:%M:%S"`
        echo -e "[${current_time}]  Local path has no folder of ${local_path}/${daily_folder}, now create it" | tee -a ${log_file}
        mkdir -p ${local_path}/${daily_folder}
    fi

    # If local path has the file, which size and build id same as remote, skip to sync
    if [ X${product_type} = X"cone" ]; then
        product_type="ConvergerOne"
    fi
    remote_iso_name=`cat ${list_builds_res} | grep -i iso | grep -vi md5 | grep -i ${product_type} | awk '{{print $9, $10}}'`
    remote_iso_name=`echo ${remote_iso_name} | sed -e 's/^[ \t]*//g'`
    array=(${remote_iso_name// / })
    # 下面这里的井号前的\，实际使用时需拿掉\
    if [[ ${\#array[@]} -gt 1 &amp;&amp; ${remote_iso_name} =~ "ConvergerOne" ]]; then
        # If has more than one ISO under remote folder
        for var in ${array[@]}
            do
                remote_iso_size=`cat ${list_builds_res} | grep ${var} | grep -v md5 | grep -i ${product_type} | awk '{{print $5}}'`
                local_iso_size=`ls -l ${local_path}/${daily_folder} | grep -vi md5 | grep -vi total | grep ${var} | awk '{{print $5}}'`
                if [ X${remote_iso_size} = X${local_iso_size} ]; then
                    current_time=`date "+%Y-%m-%d %H:%M:%S"`
                    echo -e "[${current_time}]  [SKIP]  Has been synced ISO : (${remote_path}/${latest_build_id}/${var}) to (${local_path}/${daily_folder})" | tee -a ${log_file}
                else
                    current_time=`date "+%Y-%m-%d %H:%M:%S"`
                    echo -e "[${current_time}]  Start to get ISO :(${remote_path}/${latest_build_id}/${var}) to : (${local_path}/${daily_folder}) at backend" | tee -a ${log_file}
                    echo ${var} &gt;&gt; ${iso_sync_file}
                    lftp sftp://${sftp_user}:${sftp_password}@${sftp_host} -e "lcd ${local_path}/${daily_folder};reget '${remote_path}/${latest_build_id}/${var}'; reget '${remote_path}/${latest_build_id}/${var}.md5'; bye"&amp;
                    # lftp sftp://${sftp_user}:${sftp_password}@${sftp_host} -e "lcd ${local_path}/${daily_folder};reget '${remote_path}/${latest_build_id}/${var}'; reget '${remote_path}/${latest_build_id}/${var}.md5'; bye"
                fi
            done
    else
        # Only one ISO under the remote folder
        remote_iso_size=`cat ${list_builds_res} | grep iso | grep -v md5 | grep -i ${product_type} | awk '{{print $5}}'`
        local_iso_size=`ls -l ${local_path}/${daily_folder} | grep -vi md5 | grep -vi total | grep ${latest_build_id} | awk '{{print $5}}'`
        # remote_iso_name=${remote_iso_name//$'\r'}
        # remote_iso_size=${remote_iso_size//$'\r'}
        # local_iso_size=${local_iso_size//$'\r'}
        if [[ X${remote_iso_size} = X${local_iso_size} ]]; then
            current_time=`date "+%Y-%m-%d %H:%M:%S"`
            echo -e "[${current_time}]  [SKIP]  Has been synced ISO : (${remote_path}/${latest_build_id}/${remote_iso_name}) to (${local_path}/${daily_folder})" | tee -a ${log_file}
        else
            current_time=`date "+%Y-%m-%d %H:%M:%S"`
            echo -e "[${current_time}]  Start to get ISO :(${remote_path}/${latest_build_id}/${remote_iso_name}) to : (${local_path}/${daily_folder}) at backend" | tee -a ${log_file}
            echo ${remote_iso_name} &gt;&gt; ${iso_sync_file}
            lftp sftp://${sftp_user}:${sftp_password}@${sftp_host} -e "lcd ${local_path}/${daily_folder};reget '${remote_path}/${latest_build_id}/${remote_iso_name}'; reget '${remote_path}/${latest_build_id}/${remote_iso_name}.md5'; bye"&amp;
            # lftp sftp://${sftp_user}:${sftp_password}@${sftp_host} -e "lcd ${local_path}/${daily_folder};reget '${remote_path}/${latest_build_id}/${remote_iso_name}'; reget '${remote_path}/${latest_build_id}/${remote_iso_name}.md5'; bye"
        fi
    fi
}


iso_download

# function iso_download()
# {
#     expect &lt;&lt;- EOF
#     set timeout 1800
#     spawn sftp -P $sftp_port $sftp_user@$sftp_host
# 
#     expect { 
#         "(yes/no)?" {send "yes\r"; expect_continue }
#         "*assword:" {send "$sftp_password\r"}
#     }
#     expect "sftp&gt;"
#     send "cd $sftpLoadPath \r"
#     expect "sftp&gt;"
#     send "lcd $myDir \r"
#     expect "sftp&gt;"
#     set timeout -1
#     send "reget $fileFilter \r"
#     expect "sftp&gt;"
#     send "bye\r"
# EOF
# }
</code></pre>
<h1 id="e-wai-bu-chong">额外补充</h1>
<p>这里有一个当时碰到的问题，就是如何同remote端目录结构下最后一个Build ID，当时有参考：</p>
<pre><code class="language-shell">https://stackoverflow.com/questions/49678020/how-to-get-the-latest-file-from-sftp-folder
</code></pre>
<p>虽然没有使用到，但这里mark一下，防止未来有碰到类似状况需要这篇文章中的操作指令。</p>
<p>最后自己的解决方法是整个list出来到本次文件，从本地文件中grep出来。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>一键安装 docker 的 shell 脚本</title>
    <url>/2023/01/19/install_docker_with_shell/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>一键安装Docker的shell脚本，脚本比较粗糙，将就用。</p>
<h1 id="script-content">Script Content</h1>
<pre><code class="language-shell">yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine


echo -e " =========== 1.delete exist docker ================\n\n"

echo -e "step 1: 安装必要的一些系统工具"
sudo yum install -y yum-utils device-mapper-persistent-data lvm2

echo -e "\n\nStep 2: 添加软件源信息，国内 Repository 更加稳定"
sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

version=sudo cat /etc/redhat-release|sed -r 's/.* ([0-9]+)\..*/\1/'

if $version=7; then
        echo  -e "\n\nStep 3: 更新 Centos version is : $version; run yum makecache fast"
        sudo yum makecache fast
elif $version=8; then
        echo -e "\n\nStep 3: 更新Centos version is : $version; run yum makecache fast"
        sudo dnf makecache
fi

echo -e "=========== 2.完成配置 docker Repository ================\n\n"

# 安装最新版本的 Docker Engine 和 Container
sudo yum install docker-ce docker-ce-cli containerd.io
sudo yum -y install docker-ce


echo -e "=========== 3.成功安装完 docker ================\n\n"

sudo systemctl enable docker
sudo systemctl start docker

echo -e "=========== 4.自启动 docker ================\n\n"


# 1.创建一个目录
sudo mkdir -p /etc/docker


# 2.编写配置文件
sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'
{
  "registry-mirrors": ["http://hub-mirror.c.163.com",
    "https://docker.mirrors.ustc.edu.cn",
    "https://reg-mirror.qiniu.com",
    "http://f1361db2.m.daocloud.io"
  ]
}
EOF


sudo systemctl daemon-reload
sudo systemctl restart docker

echo -e "=========== 5.配置国内镜像加速 ================\n\n"

docker ps -a
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux stat家族之mpstat</title>
    <url>/2023/01/19/linux_stat_family_of_mpstat/</url>
    <content><![CDATA[<h1 id="jie-shao">介绍</h1>
<p>此指令输出 CPU 负载相关信息。</p>
<h2 id="mpstat-zhu-yao-neng-kan-shi-yao-xing-neng-zhi-biao">mpstat 主要能看什么性能指标</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>每个 CPU 的不同类型 CPU 使用率、不同软中断类型次数统计、总中断次数</p>
</li>
<li class="lvl-2">
<p>上述所有 CPU 的平均数据</p>
</li>
</ul>
<h1 id="yu-fa-ge-shi">语法格式</h1>
<pre><code class="language-shell">mpstat [ -A ] [ -n ] [ -u ] [ -V ] [ -I { keyword [,...] | ALL } ] [ -N { node_list | ALL } ] [ -o JSON] [ -P { cpu_list | ON | ALL } ] [ interval [ count ] ]
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>interval ：间隔多久统计一次数据，可选</p>
</li>
<li class="lvl-2">
<p>count：统计一次，可选</p>
</li>
</ul>
<p>注意：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>若只传了 interval ，则统计次数是无限次，结束统计后会打印本次所有数据的平均值.</p>
</li>
</ul>
<h2 id="li-zi">例子</h2>
<p><code>mpstat 1 </code></p>
<p>每隔 1s 统计打印一次数据，统计无限次</p>
<p><code>mpstat 2 5</code></p>
<p>每隔 2s 统计打印一次数据，共统计 5 次</p>
<h1 id="tong-ji-xin-xi-de-zi-duan-shuo-ming">统计信息的字段说明</h1>
<p>最基础的命令</p>
<pre><code class="language-shell">[root@node81 ~]# mpstat 1 2
Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)


05:39:30 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:39:31 PM  all    0.38    0.00    0.25    0.00    0.00    0.00    0.00    0.00    0.00   99.37
05:39:32 PM  all    1.01    0.00    2.90    0.00    0.00    0.00    0.00    0.00    0.00   96.09
Average:     all    0.69    0.00    1.57    0.00    0.00    0.00    0.00    0.00    0.00   97.74
[root@node81 ~]# 
</code></pre>
<p>字段说明</p>
<table>
<thead>
<tr>
<th>字  段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>CPU编号，all代表全部CPU的平均值</td>
</tr>
<tr>
<td>%usr</td>
<td>用户态CPU使用率</td>
</tr>
<tr>
<td>%nice</td>
<td>高优先级的用户态CPU使用率</td>
</tr>
<tr>
<td>%sys</td>
<td>内核态CPU使用率</td>
</tr>
<tr>
<td>%iowast</td>
<td>iowait CPU使用率</td>
</tr>
<tr>
<td>%irq</td>
<td>硬中断CPU使用率</td>
</tr>
<tr>
<td>%soft</td>
<td>软中断CPU使用率</td>
</tr>
<tr>
<td>%steal</td>
<td>被虚拟处理器’偷’走的CPU百分比</td>
</tr>
<tr>
<td>%guest</td>
<td>运行虚拟处理器CPU使用率</td>
</tr>
<tr>
<td>%gnice</td>
<td>运行高优先级的虚拟处理器CPU使用率</td>
</tr>
<tr>
<td>%idle</td>
<td>空闲CPU百分比</td>
</tr>
</tbody>
</table>
<h1 id="ming-ling-xing-can-shu">命令行参数</h1>
<table>
<thead>
<tr>
<th>字  段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-V</td>
<td>版本信息</td>
</tr>
<tr>
<td>-u</td>
<td>打印CPU统计信息，默认就有</td>
</tr>
<tr>
<td>-p</td>
<td>需要输出统计信息的CPU</td>
</tr>
<tr>
<td>-o JSON</td>
<td>json格式输出结果</td>
</tr>
<tr>
<td>-l</td>
<td>报告中断情况</td>
</tr>
</tbody>
</table>
<h2 id="code-p-cpu-list-on-all-code"><code>-P { cpu_list | ON | ALL }</code></h2>
<h3 id="zuo-yong">作用</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>指定要报告其统计信息的 CPU</p>
</li>
<li class="lvl-2">
<p>cpu_list：是用 , 分隔的值或值范围的列表（例如 0,2,4-7,0-1 ）</p>
</li>
<li class="lvl-2">
<p>ON：将为每个联机 CPU 报告统计信息</p>
</li>
<li class="lvl-2">
<p>ALL：将为所有 CPU 报告统计信息</p>
</li>
</ul>
<h3 id="cpu-list-de-li-zi">cpu_list 的例子</h3>
<p>只指定 CPU1</p>
<p><code>mpstat -P 1 1 2</code></p>
<pre><code class="language-shell">[root@node81 ~]# mpstat -P 1 1 2
Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)

05:56:16 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:56:17 PM    1    0.00    0.00    5.94    0.00    0.00    0.00    0.00    0.00    0.00   94.06
05:56:18 PM    1    1.01    0.00    5.05    0.00    0.00    0.00    0.00    0.00    0.00   93.94
Average:       1    0.50    0.00    5.50    0.00    0.00    0.00    0.00    0.00    0.00   94.00
[root@node81 ~]# 
</code></pre>
<p>指定CPU0、CPU1</p>
<p><code>mpstat -P 0,1 1 2</code></p>
<pre><code class="language-shell">[root@node81 ~]# mpstat -P 0,1 1 2
Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)

05:57:48 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:57:49 PM    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:57:49 PM    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:57:50 PM    0    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:57:50 PM    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
Average:       0    0.50    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.50
Average:       1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
[root@node81 ~]# 
</code></pre>
<h3 id="on-de-li-zi">ON 的例子</h3>
<p><code>mpstat -P ON 1 2</code></p>
<pre><code class="language-shell">[root@node81 ~]# mpstat -P ON 1 2
.Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)

05:58:07 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:58:08 PM  all    1.01    0.00    0.38    0.00    0.00    0.00    0.00    0.00    0.00   98.62
05:58:08 PM    0    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:58:08 PM    1    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99
05:58:08 PM    2    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
05:58:08 PM    3    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99
05:58:08 PM    4    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:58:08 PM    5    0.99    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.01
05:58:08 PM    6    4.04    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   95.96
05:58:08 PM    7    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00

05:58:08 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:58:09 PM  all    1.25    0.00    2.38    0.00    0.00    0.13    0.00    0.00    0.00   96.25
05:58:09 PM    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:58:09 PM    1    4.04    0.00   10.10    0.00    0.00    0.00    0.00    0.00    0.00   85.86
05:58:09 PM    2    1.98    0.00    1.98    0.00    0.00    0.00    0.00    0.00    0.00   96.04
05:58:09 PM    3    2.02    0.00    6.06    0.00    0.00    0.00    0.00    0.00    0.00   91.92
05:58:09 PM    4    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:58:09 PM    5    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:58:09 PM    6    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:58:09 PM    7    0.99    0.00    0.99    0.00    0.00    0.00    0.00    0.00    0.00   98.02

Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
Average:     all    1.13    0.00    1.38    0.00    0.00    0.06    0.00    0.00    0.00   97.43
Average:       0    0.50    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.50
Average:       1    2.53    0.00    5.05    0.00    0.00    0.00    0.00    0.00    0.00   92.42
Average:       2    1.49    0.00    1.49    0.00    0.00    0.00    0.00    0.00    0.00   97.01
Average:       3    1.52    0.00    3.03    0.00    0.00    0.00    0.00    0.00    0.00   95.45
Average:       4    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
Average:       5    0.50    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.50
Average:       6    2.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.99
Average:       7    0.50    0.00    0.50    0.00    0.00    0.00    0.00    0.00    0.00   98.99
[root@node81 ~]#
</code></pre>
<h3 id="all-de-li-zi">ALL 的例子</h3>
<p><code>mpstat -P ALL 1 2</code></p>
<pre><code class="language-shell">[root@node81 ~]# mpstat -P ALL 1 2
Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)

05:59:25 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:59:26 PM  all    0.38    0.00    1.50    0.00    0.00    0.00    0.00    0.00    0.00   98.12
05:59:26 PM    0    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:59:26 PM    1    1.00    0.00    6.00    0.00    0.00    0.00    0.00    0.00    0.00   93.00
05:59:26 PM    2    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:59:26 PM    3    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:59:26 PM    4    0.00    0.00    4.04    0.00    0.00    0.00    0.00    0.00    0.00   95.96
05:59:26 PM    5    1.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:59:26 PM    6    0.99    0.00    0.99    0.00    0.00    0.00    0.00    0.00    0.00   98.02
05:59:26 PM    7    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00

05:59:26 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:59:27 PM  all    0.63    0.00    0.25    0.00    0.00    0.00    0.00    0.00    0.00   99.12
05:59:27 PM    0    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
05:59:27 PM    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:59:27 PM    2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:59:27 PM    3    2.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   97.00
05:59:27 PM    4    0.99    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.01
05:59:27 PM    5    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:59:27 PM    6    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
05:59:27 PM    7    0.00    0.00    0.99    0.00    0.00    0.00    0.00    0.00    0.00   99.01

Average:     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
Average:     all    0.50    0.00    0.88    0.00    0.00    0.00    0.00    0.00    0.00   98.62
Average:       0    0.50    0.00    0.50    0.00    0.00    0.00    0.00    0.00    0.00   99.00
Average:       1    0.50    0.00    3.02    0.00    0.00    0.00    0.00    0.00    0.00   96.48
Average:       2    0.00    0.00    0.50    0.00    0.00    0.00    0.00    0.00    0.00   99.50
Average:       3    1.50    0.00    0.50    0.00    0.00    0.00    0.00    0.00    0.00   98.00
Average:       4    0.50    0.00    2.00    0.00    0.00    0.00    0.00    0.00    0.00   97.50
Average:       5    0.50    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.50
Average:       6    0.50    0.00    0.50    0.00    0.00    0.00    0.00    0.00    0.00   99.00
Average:       7    0.00    0.00    0.50    0.00    0.00    0.00    0.00    0.00    0.00   99.50
[root@node81 ~]#
</code></pre>
<p>重点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>0 是第一个 CPU</p>
</li>
<li class="lvl-2">
<p>all 是所有处理器之间的全局平均值</p>
</li>
</ul>
<h2 id="code-i-keyword-all-code"><code>-I { keyword [,...] | ALL }</code></h2>
<h3 id="zuo-yong-1">作用</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>输出中断统计信息</p>
</li>
<li class="lvl-2">
<p>keyword 可以输入：CPU、SCPU、SUM、ALL</p>
</li>
<li class="lvl-2">
<p>CPU：显示每秒中断数量，从 /proc/interrupts 读取数据</p>
</li>
<li class="lvl-2">
<p>SCPU：显示每秒软中断数量，从 /proc/softirqs 读取数据</p>
</li>
<li class="lvl-2">
<p>SUM：显示每个处理器的中断总数</p>
</li>
<li class="lvl-2">
<p>ALL：输出上面三个关键字的所有内容</p>
</li>
</ul>
<h3 id="scpu-de-li-zi">SCPU 的例子</h3>
<p><code>mpstat -I SCPU 1 2 -P ALL</code></p>
<pre><code class="language-shell">[root@node81 ~]# mpstat -I SCPU 1 2 -P ALL
Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)

05:59:53 PM  CPU       HI/s    TIMER/s   NET_TX/s   NET_RX/s    BLOCK/s IRQ_POLL/s  TASKLET/s    SCHED/s  HRTIMER/s      RCU/s
05:59:54 PM    0       0.00       9.00       1.00       0.00       0.00       0.00       0.00      12.00       0.00       8.00
05:59:54 PM    1       0.00      11.00       0.00       3.00       0.00       0.00       0.00       8.00       0.00      10.00
05:59:54 PM    2       0.00      36.00       0.00       4.00       0.00       0.00       0.00      18.00       0.00      15.00
05:59:54 PM    3       0.00       9.00       0.00       1.00       0.00       0.00       0.00       9.00       0.00       7.00
05:59:54 PM    4       0.00       6.00       0.00       2.00       0.00       0.00       0.00       6.00       0.00       5.00
05:59:54 PM    5       0.00      98.00       0.00      14.00       0.00       0.00       0.00      23.00       0.00      51.00
05:59:54 PM    6       0.00      13.00       0.00       1.00       0.00       0.00       0.00       7.00       0.00       9.00
05:59:54 PM    7       0.00     114.00       0.00      16.00       0.00       0.00       0.00      31.00       0.00      58.00

05:59:54 PM  CPU       HI/s    TIMER/s   NET_TX/s   NET_RX/s    BLOCK/s IRQ_POLL/s  TASKLET/s    SCHED/s  HRTIMER/s      RCU/s
05:59:55 PM    0       0.00      27.00       0.00      18.00       1.00       0.00       0.00      18.00       0.00      24.00
05:59:55 PM    1       0.00      55.00       0.00       9.00       0.00       0.00       0.00      17.00       0.00      40.00
05:59:55 PM    2       0.00      70.00       0.00      17.00       0.00       0.00       0.00      31.00       0.00      44.00
05:59:55 PM    3       0.00      37.00       0.00      30.00       0.00       0.00       2.00      14.00       0.00      31.00
05:59:55 PM    4       0.00      26.00       0.00       8.00       0.00       0.00       0.00      15.00       0.00      19.00
05:59:55 PM    5       0.00     109.00       0.00      18.00       0.00       0.00       0.00      33.00       0.00      67.00
05:59:55 PM    6       0.00      55.00       0.00       7.00       0.00       0.00       0.00      16.00       0.00      34.00
05:59:55 PM    7       0.00      96.00       0.00      14.00       0.00       0.00       0.00      25.00       0.00      55.00

Average:     CPU       HI/s    TIMER/s   NET_TX/s   NET_RX/s    BLOCK/s IRQ_POLL/s  TASKLET/s    SCHED/s  HRTIMER/s      RCU/s
Average:       0       0.00      18.00       0.50       9.00       0.50       0.00       0.00      15.00       0.00      16.00
Average:       1       0.00      33.00       0.00       6.00       0.00       0.00       0.00      12.50       0.00      25.00
Average:       2       0.00      53.00       0.00      10.50       0.00       0.00       0.00      24.50       0.00      29.50
Average:       3       0.00      23.00       0.00      15.50       0.00       0.00       1.00      11.50       0.00      19.00
Average:       4       0.00      16.00       0.00       5.00       0.00       0.00       0.00      10.50       0.00      12.00
Average:       5       0.00     103.50       0.00      16.00       0.00       0.00       0.00      28.00       0.00      59.00
Average:       6       0.00      34.00       0.00       4.00       0.00       0.00       0.00      11.50       0.00      21.50
Average:       7       0.00     105.00       0.00      15.00       0.00       0.00       0.00      28.00       0.00      56.50
[root@node81 ~]#
</code></pre>
<h3 id="sum-de-li-zi">SUM 的例子</h3>
<p>显示所有 CPU 平均中断次数</p>
<p><code>mpstat -I SUM 1 2</code></p>
<pre><code class="language-shell">[root@node81 ~]# mpstat -I SUM 1 2
Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)

06:00:15 PM  CPU    intr/s
06:00:16 PM  all   1597.00
06:00:17 PM  all   3912.00
Average:     all   2754.50
[root@node81 ~]# 
</code></pre>
<p>显示每个 CPU 的中断次数、所有 CPU 平均中断次数</p>
<p><code>mpstat -I SCPU 1 2 -P ALL</code></p>
<pre><code class="language-shell">[root@node81 ~]# mpstat -I SCPU 1 2 -P ALL
Linux 4.14.148-202207281639.git553ed7f (node81) 	01/19/2023 	_x86_64_	(8 CPU)

06:00:34 PM  CPU       HI/s    TIMER/s   NET_TX/s   NET_RX/s    BLOCK/s IRQ_POLL/s  TASKLET/s    SCHED/s  HRTIMER/s      RCU/s
06:00:35 PM    0       0.00      40.00       0.00       8.00       0.00       0.00       0.00      24.00       0.00      24.00
06:00:35 PM    1       0.00      65.00       0.00       7.00       0.00       0.00       0.00      24.00       0.00      43.00
06:00:35 PM    2       0.00      36.00       0.00       3.00       0.00       0.00       0.00      19.00       0.00      27.00
06:00:35 PM    3       0.00      23.00       0.00       0.00       0.00       0.00       0.00       9.00       0.00      17.00
06:00:35 PM    4       0.00      46.00       0.00      11.00       0.00       0.00       0.00      28.00       0.00      33.00
06:00:35 PM    5       0.00     183.00       0.00      26.00       0.00       0.00       0.00      49.00       0.00      98.00
06:00:35 PM    6       0.00      38.00       0.00       0.00       0.00       0.00       0.00      18.00       0.00      30.00
06:00:35 PM    7       0.00     150.00       0.00      16.00       0.00       0.00       0.00      42.00       0.00      81.00

06:00:35 PM  CPU       HI/s    TIMER/s   NET_TX/s   NET_RX/s    BLOCK/s IRQ_POLL/s  TASKLET/s    SCHED/s  HRTIMER/s      RCU/s
06:00:36 PM    0       0.00      19.00       0.00       0.00       1.00       0.00       0.00      18.00       0.00      13.00
06:00:36 PM    1       0.00      80.00       0.00      20.00       0.00       0.00       0.00      37.00       0.00      49.00
06:00:36 PM    2       0.00      75.00       0.00      16.00       0.00       0.00       0.00      29.00       0.00      43.00
06:00:36 PM    3       0.00      30.00       0.00       5.00       0.00       0.00       2.00      13.00       0.00      22.00
06:00:36 PM    4       0.00      46.00       0.00       5.00       0.00       0.00       0.00      28.00       0.00      28.00
06:00:36 PM    5       0.00      96.00       0.00      16.00       0.00       0.00       0.00      33.00       0.00      54.00
06:00:36 PM    6       0.00      25.00       0.00       1.00       0.00       0.00       0.00      16.00       0.00      16.00
06:00:36 PM    7       0.00     152.00       0.00      21.00       0.00       0.00       0.00      44.00       0.00      74.00

Average:     CPU       HI/s    TIMER/s   NET_TX/s   NET_RX/s    BLOCK/s IRQ_POLL/s  TASKLET/s    SCHED/s  HRTIMER/s      RCU/s
Average:       0       0.00      29.50       0.00       4.00       0.50       0.00       0.00      21.00       0.00      18.50
Average:       1       0.00      72.50       0.00      13.50       0.00       0.00       0.00      30.50       0.00      46.00
Average:       2       0.00      55.50       0.00       9.50       0.00       0.00       0.00      24.00       0.00      35.00
Average:       3       0.00      26.50       0.00       2.50       0.00       0.00       1.00      11.00       0.00      19.50
Average:       4       0.00      46.00       0.00       8.00       0.00       0.00       0.00      28.00       0.00      30.50
Average:       5       0.00     139.50       0.00      21.00       0.00       0.00       0.00      41.00       0.00      76.00
Average:       6       0.00      31.50       0.00       0.50       0.00       0.00       0.00      17.00       0.00      23.00
Average:       7       0.00     151.00       0.00      18.50       0.00       0.00       0.00      43.00       0.00      77.50
[root@node81 ~]#
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux stat家族之vmstat</title>
    <url>/2023/01/19/linux_stat_family_of_vmstat/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<ul class="lvl-0">
<li class="lvl-2">Virtual Meomory Statistics，报告虚拟内存统计信息</li>
<li class="lvl-2">统计进程信息、内存、交换区、IO、磁盘、CPU 等数据</li>
</ul>
<h1 id="vmstat-zhu-yao-neng-kan-shi-yao-xing-neng-zhi-biao">vmstat主要能看什么性能指标</h1>
<p>均是 Linux 系统级别</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>运行状态、不可中断睡眠状态的进程数量</p>
</li>
<li class="lvl-2">
<p>内存、交换区、I/O、CPU 信息</p>
</li>
<li class="lvl-2">
<p>上下文切换次数、中断次数</p>
</li>
<li class="lvl-2">
<p>磁盘 I/O 的详细信息和概要信息</p>
</li>
</ul>
<h1 id="yu-fa-ge-shi">语法格式</h1>
<pre><code class="language-shell">[root@node81 ~]# vmstat -h

Usage:
 vmstat [options] [delay [count]]

Options:
 -a, --active           active/inactive memory
 -f, --forks            number of forks since boot
 -m, --slabs            slabinfo
 -n, --one-header       do not redisplay header
 -s, --stats            event counter statistics
 -d, --disk             disk statistics
 -D, --disk-sum         summarize disk statistics
 -p, --partition &lt;dev&gt;  partition specific statistics
 -S, --unit &lt;char&gt;      define display unit
 -w, --wide             wide output
 -t, --timestamp        show timestamp

 -h, --help     display this help and exit
 -V, --version  output version information and exit

For more details see vmstat(8).
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>options：命令行参数，可选</p>
</li>
<li class="lvl-2">
<p>delay：间隔多久统计一次数据，可选</p>
</li>
<li class="lvl-2">
<p>count：统计一次，可选</p>
</li>
</ul>
<p>注意:<br>
若只传了 delay，则统计次数是无限次，结束统计后会打印本次所有数据的平均值.</p>
<h2 id="shi-li">示例</h2>
<p><code>vmstat 1 </code></p>
<p>每隔 1s 统计打印一次数据，统计无限次</p>
<p><code>vmstat 2 5 </code></p>
<p>每隔 2s 统计打印一次数据，共统计 5 次</p>
<h1 id="ming-ling-xing-can-shu">命令行参数</h1>
<table>
<thead>
<tr>
<th>简  写</th>
<th>完整写法</th>
<th>是否需要指定一个值</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>-a</td>
<td>–active</td>
<td>F</td>
<td>显示活动和非活动内存</td>
</tr>
<tr>
<td>-n</td>
<td>–one-header</td>
<td>F</td>
<td>仅显示一次标题，而不是定期显示</td>
</tr>
<tr>
<td>-s</td>
<td>–stats</td>
<td>F</td>
<td>获取内存、CPU、swap、中断次数、上下文切换次数等信息</td>
</tr>
<tr>
<td>-d</td>
<td>–disk</td>
<td>F</td>
<td>获取磁盘的读写详细信息</td>
</tr>
<tr>
<td>-D</td>
<td>–disk-sum</td>
<td>F</td>
<td>获取磁盘的一些摘要信息</td>
</tr>
<tr>
<td>-P</td>
<td>–partition device</td>
<td>T (Device)</td>
<td>有关分区的详细统计信息</td>
</tr>
<tr>
<td>-S</td>
<td>–unit character</td>
<td>T (character)</td>
<td>输出数值的单位，charactr取值:k,K,m or M(Default is K),k:1000;K:1024;m:1000000;M:1048576</td>
</tr>
<tr>
<td>-t</td>
<td>–timestamp</td>
<td>F</td>
<td>加一列，显示当前时间</td>
</tr>
<tr>
<td>-V</td>
<td>–version</td>
<td>F</td>
<td>显示版本信息</td>
</tr>
<tr>
<td>-h</td>
<td>–help</td>
<td>F</td>
<td>帮助信息</td>
</tr>
</tbody>
</table>
<h1 id="tong-ji-shu-ju-de-zi-duan-shuo-ming">统计数据的字段说明</h1>
<pre><code class="language-shell">[root@node81 ~]# vmstat 2 2
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 3549024 309900 938184    0    0    47    23  246  293  1  1 98  0  0
 2  0      0 3501380 309908 938184    0    0     0    30 3602 3698  1  6 93  0  0
[root@node81 ~]# 
</code></pre>
<p>共有 6 个模块</p>
<h2 id="procs-jin-cheng-zhuang-tai">procs：进程状态</h2>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>r</td>
<td>处于 Runnable状态的进程数量</td>
</tr>
<tr>
<td>b</td>
<td>处于不可中断睡眠状态的进程数量</td>
</tr>
</tbody>
</table>
<h2 id="memory-nei-cun-xin-xi">memory：内存信息</h2>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>swpd</td>
<td>已用虚拟内存</td>
</tr>
<tr>
<td>free</td>
<td>空闲内存</td>
</tr>
<tr>
<td>buff</td>
<td>用于缓冲区的内存</td>
</tr>
<tr>
<td>cache</td>
<td>用于缓存的内存</td>
</tr>
<tr>
<td>inact</td>
<td>不活动的内存量(-a)</td>
</tr>
<tr>
<td>active</td>
<td>活动的内存量(-a)</td>
</tr>
</tbody>
</table>
<h2 id="swap-jiao-huan-qu">swap：交换区</h2>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>si</td>
<td>每秒从交换区写到内存的大小</td>
</tr>
<tr>
<td>so</td>
<td>每秒写入交换区的内存大小</td>
</tr>
</tbody>
</table>
<h2 id="io-io-du-xie-xin-xi">io：io 读写信息</h2>
<p>现在的Linux版本块的大小为1024bytes</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>bi</td>
<td>每秒读取的块数</td>
</tr>
<tr>
<td>bo</td>
<td>每秒写入的块数</td>
</tr>
</tbody>
</table>
<h2 id="system-xi-tong-xin-xi">system：系统信息</h2>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>in</td>
<td>每秒中断数，包括时钟中断</td>
</tr>
<tr>
<td>cs</td>
<td>每秒上下文切换次数</td>
</tr>
</tbody>
</table>
<h2 id="cpu-cpu-xiang-xi-xin-xi">CPU：CPU 详细信息</h2>
<p>这些是总 CPU 时间的百分比</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>字段说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>us</td>
<td>用户态进程的CPU使用率</td>
</tr>
<tr>
<td>sy</td>
<td>内核态进程的CPU使用率</td>
</tr>
<tr>
<td>id</td>
<td>空闲CPU百分比</td>
</tr>
<tr>
<td>wa</td>
<td>等待IO的CPU使用率</td>
</tr>
<tr>
<td>st</td>
<td>从虚拟机偷取的CPU百分比</td>
</tr>
</tbody>
</table>
<h1 id="shu-ju-lai-yuan">数据来源</h1>
<p>主要来自这三个文件:</p>
<pre><code class="language-shell">/proc/meminfo
/proc/stat
/proc/*/stat
</code></pre>
<pre><code class="language-shell">[root@node81 ~]# vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 3379916 312036 942032    0    0    43    21  246  294  1  1 98  0  0
[root@node81 ~]# vmstat 1 2
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 3376784 312060 942032    0    0    43    21  246  294  1  1 98  0  0
 0  0      0 3376712 312060 942040    0    0     0     0 1082 1554  0  0 100  0  0
[root@node81 ~]# 
</code></pre>
<p>上面这些信息主要来自 /proc/stat</p>
<pre><code class="language-shell">[root@node81 ~]# vmstat -s
     12295904 K total memory
      7668944 K used memory
      7718024 K active memory
       457556 K inactive memory
      3372716 K free memory
       312164 K buffer memory
       942080 K swap cache
      6161404 K total swap
            0 K used swap
      6161404 K free swap
        50128 non-nice user cpu ticks
           22 nice user cpu ticks
        86934 system cpu ticks
      7102823 idle cpu ticks
        25004 IO-wait cpu ticks
            0 IRQ cpu ticks
         3045 softirq cpu ticks
            0 stolen cpu ticks
      3105928 pages paged in
      1531600 pages paged out
            0 pages swapped in
            0 pages swapped out
     17847205 interrupts
     21369346 CPU context switches
   1674110880 boot time
        92634 forks
[root@node81 ~]# 
</code></pre>
<p>上面这些信息的分别来自于 /proc/meminfo 、 /proc/stat 和 /proc/vmstat</p>
<pre><code class="language-shell">[root@node81 ~]# vmstat -d
disk- ------------reads------------ ------------writes----------- -----IO------
       total merged sectors      ms  total merged sectors      ms    cur    sec
fd0        0      0       0       0      0      0       0       0      0      0
sda    25592    955 1207050   96572  16120  31009  665696  290943      0     60
sdb    65035   1359 3634310  342617  59749 236139 2398312 7186627      0    110
sr0       18      0    2056      41      0      0       0       0      0      0
sdc      267      0    3888     359      0      0       0       0      0      0
sdd      512      0   16360     901      0      0       0       0      0      0
sde      832      0 1314536   11707      0      0       0       0      0      6
sdf      469      0   14288     692      0      0       0       0      0      0
sdg      267      0    3888     356      0      0       0       0      0      0
sdh      267      0    3888     399      0      0       0       0      0      0
sdi      267      0    3888     402      0      0       0       0      0      0
sdj      267      0    3888     355      0      0       0       0      0      0
sdk      267      0    3888     317      0      0       0       0      0      0
dm-0     162      0    8328     238      0      0       0       0      0      0
dm-1     205      0   10400     481      0      0       0       0      0      0
dm-2     525      0 1308576   11293      0      0       0       0      0      5
[root@node81 ~]# 
</code></pre>
<p>上面这些信息主要来自于 /proc/diskstats</p>
<h1 id="qi-ta-yong-fa">其他用法</h1>
<h2 id="da-yin-huo-dong-nei-cun-he-bu-huo-dong-nei-cun-liang">打印活动内存和不活动内存量</h2>
<pre><code class="language-shell">[root@node81 ~]# vmstat -a 1 2
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free  inact active   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 3351248 457672 7736448    0    0    42    21  246  294  1  1 98  0  0
 0  0      0 3349100 457676 7738260    0    0     0    32 1482 1945  1  0 99  0  0
[root@node81 ~]# 
</code></pre>
<p>这里有 ‘inact’ &amp; 'active’关键字。</p>
<h2 id="yi-mb-dan-wei-shu-chu-jie-guo">以 MB 单位输出结果</h2>
<pre><code class="language-shell">[root@node81 ~]# vmstat -S M 1 2
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0   3259    305    920    0    0    42    21  246  294  1  1 98  0  0
 1  0      0   3259    305    920    0    0     0     0 1445 1936  0  0 99  0  0
[root@node81 ~]# 
</code></pre>
<h2 id="yi-mb-dan-wei-shu-chu-ge-shi-jian-ji-shu-qi-he-nei-cun-de-tong-ji-xin-xi">以 MB 单位输出各事件计数器和内存的统计信息</h2>
<pre><code class="language-shell">[root@node81 ~]# vmstat -s -S M
        12007 M total memory
         7527 M used memory
         7570 M active memory
          447 M inactive memory
         3254 M free memory
          305 M buffer memory
          920 M swap cache
         6016 M total swap
            0 M used swap
         6016 M free swap
        50984 non-nice user cpu ticks
           22 nice user cpu ticks
        88723 system cpu ticks
      7244100 idle cpu ticks
        25046 IO-wait cpu ticks
            0 IRQ cpu ticks
         3074 softirq cpu ticks
            0 stolen cpu ticks
      3106216 pages paged in
      1534792 pages paged out
            0 pages swapped in
            0 pages swapped out
     18194132 interrupts
     21812846 CPU context switches
   1674110880 boot time
        93251 forks
[root@node81 ~]#
</code></pre>
<h1 id="zhu-yi-shi-xiang">注意事项</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>vmstat 不需要特殊权限</p>
</li>
<li class="lvl-2">
<p>vmstat 报告旨在帮助确定系统瓶颈，所以它不会将自己视为正在运行的进程</p>
</li>
<li class="lvl-2">
<p>当前所有的 Linux 块都是 1024 字节， 旧内核可能报告的块为 512 字节，2048 字节或 4096 字节</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux stat家族之pidstat</title>
    <url>/2023/01/20/linux_stat_family_of_pidstat/</url>
    <content><![CDATA[<h1 id="pidstat-gai-shu">pidstat 概述</h1>
<p>pidstat是sysstat工具的一个命令，用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况。pidstat首次运行时显示自系统启动开始的各项统计信息，之后运行pidstat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。</p>
<h1 id="pidstat-an-zhuang">pidstat 安装</h1>
<p>pidstat 是sysstat软件套件的一部分，sysstat包含很多监控linux系统状态的工具，它能够从大多数linux发行版的软件源中获得。</p>
<p>在Debian/Ubuntu系统中可以使用下面的命令来安装:</p>
<p><code>apt-get install sysstat </code></p>
<p>CentOS/Fedora/RHEL版本的linux中则使用下面的命令：</p>
<p><code>yum install sysstat </code></p>
<h1 id="shi-jian">实践</h1>
<h2 id="xian-shi-suo-you-zheng-zai-yun-xing-de-jin-cheng-huo-te-ding-jin-cheng-de-tong-ji-xin-xi">显示所有正在运行的进程（或特定进程）的统计信息</h2>
<p>使用 -p ALL 选项查看所有正在运行的进程的性能统计信息，如下所示:</p>
<pre><code class="language-shell">root@node166:~# pidstat -p ALL | wc -l
1275
root@node166:~# pidstat -p ALL | head
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:39:51 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:39:51 PM     0         1    0.02    0.05    0.00    0.08    18  systemd
04:39:51 PM     0         2    0.00    0.00    0.00    0.00    29  kthreadd
04:39:51 PM     0         4    0.00    0.00    0.00    0.00     0  kworker/0:0H
04:39:51 PM     0         7    0.00    0.00    0.00    0.00     0  mm_percpu_wq
04:39:51 PM     0         8    0.00    0.03    0.00    0.03     0  ksoftirqd/0
04:39:51 PM     0         9    0.00    0.87    0.00    0.87    30  rcu_sched
04:39:51 PM     0        10    0.00    0.00    0.00    0.00     0  rcu_bh
root@node166:~#
</code></pre>
<p>默认情况下，这将显示 CPU 使用率。但是，可以将其更改为任何其他性能统计信息，如后面的示例所示。</p>
<p>使用 -p PID 监视特定进程的性能统计信息，如下所示:</p>
<pre><code class="language-shell">root@node166:~# pidstat -p  5736
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:41:06 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:41:06 PM     0      5736    2.34    5.06    0.00    7.40    28  ceph-osd
root@node166:~# 
</code></pre>
<h2 id="shi-yong-c-gen-ju-jin-cheng-ming-cheng-xian-shi-xing-neng-tong-ji-xin-xi">使用 -C 根据进程名称显示性能统计信息</h2>
<p>以下示例将显示匹配特定关键字（例如：ceph-osd）的所有进程的性能统计信息:</p>
<pre><code class="language-shell">root@node166:~# pidstat -C "ceph-osd"
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:41:57 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:41:57 PM     0      5736    2.34    5.07    0.00    7.41    28  ceph-osd
04:41:57 PM     0      5741    1.95    3.42    0.00    5.37    15  ceph-osd
04:41:57 PM     0      5745    2.32    4.15    0.00    6.47    10  ceph-osd
04:41:57 PM     0      5749    2.10    3.88    0.00    5.98     0  ceph-osd
04:41:57 PM     0      5751    2.69    5.81    0.00    8.50    15  ceph-osd
04:41:57 PM     0      5753    2.13    4.20    0.00    6.33     8  ceph-osd
root@node166:~# 
</code></pre>
<p>注意：在上面的例子中，选项 -C 代表“命令名称”。即它将使用给定的关键字搜索进程的命令名称。</p>
<h2 id="yi-yi-ding-de-jian-ge-zhong-fu-shu-chu">以一定的间隔重复输出</h2>
<p>默认情况下，不会重复输出。例如，选项 -u 是显示任务的 CPU 使用统计信息，这是 pidstat 命令给出的默认统计信息，只显示输出一次。</p>
<pre><code class="language-shell">root@node166:~# pidstat -p 5753
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:42:54 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:42:54 PM     0      5753    2.15    4.24    0.00    6.39     8  ceph-osd
root@node166:~# 
</code></pre>
<p>要重复输出，请指定以秒为单位的间隔作为最后一个参数。例如，以下示例将每 1 秒重复输出一次（直到按 Ctrl-C）:</p>
<pre><code class="language-shell">root@node166:~# pidstat -p 5753 1
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:43:28 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:43:29 PM     0      5753    8.00   19.00    0.00   27.00     8  ceph-osd
04:43:30 PM     0      5753    7.00   22.00    0.00   29.00     8  ceph-osd
04:43:31 PM     0      5753    8.00   21.00    0.00   29.00     8  ceph-osd
04:43:32 PM     0      5753    8.00   26.00    0.00   34.00     8  ceph-osd
04:43:33 PM     0      5753   10.00   28.00    0.00   38.00     8  ceph-osd
04:43:34 PM     0      5753   10.00   22.00    0.00   32.00     8  ceph-osd
^C
Average:        0      5753    8.50   23.00    0.00   31.50     -  ceph-osd
root@node166:~# 
</code></pre>
<p>以下将每 15 秒重复输出一次（直到按 Ctrl-C）</p>
<pre><code class="language-shell">t@node166:~# pidstat -p 5753 15
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:44:10 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:44:25 PM     0      5753    8.00   21.07    0.00   29.07     8  ceph-osd
04:44:40 PM     0      5753    9.53   23.53    0.00   33.07     8  ceph-osd
04:44:55 PM     0      5753    7.87   21.13    0.00   29.00     8  ceph-osd
04:45:10 PM     0      5753    9.13   23.53    0.00   32.67     8  ceph-osd
^C
Average:        0      5753    8.63   22.32    0.00   30.95     -  ceph-osd
root@node166:~# 
</code></pre>
<h2 id="shi-yong-d-xian-shi-te-ding-jin-cheng-de-i-o-tong-ji-xin-xi">使用 -d 显示特定进程的 I/O 统计信息</h2>
<p>使用选项 -d 报告进程的 I/O 统计信息。它的输出显示了不同的属性，如 PID、磁盘读写速度（以 kB/s 为单位），如下所示。</p>
<p>以下示例每 1 秒显示 PID 23493 的磁盘使用情况。</p>
<pre><code class="language-shell">root@node166:~# pidstat -p 5736 -d 1
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:44:51 PM   UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
04:44:52 PM     0      5736  79916.00      0.00      0.00       0  ceph-osd
04:44:53 PM     0      5736  75820.00      0.00      0.00       0  ceph-osd
04:44:54 PM     0      5736  85052.00      4.00      0.00       0  ceph-osd
04:44:55 PM     0      5736  87100.00      0.00      0.00       0  ceph-osd
04:44:56 PM     0      5736  92204.00      0.00      0.00       0  ceph-osd
04:44:57 PM     0      5736  86064.00      0.00      0.00       0  ceph-osd
^C
Average:        0      5736  84359.33      0.67      0.00       0  ceph-osd
root@node166:~# 
</code></pre>
<h2 id="shi-yong-r-xian-shi-te-ding-jin-cheng-de-fen-ye-huo-dong">使用 -r 显示特定进程的分页活动</h2>
<p>使用选项 -r 显示给定任务 (PID) 的页面错误和内存利用率。</p>
<pre><code class="language-shell">root@node166:~# pidstat -p 5753 -r 1
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)


04:45:52 PM   UID       PID  minflt/s  majflt/s     VSZ     RSS   %MEM  Command
04:45:53 PM     0      5753  36733.00      0.00 7048224 4374012   3.35  ceph-osd
04:45:54 PM     0      5753  39449.00      0.00 7048224 4374012   3.35  ceph-osd
04:45:55 PM     0      5753  48854.00      0.00 7048224 4374044   3.35  ceph-osd
04:45:56 PM     0      5753  37720.00      0.00 7048224 4374060   3.35  ceph-osd
04:45:57 PM     0      5753  46121.00      0.00 7048224 4374060   3.35  ceph-osd
04:45:58 PM     0      5753  46210.00      0.00 7048224 4392352   3.36  ceph-osd
^C
Average:        0      5753  42514.50      0.00 7048224 4377090   3.35  ceph-osd
root@node166:~#
</code></pre>
<h2 id="shi-yong-xuan-xiang-l-xian-shi-ming-ling-ming-cheng-ji-qi-can-shu">使用选项 -l 显示命令名称及其参数</h2>
<p>默认情况下，pidstat 仅显示命令名称。即没有命令的完整路径及其参数。例如，在命令列中，你只会看到 “python” （它只是程序的名称）。</p>
<pre><code class="language-shell">root@node166:~# pidstat -C python
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:46:37 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:46:37 PM     0     11307    0.05    0.03    0.00    0.07    29  python
root@node166:~# 
</code></pre>
<p>但是，当使用选项 -l 时，它将显示命令的完整路径及其所有参数，如下所示:</p>
<pre><code class="language-shell">root@node166:~# pidstat -C python -l
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:47:17 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:47:17 PM     0     11307    0.05    0.03    0.00    0.07     1  python /usr/local/bin/ezs3-app start 
root@node166:~# 
</code></pre>
<p>为了定期获取任务的统计信息，只需传递你希望查看统计信息的秒数:</p>
<pre><code class="language-shell">root@node166:~# pidstat -C ceph-osd -l 1
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:48:20 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:48:21 PM     0      5736    5.77   12.50    0.00   18.27    28  /usr/bin/ceph-osd -f --cluster ceph --id 16 --setuser root --setgroup root 
04:48:21 PM     0      5741    8.65   17.31    0.00   25.96    15  /usr/bin/ceph-osd -f --cluster ceph --id 14 --setuser root --setgroup root 
04:48:21 PM     0      5745    8.65   21.15    0.00   29.81    10  /usr/bin/ceph-osd -f --cluster ceph --id 12 --setuser root --setgroup root 
04:48:21 PM     0      5749    8.65   21.15    0.00   29.81     0  /usr/bin/ceph-osd -f --cluster ceph --id 13 --setuser root --setgroup root 
04:48:21 PM     0      5751    6.73   16.35    0.00   23.08    15  /usr/bin/ceph-osd -f --cluster ceph --id 15 --setuser root --setgroup root 
04:48:21 PM     0      5753   11.54   31.73    0.00   43.27     8  /usr/bin/ceph-osd -f --cluster ceph --id 17 --setuser root --setgroup root 

04:48:21 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:48:22 PM     0      5736    4.00    8.00    0.00   12.00    28  /usr/bin/ceph-osd -f --cluster ceph --id 16 --setuser root --setgroup root 
04:48:22 PM     0      5741    7.00   21.00    0.00   28.00    15  /usr/bin/ceph-osd -f --cluster ceph --id 14 --setuser root --setgroup root 
04:48:22 PM     0      5745    7.00   21.00    0.00   28.00    10  /usr/bin/ceph-osd -f --cluster ceph --id 12 --setuser root --setgroup root 
04:48:22 PM     0      5749   10.00   25.00    0.00   35.00     0  /usr/bin/ceph-osd -f --cluster ceph --id 13 --setuser root --setgroup root 
04:48:22 PM     0      5751    8.00   18.00    0.00   26.00    15  /usr/bin/ceph-osd -f --cluster ceph --id 15 --setuser root --setgroup root 
04:48:22 PM     0      5753    8.00   27.00    0.00   35.00     8  /usr/bin/ceph-osd -f --cluster ceph --id 17 --setuser root --setgroup root 

04:48:22 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:48:23 PM     0      5736    5.00   14.00    0.00   19.00    28  /usr/bin/ceph-osd -f --cluster ceph --id 16 --setuser root --setgroup root 
04:48:23 PM     0      5741    8.00   21.00    0.00   29.00    15  /usr/bin/ceph-osd -f --cluster ceph --id 14 --setuser root --setgroup root 
04:48:23 PM     0      5745    7.00   22.00    0.00   29.00    10  /usr/bin/ceph-osd -f --cluster ceph --id 12 --setuser root --setgroup root 
04:48:23 PM     0      5749    9.00   25.00    0.00   34.00     0  /usr/bin/ceph-osd -f --cluster ceph --id 13 --setuser root --setgroup root 
04:48:23 PM     0      5751    9.00   18.00    0.00   27.00    15  /usr/bin/ceph-osd -f --cluster ceph --id 15 --setuser root --setgroup root 
04:48:23 PM     0      5753    9.00   30.00    0.00   39.00     8  /usr/bin/ceph-osd -f --cluster ceph --id 17 --setuser root --setgroup root 
^C

Average:      UID       PID    %usr %system  %guest    %CPU   CPU  Command
Average:        0      5736    4.93   11.51    0.00   16.45     -  /usr/bin/ceph-osd -f --cluster ceph --id 16 --setuser root --setgroup root 
Average:        0      5741    7.89   19.74    0.00   27.63     -  /usr/bin/ceph-osd -f --cluster ceph --id 14 --setuser root --setgroup root 
Average:        0      5745    7.57   21.38    0.00   28.95     -  /usr/bin/ceph-osd -f --cluster ceph --id 12 --setuser root --setgroup root 
Average:        0      5749    9.21   23.68    0.00   32.89     -  /usr/bin/ceph-osd -f --cluster ceph --id 13 --setuser root --setgroup root 
Average:        0      5751    7.89   17.43    0.00   25.33     -  /usr/bin/ceph-osd -f --cluster ceph --id 15 --setuser root --setgroup root 
Average:        0      5753    9.54   29.61    0.00   39.14     -  /usr/bin/ceph-osd -f --cluster ceph --id 17 --setuser root --setgroup root 
root@node166:~# 
</code></pre>
<h2 id="ding-qi-xian-shi-shu-chu-x-ci">定期显示输出 X 次</h2>
<p>也可以在给定的时间间隔内获取特定次数的报告，以获取如下所示的过程列表。</p>
<p>添加次数作为最后一个参数（在以秒为单位的间隔之后）。</p>
<p>例如，下面将显示输出 5 次（以 2 秒的固定间隔）。在报告结束时，它还将显示“平均值”值。</p>
<pre><code class="language-shell">root@node166:~# pidstat 2 5
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:50:06 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:50:08 PM     0         9    0.00    1.46    0.00    1.46    23  rcu_sched
04:50:08 PM     0       258    0.00    0.49    0.00    0.49    23  kcompactd0
04:50:08 PM     0       259    0.00    0.49    0.00    0.49    15  kcompactd1
04:50:08 PM     0       292    0.00    6.34    0.00    6.34    22  kswapd0
04:50:08 PM     0       305    0.00    5.37    0.00    5.37    37  kswapd1
04:50:08 PM     0       720    0.00    0.49    0.00    0.49     0  jbd2/sdg2-8
04:50:08 PM   114      2695    0.49    0.00    0.00    0.49    38  memcached
04:50:08 PM     0      2730    6.83    3.41    0.00   10.24     2  ceph-mon
04:50:08 PM     0      2922    0.49    0.49    0.00    0.98    16  ezrpcd
04:50:08 PM     0      3103    0.49    0.00    0.00    0.49     8  bt-monitord
04:50:08 PM     0      5736    4.39   13.66    0.00   18.05    28  ceph-osd
04:50:08 PM     0      5741    6.83   20.00    0.00   26.83    15  ceph-osd
04:50:08 PM     0      5745    8.78   22.44    0.00   31.22    10  ceph-osd
04:50:08 PM     0      5749    8.78   26.34    0.00   35.12     0  ceph-osd
04:50:08 PM     0      5751    9.27   18.05    0.00   27.32    15  ceph-osd
04:50:08 PM     0      5753    9.76   29.76    0.00   39.51     8  ceph-osd
04:50:08 PM     0      6076    8.78    8.78    0.00   17.56     3  node_exporter
04:50:08 PM     0      7890    2.44    0.00    0.00    2.44    19  prometheus
04:50:08 PM     0     30461    0.49    0.00    0.00    0.49    30  bt-ipmi-agent.p
04:50:08 PM     0     33930    3.41    0.98    0.00    4.39    38  bt-exporter
04:50:08 PM     0     35428   13.17    0.98    0.00   14.15    13  bt-ceph-exporte
04:50:08 PM    33     66962    5.37    1.46    0.00    6.83    12  apache2
04:50:08 PM     0    115886    0.49    0.00    0.00    0.49     6  sshd
04:50:08 PM     0    121221    0.00    0.49    0.00    0.49    32  ctdbd
04:50:08 PM     0    121679    3.41    0.49    0.00    3.90     6  eziscsi-rbd-cle
04:50:08 PM     0    121790   18.05    3.90    0.00   21.95     1  btnas-agent
04:50:08 PM     0    121955    2.44    0.98    0.00    3.41    36  eziscsid.py
04:50:08 PM     0    122237    0.49    0.49    0.00    0.98    38  ezqosd
04:50:08 PM     0    147875    0.98    1.46    0.00    2.44    35  pidstat
04:50:08 PM     0    597911    0.49    0.00    0.00    0.49    11  ssh
04:50:08 PM     0    654077    0.49    0.98    0.00    1.46    36  ezs3-agent.py
04:50:08 PM     0    654597    0.49    0.00    0.00    0.49    28  bt-haproxy-agen

04:50:08 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:50:10 PM     0         9    0.00    1.00    0.00    1.00    19  rcu_sched
04:50:10 PM     0       292    0.00    7.50    0.00    7.50    23  kswapd0
04:50:10 PM     0       305    0.00    5.00    0.00    5.00    13  kswapd1
04:50:10 PM   109      2145    0.50    0.00    0.00    0.50     6  dbus-daemon
04:50:10 PM   114      2695    0.00    0.50    0.00    0.50    39  memcached
04:50:10 PM     0      2730    2.50    0.50    0.00    3.00     2  ceph-mon
04:50:10 PM     0      2783    0.50    0.00    0.00    0.50    12  ceph-mgr
04:50:10 PM     0      3103    0.50    0.50    0.00    1.00     9  bt-monitord
04:50:10 PM     0      5736    5.50   13.00    0.00   18.50    28  ceph-osd
04:50:10 PM     0      5741    7.50   20.00    0.00   27.50    15  ceph-osd
04:50:10 PM     0      5745    8.00   23.50    0.00   31.50    10  ceph-osd
04:50:10 PM     0      5749    9.00   24.50    0.00   33.50     0  ceph-osd
04:50:10 PM     0    125343    0.50    0.00    0.00    0.50     0  ganesha.nfsd
04:50:10 PM     0    147875    1.00    1.50    0.00    2.50    35  pidstat
04:50:10 PM     0    564344    0.50    0.50    0.00    1.00    33  radosgw

04:50:10 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
04:50:12 PM     0         9    0.00    1.50    0.00    1.50    23  rcu_sched
04:50:16 PM     0    654597    0.50    0.00    0.00    0.50    29  bt-haproxy-agen
==============================   中间省略 ============================

Average:      UID       PID    %usr %system  %guest    %CPU   CPU  Command
Average:        0         9    0.00    1.19    0.00    1.19     -  rcu_sched
Average:        0       258    0.00    0.10    0.00    0.10     -  kcompactd0
Average:        0       259    0.00    0.20    0.00    0.20     -  kcompactd1
Average:        0       292    0.00    6.27    0.00    6.27     -  kswapd0
Average:        0       305    0.00    5.27    0.00    5.27     -  kswapd1
Average:        0       718    0.00    0.10    0.00    0.10     -  kworker/0:1H
Average:        0       720    0.00    0.10    0.00    0.10     -  jbd2/sdg2-8
Average:      109      2145    0.20    0.00    0.00    0.20     -  dbus-daemon
Average:      110      2163    0.10    0.10    0.00    0.20     -  avahi-daemon
Average:      114      2695    0.10    0.10    0.00    0.20     -  memcached
Average:        0      2730    4.68    1.89    0.00    6.57     -  ceph-mon
Average:        0      2783    0.10    0.00    0.00    0.10     -  ceph-mgr
Average:        0      2922    0.20    0.10    0.00    0.30     -  ezrpcd
Average:        0      3103    0.50    0.20    0.00    0.70     -  bt-monitord
Average:        0      5224    0.10    0.00    0.00    0.10     -  sshd
Average:        0      5736    5.77   14.53    0.00   20.30     -  ceph-osd
Average:        0      5741    7.46   19.60    0.00   27.06     -  ceph-osd
Average:        0      5745    8.56   22.39    0.00   30.95     -  ceph-osd
Average:        0      5749    9.15   25.17    0.00   34.33     -  ceph-osd
Average:        0      5751    8.76   18.71    0.00   27.46     -  ceph-osd
Average:        0      5753   10.35   28.96    0.00   39.30     -  ceph-osd
Average:        0      6076   10.45    8.36    0.00   18.81     -  node_exporter
Average:        0      7890    2.99    0.10    0.00    3.08     -  prometheus
Average:        0     11307    0.00    0.10    0.00    0.10     -  python
Average:        0     29221    0.10    0.00    0.00    0.10     -  bt-disk-monitor
Average:        0     29625    0.00    0.10    0.00    0.10     -  bt-recovery-qos
Average:        0     30461    0.30    0.00    0.00    0.30     -  bt-ipmi-agent.p
Average:        0     33930    5.17    3.28    0.00    8.46     -  bt-exporter
Average:        0     35428    2.99    0.20    0.00    3.18     -  bt-ceph-exporte
Average:       33     66962    2.69    0.40    0.00    3.08     -  apache2
Average:        0     67124    0.00    0.10    0.00    0.10     -  kworker/14:3
Average:        0     94898    0.00    0.10    0.00    0.10     -  kworker/u80:2
Average:        0    115823    0.00    0.10    0.00    0.10     -  ssh
Average:        0    115886    0.10    0.00    0.00    0.10     -  sshd
Average:        0    121221    0.00    0.20    0.00    0.20     -  ctdbd
Average:        0    121679    0.70    0.10    0.00    0.80     -  eziscsi-rbd-cle
Average:        0    121682    0.10    0.10    0.00    0.20     -  ezfs-recycle-fl
Average:        0    121790    7.56    1.79    0.00    9.35     -  btnas-agent
Average:        0    121955    2.79    0.80    0.00    3.58     -  eziscsid.py
Average:        0    122237    0.30    0.20    0.00    0.50     -  ezqosd
Average:        0    122253    0.50    0.00    0.00    0.50     -  bt-rbd-qos-agen
Average:        0    122916    0.10    0.00    0.00    0.10     -  sshd
Average:        0    123274    0.00    0.10    0.00    0.10     -  kworker/6:2
Average:        0    125343    0.10    0.10    0.00    0.20     -  ganesha.nfsd
Average:        0    147875    0.80    1.49    0.00    2.29     -  pidstat
Average:        0    471784    0.00    0.10    0.00    0.10     -  kworker/26:0
Average:        0    564344    0.10    0.10    0.00    0.20     -  radosgw
Average:        0    597911    0.10    0.00    0.00    0.10     -  ssh
Average:        0    654077    0.30    0.30    0.00    0.60     -  ezs3-agent.py
Average:        0    654597    0.20    0.00    0.00    0.20     -  bt-haproxy-agen
Average:        0    655087    0.10    0.00    0.00    0.10     -  ssh
root@node166:~#
</code></pre>
<h2 id="shi-yong-t-xian-shi-xuan-ding-jin-cheng-ji-qi-zi-jin-cheng-de-tong-ji-xin-xi">使用 -T 显示选定进程及其子进程的统计信息</h2>
<p>使用选项 -T 指定 CHILD 或 TASKS。在这种情况下，将报告 TASKS 或任务及其所有子项的统计数据。你也可以指定 ALL。</p>
<p>-T 的可能值：CHILD、TASKS 或 ALL。</p>
<pre><code class="language-shell">root@node166:~# pidstat -T CHILD | head 
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:51:31 PM   UID       PID    usr-ms system-ms  guest-ms  Command
04:51:31 PM     0         1    538800    414470         0  systemd
04:51:31 PM     0         2         0       580         0  kthreadd
04:51:31 PM     0         8        10      8020         0  ksoftirqd/0
04:51:31 PM     0         9         0    224970         0  rcu_sched
04:51:31 PM     0        11         0       240         0  migration/0
04:51:31 PM     0        12         0        50         0  watchdog/0
04:51:31 PM     0        15        50         0         0  watchdog/1
root@node166:~# 
</code></pre>
<h2 id="shi-yong-t-yi-shu-ge-shi-xian-shi-yi-lai-jin-cheng-de-tong-ji-xin-xi">使用 -t 以树格式显示依赖进程的统计信息</h2>
<p>使用选项 -t，你可以以树格式显示输出，如下所示。</p>
<pre><code class="language-shell">root@node166:~# pidstat -t -C "ceph-osd"
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

04:52:06 PM   UID      TGID       TID    %usr %system  %guest    %CPU   CPU  Command
04:52:06 PM     0      5736         -    2.42    5.29    0.00    7.71    28  ceph-osd
04:52:06 PM     0         -      5736    0.01    0.00    0.00    0.01    28  |__ceph-osd
04:52:06 PM     0         -      5815    0.00    0.00    0.00    0.00     0  |__ceph-osd
04:52:06 PM     0      5741         -    2.07    3.75    0.00    5.82    15  ceph-osd
04:52:06 PM     0         -      5741    0.01    0.00    0.00    0.01    15  |__ceph-osd
04:52:06 PM     0         -      6056    0.00    0.00    0.00    0.00    23  |__ceph-osd
04:52:06 PM     0      5745         -    2.43    4.48    0.00    6.92    10  ceph-osd
04:52:06 PM     0         -      5745    0.01    0.00    0.00    0.01    10  |__ceph-osd
04:52:06 PM     0         -      6006    0.00    0.00    0.00    0.00    36  |__ceph-osd
04:52:06 PM     0      5749         -    2.23    4.26    0.00    6.49     0  ceph-osd
04:52:06 PM     0         -      5749    0.01    0.00    0.00    0.01     0  |__ceph-osd
04:52:06 PM     0         -      6078    0.00    0.00    0.00    0.00    13  |__ceph-osd
04:52:06 PM     0      5751         -    2.80    6.07    0.00    8.87    15  ceph-osd
04:52:06 PM     0         -      5751    0.01    0.00    0.00    0.01    15  |__ceph-osd
04:52:06 PM     0         -      6005    0.00    0.00    0.00    0.00    16  |__ceph-osd
04:52:06 PM     0      5753         -    2.30    4.67    0.00    6.97     8  ceph-osd
04:52:06 PM     0         -      5753    0.01    0.00    0.00    0.01     8  |__ceph-osd
04:52:06 PM     0         -      5861    0.00    0.00    0.00    0.00    27  |__ceph-osd
root@node166:~# 

</code></pre>
<h2 id="shi-yong-h-zai-yi-xing-shang-shui-ping-xian-shi-suo-you-tong-ji-xin-xi">使用 -h 在一行上水平显示所有统计信息</h2>
<p>如果要求 pidstat 报告多个统计数据，它会显示一个又一个统计数据。在下面的示例中，它将首先显示选项“r”的性能统计信息，然后是选项“u”，最后是选项“d”。</p>
<pre><code class="language-shell">pidstat -rud
</code></pre>
<p>但是，如果希望单个进程的所有这些统计信息都显示在一行中，请使用选项 -h，如下所示:</p>
<pre><code class="language-shell">root@node166:~# pidstat -rud -h | head
Linux 4.14.148-202302151035.git6a5dacc (node166) 	04/17/2023 	_x86_64_	(40 CPU)

#      Time   UID       PID    %usr %system  %guest    %CPU   CPU  minflt/s  majflt/s     VSZ     RSS   %MEM   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
 1681721616     0         1    0.02    0.05    0.00    0.07    21      3.08      0.00  191392   11888   0.01     22.63      5.89      2.57       8  systemd
 1681721616     0         2    0.00    0.00    0.00    0.00    28      0.00      0.00       0       0   0.00      0.00      0.00      0.00       0  kthreadd
 1681721616     0         8    0.00    0.03    0.00    0.03     0      0.00      0.00       0       0   0.00      0.00      0.00      0.00       0  ksoftirqd/0
 1681721616     0         9    0.00    0.88    0.00    0.88     8      0.00      0.00       0       0   0.00      0.00      0.00      0.00       0  rcu_sched
 1681721616     0        11    0.00    0.00    0.00    0.00     0      0.00      0.00       0       0   0.00      0.00      0.00      0.00       0  migration/0
 1681721616     0        12    0.00    0.00    0.00    0.00     0      0.00      0.00       0       0   0.00      0.00      0.00      0.00       0  watchdog/0
 1681721616     0        15    0.00    0.00    0.00    0.00     1      0.00      0.00       0       0   0.00      0.00      0.00      0.00       0  watchdog/1
root@node166:~# 
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>磁盘健康评估</title>
    <url>/2023/01/23/disk_health_assessment/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Scaler 产品中有一feature，关于DISK的健康健康。</p>
<p>本文概要的介绍一下如何判断磁盘的健康状态。</p>
<h1 id="ci-pan-jian-kang-jian-ce-cao-zuo">磁盘健康检测操作</h1>
<h2 id="ci-pan-zai-raid-qia-shang">磁盘在Raid卡上</h2>
<p>命令:</p>
<pre><code class="language-shell">$ smartctl  -A -d megaraid,{1} {2} 
</code></pre>
<p>参数：</p>
<pre><code class="language-shell">{1} --&gt; raid卡上的VD会有一个Device ID
{2} --&gt; 磁盘设备的 disk name 形式是：/dev/sdX
</code></pre>
<p>举例：</p>
<p>获取设备的 SCSI NAA ID</p>
<pre><code class="language-shell">$ udevadm info --query=symlink --name=sdc
disk/by-id/scsi-36001485000764bd02b0e1956937eb1f8 
disk/by-id/scsi-SAVAGO_Gigabyte_MR-3108_00f8b17e9356190e2bd04b7600504801 
disk/by-id/wwn-0x6001485000764bd02b0e1956937eb1f8 disk/by-path/pci-0000:af:00.0-scsi-0:2:2:0
</code></pre>
<p>再通过 storcli64 筛选符合该 ID 的 VD 组信息, 筛选对应VD信息</p>
<pre><code class="language-shell">$ storcli64 /call/vall show all | grep -B100 6001485000764bd02b0e1956937eb1f8
/c0/v2 :
======
--------------------------------------------------------------
DG/VD TYPE  State Access Consist Cache Cac sCC      Size Name 
--------------------------------------------------------------
3/2   RAID5 Optl  RW     Yes     NRWBD -   ON  36.383 TB      
--------------------------------------------------------------

PDs for VD 2 :
============
-------------------------------------------------------------------------------
EID:Slt DID State DG     Size Intf Med SED PI SeSz Model               Sp Type 
-------------------------------------------------------------------------------
56:1     74 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:2     80 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:3     73 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:4     58 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:5     79 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:6     90 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
-------------------------------------------------------------------------------

VD2 Properties :
==============
Strip Size = 128 KB
Number of Blocks = 78134968320
VD has Emulated PD = Yes
Span Depth = 1
Number of Drives Per Span = 6
Write Cache(initial setting) = WriteBack
Disk Cache Policy = Disabled
Encryption = None
Data Protection = Disabled
Active Operations = None
Exposed to OS = Yes
Creation Date = 21-11-2022
Creation Time = 11:11:18 AM
Emulation type = default
Cachebypass size = Cachebypass-64k
Cachebypass Mode = Cachebypass Intelligent
Is LD Ready for OS Requests = Yes
SCSI NAA Id = 6001485000764bd02b0e1956937eb1f8        ----可以看到匹配的SCSI NAA Id,对应的是 VD2，成员盘有6个
</code></pre>
<p>各个成员盘的 Device ID 便是表格中的 DID 列值，至此可由 smartctl 来确认各个磁盘健康状态</p>
<p>查看磁盘健康信息</p>
<pre><code class="language-shell">$ smartctl -A -d megaraid,73 /dev/sdc
smartctl 7.0 2018-12-30 r4883 [x86_64-linux-4.14.148-202207281639.git553ed7f] (local build)
Copyright (C) 2002-18, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF READ SMART DATA SECTION ===
SMART Attributes Data Structure revision number: 16
Vendor Specific SMART Attributes with Thresholds:
ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE
  1 Raw_Read_Error_Rate     0x000b   100   100   050    Pre-fail  Always       -       0
  2 Throughput_Performance  0x0005   100   100   050    Pre-fail  Offline      -       0
  3 Spin_Up_Time            0x0027   100   100   001    Pre-fail  Always       -       6016
  4 Start_Stop_Count        0x0032   100   100   000    Old_age   Always       -       1002
  5 Reallocated_Sector_Ct   0x0033   100   100   050    Pre-fail  Always       -       0
  7 Seek_Error_Rate         0x000b   100   100   050    Pre-fail  Always       -       0
  8 Seek_Time_Performance   0x0005   100   100   050    Pre-fail  Offline      -       0
  9 Power_On_Hours          0x0032   060   060   000    Old_age   Always       -       16152
 10 Spin_Retry_Count        0x0033   120   100   030    Pre-fail  Always       -       0
 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       548
191 G-Sense_Error_Rate      0x0032   100   100   000    Old_age   Always       -       0
192 Power-Off_Retract_Count 0x0032   099   099   000    Old_age   Always       -       530
193 Load_Cycle_Count        0x0032   100   100   000    Old_age   Always       -       1070
194 Temperature_Celsius     0x0022   100   100   000    Old_age   Always       -       31 (Min/Max 14/55)
196 Reallocated_Event_Count 0x0032   100   100   000    Old_age   Always       -       0
197 Current_Pending_Sector  0x0032   100   100   000    Old_age   Always       -       0
198 Offline_Uncorrectable   0x0030   100   100   000    Old_age   Offline      -       0
199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0
220 Disk_Shift              0x0002   100   100   000    Old_age   Always       -       0
222 Loaded_Hours            0x0032   061   061   000    Old_age   Always       -       15639
223 Load_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0
224 Load_Friction           0x0022   100   100   000    Old_age   Always       -       0
226 Load-in_Time            0x0026   100   100   000    Old_age   Always       -       558
240 Head_Flying_Hours       0x0001   100   100   001    Pre-fail  Offline      -       0
</code></pre>
<p>重点关注几个 RAW_VALUE</p>
<pre><code class="language-shell"> 5  Reallocated_Sector_Ct         ：  reallocated sectors count 重分配扇区计数：硬盘生产过程中，有一部分扇区是保留的。
                                                       当一些普通扇区读/写/验证错误，则重新映射到保留扇区，挂起该异常扇区，并增加计数。随着计数增加，io性能骤降。如果数值不为0，就需要密切关注硬盘健康状况；
                                                       如果持续攀升，则硬盘已经损坏；如果重分配扇区数超过保留扇区数，将不可修复
197 Current_Pending_Sector    ：  待映射扇区数：出现异常的扇区数量，待被映射的扇区数量。 如果该异常扇区之后成功读写，则计数会减小，扇区也不会重新映射。读错误不会重新映射，只有写错误才会重新映射；
194 Temperature_Celsius          ：  硬盘温度
</code></pre>
<h2 id="ci-pan-bu-zai-raid-qia-shang">磁盘不在Raid卡上</h2>
<p>命令</p>
<pre><code class="language-shell">$ smartctl -A {1}
</code></pre>
<p>参数：</p>
<pre><code class="language-shell">{1} --&gt; 设备的 disk name，形式是 /dev/sdX

</code></pre>
<p>举例：</p>
<p>直接获取磁盘健康状态</p>
<pre><code class="language-shell">$ smartctl -A /dev/sdg
smartctl 7.0 2018-12-30 r4883 [x86_64-linux-4.14.148-202207281639.git553ed7f] (local build)
Copyright (C) 2002-18, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF READ SMART DATA SECTION ===
SMART Attributes Data Structure revision number: 1
Vendor Specific SMART Attributes with Thresholds:
ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE
  5 Reallocated_Sector_Ct   0x0032   100   100   000    Old_age   Always       -       0
  9 Power_On_Hours          0x0032   100   100   000    Old_age   Always       -       9264
 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       243
170 Available_Reservd_Space 0x0033   100   100   010    Pre-fail  Always       -       0
171 Program_Fail_Count      0x0032   100   100   000    Old_age   Always       -       0
172 Erase_Fail_Count        0x0032   100   100   000    Old_age   Always       -       0
174 Unsafe_Shutdown_Count   0x0032   100   100   000    Old_age   Always       -       171
175 Power_Loss_Cap_Test     0x0033   100   100   010    Pre-fail  Always       -       2359 (243 65535)
183 SATA_Downshift_Count    0x0032   100   100   000    Old_age   Always       -       0
184 End-to-End_Error_Count  0x0033   100   100   090    Pre-fail  Always       -       0
187 Uncorrectable_Error_Cnt 0x0032   100   100   000    Old_age   Always       -       0
190 Drive_Temperature       0x0022   063   061   000    Old_age   Always       -       37 (Min/Max 37/39)
192 Unsafe_Shutdown_Count   0x0032   100   100   000    Old_age   Always       -       171
194 Temperature_Celsius     0x0022   100   100   000    Old_age   Always       -       37
197 Pending_Sector_Count    0x0012   100   100   000    Old_age   Always       -       0
199 CRC_Error_Count         0x003e   100   100   000    Old_age   Always       -       0
225 Host_Writes_32MiB       0x0032   100   100   000    Old_age   Always       -       1456731
226 Workld_Media_Wear_Indic 0x0032   100   100   000    Old_age   Always       -       1832
227 Workld_Host_Reads_Perc  0x0032   100   100   000    Old_age   Always       -       6
228 Workload_Minutes        0x0032   100   100   000    Old_age   Always       -       554202
232 Available_Reservd_Space 0x0033   100   100   010    Pre-fail  Always       -       0
233 Media_Wearout_Indicator 0x0032   099   099   000    Old_age   Always       -       0
234 Thermal_Throttle_Status 0x0032   100   100   000    Old_age   Always       -       0/0
235 Power_Loss_Cap_Test     0x0033   100   100   010    Pre-fail  Always       -       2359 (243 65535)
241 Host_Writes_32MiB       0x0032   100   100   000    Old_age   Always       -       1456731
242 Host_Reads_32MiB        0x0032   100   100   000    Old_age   Always       -       108597
243 NAND_Writes_32MiB       0x0032   100   100   000    Old_age   Always       -       2011255
</code></pre>
<h2 id="raid-qia-shang-mei-you-jian-li-raid-de-pan">Raid卡上没有建立Raid的盘</h2>
<p>扫描所有设备</p>
<pre><code class="language-shell">$ smartctl --scan
/dev/sda -d scsi # /dev/sda, SCSI device
/dev/sdb -d scsi # /dev/sdb, SCSI device
/dev/sdc -d scsi # /dev/sdc, SCSI device
/dev/sdd -d scsi # /dev/sdd, SCSI device
/dev/sde -d scsi # /dev/sde, SCSI device
/dev/sdf -d scsi # /dev/sdf, SCSI device
/dev/sdg -d scsi # /dev/sdg, SCSI device
/dev/bus/0 -d megaraid,57 # /dev/bus/0 [megaraid_disk_57], SCSI device
/dev/bus/0 -d megaraid,58 # /dev/bus/0 [megaraid_disk_58], SCSI device
/dev/bus/0 -d megaraid,59 # /dev/bus/0 [megaraid_disk_59], SCSI device
/dev/bus/0 -d megaraid,60 # /dev/bus/0 [megaraid_disk_60], SCSI device
/dev/bus/0 -d megaraid,61 # /dev/bus/0 [megaraid_disk_61], SCSI device
/dev/bus/0 -d megaraid,62 # /dev/bus/0 [megaraid_disk_62], SCSI device
/dev/bus/0 -d megaraid,63 # /dev/bus/0 [megaraid_disk_63], SCSI device
/dev/bus/0 -d megaraid,64 # /dev/bus/0 [megaraid_disk_64], SCSI device
/dev/bus/0 -d megaraid,65 # /dev/bus/0 [megaraid_disk_65], SCSI device
/dev/bus/0 -d megaraid,66 # /dev/bus/0 [megaraid_disk_66], SCSI device
/dev/bus/0 -d megaraid,67 # /dev/bus/0 [megaraid_disk_67], SCSI device
</code></pre>
<p>通过 storcli64 获取没有建立 Raid 盘的 DID，然后直接获取健康信息；传参时候，用 /dev/bus/0 代替 disk name,获取磁盘健康信息</p>
<pre><code class="language-shell">$ smartctl -A -d megaraid,66 /dev/bus/0
......
</code></pre>
<p>这里可以发现对比前面 disk name 参数有所改变，因为对于没有建立Raid的盘，系统层级没有与之对应的 sdX，所以用 /dev/bug/0 来代替这个参数，/dev/bus/0 也就是总线设备路径</p>
<h1 id="fu-jia">附加</h1>
<h2 id="ding-wei-xi-tong-ceng-ji-pan-fu-dui-ying-de-raid-zu">定位系统层级盘符对应的Raid组</h2>
<p>1、JBOD盘</p>
<p>JBOD磁盘，通过SN（Serial Number）来定位盘符</p>
<p>#通过 smartctl 获取 /dev/sda 的 SN</p>
<pre><code class="language-shell">$ smartctl -a /dev/sda
=== START OF INFORMATION SECTION ===
Device Model     :     TOSHIBA MG05ACA800E
Serial Number    :      29Q1KOBBFUUD          --------通过此标识来定位JBOD磁盘信息
LU WWN Device Id :       5 000039 91b703090
Firmware Version :       GX2A
User Capacity    :      8,001,563,222,016 bytes [8.00 TB]
Sector Sizes     :     512 bytes logical, 4096 bytes physical
Rotation Rate    :      7200 rpm
</code></pre>
<p>查看Raid卡上该磁盘信息</p>
<pre><code class="language-shell">$ storcli64 /call/eall/sall show all
......
Drive /c0/e55/s1 Device attributes :
==================================
SN                = 29Q1KOBBFUUD             --------可以得到这个SN对应的磁盘槽位是/c0/e55/s1
Manufacturer Id   = ATA     
Model Number      = TOSHIBA MG05ACA800E
NAND Vendor       = NA
WWN               = 500003991b703090
Firmware Revision = GX2A
......
</code></pre>
<p>2、普通Raid组磁盘，通过 scsi_id 定位</p>
<p>获取硬盘 scsi_id</p>
<pre><code class="language-shell">$ udevadm info --query=symlink --name=sdc
disk/by-id/scsi-36001485000764bd02b0e1956937eb1f8    ----取这个 scsi_3 后面内容(截取部分 grep过滤即可)    
disk/by-id/scsi-SAVAGO_Gigabyte_MR-3108_00f8b17e9356190e2bd04b7600504801        
disk/by-id/wwn-0x6001485000764bd02b0e1956937eb1f8 disk/by-path/pci-0000:af:00.0-scsi-0:2:2:0
</code></pre>
<p>storcli64 获取对应 Raid 组信息</p>
<pre><code class="language-shell">$ storcli64 /call/vall show all | grep -B100 6001485000764bd02b0e1956937eb1f8
/c0/v2 :
======
--------------------------------------------------------------
DG/VD TYPE  State Access Consist Cache Cac sCC      Size Name 
--------------------------------------------------------------
3/2   RAID5 Optl  RW     Yes     NRWBD -   ON  36.383 TB      
--------------------------------------------------------------

PDs for VD 2 :
============
-------------------------------------------------------------------------------
EID:Slt DID State DG     Size Intf Med SED PI SeSz Model               Sp Type 
-------------------------------------------------------------------------------
56:1     74 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:2     80 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:3     73 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:4     58 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:5     79 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
56:6     90 Onln   3 7.276 TB SATA HDD N   N  512B TOSHIBA MG05ACA800E U  -    
-------------------------------------------------------------------------------

VD2 Properties :
==============
Strip Size = 128 KB
Number of Blocks = 78134968320
VD has Emulated PD = Yes
Span Depth = 1
Number of Drives Per Span = 6
Write Cache(initial setting) = WriteBack
Disk Cache Policy = Disabled
Encryption = None
Data Protection = Disabled
Active Operations = None
Exposed to OS = Yes
Creation Date = 21-11-2022
Creation Time = 11:11:18 AM
Emulation type = default
Cachebypass size = Cachebypass-64k
Cachebypass Mode = Cachebypass Intelligent
Is LD Ready for OS Requests = Yes
SCSI NAA Id = 6001485000764bd02b0e1956937eb1f8             ----对应该 SCSI NAA Id 的VD，VD成员盘信息如表格所示
</code></pre>
<p>新建RAID或者换盘重建RAID时，在满足一定磁盘数量后会进行后台初始化，后台初始化会对全盘进行数据校验，十分耗时，若想终止后台初始化可参考以下命令，先执行命令1，再执行命令2</p>
<p>后台初始化相关命令:</p>
<p>1、禁止后台初始化 <code>/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -dsbl -L0 -a0</code></p>
<p>2、结束正在进行的后台初始化 <code>/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -abort -L0 -a0</code></p>
<p>3、查看后台初始化的设置 <code>/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -getsetting -L0 -a0</code></p>
<p>4、显示后台初始化进度 <code>/opt/MegaRAID/MegaCli/MegaCli64 -LDBI -progdsply -L0 -a0</code></p>
]]></content>
      <categories>
        <category>Disk</category>
      </categories>
      <tags>
        <tag>Disk</tag>
      </tags>
  </entry>
  <entry>
    <title>blocktrace跟踪磁盘</title>
    <url>/2023/01/30/blocktrace/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>通过blocktrace命令，跟踪磁盘，获取磁盘的D2C，C2C信息，判断磁盘IO响应时延分布状况，进而判断磁盘是否出现了硬件瓶颈</p>
<h1 id="shi-li">示例</h1>
<pre><code class="language-shell">blktrace -d /dev/sdX -o - |blkparse -i -
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>彻底删除Linux下md设备</title>
    <url>/2023/02/03/delete_md_device/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Lab 2U4N设备上SSD盘有soft-raid存在，本文介绍如何清理掉这些md 设备。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="huo-qu-xiang-guan-xin-xi">获取相关信息</h2>
<p>当前OS中md设备信息：</p>
<pre><code class="language-shell">root@node123:~# lsblk
NAME        MAJ:MIN RM    SIZE RO TYPE  MOUNTPOINT
sda           8:0    0    3.5T  0 disk  
sdb           8:16   0    3.5T  0 disk  
sdc           8:32   0    3.5T  0 disk  
sdd           8:48   0    3.5T  0 disk  
sde           8:64   0    3.5T  0 disk  
sdf           8:80   0    3.5T  0 disk  
└─md126       9:126  0    3.5T  0 raid0 
  ├─md126p1 259:6    0      8G  0 part  
  ├─md126p2 259:7    0    3.5T  0 part  
  └─md126p3 259:8    0 1007.5K  0 part  
nvme0n1     259:0    0  238.5G  0 disk  
├─nvme0n1p1 259:2    0   1007K  0 part  
├─nvme0n1p2 259:3    0    512M  0 part  /boot/efi
├─nvme0n1p3 259:4    0      8G  0 part  [SWAP]
└─nvme0n1p4 259:5    0    230G  0 part  /
nvme1n1     259:1    0  238.5G  0 disk  
pmem0       259:9    0     16G  0 disk  
pmem1       259:10   0     16G  0 disk  
root@node123:~# 
</code></pre>
<pre><code class="language-shell">root@node123:~# mdadm -Ds 
ARRAY /dev/md/ddf0 metadata=ddf UUID=783f1a5c:5a361165:b27fff3b:c518b21a
ARRAY /dev/md126 container=/dev/md/ddf0 member=2 UUID=926ae63a:c3cd5a73:93063a44:eda9c39f
root@node123:~# 
</code></pre>
<pre><code class="language-shell">root@node123:~# mdadm -D /dev/md126
/dev/md126:
         Container : /dev/md/ddf0, member 2
        Raid Level : raid0
        Array Size : 3750199296 (3576.47 GiB 3840.20 GB)
      Raid Devices : 1
     Total Devices : 1

             State : clean 
    Active Devices : 1
   Working Devices : 1
    Failed Devices : 0
     Spare Devices : 0

        Chunk Size : 64K

Consistency Policy : none

    Container GUID : 4C534920:20202020:1000005D:10009361:50C1A436:0B5F09A0
                  (LSI      12/07/22 16:09:26)
               Seq : 00000259
     Virtual Disks : 5

    Number   Major   Minor   RaidDevice State
       0       8       80        0      active sync   /dev/sdf
root@node123:~#
</code></pre>
<pre><code class="language-shell">root@node123:/etc/mdadm# cat /proc/mdstat 
Personalities : [raid0] [linear] [multipath] [raid1] [raid6] [raid5] [raid4] [raid10] 
md127 : inactive sdf[0](S)
      538968 blocks super external:ddf
       
unused devices: &lt;none&gt;
root@node123:/etc/mdadm# 
</code></pre>
<pre><code class="language-shell">root@node123:/etc/mdadm# mdadm -D /dev/md127
/dev/md127:
           Version : ddf
        Raid Level : container
     Total Devices : 1

   Working Devices : 1

    Container GUID : 4C534920:20202020:1000005D:10009361:50C1A436:0B5F09A0
                  (LSI      12/07/22 16:09:26)
               Seq : 00000259
     Virtual Disks : 5

     Member Arrays :

    Number   Major   Minor   RaidDevice

       -       8       80        -        /dev/sdf
root@node123:/etc/mdadm#
</code></pre>
<pre><code class="language-shell">root@node123:~# cat /etc/mdadm/mdadm.conf
# mdadm.conf
#
# !NB! Run update-initramfs -u after updating this file.
# !NB! This will ensure that initramfs has an uptodate copy.
#
# Please refer to mdadm.conf(5) for information about this file.
#

# by default (built-in), scan all partitions (/proc/partitions) and all
# containers for MD superblocks. alternatively, specify devices to scan, using
# wildcards if desired.
#DEVICE partitions containers

# automatically tag new arrays as belonging to the local system
HOMEHOST &lt;system&gt;

# instruct the monitoring daemon where to send mail alerts
MAILADDR root

# definitions of existing MD arrays
ARRAY metadata=ddf UUID=f6da2fa6:f847cfe8:6efae15e:1ec1cb18
ARRAY container=f6da2fa6:f847cfe8:6efae15e:1ec1cb18 member=0 UUID=9ff807d6:cd51ad98:0fde88a0:bed80d0e
ARRAY container=f6da2fa6:f847cfe8:6efae15e:1ec1cb18 member=1 UUID=be17285a:62edb788:24f8e528:00912e8c
ARRAY container=f6da2fa6:f847cfe8:6efae15e:1ec1cb18 member=2 UUID=b08d0c30:d7aa7ba5:0a22787e:103831d9
ARRAY container=f6da2fa6:f847cfe8:6efae15e:1ec1cb18 member=3 UUID=5159a750:d1c2251f:56b0ef10:4b9a1309
ARRAY container=f6da2fa6:f847cfe8:6efae15e:1ec1cb18 member=4 UUID=70f4a9f0:fdb95f4d:753d57a5:8c2314c0
ARRAY metadata=ddf UUID=471d86af:9306e6d2:bc56f74d:c3b578f9
ARRAY container=471d86af:9306e6d2:bc56f74d:c3b578f9 member=0 UUID=6d0bf5f0:b39ef888:80529401:91f64dcb
ARRAY container=471d86af:9306e6d2:bc56f74d:c3b578f9 member=1 UUID=7cc9f621:c04ac67c:f4b0976a:78fe15f2
ARRAY container=471d86af:9306e6d2:bc56f74d:c3b578f9 member=2 UUID=95994645:864ddcc9:67c2f8ce:9fe93d97
ARRAY container=471d86af:9306e6d2:bc56f74d:c3b578f9 member=3 UUID=91b65356:8b4ec6e8:f64d7f23:63f8bd83
ARRAY container=471d86af:9306e6d2:bc56f74d:c3b578f9 member=4 UUID=c8f2b38c:f32ce54b:9d2ef6ff:4e537329
ARRAY metadata=ddf UUID=783f1a5c:5a361165:b27fff3b:c518b21a
ARRAY container=783f1a5c:5a361165:b27fff3b:c518b21a member=0 UUID=af20c622:b4cab24e:6e79902d:a83f750c
ARRAY container=783f1a5c:5a361165:b27fff3b:c518b21a member=1 UUID=2f4788c1:1dbe4d60:274c34fc:fdad0f1e
ARRAY container=783f1a5c:5a361165:b27fff3b:c518b21a member=2 UUID=926ae63a:c3cd5a73:93063a44:eda9c39f
ARRAY container=783f1a5c:5a361165:b27fff3b:c518b21a member=3 UUID=5bebdf83:dfd7c23d:99bdb41a:3991d212
ARRAY container=783f1a5c:5a361165:b27fff3b:c518b21a member=4 UUID=efc49f2c:f23319c6:b2b4666f:26f9dba6
ARRAY container=783f1a5c:5a361165:b27fff3b:c518b21a member=5 UUID=e05f0b90:235cb256:9d031efe:ac7f6f4f

# This configuration was auto-generated on Thu, 02 Feb 2023 12:52:09 +0800 by mkconf
root@node123:~#
</code></pre>
<h1 id="shan-chu-md-device">删除md device</h1>
<pre><code class="language-shell">root@node123:~# mdadm --stop -s /dev/md126
mdadm: stopped /dev/md126
root@node123:~# 
</code></pre>
<pre><code class="language-shell">root@node123:~# mdadm --misc --zero-superblock /dev/sdf
mdadm: Couldn't open /dev/sdf for write - not zeroing
root@node123:~# mdadm --zero-superblock /dev/sdf
mdadm: Couldn't open /dev/sdf for write - not zeroing
root@node123:~# 
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>说明通过上面的方法，是无法删除md设备的，即使清空了/etc/mdadm/mdadm.conf也没用，重启机器后md设备又在了。</p>
</li>
</ul>
<p>正确的删除方法是：</p>
<h2 id="cong-proc-mdstat-zhong-huo-qu-dang-qian-os-xia-de-suo-you-md-xin-xi">从/proc/mdstat中获取当前OS下的所有md信息</h2>
<pre><code class="language-shell">root@node122:/var/log/history# cat /proc/mdstat 
Personalities : [raid0] [linear] [multipath] [raid1] [raid6] [raid5] [raid4] [raid10] 
md120 : inactive sda[0]
      3750199296 blocks super external:/md124/3
       
md124 : inactive sda[1](S) sdb[0](S)
      1077936 blocks super external:ddf
       
md127 : inactive sdd[1](S) sdc[0](S)
      1077936 blocks super external:ddf
       
unused devices: &lt;none&gt;
root@node122:/var/log/history# 
</code></pre>
<p>根据/proc/mdstat中的md信息，逐一stop并清理掉metadata信息，如下：</p>
<pre><code class="language-shell">root@node123:/etc/mdadm# mdadm -S /dev/md127
mdadm: stopped /dev/md127
root@node123:/etc/mdadm# mdadm --zero-superblock /dev/sdf
root@node123:/etc/mdadm# 
</code></pre>
<p>这样，即使机器reboot后，也不会再次出现md设备了，干净清理掉。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>mdadm</tag>
      </tags>
  </entry>
  <entry>
    <title>Python下使用function timeout</title>
    <url>/2023/02/06/function_timeout/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天在编写S3 multipart upload相关test case时，碰到一个Quota相关场景，即上传S3 Object超过了Bucket Quota 的设定，导致thread hang住，无法退出。一般情况下，无Quota下，程序正常上传Object并退出，但碰到这种有Quota场景的，一旦超额，用例对应multipart upload function 卡住。为此，本文介绍如果给function增加timeout，正常退出，且不影响后续程序的运行。</p>
<h1 id="shi-jian">实践</h1>
<p>直接上解决方法.</p>
<p>如下，为多线程中的使用</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-
from func_timeout import func_set_timeout
import time
import func_timeout

@func_set_timeout(1)
def task():
    while True:
        print('hello world')
        time.sleep(1)


if __name__ == '__main__':
    try:
        task()
    except func_timeout.exceptions.FunctionTimedOut:
        print('task func_timeout')

</code></pre>
<p>Program output:</p>
<pre><code class="language-shell">hello world
task func_timeout
</code></pre>
<p>这样就可以不用中断主程序，可以继续执行后面的任务，也可以在超时后加上重试等功能，这就看自己需要了。</p>
<p>对应的测试用例基类：</p>
<pre><code class="language-python">    if option in ['upload']:
        try:
            self.upload_file_multipart(file_path, object_name, bucket, thread_cnt)
        except func_timeout.exceptions.FunctionTimedOut:
            logging.debug("--  Upload failed by FunctionTimedOut")
</code></pre>
<p>被 call function 头部增加装饰器 <code>func_set_timeout</code></p>
<pre><code class="language-python">
    @func_set_timeout(5)
    def upload_file_multipart(self, file_path, object_name, bucket, thread_cnt):
        filesize = os.stat(file_path).st_size
        mp = bucket.initiate_multipart_upload(object_name)
        q = self.init_queue(filesize)
        for i in range(0, thread_cnt):
            t = threading.Thread(target=self.upload_chunk, args=(file_path, mp, q, i))
            t.setDaemon(True)
            t.start()
        q.join()
        mp.complete_upload()
</code></pre>
<p>如上，完美解决掉thread hang死问题。</p>
<p>参考：</p>
<p><a href="https://zhuanlan.zhihu.com/p/39743129">https://zhuanlan.zhihu.com/p/39743129</a></p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>S3 object encryption by awscli</title>
    <url>/2023/02/08/s3_object_encryption/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍如何使用awscli 上传、下载S3 object 的加密object.</p>
<p>写此文章的目的在于转换用户过程中，碰到了object加密上传下载，碍于本人对于awscli指令不熟悉，简易记录下来mark下。</p>
<h1 id="shi-zhan">实战</h1>
<p>前提条件：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>创建了Bucket</p>
</li>
</ul>
<p>本文以bucket01示例。</p>
<h2 id="dui-bucket-she-zhi-default-encryption">对 bucket设置Default encryption</h2>
<pre><code class="language-shell">aws s3api put-bucket-encryption --bucket=bucket01 --server-side-encryption-configuration '{"Rules": [{"ApplyServerSideEncryptionByDefault": {"SSEAlgorithm": "AES256"}}]}' --endpoint-url=http://localhost/ --debug
</code></pre>
<h2 id="huo-qu-bucket-de-encryption-xin-xi">获取bucket的encryption信息</h2>
<pre><code class="language-shell">aws s3api get-bucket-encryption --bucket=bucket05 --endpoint-url=https://localhost/
</code></pre>
<h2 id="shang-chuan-object">上传object</h2>
<pre><code class="language-shell">aws s3api put-object --bucket bucket03 --key 2.txt --body /root/2.txt --server-side-encryption aws:kms&nbsp;--no-verify-ssl --endpoint-url=https://localhost/
</code></pre>
<h2 id="xia-zai-object">下载Object</h2>
<pre><code class="language-shell">aws s3api  get-object --endpoint-url=https://localhost --bucket=bucket01 --key 2.txt output2.txt --server-side-encryption AES256 --no-verify-ssl
</code></pre>
<p>如果endpoint-url中不想带上https,需要修改如下参数，并重启rgw</p>
<p><code>ceph.config</code></p>
<pre><code class="language-shell">[radosgw]
rgw verify ssl = false
rgw crypt require ssl = false
</code></pre>
<p>参考资料：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><a href="https://ecloud.10086.cn/op-help-center/doc/article/57923">https://ecloud.10086.cn/op-help-center/doc/article/57923</a></p>
</li>
<li class="lvl-2">
<p><a href="https://blog.csdn.net/QTM_Gitee/article/details/118052481">https://blog.csdn.net/QTM_Gitee/article/details/118052481</a></p>
</li>
<li class="lvl-2">
<p><a href="https://advancedweb.hu/encryption-options-for-s3-objects/">https://advancedweb.hu/encryption-options-for-s3-objects/</a></p>
</li>
<li class="lvl-2">
<p><a href="https://repost.aws/questions/QUVIw4-39zSPe_pxZ7m4Ejiw/using-aws-s-3-api-put-object-sse-customer-key-md-5-fails-with-cli">https://repost.aws/questions/QUVIw4-39zSPe_pxZ7m4Ejiw/using-aws-s-3-api-put-object-sse-customer-key-md-5-fails-with-cli</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>tmpfiles.d_guide</title>
    <url>/2023/01/13/tmpfiles.d_guide/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在产品web login后，/tmp/sessions目录莫名被删，导致再次登录web无此目录，引发登录失败问题。最终定位到产品在清理/tmp files存在使用上的问题，误删除了此目录。</p>
<p>本文引述他人翻译，介绍tmpfiles.d</p>
<p>参考：</p>
<p><a href="http://www.jinbuguo.com/systemd/tmpfiles.d.html">http://www.jinbuguo.com/systemd/tmpfiles.d.html</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>kerberos安装与客户端配置</title>
    <url>/2023/02/17/deploy_kerberos/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>由于产品有使用到kerberos做NFS Auth, 近期环境出现异常，也没有文档记录kerberos安装过程，故重新部署并记录文档。</p>
<h1 id="huan-jing-gui-hua">环境规划</h1>
<p>在部署之前一定要提前规划好角色、域名以及IP地址，否则会出现异常</p>
<p>系统: ubuntu-18.04.6-desktop-amd64.iso，主机名与地址配置:</p>
<table>
<thead>
<tr>
<th>角色</th>
<th>全称域名（FQDN）</th>
<th>IP地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kadmin KDC</td>
<td><a href="http://kadminkdc.njqa.com">kadminkdc.njqa.com</a></td>
<td>172.17.75.240</td>
</tr>
<tr>
<td>kerberos client1</td>
<td><a href="http://kclient241.njqa.com">kclient241.njqa.com</a></td>
<td>172.17.75.241</td>
</tr>
<tr>
<td>kerberos client2</td>
<td><a href="http://kclient242.njqa.com">kclient242.njqa.com</a></td>
<td>172.17.75.242</td>
</tr>
<tr>
<td>Scaler集群</td>
<td><a href="http://scaler.njqa.com">scaler.njqa.com</a></td>
<td>172.17.72.11; 172.17.72.12;172.17.72.13</td>
</tr>
</tbody>
</table>
<p>添加域名映射到/etc/hosts文件中，确保集群和kdc以及client可以通过全称域名互相访问（若有DNS服务器更好，可以避免一些奇怪的问题）</p>
<p>多节点集群每个节点都应当配置好hosts，否则不能在集群配置界面配置kerberos服务器为全称域名</p>
<pre><code class="language-shell">172.17.75.240   kadminkdc.njqa.com      kadminkdc
172.17.75.241   kclient241.njqa.com     kclient241
172.17.75.242   kclient242.njqa.com     kclient242

172.17.72.111   scaler.njqa.com    node111
172.17.72.112   scaler.njqa.com    node112
172.17.72.113   scaler.njqa.com    node113
</code></pre>
<h1 id="ji-qun-wei-duo-jie-dian-qing-kuang-xia-xu-yao-suo-you-jie-dian-du-pei-zhi-ying-she-dao-yi-ge-yu-ming">集群为多节点情况下需要所有节点都配置映射到一个域名</h1>
<p>Kerberos服务器对时间较为敏感，可以在KDC和kerberos client上配置NTP同步时间,Scaler集群自带NTP服务</p>
<pre><code class="language-shell">apt-get install ntp -y
</code></pre>
<p>另外若有防火墙需要先将防火墙关闭ufw disable,或者让防火墙允许Kerberos服务通过</p>
<h1 id="pei-zhi-kdc-he-kadmin">配置KDC和kadmin</h1>
<h2 id="an-zhuang-xiang-guan-zu-jian">安装相关组件</h2>
<pre><code class="language-shell">apt-get install krb5-kdc krb5-admin-server
</code></pre>
<p>安装完成后会弹出Kerberos的配置界面，该配置界面也可以使用命令dpkg-reconfigure krb5-kdc来打开</p>
<h3 id="tian-xie-realm-kerberos-de-realm-wei-da-xie-a-href-http-xn-njqa-965-fm-4-a-046-gd-65-a-com-wo-men-shi-yong-njqa-com-a">填写Realm，Kerberos的Realm为大写，<a href="http://xn--NJQA-965fm4a046gd65a.COM">我们使用NJQA.COM</a></h3>
<img class="shadow" src="/img/in-post/kerberos/kerberos-1.png" width="1200">
<p>设置Kerberos server，为我们的Kerberos主机名，<a href="http://xn--kadminkdc-4b3oo3df69az1somcc3vn59cot4e.njqa.com">按照规划应当填入kadminkdc.njqa.com</a>，图中仅作参考</p>
<img class="shadow" src="/img/in-post/kerberos/kerberos-2.png" width="1200">
<p>设置Administrative server，因为我们只有一台KDC服务器，所以设置为这台Kerberos的主机名，<a href="http://xn--kadminkdc-4b3oo3df69az1somcc3vn59cot4e.njqa.com">按照规划应当填入kadminkdc.njqa.com</a> ，图中仅作参考</p>
<img class="shadow" src="/img/in-post/kerberos/kerberos-3.png" width="1200">
<h3 id="chuang-jian-kerberos-shu-ju-ku-li-mian-wei-hu-zhao-ren-zheng-xi-tong-zhong-suo-you-zhu-ji-de-mi-ma">创建Kerberos数据库，里面维护着认证系统中所有主机的密码</h3>
<p>krb5_newrealm 按照提示设置密码即可</p>
<img class="shadow" src="/img/in-post/kerberos/kerberos-4.png" width="1200">
<h3 id="wei-kerberos-tian-jia-yi-ge-guan-li-yuan-zhang-hao-yi-guan-li-ren-zheng-xi-tong-zhong-de-principal-zai-tian-jia-san-ge-principals-liang-ge-yong-yu-client-ling-yi-ge-yong-yu-scaler-ji-qun">为Kerberos添加一个管理员帐号，以管理认证系统中的principal，再添加三个principals，两个用于client，另一个用于scaler集群</h3>
<pre><code class="language-shell">root@kdc:~# kadmin.local
Authenticating as principal root/admin@NJQA.COM with password.
kadmin.local:  ank root/admin@NJQA.COM                                                           #管理员账号
WARNING: no policy specified for root/admin@NJQA.COM; defaulting to no policy
Enter password for principal "root/admin@NJQA.COM": 
Re-enter password for principal "root/admin@NJQA.COM": 
Principal "root/admin@NJQA.COM" created.
kadmin.local:  
kadmin.local:  ank host/kclient241.njqa.com@NJQA.COM                                               #Kerberos client1
WARNING: no policy specified for host/kclient241.njqa.com@NJQA.COM; defaulting to no policy
Enter password for principal "host/kclient241.njqa.com@NJQA.COM": 
Re-enter password for principal "host/kclient241.njqa.com@NJQA.COM": 
Principal "host/kclient241.njqa.com@NJQA.COM" created.

kadmin.local:  ank host/kclient242.njqa.com@NJQA.COM                                               #Kerberos client2
WARNING: no policy specified for host/kclient242.njqa.com@NJQA.COM; defaulting to no policy
Enter password for principal "host/kclient242.njqa.com@NJQA.COM": 
Re-enter password for principal "host/kclient242.njqa.com@NJQA.COM": 
Principal "host/kclient242.njqa.com@NJQA.COM" created.

kadmin.local:  ank nfs/scaler.njqa.com@NJQA.COM                                                  #Cluster
WARNING: no policy specified for nfs/scaler.njqa.com@NJQA.COM; defaulting to no policy
Enter password for principal "nfs/scaler.njqa.com@NJQA.COM": 
Re-enter password for principal "nfs/scaler.njqa.com@NJQA.COM": 
Principal "nfs/scaler.njqa.com@NJQA.COM" created.
</code></pre>
<h3 id="wei-kadmind-fu-wu-chuang-jian-yi-ge-mi-yao-biao-wen-jian">为 kadmind 服务创建一个密钥表文件</h3>
<p>此命令序列创建一个包含 kadmin/<fqdn> 和 kadmin/changepw 的主体项的特殊密钥表文件。kadmind 服务需要使用这些主体，要更改口令也需要使用这些主体。请注意，当主体实例为主机名时，无论 /etc/resolv.conf 文件中的域名是大写还是小写，都必须以小写字母指定FQDN。</fqdn></p>
<pre><code class="language-shell">kadmin.local: ktadd -k /etc/krb5/kadm5.keytab kadmin/kadminkdc.njqa.com@NJQA.COM
Entry for principal kadmin/kadminkdc.example.com@NJQA.COM with kvno 3, encryption type AES-256 CTS mode
          with 96-bit SHA-1 HMAC added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/kadminkdc.example.com@NJQA.COM with kvno 3, encryption type AES-128 CTS mode
          with 96-bit SHA-1 HMAC added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/kadminkdc.example.com@NJQA.COM with kvno 3, encryption type Triple DES cbc
          mode with HMAC/sha1 added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/kadminkdc.example.com@NJQA.COM with kvno 3, encryption type ArcFour
          with HMAC/md5 added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/kadminkdc.example.com@NJQA.COM with kvno 3, encryption type DES cbc mode
          with RSA-MD5 added to keytab WRFILE:/etc/krb5/kadm5.keytab.

kadmin.local: ktadd -k /etc/krb5/kadm5.keytab kadmin/changepw@NJQA.COM
Entry for principal kadmin/changepw@NJQA.COM with kvno 3, encryption type AES-256 CTS mode
          with 96-bit SHA-1 HMAC added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/changepw@NJQA.COM with kvno 3, encryption type AES-128 CTS mode
          with 96-bit SHA-1 HMAC added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/changepw@NJQA.COM with kvno 3, encryption type Triple DES cbc
          mode with HMAC/sha1 added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/changepw@NJQA.COM with kvno 3, encryption type ArcFour
          with HMAC/md5 added to keytab WRFILE:/etc/krb5/kadm5.keytab.
Entry for principal kadmin/changepw@NJQA.COM with kvno 3, encryption type DES cbc mode
          with RSA-MD5 added to keytab WRFILE:/etc/krb5/kadm5.keytab.
kadmin.local:
</code></pre>
<h3 id="yun-xing-yi-xia-ming-ling-zhe-liang-ge-deamon-xu-yao-bao-chi-yun-xing-zhuang-tai">运行以下命令（这两个deamon需要保持运行状态）</h3>
<pre><code class="language-shell">krb5kdc
kadmind
</code></pre>
<h3 id="bian-ji-pei-zhi-wen-jian">编辑配置文件</h3>
<pre><code class="language-shell">vim /etc/krb5.conf

[logging]
        default = FILE:/var/log/krb5.log
        kdc = FILE:/var/log/krb5kdc.log
        admin_server = FILE:/var/log/kadmind.log


[libdefaults]
        default_realm = NJQA.COM
        dns_lookup_kdc = true
        dns_lookup_realm = true
        ticket_lifetime = 24000 
        clock_skew = 300
        kdc_timesync = 1
        ccache_type = 4
        forwardable = true
        proxiable = true


[realms]
        NJQA.COM = {
                kdc = kdc
                admin_server = kdc
        }

[domain_realm]
        .NJQA.COM = NJQA.COM
        NJQA.COM = NJQA.COM


vim /etc/krb5kdc/kdc.conf

[kdcdefaults]
    kdc_ports = 750,88

[realms]
    NJQA.COM = {
        database_name = /var/lib/krb5kdc/principal
        admin_keytab = FILE:/etc/krb5kdc/kadm5.keytab
        acl_file = /etc/krb5kdc/kadm5.acl
        key_stash_file = /etc/krb5kdc/stash
        kdc_ports = 750,88
        max_life = 10h 0m 0s
        max_renewable_life = 7d 0h 0m 0s
        master_key_type = des3-hmac-sha1
        supported_enctypes = aes256-cts:normal arcfour-hmac:normal des3-hmac-sha1:normal des-cbc-crc:normal des:normal des:v4 des:norealm des:onlyrealm des:afs3                                                 
        default_principal_flags = +preauth
    }

</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>/etc/krb5.conf中原本内容删除，替换成上面的内容</p>
</li>
<li class="lvl-2">
<p>/etc/krb5kdc/kdc.conf中将supported_enctypes前面的#去掉，并增加多种认证方式</p>
</li>
</ul>
<h3 id="pei-zhi-acl">配置acl</h3>
<p>将步骤3中添加的3个principal添加进acl文件中</p>
<pre><code class="language-shell">vim /etc/krb5kdc/kadm5.acl

# This file Is the access control list for krb5 administration.
# When this file is edited run service krb5-admin-server restart to activate
# One common way to set up Kerberos administration is to allow any principal 
# ending in /admin  is given full administrative rights.
# To enable this, uncomment the following line:
*/admin                   *
root/admin@NJQA.COM       *
host/admin@NJQA.COM       *
nfs/admin@NJQA.COM        *
</code></pre>
<h3 id="tian-jia-ri-zhi-he-cun-qu-principal-de-quan-xian">添加日志和存取principal的权限</h3>
<p>若不修改此项，日志记录和存取principal时会有问题</p>
<p>在ReadWriteDirectories项添加路径/etc/krb5kdc /var/log以增加权限</p>
<pre><code class="language-shell">vim /lib/systemd/system/krb5-admin-server.service

[Unit]
Description=Kerberos 5 Admin Server


[Service]
Type=simple
ExecStart=/usr/sbin/kadmind -nofork $DAEMON_ARGS
EnvironmentFile=-/etc/default/krb5-admin-server
InaccessibleDirectories=-/etc/ssh -/etc/ssl/private  /root
ReadOnlyDirectories=/
ReadWriteDirectories=-/var/tmp /tmp /var/lib/krb5kdc -/var/run /run /etc/krb5kdc /var/log        #后两项需要添加上
CapabilityBoundingSet=CAP_NET_BIND_SERVICE
Restart=on-abnormal

[Install]
WantedBy=multi-user.target
vim /lib/systemd/system/krb5-kdc.service

[Unit]
Description=Kerberos 5 Key Distribution Center


[Service]
Type=forking
PIDFile=/var/run/krb5-kdc.pid
ExecReload=/bin/kill -HUP $MAINPID
EnvironmentFile=-/etc/default/krb5-kdc
ExecStart=/usr/sbin/krb5kdc -P /var/run/krb5-kdc.pid $DAEMON_ARGS
InaccessibleDirectories=-/etc/ssh -/etc/ssl/private  /root
ReadOnlyDirectories=/
ReadWriteDirectories=-/var/tmp /tmp /var/lib/krb5kdc -/var/run /run /etc/krb5kdc /var/log
CapabilityBoundingSet=CAP_NET_BIND_SERVICE
Restart=on-abnormal


[Install]
WantedBy=multi-user.target
</code></pre>
<p>修改完成后使用systemctl daemon-reload命令重新加载</p>
<h3 id="zhong-qi-fu-wu">重启服务</h3>
<p><code>systemctl restart krb5-admin-server.service krb5-kdc.service</code></p>
<h1 id="pei-zhi-kerberos-client">配置Kerberos client</h1>
<h2 id="an-zhuang-xiang-guan-zu-jian-1">安装相关组件</h2>
<p><code>apt-get install krb5-user</code>，在配置界面填写的内容与Kerberos主机填写内容相同，即Server、Client与Kerberos的krb5.conf是相同的可以将KDC的krb5.conf拷贝到Client端</p>
<pre><code class="language-shell">root@kclient241:/etc/apt# scp 172.17.75.240:/etc/krb5.conf /etc/krb5.conf
The authenticity of host '172.17.75.240 (172.17.75.240)' can't be established.
ECDSA key fingerprint is SHA256:LnlXsXoJenNd6t5MXyebncsPsgRHJwsHrd+nMt4AHNE.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.17.75.240' (ECDSA) to the list of known hosts.
root@172.17.75.240's password: 
krb5.conf                                                                                       100%  542   779.2KB/s   00:00
</code></pre>
<h2 id="tong-guo-wo-men-chuang-jian-de-guan-li-yuan-zhang-hao-deng-lu-hou-huo-qu-server-de-krb-5-keytab">通过我们创建的管理员帐号登录后获取Server的krb5.keytab</h2>
<p>如下</p>
<pre><code class="language-shell">root@kclient241:~# kadmin
Authenticating as principal root/admin@NJQA.COM with password.
Password for root/admin@NJQA.COM: 
kadmin:  ktadd -k /etc/krb5.keytab host/kclient241.njqa.com@NJQA.COM
Entry for principal host/kclient241.njqa.com@NJQA.COM with kvno 2, encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:/etc/krb5.keytab.
Entry for principal host/kclient241.njqa.com@NJQA.COM with kvno 2, encryption type arcfour-hmac added to keytab WRFILE:/etc/krb5.keytab.
Entry for principal host/kclient241.njqa.com@NJQA.COM with kvno 2, encryption type des3-cbc-sha1 added to keytab WRFILE:/etc/krb5.keytab.
Entry for principal host/kclient241.njqa.com@NJQA.COM with kvno 2, encryption type des-cbc-crc added to keytab WRFILE:/etc/krb5.keytab.
kadmin:  q
</code></pre>
<h2 id="shi-yong-kinit-shen-qing-tgt-yan-zheng-ren-zheng-pei-zhi-shi-fou-cheng-gong-kinit-zhi-xing-wan-cheng-hou-shi-yong-klist-cha-kan-ping-zheng-yi-na-dao">使用kinit申请TGT验证认证配置是否成功，kinit执行完成后使用klist查看凭证已拿到</h2>
<pre><code class="language-shell">root@kclient241:~# kinit -kt /etc/krb5.keytab host/kclient241.njqa.com@NJQA.COM
root@kclient241:~# klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: host/kclient241.njqa.com@NJQA.COM

Valid starting       Expires              Service principal
2023-01-31T15:32:50  2023-01-31T22:12:50  krbtgt/njqa.COM@NJQA.COM
</code></pre>
<p>如果这里有问题请检查hostname、hosts、krb5.conf、各个principal是否正确，krb5.keytab是否存在，还有最容易忽略的时间是否统一可以手动校准也可以使用NTP、Chrony等时间同步服务来做</p>
<h2 id="zai-kclient-242-shang-an-zhao-1-3-bu-zou-ye-cao-zuo-yi-bian">在kclient242上按照1-3步骤也操作一遍</h2>
<h1 id="pei-zhi-scaler-ji-qun">配置Scaler集群</h1>
<p>注意：</p>
<ol>
<li class="lvl-4">
<p>提前配置好集群的node的hostname以及hosts</p>
</li>
<li class="lvl-4">
<p>多节点集群中每个节点都需要配置好hosts</p>
</li>
</ol>
<p>在虚拟存储器的配置界面找到Kerberos配置，点击…配置kerberos，其中kerberos服务器建议使用全称域名配置</p>
<img class="shadow" src="/img/in-post/kerberos/kerberos-5.png" width="1200">
<p>配置好Kerberos后添加principal</p>
<img class="shadow" src="/img/in-post/kerberos/kerberos-6.png" width="1200">
<img class="shadow" src="/img/in-post/kerberos/kerberos-7.png" width="1200">
<p>在虚拟存储器的NAS页面中创建共享文件夹，在NFS菜单中选择krb5、krb5i或krb5p，创建基于Kerberos认证的共享文件夹</p>
<img class="shadow" src="/img/in-post/kerberos/kerberos-8.png" width="1200">
<p>然后在Kerberos client端mount共享文件夹</p>
<p>使用nfs4挂载krb5的共享文件夹</p>
<p>mount时使用主机名、ip地址或全称域名均可</p>
<pre><code class="language-shell">root@kclient241:~# mount -t nfs -o vers=4.2 node111:/vol/folder01 /mnt/folder01/
root@kclient241:~# mount |grep node111
node111:/vol/folder01 on /mnt/folder01 type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=krb5,clientaddr=172.17.75.241,local_lock=none,addr=172.17.72.111)
root@kclient241:~# 
</code></pre>
<p>使用nfs3挂载krb5i的共享文件夹</p>
<pre><code class="language-shell">root@kclient241:~# mount -t nfs -o vers=3 node111:/vol/folder02 /mnt/folder02/
root@kclient241:~# mount |grep node111
node111:/vol/folder01 on /mnt/folder01 type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=krb5,clientaddr=172.17.75.241,local_lock=none,addr=172.17.72.111)
node111:/vol/folder02 on /mnt/folder02 type nfs (rw,relatime,vers=3,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=krb5i,mountaddr=172.17.72.111,mountvers=3,mountport=47733,mountproto=udp,local_lock=none,addr=172.17.72.111)
root@kclient241:~# 
</code></pre>
]]></content>
      <categories>
        <category>kerberos</category>
      </categories>
      <tags>
        <tag>kerberos</tag>
      </tags>
  </entry>
  <entry>
    <title>评测USB接口速度</title>
    <url>/2023/02/28/get_usb_speed/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天同事咨询国产化设备某台硬件服务器上的<code>USB</code>版本是多少，查询了下资料，发现<code>lsusb</code>这个指令可以捞到，mark it.</p>
<h1 id="xin-xi">信息</h1>
<p>如果没有安装，执行</p>
<p><code>apt-get install usbutils </code><br>
or</p>
<p><code>yum install usbutils </code></p>
<p>output:</p>
<pre><code class="language-shell">[root@bigtera etc]# hostnamectl 
   Static hostname: bigtera
         Icon name: computer-server
           Chassis: server
        Machine ID: b3315f4c3ab849a7ae5ffc905a73e45a
           Boot ID: 39bbd8a659fa4465bb4189bc6e4af69a
  Operating System: Kylin Linux Advanced Server V10 (Sword)
            Kernel: Linux 4.19.90-24.4.v2101.ky10.aarch64
      Architecture: arm64
[root@bigtera etc]# lsusb -t
/:  Bus 08.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/1p, 5000M
/:  Bus 07.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/1p, 480M
/:  Bus 06.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/1p, 5000M
    |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/4p, 5000M
/:  Bus 05.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/1p, 480M
    |__ Port 1: Dev 2, If 0, Class=Hub, Driver=hub/4p, 480M
/:  Bus 04.Port 1: Dev 1, Class=root_hub, Driver=ohci-pci/2p, 12M
/:  Bus 03.Port 1: Dev 1, Class=root_hub, Driver=ohci-pci/2p, 12M
/:  Bus 02.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/2p, 480M
/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=ehci-pci/2p, 480M
    |__ Port 1: Dev 2, If 0, Class=Human Interface Device, Driver=usbhid, 480M
    |__ Port 1: Dev 2, If 1, Class=Human Interface Device, Driver=usbhid, 480M
[root@bigtera etc]#
</code></pre>
<div class="note success"><p>说明:</p>
</div>
<ul class="lvl-0">
<li class="lvl-2">
<p>12M --&gt; USB V1.0</p>
</li>
<li class="lvl-2">
<p>480M --&gt; USB V2.0</p>
</li>
<li class="lvl-2">
<p>5000M --&gt; USB V3.0</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>提升 PG scrub速度</title>
    <url>/2023/03/01/pg_deep_scrub/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍如何提升ceph PG scrub 速度</p>
<h1 id="ti-sheng-ceph-pg-scrub-de-su-du">提升CEPH PG scrub的速度</h1>
<p>CEPH会定期（默认每个星期一次）对所有的PGs进行scrub，即通过检测PG中各个osds中数据是否一致来保证数据的安全。</p>
<p>当CEPH更换一块坏硬盘，进行数据修复后，出现了大量的PGs不能及时进行scrub，甚至有些PGs数据不一致，导致CEPH系统报警，如下所示：</p>
<pre><code class="language-shell">  cluster:
    id:     8f1c1f24-59b1-11eb-aeb6-f4b78d05bf17
    health: HEALTH_ERR
            6 scrub errors
            Possible data damage: 5 pgs inconsistent
            1497 pgs not deep-scrubbed in time
            1466 pgs not scrubbed in time

  services:
    mon: 5 daemons, quorum ceph101,ceph103,ceph107,ceph109,ceph105 (age 5d)
    mgr: ceph107.gtrmmh(active, since 9d), standbys: ceph101.qpghiy
    mds: cephfs:3 {0=cephfs.ceph106.hggsge=up:active,1=cephfs.ceph104.zhkcjt=up:active,2=cephfs.ceph102.imxzno=up:active} 1 up:standby
    osd: 360 osds: 360 up (since 5d), 360 in (since 5d)

  data:
    pools:   4 pools, 10273 pgs
    objects: 331.80M objects, 560 TiB
    usage:   1.1 PiB used, 4.2 PiB / 5.2 PiB avail
    pgs:     10261 active+clean
             7     active+clean+scrubbing+deep
             5     active+clean+inconsistent

  io:
    client:   223 MiB/s rd, 38 MiB/s wr, 80 op/s rd, 12 op/s wr
</code></pre>
<p>此时，需要提高对PGs的scrub速度。默认情况下一个OSD近能同时进行一个scrub操作且仅当主机低于0.5时才进行scrub操作。我运维的CEPH系统一个PG对应10个OSDs，每个OSD仅能同时进行一个scrub操作，导致大量scrub操作需要等待，而同时进行的scrub操作数量一般为8个。因此需要在各台存储服务器上对其OSDs进行参数修改，来提高scrub速度。</p>
<p>osd_max_scrubs参数用于设置单个OSD同时进行的最大scrub操作数量；osd_scrub_load参数设置负载阈值。主要修改以上两个参数来提高scrub速度，其默认值为1和0.5。</p>
<p>例如，对ceph101主机中的所有OSDs进行参数修改：</p>
<p>首先，获取ceph101中所有的OSD信息：</p>
<pre><code class="language-shell">ceph osd dump | grep `grep ceph101 /etc/hosts | perl -ne 'print $1 if m/(\d\S*)/'` | perl -ne 'print "$1\n" if m/(osd.\d+)/' &gt; /tmp/osd.list
</code></pre>
<p>然后，对所有OSD的参数进行批量修改：</p>
<pre><code class="language-shell">for i in `cat /tmp/osd.list`
do
    ceph tell $i injectargs --osd_max_scrubs=10 --osd_scrub_load_threshold=10
done
检查修改后的效果

for i in `cat /tmp/osd.list`
do
    echo $i
    ceph daemon $i config show | egrep "osd_max_scrubs|osd_scrub_load"
done
</code></pre>
<p>对所有的CEPH主机进行上述修改后，同时进行scrub的数量提高了30倍，并且使用top命令可以看到ceph-osd进程对CPU的资源消耗明显上升。</p>
<pre><code class="language-shell">  cluster:
    id:     8f1c1f24-59b1-11eb-aeb6-f4b78d05bf17
    health: HEALTH_ERR
            6 scrub errors
            Possible data damage: 5 pgs inconsistent
            1285 pgs not deep-scrubbed in time
            1208 pgs not scrubbed in time
            1 slow ops, oldest one blocked for 37 sec, daemons [osd.124,osd.352] have slow ops.

  services:
    mon: 5 daemons, quorum ceph101,ceph103,ceph107,ceph109,ceph105 (age 5d)
    mgr: ceph107.gtrmmh(active, since 9d), standbys: ceph101.qpghiy
    mds: cephfs:3 {0=cephfs.ceph106.hggsge=up:active,1=cephfs.ceph104.zhkcjt=up:active,2=cephfs.ceph102.imxzno=up:active} 1 up:standby
    osd: 360 osds: 360 up (since 5d), 360 in (since 5d)

  data:
    pools:   4 pools, 10273 pgs
    objects: 331.80M objects, 560 TiB
    usage:   1.1 PiB used, 4.2 PiB / 5.2 PiB avail
    pgs:     10041 active+clean
             152   active+clean+scrubbing+deep
             75    active+clean+scrubbing
             3     active+clean+scrubbing+deep+inconsistent+repair
             2     active+clean+inconsistent

  io:
    client:   65 MiB/s rd, 4.2 MiB/s wr, 21 op/s rd, 2 op/s wr
</code></pre>
<p>此外，注意：（1）提高scrub的并行数可能对CEPH集群内网的网速要求较高，推荐使用10GE以上交换机。（2）条scrub的并行数，会导致一个OSD对应的硬盘同时并行读取的操作数量较高，当导致磁盘100%被使用时，可能磁盘的利用效率并不高，因此不推荐将 osd_max_scrubs参数调节到10以上。</p>
<p>对两个星期内（当前时间2022-08-03）未进行deep-scrubbed，已经有报警信息的PGs进行操作。</p>
<pre><code class="language-shell">ceph pg dump | perl -e 'while (&lt;&gt;) { @_ = split /\s+/; $pg{$_[0]} = $1 if ($_[22] =~ m/2022-07-(\d+)/ &amp;&amp; $1 &lt;= 21); } foreach ( sort {$pg{$a} &lt;=&gt; $pg{$b}} keys %pg ) { print "ceph pg deep-scrub $_; sleep 30;\n"; }' &gt; for_deep_scrub.list

sh for_deep_scrub.list
</code></pre>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 22.04上部署、配置Jenkins</title>
    <url>/2023/03/08/ubuntu22_deploy_jenkins/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文基于Ubuntu 22 安装 Jenkins 2.375.3，记录下部署与调试过程   。</p>
<h1 id="zhun-bei-gong-zuo">准备工作</h1>
<h2 id="an-zhuang-ubuntu-22-04">安装Ubuntu 22.04</h2>
<p>OS信息如下：</p>
<pre><code class="language-shell"> Static hostname: jenkins
       Icon name: computer-vm
         Chassis: vm
      Machine ID: 5876152df2764a3a80c0788e54f81f62
         Boot ID: fb9b1e97473f40df811b0980474c029d
  Virtualization: vmware
Operating System: Ubuntu 22.04.1 LTS              
          Kernel: Linux 5.15.0-43-generic
    Architecture: x86-64
 Hardware Vendor: VMware, Inc.
  Hardware Model: VMware Virtual Platform
</code></pre>
<h2 id="an-zhuang-bi-yao-de-ruan-jian-bao">安装必要的软件包</h2>
<p>如下，列出了必要的软件安装（没有完整的记录下来，可能不全）：</p>
<pre><code class="language-shell">apt-get update
apt-get install git -y
apt-get install libpcsclite1 -y
apt-get install ca-certificates-java -y
apt-get install fonts-dejavu-extra -y --fix-missing
apt-get install libllvm13 -y
apt-get install fonts-dejavu-extra -y
apt-get install openjdk-11-jre-headless -y
apt-get install openjdk-11-jre -y
apt-get install libdrm-amdgpu1 libdrm-nouveau2 libdrm-radeon1 libglapi-mesa libsensors5 libvulkan1 -y
apt-get install libgl1 -y
apt-get install libglvnd0 -y
apt-get install plocate -y
apt-get install git-lfs -y
apt-get install expect -y
apt-get install spawn -y
apt-get install sshpass -y  
apt-get install allure-commandline -y
apt-get install python3-pip -y
apt install jenkins -y
</code></pre>
<p>为了支持Email对pylint 绘图功能，需要安装matlpotib, 相关安装包信息参考如下：</p>
<pre><code class="language-shell">ca-certificates-java_20190909ubuntu1.1_all.deb
contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
cycler-0.11.0-py3-none-any.whl
default-jre-headless_1.11-72build2_amd64.deb
fonts-dejavu-extra_2.37-2build1_all.deb
fonttools-4.38.1.dev0-py3-none-any.whl
g++-11_11.3.0-1ubuntu1~22.04_amd64.deb
java-common_0.72build2_all.deb
libgl1-mesa-dri_22.0.5-0ubuntu0.3_amd64.deb
libllvm13_13.0.1-2ubuntu2_amd64.deb
libpython3.10-dev_3.10.6-1~22.04.2_amd64.deb
matplotlib-3.7.1.tar.gz
numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
openjdk-11-jre-headless_11.0.17+8-1ubuntu2~22.04_amd64.deb
python3.10-minimal_3.10.6-1~22.04.2_amd64.deb
</code></pre>
<h1 id="pei-zhi-jenkins">配置Jenkins</h1>
<p>Jenkins 安装好后，访问8080端口，按提示一步一步往下走，此处不做额外赘述。</p>
<h2 id="jenkins-plugin-de-an-zhuang">Jenkins Plugin 的安装</h2>
<p><strong>需要安装如下插件与工具：</strong></p>
<pre><code class="language-shell">allure
Cobertura Coverage
Violations Plugin # Pylint
AnsiColor         # 颜色
Next Build Number Plugin
</code></pre>
<p>一些基础的Plug，像git, pipline 之类的安装，此处不做赘述。</p>
<p><strong>install allure commandline：</strong></p>
<p>安装包手动<a href="https://repo.maven.apache.org/maven2/io/qameta/allure/allure-commandline/2.21.0/allure-commandline-2.21.0.tgz">下载</a>下来，在Jenkins上使用root 用户，安装到/usr/lib/下，参考如下：</p>
<p><code>/usr/lib/allure-2.21.0/lib/allure-commandline-2.21.0.jar </code></p>
<h2 id="xiu-gai-expect-spawn-ssh-shi-prompt-wu-fa-tong-guo-wen-ti">修改 expect spawn ssh时prompt无法通过问题</h2>
<p>修改vim /etc/ssh/ssh_config</p>
<p><code>StrictHostKeyChecking ask   --&gt;改为 StrictHostKeyChecking no</code></p>
<p>并重启ssh服务，以此来避免expect 中执行spawn交互失败。</p>
<h2 id="jenkins-you-xiang-pei-zhi">Jenkins 邮箱配置</h2>
<p>Jenkins 当前登录UI用户的邮箱，需要和全局配置里设置的邮箱用户名保持一致，否则会报错，参考如下：</p>
<p><img class="shadow" src="/img/in-post/jenkins_email_config.png" width="1200"></p>
<p>参考如下：</p>
<p><code>https://naiveskill.com/jenkins-pipeline-email-notification/</code></p>
<h2 id="jenkins-ni-ming-yong-hu-quan-xian-pei-zhi">Jenkins 匿名用户权限配置</h2>
<p>为了让Email端能够正常展示出allure trend，pylint error，以及CODE COVERAGE信息，需要对匿名用户开放一定的权限：</p>
<p><img class="shadow" src="/img/in-post/Jenkins_permission.png" width="1200"></p>
<h2 id="email-mo-ban">Email 模板</h2>
<p>为了让CI结果更好的展示，基于<a href="https://github.com/jenkinsci/email-ext-plugin/blob/master/src/main/resources/hudson/plugins/emailext/templates/groovy-html.template">官方模板</a>，增加了allure, pylint 和 CODE COVERAGE信息，自定义了一个EMail模板，存放在Jenkins install path下：</p>
<pre><code class="language-shell">jenkins@jenkins:/var/lib/jenkins$ cd email-templates/
jenkins@jenkins:/var/lib/jenkins/email-templates$ ls -l
total 120
-rw-rw-r-- 1 jenkins jenkins  6292 Feb 17 15:49 allure-report.groovy
-rw-r--r-- 1 jenkins jenkins 69669 Mar  7 18:57 v1.0_allure-pipeline-report.groovy
-rw-r--r-- 1 jenkins jenkins  7759 Mar  7 22:24 v1.1_allure-pipeline-report.groovy
jenkins@jenkins:/var/lib/jenkins/email-templates$ 
jenkins@jenkins:/var/lib/jenkins/email-templates$ 
</code></pre>
<p>其中，<strong>v1.1_allure-pipeline-report.groovy</strong> 为当前使用模板，里面有定义一个需要被替换的内容：</p>
<pre><code class="language-shell">  &lt;table&gt;
    &lt;tr&gt;
        &lt;img src="EMAIL_BASE64_IMG_REPLACE" width="500px" height="200px"/&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
</code></pre>
<p>此处内容，需要借助 <strong>edit_email_template.py</strong>  这个代码来生成base64 image并替换，最终被pipline 处的EMail 使用。</p>
<p>需要借助 <strong>edit_email_template.py</strong>  的原因在于，新版本的Jenkins，对于pylint结果产生的图形，是基于canvas，并不是一个静态图片，无法通过HTML中的img src来直接指定。</p>
<h1 id="shi-jian">实践</h1>
<p>如下，以Lab 实际配置截图：</p>
<p><img class="shadow" src="/img/in-post/jenkins_job_config.png" width="1200"></p>
<p>总共设置了String类型的如下参数：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>GIT_WEB  --&gt; <code>http://1.22.21.9/pytest_framework</code></p>
</li>
<li class="lvl-2">
<p>GIT_URL  --&gt; <code>git@1.22.21.9:pytest_framework.git</code></p>
</li>
<li class="lvl-2">
<p>GIT_BRANCH --&gt; 8.3</p>
</li>
<li class="lvl-2">
<p>REPORT_DIR --&gt; /root/${JOB_NAME}/report                                        # Jenkins install path</p>
</li>
<li class="lvl-2">
<p>WORK_SPACE --&gt; ${JENKINS_INSTALL_PATH}/workspace/pytest_8.3_pipeline           # Jenkins work space</p>
</li>
<li class="lvl-2">
<p>JOB_SPACE --&gt; ${JENKINS_INSTALL_PATH}/jobs/pytest_8.3_pipeline                 # pytest job space</p>
</li>
<li class="lvl-2">
<p>BAT_INSTALL --&gt;  /root/batch_install/batch_install.py /root/batch_install/config/pytest/pytest_8.3_pipeline_195_cone # Bat install OS by Cobbler</p>
</li>
<li class="lvl-2">
<p>IPS --&gt; 12.71.57.11,12.71.57.12,12.71.57.13,12.71.57.14,12.71.57.15,12.71.57.16,12.71.57.17,12.71.57.18              # Cluster hosts IP,split by,</p>
</li>
<li class="lvl-2">
<p>CODE_DIR --&gt; /root/${JOB_NAME}/src                                             # pytest code dir which will be runned</p>
</li>
</ul>
<p><strong>Email Template</strong></p>
<p>在<a href="https://github.com/jenkinsci/email-ext-plugin/blob/master/src/main/resources/hudson/plugins/emailext/templates/groovy-html.template">官方模板</a>的基础上，增加了三张图。</p>
<p><strong>pipline Script</strong></p>
<pre><code class="language-shell">#!groovy

ip_list = IPS.split(',')
ips_size = ip_list.size()

def cluster1_ip = ip_list[0..2][1]
def cluster2_ip = ip_list[4..6][1]
def cluster3_ip = ip_list[7..9][1]
def cluster4_ip = ip_list[10..12][1]
def cluster5_ip = ip_list[13..15][1]

def cluster_ip = "${cluster1_ip} ${cluster2_ip} ${cluster3_ip} ${cluster4_ip} ${cluster5_ip}"

/* !!! WARNING !!!
  Introduce the -n parameter, because 03Hosts and 05RRS will involve the fourth node,
  so 03Hosts and 05RRS need to be executed in a cluster 
*/

pipeline {
    agent any

    options {
        timestamps()
        }

    stages {
        /* IP check */
        stage("IP Cheeck") {
                steps {
                    script {
                            sh """
                                if [[ ${ips_size} != 16 ]]; then
                                    echo "IPS is not enough, but give (${ips_size}) nodes to run case"
                                    exit 1
                                fi
                            """
                            }
                       }
            }

        /* Install VM by PVE */
        stage("Initialize") {
                steps {
                    script {
                            sh """
                            #!/bin/bash -xe
                            echo "Call batch_install_vs.py to install ISO."
                            sshpass -p 1 ssh -p 22 12.71.57.236 -l root \${BAT_INSTALL}
                            """
                        }
                }
            }

        /* Get code */
        stage("Code Checkout") {
                steps {
                    retry(2) {
                        timeout(activity: false, time: 60, unit: 'MINUTES') {
                            checkout([$class: 'GitSCM',
                                branches: [[name: GIT_BRANCH]],
                                browser: [$class: 'GitLab', repoUrl: GIT_WEB, version: '12.8'],
                                doGenerateSubmoduleConfigurations: false,
                                extensions: [
                                    [$class: 'CleanBeforeCheckout', deleteUntrackedNestedRepositories: true],
                                    [$class: 'SubmoduleOption', recursiveSubmodules: true],
                                    [$class: 'GitLFSPull'],
                                    [$class: 'PruneStaleBranch']
                                ],
                                submoduleCfg: [],
                                userRemoteConfigs: [[url: GIT_URL]]
                            ])
                        }
                    }
                }
            }

        /* scp code to nodes */
        stage("Sync Code to Cluster Nodes") {
                steps {
                    script {                            
                            sh """
                            #!/bin/bash -xe
                            cd \${WORK_SPACE};
                            rm -rf build.properties;
                            rm -rf report;
                            cd jenkins;
                            chmod a+x *.sh;
                            for each_ip in ${cluster_ip}
                                do
                                    echo "Scp code to node : \${each_ip}"
                                    ssh-keygen -f '$HOME/.ssh/known_hosts' -R \${each_ip};
                                    ./rsync_pytest.sh \${WORK_SPACE} \${each_ip} root p@ssw0rd
                                    sleep 1
                                done
                            """
                        }
                    }
            }

        // Parallel Stage
        stage('Parallel Stage to Run Cases') {
            failFast true
            parallel {
                stage('Run test case on Cluster1') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster1_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root ${cluster1_ip} \'cd ${CODE_DIR}; dpkg -i ../python_3rd_lib/python-configobj_4.7.2+ds-3build1_all.deb;cp config/autotest_11_12_13.config config/autotest.config;python run.py -t \"testcase/Function_Test/case_03_Hosts/\" -n True \'"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }


                    }
                }
                stage('Run test case on Cluster2') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster2_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root ${cluster2_ip} \'cd ${CODE_DIR}; dpkg -i ../python_3rd_lib/python-configobj_4.7.2+ds-3build1_all.deb;cp config/autotest_15_16_17.config config/autotest.config;python run.py -t \"testcase/Function_Test/case_11_CSI testcase/Function_Test/case_10_S3/test_05_datasearch.py \"\'"

                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }
                    }
                }
                stage('Run test case on Cluster3') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster3_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root ${cluster3_ip} \'cd ${CODE_DIR}; dpkg -i ../python_3rd_lib/python-configobj_4.7.2+ds-3build1_all.deb;cp config/autotest_18_19_20.config config/autotest.config;python run.py -t \"testcase/Function_Test/case_04_Virtual_Storages/03_NAS \"\'"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }


                    }
                }
                stage('Run test case on Cluster4') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster4_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root ${cluster4_ip} \'cd ${CODE_DIR}; dpkg -i ../python_3rd_lib/python-configobj_4.7.2+ds-3build1_all.deb;cp config/autotest_21_22_23.config config/autotest.config;rm -rf testcase/Function_Test/case_10_S3/test_05_datasearch.py;python run.py -t \"testcase/Function_Test/case_10_S3/ \"\'"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }
                    }
                }
                stage('Run test case on Cluster5') {
                    steps {
                        script {
                            try {
                                echo "Run test case on node : ${cluster5_ip}"
                                sh "sshpass -p p@ssw0rd ssh -p 22 -l root ${cluster5_ip} \'cd ${CODE_DIR}; dpkg -i ../python_3rd_lib/python-configobj_4.7.2+ds-3build1_all.deb;cp config/autotest_24_25_26.config config/autotest.config;python run.py -t \"testcase/Function_Test/case_99_others \"\'"
                            }catch(err){
                                echo "${err}"
                                sh 'exit 1'
                            }
                        }
                    }
                }
            }
        }

    /* Merge report */
        stage("Merge Report") {
            steps {
                script {
                    sh """
                        #!/bin/bash -xe
                        JENKINS_IP=`cat \${JENKINS_INSTALL_PATH}/jenkins.model.JenkinsLocationConfiguration.xml | grep jenkinsUrl | awk -F ':' '{{print \$2}}' | sed 's#/##g'`
                        rm -rf \${WORK_SPACE}/report/*
                        cd \${WORK_SPACE}/jenkins;
                        for each_ip in ${cluster_ip}
                            do
                                echo "Scp report from : (\${each_ip}) to jenkins node"
                                ./rsync_report.sh \${each_ip} btadmin btadmin \${REPORT_DIR} \${WORK_SPACE} \${JENKINS_IP};
                            done
                        ./jenkins_build_properties.sh \${WORK_SPACE}
                        """
                    }
            }
        }

        stage("Generate Allure Report") {
            steps {
                script {
                    allure([
                            includeProperties: false,
                            jdk: '',
                            properties: [],
                            reportBuildPolicy: 'ALWAYS',
                            results: [[path: 'report/json']]
                       ])
                    }
                }
        }

        /* Publish Cobertura Coverage Report */
        stage("Publish Cobertura Coverage Report") {
            steps {
                script {
                       cobertura([
                               autoUpdateHealth: false,
                               autoUpdateStability: false,
                               coberturaReportFile: 'report/coverage.xml',
                               conditionalCoverageTargets: '70, 0, 0',
                               failUnhealthy: false,
                               failUnstable: false,
                               lineCoverageTargets: '80, 0, 0',
                               maxNumberOfBuilds: 0,
                               methodCoverageTargets: '80, 0, 0',
                               onlyStable: false,
                               sourceEncoding: 'ASCII',
                               zoomCoverageChart: false
                       ])
                    }
                }
        }

        /* Generate pylint Report */
        stage('Code Quality Check') {
            steps {
                script{
                    echo "Run pylint code style check"
        		    // Ignore pylint comments via "-d C"
                    /*
        		    sh '''
        		    	. .venv/bin/activate
        			    pylint -d C -f parseable ${SOURCE_ROOT} --exit-zero | tee ${PYLINT_REPORT}
        		    '''
                    */
                }
        	}

        	post { 
                always {
                   sh 'cat report/pylint.out'
                   recordIssues healthy: 1, tools: [pyLint(name: 'PyLint', pattern: 'report/pylint.out')], unhealthy: 2
                }
            }
        }

    /* Edit Email Template */
        stage("Edit Email Template") {
            steps {
                script {
                    sh """
                        #!/bin/bash -xe
                        cp \${JENKINS_INSTALL_PATH}/email-templates/v1.1_allure-pipeline-report.groovy \${JENKINS_INSTALL_PATH}/email-templates/allure-pipeline-report.groovy
                        cd \${WORK_SPACE}/jenkins; 
                        python3 edit_email_template.py \${JOB_SPACE}/builds \${JENKINS_INSTALL_PATH}/email-templates/allure-pipeline-report.groovy EMAIL_BASE64_IMG_REPLACE
                        """
                    }
            }
        }

        /* Send Email */
        stage("Send Email") {
            steps {
                script {
                        /*
                        build_status = sh (
                            script: """curl http://127.0.0.1:8080/job/${JOB_NAME}/lastBuild/api/json | json_pp | grep result | sed 's/   \"result" : \"//g' | sed 's/",//g'""",
                            returnStdout: true
                            ).trim()
                        echo "build status  ${build_status}"
                       */

                       product_version = sh (
                            script: """sshpass -p btadmin ssh -p 22 ${cluster1_ip} -l btadmin ezs3-version""",
                            returnStdout: true
                            ).trim()
                        env.PRODUCT_VERSION = product_version

                        emailext([
                                // attachLog: true,
                                // attachmentsPattern: 'report/cgi_response_elapsed_time.txt,report/pytest_autotest.log.gz',
                                attachmentsPattern: 'report/cgi_response_elapsed_time.txt',
                                body: '${SCRIPT, template="allure-pipeline-report.groovy"}',
                                compressLog: true,
                                postsendScript: '$DEFAULT_POSTSEND_SCRIPT',
                                presendScript: '$DEFAULT_PRESEND_SCRIPT',
                                replyTo: '$PROJECT_DEFAULT_REPLYTO',
                                // subject: '${env.PROJECT_DEFAULT_SUBJECT}',
                                subject: '${JOB_NAME} - ${BUILD_DISPLAY_NAME}',
                                to: 'zhangsan@163.com'
                       ])
                    }
                }
        }
    }
}
</code></pre>
<p>如果想生成3个维度的数据，示例代码如下：</p>
<pre><code class="language-python">import base64
import io
import matplotlib.pyplot as plt
from matplotlib.ticker import MultipleLocator

def generate_chart(x, excellent, satisfactory, failing):
    fig = plt.figure(figsize=(15, 7.5))
    ax = fig.add_subplot(111)
    ax.stackplot(
        x,
        excellent, satisfactory, failing,
        colors=("#c0e2c1", "#fff8ba", "#f4b8b8"),
        labels=('Excellent', 'Satisfactory', 'Failing'),
    )
    ax.legend()
    # ax.set_title("History")    ax.set_xlabel("Builds")
    ax.set_ylabel("Amounts")
    ax.xaxis.set_minor_locator(MultipleLocator(1))
    ax.yaxis.set_major_locator(MultipleLocator(1))
    output = io.BytesIO()
    plt.savefig(output, bbox_inches='tight')
    output.seek(0)
    encoded = base64.b64encode(output.read())
    return f"data:image/jpg;base64,{encoded.decode('utf8')}"


if __name__ == "__main__":
    x = [79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102]
    excellent = [0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3]
    satisfactory = [0,0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2]
    failing = [0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,93]
    res = generate_chart(x, excellent, satisfactory, failing)
    print(res)
</code></pre>
<h1 id="xiao-guo-zhan-shi">效果展示</h1>
<p>最终EMail 邮寄出来的内容如下：</p>
<p>全部成功状态下：</p>
<p><img class="shadow" src="/img/in-post/jenkins_build_success.png" width="1200"></p>
<p>部分用例失败状态下：</p>
<p><img class="shadow" src="/img/in-post/jenkins_build_unstable.png" width="1200"></p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>Jenkins</category>
        <category>CI</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Jenkins</tag>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title>磁盘性能评估与实测</title>
    <url>/2023/03/10/disk_performance_evaluation/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍硬盘性能评估，并做了一些实测。</p>
<h1 id="gai-nian-jie-shao">概念介绍</h1>
<p>寻道时间Tseek是指将读写磁头移动至正确的磁道上所需要的时间。寻道时间越短，I/O操作越快，目前磁盘的平均寻道时间一般在3－15ms。</p>
<p>旋转延迟Trotation是指盘片旋转将请求数据所在扇区移至读写磁头下方所需要的时间。旋转延迟取决于磁盘转速，通常使用磁盘旋转一周所需时间的1/2表示。比如，7200 rpm的磁盘平均旋转延迟大约为60*1000/7200/2 = 4.17ms，而转速为15000 rpm的磁盘其平均旋转延迟约为2ms。</p>
<p>数据传输时间Ttransfer是指完成传输所请求的数据所需要的时间，它取决于数据传输率，其值等于数据大小除以数据传输率。目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率，数据传输时间通常远小于前两部分时间。</p>
<p>因此，理论上可以计算出磁盘的最大IOPS，即IOPS = 1000 ms/ (Tseek + Troatation)，忽略数据传输时间。假设磁盘平均物理寻道时间为3ms, 磁盘转速为7200,10K,15K rpm，则磁盘IOPS理论最大值分别为，</p>
<pre><code class="language-shell">IOPS = 1000 / (3 + 60000/7200/2) = 140
IOPS = 1000 / (3 + 60000/10000/2) = 167
IOPS = 1000 / (3 + 60000/15000/2) = 200
</code></pre>
<h1 id="ci-pan-xing-neng-ping-gu-shi-ce">磁盘性能评估实测</h1>
<img class="shadow" src="/img/in-post/disk_performace-1.png" width="1200">
<p>此测试是对裸盘使用fio进行读写测试，分别是1M顺序读写和4K随机读写，并采用同等测试方法对基于不同raid创建的OSD进行读写测试，详细测试数据下表：</p>
<img class="shadow" src="/img/in-post/disk_performace-2.png" width="1200">
<p>结论：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Raid0：条带大小对读写性能影响不大；</p>
</li>
<li class="lvl-2">
<p>Raid0、Raid1 类型的阵列，增加 N 块盘，磁盘阵列读、写都有提升，效果相当于多了N块盘的性能；</p>
</li>
<li class="lvl-2">
<p>Raid5、Raid6 类型的阵列，增加磁盘，对 4K 随机写性能影响不大，对4K 随机读有略微提升</p>
</li>
</ul>
<p>BBU和缓存策略对磁盘性能的影响:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>对randwrite影响最大，启用BBU的randwrite约为未启用的8倍左右</p>
</li>
<li class="lvl-2">
<p>未启用BBU的场景randread反而略有提升</p>
</li>
<li class="lvl-2">
<p>对1M顺序读写没有太大影响</p>
</li>
</ul>
<p>创建了OSD的磁盘读写性能略微有些下降，但是可以忽略不计。</p>
<div class="note success"><p>说明：</p>
</div>
<ul class="lvl-0">
<li class="lvl-2">
<p>测试为先在路径/data/osd.x/下先写一个200G大小的文件，对该文件进行读写测试，文件大小对顺序读写无影响，对随机读写有影响，小文件随机读写性能随文件size增大而减小</p>
</li>
<li class="lvl-2">
<p>OSD创建完成后会在后台进行ext4lazyinit，此进程会影响OSD的读写性能，大小越大43.661 TiB大小的OSD的ext4lazyinit会持续约一个小时10分钟左右</p>
<p>​								​								​								​								​								​								​										​										​</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Disk</category>
      </categories>
      <tags>
        <tag>Disk</tag>
      </tags>
  </entry>
  <entry>
    <title>LV 扩容</title>
    <url>/2023/03/16/ubuntu22_lv_capacity_expansion/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>前段时间基于Ubuntu22.04 搭建了Jenkins, VM 当时给的 OS disk size是100G, 今天查看环境，无意间发现/空间使用率接近50%。</p>
<p>本文简易概述LV扩容。</p>
<h1 id="xian-xiang">现象</h1>
<pre><code class="language-shell">root@jenkins:~# df -Ph
Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                              796M  1.2M  794M   1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv   48G   22G   25G  47% /
tmpfs                              3.9G     0  3.9G   0% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/sda2                          2.0G  126M  1.7G   7% /boot
tmpfs                              796M  4.0K  796M   1% /run/user/0
root@jenkins:~# lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
fd0                         2:0    1     4K  0 disk 
loop0                       7:0    0  63.3M  1 loop /snap/core20/1822
loop1                       7:1    0  63.3M  1 loop /snap/core20/1828
loop2                       7:2    0  79.9M  1 loop /snap/lxd/22923
loop3                       7:3    0 111.9M  1 loop /snap/lxd/24322
loop4                       7:4    0  49.8M  1 loop /snap/snapd/17950
loop5                       7:5    0  49.8M  1 loop /snap/snapd/18357
sda                         8:0    0   100G  0 disk 
├─sda1                      8:1    0     1M  0 part 
├─sda2                      8:2    0     2G  0 part /boot
└─sda3                      8:3    0    98G  0 part 
  └─ubuntu--vg-ubuntu--lv 253:0    0    49G  0 lvm  /
sr0                        11:0    1  1024M  0 rom  
</code></pre>
<p>可用空间98G，实际只分配了49G，余下空间想利用起来。</p>
<h1 id="shi-jian">实践</h1>
<ol>
<li class="lvl-3">
<p>查看可用空间</p>
</li>
</ol>
<pre><code class="language-shell">root@jenkins:~# lvdisplay
  --- Logical volume ---
  LV Path                /dev/ubuntu-vg/ubuntu-lv
  LV Name                ubuntu-lv
  VG Name                ubuntu-vg
  LV UUID                c5tkxV-ZwMC-rVs5-ucVU-gYeQ-B36P-Fgw3JT
  LV Write Access        read/write
  LV Creation host, time ubuntu-server, 2023-01-29 15:41:37 +0800
  LV Status              available
  # open                 1
  LV Size                &lt;49.00 GiB
  Current LE             12543
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           253:0
   
root@jenkins:~# 
</code></pre>
<pre><code class="language-shell">root@jenkins:~# fdisk -l /dev/sda
Disk /dev/sda: 100 GiB, 107374182400 bytes, 209715200 sectors
Disk model: Virtual disk    
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: gpt
Disk identifier: EEA2172F-74FA-41F6-AB3C-D4E8F8F5A991

Device       Start       End   Sectors Size Type
/dev/sda1     2048      4095      2048   1M BIOS boot
/dev/sda2     4096   4198399   4194304   2G Linux filesystem
/dev/sda3  4198400 209713151 205514752  98G Linux filesystem
root@jenkins:~#
</code></pre>
<p>从上图可以看出磁盘大小(98)大于系统逻辑分区大小(49G)，知道了现在磁盘完全可以提升利用率，就可以直接进行扩容，不需要额外增加硬盘</p>
<ol start="2">
<li class="lvl-3">
<p>执行命令扩容</p>
</li>
</ol>
<p><code>lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv</code></p>
<pre><code class="language-shell">root@jenkins:~# lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv
  Size of logical volume ubuntu-vg/ubuntu-lv changed from &lt;49.00 GiB (12543 extents) to &lt;98.00 GiB (25087 extents).
  Logical volume ubuntu-vg/ubuntu-lv successfully resized.
root@jenkins:~# 
</code></pre>
<p>注意后面的逻辑分区名字使用lvdisplay命令获取到的</p>
<p>3、执行 命令 <code>resize2fs /dev/ubuntu-vg/ubuntu-lv</code> 刷新逻辑卷</p>
<p>4、执行命令df -h查看效果</p>
<pre><code class="language-shell">root@jenkins:~# df -Ph
Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                              796M  1.2M  794M   1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv   97G   22G   71G  24% /
tmpfs                              3.9G     0  3.9G   0% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/sda2                          2.0G  126M  1.7G   7% /boot
tmpfs                              796M  4.0K  796M   1% /run/user/0
root@jenkins:~# 

root@jenkins:~# lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
fd0                         2:0    1     4K  0 disk 
loop0                       7:0    0  63.3M  1 loop /snap/core20/1822
loop1                       7:1    0  63.3M  1 loop /snap/core20/1828
loop2                       7:2    0  79.9M  1 loop /snap/lxd/22923
loop3                       7:3    0 111.9M  1 loop /snap/lxd/24322
loop4                       7:4    0  49.8M  1 loop /snap/snapd/17950
loop5                       7:5    0  49.8M  1 loop /snap/snapd/18357
sda                         8:0    0   100G  0 disk 
├─sda1                      8:1    0     1M  0 part 
├─sda2                      8:2    0     2G  0 part /boot
└─sda3                      8:3    0    98G  0 part 
  └─ubuntu--vg-ubuntu--lv 253:0    0    98G  0 lvm  /
sr0                        11:0    1  1024M  0 rom  
root@jenkins:~# 
root@jenkins:~#
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Loop assign GWs to different VS</title>
    <url>/2023/03/31/assign_gw_to_vs/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>RD has a scenario like the fallowing:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>3-node cluster, each node with GW services enabled, all under Default VS by default</p>
</li>
<li class="lvl-2">
<p>Create VS-1 and assign GW1 to VS-1</p>
</li>
<li class="lvl-2">
<p>Create VS-2 and assign GW2 and GW3 to VS-2</p>
</li>
<li class="lvl-2">
<p>Create VS-3, assign GW1 to VS-3, and delete VS-1</p>
</li>
<li class="lvl-2">
<p>Create VS-4, assign GW2 and GW3 to VS-4, and delete VS-2</p>
</li>
<li class="lvl-2">
<p>So on and so forth, after each round of allocation, you need to check the health status of ctdb under the current VS</p>
</li>
</ul>
<p>Considering that manual testing can be time consuming, write a test script and run it overnight or more rounds (e.g: loop 1000 times) and see how the test works the next day.</p>
<h1 id="script-of-assign-gw-v-8-3-sh">Script of assign_gw_v8.3.sh</h1>
<pre><code class="language-shell">#!/bin/bash

target="1.2.3.164"
user="admin"
pass="1"
gateways1="1.2.3.164"
gateways2="1.2.3.165"
single_gateways="1.2.3.166"
no_gws=2
previous_vs="Default"
log_file="/var/log/assign_vs.log"


function login(){
    login_res=`curl --insecure --cookie-jar cookie.jar -s -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${target}:8080/auth" --data "{\"password\": \"${pass}\", \"user_id\": \"${user}\"}"`
    login_return_code=`echo ${login_res} | sed 's@{"name": "login", "return_code": @@' | sed 's/}//'`

    if [ x"${login_return_code}" == x"300" ]; then
        echo ""
        echo "[ERROR]  Login Failed, exit!!!"
        echo ""
        exit 1
    elif [[ ${login_return_code} =~ 'session_id' ]]; then
        echo ""
        echo "Login success"
        echo ""
    fi
}


function loop_assign_gws(){
    for i in `seq 1 1000`
    do
      echo "============================  ($i) times to run  ============================\n" | tee -a ${log_file}
    
      date_time=`date +"%Y-%m-%d %H:%M:%S"`
      echo -e "[${date_time}]  Start to create VS and assign GW to VS" | tee -a ${log_file} 
      vs="vs-$i"
      res=`curl --insecure --cookie cookie.jar "https://${target}:8080/cgi-bin/ezs3/json/gwgroup_create?name=${vs}&amp;vs_type=standard"`
      if [[ ${res} =~ 'unauthorized' ]]; then
          login
          curl --insecure --cookie cookie.jar "https://${target}:8080/cgi-bin/ezs3/json/gwgroup_create?name=${vs}&amp;vs_type=standard"
      fi
      curl --insecure --cookie cookie.jar -X PUT --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${target}:8080/vs/${vs}/pool" --data '{"pools":["Default"]}'
      curl  --insecure --cookie cookie.jar -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${target}:8080/vs/${vs}/host" --data "{\"ip\":\"${gateways1}\"}"
      curl  --insecure --cookie cookie.jar -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${target}:8080/vs/${vs}/host" --data "{\"ip\":\"${gateways2}\"}"
    
      if [ $i -ge 2 ]; then
          old_vs="vs-$((i-1))"
          curl  --insecure --cookie cookie.jar -X POST --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${target}:8080/vs/${old_vs}/host" --data-raw "{\"ip\":\"${single_gateways}\"}"
      fi
    
      ctdb_cnt=`ssh root@${target} 'ctdb status|grep OK|wc -l'`
      while [ $ctdb_cnt -ne ${no_gws} ]
      do
        date_time=`date +"%Y-%m-%d %H:%M:%S"`
        echo -e "[${date_time}]  Not done yet, wait for 5 seconds." | tee -a ${log_file}
        sleep 5
        ctdb_cnt=`ssh root@${target} 'ctdb status|grep OK|wc -l'`
      done

      date_time=`date +"%Y-%m-%d %H:%M:%S"`
      echo -e "[${date_time}]  All gateways successfully assigned to virtual storage ${vs}." | tee -a ${log_file}

      if [ $previous_vs != "Default" ]; then
         date_time=`date +"%Y-%m-%d %H:%M:%S"`
         echo -e "[${date_time}]  Delete VS ${vs}"  | tee -a ${log_file}
         curl --insecure --cookie cookie.jar -X DELETE --header "Accept: application/json, text/javascript, */*; q=0.01" --header "Content-Type: application/json" "https://${target}:8080/vs/$previous_vs"
      fi
      previous_vs=$vs
    done
}


login
loop_assign_gws
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下部署HDFS</title>
    <url>/2023/04/09/deploy_hdfs/</url>
    <content><![CDATA[<h1 id="hdfs-an-zhuang-bu-shu">HDFS 安装部署</h1>
<h2 id="yi-xi-tong-qian-xi">一、系统浅析</h2>
<p>HDFS是Hadoop生态下的分布式文件系统, 其中，DataNode和NameNode是HDFS的两大核心。</p>
<p>NameNode（名称节点）：</p>
<p>保存整个文件系统的目录信息、文件信息及分块信息，如果主 NameNode 失效，切换到Secondary NameNode。</p>
<p>NameNode管理文件系统的命名空间，它维护着文件系统树及整棵树内所有的文件和目录，即元数据（MetaData）。</p>
<p>如果NameNode不可用，那么等同于整个HDFS文件系统不可用。如果NameNode由于故障导致磁盘数据丢失，那么等同于整个HDFS文件系统数据丢失。如果NameNode块映射关系的内存爆满，那么等同于整个HDFS文件系统无法再继续存储，也就是意味着NameNode内存决定了HDFS能够存储的块数量。</p>
<p>DataNode（数据节点）：</p>
<p>分布在廉价的计算机上，用于存储Block块文件。 DataNode角色的节点是真正存放块（block）数据的节点，当DataNode启动时，它将扫描其本地文件系统，生成与每个本地文件相对应的所有HDFS数据块的列表，并将此报告发送到NameNode。该报告称为BlockReport。</p>
<p>现在需要将hdfs部署在我司scaler之上。即可以通过 HDFS客户端上载文件，然后底层存储接入scaler，以scaler存储HDFS数据。</p>
<h2 id="er-scaler-ji-qun-bu-shu">二、scaler 集群部署</h2>
<p>本文以scaler 8.3 版本详细说明HDFS部署在scaler上的操作过程。</p>
<p>1、创建集群</p>
<p>关于scaler 8.3部分的部署暂不描述。</p>
<p>2、创建pool hdfs</p>
<p>3、将pool hdfs 加入cephfs data pool</p>
<p>4、新建sharefolder，名字为hdfs</p>
<p>5、在hdfs下创建文件夹备HDFS的namenode、datanode、jornalnode使用</p>
<pre><code class="language-shell">root@host11:/var/share/ezfs/shareroot/hdfs# mkdir host11 host12 host13
root@host11:/var/share/ezfs/shareroot/hdfs# mkdir -p host11/name host11/data host11/jn
root@host11:/var/share/ezfs/shareroot/hdfs# mkdir -p host12/name host12/data host12/jn
root@host11:/var/share/ezfs/shareroot/hdfs# mkdir -p host13/name host13/data host13/jn
查看目录结构：
root@host11:/var/share/ezfs/shareroot/hdfs# tree
├── host11
│   ├── data
│   └── name
│   └── jn
├── host12
│   ├── data
│   └── name
│   └── jn
├── host13
│   ├── data
│   └── name
│   └── jn
</code></pre>
<h2 id="san-hdfs-bu-shu">三、HDFS部署</h2>
<h3 id="1-hadoop-xia-zai">1、hadoop下载</h3>
<pre><code class="language-shell">wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz
</code></pre>
<h3 id="2-jie-ya">2、解压</h3>
<p>在所有节点上解压hadoop包， 命令如下</p>
<pre><code class="language-shell">tar -zxvf hadoop-3.3.2.tar.gz -C /usr/local/
</code></pre>
<h3 id="3-zhong-ming-ming">3、重命名</h3>
<p>在所有节点上重命名hadoop</p>
<pre><code class="language-shell">onnode all mv /usr/local/hadoop-3.3.2 /usr/local/hadoop
 
</code></pre>
<h3 id="4-huan-jing-bian-liang-pei-zhi">4、环境变量配置</h3>
<p>Hadoop安装时需要配置一些环境变量，如指定HADOOP_HOME位置，指定java环境变量等，主要集中在两个配置文件中。</p>
<p>修改/etc/profile配置</p>
<pre><code class="language-shell">vim /etc/profile
# 添加如下配置
export HADOOP_HOME=/usr/local/hadoop
export PATH=.:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$PATH
# export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
# export PATH=$JAVA_HOME/bin:$PATH
# export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
 
</code></pre>
<p>加载环境变量</p>
<pre><code class="language-shell">source /etc/profile
</code></pre>
<p>修改hadoop-env.sh配置</p>
<p>hadoop-env.sh为hadoop运行环境定义hadoop运行环境相关的配置信息</p>
<pre><code class="language-shell">vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh
# 添加如下配置
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre/
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HADOOP_SECURE_LOG=/var/log/hdfs
export HADOOP_ROOT_LOGGER=INFO,console
export HADOOP_DAEMON_ROOT_LOGGER=INFO,RFA
export HADOOP_SECURITY_LOGGER=INFO,NullAppender
export HADOOP_AUDIT_LOGGER=INFO,NullAppender
export HDFS_NAMENODE_OPTS="-Dhadoop.security.logger=INFO,RFAS"
export HDFS_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=INFO,RFAS"
</code></pre>
<p>修改dev_env.sh配置</p>
<pre><code class="language-shell">vim /etc/profile.d/dev_env.sh
# 添加如下配置
export HADOOP_HOME=/usr/local/hadoop
export PATH=.:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$PATH
 
</code></pre>
<p>以上配置文件完成，需要同步复制到其它所有节点</p>
<h3 id="5-xiu-gai-mu-lu-quan-xian">5、修改目录权限</h3>
<p>用户名及用户组</p>
<pre><code class="language-shell">chown -R root /usr/local/hadoop
chgrp -R root /usr/local/hadoop
</code></pre>
<h3 id="6-yan-zheng">6、验证</h3>
<pre><code class="language-shell">root@host12:/usr/local/hadoop/etc/hadoop#  hadoop version
Hadoop 3.3.2
Source code repository git@github.com:apache/hadoop.git -r 0bcb014209e219273cb6fd4152df7df713cbac61
Compiled by chao on 2022-02-21T18:39Z
Compiled with protoc 3.7.1
From source with checksum 4b40fff8bb27201ba07b6fa5651217fb
This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-3.3.2.jar
</code></pre>
<p>如上提示即为配置成功</p>
<h3 id="7-xiu-gai-hdfs-pei-zhi-wen-jian">7、修改HDFS配置文件</h3>
<p>Hadoop所有的配置文件都存在于安装目录下的etc/hadoop中，需要修改如下配置文件</p>
<h4 id="7-1-core-site-xml-pei-zhi">7.1、core-site.xml配置</h4>
<p>core-site.xml：集群全局参数，用于定义系统级别的参数，如HDFS URL 、Hadoop的临时目录等</p>
<p>·    fs.defaultFS：HDFS的默认访问路径。</p>
<p>·    hadoop.tmp.dir：Hadoop临时文件的存放目录，可自定义。</p>
<pre><code class="language-shell">vim /usr/local/hadoop/etc/hadoop/core-site.xml

&lt;configuration&gt;
   &lt;property&gt;
       &lt;name&gt;fs.defaultFS&lt;/name&gt;
       &lt;value&gt;hdfs://mycluster&lt;/value&gt; 
   &lt;/property&gt;
   &lt;property&gt;
       &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
       &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;
   &lt;/property&gt;
   &lt;property&gt;
       &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
       &lt;value&gt;host11:2181,host12:2181,host13:2181&lt;/value&gt;
   &lt;/property&gt;
&lt;/configuration&gt;
 
</code></pre>
<h4 id="7-2-xiu-gai-hdfs-hdfs-site-xml-pei-zhi">7.2、修改hdfs hdfs-site.xml配置</h4>
<p>hdfs-site.xml HDFS 如名称节点和数据节点的存放位置、文件副本的个数、文件的读取权限等</p>
<pre><code class="language-shell">vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml

&lt;configuration&gt;
    &lt;!-- 定义集群名称 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.nameservices&lt;/name&gt;
        &lt;value&gt;mycluster&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 定义集群中NameNode节点 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;
        &lt;value&gt;nn1,nn2,nn3&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- nn1的RPC通信地址 host11为实际机器的hostname --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;
        &lt;value&gt;host11:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- nn2的RPC通信地址 host12为实际机器的hostname --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;
        &lt;value&gt;host12:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- nn3的RPC通信地址 host13为实际机器的hostname --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn3&lt;/name&gt;
        &lt;value&gt;host13:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- nn1的http通信地址  host11为实际机器的hostname--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;
        &lt;value&gt;host11:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- nn2的http通信地址 host12为实际机器的hostname--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;
        &lt;value&gt;host12:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- nn3的http通信地址 host13为实际机器的hostname --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.mycluster.nn3&lt;/name&gt;
        &lt;value&gt;host13:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定NameNode元数据在JournalNode上的存放位置 hostname以实际配置为准 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
        &lt;value&gt;qjournal://host11:8485;host12:8485;host13:8485/mycluster&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
        &lt;value&gt;sshfence&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
        &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 1、声明journalnode服务器存储目录 目录结构在上文中已经创建，如果不创建则会报错
         2、/host11/jn， 每个节点都需要修改为自己节点hostname，三个节点各不相同
    --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
        &lt;value&gt;/var/share/ezfs/shareroot/hdfs/host11/jn&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 关闭权限检查--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.permissions.enable&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;             
        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- namenode存储目录，每个节点各不相同，目录结构已经在上文中创建--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.name.dir&lt;/name&gt;
        &lt;value&gt;/var/share/ezfs/shareroot/hdfs/host11/name&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--DateNode存储目录，没有则新建--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.data.dir&lt;/name&gt;
        &lt;value&gt;/var/share/ezfs/shareroot/hdfs/host11/data&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--文件在HDFS系统中的副本数--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;3&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;root&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
 
</code></pre>
<h4 id="7-3-xiu-gai-qi-ting-pei-zhi">7.3、修改启停配置</h4>
<p>修改启动的配置文件：<a href="http://start-dfs.sh">start-dfs.sh</a></p>
<pre><code class="language-shell">vim /usr/local/hadoop/sbin/start-dfs.sh
# 添加如下配置
HDFS_DATANODE_USER=root
HADOOP_SECURE_USER=root
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
HDFS_ZKFC_USER=root
HDFS_JOURNALNODE_USER=root

</code></pre>
<p>修改停用的配置文件：<a href="http://stop-dfs.sh">stop-dfs.sh</a></p>
<pre><code class="language-shell">vim /usr/local/hadoop/sbin/stop-dfs.sh
# 添加如下配置
HDFS_DATANODE_USER=root
HADOOP_SECURE_USER=root
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
HDFS_ZKFC_USER=root
HDFS_JOURNALNODE_USER=root
 
</code></pre>
<h4 id="7-4-workers-she-zhi">7.4、workers 设置</h4>
<pre><code class="language-shell">vim /usr/local/hadoop/etc/hadoop/workers
host11
host12
host13
# 以实际机器的hostname为准
 
</code></pre>
<h4 id="7-5-hosts-she-zhi">7.5、hosts设置</h4>
<p>服务器端host配置</p>
<pre><code class="language-shell">vim /etc/hosts
172.17.73.11 host11
172.17.73.12 host12
172.17.73.13 host13
# 需要把127.0.1.1 注释掉，否则后面会出错。
# 以实际机器的hostname为准

</code></pre>
<h4 id="7-6-chuang-jian-ruan-jian-lian-jie">7.6、创建软件链接</h4>
<pre><code class="language-shell">onnode all ln -s /usr/share/elasticsearch/jdk/bin/jps /bin/jps
 
</code></pre>
<h2 id="si-zookeeper-bu-fen">四、zookeeper部分：</h2>
<h3 id="1-jie-ya">1、解压</h3>
<pre><code class="language-shell">tar -zxvf /home/btadmin/zookeeper.tar.gz -C /usr/local
 
</code></pre>
<h3 id="2-chuang-jian-wen-jian-jia">2、创建文件夹</h3>
<pre><code class="language-shell">mkdir -p /usr/local/zookeeper/zkData
 
</code></pre>
<h3 id="3-xiu-gai-wen-jian-ming">3、修改文件名</h3>
<pre><code class="language-shell">mv /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo.cfg
</code></pre>
<h3 id="4-xiu-gai-wen-jian-zoo-cfg">4、修改文件zoo.cfg</h3>
<pre><code class="language-shell">vim /usr/local/zookeeper/conf/zoo.cfg

#添加如下配置

dataDir=/usr/local/zookeeper/zkData/
server.1=host11:2888:3888
server.2=host12:2888:3888
server.3=host13:2888:3888
 
admin.serverPort=8085
 
</code></pre>
<h3 id="5-xiu-gai-mu-lu-quan-xian-1">5、修改目录权限</h3>
<p>用户名及用户组</p>
<pre><code class="language-shell">chown -R root /usr/local/zookeeper
chgrp -R root /usr/local/zookeeper
</code></pre>
<h3 id="6-xiu-gai-wen-jian-myid-wen-jian">6、修改文件myid文件</h3>
<p>在多个节点上分别配置myid文件，序号依次增加</p>
<p>在第一个节点值为1</p>
<pre><code class="language-shell">vim /usr/local/zookeeper/zkData/myid
1
</code></pre>
<p>在第二个节点值为2</p>
<pre><code class="language-shell">vim /usr/local/zookeeper/zkData/myid
2
</code></pre>
<p>在第三个节点值为3</p>
<pre><code class="language-shell">vim /usr/local/zookeeper/zkData/myid
3
</code></pre>
<h2 id="wu-qi-dong-ji-qun">五、启动集群</h2>
<p>HDFS HA配置完成后，下面我们将集群启动</p>
<h3 id="1-xian-qi-dong-zookeeper-ji-qun">1、先启动zookeeper集群</h3>
<pre><code class="language-shell"># 在所有节点分别执行如下命令：
/usr/local/zookeeper/bin/zkServer.sh start
 
# 在第一个节点执行如下命令：
hdfs zkfc -formatZK
 
# 在所有节点执行如下命令：
hdfs --daemon start zkfc
</code></pre>
<p>执行成功后可看：</p>
<pre><code class="language-shell">root@host13:/home/btadmin# jps
180491 Jps
154684 DFSZKFailoverController
 
# 看到DFSZKFailoverController表示启动成功
</code></pre>
<h3 id="2-qi-dong-hdfs">2、启动HDFS</h3>
<p>删除各个节点的$HADOOP_HOME/tmp目录下的所有文件（如果是新建环境不需要此步）</p>
<p>在各个节点分别执行下面命令，启动三台JournalNode ：</p>
<pre><code class="language-shell">hdfs --daemon start journalnode
</code></pre>
<p>启动结果如下</p>
<pre><code class="language-shell">root@host11:/usr/local/hadoop/sbin# jps
494797 JournalNode
 
# 表示JournalNode启动成功
</code></pre>
<h3 id="3-ge-shi-hua-namenode">3、格式化namenode</h3>
<p>只在第一个节点上执行namenode格式化。</p>
<p>注意：如果没有启动JournalNode，格式化将失败</p>
<pre><code class="language-shell">hdfs namenode -format
 
</code></pre>
<p>出现如下输出代表格式化成功：</p>
<pre><code class="language-shell">2023-04-21 13:51:54,909 INFO util.GSet: 0.25% max memory 1.7 GB = 4.4 MB
2023-04-21 13:51:54,909 INFO util.GSet: capacity      = 2^19 = 524288 entries
2023-04-21 13:51:54,927 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-04-21 13:51:54,927 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2023-04-21 13:51:54,927 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-04-21 13:51:54,932 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
2023-04-21 13:51:54,932 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-04-21 13:51:54,934 INFO util.GSet: Computing capacity for map NameNodeRetryCache
2023-04-21 13:51:54,934 INFO util.GSet: VM type       = 64-bit
2023-04-21 13:51:54,934 INFO util.GSet: 0.029999999329447746% max memory 1.7 GB = 538.1 KB
2023-04-21 13:51:54,934 INFO util.GSet: capacity      = 2^16 = 65536 entries
2023-04-21 13:51:56,366 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1632620897-127.0.1.1-1682056316366
2023-04-21 13:51:56,461 INFO common.Storage: Storage directory /var/share/ezfs/shareroot/hdfs/host11/name has been successfully formatted.
2023-04-21 13:51:57,003 INFO namenode.FSImageFormatProtobuf: Saving image file /var/share/ezfs/shareroot/hdfs/host11/name/current/fsimage.ckpt_0000000000000000000 using no compression
2023-04-21 13:51:57,139 INFO namenode.FSImageFormatProtobuf: Image file /var/share/ezfs/shareroot/hdfs/host11/name/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2023-04-21 13:51:57,171 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0
2023-04-21 13:51:57,230 INFO namenode.FSNamesystem: Stopping services started for active state
2023-04-21 13:51:57,231 INFO namenode.FSNamesystem: Stopping services started for standby state
2023-04-21 13:51:57,235 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.
2023-04-21 13:51:57,235 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at host11/127.0.0.1
************************************************************
</code></pre>
<h3 id="4-qi-dong-di-yi-ge-jie-dian-de-namenode">4、启动第一个节点的namenode</h3>
<p>注意：namenode在启动前必须执行格式化namenode操作，如果不执行，则启动namenode操作失败</p>
<p>如果先启动namenode失败后，需要再格式化namenode的话，需要把name data jn文件夹下的内容全部删除，/tmp/下hadoop部分的内容删除后，格式化namenode才能成功</p>
<p>在第一个节点启动namenode， 启动namenode后会生成images元数据</p>
<pre><code class="language-shell">hdfs --daemon start namenode
</code></pre>
<h3 id="5-qi-dong-di-er-san-ge-jie-dian-de-bootstrap-standby">5、启动第二，三个节点的bootstrapStandby</h3>
<p>在启动第二，三节点的namenode之前 ，需要先执行同步数据操作，将第一个节点上的NameNode元数据拷贝到第二个，第三个节点上。命令如下：</p>
<pre><code class="language-shell">hdfs namenode -bootstrapStandby
</code></pre>
<p>输出以下信息代表拷贝成功：</p>
<pre><code class="language-shell">18/03/15 14:28:01 INFO common.Storage: Storage directory /opt/modules/hadoop-2.7.1/tmp/dfs/name has been successfully formatted.
</code></pre>
<p>启动第二，三节点namenode，命令如下</p>
<pre><code class="language-shell">hdfs --daemon start namenode
</code></pre>
<h3 id="6-qi-dong-suo-you-jie-dian-de-datanode">6、启动所有节点的datanode</h3>
<p>在所有节点上启动datanode</p>
<pre><code class="language-shell">hdfs --daemon start datanode
</code></pre>
<h3 id="7-qie-huan-nn-1-wei-namenode-active">7、切换nn1为namenode active</h3>
<pre><code class="language-shell">hdfs haadmin -transitionToActive nn1
</code></pre>
<h3 id="8-que-ren-fu-wu-zhuang-tai">8、确认服务状态</h3>
<pre><code class="language-shell">onnode all jps
 
&gt;&gt; NODE: 10.10.10.11 &lt;&lt;
439493 Jps
416240 DataNode
377026 DFSZKFailoverController
380124 JournalNode
368555 QuorumPeerMain
421097 NameNode
 
&gt;&gt; NODE: 10.10.10.12 &lt;&lt;
218659 Jps
163971 JournalNode
213088 DataNode
178596 NameNode
161803 DFSZKFailoverController
155512 QuorumPeerMain
 
&gt;&gt; NODE: 10.10.10.13 &lt;&lt;
206103 DataNode
156919 JournalNode
209579 NameNode
148043 QuorumPeerMain
154684 DFSZKFailoverController
209885 Jps
</code></pre>
<p>至此，HDAP集群搭建完成</p>
<h2 id="liu-ke-hu-duan-pei-zhi">六、客户端配置</h2>
<p>修改客户端hosts配置文件：</p>
<p>打开文件c:\Windows\System32\drivers\etc\hosts</p>
<pre><code class="language-shell">172.17.73.11 host11
172.17.73.12 host12
172.17.73.13 host13
</code></pre>
<h2 id="qi-hdfs-shi-yong">七、HDFS使用</h2>
<p>使用浏览器打开HDFS 客户端</p>
<pre><code class="language-shell">http://172.17.73.11:50070/
</code></pre>
<img class="shadow" src="/img/in-post/HDFS-1.png" width="1200">
<p>可以看到当前节点是NN1且处于active状态</p>
<p>上传文件，打开如下界面</p>
<img class="shadow" src="/img/in-post/HDFS-2.png" width="1200">
<img class="shadow" src="/img/in-post/HDFS-3.png" width="1200">
<p>上传文件后如下：</p>
<img class="shadow" src="/img/in-post/HDFS-4.png" width="1200">
<p>上传成功！</p>
<h2 id="ba-yu-dao-wen-ti-ji-jie-jue-fang-fa">八、遇到问题及解决方法</h2>
<p>问题1、第二或第三个节点执行BootstrapStandby 格式无法成功。 显示如下</p>
<pre><code class="language-shell">2023-04-21 13:55:00,314 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:01,315 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:02,316 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:03,317 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:04,319 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:05,320 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:06,322 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:07,323 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:08,324 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:09,326 INFO ipc.Client: Retrying connect to server: host11/172.17.73.11:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-04-21 13:55:09,335 WARN ha.BootstrapStandby: Unable to fetch namespace information from remote NN at host11/172.17.73.11:9000: Call From host15/172.17.73.15 to host11:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
2023-04-21 13:55:19,352 WARN ha.BootstrapStandby: Unable to fetch namespace information from remote NN at host16/172.17.73.16:9000: Call From host15/172.17.73.12 to host16:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
2023-04-21 13:55:19,353 ERROR ha.BootstrapStandby: Unable to fetch namespace information from any remote NN. Possible NameNodes: [RemoteNameNodeInfo [nnId=nn1, ipcAddress=host11/172.17.73.11:9000, httpAddress=http://host11:50070], RemoteNameNodeInfo [nnId=nn3, ipcAddress=host16/172.17.73.16:9000, httpAddress=http://host16:50070]]
2023-04-21 13:55:19,357 INFO util.ExitUtil: Exiting with status 2: ExitException
2023-04-21 13:55:19,360 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at host12/172.17.73.12
************************************************************/

</code></pre>
<p>解决：</p>
<p>查看端口的使用情况，发现请求的9000端口使用情况如下：</p>
<pre><code class="language-shell">root@host11:/tmp# lsof -i:9000
COMMAND    PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
java    498909 root  330u  IPv4 689923      0t0  TCP 127.0.1.1:9000 (LISTEN)
端口的ip是127.0.1.1
</code></pre>
<p>进一步查原因，发现/etc/hosts里host11的ip是127.0.1.1，而请求的是172.17.13.11</p>
<p>把/etc/hosts里127.0.1.1注释掉。重启node1</p>
<p>然后按顺序重新启动journalnode. namenode</p>
<p>再次查看</p>
<pre><code class="language-shell">root@host11:/usr/local/hadoop/sbin# lsof -i:9000
COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
java 
</code></pre>
<p>结果正常</p>
<p>问题二：无法上传文件，如下</p>
<img class="shadow" src="/img/in-post/HDFS-5.png" width="1200">
<p>解决方法：</p>
<pre><code class="language-shell">root@host11:/usr/local/hadoop/sbin# hdfs haadmin -getServiceState nn2
active
 
</code></pre>
<p>从UI上登录active节点即可</p>
<img class="shadow" src="/img/in-post/HDFS-6.png" width="1200">
<p>问题三：上传文件失败</p>
<img class="shadow" src="/img/in-post/HDFS-7.png" width="1200">
<p>解决方法：</p>
<p>客户端没有配置host</p>
<p>打开文件c:\Windows\System32\drivers\etc\hosts</p>
<p>添加三个节点的host</p>
<pre><code class="language-shell">172.17.73.11 host11
172.17.73.12 host12
172.17.73.13 host13
</code></pre>
<p>再次尝试</p>
<img class="shadow" src="/img/in-post/HDFS-8.png" width="1200">
<p>文件上传成功！</p>
<p>问题四：启动zookeeper失败</p>
<p>bug现象：</p>
<img class="shadow" src="/img/in-post/HDFS-9.png" width="1200">
<p>log：</p>
<pre><code class="language-shell">2023-04-24 14:37:11,952 [myid:] - WARN  [main:ConstraintSecurityHandler@759] - ServletContext@o.e.j.s.ServletContextHandler@1b68ddbd{/,null,STARTING} has uncovered http methods for path: /*
2023-04-24 14:37:11,961 [myid:] - INFO  [main:ContextHandler@915] - Started o.e.j.s.ServletContextHandler@1b68ddbd{/,null,AVAILABLE}
2023-04-24 14:37:11,970 [myid:] - ERROR [main:ZooKeeperServerMain@86] - Unable to start AdminServer, exiting abnormally
org.apache.zookeeper.server.admin.AdminServer$AdminServerException: Problem starting AdminServer on address 0.0.0.0, port 8080 and command URL /commands
        at org.apache.zookeeper.server.admin.JettyAdminServer.start(JettyAdminServer.java:188)
        at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:155)
        at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:113)
        at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:68)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:141)
        at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:91)
Caused by: java.io.IOException: Failed to bind to /0.0.0.0:8080
        at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:349)
        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:310)
        at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
        at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)
        at org.eclipse.jetty.server.Server.doStart(Server.java:401)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)
        at org.apache.zookeeper.server.admin.JettyAdminServer.start(JettyAdminServer.java:179)
        ... 5 more
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:461)
        at sun.nio.ch.Net.bind(Net.java:453)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:222)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:85)
        at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:344)
        ... 12 more
Unable to start AdminServer, exiting abnormally
 
</code></pre>
<p>原因：</p>
<p>端口占用是8080…</p>
<p>解决办法：</p>
<p>在zoo.cfg中增加admin.serverPort=没有被占用的端口号</p>
]]></content>
      <categories>
        <category>HDFS</category>
        <category>HadoopFS</category>
      </categories>
      <tags>
        <tag>HDFS</tag>
        <tag>HadoopFS</tag>
      </tags>
  </entry>
  <entry>
    <title>查看JBOD Write Cache Policy</title>
    <url>/2023/04/13/jbod_write_cache/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>在在验证JBOD启用Write Cache时，服务器强制掉电是否出现文件系统错误，需要先检查JBOD是否启用了Write Cache。故本文介绍查看JBOD Write Policy，至于服务器掉电是否引发文件系统错误的验证，参考我同事的一篇<a href="https://bean-li.github.io/check-hardware-data-loss">文章</a>。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="xian-shi-jbod-write-cache-xin-xi">显示JBOD Write Cache信息</h2>
<pre><code class="language-shell">root@node216:~# hdparm -W /dev/sdj

/dev/sdj:
 write-caching =  1 (on)
root@node216:~# hdparm -W 0 /dev/sdj

/dev/sdj:
 setting drive write-caching to 0 (off)
 write-caching =  0 (off)
root@node216:~# hdparm -W 1 /dev/sdj

/dev/sdj:
 setting drive write-caching to 1 (on)
 write-caching =  1 (on)
root@node216:~#
</code></pre>
<h2 id="xian-shi-ying-pan-de-xiang-guan-she-zhi">显示硬盘的相关设置</h2>
<pre><code class="language-shell">hdparm /dev/sda
/dev/sda:
IO_support = 0 (default 16-bit)
readonly = 0 (off)
readahead = 256 (on)
geometry = 19457［柱面数］/255［磁头数］/63［扇区数］, sectors = 312581808［总扇区数］, start = 0［起始扇区数］
</code></pre>
<h2 id="xian-shi-ying-pan-de-zhu-mian-ci-tou-shan-qu-shu">显示硬盘的柱面、磁头、扇区数</h2>
<pre><code class="language-shell">hdparm -g /dev/sda
/dev/sda:
geometry = 19457［柱面数］/255［磁头数］/63［扇区数］, sectors = 312581808［总扇区数］, start = 0［起始扇区数］
</code></pre>
<h2 id="ce-shi-ying-pan-de-du-qu-su-du">测试硬盘的读取速度</h2>
<pre><code class="language-shell">hdparm -T /dev/sda
/dev/sda:
 Timing cached reads:   4684 MB in  2.00 seconds = 2342.92 MB/sec
</code></pre>
<h2 id="ce-shi-ying-pan-huan-cun-de-du-qu-su-du">测试硬盘缓存的读取速度</h2>
<pre><code class="language-shell">hdparm -T /dev/xvda
/dev/xvda:
Timing cached reads: 11154 MB in 1.98 seconds = 5633.44 MB/sec
</code></pre>
<h2 id="jian-ce-ying-pan-de-dian-yuan-guan-li-mo-shi">检测硬盘的电源管理模式</h2>
<pre><code class="language-shell">hdparm -C /dev/sda
/dev/sda:
drive state is: standby [省电模式]
</code></pre>
<h2 id="cha-xun-bing-she-zhi-ying-pan-duo-zhong-shan-qu-cun-qu-de-shan-qu-shu-yi-zeng-jin-ying-pan-de-cun-qu-xiao-lu">查询并设置硬盘多重扇区存取的扇区数，以增进硬盘的存取效率</h2>
<pre><code class="language-shell">hdparm -m /dev/sda
hdparm -m    #参数值为整数值如8 /dev/sda
</code></pre>
<h2 id="fu-ying-pan-pi-dao-xiu-fu-fang-fa">附：硬盘坏道修复方法</h2>
<pre><code class="language-shell">检查：smartctl -l selftest /dev/sda
卸载：umount /dev/sda*
修复：badblocks /dev/sda
</code></pre>
]]></content>
      <categories>
        <category>JBOD</category>
      </categories>
      <tags>
        <tag>JBOD</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 tmpwatch/tmpreaper 删除旧文件</title>
    <url>/2023/04/17/delete_linux_tmpwatch_tmpreaper/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Linux系统中我们常常会把一些临时文件或者没有什么用处的文件放置在/tmp下，还有一些进程也会将临时数据放到/var或者/tmp。这些文件如长时间不去处理日积月累可能造成磁盘空间爆满，也浪费磁盘资源。tmpwatch是一款非常实用的空间清理工具，可以帮助我们自动清理/tmp和/var空间的部分目录。</p>
<p>tmpwatch 能够循环地删除指定目录下指定时间内没有被访问的文件，这一命令常常用于清理临时文件目录，比如 /tmp 或者 /var/tmp 这类目录。它只清除指定目录下的空目录、普通文件和符号链接文件，也不会影响其他目录，而且会避开那些属于root用户的系统相关关键文件的。</p>
<p>默认设置下，tmpwatch 命令依据文件的 atime （access time）而非mtime （modify time）来删除文件。如果你想改变它的删除依据，可以在使用这个命令时加上你想修改的参数。</p>
<div class="note warning"><p>注意：</p>
</div>
<p>千万不要在根目录底下运行 tmpwatch 或者 tmpreaper 命令，因为系统可没有任何机制阻止你在根目录下运行此命令。</p>
<h1 id="tmpwatch-shi-yong-shuo-ming">tmpwatch使用说明#</h1>
<p>tmpwatch参数说明</p>
<pre><code class="language-shell"> -u, --atime 基于访问时间来删除文件，默认的。
 -m, --mtime 基于修改时间来删除文件。
 -c, --ctime 基于创建时间来删除文件，对于目录，基于mtime。
 -M, --dirmtime 删除目录基于目录的修改时间而不是访问时间。
 -a, --all 删除所有的文件类型，不只是普通文件，符号链接和目录。
 -d, --nodirs 不尝试删除目录，即使是空目录。
 -d, --nosymlinks 不尝试删除符号链接。
 -f, --force 强制删除。
 -q, --quiet 只报告错误信息。
 -s, --fuser 如果文件已经是打开状态在删除前，尝试使用“定影”命令。默认不启用。
 -t, --test 仅作测试，并不真的删除文件或目录。
 -U, --exclude-user=user 不删除属于谁的文件。
 -v, --verbose 打印详细信息。
 -x, --exclude=path 排除路径，如果路径是一个目录，它包含的所有文件被排除了。如果路径不存在，它必须是一个绝对路径不包含符号链接。
 -X, --exclude-pattern=pattern 排除某规则下的路径。
</code></pre>
<h1 id="tmpwatch-ming-ling-de-guan-jian-xuan-xiang-he-can-shu">tmpwatch 命令的关键选项和参数</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>atime (File Last Access Time)：文件最后一次被访问的时间；</p>
</li>
<li class="lvl-2">
<p>mtime (File Last Modify Time)：文件内容最后一次被修改的时间；</p>
</li>
<li class="lvl-2">
<p>ctime (File Last Change Time)：文件元数据最后一次被修改的时间，即文件相关属性被修改的时间，多数情况下 mtime 和 ctime 值相同，但是诸如文件所有者、权限、所属组这类不涉及内容的属性被修改时则只会影响 ctime；</p>
</li>
<li class="lvl-2">
<p>dirmtime (Directory Last modification time)：目录最后一次被修改的时间。</p>
</li>
</ul>
<p>这些时间参数用来设置删除文件的条件阈值：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>d：单位为天；</p>
</li>
<li class="lvl-2">
<p>h：单位为小时；</p>
</li>
<li class="lvl-2">
<p>m：单位为分钟；</p>
</li>
<li class="lvl-2">
<p>s：单位为秒。</p>
</li>
</ul>
<h1 id="yong-tmpwatch-ming-ling-shan-chu-yi-duan-shi-jian-nei-mei-you-bei-fang-wen-de-wen-jian">用 tmpwatch 命令删除一段时间内没有被访问的文件</h1>
<p>如前所述，tmpwatch 命令的默认选项是 atime，而默认的单位参数则是h，所以如果你确实要按以小时为单位计算的访问时间来删除文件，那么你不用加任何特殊的选项或则参数后缀，可以直接是用这个命令。如下例所示，即为删除 /tmp 目录下过去5小时内没有被访问的文件：</p>
<p><code>tmpwatch 5 /tmp</code></p>
<p>下面这个示例是删除 /home/btadmin/Downloads 目录下过去十小时内没有修改过内容的文件，注意，如果要按 mtime 来删除文件，需要在命令中加上-m 的选项：</p>
<p><code>tmpwatch -m 10 /home/btadmin/Downloads</code></p>
<h2 id="shan-chu-yi-qi-ta-dan-wei-ji-suan-de-mou-duan-shi-jian-nei-mei-you-bei-fang-wen-de-wen-jian">删除以其他单位计算的某段时间内没有被访问的文件</h2>
<p>如果你要以天为单位，则需要加上 d 的后缀，如下为删除30天内没有被访问的文件：</p>
<p><code>tmpwatch 30d /home/btadmin/Downloads</code></p>
<h2 id="shan-chu-yi-duan-shi-jian-nei-wei-bei-shi-yong-de-suo-you-wen-jian">删除一段时间内未被使用的所有文件</h2>
<p>如果你想不仅仅删除普通文件、符号链接文件、空目录文件，而是想删除指定目录下某段时间内没有被访问的所有文件，则需要加上选项 -a，如下为删除指定目录下12小时未被修改内容的所有文件：</p>
<p><code>tmpwatch -am 12 /tmp</code></p>
<h2 id="jiang-mou-xie-mu-lu-pai-chu-zai-shan-chu-cao-zuo-wai">将某些目录排除在删除操作外</h2>
<p>如下命令可以让那些十小时内没有被修改过内容的目录不被删除：</p>
<p><code>tmpwatch -am 10 --nodirs /home/btadmin/Downloads</code></p>
<h2 id="jiang-te-ding-lu-jing-pai-chu-zai-shan-chu-cao-zuo-wai">将特定路径排除在删除操作外</h2>
<p>下面的命令删除 /home/btadmin/Downloads 目录下所有十小时内没有修改内容的文件，但是 /home/btadmin/Downloads/Builds 路径下却不受影响，即该路径下十小时内没修改的文件也不会被删除：</p>
<p><code>tmpwatch -am 10 --exclude=/home/btadmin/Downloads/Builds /home/btadmin/Downloads </code></p>
<h2 id="jiang-te-ding-ge-shi-de-wen-jian-pai-chu-zai-shan-chu-cao-zuo-wai">将特定格式的文件排除在删除操作外</h2>
<p>下面所示的命令为删除指定文件下的所有10小时内未被改动的文件，除了pdf 格式的文件：</p>
<p><code>tmpwatch -am 10 --exclude-pattern='*.pdf' /home/btadmin/Downloads</code></p>
<h2 id="yu-yan-tmpwatch-de-xiao-guo">预演 tmpwatch 的效果</h2>
<p>下面这条命令即是对 tmpwatch 的功能效果进行预演：</p>
<p><code>tmpwatch -t 5h /home/btadmin/Downloads</code></p>
<h2 id="yong-tmpwatch-she-zhi-yi-ge-ding-shi-ren-wu-zhou-qi-xing-di-zhi-xing-shan-chu-cao-zuo">用 tmpwatch 设置一个定时任务周期性地执行删除操作</h2>
<p>要完成这个任务，会在 /etc/cron.daily/tmpreaper 目录下留下一个 cronjob 文件，这个文件是按照 /etc/timereaper.conf 的设定工作的，你可以按自己的需求设置它。</p>
<p>如下所示的设置，能在每天上午10点时删除指定目录下，十五天没被访问的文件：</p>
<p><code>crontab -e0 10 * * * /usr/sbin/tmpwatch 15d /home/btadmin/Downloads</code></p>
<h3 id="mo-ren-ding-shi-ren-wu-pei-zhi">默认定时任务配置</h3>
<p>安装后会在/etc/cron.daily/目录下生成一个tmpwatch文件，crontab每天会调用执行一次。内容如下：</p>
<pre><code class="language-shell">[roota@redhat6 ~]# cat /etc/cron.daily/tmpwatch 
#! /bin/sh
flags=-umc
/usr/sbin/tmpwatch "$flags" -x /tmp/.X11-unix -x /tmp/.XIM-unix \
        -x /tmp/.font-unix -x /tmp/.ICE-unix -x /tmp/.Test-unix \
        -X '/tmp/hsperfdata_*' -X '/tmp/.hdb*lock' -X '/tmp/.sapstartsrv*.log' \
        -X '/tmp/pymp-*' 10d /tmp
/usr/sbin/tmpwatch "$flags" 30d /var/tmp
for d in /var/{cache/man,catman}/{cat?,X11R6/cat?,local/cat?}; do
    if [ -d "$d" ]; then
        /usr/sbin/tmpwatch "$flags" -f 30d "$d"
    fi
done
</code></pre>
<p>从配置可以看出tmpwatch排查了/tmp 和 /var 下的一些目录，/tmp保留10d内访问修改过的文件，/var保留30d，其他都删除。</p>
<h1 id="zong-jie">总结</h1>
<p>tmpwatch是空间清理的利器，但在测试和使用时也需要注意安全。重要数据切记不要放到/tmp下，尽管其他非特权用户没有权限删除但tmpwatch可以。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>一行命令获取python当前默认的编码格式</title>
    <url>/2023/04/17/get_python_encoding/</url>
    <content><![CDATA[<h1 id="shi-jian">实践</h1>
<p>Python2.x</p>
<pre><code class="language-shell">python -c 'import locale; print(locale.getpreferredencoding())'
</code></pre>
<p>Python 3.x</p>
<pre><code class="language-shell">python3 -c 'import locale; print(locale.getpreferredencoding())'
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>如何查看端口是否被封</title>
    <url>/2023/04/20/how_to_check_if_a_port_is_blocked/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>比如客户现场，PC端无法正常访问SAMBA Folder, 在网络通畅状况下依然无法访问，就需要检查是否防火墙封掉了SAMBA 相关端口。本文概述如何判断某个端口是否被封。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="shi-yong-telnet-ming-ling-jin-xing-lian-jie-ce-shi">使用 telnet 命令进行连接测试</h2>
<p>在命令行中输入命令 telnet IP地址 端口号，如果能够连接上，则表明该端口没有被封；如果无法连接，则表明该端口可能被封了。</p>
<p>例如：</p>
<pre><code class="language-shell">telnet 192.168.1.100 80
</code></pre>
<p>如果能够连接上，则输出如下内容：</p>
<pre><code class="language-shell">Trying 192.168.1.100...
Connected to 192.168.1.100.
Escape character is '^]'.
</code></pre>
<p>如果无法连接，则输出如下内容：</p>
<pre><code class="language-shell">Trying 192.168.1.100...
telnet: Unable to connect to remote host: Connection refused
</code></pre>
<h2 id="shi-yong-nc-ming-ling-jin-xing-lian-jie-ce-shi">使用 nc 命令进行连接测试</h2>
<p>在命令行中输入命令 nc -vz IP地址 端口号，如果能够连接上，则表明该端口没有被封；如果无法连接，则表明该端口可能被封了。</p>
<p>例如：</p>
<pre><code class="language-shell">nc -vz 192.168.1.100 80
</code></pre>
<p>如果能够连接上，则输出如下内容：</p>
<pre><code class="language-shell">Connection to 192.168.1.100 80 port [tcp/*] succeeded!
</code></pre>
<p>如果无法连接，则输出如下内容：</p>
<pre><code class="language-shell">nc: connect to 192.168.1.100 port 80 (tcp) failed: Connection refused
</code></pre>
<h2 id="shi-yong-wang-luo-gong-ju-jin-xing-jian-ce">使用网络工具进行检测：</h2>
<p>可以使用网络工具（如 Wireshark、tcpdump 等）进行抓包检测</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>快速清除rbd image</title>
    <url>/2023/04/21/fast_to_delete_rbd_image/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>当集群里出现一个较大的rbd image时，如何快速清理掉它并释放空间，已经存在文章 ：<a href="https://cephnotes.ksperis.com/blog/2014/07/04/remove-big-rbd-image/">https://cephnotes.ksperis.com/blog/2014/07/04/remove-big-rbd-image/</a> 做了介绍。并且对不同的方法做了分析，这里先把结论说下:</p>
<table>
<thead>
<tr>
<th>rbd类型</th>
<th>rbd rm 方法</th>
<th>rados -p rm方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>未填充很多</td>
<td>慢</td>
<td>快</td>
</tr>
<tr>
<td>已填充很多</td>
<td>快</td>
<td>慢</td>
</tr>
</tbody>
</table>
<p>在rbd进行删除的时候，即使内部没有对象数据，也一样需要一个个对象去发请求，即使对象不存在，这个可以开日志看到:<br>
在/etc/ceph/ceph.conf中添加</p>
<pre><code class="language-shell">[client]
debug_ms=1
log_file=/var/log/ceph/rados.log
</code></pre>
<h1 id="shi-jian">实践</h1>
<p>dd写，bs=1M,写了40G的数据：</p>
<pre><code class="language-shell">root@pytest-83-19:~# dd if=/dev/zero of=/dev/rbd0 bs=1M count=40960
40960+0 records in
40960+0 records out
42949672960 bytes (43 GB, 40 GiB) copied, 261.264 s, 164 MB/s
</code></pre>
<h2 id="rbd-image-xin-xi">rbd image 信息</h2>
<pre><code class="language-shell">root@pytest-83-19:~# rbd ls
889795de-fafb-4fca-9bf1-9b984e6124d2.img
root@pytest-83-19:~# rbd info rbd/889795de-fafb-4fca-9bf1-9b984e6124d2.img
rbd image '889795de-fafb-4fca-9bf1-9b984e6124d2.img':
	size 600GiB in 614400 objects
	order 20 (1MiB objects)
	used objects: 0
	block_name_prefix: rbd_data.30dc419495cff
	format: 2
	features: layering
	flags: 
	create_timestamp: Fri Apr 21 14:26:48 2023
root@pytest-83-19:~#
</code></pre>
<h2 id="yuan-shi-de-kuai-su-shan-chu-fang-fa">原始的快速删除方法</h2>
<pre><code class="language-shell">root@pytest-83-19:~# time rados -p rbd ls | grep '^rbd_data.30dc419495cff' | xargs -n 200  rados -p rbd rm

real	2m5.564s
user	0m46.126s
sys	0m4.718s
root@pytest-83-19:~# 
</code></pre>
<h2 id="kai-qi-duo-jin-cheng-shan-chu-de-fang-fa">开启多进程删除的方法</h2>
<p>这个比上面那种方法好的是：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>可以显示当前删除的进度</p>
</li>
<li class="lvl-2">
<p>可以指定删除的进程并发数</p>
</li>
<li class="lvl-2">
<p>可以显示当时正在删除的对象</p>
</li>
<li class="lvl-2">
<p>可以增加一个中断时间降低负载</p>
</li>
</ul>
<p>首先获取一个需要快速删除的rbd的列表:</p>
<h3 id="huo-qu-prifix">获取prifix</h3>
<pre><code class="language-shell">root@pytest-83-19:~# rbd info rbd/889795de-fafb-4fca-9bf1-9b984e6124d2.img | grep prefix
	block_name_prefix: rbd_data.30dc419495cff
root@pytest-83-19:~# 
</code></pre>
<h3 id="huo-qu-lie-biao">获取列表</h3>
<pre><code class="language-shell">root@pytest-83-19:~# rados -p rbd ls |grep rbd_data.30dc419495cff &gt; delobject
</code></pre>
<p>这里可以看下内容有没有问题，检查确认下:</p>
<pre><code class="language-shell">root@pytest-83-19:~# vim delobject 
rbd_data.30dc419495cff.0000000000008e90
rbd_data.30dc419495cff.00000000000047a4
rbd_data.30dc419495cff.000000000000063f
............... 如下内容省略 ..........
</code></pre>
<p>删除的fast_remove.sh脚本如下：</p>
<pre><code class="language-shell">root@node161:~# cat fast_remove.sh 
#!/bin/bash

process=400
objectlistfile="./delobject"
deletepool=san-pool


delete_fun()
  {
      date "+%Y-%m-%d %H:%M:%S"
      rados -p $deletepool rm $1
      #sleep 1
  }


concurrent()
 {
     start=$1 &amp;&amp; end=$2 &amp;&amp; cur_num=$3
     mkfifo   ./fifo.$$ &amp;&amp;  exec 4&lt;&gt; ./fifo.$$ &amp;&amp; rm -f ./fifo.$$
     for ((i=$start; i&lt;$cur_num+$start; i++)); do
         echo "init  start delete process $i" &gt;&amp;4
     done

     for((i=$start; i&lt;=$end; i++)); do
         read -u 4
         {
             # echo -e "-- current delete: [:delete $i/$objectnum  $REPLY]"
             delob=`sed -n "${i}p" $objectlistfile`
             delete_fun $delob
             # echo "delete $delob done"  1&gt;&amp;4  # write to $ff_file
         } &amp;
     done
     wait
 }

objectnum=`cat $objectlistfile | wc -l`
concurrent 1 $objectnum $process
root@node161:~#
</code></pre>
<h3 id="ce-shi-jie-guo">测试结果</h3>
<p>如下为Physical node的测试结果：</p>
<pre><code class="language-shell"># 400 并发:
root@node161:~# time rados -p san-pool ls | grep '^rbd_data.3bba6b8b4567' | xargs -n 400  rados -p san-pool rm

real	0m55.853s
user	0m40.324s
sys	0m1.949s
root@node161:~# 


# 1200 并发:
root@node161:~# time rados -p san-pool ls | grep '^rbd_data.3bba6b8b4567' | xargs -n 1200  rados -p san-pool rm

real	0m53.060s
user	0m38.611s
sys	0m1.221s
root@node161:~# 
</code></pre>
<p>脚本删除结果：</p>
<pre><code class="language-shell"># 400 并发:
2023-04-21 17:55:16
-- current delete: [:delete 40960/40960  delete rbd_data.3bba6b8b4567.00000000000007b1 done]
2023-04-21 17:55:16
2023-04-21 17:55:16

real	1m59.236s
user	30m37.312s
sys	25m4.611s
root@node161:~#


# 1200 并发：

real	1m30.148s
user	24m40.103s
sys	19m49.270s
root@node161:~# 
</code></pre>
<p>尝试了VM以及Phsical Machine，多轮次测试验证，脚本删除的效果并不佳.</p>
<h1 id="gai-ban-2023-04-28">改版(2023-04-28)</h1>
<pre><code class="language-shell">#!/bin/bash

LOG="del.log"
TASK_NO=100
POOL_NAME=$1
RBD_IMAGE_NAME=$2
DEL_OBJECT="rbd_del_objects"
PAGED_FILE_NAME='del-object-page-'


function usage()
{
   echo -e "*****************************************"
   echo "usae: $0 POOL_NAME IMAGE_NAME"
   echo -e ""
   echo "  e.g.: $0 rbd fad9f42b-a255-4871-8515-38b96e8e4fa2.img"
   echo -e ""
   echo -e "*****************************************"
   exit 1
}


function env_check()
{
    rbd_info=`rbd info $1/$2`
    if [[ -z ${rbd_info} ]]; then
        echo ""
        echo "[ERROR]  POOL ($1) or Image ($2) not found, eixt!!"
        echo ""
        exit 2
    fi
}


function get_delete_object()
{
   start_time=`date "+%G-%m-%d %H:%M:%S"`

   block_name_prefix=`rbd info $1/$2 | grep block_name_prefix | awk '{{print $NF}}'`
   rados -p $1 ls | grep ${block_name_prefix} &gt; ${DEL_OBJECT}

   end_time=`date "+%G-%m-%d %H:%M:%S"`
   time_distance=$(expr $(date +%s -d "${end_time}") - $(date +%s -d "${start_time}"))
   echo -e "[${end_time}]  Generate ${DEL_OBJECT} cost ${time_distance}s" | tee -a ${LOG}
}


function clean_objects()
{
    del_no=`cat ${DEL_OBJECT} | wc -l`
    if [[ $del_no -eq 1 ]]; then
        echo ""
        echo "[ERROR]  No record to delete, exit!!!" 
        echo ""
        exit 3
    fi

    rm -rf ${PAGED_FILE_NAME}*

    split_no=1000
    file_no=$(($del_no/${split_no}))
    suffix_length=$</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>快速清除S3 Bucket下Objects</title>
    <url>/2023/04/26/how_fast_to_delete_s3_objects/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>客户现场碰到ceph集群在 Recovery，但是 backfill full,需要清理掉部分数据。</p>
<p>本文针对Bucket下上千万的Object的清理，如何做到又快，又不出现将集群压死（集群压力过大），需要寻求一个平衡点，故本文介绍删除方法，相关参数可根据实际环境进行调测。</p>
<h1 id="ce-shi-huan-jing">测试环境</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>NJ Lab 4U36B，3台物理设备，每个node 3盘组RAID0, 内置两颗3.84T威刚NVME SSD</p>
</li>
<li class="lvl-2">
<p>每个节点12个OSD，总计36个OSD</p>
</li>
<li class="lvl-2">
<p>2+1 EC Pool 作为 S3 Data Pool</p>
</li>
<li class="lvl-2">
<p>3台Client，运行Cosbench，向单一Bucket中灌入512KiB和 5MiB 大小的对象，按 1:1 比例灌入，大约写入300000个对象</p>
</li>
</ul>
<h1 id="object-qing-li-si-lu">Object清理思路</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>利用aws s3api list-object-versions携带query参数，获取指定Bucket下待清理Objects</p>
</li>
<li class="lvl-2">
<p>利用aws s3api delete-objects 去delete Objects</p>
</li>
</ul>
<p>流程大致如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>支持清理多个prefix objects</p>
</li>
<li class="lvl-2">
<p>支持被清理Bucket enable/disable Version下objects的清理</p>
</li>
<li class="lvl-2">
<p>支持并发处理</p>
<ol>
<li class="lvl-6">
<p>每次获取指定数量（e.g:50000）的Objects</p>
</li>
<li class="lvl-6">
<p>获取到的原始数据，并发分割成子文件，每个文件最多只含有1000个待删除Objects</p>
</li>
<li class="lvl-6">
<p>并发读取各个子文件进行Objects的delete操作</p>
</li>
</ol>
</li>
</ul>
<h1 id="ce-shi-jie-guo">测试结果</h1>
<h2 id="bucket-mei-you-qi-yong-version">Bucket 没有启用version</h2>
<pre><code class="language-shell">*****************************************************************************************
[2023-04-26 08:45:45]  ceph df:
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    786TiB     766TiB      20.7TiB          2.63
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS
    .rgw.root                     1      1.07KiB         0        108TiB           4
    default.rgw.control           2           0B         0        224TiB           8
    default.rgw.meta              3      2.14KiB         0        225TiB          15
    default.rgw.log               4           0B         0        224TiB         288
    .ezs3                         5       210KiB         0        234TiB           7
    data                          6      5.81TiB      1.96        290TiB     6643190
    default.rgw.buckets.data      7           0B         0        290TiB           0
    .ezs3.central.log             8       214KiB         0        235TiB         113
    .ezs3.statistic               9           0B         0        246TiB           0
    metadata                      10      123MiB         0        361TiB        1056
    default.rgw.buckets.index     11     10.8GiB         0        206TiB         643
    ec                            13      726GiB      0.15        479TiB      297854
    rbd                           14          0B         0        291TiB           0
    san-pool                      15     4.59TiB      1.26        361TiB     4814435
*********************************  Generate Objects file  *******************************
[2023-04-26 08:48:31]  ceph df:
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    786TiB     767TiB      19.6TiB          2.50
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS
    .rgw.root                     1      1.07KiB         0        108TiB           4
    default.rgw.control           2           0B         0        224TiB           8
    default.rgw.meta              3      2.14KiB         0        225TiB          15
    default.rgw.log               4           0B         0        224TiB         288
    .ezs3                         5       210KiB         0        234TiB           7
    data                          6      5.81TiB      1.96        290TiB     6643190
    default.rgw.buckets.data      7           0B         0        291TiB           0
    .ezs3.central.log             8       214KiB         0        235TiB         113
    .ezs3.statistic               9           0B         0        246TiB           0
    metadata                      10      123MiB         0        362TiB        1056
    default.rgw.buckets.index     11     10.8GiB         0        206TiB         643
    ec                            13     16.2GiB         0        480TiB        3323
    rbd                           14          0B         0        292TiB           0
    san-pool                      15     4.59TiB      1.25        362TiB     4814435
*********************************  Generate Objects file  *******************************
[2023-04-26 08:48:32]  Generate Objects file
aws s3api list-object-versions --endpoint-url=http://localhost --bucket "bucket01" --prefix "Veeam/" --page-size 1000 --max-items 50000 --query "[Versions][].{Key: Key}" &gt;&gt; Veeam-all.json
[2023-04-26 08:48:32]  Generate Veeam-all.json cost 0s
[2023-04-26 08:48:32]  Matched objects versions count : 0 to delete
*********************************  Calc total cost time *********************************
[2023-04-26 08:48:32]  Total cost 167s
</code></pre>
<p>清理速度：</p>
<pre><code class="language-shell">(726 - 16.2) / 167 = 4.25GiB/s
(297854 - 3323) / 167 = 1763 Objects/s
</code></pre>
<h2 id="bucket-qi-yong-version">Bucket 启用 version</h2>
<pre><code class="language-shell">root@node161:~# bash empty_bucket_v1.2.sh 
***** This script will to delete objects which PREFIX is Veeam *****
*****************************************************************************************
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED 
    786TiB     766TiB      20.7TiB          2.63 
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS 
    .rgw.root                     1      1.07KiB         0        108TiB           4 
    default.rgw.control           2           0B         0        224TiB           8 
    default.rgw.meta              3      2.14KiB         0        225TiB          15 
    default.rgw.log               4           0B         0        224TiB         288 
    .ezs3                         5       210KiB         0        234TiB           7 
    data                          6      5.81TiB      1.96        290TiB     6643190 
    default.rgw.buckets.data      7           0B         0        290TiB           0 
    .ezs3.central.log             8       214KiB         0        235TiB         115 
    .ezs3.statistic               9           0B         0        246TiB           0 
    metadata                      10      123MiB         0        361TiB        1056 
    default.rgw.buckets.index     11     17.9GiB         0        206TiB         674 
    ec                            13      734GiB      0.15        479TiB      597759 
    rbd                           14          0B         0        291TiB           0 
    san-pool                      15     4.59TiB      1.26        361TiB     4814435 
*********************************  Generate Objects file  *******************************
 
***** This script will to delete objects which PREFIX is Veeam *****
Deleted Veeam-all.json...
*****************************************************************************************
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED 
    786TiB     767TiB      19.6TiB          2.50 
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS 
    .rgw.root                     1      1.07KiB         0        108TiB           4 
    default.rgw.control           2           0B         0        224TiB           8 
    default.rgw.meta              3      2.14KiB         0        225TiB          15 
    default.rgw.log               4           0B         0        224TiB         288 
    .ezs3                         5       210KiB         0        234TiB           7 
    data                          6      5.81TiB      1.96        290TiB     6643190 
    default.rgw.buckets.data      7           0B         0        291TiB           0 
    .ezs3.central.log             8       214KiB         0        235TiB         115 
    .ezs3.statistic               9           0B         0        246TiB           0 
    metadata                      10      123MiB         0        362TiB        1056 
    default.rgw.buckets.index     11     17.9GiB         0        206TiB         674 
    ec                            13     1.38GiB         0        480TiB         541 
    rbd                           14          0B         0        292TiB           0 
    san-pool                      15     4.59TiB      1.25        362TiB     4814435 
*********************************  Generate Objects file  *******************************
aws s3api list-object-versions --endpoint-url=http://localhost --bucket "bucket01" --prefix "Veeam/" --page-size 1000 --max-items 50000 --query "[Versions,DeleteMarkers][].{Key: Key, VersionId: VersionId}"  &gt;&gt; Veeam-all.json
[2023-04-26 09:05:57]  Generate Veeam-all.json cost 1s
[2023-04-26 09:05:57]  Matched objects versions count : 0 to delete
[WARN]  Matched (0) object to delete, exit!!!
 
*********************************  Calc total cost time *********************************
[2023-04-26 09:05:57]  Total cost 314s
root@node161:~# 
</code></pre>
<p>清理速度：</p>
<pre><code class="language-shell">(734 - 1.38) / 314 = 2.33 GiB/s
(597759 - 541) / 314 = 1901 Objects/s
</code></pre>
<p>TiB 级别的大量数据的删除：</p>
<div class="note default"><p>说明：</p>
</div>
<ul class="lvl-0">
<li class="lvl-4">
<p>如下删除动作，是先全部Dump完被删除对象，再并发清理。 Script后来有调整，防止最初的dump原始数据耗时太久出现异常。</p>
</li>
<li class="lvl-4">
<p>如下记录，仅做一个参考（通过其他的测试，从结果上看，Script后来的调整并没有出现删除衰减掉线严重现象）</p>
</li>
<li class="lvl-4">
<p>全部Dump出来记录再删除，如果这个dump的速度跟不上业务写入的速度（假定业务会持续写入），会出现一直都在dump数据，肯定会消耗比较多的Memory；所以跳转成每次只dump 5万笔记录，然后并发对这5万笔记录清理。</p>
</li>
</ul>
<pre><code class="language-shell">*****************************************************************************************
[2023-04-25 15:57:06]  ceph df:
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    786TiB     754TiB      32.9TiB          4.18
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS
    .rgw.root                     1      1.07KiB         0        106TiB           4
    default.rgw.control           2           0B         0        220TiB           8
    default.rgw.meta              3      2.14KiB         0        221TiB          15
    default.rgw.log               4           0B         0        220TiB         288
    .ezs3                         5           0B         0        230TiB           4
    data                          6      5.81TiB      2.00        285TiB     6643190
    default.rgw.buckets.data      7           0B         0        286TiB           0
    .ezs3.central.log             8       212KiB         0        231TiB         113
    .ezs3.statistic               9           0B         0        242TiB           0
    metadata                      10      123MiB         0        355TiB        1056
    default.rgw.buckets.index     11     8.45GiB         0        203TiB        3203
    ec                            13     8.83TiB      1.84        471TiB     7784745
    rbd                           14          0B         0        286TiB           0
    san-pool                      15     4.59TiB      1.28        355TiB     4814435
*********************************  Generate Objects file  *******************************
[2023-04-25 15:57:06]  Generate Objects file
aws s3api list-object-versions --endpoint-url=http://localhost --bucket "bucket01" --prefix "Veeam/" --page-size 10000 --query "[Versions,DeleteMarkers][].{Key: Key, VersionId: VersionId}"  &gt;&gt; Veeam-all.json
[2023-04-25 16:28:21]  Generate Veeam-all.json cost 1875s
[2023-04-25 16:28:21]  Matched objects versions count: 3839000 to delete
************************************  Split files  **************************************
[2023-04-25 16:28:43]  Split files
[2023-04-25 16:30:46]  Split json file cost 123s
***********************************  Delete Objects *************************************
[2023-04-25 16:30:46]  Delete Objects
[2023-04-25 16:30:46]  1000 records per pickup file, which will be delete from 3839 files
[DEBUG]  Total loop times : 39
[DEBUG]  Loop time : 0, delete from 1 to 100
aws s3api delete-objects --bucket bucket01 --delete file://Veeam-page-1.json --endpoint-url=http://localhost
........................................ 中间内容省略 ......................................
aws s3api delete-objects --bucket bucket01 --delete file://Veeam-page-3838.json --endpoint-url=http://localhost
aws s3api delete-objects --bucket bucket01 --delete file://Veeam-page-3839.json --endpoint-url=http://localhost
[2023-04-25 16:58:19]  Delete Objects cost 1653s
*********************************  Calc total cost time *********************************
[2023-04-25 16:58:19]  Total cost 3673s
***************************************  ceph df ****************************************
[2023-04-25 16:58:19]  ceph df:
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    786TiB     767TiB      19.7TiB          2.51
POOLS:
    NAME                          ID     USED        %USED     MAX AVAIL     OBJECTS
    .rgw.root                     1      1.07KiB         0        108TiB           4
    default.rgw.control           2           0B         0        224TiB           8
    default.rgw.meta              3      2.14KiB         0        225TiB          15
    default.rgw.log               4           0B         0        224TiB         288
    .ezs3                         5           0B         0        234TiB           4
    data                          6      5.81TiB      1.96        290TiB     6643190
    default.rgw.buckets.data      7           0B         0        291TiB           0
    .ezs3.central.log             8       213KiB         0        235TiB         113
    .ezs3.statistic               9           0B         0        246TiB           0
    metadata                      10      123MiB         0        362TiB        1056
    default.rgw.buckets.index     11     8.45GiB         0        206TiB        1698
    ec                            13     73.5GiB      0.01        480TiB      119043
    rbd                           14          0B         0        292TiB           0
    san-pool                      15     4.59TiB      1.25        362TiB     4814435
</code></pre>
<p>删除速度：</p>
<pre><code class="language-shell">root@node162:~# python
Python 2.7.12 (default, Oct  5 2020, 13:56:01) 
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; 8.83 * 1024 - 73.5
8968.42
&gt;&gt;&gt; (8.83 * 1024 - 73.5) / 3673.0
2.4417152191668934
&gt;&gt;&gt; 
&gt;&gt;&gt; (7784745 - 119043) / 3673.0
2087.041110808603
&gt;&gt;&gt; 
</code></pre>
<p>相当于 2.44GiB/s，或2087Objects/s的删除速度。</p>
<h1 id="ce-shi-jie-guo-hui-zong">测试结果汇总</h1>
<table>
<thead>
<tr>
<th>删除的数据量</th>
<th>删除的Objects数</th>
<th>Bucket是否启用Version</th>
<th>耗时</th>
<th>删除速度</th>
</tr>
</thead>
<tbody>
<tr>
<td>From 726GiB to 16.2GiB</td>
<td>From 297854 to 3323</td>
<td>No</td>
<td>167s</td>
<td>4.25GiB/s; 1763 Objects/s</td>
</tr>
<tr>
<td>From 734GiB to 1.38GiB</td>
<td>From 597759 to 541</td>
<td>Yes</td>
<td>314s</td>
<td>2.33 GiB/s; 1901 Objects/s</td>
</tr>
<tr>
<td>From 8.83TiB to 73.5GiB</td>
<td>From 7784745 to 119043</td>
<td>Yes</td>
<td>3673s</td>
<td>2.442GiB/s; 2087.04 Objects/s</td>
</tr>
</tbody>
</table>
<h1 id="script-nei-rong">Script 内容</h1>
<h2 id="prefix-txt-wen-jian-shuo-ming">prefix.txt文件说明</h2>
<p>prefixes.txt，这个文件要存在，里面记录被删除Object的前缀(是目录哦，如果文件直接放在顶层Bucket下，需要修改脚本中 “aws s3api list-object-version” 动作里的 ‘–prefix "$current_prefix/"’ 变更成 ‘–prefix "$current_prefix"’)，如果有多个前缀，每行一个前缀记录，参考如下：</p>
<p>单个prefix信息：<br>
e.g:</p>
<pre><code class="language-shell">root@node161:~# cat prefixes.txt 
Veeam
root@node161:~# 
</code></pre>
<p>多个prefix信息：<br>
e.g:</p>
<pre><code class="language-shell">root@node161:~# cat prefixes.txt 
Veeam
Video
Stream
root@node161:~# 
</code></pre>
<h2 id="script-nei-rong-1">Script 内容</h2>
<pre><code class="language-shell">root@node244:~# cat empty_bucket_v1.3.sh 
#!/bin/bash

LOG="del.log"
TASK_NO=100        # Maximum deletion concurrency allowed
MAX_ITEMS=50000    # List-version fetches the maximum number of records at a time
BUCKET=$1
VERSION_SPLIT_NUMBER=4000  # One complete record every 4 line for query out if bucket enable version, i.e. 1000 Objects
NO_VERSION_SPLIT_NUMBER=3000  # One complete record every 3 line for query out if bucket not enable version, i.e. 1000 Objects
PREFIXES_FILE="prefixes.txt"  # If has many preifix, each line one record


function usage()
{
   echo -e "*****************************************"
   echo "usae: $0 BUCKET_NAME"
   echo -e ""
   echo "  e.g.: $0 bucket01"
   echo -e ""
   echo -e "*****************************************"
   exit 1
}


function check_jq()
{
    os_type=`hostnamectl | grep 'Operating System'`
    if [[ ${os_type} =~ 'Ubuntu' ]]; then
        grep_res=`dpkg -l | grep -w jq`
        install_cmd="apt-get update;apt-get install jq -y"
    else
        grep_res=`rpm -qa | grep jq-`
        install_cmd="yum install jq -y"
    fi

    if [[ ${grep_res} =~ 'jq' ]]; then
        echo
    else
        echo ""
        echo -e "[ERROR]  Not install jq, please run '${install_cmd}' to installl it"
        echo ""
        exit 2
    fi
}


function empty_bucket()
{
    version_tag=`aws s3api get-bucket-versioning --bucket ${BUCKET} --endpoint-url=http://localhost`
    flag=`echo $?`
    if [[ ${version_tag} =~ 'Enabled' ]];then
        version_flag='enable'
    else
        if [[ ${flag} -eq 0 ]]; then
            version_flag='disable'
        else
            echo ""
            echo -e "[ERROR]  Reason:\n
    1. No aws credentials, please type 'aws configure' to config \n
    2. Configed aws credentials, but not match the S3 AKEY/SKEY \n
    3. Bucket : [${BUCKET}] not exist \n"

            exit 1
        fi
    fi

    if [[ -f "$PREFIXES_FILE" ]]; then
        while read -r current_prefix
        do
            printf '***** This script will to delete objects which PREFIX is %s *****\n' "$current_prefix"

            OLD_OBJECTS_FILE="$current_prefix-all.json"

            if [ -f "$OLD_OBJECTS_FILE" ]; then
                printf 'Deleted %s...\n' "$OLD_OBJECTS_FILE"

                rm "$OLD_OBJECTS_FILE"
                rm -rf $current_prefix-page-*.json
            fi

            echo -e "*****************************************************************************************" | tee -a ${LOG}
            # At first, get output of 'ceph df'
            cur_time=`date "+%G-%m-%d %H:%M:%S"`
            echo -e "[${cur_time}]  ceph df:" &gt;&gt; ${LOG}
            ceph df | tee -a ${LOG}

            echo -e "*********************************  Generate Objects file  *******************************" | tee -a ${LOG}
            gen_obj_start_time=`date "+%G-%m-%d %H:%M:%S"`
            echo -e "[${gen_obj_start_time}]  Generate Objects file" &gt;&gt; ${LOG}

            if [[ ${version_flag} == 'disable' ]]; then
               # cmd="aws s3api list-object-versions --endpoint-url=http://localhost --bucket \"$BUCKET\" --prefix \"$current_prefix/\" --page-size 1000 --max-items ${MAX_ITEMS} --query \"[Versions][].{Key: Key}\" &gt;&gt; $OLD_OBJECTS_FILE"
               cmd="aws s3api list-object-versions --endpoint-url=http://localhost --bucket \"$BUCKET\" --prefix \"$current_prefix\" --page-size 1000 --max-items ${MAX_ITEMS} --query \"[Versions][].{Key: Key}\" &gt;&gt; $OLD_OBJECTS_FILE"
            else
               # cmd="aws s3api list-object-versions --endpoint-url=http://localhost --bucket \"$BUCKET\" --prefix \"$current_prefix/\" --page-size 1000 --max-items ${MAX_ITEMS} --query \"[Versions,DeleteMarkers][].{Key: Key, VersionId: VersionId}\"  &gt;&gt; $OLD_OBJECTS_FILE"
               cmd="aws s3api list-object-versions --endpoint-url=http://localhost --bucket \"$BUCKET\" --prefix \"$current_prefix\" --page-size 1000 --max-items ${MAX_ITEMS} --query \"[Versions,DeleteMarkers][].{Key: Key, VersionId: VersionId}\"  &gt;&gt; $OLD_OBJECTS_FILE"
            fi

            echo -e "$cmd" | tee -a ${LOG}
            eval "$cmd"
            gen_obj_end_time=`date "+%G-%m-%d %H:%M:%S"`
            gen_obj_time_distance=$(expr $(date +%s -d "${gen_obj_end_time}") - $(date +%s -d "${gen_obj_start_time}"))
            echo -e "[${gen_obj_end_time}]  Generate $OLD_OBJECTS_FILE cost ${gen_obj_time_distance}s" | tee -a ${LOG}

            no_of_obj=$(cat "$OLD_OBJECTS_FILE" | jq 'length')
            if [[ "$no_of_obj" = "" ]]; then
                no_of_obj=0
            fi

            # Get old version Objects
            echo -e "[${gen_obj_end_time}]  Matched objects versions count : $no_of_obj to delete" | tee -a ${LOG}

            # If $OLD_OBJECTS_FILE, means no need to generate again, exit
            if [[ ${no_of_obj} -eq 0 ]]; then
                echo -e "[WARN]  Matched (${no_of_obj}) object to delete, exit!!!"
                echo ""

                end_time=`date "+%G-%m-%d %H:%M:%S"`
                time_distance=$(expr $(date +%s -d "${end_time}") - $(date +%s -d "${start_time}"))

                echo -e "*********************************  Calc total cost time *********************************" | tee -a ${LOG}
                echo -e "[${end_time}]  Total cost ${time_distance}s" | tee -a ${LOG}
                echo ""
                echo -e "*****************************************************************************************" | tee -a ${LOG}
                exit 2
            fi

            echo -e "************************************  Split files  **************************************" | tee -a ${LOG}
            split_obj_start_time=`date "+%G-%m-%d %H:%M:%S"`
            echo -e "[${split_obj_start_time}]  Split files" &gt;&gt; ${LOG}

            cp $OLD_OBJECTS_FILE ${OLD_OBJECTS_FILE}_bak
            # 1st, modify the $OLD_OBJECTS_FILE
            ## Delete the first line
            sed -i '1d' $OLD_OBJECTS_FILE
            ## Replace the last line, change ']' to ','
            sed -i '$s/]/,/' $OLD_OBJECTS_FILE

            # 2nd, split file
            ## If enable version, each 4 line is one record
            ## If not enable version, each 3 line is one record
            split_no=1000
            file_no=$(($no_of_obj/${split_no}))
            previous_file_no=$((${file_no} - 1))
            suffix_length=$</code></pre>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>快速识别热插拔硬盘</title>
    <url>/2023/05/01/scan_host_plugin_device/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>虚拟机添加硬盘，无需重启，识别新硬盘（热插拔）</p>
<h1 id="jiao-ben">脚本</h1>
<pre><code class="language-shell">#/bin/bash
# ReScan all SCSI/SATA Hosts
for SHOST in /sys/class/scsi_host/host*; do
    echo -n "Scanning ${SHOST##*/}..."
    echo "- - -" &gt; ${SHOST}/scan
    echo Done
done
</code></pre>
]]></content>
      <categories>
        <category>Linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>PowerCLI Scirpt: list_used_fiber.ps</title>
    <url>/2023/05/04/list_used_fiber/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>This script is used to find fibre card for each VM on vCenter.</p>
<p>Usage:</p>
<p><code>pwsh list_used_fiber.ps -server 10.1.2.3 -user user1 -pwd password -fibre_name *Fibre* </code></p>
<h1 id="scripts-of-list-used-fiber-ps">Scripts of list_used_fiber.ps</h1>
<pre><code class="language-shell"># This script is used to find fibre card for each VM on vCenter.
# Usage: pwsh list_used_fiber.ps -server 10.1.2.3 -user user1 -pwd password -fibre_name *Fibre*

param (
    [string] $server = "",
    [string] $user = "",
    [string] $pwd = "",
    [string] $fibre_name= "*Fibre*"
)

If (-Not ($server -and $user -and $pwd)) {
    Write-Host "Please input vCenter IP, user name and password to conect to vCenter:$server"
    Write-Host "Usage: pwsh list_used_fiber.ps -server 10.1.14.3 -user user1 -pwd password -fibre_name *Fibre*" -ForegroundColor green
    exit
}

$output = ""

Connect-VIServer -Server $server -Protocol https -force -User $user -Password $pwd
$vm_name = Get-VM

Write-Host    "`n`nStart to search which VM used fibre card...`n"
#Write-Host "VM | PCI Device"
$output += "VM | PCI Device`n"
foreach($vm in $vm_name)
{
    $device=Get-PassthroughDevice -Type pci -VM $vm -name $fibre_name
    If ($device) {
	    #Write-Host "$($vm) | $($device)"
	    $output += "$($vm) | $($device)`n"
    }
}

Write-Host $output

</code></pre>
]]></content>
      <categories>
        <category>VCenter</category>
      </categories>
      <tags>
        <tag>VCenter</tag>
        <tag>PowerCLI</tag>
      </tags>
  </entry>
  <entry>
    <title>Type iperf to test BW between different Hosts</title>
    <url>/2023/05/11/iperf/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Use the iperf or iperf3 command to automatically and concurrently verify the network bandwidth between different hosts based on the IP address or IP range segment entered by the user.</p>
<h1 id="script-of-iperf-tools">Script of iperf tools</h1>
<pre><code class="language-python">#!/usr/bin/python

import os
import sys
import time
import argparse
import ipaddress
import subprocess

"""
This is a tool for Support and QA
after configure network, before create cluster, we may need to test network bandwidth.
if password have changed after cluster created, use --nopass
"""

def sshpass_param(nopass=False):
    if not nopass:
        param = 'sshpass -p {}'.format('p@ssw0rd')
    else:
        param = ''
    return param

def full_ssh_pass(nopass=False):
    param = "{} ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o LogLevel=ERROR " \
            .format(sshpass_param(nopass))
    return param

def start_iperf_server(host, user="root", nopass=False, cmd='iperf'):
    full_cmd = "{} {}@{} '{} -s'".format(full_ssh_pass(nopass), user, host, cmd)

    with open(os.devnull, 'w') as devnull:
        p = subprocess.Popen(full_cmd, stderr=devnull, stdout=devnull, shell=True)
    return p


def stop_iperf_server(host, user="root", nopass=False, cmd='iperf'):
    full_cmd = "{} {}@{} killall {} 2&gt;/dev/null".format(full_ssh_pass(nopass), user, host, cmd)

    p = subprocess.Popen(full_cmd, shell=True)
    p.wait()
    return p


def start_iperf_client(client, server, user="root", nopass=False, cmd='iperf'):
    if cmd == 'iperf3':
        full_cmd = "{} {}@{} iperf3 -c {} -P 10 -i 1 -t 3 |grep SUM |grep sender|awk '/sec/ {{print $6,$7}}'|tail -1" \
                    .format(full_ssh_pass(nopass), user, client, server)
    else:
        full_cmd = "{} {}@{} iperf -c {} -P 10 -i 1 -t 3 |grep SUM |awk '/sec/ {{print $7,$8}}'|tail -1" \
                    .format(full_ssh_pass(nopass), user, client, server)

    p = subprocess.Popen(full_cmd, stdout=subprocess.PIPE, shell=True)
    p.wait()
    out, err = p.communicate()
    return out


def start_ping(src_ip, dst_ip, count, user="root", nopass=False):
    full_cmd = "{} {}@{} ping {} -c {} -R".format(full_ssh_pass(nopass), user, src_ip, dst_ip, count)
    p = subprocess.Popen(full_cmd, shell=True)
    p.wait()
    return p


def normalize_ip_list(iplist):
    result = []
    for ip in iplist:
        if '~' in ip:
            current = ip.split('~')
            start_ip = current[0]
            comp = start_ip.split('.')
            begin = int(comp[3])
            end = int(current[1])

            while begin &lt;= end:
                current = '.'.join([comp[0],comp[1], comp[2], str(begin)])
                try:
                    network = ipaddress.IPv4Network(unicode(current))
                    result.append(current)
                except Exception:
                    pass
                begin += 1
        else:
            try:
                network = ipaddress.ip_address(unicode(ip))
                result.append(ip)
            except Exception:
                continue

    return result


def get_ip_list():
    parser = argparse.ArgumentParser(description='Iperf test each other')
    parser.add_argument("iplist", nargs='+', help="Please specify the target IPs of nodes")
    parser.add_argument("--nopass", dest="nopass",
                        action='store_true', default=False,
                        help="ssh without default password")
    parser.add_argument("-p", "--ping", action='store_true', help="Ping test each other")
    parser.add_argument("-c", "--count", default='3', help=" Stop after sending count ECHO_REQUEST packets")
    args = parser.parse_args()
    return normalize_ip_list(args.iplist), args.nopass, args.ping, args.count


def get_linux_distro():
    info = platform.linux_distribution()
    if 'Ubuntu' in info[0]:
        return 'ubuntu'
    elif 'CentOS' in info[0]:
        return 'centos'
    else:
        raise RuntimeError('Unknown Distribution: {}'.format(info[0]))


def get_iperf_bin_by_distro():
    distro = get_linux_distro()
    if distro == "centos":
        return 'iperf3'
    return 'iperf'


if __name__ == "__main__":
    ip_list, nopass, ping, count = get_ip_list()
    if not ip_list:
        sys.exit(1)

    cmd = get_iperf_bin_by_distro()
    for ip in ip_list:
        stop_iperf_server(ip, nopass=nopass, cmd=cmd)
    time.sleep(0.1)
    if ping:
        for sip in ip_list:
            for cip in ip_list:
                if cip != sip:
                    print "******** {} =&gt; {} ********".format(sip, cip)
                    start_ping(sip, cip, count)
                    print "\n\n"
        sys.exit(0)
    for sip in ip_list:
        print '-------------{}--------------'.format(sip)
        p = start_iperf_server(sip, nopass=nopass, cmd=cmd)
        time.sleep(0.1)
        for cip in ip_list:
            if cip != sip:
                bw = start_iperf_client(cip, sip, nopass=nopass, cmd=cmd)
                print "{} =&gt; {}: {}".format(cip, sip, bw)
        time.sleep(0.1)
        p.terminate()
        stop_iperf_server(sip, nopass=nopass, cmd=cmd)
</code></pre>
]]></content>
      <categories>
        <category>iperf</category>
      </categories>
      <tags>
        <tag>iperf</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Email Template</title>
    <url>/2023/05/12/jenkins_email_template/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Recently in organizing the documentation, I remembered that some time ago, I redid the jenkins environment, using the latest version, and the email template was adjusted a bit, so here is a record of the recent template used in the current CI environment (Jenkins).</p>
<h1 id="script-of-email-template">Script of email template</h1>
<pre><code class="language-javascript">&lt;STYLE&gt;
  BODY, TABLE, TD, TH, P {
    font-family: Calibri, Verdana, Helvetica, sans serif;
    font-size: 12px;
    color: black;
  }
  .console {
    font-family: Courier New;
  }
  .filesChanged {
    width: 10%;
    padding-left: 10px;
  }
  .section {
    width: 100%;
    border: thin black dotted;
  }
  .td-title-main {
    color: white;
    font-size: 200%;
    padding-left: 5px;
    font-weight: bold;
  }
  .td-title {
    color: white;
    font-size: 120%;
    font-weight: bold;
    padding-left: 5px;
    text-transform: uppercase;
  }
  .td-title-tests {
    font-weight: bold;
    font-size: 120%;
  }
  .td-header-maven-module {
    font-weight: bold;
    font-size: 120%;    
  }
  .td-maven-artifact {
    padding-left: 5px;
  }
  .tr-title {
    background-color: &lt;%= (build.result == null || build.result.toString() == 'SUCCESS') ? '#27AE60' : build.result.toString() == 'FAILURE' ? '#E74C3C' : '#f4e242' %&gt;;
  }
  .test {
    padding-left: 20px;
  }
  .test-fixed {
  	font-weight: bold;
    font-size: 120%;
    color: #27AE60;
  }
  .test-failed {
  	font-weight: bold;
    font-size: 120%;
    color: #FF0000;
  }
  .test-passed {
  	font-weight: bold;
    font-size: 120%;
    color: #008000;
  }
  .test-skiped {
  	font-weight: bold;
    font-size: 120%;
    color: #3366ff;
  }
  .test-broken {
   	font-weight: bold;
    font-size: 120%;
    color: #800000;
  }
&lt;/STYLE&gt;
&lt;BODY&gt;
  &lt;!-- BUILD RESULT --&gt;
  	&lt;%
        def envOverrides = it.getAction("org.jenkinsci.plugins.workflow.cps.EnvActionImpl").getOverriddenEnvironment()
        product_version = envOverrides["PRODUCT_VERSION"]
    %&gt;
  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title-main" colspan=2&gt;
        BUILD ${build.result ?: 'COMPLETED'}
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;URL:&lt;/td&gt;
      &lt;td&gt;&lt;A href="${rooturl}${build.url}"&gt;${rooturl}${build.url}&lt;/A&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Project:&lt;/td&gt;
      &lt;td&gt;${project.name}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Product Version:&lt;/td&gt;
      &lt;td&gt;${product_version}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Date:&lt;/td&gt;
      &lt;td&gt;${it.timestampString}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Duration:&lt;/td&gt;
      &lt;td&gt;${build.durationString}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Cause:&lt;/td&gt;
      &lt;td&gt;&lt;% build.causes.each() { cause -&gt; %&gt; ${hudson.Util.xmlEscape(cause.shortDescription)} &lt;%  } %&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
  &lt;br/&gt;

  &lt;!-- CHANGE SET --&gt;
  &lt;%
  def changeSets = build.changeSets
  if(changeSets != null) {
    def hadChanges = false %&gt;
  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title" colspan="2"&gt;CHANGES&lt;/td&gt;
    &lt;/tr&gt;
    &lt;% changeSets.each() { 
      cs_list -&gt; cs_list.each() { 
        cs -&gt; hadChanges = true %&gt;
    &lt;tr&gt;
      &lt;td&gt;
        Revision
        &lt;%= cs.metaClass.hasProperty('commitId') ? cs.commitId : cs.metaClass.hasProperty('revision') ? cs.revision : cs.metaClass.hasProperty('changeNumber') ? cs.changeNumber : "" %&gt;
        by &lt;B&gt;&lt;%= cs.author %&gt;&lt;/B&gt;
      &lt;/td&gt;
      &lt;td&gt;${cs.msgAnnotated}&lt;/td&gt;
    &lt;/tr&gt;
        &lt;% cs.affectedFiles.each() {
          p -&gt; %&gt;
    &lt;tr&gt;
      &lt;td class="filesChanged"&gt;${p.editType.name}&lt;/td&gt;
      &lt;td&gt;${p.path}&lt;/td&gt;
    &lt;/tr&gt;
        &lt;% }
      }
    }
    if ( !hadChanges ) { %&gt;
    &lt;tr&gt;
      &lt;td colspan="2"&gt;No Changes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;% } %&gt;
  &lt;/table&gt;
  &lt;br/&gt;
  &lt;% } %&gt;

&lt;!-- ARTIFACTS --&gt;
  &lt;% 
  def artifacts = build.artifacts
  if ( artifacts != null &amp;&amp; artifacts.size() &gt; 0 ) { %&gt;
  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title"&gt;BUILD ARTIFACTS&lt;/td&gt;
    &lt;/tr&gt;
    &lt;% artifacts.each() {
      f -&gt; %&gt;
      &lt;tr&gt;
        &lt;td&gt;
          &lt;a href="${rooturl}${build.url}artifact/${f}"&gt;${f}&lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;% } %&gt;
  &lt;/table&gt;
  &lt;br/&gt;
  &lt;% } %&gt;

&lt;!-- MAVEN ARTIFACTS --&gt;
  &lt;%
  try {
    def mbuilds = build.moduleBuilds
    if ( mbuilds != null ) { %&gt;
  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title"&gt;BUILD ARTIFACTS&lt;/td&gt;
    &lt;/tr&gt;
      &lt;%
      try {
        mbuilds.each() {
          m -&gt; %&gt;
    &lt;tr&gt;
      &lt;td class="td-header-maven-module"&gt;${m.key.displayName}&lt;/td&gt;
    &lt;/tr&gt;
          &lt;%
          m.value.each() { 
            mvnbld -&gt; def artifactz = mvnbld.artifacts
            if ( artifactz != null &amp;&amp; artifactz.size() &gt; 0) { %&gt;
    &lt;tr&gt;
      &lt;td class="td-maven-artifact"&gt;
              &lt;% artifactz.each() {
                f -&gt; %&gt;
        &lt;a href="${rooturl}${mvnbld.url}artifact/${f}"&gt;${f}&lt;/a&gt;&lt;br/&gt;
              &lt;% } %&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
            &lt;% }
          }
        }
      } catch(e) {
        // we don't do anything
      } %&gt;
  &lt;/table&gt;
  &lt;br/&gt;
    &lt;% }
  } catch(e) {
    // we don't do anything
  } %&gt;

&lt;!-- Allure Result --&gt;
&lt;%
  lastAllureReportBuildAction = build.getAction(ru.yandex.qatools.allure.jenkins.AllureReportBuildAction.class)
  if (lastAllureReportBuildAction) {
    allureResultsUrl = "${rooturl}${build.url}allure"
    allureLastBuildSuccessRate = String.format("%.2f", lastAllureReportBuildAction.getPassedCount() * 100f / lastAllureReportBuildAction.getTotalCount())
  }
%&gt;

&lt;%
pylintResultsUrl = "${build.environment['JOB_URL']}warnings50/trendGraph"
coberturaResultsUrl = "${rooturl}${build.url}cobertura"
%&gt;

&lt;%
   def total = lastAllureReportBuildAction.getPassedCount() + lastAllureReportBuildAction.getFailedCount() + lastAllureReportBuildAction.getSkipCount() + lastAllureReportBuildAction.getBrokenCount()
%&gt;

  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title" colspan="7"&gt;Test Cases Status&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td class="td-title-tests"&gt;Name&lt;/td&gt;
        &lt;td class="test-fixed"&gt;Total&lt;/td&gt;
        &lt;td class="test-passed"&gt;Passed&lt;/td&gt;
        &lt;td class="td-title-tests"&gt;Success Rate&lt;/td&gt;
        &lt;td class="test-failed"&gt;Failed&lt;/td&gt;
        &lt;td class="test-skiped"&gt;Skipped&lt;/td&gt;
        &lt;td class="test-broken"&gt;Broken&lt;/td&gt;
      &lt;/tr&gt;
    &lt;tr&gt;    	
      &lt;td&gt;${project.name}&lt;/td&gt;
      &lt;td class="test-fixed"&gt;${total}&lt;/td&gt;
      &lt;td class="test-passed"&gt;${lastAllureReportBuildAction.getPassedCount()}&lt;/td&gt;
      &lt;td  class="test-fixed"&gt;${allureLastBuildSuccessRate}% &lt;/td&gt;
      &lt;td class="test-failed"&gt;${lastAllureReportBuildAction.getFailedCount()}&lt;/td&gt;
      &lt;td class="test-skiped"&gt;${lastAllureReportBuildAction.getSkipCount()}&lt;/td&gt;
      &lt;td  class="test-broken"&gt;${lastAllureReportBuildAction.getBrokenCount()}&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;

&lt;br&gt; &lt;/br&gt;

&lt;!-- CI of Allure/Pyline/Cobertura --&gt;
  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title" colspan="2"&gt;Allure history trend&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;

  &lt;table&gt;
    &lt;tr&gt;
       &lt;img lazymap="${allureResultsUrl}/graphMap" src="${allureResultsUrl}/graph" width="500px" height="200px"/&gt;
    &lt;/tr&gt;
  &lt;/table&gt;

&lt;br&gt; &lt;/br&gt;
  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title" colspan="2"&gt;PyLint Warnings Trend&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;

  &lt;table&gt;
    &lt;tr&gt;
        &lt;img src="EMAIL_BASE64_IMG_REPLACE" width="500px" height="200px"/&gt;
    &lt;/tr&gt;
  &lt;/table&gt;

&lt;br&gt; &lt;/br&gt;
  &lt;table class="section"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title" colspan="2"&gt;Code Coverage&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;

  &lt;table&gt;
    &lt;tr&gt;
        &lt;img lazymap="${coberturaResultsUrl}/graphMap" src="${coberturaResultsUrl}/graph" width="500px" height="200px"/&gt; 
   &lt;/tr&gt;
  &lt;/table&gt;

&lt;!-- CONSOLE OUTPUT --&gt;
  &lt;%
  if ( build.result == hudson.model.Result.FAILURE ) { %&gt;
  &lt;table class="section" cellpadding="0" cellspacing="0"&gt;
    &lt;tr class="tr-title"&gt;
      &lt;td class="td-title"&gt;CONSOLE OUTPUT&lt;/td&gt;
    &lt;/tr&gt;
    &lt;% 	build.getLog(100).each() {
      line -&gt; %&gt;
	  &lt;tr&gt;
      &lt;td class="console"&gt;${org.apache.commons.lang.StringEscapeUtils.escapeHtml(line)}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;% } %&gt;
  &lt;/table&gt;
  &lt;br/&gt;
  &lt;% } %&gt;
&lt;/BODY&gt;
</code></pre>
<p>Description:</p>
<p>This file, placed in the email-templates directory in the Jenkins installation directory (if this directory does not exist, just create it manually, and note this directory’s ownership information), for example: <code>${JENKINS_INSTALL_PATH}/email-templates/v1.1_allure-pipeline-report.groovy</code></p>
<h1 id="e-mail-shows-info">E-Mail shows info</h1>
<h2 id="cell-phone-terminal-display-effect-picture">Cell phone terminal display effect picture</h2>
<img class="shadow" src="/img/in-post/cell_phone_of_jenkins_email.jpg" width="1200">
<h2 id="pc-mailbox-example-only">PC mailbox (example only)</h2>
<p>All cases are in success stat:</p>
<img class="shadow" src="/img/in-post/jenkins_build_success.png" width="1200">
<p>Parts of failed cases:</p>
<img class="shadow" src="/img/in-post/jenkins_build_unstable.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Dead lock test</title>
    <url>/2023/05/13/lock_test/</url>
    <content><![CDATA[<h1 id="scripts">Scripts</h1>
<p><code>file_lock_test.py</code></p>
<pre><code class="language-python">import fcntl
import os, time
import logging


logger = logging.getLogger()
hdlr = logging.FileHandler(logfile)
formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
hdlr.setFormatter(formatter)
logger.addHandler(hdlr)
logger.setLevel(logging.INFO)


FILE = "lockf.txt"

if not os.path.exists(FILE):
    file = open(FILE, "a+")
    file.write("0")
    file.close()

for i in xrange(50):
    file = open(FILE, "r+")
    start_time = time.time()
    fcntl.lockf(file.fileno(), fcntl.LOCK_EX)
    # fcntl.flock(file.fileno(), fcntl.LOCK_EX)
    
    counter = int(file.readline()) + 1
    file.seek(0)
    file.write(str(counter))
    
    end_time = time.time()
    
    print 'used time: ' + str(end_time - start_time), '\n'
    logger.info(u'used time: {}'.format(str(end_time - start_time)))
        
    # unlocks the file
    file.close()
    
    # print os.getpid(), "=&gt;", counter

</code></pre>
<p><code>lock_test.py</code></p>
<pre><code class="language-python">import time
import random
import logging

from ezs3.log import EZLog
from ezs3.lock import RESOURCE, SingleLock

logger = EZLog.get_logger(__name__)
EZLog.init_handler(logging.INFO, "./lock_test.log")

resource_list = [RESOURCE.FS_MANAGER, RESOURCE.VS_MANAGER, RESOURCE.MDS_HOST_PRIOR, RESOURCE.SHARED_FOLDER_MGR, RESOURCE.EXPORT_LOGS, RESOURCE.CENTRAL_FLUSH_LOCK, RESOURCE.POOL, RESOURCE.FEATURE_NODES]
sum = 0.0 
min = 0.0 
max = 0.0 
loop = 0 
fail_cnt = 0
for i in xrange(200):
    random.shuffle(resource_list) 
    for each_resource in resource_list:
        try:
            begin = time.time()
            with SingleLock(resource=each_resource, auto_renew=True):
                interval = time.time() - begin
                if min == 0.0 or min &gt; interval:
                    min = interval
                if interval &gt; max :
                    max = interval
                sum += interval
                loop += 1
                logger.info("avg {} min {} max {} loop = {}".format(sum/loop, min, max, loop))
                print("avg {} min {} max {} loop = {}".format(sum/loop, min, max, loop))
                random_sleep = random.randint(1,3)
                time.sleep(random_sleep)
                logger.info("[Success] (%s) time(s) to get and release lock : (%s), random sleep ; (%s)", i+1, each_resource, random_sleep)
        except Exception as ex:
            fail_cnt += 1
            interval = time.time() - begin 
            print("cost time {} and FAILURE,  failed cnt {} ".format(interval, fail_cnt))
            logger.info("cost time {} and FAILURE,  failed cnt {} ".format(interval, fail_cnt))
            time.sleep(1)


if __name__ == '__main__':
    pass

</code></pre>
<pre><code class="language-python">root@scaler80:/usr/lib/python2.7/dist-packages/ezs3# cat log.py
import os
import sys
import logging
import threading
from logging.handlers import SysLogHandler, WatchedFileHandler
from logging import StreamHandler
from contextlib import contextmanager

from ezs3.distro import get_syslog_file_name_by_distro

logging.raiseExceptions = False


class SysLogFile:
    DEFAULT = (SysLogHandler.LOG_USER, "/var/log/{}".format(get_syslog_file_name_by_distro()))
    EZS3_ADMIN = (SysLogHandler.LOG_LOCAL0, "/var/log/ezcloudstor/ezs3admin.log")
    EZS3_GMOND = (SysLogHandler.LOG_LOCAL2, "/var/log/ezcloudstor/ezgmond.log")
    EZS3_CENTRAL = (SysLogHandler.LOG_LOCAL3, "/var/log/ezcloudstor/ezcentral.cache")
    BTSNMP = (SysLogHandler.LOG_LOCAL4, "/var/log/ezcloudstor/btsnmp.log")


# ref: http://www.electricmonk.nl/log/2011/08/14/redirect-stdout-and-stderr-to-a-logger-in-python/
class StreamToLogger(object):
    """
    Fake file-like stream object that redirects writes to a logger instance.
    """
    def __init__(self, fno, logger, log_level=logging.INFO):
        self.logger = logger
        self.log_level = log_level
        self.linebuf = ''
        self.fno = fno

    def write(self, buf):
        for line in buf.rstrip().splitlines():
            self.logger.log(self.log_level, line.rstrip())

    def flush(self):
        # StreamToLogger flushes every write so this function should be no-op
        pass

    def fileno(self):
        return self.fno


class EZLog:
    _handler = None
    _modules = []  # modules with uninitialized loggers
    _initial_level = logging.INFO
    _debug_ref_cnt = 0
    _debug_enable_lock = threading.Lock()


    @classmethod
    def init_handler(cls, level=logging.INFO, logfile=None, syslog=False,
                     syslogfile=SysLogFile.DEFAULT, redirect_stderr=False,
                     fmt=None):
        if cls._handler:
            raise Exception("EZLog handler initailized twice")

        if not fmt:
            fmt = "[%(asctime)s] [%(levelname)s] [%(process)d] [%(name)s] " \
                    "[%(funcName)s:%(lineno)d] %(message)s"
        if syslog:
            sys_formatter = logging.Formatter(fmt)
            cls._handler = SysLogHandler(address='/dev/log', facility=syslogfile[0])
            cls._handler.setFormatter(sys_formatter)
        elif logfile:
            dirpath = os.path.dirname(logfile)
            if not os.path.exists(dirpath):
                os.makedirs(dirpath)
            file_formatter = logging.Formatter(fmt)
            cls._handler = WatchedFileHandler(logfile, encoding='UTF-8')
            cls._handler.setFormatter(file_formatter)
        else:
            cls._handler = StreamHandler(sys.stdout)
            cls._handler.setFormatter(logging.Formatter('%(message)s'))

        if os.environ.get("EZDEBUG"):
            level = logging.DEBUG

        cls._handler.setLevel(level)
        cls._initial_level = level
        for module in cls._modules:
            logger = logging.getLogger(module)
            if cls._handler not in logger.handlers:
                logger.addHandler(cls._handler)

        if redirect_stderr:
            logger = EZLog.get_logger('stderr')
            sys.stderr = StreamToLogger(sys.stderr.fileno(), logger, logging.ERROR)

    @classmethod
    def get_logger(cls, module):
        logger = logging.getLogger(module)
        logger.setLevel(logging.DEBUG)

        if cls._handler is None:
            cls._modules.append(module)
        elif cls._handler not in logger.handlers:
            logger.addHandler(cls._handler)

        return logger

    @classmethod
    def setLevel(cls, level):
        cls._initial_level = level
        cls._handler.setLevel(level)

    @classmethod
    def getLevel(cls):
        return cls._handler.level

    @classmethod
    def setTmpLevel(cls, level):
        cls._handler.setLevel(level)

    @classmethod
    def getInitialLevel(cls):
        return cls._initial_level


# context helper to enable debug logging in a code block
@contextmanager
def enable_debug_log():
    with EZLog._debug_enable_lock:
        EZLog._debug_ref_cnt += 1

    old_level = EZLog.getInitialLevel()
    EZLog.setTmpLevel(logging.DEBUG)
    try:
        yield
    finally:
        with EZLog._debug_enable_lock:
            EZLog._debug_ref_cnt -= 1
            if EZLog._debug_ref_cnt == 0:
                EZLog.setTmpLevel(old_level)
</code></pre>
<pre><code class="language-python">
root@scaler80:/usr/lib/python2.7/dist-packages/ezs3# cat lock.py
import errno
import fcntl
import json
import os
import time
import signal
import Queue
import multiprocessing
from ezs3.command import do_cmd
from ezs3.log import EZLog
from functools import wraps
from threading import Lock, Event, Thread
from ezs3.ezrados import SafeRados


logger = EZLog.get_logger(__name__)


class LOCK_TYPE:
    SHARED = "shared"
    EXCLUSIVE = "exclusive"


class RESOURCE(object):
    FS_PROGRESS = 'fs_progress'
    FS_MANAGER = 'fs_manager'
    FS_INSTANCE = 'fs_instance'
    MDS_INSTANCE = 'mds_instance'
    EVENT_CACHE = 'event_cache'
    CTDB = 'ctdb'
    SDS_CONTROLLERS = 'sds_controllers'
    FEATURE_NODES = 'feature_nodes'
    EZZERO_COPY = 'ezzero_copy'
    EZDEEP_COPY = 'ezdeep_copy'
    EZ_NAS_TO_S3 = 'ez_nas_to_s3'
    EZ_S3_TO_NAS = 'ez_s3_to_nas'
    EZFS_AGENT = 'ezfs_agent'
    SMB_MANAGEMENT = 'samba_management'
    EXPORT_LOGS = 'export_logs'
    NODE_STATUS = 'node_status'
    POOL = 'pool.{}'
    NODE_MANAGEMENT = 'node_management'
    CENTRAL_CONFIG_LOCK = 'central.config'
    CENTRAL_FLUSH_LOCK = 'central.flush'
    VS_MANAGER = 'vs_manager'   # protect "gateway_groups" config key
    MDS_HOST_PRIOR = 'mds_host_prior'
    DISK_RECOVERY = 'disk_recovery'
    RGW_MANAGER = 'rgw_manager'
    CRUSH_REWEIGHT = "crush_reweight"
    CEPH_CRUSHMAP = "ceph_crushmap"
    HARDWARE_INFO = 'hardware_info'
    POOLS_INFO = 'POOLS_INFO'
    USER_MAPPING_MANAGEMENT = 'user_mapping_management'
    SDS_ADMIN_ACCOUNT = 'sds_admin_account'
    SNS_CONFIG = 'sns_config'
    SQS_CONFIG = 'sqs_config'
    S3NOTIF_CONFIG = 's3notif_config'
    STORCLS_SERVICE = 'storage_class_service'
    IMPORT_ACCOUNT_CONFIG = 'import_account_config'
    MIGRATE_CEPH_ACCOUNTS = 'migrate_ceph_accounts'
    MIGRATE_JOB = 'migrate_job'
    MIGRATE_INDEX_JOB = 'migrate_index_job'
    MIGRATE_META_JOB = 'migrate_meta_job'
    MIGRATE_DATA_JOB = 'migrate_data_job'
    MIGRATE_QUOTA_JOB = 'migrate_quota_job'
    MIGRATE_FAILUE_JOB = 'migrate_failue_job'
    MIGRATE_DOMAIN = 'migrate_domain'
    IPMI_CONFIG = 'ipmi_config'
    RAID_STATE = 'raid_state'
    LICENSE = 'license'
    ISCSI_MANAGER = 'iscsi_manager'
    OSD_ID_ASSIGN = 'osd_id_assign'
    SYSTEM_UID = 'system_uid'
    ALLOW_POOL_DELETE = 'allow_pool_delete'
    PUBLIC_IPS = 'public_ips'


class FILE_RESOURCE(object):
    HOSTS = "hosts"
    STORAGE_CONF_WRITE = 'storage_conf_write'
    STORAGE_CONF_READ = 'storage_conf_read'
    LSBLK = 'lsblk'
    NAS_DISK_CONF = 'nas_disk_conf'
    ISCSI_SESSIONS = 'iscsi_sessions'
    CEPH_CONF = 'ceph_conf'
    AD = 'ad'


def rbd_task_lock_name(pool, img):
    return "rbd_task.{}.{}".format(pool, img)


file_resource_thread_locks = {}


def init_file_resource_thread_locks():
    global file_resource_thread_locks
    file_resources = [r for r in dir(FILE_RESOURCE) if not r.startswith('__')]
    file_resource_thread_locks = {
        FILE_RESOURCE.__dict__[r]: Lock() for r in file_resources}

init_file_resource_thread_locks()


def list_locked_resources():
    output = do_cmd('ceph lock list')
    return json.loads(output)


def delete_resource_lock(resource):
    do_cmd('ceph lock delete {}'.format(resource))


class MonitorLockError(RuntimeError):
    def __str__(self):
        return "CephMonitorLockError: {}".format(self.message)


class SingleLock(object):
    def __init__(self, resource, lock_type=LOCK_TYPE.EXCLUSIVE,
                 auto_renew=False):
        self.resource = resource
        self.lock_type = lock_type
        self.timestamp = ''

        self._auto_renew = auto_renew   # default config
        self._enable_auto_renew = False # state of current lock
        self._autorenew_thread = None
        self._stop_renew = Event()
        self._renew_interval = 10
        self._rds = SafeRados.get_instance()

    def acquire(self, blocking=True, auto_renew=None, renew_interval=10):
        self._enable_auto_renew = (auto_renew == True) or \
            (auto_renew == None and self._auto_renew)
        json_cmd = {'prefix': 'lock acquire', 'type': self.lock_type, 'key': self.resource}
        acquire_retry_cnt = 0
        while True:
            ret, outbuf, outs = self._rds.json_command(argdict=json_cmd,
                                                       timeout=30, do_retry=False)
            if ret == 0:
                self.timestamp = outbuf
                if self._enable_auto_renew:
                    logger.debug('Got lock {} and auto renew is enabled, timestamp={}'
                                 .format(self.resource, self.timestamp))
                    self._stop_renew.clear()
                    self._renew_interval = renew_interval
                    self._autorenew_thread = Thread(target=self.renew_thread)
                    self._autorenew_thread.start()
                else:
                    logger.debug('Got lock and auto renew is disabled')
                return True
            elif ret == -errno.EBUSY or ret == -errno.EAGAIN:
                acquire_retry_cnt += 1
                if ret == -errno.EBUSY:
                    message = 'Lock {} is occupied ({})...'.format(self.resource, acquire_retry_cnt)
                else:
                    message = 'Lock {} acquire cannot exec, may not in quorum ({}) ...'.format(self.resource, acquire_retry_cnt)
                if acquire_retry_cnt in [5,10,20,50,100,300]:
                    logger.warn(message)
                elif acquire_retry_cnt &gt; 300:
                    logger.error(message)
                else:
                    logger.debug(message)
                if not blocking:
                    return False
                time.sleep(1)
            else:
                raise MonitorLockError('Monitor returned: {}({})'.format(errno.errorcode[-ret], ret))

    def release(self):
        if not self.timestamp:
            return

        if self._enable_auto_renew:
            self._stop_renew.set()
            self._autorenew_thread.join()

        json_cmd = {'prefix': 'lock release', 'ts': self.timestamp, 'key': self.resource}
        ret, _outbuf, _outs = self._rds.json_command(argdict=json_cmd,
                                                     timeout=30, do_retry=False)

        if ret == 0:
            self.timestamp = ''
            return True
        elif ret == -errno.ENOENT:
            logger.warning('lock {} release with no entry, ret={}, timestemp={}'.format(self.resource, ret, self.timestamp))
        else:
            logger.error('lock {} release failed, ret={}, timestemp={}'.format(self.resource, ret, self.timestamp))
        return False

    def renew(self):
        logger.debug("renew monitor lock {} with timestamp={}".format(self.resource, self.timestamp))
        json_cmd = {'prefix': 'lock renew', 'ts': self.timestamp, 'key': self.resource}
        ret, outbuf, _ = self._rds.json_command(argdict=json_cmd, timeout=30, do_retry=False)
        if ret == 0:
            self.timestamp = outbuf
            return True
        else:
            logger.error('lock {} renew failed, ret={}, timestemp={}'.format(
                self.resource, ret, self.timestamp))
            return False

    def renew_thread(self):
        while not self._stop_renew.wait(self._renew_interval):
            self.renew()

    def __enter__(self):
        blocking = True
        self.acquire(blocking, self._auto_renew)
        return self

    def __exit__(self, type, value, traceback):
        self.release()


class MultiLock(object):
    def __init__(self, resources, lock_type=LOCK_TYPE.EXCLUSIVE, auto_renew=False):
        self.resources = resources
        self.lock_type = lock_type
        self.auto_renew = auto_renew
        self.locks = []

    def acquire(self):
        for resource in self.resources:
            lock = SingleLock(resource, self.lock_type, self.auto_renew)
            self.locks.append(lock)

        for lock in self.locks:
            lock.acquire()

    def release(self):
        for lock in self.locks:
            lock.release()

    def renew(self):
        for lock in self.locks:
            lock.renew()

    def __enter__(self):
        self.acquire()
        return self

    def __exit__(self, type, value, traceback):
        self.release()


class GroupLock(SingleLock):
    def __init__(self, gwgroup, resource, lock_type=LOCK_TYPE.EXCLUSIVE,
                 auto_renew=False):
        SingleLock.__init__(self, '{}.{}'.format(gwgroup, resource), lock_type,
                            auto_renew)


class ProcessLockTimeout(RuntimeError):
    pass


class ProcessLockFailed(RuntimeError):
    pass


# The process lock is implemented by flock syscall, and it can only be interrupted by SIGALRM.
# In order to allow background threads having their own process lock with timeout ability,
# we implement a worker process for every ProcessLock to do flock operations (if timeout is specified).
class ProcessLock:
    def __init__(self, resource, lock_type=LOCK_TYPE.EXCLUSIVE, blocking=True, timeout=0):
        self.resource = resource
        self.lock_type = lock_type
        self.blocking = blocking
        self.timeout = timeout
        self.flock_result = None
        self.release_event = None
        self.worker = None
        self.process_lock = None

    def acquire(self):
        # currently we forbid re-entrant lock to simplify the cases
        if self.process_lock:
            raise ProcessLockFailed('Unable to re-acquire lock {}'.format(self.resource))

        self.process_lock = _ProcessLock(self.resource, self.lock_type, self.blocking)

        if self.timeout &gt; 0:
            self.flock_result = multiprocessing.Queue(1)
            self.release_event = multiprocessing.Event()
            self.worker = ProcessLockWorker(self.flock_result,
                                            self.release_event,
                                            self.process_lock)
            self.worker.start()
            try:
                res = self.flock_result.get(timeout=self.timeout)
                if res[0] &lt; 0:
                    self.process_lock = None
                    raise ProcessLockFailed('Unable to lock {}, err={}'.format(self.resource, res[1]))
            except Queue.Empty:
                self.process_lock = None
                # interrupt blocking flock syscall in worker
                os.kill(self.worker.pid, signal.SIGALRM)
                while self.worker.is_alive():
                    self.worker.terminate()
                raise ProcessLockTimeout('Timeout to lock {}'.format(self.resource))
        else:
            try:
                self.process_lock.acquire()
            except Exception as e:
                self.process_lock = None
                logger.exception("Acquire lock failed..")
                raise ProcessLockFailed('Unable to lock {}, err={}'.format(self.resource, e.message))

    def release(self):
        if self.process_lock:
            if self.worker:
                self.release_event.set()
                self.worker.join()
                self.worker = None
            else:
                self.process_lock.release()
            self.process_lock = None

    def __enter__(self):
        self.acquire()
        return self

    def __exit__(self, type, value, traceback):
        self.release()


class _ProcessLock:
    FILE_LOCK_PATH = '/var/lock/ezs3'

    def __init__(self, resource, lock_type, blocking):
        self.resource = resource
        self.lock_type = lock_type
        self.blocking = blocking
        self.handle = None
        self.thread_lock = file_resource_thread_locks[self.resource]

    def acquire(self):
        self.thread_lock.acquire()
        if not os.path.exists(_ProcessLock.FILE_LOCK_PATH):
            os.mkdir(_ProcessLock.FILE_LOCK_PATH)

        filename = os.path.join(_ProcessLock.FILE_LOCK_PATH, self.resource)
        self.handle = open(filename, 'w')

        lock_op = 0

        if self.lock_type == LOCK_TYPE.EXCLUSIVE:
            lock_op = fcntl.LOCK_EX
        else:
            lock_op = fcntl.LOCK_SH

        if self.blocking:
            fcntl.flock(self.handle, lock_op)
        else:
            fcntl.flock(self.handle, lock_op | fcntl.LOCK_NB)

    def release(self):
        if self.handle:
            fcntl.flock(self.handle, fcntl.LOCK_UN)
            self.handle.close()
            self.handle = None
        if self.thread_lock.locked():
            self.thread_lock.release()


# NOTE: do not logging in ProcessLockWorker because logging in
# another process without syslog handler might corrupt the log.
class ProcessLockWorker(multiprocessing.Process):
    def __init__(self, flock_result, release_event, process_lock):
        multiprocessing.Process.__init__(self)
        self.flock_result = flock_result
        self.release_event = release_event
        self.process_lock = process_lock

    def run(self):
        try:
            self.process_lock.acquire()
            self.flock_result.put([0, ''])
            self.release_event.wait()
            self.process_lock.release()
        except Exception as e:
            self.flock_result.put([-1, e.message])


internal_lock = {}


def get_internal_lock(lock_name):
    global internal_lock
    if lock_name not in internal_lock:
        internal_lock[lock_name] = Lock()
    return internal_lock[lock_name]


external_lock = {}


def get_external_lock(lock_name, rds=None, timeout=60):
    global external_lock
    if lock_name not in external_lock or external_lock[lock_name] is None:
        try:
            rl = SingleLock(lock_name)
        except:
            rl = None
            logger.warn('Faile to create monitor lock')
        external_lock[lock_name] = rl
    return external_lock[lock_name]


def monlock(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        lock_name = kwargs.get('_lock_name')
        if not lock_name:
            lock_name = func.__module__
        else:
            del kwargs['_lock_name']

        ret = None
        try:
            # Honestly, we should only using rados lock here, but due to the memory leak issue of rados lock, we added a internal lock so one process can share one rados lock.
            in_lock = get_internal_lock(lock_name)
            ex_lock = get_external_lock(lock_name)
            in_lock.acquire()
            if ex_lock:
                ex_lock.acquire(auto_renew=True)
            ret = func(*args, **kwargs)
        except Exception, ex:
            logger.error('Running wrapped function {} error: {}'.format(str(func), str(ex)))
            raise ex
        finally:
            if ex_lock:
                ex_lock.release()
            if in_lock:
                in_lock.release()

        return ret
    return wrapper

class MonLockWithName(object):
    def __init__(self, lock_name):
        self.lock_name = lock_name

    def __call__(self, func):
        def wrapped_f(*args):
            ret = None
            try:
                in_lock = get_internal_lock(self.lock_name)
                ex_lock = get_external_lock(self.lock_name)
                in_lock.acquire()
                if ex_lock:
                    ex_lock.acquire(auto_renew=True)
                ret = func(*args)
            except Exception, ex:
                logger.error('Running wrapped function {} error: {}'.format(str(func), str(ex)))
                raise ex
            finally:
                if ex_lock:
                    ex_lock.release()
                if in_lock:
                    in_lock.release()

            return ret
        return wrapped_f


class RWLock(object):
    class _Switch(object):
        def __init__(self):
            self._count = 0
            self._mutex = Lock()

        def acquire(self, lock):
            self._mutex.acquire()
            self._count += 1
            if self._count == 1:
                lock.acquire()
            self._mutex.release()

        def release(self, lock):
            self._mutex.acquire()
            self._count -= 1
            if self._count == 0:
                lock.release()
            self._mutex.release()

    def __init__(self):
        self._read_switch = self._Switch()
        self._write_switch = self._Switch()
        self._no_readers = Lock()
        self._no_writers = Lock()
        self._readers_queue = Lock()

    def read_acquire(self):
        self._readers_queue.acquire()
        self._no_readers.acquire()
        self._read_switch.acquire(self._no_writers)
        self._no_readers.release()
        self._readers_queue.release()

    def read_release(self):
        self._read_switch.release(self._no_writers)

    def write_acquire(self):
        self._write_switch.acquire(self._no_readers)
        self._no_writers.acquire()

    def write_release(self):
        self._no_writers.release()
        self._write_switch.release(self._no_readers)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Testlink support Excel import/export test cases</title>
    <url>/2023/05/19/testlink_xml_excel/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Testlink is used for writing and maintaining manual test cases. Sometimes, in order to write more efficiently, you need to export the Testlink Excel template, edit Excel directly on this basis, and finally import it to Testlink. XML is similar, but it happens that Testlink only supports import and export of XML files, not Excel.</p>
<p>Therefore, this article provides a python script that allows Test to support the import and export of Excel.</p>
<p>This article ignores the part that involves modifications to Testlink; this article only provides the python script:</p>
<p>It includes two tools, one is to transfer xml to excel, the other is to do the opposite<br>
Testlink version using with this tool is TestLink 1.9.10(El D1eG0).</p>
<ul class="lvl-0">
<li class="lvl-3">
<p><strong>LIMITATION: <code>excel2testlinkxml.py</code> supports at most 2-layer hierarchy for now.</strong></p>
</li>
</ul>
<pre><code class="language-shell">TestSuite
 &gt; Subsuite1 
   &gt;&gt; TestCase1
   &gt;&gt; TestCase2
 &gt; Subsuite2
   &gt;&gt; TestCase1
   &gt;&gt; TestCase2
 &gt; Subsuite3 
   &gt;&gt; TestCase1
   &gt;&gt; TestCase2
</code></pre>
<h1 id="scripts">Scripts</h1>
<h2 id="excel-2-testlinkxml">excel2testlinkxml</h2>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import xlrd
from lxml import etree


input=raw_input("Input file name:")
# test_suite_name=raw_input("Input test suite name:")
# if test_suite_name=='':
    # test_suite_name="Gateway VM Deployment"

f_in = xlrd.open_workbook(input)
sheet = f_in.sheet_by_index(0)

# create XML
#testsuite = etree.Element('testsuite', name=test_suite_name)

xmlroot = None

for seq in range(1, sheet.nrows):
    # print(sheet.row_values(seq))
    print seq
    try:
        suite_ = sheet.row_values(seq)[0]
        case_ = sheet.row_values(seq)[1]
        pre_ = sheet.row_values(seq)[2]
        step_ = sheet.row_values(seq)[3]
        expect_ = sheet.row_values(seq)[4]
        keywords_ = sheet.row_values(seq)[5]
        
        
        if suite_ != '':
            if xmlroot == None:
                xmlroot = etree.Element('testsuite', name=suite_)
                testsuite_ = xmlroot
            else:
                testsuite_ = etree.SubElement(xmlroot, 'testsuite', name=suite_)
            continue
        if case_ == '':
            continue
        
        # To make lines
        pre_ = '&lt;![CDATA[&lt;p&gt;\n' + pre_.replace('\n','&lt;/p&gt;\n&lt;p&gt;\n') + '&lt;/p&gt;\n]]&gt;'
        step_ = '&lt;![CDATA[&lt;p&gt;\n' + step_.replace('\n','&lt;/p&gt;\n&lt;p&gt;\n') + '&lt;/p&gt;\n]]&gt;'
        expect_ = '&lt;![CDATA[&lt;p&gt;\n' + expect_.replace('\n','&lt;/p&gt;\n&lt;p&gt;\n') + '&lt;/p&gt;\n]]&gt;'
        
        test_case = etree.SubElement(testsuite_, 'testcase', name=case_)
        preconditions = etree.SubElement(test_case, 'preconditions')
        preconditions.text = u'{0}'.format(pre_)
        steps = etree.SubElement(test_case, 'steps')
        step = etree.SubElement(steps, 'step')
        step_number = etree.SubElement(step, 'step_number')
        step_number.text = u'1'
        actions = etree.SubElement(step, 'actions')
        actions.text = u'{0}'.format(step_)
        expectedresults = etree.SubElement(step, 'expectedresults')
        expectedresults.text = u'{0}'.format(expect_)
        keywords = etree.SubElement(test_case, 'keywords')
        keyword_list = keywords_.split('\n')
        for kw in keyword_list:
            keyword = etree.SubElement(keywords, 'keyword', name=kw)
    except Exception as e:
        print("line:", seq)
        print(str(e))
        for item in sys.exc_info():
            print item

s = etree.tostring(xmlroot, pretty_print=True)
s = s.replace('&amp;lt;', '&lt;')   # 临时强制修改，将来碰到内容中包含大于小于的可能会导致XML格式错误，导入失败。
s = s.replace('&amp;gt;', '&gt;')
f_out = open('output.xml', 'w')
f_out.write(s)
</code></pre>
<h2 id="testlinkxml-2-excel">testlinkxml2excel</h2>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: utf-8 -*-


import re
from collections import OrderedDict
from xlwt import Workbook
from lxml import etree

pattern = re.compile(r'&lt;p&gt;\n&lt;/p&gt;\n|&lt;/p&gt;|&lt;p&gt;\n')


class XML2ExcelManager:

    def __init__(self, xml_file_name):
        self._tree = etree.parse(xml_file_name)
        self.root = self._tree.getroot()
#        suite_depth = 0
        self.content = []
        
    def xmlnode_to_list(self, node):
        columns = (
           ("suitename", ""),
           ("casename", ""),
           ("preconditions", ""),
           ("steps", ""),
           ("expected", ""),
           ("keywords", ""),
           ("caseid", "")
        )
        line = OrderedDict(columns)
        if node.tag == 'testsuite':
            line["suitename"] = node.get("name")
            self.content.append(line)
        if node.tag == 'testcase':
            line["casename"] = node.get("name")
            line["caseid"] = node.find("externalid").text
            line["preconditions"] = node.find("preconditions").text
            line["steps"] = node.find("steps/step/actions").text \
                if node.find("steps/step/actions") is not None else ""
            line["expected"] = node.find("steps/step/expectedresults").text \
                if node.find("steps/step/expectedresults") is not None else ""
            line["keywords"] = []
            for keyword in node.findall("keywords/keyword"):
                line["keywords"].append(keyword.get("name"))
            self.content.append(line)
        for child in node.getchildren():
            self.xmlnode_to_list(child)

    def write_list_to_excel(self, excel_file_name):
        excel = Workbook()
        sheet1 = excel.add_sheet('Sheet1')
        # write title name
        row = sheet1.row(0)
        for idx, key in enumerate(self.content[0]):
            row.write(idx, key)

        for i in range(len(self.content)):
            row = sheet1.row(i+1)  # Offset for title
            for idx, key in enumerate(self.content[i]):
                val = self.content[i][key]
                if key != "keywords":  # Because keywords is list, not string
                    val = pattern.sub('', val)
                else:
                    val = '\n'.join(val)
                row.write(idx, val)
        excel.save(excel_file_name)

if __name__ == '__main__':
    f_xml = raw_input("Input xml name:")
    xem = XML2ExcelManager(f_xml)
    xem.xmlnode_to_list(xem.root)
    xem.write_list_to_excel('output.xls')

</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>Testlink</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Testlink</tag>
      </tags>
  </entry>
  <entry>
    <title>fio benchmark</title>
    <url>/2023/05/20/fio_benchmark/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Write a performance tool to test NFS, CIFS, SAN Device, and output result after each scene.</p>
<h1 id="sop">SOP</h1>
<h2 id="1-prepare-test-environment">1. Prepare test environment</h2>
<ul class="lvl-0">
<li class="lvl-4">
<p>Install CentOS 7 as clients (Ubuntu should also be OK), client number is suggested same as that of gateways</p>
</li>
<li class="lvl-4">
<p>The IP address of clients must be sequential</p>
</li>
<li class="lvl-4">
<p>Yum install some packages, including fio, expect, psmisc, iscsi-initiator-utils, mount.nfs</p>
</li>
<li class="lvl-4">
<p>Install dstat on storage node</p>
</li>
</ul>
<h2 id="2-configure-nfs-i-scsi-in-web-ui">2. Configure NFS/iSCSI in web UI</h2>
<ul class="lvl-0">
<li class="lvl-4">
<p>For NFS test</p>
<ul class="lvl-2">
<li class="lvl-6">Create pool and shared folder within the pool</li>
<li class="lvl-6">Mkdir some subfolders under the shared folder, number of subfolders is identical to gateway number</li>
</ul>
</li>
<li class="lvl-4">
<p>For iSCSI test</p>
<ul class="lvl-2">
<li class="lvl-6">Create pool and some iSCSI targets, number of targets is identical to gateway number</li>
<li class="lvl-6">Create one iSCSI LUN on each iSCSI target</li>
</ul>
</li>
</ul>
<h2 id="3-access-storage-from-clients">3. Access storage from clients</h2>
<ul class="lvl-0">
<li class="lvl-4">
<p>For NFS test</p>
<ul class="lvl-2">
<li class="lvl-6">Create mount point, same as the value of “nfsmount” in parameters.conf</li>
<li class="lvl-6">Mount subfolders from clients, one subfolder to one client to one gateway</li>
</ul>
</li>
<li class="lvl-4">
<p>For iSCSI test</p>
<ul class="lvl-2">
<li class="lvl-6">Discovery and login iSCSI LUN, one target to one client to one gateway</li>
<li class="lvl-6">Make sure all clients have same /dev/sdx for iSCSI LUN, and the value is identical to “iscsilun” in parameters.conf<br>
– Go to /etc/multipath, delete all of files under this folder, logout all of iscsi session, then login iscsi</li>
</ul>
</li>
</ul>
<h2 id="4-run-test">4. Run test</h2>
<ul class="lvl-0">
<li class="lvl-5">
<p>Unzip the fio_benchmark in one of the clients</p>
</li>
<li class="lvl-5">
<p>Modify parameters.conf, adjust client/server info</p>
</li>
<li class="lvl-5">
<p>Check configs under fio_conf to adapt current situation</p>
</li>
<li class="lvl-5">
<p>Run 01_fio_deploy.sh to deploy scripts on all clients</p>
</li>
<li class="lvl-5">
<p>Run 03_run_remote_fio.sh to execute fio scripts as config order</p>
</li>
<li class="lvl-5">
<p>Run 04_collect_fio_result.sh and 05_analayse_reslut.sh to collect results</p>
</li>
<li class="lvl-5">
<p>Run 06_aggregate_result.sh is used to aggregate results of several cycles</p>
</li>
</ul>
<h2 id="content">Content</h2>
<h4 id="parameter-conf">parameter.conf:</h4>
<p>This conf defines items below:</p>
<ol>
<li class="lvl-3">
<p>Info of clients and storage nodes</p>
</li>
<li class="lvl-3">
<p>NFS mount point and iSCSI dev name</p>
</li>
<li class="lvl-3">
<p>Location of scripts on each client</p>
</li>
</ol>
<p>Scripts are usually executed by order of the number prefixed to the filename.</p>
<h4 id="00-run-sh">00_run.sh:</h4>
<p>This script can be treated as a set which is constituted by the following scripts. You can modify the steps to fill the concrete requirements.</p>
<h4 id="01-fio-deploy-sh">01_fio_deploy.sh:</h4>
<p>This script is used to copy related scripts and debs to all clients according to parameter.conf. The location is previously defined in parameter.conf. Since this script uses expect to interact, it is requested to install expect has not been installed on this client.</p>
<h4 id="02-install-rpm-sh">02_install_rpm.sh:</h4>
<p>This step is optional. Execute it to install fio on all clients if have no fio installed before. 【Deprecated】</p>
<h4 id="03-run-remote-fio-sh">03_run_remote_fio.sh:</h4>
<p>Execute this script if everything is ready.</p>
<h4 id="04-collect-fio-result-sh">04_collect_fio_result.sh:</h4>
<p>Collect all fio result logs to subfolder called fio_result on this client. The results are orgnized by client IP and located under result folder.</p>
<h4 id="05-analayse-reslut-sh">05_analayse_reslut.sh:</h4>
<p>It parses the results collected with 04_collect_fio_result.sh, convert result logs to csv for further disposal, and generate a report “Total.result” under result folder.</p>
<h4 id="06-aggregate-result-sh">06_aggregate_result.sh</h4>
<p>Format result and store to result folder</p>
<h4 id="07-result-process-sh">07_result_process.sh</h4>
<p>Format and summary all of test result, so can copy the result into Excel</p>
<h4 id="fio-conf">fio_conf/:</h4>
<p>Put all fio configs under this folder, can decide the running sequence by specfying proper filename.</p>
<h4 id="rpm">rpm/:</h4>
<p>Include expect and fio tools.</p>
<h4 id="subin">subin/:</h4>
<p>Some internal functions used by scripts.</p>
<h1 id="files-list">Files list</h1>
<pre><code class="language-shell">root@scaler80:/mnt/code/fio-benchmark# ls -l
total 152
-rw-r--r-- 1 root root  2082 May 28 04:13 00_run.sh
-rw-r--r-- 1 root root  2510 May 28 04:13 01_fio_deploy.sh
-rw-r--r-- 1 root root   571 May 28 04:13 02_install_rpm.sh
-rw-r--r-- 1 root root  2991 May 28 04:13 03_run_remote_fio.sh
-rw-r--r-- 1 root root  1301 May 28 04:13 04_collect_fio_result.sh
-rw-r--r-- 1 root root  4578 May 28 04:13 05_analyse_result.sh
-rw-r--r-- 1 root root  1582 May 28 04:13 06_aggregate_result.sh
-rw-r--r-- 1 root root  1668 May 28 04:13 07_result_process.sh
drwxr-xr-x 2 root root  4096 May 28 04:13 dpkg
drwxr-xr-x 3 root root  4096 May 28 04:13 fio_conf
-rw-r--r-- 1 root root   198 May 28 04:13 parameters.conf
-rw-r--r-- 1 root root   480 May 28 04:13 rdma_mount.sh
-rw-r--r-- 1 root root  3232 May 28 04:13 README.md
drwxr-xr-x 8 root root  4096 May 28 04:13 result
drwxr-xr-x 2 root root  4096 May 28 04:13 rpm
-rw-r--r-- 1 root root  1042 May 28 04:13 server_collect.sh
drwxr-xr-x 2 root root  4096 May 28 04:13 setup_env
drwxr-xr-x 4 root root  4096 May 28 04:13 storage-snapshot
drwxr-xr-x 2 root root  4096 May 28 04:13 subin
drwxr-xr-x 2 root root  4096 May 28 04:13 utils
-rw-r--r-- 1 root root  1877 May 28 04:13 watch_state.sh
root@scaler80:/mnt/code/fio-benchmark# 
</code></pre>
]]></content>
      <categories>
        <category>performance</category>
        <category>shell</category>
        <category>fio</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>performance</tag>
        <tag>shell</tag>
        <tag>fio</tag>
      </tags>
  </entry>
  <entry>
    <title>备份 TestLink MySQL数据库</title>
    <url>/2023/06/03/backup_mysql_db/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Lab 环境中有一套TestLink（测试用例管理平台）和一套 media wiki（存放大家日常工作中写的总结性、经验性文档），他们共用一套MySQL 数据库(不同的db user)。</p>
<p>为了确保数据不丢失，需要每天备份一次mysql，目前的备份策略是全量备份，并同步到一台NAS服务器指定目录。</p>
<p>设置的crontab job，每天凌晨1点执行备份，并sync到一套NAS服务器，完成备份文件的备份，以及清理掉规定日期前的备份文件。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="mysql-backup-sh">mysql_backup.sh</h2>
<pre><code class="language-shell">#!/bin/bash
#This script backup the mysql databases and attachments automatically.
 
#variable list
DbName=( 'testlink' 'bugs' 'wikidb' )   # testlink, bugzilla, mediawiki
DbUser=( 'root' 'bugs' 'wikiuser' )
DbPwd=( 'p@ssw0rd' 'bigtera!@#' '111111' )
PicPath=( '/var/www/html/testlink/upload_area/nodes_hierarchy/' '' '/var/www/html/mediawiki/images/' )  # 备份附件等其他目录
BackupPath=/root/mysql_backup/
LogFile=/root/mysql_backup/log_file
 
#check the backup file exists or not
if [ ! -d $BackupPath ]; then
    mkdir $BackupPath
fi

echo "-----------------------------------------"
echo $(date +"%y-%m-%d %H:%M:%S")
echo $(date +"%y-%m-%d %H:%M:%S") &gt;&gt; $LogFile
echo "-----------------------------------------"

for ((i=0;i&lt;${#DbName[@]};i++))
do
    NewFile="$BackupPath"${DbName[$i]}_DB_$(date +%y-%m-%d).tar.gz
    DumpFile="$BackupPath"${DbName[$i]}_DB_$(date +%y-%m-%d).sql
    OldFile="$BackupPath"${DbName[$i]}_DB_$(date +%y-%m-%d --date='1 weeks ago').tar.gz

    #create new backup file weekly
    if [ -f $NewFile ]; then
        echo "New backup file have exists!"
    else
        mysqldump -u${DbUser[$i]} -p${DbPwd[$i]} ${DbName[$i]} &gt; $DumpFile
        tar czvf $NewFile $DumpFile ${PicPath[$i]}
        rm -rf $DumpFile
        echo "[$NewFile] backup completely!" &gt;&gt; $LogFile
    fi

    #remove the obsolete file
    if [ -f $OldFile ]; then
        rm -f $OldFile
        echo "delete the old file: [$OldFile]"
    fi
done
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>统计NAS写入速度(Base on oceanfile tool)</title>
    <url>/2023/06/06/calc_nas_write_speed/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>借助同事 <a href="http://bean-li.github.io/">Bean Li</a> 写的<code>oceanfile</code>（类似<code>mdtest</code>或者<code>vdbench</code>的一个简易工具），快速观察写不同<code>block size</code>的<code>file</code>（含多层目录），NAS的性能表现如何。</p>
<p>此脚本方便快速获取NAS的读写性能，下班前<code>tmux</code>在被测环境中跑一夜，第二天观察统计结果即可。</p>
<h1 id="jiao-ben-nei-rong">脚本内容</h1>
<p><code>run_oceanfile_calc_NAS_performance.sh</code></p>
<pre><code class="language-shell">#!/bin/bash

EFILE=/usr/local/bin/oceanfile
target_no=5000000
WRITE_DIR="/vol/nas02/"
LOG="/var/log/nas_ocean.log"


function check_arch()
{   
    new_arch=(`echo $arch | tr ',' ' '` )
    total_no=1 
    for var in ${new_arch[@]}
    do  
        # echo $var
        let total_no*=$var
    done 

    if [[ ${total_no} -ne ${target_no} ]]; then
        echo ''
        echo '[ERROR]  The current round amount of data: (${total_no}) is less than expected amount of data: (${target_no})'
        echo ''
        exit 1
    fi
}


if [ $# != 3 ] ; then
    echo ""
    echo "USAGE: $0 parallel size arch"
    echo "  e.g.: $0 20 64 10,10,10,10,100"
    echo ""
    exit 1;
fi

parallel=$1
file_size=$2  # Unit is K
arch=$3

# Check arch numbers
check_arch

for round in {1..22}
do
    while (( $(ps aux | grep -w oceanfile | grep -v grep | wc -l) &gt;= 1 )); do
        sleep 60
    done

    write_dir=${WRITE_DIR}/round_${round}

    if [[ ! -d ${write_dir} ]]; then
        mkdir -p ${write_dir}
    fi

    echo $(date) ROUND ${round} BEGIN  &gt;&gt;$LOG 2&gt;&amp;1
    start_time=`echo $[$(date +%s%N)/1000000]`
    ${EFILE} -d ${write_dir} -p ${parallel} -s ${file_size}k -b ${file_size}k -a ${arch} -i 5 &gt;&gt;$LOG 2&gt;&amp;1 
    end_time=`echo $[$(date +%s%N)/1000000]`

    diff=`expr ${end_time} - ${start_time}`
    time_diff=`echo | awk "{print $diff/1000}"`
    avg_speed=`echo | awk "{print ${target_no}/${time_diff}}"`
   
    # echo ROUND $round "* ${target_no}  cost $time_diff (ms) avg_speed $avg_speed"
    printf "ROUND %-8s  %12d (Files)       Cost %10.2f (s)  Avage: %8.2f\n" $round $target_no $time_diff $avg_speed
    
    echo &gt;&gt;$LOG 2&gt;&amp;1
    echo "ROUND $round  * $target_no (files) cost $time_diff (s)  avg_speed: $avg_speed" &gt;&gt; $LOG 2&gt;&amp;1
    echo $(date) ROUND ${round} FINISH  &gt;&gt;$LOG 2&gt;&amp;1
    echo &gt;&gt;$LOG 2&gt;&amp;1
    echo &gt;&gt;$LOG 2&gt;&amp;1
done
</code></pre>
]]></content>
      <categories>
        <category>shell</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>获取WIFI密码</title>
    <url>/2023/06/07/show_wifi_password/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>已经连上过WIFI，忘记了密码，有新的电脑设备要加入，如何快速获取WIFI密码，本文介绍wlan命令，通过wlan命令获取WIFI密码。</p>
<h1 id="shi-jian">实践</h1>
<pre><code class="language-shell">Microsoft Windows [版本 10.0.19045.2965]
(c) Microsoft Corporation。保留所有权利。

C:\Users\Gavin&gt;netsh
netsh&gt;wlan show profile

接口 WLAN 上的配置文件:


组策略配置文件(只读)
---------------------------------
    &lt;无&gt;

用户配置文件
-------------
    所有用户配置文件 : wifiYang_5G
    所有用户配置文件 : strayeagle_5G

netsh&gt;
</code></pre>
<pre><code class="language-shell">netsh&gt;wlan show profile name="strayeagle_5G" key=clear

接口 WLAN 上的配置文件 strayeagle_5G:
=======================================================================

已应用: 所有用户配置文件

配置文件信息
-------------------
    版本                   : 1
    类型                   : 无线局域网
    名称                   : strayeagle_5G
    控制选项               :
        连接模式           : 自动连接
        网络广播           : 只在网络广播时连接
        AutoSwitch         : 请勿切换到其他网络
        MAC 随机化: 禁用

连接设置
---------------------
    SSID 数目              : 1
    SSID 名称              :“strayeagle_5G”
    网络类型               : 结构
    无线电类型             : [ 任何无线电类型 ]
    供应商扩展名           : 不存在

安全设置
-----------------
    身份验证         : WPA2 - 个人
    密码                 : CCMP
    身份验证         : WPA2 - 个人
    密码                 : GCMP
    安全密钥               : 存在
    关键内容            : HelloPasswordTest123!

费用设置
-------------
    费用                : 无限制
    阻塞                : 否
    接近数据限制        : 否
    过量数据限制        : 否
    漫游                : 否
    费用来源            : 默认

netsh&gt;
</code></pre>
<p><strong>说明：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>此处的 “关键内容            : HelloPasswordTest123!”，即为wifi的密码.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>WIFI</category>
      </categories>
      <tags>
        <tag>WIFI</tag>
      </tags>
  </entry>
  <entry>
    <title>fio 校验文件写完整性</title>
    <url>/2023/06/07/fio_verify/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天在整理电脑，发现了之前写的一个利用fio，模拟ceph集群发生OSD Down、UP期间，数据写入内容准确性校验，是否存在业务持续写入过程中，ceph集群发生异常，引发数据丢失的可能。</p>
<h1 id="shi-jian">实践</h1>
<p>脚本分为三部分，一部分是fio写，一部分是 restart ceph-osd，最后一部分是校验fio写文件内容准确性。</p>
<pre><code class="language-shell">run_fio.py
restart_osd.py
check_fio.py
</code></pre>
<h2 id="run-fio-py">run_fio.py</h2>
<pre><code class="language-python">import time

from ezs3.command import do_cmd


fio_cmd = "fio --name=verify --rw=write --bssplit=128k/30:256k/30:512k/20:1m/20 --size=100G --numjobs=32 --ioengine=libaio --iodepth=16 --direct=1 --group_reporting --verify=md5 --filename=/dev/rbd0 --loops=1000"

for i in xrange(100):
    print "------- {} times to run fio  -------".format(i)
    do_cmd(fio_cmd)
    time.sleep(15)
</code></pre>
<h2 id="restart-osd-py">restart_osd.py</h2>
<pre><code class="language-python">import time
import random

import logging
from ezs3.log import EZLog

from ezs3.cluster import ClusterManager
from ezs3.command import do_cmd

EZLog.init_handler(logging.INFO, "/root/osd_random_restart.log")
logger = EZLog.get_logger("restart_osd")


def get_osd_id_ip_map():
    """  Get all of OSD id  """
    osd_id_ip_map = {}
    all_osds_set = ClusterManager().get_osds()[-1]
    
    for key in all_osds_set:
        osd_id_ip_map[key.id] = key.ip

    logger.info("Get all of OSD id and ip mapping information : (%s)", osd_id_ip_map)
    return osd_id_ip_map


def get_osd_id(osd_id_ip_map):
    """  Get a OSD id by random  """
    slice_list = random.sample(osd_id_ip_map.keys(), 1)
    osd_id = slice_list[0]
    ip = osd_id_ip_map[osd_id]

    return osd_id, ip


def restart_osd(osd_id_ip_map, sleep_time=None):
    """  Restart the OSD  """
    sleep_time = 1800 if sleep_time is None else sleep_time

    for i in xrange(100):
        osd_id_ip_info = get_osd_id(osd_id_ip_map)
        osd_id = osd_id_ip_info[0]
        ip = osd_id_ip_info[1]

        logger.info("Will restart OSD : (%s), then sleep : (%s)", osd_id, sleep_time)
        cmd = "ssh {} /etc/init.d/ceph restart osd.{}".format(ip, osd_id)
        logger.info("Restart osd cmd is : (%s)", cmd)
        do_cmd(cmd, 300)
        time.sleep(sleep_time)


if __name__ == "__main__":
    all_osds = get_osd_id_ip_map()
    restart_osd(all_osds)
</code></pre>
<h2 id="check-fio-py">check_fio.py</h2>
<pre><code class="language-python">import sys
import time
import logging

from ezs3.log import EZLog
from ezs3.command import do_cmd

EZLog.init_handler(logging.INFO, "/root/read_check.log")
logger = EZLog.get_logger("check_fio")

fio_cmd = "fio --name=verify --rw=read --bssplit=128k/30:256k/30:512k/20:1m/20 --size=100G --numjobs=32 --ioengine=libaio --iodepth=16 --direct=1 --group_reporting --verify=md5 --filename=/dev/rbd0 &gt; /root/fio_output.txt"


def fio_read_verify(sleep_time=None):
    """  FIO read verify  """
    sleep_time = 600 if sleep_time is None else sleep_time

    for i in xrange(10000):
        do_cmd(fio_cmd)
        fio_output = do_cmd("cat /root/fio_output.txt | grep 'err='", 60).strip()
        err = fio_output.split("err=")[1].split()[0]
        print("--  err is : ({})".format(err))
        if int(err) &gt; 0:
            logger.error("[ERROR]  Find error in fio result when read verify")
            sys.exit(0)
        else:
            logger.info("Continue to sleep : (%s)", sleep_time)
            time.sleep(sleep_time)


if __name__ == "__main__":
    fio_read_verify()

</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>ceph</category>
        <category>fio</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>ceph</tag>
        <tag>fio</tag>
      </tags>
  </entry>
  <entry>
    <title>S3 Example</title>
    <url>/2023/06/21/s3_example/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>日常工作中经常使用的S3相关的动作，诸如上传Object，携带metadata等，简单做个汇总。</p>
<h1 id="shi-li-dai-ma">示例代码</h1>
<pre><code class="language-python">#-*-coding:UTF-8-*-

import boto

import boto.s3.connection
import os
from boto.s3.key import Key
access_key ='XX4SO4LP5SDY3DZ0G0KN'
secret_key = 'tvRtXW/ADPUNSw9ccuMWoU1cFu/wJG2QbCOvbX34'


#建立连接
print "createt connection BEGIN \n"
conn = boto.connect_s3(
        aws_access_key_id = access_key,
        aws_secret_access_key = secret_key,
        host = '10.16.17.88',
        #is_secure=False,    #uncomment if you are not using ssl
        calling_format = boto.s3.connection.OrdinaryCallingFormat(),
        )
print conn

print "createt connection  END\n"

#列出所有已有的bucket，以及创建时间
print "list all the bucket in this account, empty of course"
for bucket in conn.get_all_buckets():
    print "{name}\t{created}".format(
            name = bucket.name,
            created = bucket.creation_date,
            )
print "list all buckets finished\n"

# 查找bucket是否存在
print "create bucket and list all bucket BEGIN"
bucket_name = "my-bucket"
bucket = conn.lookup(bucket_name)
if bucket == None :
    print "bucket {} is not exists".format(bucket_name)
    # 创建bucket 
    bucket = conn.create_bucket(bucket_name)
    # 再次列出所有的bucket，查看是否存在新建的bucket
    for bucket in conn.get_all_buckets():
        print "{name}\t{created}".format(
                name = bucket.name,
                created = bucket.creation_date,
                )
    print "create bucket and list all bucket END\n"

#查看bucket中的所有对象
print "list all the OBJECTS in bucket, empty of course"
bucket = conn.lookup(bucket_name)
for key in bucket.list():
    print "{name}\t{size}\t{modified}".format(
                name = key.name,
                size = key.size,
                modified =
                key.last_modified,
           )
print "list all the OBJECTS in bucket END\n"
   
# 上传对象，对象的内容来自字符串
key_name = "my-object"

print "upload object from string ,and list it "
key = bucket.lookup(key_name)
if key == None:
    print "key {} is not exists in bucket {}".format(key_name,bucket_name)
    k = Key(bucket)
    k.key = key_name
    k.set_contents_from_string("this object is generated by string")
    for key in bucket.list():
        print "{name}\t{size}\t{modified}".format(
                    name = key.name,
                    size = key.size,
                    modified =
                    key.last_modified,
               )

print "upload object from string ,and list it END\n "

# 上传对象，对象的内容来自文件
key_name = "my-object-from-file"

print "upload object from filename ,and list it "
#需要上传文件的路径，我的例子是Linux的路径，Windows下用文件的路径即可。
filename_need_upload = "/var/log/kern.log"
key = bucket.lookup(key_name)
if key == None:
    print "key {} is not exists in bucket {}".format(key_name,bucket_name)
    k = Key(bucket)
    k.key = key_name
    k.set_contents_from_filename(filename_need_upload)

    #上传完毕后，列出所有的对象，查看新上传的文件是否存在。
    for key in bucket.list():
        print "{name}\t{size}\t{modified}".format(
                    name = key.name,
                    size = key.size,
                    modified =
                    key.last_modified,
               )

print "upload object from file ,and list it END\n"
# 下载刚刚上传的对象 
key_name = "my-object-from-file"
filename_of_download = "/tmp/kern.log.bak"


print "download object to file string ,and check file "
key = bucket.get_key(key_name)
key.get_contents_to_filename(filename_of_download)

if os.path.isfile(filename_of_download):
    print "{} is file ,download successfully".format(filename_of_download)

print "download object to file string ,and check file END\n "


# 删除bucket中的某个对象

key_name = "my-object-from-file"
bucket.delete_key(key_name)

# 删除之后查看对应的key 是否存在
for key in bucket.list():
    print "{name}\t{size}\t{modified}".format(
                name = key.name,
                size = key.size,
                modified =
                key.last_modified,
           )

# 删除bucket中所有的objcet
for key in bucket.list():
    bucket.delete_key(key.name)

# 删除bucket
bucket_name = "my-bucket"
conn.delete_bucket(bucket_name)

</code></pre>
<pre><code class="language-python">#!/usr/bin/env python
#-*-coding:UTF-8-*-

import boto3

s3_client = boto3.client('10.16.17.11:8080')
open('hello.txt').write('Hello, world!')

# Upload the file to S3
s3_client.upload_file('hello.txt', 'BUCKET', 'hello-remote.txt')

# Download the file from S3
s3_client.download_file('BUCKET', 'hello-remote.txt', 'hello2.txt')
print(open('hello2.txt').read())

</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>S3</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>S3</tag>
      </tags>
  </entry>
  <entry>
    <title>vim支持黏贴</title>
    <url>/2023/07/08/vim_copy/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>打开vim进行编辑时，有时候通过类似xshell这样的终端工具，想拷贝vim里的内容或者黏贴内容到vim里，会出现无法黏贴的现象。</p>
<p>虽然可以在vim中直接设置 ‘:set mouse=a’，但是无法永久生效。为了解决此问题，本文介绍之。</p>
<h1 id="vim-wu-fa-nian-tie-wen-ti">vim 无法粘贴问题</h1>
<p>修改配置文件，找到如下配置文件</p>
<p><code>vim /usr/share/vim/vim90/defaults.vim</code></p>
<p>在81行找到如下内容：</p>
<pre><code class="language-shell">if has('mouse')
  if &amp;term =~ 'xterm'
    set mouse=a
  else
    set mouse=nvi
  endif
endif
</code></pre>
<p>修改为</p>
<pre><code class="language-shell">if has('mouse')
  if &amp;term =~ 'xterm'
    set mouse-=a
  else
    set mouse=nvi
  endif
endif
</code></pre>
<p>保存退出</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>修改默认shell</title>
    <url>/2023/07/16/edit_shell/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>今天在Ubuntu22环境下安装LANMP，执行<code>sh lanmp.sh</code>命令运行LANMP，如果出现如下错误：</p>
<pre><code class="language-shell">root@ubuntu22:~# sh lanmp.sh 
lanmp.sh: 49: lib/common.conf: function: not found
lanmp.sh: 76: lib/common.conf: Syntax error: "}" unexpected
root@ubuntu22:~# 
</code></pre>
<p>这是因为在Kali或Ubuntu系统中，对dash的兼容性不好，而编译常用的是bash（Ubuntu默认shell是dash,  但是从bash环境拿过来的shell脚本执行就会遇到一些问题）。</p>
<p>这里涉及到更改系统的编辑器(shell)操作，本文介绍之。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="fang-fa-1-jiao-hu-shi-xiu-gai">方法1： 交互式修改</h2>
<p>输入命令dpkg-reconfigure dash ，然后选择&lt;NO&gt;选项：</p>
<pre><code class="language-shell">dpkg-reconfigure dash 
</code></pre>
<img class="shadow" src="/img/in-post/reconfig-shell.png" width="1200">
<h2 id="fang-fa-2-fei-jiao-hu-shi-xiu-gai">方法2：非交互式修改</h2>
<p>方法1是交互式的, 但是实际情况用脚本的更多, 所以我们还是用命令修改吧</p>
<pre><code class="language-shell">[[ -L /bin/sh ]] &amp;&amp; mv /bin/sh /tmp/.sh$(date +%s)
[[ -f /bin/sh ]] || ln -s /bin/bash /bin/sh
[[ -L /usr/share/man/man1/sh.1.gz ]] &amp;&amp; mv /usr/share/man/man1/sh.1.gz /tmp/.sh.1.gz$(date +%s)
[[ -f /usr/share/man/man1/sh.1.gz ]] || ln -s /usr/share/man/man1/bash.1.gz /usr/share/man/man1/sh.1.gz
</code></pre>
<p>这些命令就是根据dpkg-reconfigure dash的结果来修改的。</p>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>ceph PG 修复</title>
    <url>/2023/06/01/ceph_pg_repair/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>3月份的时候，江苏电力这个客户发生PG状态异常(纯粹是友情支持，发生问题的环境非我司ceph集群，而是ceph 开源集群)，需要进行手工修复。</p>
<p>应客户要求，临时写了个修复脚本，供客户设置定时任务，定期自动修复。</p>
<p>考虑到一些PG状态是无法修复的，做了一些保护；以及修复失败的保护。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="inconsistent-pg-repair-py">inconsistent_pg_repair.py</h2>
<p>脚本内容如下：</p>
<pre><code class="language-python">import os
import sys
import gzip
import json
import time
import errno
import select
import atexit
import socket
import logging
import commands
import traceback
import logging.handlers

from threading import Event
from fcntl import flock, LOCK_EX, LOCK_NB
from signal import signal, SIGTERM, SIGKILL, SIGUSR1


class Daemon(object):
    """
    A generic daemon class.

    Usage: subclass the Daemon class and override the run() method
    """
    def __init__(self, pidfile, stdin='/dev/null', stdout='/dev/null', stderr='/dev/null', kill_timeout=90):
        """
        Constructor.

        @param  pidfile:    path of the pid file
        @type   pidfile:    string
        @param  stdin:      path of the stdin
        @type   stdin:      string
        @param  stdout:     path of the stdout
        @type   stdout:     string
        @param  stderr:     path of the stderr
        @type   stderr:     string
        """
        self.stdin = stdin
        self.stdout = stdout
        self.stderr = stderr
        self.pidfile = pidfile
        self.lock_fd = -1
        self._kill_timeout = kill_timeout
        self._daemon_stopped = Event()
        self.first_loop = True

    def daemonize(self):
        """
        do the UNIX double-fork magic, see Stevens' "Advanced
        Programming in the UNIX Environment" for details (ISBN 0201563177)
        http://www.erlenstar.demon.co.uk/unix/faq_2.html#SEC16
        """
        try:
            pid = os.fork()
            if pid &gt; 0:
                # exit first parent
                sys.exit(0)
        except OSError as e:
            sys.stderr.write("fork #1 failed: %d (%s)\n" % (e.errno, e.strerror))
            sys.exit(1)

        # decouple from parent environment
        os.chdir("/")
        os.setsid()
        os.umask(0)

        # do second fork
        try:
            pid = os.fork()
            if pid &gt; 0:
                # exit from second parent
                sys.exit(0)
        except OSError as e:
            sys.stderr.write("fork #2 failed: %d (%s)\n" % (e.errno, e.strerror))
            sys.exit(1)

        # redirect standard file descriptors
        sys.stdout.flush()
        sys.stderr.flush()
        si = open(self.stdin, 'r')
        so = open(self.stdout, 'a+')
        se = open(self.stderr, 'a+b', 0)
        os.dup2(si.fileno(), sys.stdin.fileno())
        os.dup2(so.fileno(), sys.stdout.fileno())
        os.dup2(se.fileno(), sys.stderr.fileno())

        # write pidfile
        atexit.register(self.delpid)
        pid = str(os.getpid())
        open(self.pidfile,'w+').write("%s\n" % pid)

    def delpid(self):
        """
        Delete the pid file.
        """
        os.remove(self.pidfile)

    def lock_or_exit(self):
        try:
            self.lock_fd = os.open(self.pidfile, 
                                   os.O_CREAT|os.O_TRUNC|os.O_WRONLY|os.O_EXCL,
                                   0o666)
        except OSError as e:
            if e.errno == errno.EEXIST:
                self.lock_fd = os.open(self.pidfile,os.O_WRONLY)
            else:
                sys.stderr.write(
                    u"Can not create pidfile : {} error {} \n".format(
                        self.pidfile, str(e)
                    )
                )
                sys.exit(1)

        try:
            # flock can be  inherited by child process, even exec()
            flock(self.lock_fd, LOCK_EX | LOCK_NB)
        except IOError as e:
            if e.errno == errno.EAGAIN:
                sys.stderr.write(
                    u"pidfile {} is locked, Daemon already running?\n".format(
                        self.pidfile
                    )
                )
                sys.exit(0)
            else:
                sys.stderr.write(
                    u"failed to lock the pid file {} , error {}".format(
                        self.pidfile, str(e)
                    )
                )
                sys.exit(1)

    def start(self):
        """
        Start the daemon
        """

        self.lock_or_exit()

        # Start the daemon
        self.prepare_start()
        self.daemonize()
        signal(SIGTERM, self.handle_term)
        signal(SIGUSR1, self.handle_siguser1)
        daemon_name = self.__class__.__name__
        try:
            logger.info('Daemon {} start'.format(daemon_name))
            self.run()
            logger.info('Daemon {} stopped'.format(daemon_name))
        except Exception:
            logger.exception('Daemon {} terminates unexpectedly'.format(daemon_name))

    def get_pid(self):
        # Get the pid from the pidfile
        try:
            pid_str = (open(self.pidfile).read().strip())
            if len(pid_str):
                pid = int(pid_str)
            else:
                pid = None
        except IOError:
            pid = None
        return pid

    def stop(self):
        """
        Stop the daemon
        """
        pid = self.get_pid()

        if not pid:
            message = "pidfile %s does not exist. Daemon not running?\n"
            sys.stderr.write(message % self.pidfile)
            return  # not an error in a restart

        # Try killing the daemon process
        try:
            waiting_killed = 0
            while 1:
                if waiting_killed == 0:
                    os.kill(pid, SIGTERM)
                elif waiting_killed &lt; self._kill_timeout:
                    os.kill(pid, 0)
                else:
                    # Use kill pg to force kill all subprocess
                    os.killpg(os.getpgid(pid), SIGKILL)
                time.sleep(1)
                waiting_killed = waiting_killed + 1
        except OSError as err:
            err = str(err)
            if err.find("No such process") &gt; 0:
                if os.path.exists(self.pidfile):
                    os.remove(self.pidfile)
            else:
                print(str(err))
                sys.exit(1)

    def restart(self):
        """
        Restart the daemon
        """
        self.stop()
        self.start()

    def prepare_start(self):
        """
        You should override this method when you subclass Daemon. It will be called before the process has been
        daemonized by start() or restart().
        """

    def run(self):
        """
        You should override this method when you subclass Daemon. It will be called after the process has been
        daemonized by start() or restart().
        """

    def terminate(self):
        """
        You should override this method when you subclass Daemon. It will be called after the process has been
        daemonized by stop() or restart().
        """
    
    def user_signal_1(self):
        """
        You may override this method when you subclass Daemon.
        The default method toogle to change the loglevel from between debug and info
        """

        new_level = logging.INFO if EZLog.getLevel() == logging.DEBUG else logging.DEBUG
        EZLog.setLevel(new_level)
        logger.info('Daemon {} log level is chaged to {}'.format(
            self.__class__.__name__,
            'debug ' if new_level == logging.DEBUG else 'info'))

    def is_daemon_running(self, wait=0):
        # do not wait for first loop
        if self.first_loop and wait &gt; 0:
            wait = 0
            self.first_loop = False
        return not self._daemon_stopped.wait(wait)

    def handle_term(self, sig, frm):
        logger.info('Got signal: {}'.format(sig))
        if self.is_daemon_running():
            self._daemon_stopped.set()
            self.terminate()

    def handle_siguser1(self, sig, frm):
        logger.info('Got signal: {}'.format(sig))
        self.user_signal_1()


class BtLogger():

    def __init__(self, log_name, log_file_name, log_level=logging.DEBUG, max_bytes=5*1024*1024, backup_count=5):

        self.logger = logging.getLogger(log_name)
        self.logger.setLevel(logging.DEBUG)
        formatter = logging.Formatter('%(asctime)s %(filename)-8s[line:%(lineno)-4s] [%(levelname)-5s] %(message)s')

        self.h_rotating_file = logging.handlers.RotatingFileHandler(log_file_name, maxBytes=max_bytes, backupCount=backup_count)
        self.h_rotating_file.setFormatter(formatter)
        self.h_rotating_file.rotator = self._rotator
        self.h_rotating_file.namer = self._namer
        self.h_stream = logging.StreamHandler(sys.stdout)
        self.h_stream.setFormatter(formatter)

        self.h_rotating_file.setLevel(log_level)
        self.h_stream.setLevel(logging.INFO)
        self.logger.addHandler(self.h_rotating_file)
        self.logger.addHandler(self.h_stream)

    def _namer(self, name):
        return name + ".gz"

    def _rotator(self, source, dest):
        with open(source, "rb") as sf:
            data = sf.read()
            with gzip.open(dest, "wb") as gf:
                gf.write(data)
        os.remove(source)

    def get_logger(self):
        return self.logger


sleep_time = 1 * 60 * 1
logger = BtLogger(__name__, "/var/log/inconsistent_pg_repair.log", log_level=logging.DEBUG).get_logger()


class RepairDaemon(Daemon):
    """ Repari inconsistent PG in daemon  """

    @staticmethod
    def pg_not_health():
        unhealth_pg = ["scrubbing", "nearfull", "incomplete", "full", "backfill",
                       "degraded", "remapped", "stale", "recovering"]
        pg_stat = commands.getoutput('ceph pg stat').strip()
        for each_unhealth_pg in unhealth_pg:
            if each_unhealth_pg in pg_stat:
                logger.error("[ERROR]  Find unhealth PG : (%s), do nothing, exit!!!", each_unhealth_pg)
                sys.exit(2)

    @staticmethod
    def get_inconsistent_pg():
        inconsistent_pg = []
        res = commands.getoutput("/usr/bin/ceph --connect-timeout=10 health detail | "
                                 "grep inconsistent | grep acting").strip()

        if res:
            if 'failed_repair' in res:
                logger.error("[ERROR]  Find 'failed_repair' PG, do nothing, exit!!!")
                sys.exit(2)

            for each_element in res.split('\n'):
                inconsistent_pg.append(each_element.strip().split()[1])

            # Remove duplicate and None element
            inconsistent_pg = {}.fromkeys(inconsistent_pg).keys()
            inconsistent_pg = filter(None, inconsistent_pg)
            logger.debug("Find inconsistent PG : (%s)", inconsistent_pg)
            return inconsistent_pg
        else:
            logger.debug("Not find inconsistent PG.")
            return inconsistent_pg

    def auto_repair(self, pg_name):
        """
        Run 'ceph pg reapir pg_name', try to repair PG
        :param pg_name, string, a PG id
        """
        repair_cmd = "ceph pg repair {}".format(pg_name)
        logger.info("Starts to repair PG : (%s), command : (%s)", pg_name, repair_cmd)
        repair_res = commands.getoutput(repair_cmd)

        health_res = commands.getoutput('/usr/bin/ceph --connect-timeout=10 -s').strip()
        if 'failed_repair' in health_res:
            logger.error("[ERROR]  Repair PG :(%s) failed, please pay more attention!!!!!")
            sys.exit(1)
        else:
            logger.info("Repair PG : (%s) result : (%s), now sleep (%s)", pg_name, repair_res, sleep_time)
            time.sleep(sleep_time) 

    def list_inconsistent_obj_repair(self):
        """
        List inconsistent object for each inconsistent PG before, then repair
        """
        self.pg_not_health()

        inconsistent_pg = self.get_inconsistent_pg()
        if len(inconsistent_pg) &gt; 3:
            logger.warn("[WARN]  Found more than 3 abnormal PGs, suggest to repair manually, exits!!!")
            sys.exit(3)

        if len(inconsistent_pg):
            for each_pg in inconsistent_pg:
                list_cmd = "rados list-inconsistent-obj {} --format=json-pretty".format(each_pg)
                list_res = commands.getoutput(list_cmd)
                logger.debug("rados list-inconsistent-obj %s : (%s)", each_pg, list_res)
                if list_res and len(json.loads(list_res)['inconsistents']):
                    logging.warn("Find inconsistent PG : (%), now reapir "
                                 "(%s)",json.loads(list_res)['inconsistents'], each_pg)
                    self.auto_repair(each_pg)
                else:
                    logging.warn("PG in inconsistent, but list inconsistent object is None, skip to repair!!!")
        else:
            logger.info("Not find inconsistent PG, skip.")

    def run(self):
        logger.info("Repair inconsistent PG Daemon starts run")

        while self.is_daemon_running(wait=30):
            try:
                self.list_inconsistent_obj_repair()
            except Exception:
                logger.error("ezsnapsched exception: {}".format(traceback.format_exc()))


if __name__ == '__main__':
    daemon = RepairDaemon('/var/run/bt-repair.pid')
    if len(sys.argv) == 2:
        if 'start' == sys.argv[1]:
            daemon.start()
        elif 'stop' == sys.argv[1]:
            daemon.stop()
        elif 'restart' == sys.argv[1]:
            daemon.restart()
        else:
            print "Unknown command"
            sys.exit(2)
        sys.exit(0)
    else:
        print "usage: %s start|stop|restart" % sys.argv[0]
        sys.exit(2)

</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows下pyserial嵌入式自动化测试框架</title>
    <url>/2023/07/19/pyseral_automation/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，密码错误！" data-whm="抱歉, 这个文章不能被校验, 不过你还是能看看解密后的内容。">
  <script id="hbeData" type="hbeData" data-hmacdigest="fe4c1d9a9625a9ed3db0c510e45234d168aa00241c34f3156f7a23f1391df7a4">5578a3011739917ed1e826a9c83d0401c4abd65da3acb0485a568f1f20a3315608f95ae27733432853a997dd9ec3294aa0f44e6cf4070a2deb312510a21a20f6353dafe0afaf7916b6e2a274e761c939291b948134bea457904b4b3c49af4b8194fc81c0f9be265f992dad4f0b00af58d7981a569e210ee346b8a5b20ddcc73070f5ec1c33a119f2f250cb1712e36e9f885825adb12d08dd3a23a9ab432e2f1d92608560eaeb33b5c7226b9d26ac6d6a0d4ad2912ac15cf5432f38044c9a3cc0911b633bdfb384e5efca8e38972083f503c3ebe0971b98ff3deba21dcf4c07efa29ca66669dbc05df3f99efebaa5049667b01dc95874dc5938194c3b5dad256e1fdbb668f0d0369b082d6b0e7fc457a3767cc78e33932936f7753a515eefb9b0c1f72652ba018c00e033ac0dde46a4310befcc88b69c63a6074276dceb06bd4a4ec04c221bc784061c6303712ab967bf4fd029e932e0e12d31e83d8bcd578e02e3290f1e9b4799c68af5e7355eafe45946b73f83c87539e02f34b3be9073223cfdcdee3d403ffc3fe0c8dcf8fc60542d0c5023c711b95ec4cbb979057911f4e5fe79273967c5f9e3c75cc8a0f7339583b6bd561fa36ba9649a71c08f79f876f99e78c60beca8454b6146746bbbaf3a67092e22ecdeb0d2a117ffdc94a48366b4f8f42cd1f6b4323b2816677031720196c114722c2d08eb4ae888e03566a261b3b9e34f16151284d06e70eee381f7b69166e09e4e801951a752c0b3b3167fa6222984076204cb96292b5ba5ba19c9750c3921063eeb75e182f77f14a8656f18f4ac1d32bd9d964022950b79458ee6d9b226141a8f9d39dcbeac062b2288f70629fd91df8735ba30fdbf62265b9f99c85a6b2fda781e9eb3044ccf6d3f3d8b098f7310b5143961c4bd17025a25037605434c0307b164caabe1219529a23ec8502c1deacde4e39b5a19e6a999696b21da92d4e0fe82adac52af776b95316e75a55f795d09593bd7cbef9ef300da520a3e2852a0c6b6f2b2e704bdc3f00acdc3b166a1d6ce816e3a49bcd1a459b547afeeb87fa5cb7ea21d4e5658fb8e3455379c6029dc6482fdcfd696b94b98985f622859092f40b45234a2a4864e5f87c3ae4de1c913f25a2b7b7f2ffa834cd30b0463120e33a0a7b85444d10404f04a0f71e12cd3ec623aae97c06a593a6e81d9a84b3b0f9b9a214cd5f9399353aa6cd9e71258d4d736bf12ccbfd80141f7ab4df97eda270c1b02bfe19d7ea12e7a7f9de720183dbbb6a89407fa110c06ad7f18a41c2a6b05a9ce9e6fc6ae019019433b4bc7aa67a41b5aeadab80a5d214b3ae7ad4a6ac0a38080ac57201bc1aa54a030125daad94b7d5c403feefdf9ae6c691963154efe9bb275152a1d4eeae1b07ea6b19e7b126d2edd1419af9ad6986f45dba5b36572a564e09696bc693ff022e8122c084a95ef6b32ed3daf9855a3ab73afd0299323c7d6f80418b6c15204bfed26bb1101b44281234c54a4e27e8619d3188f614ea08734d21f9365319d3e05ab55d7bf06b7a5a7e286f8e5693c97376db83d19aa75b2b0cd84f616bceb0a6d22bf96c38296c545f5f23f2180882c52169e6e40177f7a2c52d377fc03405425a1650aa1151b2a2c594449dd5781928f5faf6495db9353df81b777d569ef6e33a63dad5e3fbdf9d267746cb07b206e7def2ccbc66a2bab188ab12b805894fc86aba83ad00a66fdfd87745103a5c63ca6b4b044d9e0cac3d87bdcbe4789b7ef86b9009a820d565b01ae58134d523ad57d47a0c7418833cc8426a14bf01592022f09b95d6f1720381d6f67fde86cd48bd710bf501c3f305629a23a0d24634c6f980c2d330c9af260749aa5b41be1aed9c40a03d0256eb58533043ba924366675a53f917b6d4a39cc5abf273d98217b7579a988449b3032e26f558b7b286d00b340bcd28b56dbfe16d84d651019ccea24984e79ecbd4edec398745f671181c069853b9947f541de6758e4d0f5bc4dabd0e64a7401e1eb759d4c7558a63def5e1685b8d673608496a6d43e587bfa5fd4049adf7c156b96830f7093646397896a4152a0316d5fb74fdcbefec0bc02fb00147e8c3be2ab778e68ae1a17ce13ab28d9ed3dda999afd58377f55c387d2d443ff4d16d83b1955f96b02095c1bcc64e3fbc5f0ce7b371234bf78276e34672258948c433b5544a581aee33c8d5dd4018f9b4a1294ba9665e0526d73bf93f0458cee3ecda83c2f0c13d3073935d6f3fa6a23120675a002b27406b81f1e3f61f20470ce9dab051644f8598622474b6fd9d3c62be59513f959aef4b30f0e644729ed601729f7fb68edbf12028713165da1b3e57156c37a1c07c0de4bb792114f04bb613e28c2cf5df34241e7d99fb6d864062b6073ca6a1a93b108d230ec6cad55e1150dfe2cfb3d1a0f6dadc36063692d0df99d9b5ddbf67b630717ed4a2429b2f7c540e5bafbe4c48899e40aa400b2423130b6f9821149a3ae804679eefab040910037bb384b8484352f8cff56c105b7f993b62e21c49a12c4b22267f9fda8951a537ddb3b88fcd19ee365db4da2817f0c8d8799485835596433a45602c39cabb280405890aee73090e743509ac29f321495a00d63c8c28eb07e242e160bd66486b1b6c59667e53d891f606bc4b349564e3b6486b761010c78c4a8d3ecfd8be35dd795c33b9267395ea466bb51d04294219c812454c2be3f58778c971a67c3df60074b7f6e4426c8dea243ff6fd6a44b2c3ea95faee8363ab9d0972036e2f7f769c105ef8c29aecbb2d4f95abaaee605d2d011c717d231ce65a293cc2a938dc9779a059fc307ff667eaae91180b5792f6a543dd9a8a8ac424cb1a25e42efc57f914ed6824f83ee5998b74c7d03bdf183462e549acaf3586e9d4eacac54996bd9b9c32b9f00c20ff8e865f44ca89056f176596bf2e4dba4eb0f1530f9fd200216f5acf924717111d1ead10a399c9af4362a4aae0837b10a5084e354e81d9ab19e65b5265df2830b6ef4ae4e2a868c6c01ed9ae89659e531649af48ec241158e9606032b1da79183f660e313577cebf546b43ca6fb9df47b7b300af504742afbc1cf0ebed396d7783b33ab4d64077e0eb0a7586a30c24b2d20b8f71f9e734409828743f6046b0e08e00a583de7dc57be3deb4bc9c0736c470bf8300304023c4ab12a3eced80fd43b1bb5978a734c98bcb5549cbc66e264740445217b73d2afc7882b38d58d0232078ef3583e8de0794bc28c5b6f7d20fd8ebdf1fa6bf71411a4eb22bab142bd95b47a0db5796097d8b36cf022c24ea860fc4fe5f1c097a44e816b1fc1976894f2b9fe1cfa6ae9ccb5ba03f4a9eb2d64d9bbfae02ff177835e6b376777f43c80b204affdd669b98735b4c361192b2f132f60d685c5f705eb1f769ee50e33eb7fec5ed4255e8251863d3799bc8c5173df9800cbbc0fa1ceb4c833215d1c1462d648448925cfe919e93ab7b9bef134f1bc16626ed8206e1596a330bf0f4e906e3e9898b57792d4e984ed10012c035ac5faa95e058499714157cb964a287ba99778dda28739fc073118f143001ee57d2deb409a9665b157e61a2328b471c5b78725a01689da5c45cd17ec59c0d77be73a6df339cea8eefc0048553e45c61b6b001682cb1275ba3f1cde9536b0132fd05b5d654b8689d4aaec59b4f334ee205e10d2a499b5b717e08f99a3dbc26e00a7929f7d41ced03f9066fae45f921dce484fe9436121410ef1adb7bed09da32b2dd94e647eb4fa5b9f77f516f59ff8f28f0bbbdca2f1bbd1e70a0e94886c0bb1d8b76d5d832e6fc7eec601a9aef6396be37781ec8c6643d02e4cad7eadaf1d6166995eada0555e9daf6475e0bfb4f17a0ddaccff82f51918410bba81c5a8f24386156727227c3cf4ba5f2422b675e49ac45bb83b4ecc57acba63a54b30dc4f0be428a9e9f5936a968641be8eba0672ea9863ed1b74a0b2ee8a293b964c91ec5e31295ff81210fb0bda9c8048c725940befa6d3257a714b2f2adb0a0a3a60957c3a1c099cdfdac871f2d44c0b6df0879f26268e6581906dcbe70fbf2314376bbf90c99bb3dbbae7671dcccc64bfa49ce60f788b3feebbcc4a83079d83ae788057690706adb3d27a04e1fc147a244137af4964ad59164c8e314d8abe7b934fa62f886563f17e1e90897a69022d7c6e0cf7049363f476b35b39ea590cb4016aa484e63fb96767a31357d163c58fa044e94004cfd707189bce9c8acf42d6a253f7b7d29a19bd955c41bb619590182719d31a3cc8cb86350ac67614386097adc78c2cce903b01795d15ff29077c94d2497aa6148a3969476fa3150514950fb0e30258c35b1ddb4c7295ac9b42db10cb59f13c234522bd9f2acdaffcaaad74cf85b778adf7b616dca62ae42e8ace49fc2817f116d141fa28ebe38f5325951e365699be73381660f08ad863c24810ecdbc15c18d8418359571ec79d47f9647a02e08e620bca2b6d82865a47ba6821e014556635622676300748026467a904735af413edd5bb85d749990a8cca7825d327335180813b4cda04dd70c9ddce0056c01026371c3dd724d61febedcf92d82b53d277a6f5300758b8bf513d9c7dd7e2cdcc5973fac99df89f95ec21cb8b1cbc56d9a4bb4f9d4ab1f53a8c6476f4be11c01cdcadaee108d4c62f0a9b62017d7dff593e00ad695bd481e58a5bf4cd47526671df746ba89ccc8a0f005bb19d87f3e1649a37d18173a072604517d97cc2d6b52af611967e00488b7703bf425a400f551d36361571bb63a04cffcb72f54a17fc6730295f580cd1779c7129f39646333ea74f7f39e6023ec67db316865196c8a1ed14f4d7636ced7851ad651b37f462ad61f8c620b508646f31290543d2d653cadb814a840756c8d131742d4d58e0c02ef6fbe5265b23c5aa60d05bf176ce39fc87ac47266c2a8e06fd2c958b963d933402e154465472825d7c330a5c656e4d2621f688e3037aa33542de1b143d3be631bf24840d1a170682fb625c5d07b3362c6e4a597aba6f290beaee1774263553fb4aed4d1b6be71e0019223b2e39654df49e70364bcda56125224bd5128260073228493f9e7e89ea0e646c306d044f4aa5b7b64fe158f31c2ea39fd1c3013bce22d4218ab41e220408c82c549079087d3fc57140dd69e719282113b2bf6fba16d60fecfd044e8be3dcf640487aa46ff2a0d8f091a41b619a5bdd32b3969a41eb9156a13f553bc3de9f0aba4da972a9f698672cfe3b9cfa6b1278004868ca9c3e4724c97ed2ded58bba931f4e0d9083708380777cb136266bc7780119c73b7fa06cdd925a9aff9dba9a836f1b779f9fe9c912ac36ff5c595d60289d896368f7d80f7966656dd32b99aaf52f8f8dcbd791ed11e7d2f68f85fd732852be79cd4bfe69238de0176d943072527acf45b1f5b20f5df2172392326c2e65e90fc8ac61f21aab8da47905f6f95251b52ca621b60b3c06abb91bcb2cd243c7000bc03f13f5c0535d81d9eaf49080c953a73468139d93fb5d89df910cd9e83187e2716617865a09e94e3c749fe5f8186b32dc44452b7b27648002c31c52a08cc71c120f6ca39de1fd4b01abac75c8e7b9fbd246134b14dc9b7002a35be59753f74e9ad725639c58671428de5d66449de610c99ed6eb37de52ff67e7897b6563fd15069dcec90810379fa2a29062a19c616f04f1bebd5645313627355b3d3212de2d3c6ceba46ce637af2e731fc3c6b01778210bf50e040c6c83d0d1cfb86b1fa16790c876e5bc5d8a22c11239eda08519ab842022a64a833468d778bbf0c0440dde00eae90cb685c86f1cc22dcf7f4bd00451ace98c6f6ed00616d194941146909dc51329fab30b91848b7e780c3bebfc79eb496a1c369c9ee02af2f38122b52351b1309fa475deb62b99abe0ca97b26d6e4e93dde8cdc6c39a2dbc2c0d9726f80a16dec1e2700573a4f3d4a2043ad4c2ff3da7bacb4b008377f1722740fa39b824c2817ab22ccd5ba55d631b6f9f6535fc7a3d9455644d290fa6ab8a41fd693ece8018b356471cc5a22e03a23c674f3cf294dc2982090290747b16f30798963a1e09c4ed3426b3077d464937a6e105a44f2d37a7d99a0644c1f247adf06ad2847418437f77e67186fa2ad50a72b656931e38ebf28aa26fd36f6c06ad83d4aa7404c70d8730456d8d5756a1f261af7bb9e51b787339b755b2d5abbc42557412e44b7a6f23320943e57feaed632fe736b4d2898872eb9f082164b1f6e102f144ec7ebc25d3f6e7b8a429eca1eed1cfec67d5bf125cfe2bffbcf38b2a4882547d9e4e1e1c1ea60a57c56f1f3665fb9862bafa0de34dba0919c88eda73b581cffcca8bea486782ec39ac7999426ee2e52bd9b33ef555b099d2e38de26f272338489395a36566a3c0b859995545a64eb3540ad7a1454df131615e717af0da8587552989de83c9772f5a8e1253f076ce721878220387dcd3274e4e080d098219ed03a438e6a5926d04a24bb3e866ff05d68a92eb883cd6677d04b9dd363fc8ad454b2aa9c8a18d781d702486a92fee26308ef1574d59b0f57bab9789287aa7b9cedea0eec575e942c582adc4a31579403d2ed6b4c028afdc8d3ced841b758920e6e8e300bd5cbaebfeddd992b7a9408ed574284bd3c45e2055755e5cf051a429aab174e607d026b8b86dc7823e95501b973e2f2666eb76ce9830ca0e457492718e19e1bbd5d3b8fe7ddb5c8a88e8b5702c2c5d29c2349e8bef3c5bc32a73cdbdfec19524c89d6f99e512537ae52632f736864e4a790dfc94a016ed7320ecf433d3411900cdd0aaba5ed963d577db0d23c7d884ca928bdc3440c6ca3d90c39e976058bc88601958fe4901cdcc9891823d4a6f2341b76b74d6659ff6a6057b2a118cd0bbfd39f8d77d2bb31ac1363c9fe748f7efaa9867e1f610e8aa501c906a8c32649cd1f5d5696261374f9dffeb1b7fd52ee0fcc95cf3e73e5bd9d17e98998f7760d760e0c053900786ca7c62be6f5260486932d7538310b7cc2fd24b78ef79a4c03067d0d35c9d19a5c51da918d6813371121edb16496c21d5d577fe24b4ed3da3dba5c7a2f51de64cf5f82a494767f7eb5304d013815b04bde1507e9c18e610ad5b2cc52ebbb139b693ce5dc7509a756df89d409ee25aecfd92de318943bf7832f9b3068d20b31fdf0a28d77d8c57d917bfd8df34e720d19e6bc48a15bc934d4b826b540a7dacb37912ccdaa0c5ef3aee44c919a2125d2874b3f3c62e43b0a9a08ea88bbe2ed70b863d283c900dae647f47124c2f35d55e5d1e9f51e0f84a2382f3e0de2be7074d0f3ba89c19a22fc059cae94c4891115fe623981c9e1bc2f7cf16ae795c7570a5edd0a34ff511311ac3c4bb6b9b65d0ac59510048685733f32f73c52adf43fef352b0e8c885a94148c6e8b1947e748edef8329cf826fb5845967a2a277007567c703d5aa9c9f7d0f97138140b70a0043b62f97dfd93c55b559cb786b7ac774e491888cff7c5cea83168d8950243fdc63e6518444347d7fa062be896060a83a55c6050ed3a7f0aadbf7b02260f0d078eaacff18ab2f50914c981b4d234f924274e109a96fb3c29e3d9d63b8b0cdd511cefd4d92f2bd64c43b0159fd7a736f4c9686658c8bdbfedd38dd815971044254c82081aaf742a731bbd620ed6200c87e830a7b2e6e9ec828122c204e2ddae590ee5efd9ad93d1ae7b9410a4d4bf80956d7cac94dfa9d1b45c1a2844904acc563f84fb1ca492168720311d4d93ed5eb57bb8f52d12cf0410a8cf87d2a11c444ea5827fb007559a01659a118cbdc0a4453218ca5ebd941d2422e7f16666e45749fc4f742eebd53739b141b50015b9f505347c918f21214fc4676dfffd7c3bf50a830e03d24d4c9c755ece1eddc7235931c58d59f4e4e994c741d0109b8005ab4fe7c173f60aee0c0197ecb67a31df7c6aed933b77235cecf26a04ba3c13fb3d51ccf29baff0b596bbb71c92669c89ffbbae32bb4bc844fe081ee04ba4e7fb7a120f3b668f126f22d3d96bedb54f309245a299bcc154e8ecf06dfeb8a16ea33527d0985bbed8d9bc97ca50d495241d6c34cdc3a4806463c7016cb7cab717fc76a63d3cffba7eec0729735f496a4b659debb2415f6b7bd9c548768b23240934898864822d076423bf04592527266bf515866afcc7b442b979d6ed7f290d13412b21a29e4c086118d97271c36ced1b1a6e68961b99bdf6d7f5e56d703bcd5ae6136086ff6b82245305f17fc2eb5d2bbafe7756f25017b3804b803bf02bab5192ad1e80e602848081d5756fe45fe4ba6d5d53eceaafcde6001167958ec05984f13034871016ab8fc96384dedc275ffcfb12848129320eef050cea40681b9a688ea78d048bc0016e9c236c0c1f985f290ef6c9177e34b3c6620126c9313d162dae08308143d8e611ecb2a7b9e002e892f72951db8105f85fd04a72600bfa71c823b372d2c9599bbf8e9ccf123040a96d6d2e1840b07ce028243b987ac13d17b2b3922e470070bd4c7b4ab3acf97db9102f8e6cabea0f96164a33a9ed2b0fc7e2c061ed8cb2c24eab039b6a07c11856cd824439328b37154e8e152d6e16ef3abd0365cd58574adc1baa05324956c57762a8767de5b74a42e38d5ad0e95543e94e9b58cbc689cdf3057f81b073255cf3f88b500b9382e31c7e56fbbfa1f4e6443b3cb7f1a528b71fb3eba5f8bd742e8316d282610e44035d19a42b8d4aba53f1b8998e67317eff5b024634a3226f9d901abbabab306fceb122b36dcf0f77a0d33b70ef4afe128ddb2e4faaaf1fed27c71524ef366bd0a0e96102e7b2f358daf401099da91704542b4410ab1e6577044fa7638474c8eb4300864c3dcc38670edda36158763d39cb957bff99f2b4d7bc5a60c4a0d8969f1425dd555e4881578638047e7abbde5a5971fe4c6a73c5e28c730f05e2bf1b48f057376e47dd5e72691899a0d5afb51e3a1d946470f879cd0b7cd6417529f0bf631935ec4ac402271252c83dd400a2a1b7c50a020f151115d8ae7153a7b70c31cd9e66eb4c7acd658b501ba22611d8fc8daf66fa5455988c4c56cf5a10eeac76cf15bd2d7f4dad908ee609d80cecf506b70573fba7965014db2f0ce927dba386a68ef7f798288dc322b8adaaae75e04b84c556ca859aa7f83f19ae2ce38796f3549a7ba47b2df0dc0c1f627a8911e279a3fd673c00dcee2734fcedfec1db9878e05def7e8cf257ec7d1df9eee17c30a8c4c6228aece85936b09f4cfb542d711060ad6f77cb7c5ccbd6c5b992050dd4766017a5efbbba3d4cdcfc22328dc108155985c1d8341e034dafda7b29c27391ed184021285d2e57a0f6bb356cef420babf8237d05deee18394933914a8f92ac64b58614126eee290c1d05780c17e3e676af2e89280436daaa4b5a54af9d63c518689cb8bb3eff37627a7e7fe61422c7630db5f2729372bd6ab3c833dbe3e12811010b751f5472510a7832c35c8cc8772d126c10ccde868c8be45f1527275fd6ba40ea49528f5b3c5ee42352d632ddd0968c54761163be37b659561457af50c2da4c599d962ea27db64b6f5f4e80179dcb9d2129949e19fe21fcb8257656b55608613538003f968097a104587865a57dac8fb8bdf4b49a39e61370e67fc674de5f85a863abd7665e8bd7576907cc7f77cf05cb3a6907953afb160a64e541e89a60bb6a97109a537f338cdca16b0e0b46003f01b9f59dcdb1d3c6ff8a5d3794553fcf506ecd83361df142c894d676a16e371e39596659c748cc7acb72568d36f723a74400fb4c099e71024f47f61c6ece018c0c6af895f47c463a33fb86d1dde1fc223427812f3f45b094ab49aa36544d62cf1c548e99ac97e969dc2fb40cc7dd255d381fa6188b8e2b6ba26fd5c2a977267acae3f7c324de568641f79d8b9432981e19bca0a94e43dab932e860c62df9c934b1e865770321e24e3ae9f0b5f3d98b2642764b1f5afd9321b7aae3d3b7388b022eeaccd533ac48d510be738835836e937b726bde544cc6f7e99b703f39ff5fd9f4eafad3129f69e05b4c4b81ce16376e2491e5dafc7bf1a9bcbe82e4fd45d8351ab9b4f15f540d6d3b4a60ea494a5d65cb2a88a1888114568f94d88e91585190e914694f1d325277beb1b4f9410387e162a8273403c80d606f485569596061749b45812ede20aff9088d644b23b247501719c02511649ef6496415fe6c439c9308fbf3591f0a83b5a9b9ada7aa5c5cf93698329dae89d3b261ec46a716c524e0313ef197b114e40b757495ae9e06df7c1581973d437e888bffdea1fb4d5fd4f0b7e81d4c64d013b1cf0d1f6a260aec3b72aecda64d27b5d89f88063dd8e8f2bfbc255b25f5dfabc193ca074c8c3ac4c626005ab96630967f7327a3e80bef86378b78d543224166fc823c95615f9dd6ef9f7e2de7f604436df1917fea27307b1b7ef33c660a702ff6f598a4a72e8b31794e0b7d094aef403f4c3dd6cbd76a4f98dbd42a021dd4e7d2d35b5b5124a164e97d0c7fd9f8c5d66bdf772b919a4a4d63d2aa387d8ff6278e067433b5686e248621e7e4ba9ff95e44b551df077a60da2e9aa39fb56ea7f3baa864b80a6b5aad58256b8fa434ef52b2ffde4965831876df4d121c4cd72c074e10105e12301a2be45cb95c02813077abb87e8a3b9417f03005e91127253b9f783077d1e29e3e90b8df54941804029f057a01fa272ce370eda555b4e0d98c38ca5d865648ad630b5c5c0bcf6449c761b3b6aad242e28d700f32717cd0402aade7f9685df70463b887784726fb9c9e9b7b8e5aa758bd81361e7a785ded0b7b5976cae6fa8c1806f9acdec40ec72189f2208fce029d2bdb10cce448110b25c70a4fd288338d25df02440227975017458a5a0c04038ef0e88b14eac130a17400c8888f891564ee068f5bf8f12b9fe76d7edddcfbf8983cdd74f670df256a89c3229a6aa653b6fe8cf795ee170b0b8bf930c1a780da198dc3ef5a3f1780aa134b9d483ae701d458e4603c8f5e542ffdfc25d60e5957013192a8c2be982316dd4a209f19aacacb763d5717880cbf7a2112843cb7901e84a54ed88fd88c10bc6f8650b0be953745b09031cdfaf38f4e0c597cd9426042a90f411a4347e8bc3f31ff6f2dcc5320def9939de70c23631c8fc3c81c7e8289be4769f61f394586faaf2e8297cbb969a3a58172935ac545f46b07236c5757135bc6a9ec510c1957ea91a7ba51d55d312de33495530852139eab5a68c714e638a2e5dd7488acbf56fb2dd8bd19cc09a1f87dfba85851d9ba2b5fba5384b49df57ce8686acd542e1f0fa3fbc07549b3d243b58387b7a34b17abc56924e3585fca15903d09c8bb2d9d2d0e4b0a478d6bb151dfec91e443b1432e94cb930c935c0808894ad60c3d82087dcb0009a64bb8a5520f1f6279de92be1672b9e005baee95fa8e60bf0f61a54cb606c0ee6c363b47b9dd9748409548e7ac0117ce1f4b49e218ecca9783c23425259657ead074f33691aaafd0a9a7f73679470b5398f7e81b7202090a3763f611b123b14903938b282624516b777389aea28e256f0dab2a2a1d9981eb7f7b85bfe0135c208cc4088f368394c34ac8f53f12811f15f70702d97587ba4c1be577decfc8cc4980f9cbb6f32f421bbeeb5a7484b8a5440bf83922b8e6d202a80e423bf1a62464316b0f5b243f17ad7a1305a3172b0259c9c19ca0c461ce579a6b0dcea37b1ee4cc82e15bbf857813b8e738696acd1996cc255b3ac21574e00610256ed1addee6e47faae3f050c17b6240ca07032f9e56dbd0df84b73c8121ef2d4b01c625cc00ab0f5cfc3f48287aff8b94708be1a52aaa69590fd2f4ef35e4bb3248aefeeb8c35badedc409d9d532854c3b988662283f0aca5eb7e57c635e1840715d7223506cf253a66d148cb7738607d6f86e2d0313388183ed027035c89a81a3cc1591548dd95cafdd35cc99590c58a92bb015bef491d62aef7c4b12f74c6a0789dc611adb3ddeb9093cec016eb5398cd04e35018cbbc00d64fb688dcff241d8d8c75540d93027fbc90e2ee8d9423bd60d239c17c34d773aa9d1e63fb38d45b6f984fafca2611441d27e7e7d5c712e24ed2c39b38bb336f1b7908b1456d553d357930987aac99be25e2408c860c3fd857f2883d6ca21b057c5579218d6a01e3250b79b665a93ef33b0ea946c7e3f101daae6d619bf7ea9d3575708122e41562bb3850e9c313ac7e47d2eb808af6733e39edbcfbb8e4c66048f7d36ced8225c39b138e4f392236248b56f3c631aa1fcf55c00790c758941b4d71181e5d242e2f57d475947f97fe62faed55476c6107f6391b1979cc069dc7e6fc8301f6731b598ccd89511ff792a160e505e12e69a2be0cc6b5a7ad960a95cd3b67943092f4eead321d3b7696c50d8d38d36b85182d26b286b62f04a7dbc098ec76ca363c7a279fad4af7e962231bcc1f66a5df7eedd22a31937bb9c1db1161fc116762ca4aec62493b003bc49800692cf2d74b25d3a732438c296123663ca1f4816201f2c87d5bae27db00c56882552b136200bd33c69fc26c06f1d39d64b4c4a62290d794fde38bceb9ebcbe90ba15012eb444eeeac0182aa8d823ec25944788f0ffddcb7d04289d14e2a45d060328b916552028185e73af14ae6398d5d843996176e6009371247d2908c547e218fa6ffa52473d64b1c4f5f182db329c636070d88d7141e23042880379ddd209844c1d24dd62dc343bbba0f9907994e6c53a51bb74becd359ea88a4c2d25668b0d308c05ecac14a101099ca10177fca9e3b32089a3525106b5e4d2b84be60ff8b16ce0c6ee90ef75e27849c6b3c3b14b053e2fa908db91a93da0337a1308f8f440229784feacf2110c6d924460c88408a7e6e9c1658fc299ef4885ab6c01b467ee146362b11e5ffd29587d7622b85910e0d263559f64a09a2efee4c61fa9630232d96603a71e450c17e0db77376647db20bfa2514e3cfead795d86365402bd85c617a7a57de98dbad5b1b5642897516588949bf1b23e7c05405e5612df803cbd5ddfa9969602189f7ee151bac0ae8f18ccf77bc6b064a51a58ef0bdfe659a4ef43ebf334330cf3f1c9036985455bc5e01c16da44d67657f48e3417cbab848eb7565e9b53fb590ff9e28f66670a0d4ca91f62af8441d671cc49b50fa3e54995273db3371d787868a11d665d5101c5ed39754bd847dc718a7ba1f52cf6f990829c4e1ffa470672df0321f7eb13f69976ae8d048424d14d80b1d5f891e2eabd8a94a02964c6f0a9849d7cdd139847855a851da54bdec61f21d492a876df123bfd966a317fb33455ef8379bccdd8ecf753994c26e5a07c0f39d7ce4a4370a41b2afa1a524617b9462701bf31d1f6aa4fca9e5767f9223c3687067ad00d5c1b71e5ebf6f447a41b152eff16e02c9089e2952a504e6905f20b43a371d81f1c01fdb9cbf4724b9c19ead2ff94da5425cd1ad2dfec93ee267b89c5bfacff7dd1cc1f3d4ac4328508f6df81141177a2d3a65c399691aa9d99f99e28ee1c6ca5b6c132a887f68b929aec942f29c09eb8f85d7be1ca67efdc2d89e504b2e7c19659267fae830348defab893a24471457e5df924dbf0c67af18383394bd56b0109d035641ebc9ae745e1b2a8ed799da49fe32e5be74778926d1b71bf620b58704e9dbfb06872b743abb3e3ccd573ef61f08ec211352fdafb2a1e9049e5c3e454e14e4c11bc11c1fef2cd7f200eed1a723e908dca907a1a22067439c28f0abaa35fb1c49e5d90931c89396aff302623152cafd461ae547dcd0328f2d371b9601a0c73d9ac4506a87c08ae0ca2ab6d441090c16c3bde8ada64aad8779216a84f9d82d320dbdffdc854c973a72fe02089bd295dd7249acbd65c7129459cf5f177469be2e3c46263cc84c42beda1575c1e173252a3d4fd8fda588f1c8b2f8e04ff1c040d7000e96b27a3cc77b0ac4113fc27ba7fa054a7b2e4f07e54dbe1c32fceeedff0bb0dfeac52b7f8918557e5bf9cb7e31c26e5d645ce41f665dc21b9f2194b2b6d0695f9a03797ea4b5a59b95f57fe89131897247f4a2603673e81c0558cc16f72f8d2a1068e01f1f1a3449fba1d69b477748fcafe7936606f4e4ed1a3d38daddaa121807a80fe2b3d9cc1d7b5c3ac85e0cd0298f42517a6e412bbf945cbfbc0fea4b0b3d0d71fb802be7fc00e86edb490cc63022ab8bf3bf74ef7e296ef04e3cf598e6d8ad3029042e2e31e530626100358802750cc41adf47fecfa56591d5576a6018680df907987ffb9351f53f8f39ce4d0b7706a6824ad8a3707bc56f13225b8df161ea9d070ac83106db14bc043159a4fcf2f4937aa2cc44ad7d5920de6572571f3cf18b00baceb04414ccbd3206cab4a0da9019cd6edcbd954fd2b9a7ddf8513ba7a765189b59a9da920bcad996a17027418157575c49c8b804ac11fbd3fcc06e9a279b35aa3fbb48e48f5404d1816967bd1469a715dfb9097b929980bc1b85190edb66074ad09b97e657d27b889b13d4512404b133d556c13e98b2499318ded129574ce0f8eb47de2fe8f2a6503a40aafacd517e8ab0ff1cfd8acf88df34b68b399f1e98dea6554d2804b4b843c44bdd6af608211ad0261b48524a06fe9550836cb153bf545676a907433aec22bff98d1843664ca2963a1e7a1e66db3f86a13a18923a54bf5f612c6942c61a6c3d61dda853f0789bcaea112726abea289afbe1cc0e063006550477b0219fb32e4c0f8df30ca2b44850b796620a9bcaac37fea6b2276ff95d4db11c3f5eb155337b35d6af6600271ea0ec269ef17726f4428adcfda96bfe8add5212cc8b39914421e47731ea6ef30248ab68c7f5dc88dd51bfd9e2f2dc78ffd087c7a7859dbcc03cbce89210c63e62a02c7845240923d005d6bc36046059d1c9ea2a3361ddfcf529dfe69cfbf8007faeb9a1cd40a4f423150917b4df311067ef5d2fcb0e45967b0e45b941069367152c5407dc2a64c807370f50147665f65b0dca9c84d9caa01982acd5c3c05408442d478c0229e0e6d54c908a9733d4a152680ff35af90c9df9cab35b1b973c60f18f4c77591c50dfd97baf07a7d53027c772c5cf2e4f8281773a6bd1701c8167dabfa0cd6ceb51f193ba1f048647beaedfd29c58a779f688d5b1521cfdd088721d36ce14a62a8870c93cfad2d63ddaa0b4f1e2046af2bf3fd0e349d4c6a9769cabae5d4cd146d2ed53b9af1c26bd8634f78f55f02076cbb9f2d59e64e56962602ad2a09907c62fd6339712a163afe2704ca8a96fdd5745dd8013aede7d05735c046340961e241898d0f20a1f253a76db5e16b2cd3f66964e5b9a0bce85e67e09a76e4efe23c37c2999c78b950a2d47bd2ff1d5f4383f30f26e8170b496da21af6e762a04ef5d91ae8e2379f5b6ec3e38b824dfad4aeeef9e1ac6787e5924a47b62fd7ea786f5dc7c020fec0ab1c67a1c1842bacb3447d474f214d7374b092b41f44d4dbab68fadb8758ad98d2f5899350dc39f61f1b301717cbf22cb175a684c6b8ee8ca5e426350eb22bc36e2ee53613c72f347a8e1f0a95d0134eebc3062bc3649cc7031874ff42e10647890378e8edf7a0e12c1759298345ac78ecbb842ee9458d5c391cdac88d7f66089cdc356682dceb27062c4d519da43a6920af1553521fbe6269c944b4ba21dfef3e71750c38bbb45521ee4b59f38d703c6bcfcacf608feaf37db66beaff357577f55045e74e83a2ff98d38adb7a68c2a2d9a427a56e3df74026e50368a4535e86561a3b92c2dacfd90086d13321957a8c1a6a9942c4ad611227083e5e37efc59de3cfa1b86c62cdb28b92a744a402a611690197984822ae522336a9d060616de2d868c304dd372a1f651362d9f1ceea844485300a420710d488285fde20ee606073979305dc9e1ae3388622b31e3941f38d9869c62f29991632268332362db5f5032202c93e91dc1587d2fe63ba318f661674ec56bfb2f4d5906a31912439819ca93d20919b259168cf15682a727666e9c17664e905fe1603e197383ca6f03d2cf011945df055e8914993ad1120f8a19a7dedd7d9fabc85320063f760a7667a7bec10d5f82754fc50beb0da88624008d45083edcaa8324ebb8c41f95ca27de96c37ba401607c52c2263ed5c49c6eb6bc7f3e946230f1bfcaf10139bac1797e0552a813a8a819dbe35616003a5130fb494c7439b3c12c1a3eeea3ceeb0a1c9493cf725629825b24890620a6e0b254fcefbeb8da31babf1973dbcb30444f18b69f812f669541a9b36b28f81ab41011d274b01489c45f231e29c8508080cf43b63d9b0db1a80bb8c72afdfa3bef05583aebce0c26fa51a94d9e76bd4a998165d3e8b93c046cd81c417d4729e7ea3c41e1a032b298472d10de054fa5572043cd067d38ff22744462938c107d70e2248a5cd87d80b9d9044ca0caa5da9932367a1ca3bf039cd2da890a451a379f1603b4e60fd08ba325afa274c2a2db835872850fc72cc5af16f05870a8aa28149bdec7a4647cc9b8863611e0e5d32a2f95ce5b68570118390c105a2143d5841e8b713dcf1f378b41f5225e27d956ef092f9c58ec77e7c871bd2c055f23ebe83b99444819fded630f5ec32a7b4a95b16a19fb216f70c0e13b48b5af493f745abee898aaef8a69e65f6a9da4ec3c619cee0d796ddab0c342fb1ee59e62158c171b2f232549fd98baf0c3cf48f06776db6de297bb18cd288aecf2d692792146189b4ac6abf33eb9420c7e50e3dc0157b514fc481f3aa337c6bf88b760fa1af9d2fbc0c7d7cd213ee0f87bc3b9c0ef0dd231ba60d82d87d7f7e56e916612d9ea93955501b7a2099d326df959948ede304e44879a4387ca793fb6f8522a8b87d842a4923de63019971ba09ead06ac75274d6081fc457783f48054825d4e0c66e7eb4fb88f2e2ca28ca37c182922c83e6fbafcc0a4330dc41459913564e4626a9fe7f41de2763a38cf15e3635b5a73ad1a8fed3d5e85759456113ac0ffbcfff3de7a97059ef9b9552d8ada95bccc2f7ffbd156486ac128c3c184b718f46285bdf07c692c6b7fc01e220c5826f797acfd7a3b85bd1bd188c5053dbff348d7917eca8d8f6118c20c0c3b12e14deb680c890ed21ebfb29ecd6d17af195466e5e52567b369a5baaf4666d852a4d58a95c147150ddc57661cfbff10da5b74470f02620a3ad39dc7b8b3b0dcfc02779a8434bf245f7b5595ad1dbeeaf6e62d864ee5cc7376ee51e55455f84a55a7aeb168dbf0428e81613ac9bbe6d2091abbf3bacb2cc8c28e336f783e646a06ab9d07957ebba3ce800a6019e74e45ce8c4ca4df68aabaa5f49670bff6bc761a80cfb72c26d3dddba30c3c362e7a13bc3db7eeb2c66835630547fc838be7047d1b6cb97501d482589b6b82a0643bac606fe03e90fef710eb6cebbff0c9acd19e4f71915b6da0579fda5112a82210f17a218bfdd7750dd2fe48c956e5e8a2113a06f5bf1d809b65560e9bb6d6311403ab5c4284fa996fe41447da0e38cb200c2170294215a17d39563e5fedf38af18269a91200edebd3604ee671baacf0db4da180b99cb9a68fddbb31fcc0fc3a22c62efbcb1843b1f44544a35f6dbc0125657dd2b9211582518c29c3abbe9f5afd1cc3c2f641ba2d3c5c9b5305948df7051a2f48cc5f608627451da950f570e698820581aa391596f01eb4bc13af12dfa5458e85e20a4ba9857bad60f719a3a510924f5633515ed29998afcca47b07f496f987aac0323fce3cfca840fa2f5daefae114ced3624a49929d3cfa5dba52f439c77656f6df145e915f0edf60a7ec936044f4e69bfc8d1b6b361a09ee8c88208befadf9681b62db46c729175f42a5775a288e1203da409c8dc71cc7f150e733b55b085b0f6b326ac7dddbf8574ad53b6c837a42f11a9be130060257e9af9da8332e81ba4045d2750cf6054e8e14233b0466eb8d1a9adfd9b5287f5ecede042cd0b3db2047894c073bb95affcb77a88378bceaeb68aecd476b3f842cc8425cdaebb12114d729eb17cdfd33b854a841a52ac3bc0a23994db302ade6d34a80b9e73659365a8d2c5b250c21b4cdb3bccfb7a1b2363273ed7f793f871bd686d5837c0d341c6f65350f060ed588714dd04d1fbc9e328b06a46267f0304e87b3e2b348e7cb03a1ee866e674fb50506ae2a8586b18f02fee0f55db76ab9086f07440563ff710bfc4adb6410530f567828abd81ebb036cb1de300717a8dcb18b046673b886c500041aa2d93dfe386a23bdf79f47c6c56700c4a78a3a7c8957aefe42fbf20acb71cea34a70c1531319bfda070045de7b50119b56aacb4823ce8b78de8fde2a815c53dac68c56fbb29cc97aa4b78ed2985feda49175f055e7790ce92b41e3e8dbd234442c757c3fa093192101b44bf83d6db79d980120130570c754ec295c147fb9a1502541aa5a0629a4a0f721b59af00f4f974bc3d37516cde1f01e916e2fb400bcc20507c9dbe087bbd8c992e9dac7c57e6faab8e915aadcb9bddd313c4a1f5c7afbf2741bd1b1857cf4d06d18e35ea9c328373e95d4d9728ce30d1ee80dec6d00721a3affa71234c60140fd5c01a7242627106da65867a8158476664e007917421162dec816c337b425991e3407a13a519828d26f03a23a479707a9dbf5b50735f2ed6b4f2c0520696eb2e36f945b5b2480301f1765904fc6a728988c9af52af4829a27a3cc3f4625f2ae4ed8e5b95fc13dcdcfd132639aba554461cfda8e20f500de7becb9a7910bbb1166c648ec79309dcd813721c95111a0a15161e495ae4ce60818e2ee02318171e59f9dd211d2f414d9634f833a716c6e73c84872781a7eca1d402ebf2ea547fba450549f61b88f6b537ae196d540117060e74762248e4e09aafb9906b91d2cd472d0dc73c69fe5d5a68a6723d98c87398d2adfebb02b2caaa73211b097597ff1dfe5088cfbb948bc6f85cb26dd0794c14bb6435592835592af0f865dfc591d62a3c813b36c1946d5a7632c5230827fa07b7ba54bb7f663a08f7c70bec6b62c3c7a4b05769b793386272ce97cdef2058c5bb5e4fd15bff2c2dbcf329208b5f62e4a102c26770e941a684d3d17d152ec38e522fafc330a551cf5b73063410783d0676b77baf8bcbcfea459aab0372663fdbd408b95f044921befff0674112be825dd4f9c7ef1245da64f176f24a235059c49219325726856a97259d071401605a99e0d208f82610f461fc9d1fbd0366374ed52f9574ed9772f47f122c7a55110d1e48f27883257559e2fe1cabeef8779bc13d4023c6c3a258ab6de627d4d8f579f0afceb241e411413b1ae9c8291f90576b08da8246d6a6988af4f02e4f5e9f9ceddedb9c74dccc53f28343c5ced6f3c9e583ff2c3e8a3c671cdb6c7fdd689337d527b49ec9184b79671e1b06b3cbcb9dae5cc69ad728903298eb418d39cdadb455ca0a03829371e26e876aff87344aed80bd2f5ef85daf7daed9a768ac6a9b802785da15d732cb3b6800f343e1031f129d1fad5f8425e3d36a129cc5d7b09f2114a6e3aacb124eb0639ca3b84dd78551399a3294355ff33cfb977948b48d5bb6093c1c760f937411204393d21fedefc5836e37c4061b746084c2321c1cd0c417a6d2050e493c324ccfcc94b5972fb84a1ed4ecd7b84a8ec6ff3f5ff8b0e08e1f57c33c4bef989bcaa840b8627720e6a80275c63576aeb379a6358986b20a7b128ac368e23dfc6d8b5c6494a58cb3630a7f82e979dba0c38b425cd76adfbfc7414a4dc4ab3cd390c8555e1e51efcde0c65ece0bd256ea6b428ef89ff34b0ec1b236dd34584738e6815feee118135442b5c4f6cda9222d2764bfb9e4420ac862d95ad056732d3f1252f1ff42df51cfead3b0a717e2a6b4a226a5be1fc05b33d988ad3138cd5daa02b021070476f572bfb0f87a1a13f69cafa3e2d4a98931ef82b2892b67ca715c515f99b223cf9b942d36163f19a5a92452214e9c2fcf6a1313b8becd7bebdce4d03cb8008da1416c803878b6ae14601c781e93c5faa7b70953ea2f3f632eb7c1e1d7880a3d46f8f84c5d288cc4b67290ef7590e3ec8ef80a9836cea6a601e23fc1b1e74d192bec735998bc837c694e870c9d254c25d5ae8067804f16b6c27a29e589395fcc9c61708e816425d5fd176e87872bdac5e92d8e8f39925633ef8005ad3238bc9a531574b6e39946b008742c4219623583b9e8078d7400f446fc7e12c33d717addcaa28313fa191f77f763c883f703252bd6a6dee8113811e924f7e949a15b477b2d7ec0dea75c8cfa6e7df4e52f869acecfa9e97c90e99bded43f88ca0cebda57732e73b4ab58344e63fb93f1096bb139770573069841a8db53bf9c709afde36b802ade8f675b8914c4a5b1d664bf67422904e558d0634beb618000429020371b8be5268e83eceb40390f5a5f89d39188a82e0f78dcb34d1d292b52b6a253ec21600f0854bf798207fd806621b5300bb6a813d95e80d5dd405845dbb5d45d48562d3d3a7df2dc6faf1705dd7c9328b81e311d653f775b4b710041c32b4512007ac372d98e25d7a9479af88f17a867f85a489e0b96afbfc1e78709b44580341d2a7ac165b90d86bdbc1007002e0269a1e3adb9fe05635e3df41431ea18200c0ec0c0d75ba567fdfb507b075f7522e242deaf7a5faa0b11756a568a4970a2c1d204473feb5fd997d780bb405e6098c6f144de14108d745e6c2f27feffdd759ff56822d2061c6db5fc2b7fa3139f52b29773d2fe22ea5e03e1288791b12759f8d7aa6da55f5695599165a39e2ed23402ee3f68dc906ad124a1f9fb8fe3cc2e4690ddd7cff6d0eaecbbb1d24d6df404b90a77dae2e0e11935ca2859bbb9f957d7d990887e8011125f0fff495797b5c5c802ff5adc6b538059e8ab289c156116610d4bb4ebb2681e28f4b3e17b1f232ec2314a61710c13a8c2b6c01674cde8a7413a96e66ffc4c9d3e57f09fe1a48b0fce010977747f76309279d03aa0644b87187c2c3091e6c18fdb46daad4b52bf0341d30e152725f37fe29aa288efe8c784ebdd9107d027cc3c43091e68e61da1ffea2bdf5635490d8739e87d9876a496f55f02095f536f0a9c94c9bfdfa5f5d7f4906f3cce2375f79abe53b5b45c610014cc7417ae07e151ff2243d80a9d98837cc3d2966f5256d89e42237566c16e9d4d0f540e386eb07c19512804d0531d288da31bd2f0849171c999405a01d2b85bd4fa9f461c943bbef997fb59984e447ac33ae6bf638158da579b0d434fdf6c32ce5bf862df9b0b59bcfcd799748afdbb9c51f929e957f392f32cccaa6cb07f28498d9dfc038e8e09ac471d5fe48e7a695a3111eb21dbd7b31eb006f8df36a6b7329621a58cbf77104d48f2ce42c4fd2efeb95d35259d42a4614c7e84a3063273f5c19ef03a4fcf4b3f63cfb4d7868cd376c2ada6eedadf85bfb7ebbc76af2b08f2ad8aad62adcebf4d2c71732c161acf4f235176e0fe717fd608f605866922a9e07929afa0ddf082814995a97d3706a05adc1e072bf059d90205d83c9521f1a7d494285502243429b3fb9f8fd49f31b608f8af5ee8b3b320e2c4665c49013a0d0bd833ddfeae32d0501a6268242ca482d6bdb1afbe169dc9887f9b237566dd352a946e73e9368b40fc4bc776cc196e71a8a13a232fb63b65745e6be33b7a8c6fbdfb630c6b7324b6348d893ee9b60245c0881fe69c10fbd1601c26702ab9b40641afde5abf6bf6d492a67dbe6b9cd8bf043965f8401f6e3a1a42bc483a5394714407471b5f5e3395d4cab6be2d984e082a79fd3c74aee19a17ebbeccb089fbb73cb70a5d293dddefabed48631c27f8cae03f5c26c9d009ba54cf21511703c83c5fb5f9f406ee80f83dfd2aa6208bdcff3407482c81d2d1e61fe49bb73866d3937d19b38f212a5e0babf531341bb91849f25bf8f07bacea51db8e8ce72547907752a0a056d0719982ba2874e328fd7182e60d496b2a369293febe2a11b6feb5e18c9d87b3736314fb279767869ef7b62c72e0a9a1f20ba10231cb6b8870c03a7b3e2223109ccdc24af5aaf5c237e2309d5417257ee3f2593e44dccb4325d234cc0493ee5a58de48041b35b14b6b071e5507de6d205b5179640f31633f13399dc7b0478c43e5a0a4b859e0c78be45d5782d40a6f918b7fa8aa82aaed47846c7cbabee42341264c8c50b3282e016c38d27118d103cdae012a6df9d6ecf75981c32a3b502b1e136708a79da528f176b58bf62f7a2562595b19f1fa44b7c5ffca72ba281f1a75feb98673dde1433d1230cad9e216d794751b1222f75e0e7cb6614f011f6eeb92feb1f14f38b62ef85432a7ac13d1929e65ebe4533aa33a6cb215edeca94d09d404ba06ae0aafc8824f9ce930bad38f208e741de2be135dcc096cec5b7389bbdf581f7f6b3ffbe0e8f734de00cd2564cef0bcfd3d81afccae871a293cedaad7f96046ae6189e15fd4ce424ba51d277cb247405f26444d86de1530f6f574a33b246f2297a65d038223008359a80b2477b04f9274ba84c91ba48694cd01eb50ab7d1e3e1cece5492d638c38ccfc00a926745e397164bc9d553e7fe6e9cde11fb2173d81621a375cdca6d59236e1635efce21fabc1147e4ae70a382da4e8c42bedfeb2ae7031f84055c54a9a9d214c14849a5a99ab514069fb90236469621889bcaa89d48b24c2bf1bd9100e7648f9937505b2bed19ab8c7a7b5a9aabda4b467de69b7e607023b98f07455e74e97269e5f6ff72377ac956f1bb88b58dc3c87822e0f2b191621c6037a5bb98cec380f0c55cef8f83fec06b3e58f711e676cd2be4b292e32695dad671d1a4d60f20e5e2e83dba79f9ba7ef2b98cebbdae606af0a721994e0bdaf8d84eaab7303d76dae8ab0ff2a5939d6d555f01c458d02668ed93134473fad0644042420171e6f3aef0bd36391f68d63d06314e103446ae8ac20ed26c1626ed263c2981eca722a09a941ac791aa0c9ee955554c8e9e6f01679d001a7c092d1bccb6399ef844a2ed321591178fe61091b1a5e44f0cbd9181b082a781460b64939f93263f4f49591b8bb80469453720caab5de7ad2fbd547d812bf0449a6b9afe99ee464f20edbf4d703bf6db89b74ff7cee436f61e7e0cbd64d71af86aed7d7864d73258be9462bc184078b4d5f7fdc8447cc0119d380fca9431417b57256ef4a11bcbb79959be8972dbf7bd37bf8364a8a922a75e6ec0f250e7f3a976c31c207da3d6c8a49b4b250d2cfe93adab38ac4b7e91d7391f8f07b5dd300fa8e1cd1237c0f3cb503ef64aa3b47131768591b8cacda0c2b21a13967f4b3aabc7cd4082a91983baac5f618a97bdbe0f6db85712cb97f2ed5789e5850fbcd13a74f5c93ebbe34ec059f9655b78f15d3714a9b273542b0756ada1a6a839a771a703be1c49cfbb636eb410d309e790d20fb766ec1f95f499073ff0140d353ca384684b05a1fffeb91cfb6f2b341ee308de6a704d6659675bb6e9a8374ccc3e35ebaea68f84c743156bc1980e15899188dd5a8930f347d8d3d8f8b8b78158ead4bc2ab0d054a9fdaa8121c4bf338c7c1202d66f8f404e8850bbefd8c50ac74c9a62f4ddb263f9f11d2a88ec2c36998ce3ee9b2679e3b35cc4ab3b0f5ae60ef1967ffd6f8615213555188a58277e9f92b082564ec44d131c85b3097546bfc157e2ef43101931fd2ab5275cceadd64faaa1af755c22cb3caa39a32bbb52c2914f03660126bc1c0a512da1acd459908688bed86b9a37db5f497156289b7db8917f662f779809c4cc68629fd6548764ab1868cfaf322333c17b89e1fec54ae4895b57ec0bfaef31ca82af964d9c1140f3126cf264bd8f822fd6bcb743dbcc144d733bd6ad9c061a132191d78733ade591fb8b4e9cca6b6fd28a7a89f227ddfc2e9ade97bb0001cf494a42f771767c55d66e744ce3f07a1037bdd4b972a918457569331cc3047c876ef2d4ec0bbdb1e7eca6ec78b49f72785fae2167bbee7fae3f328109f56a51d00f97153cbfd579f41b2b0d621e20a5420ad24a86a8ff73da8ba0a35f3cb466f31888cec8114bcfba144ee1c2a2e1f34c3537f8b4f8f4a3601078f3fdb011c4e0fc3aedfaa734c75c4ce313756264ffac6de8521ea7a76bfbe2549829912009617afd5d535d89dcd4d04aaebb44e455a71c094cbf2ff6132155f1712cae57898ae9ec9f324e9504ab17dd90a069060ef0d6dbb65a1dfc2e03e40306da2f147040a815c8b1f8a9d38d9b996a97dcdc2858dbc401d4ff8cb3220b9a238913f8619f233b1c6a8be866c84161f5551e771a16e660b347ad19a4d6a83493c96390f0f4e0a03a4289af1489662c46b9f12cc5086a6b57a961a641c265bcc48163fde3e70b7fd92ac86526db9f5a0f09c7bb64278354f759aa547856676ddd6bdfd3d7af6a885197159bbd198e59d229f8184beaf2e7e9c92a3a4cecdf1b7c88ef6b198f4795a91cbcf255e2c05e09e462ab1bfc4f64fd047b856620834eb69d43d0408debe412a6eb2a5bfbc57ebd719e375f1bdcdc30ccb0adaf4415d88ed88f17244bcae3c850425161662bb46c994f2e0f2ec18af7c0dd2ae5f826bba3e951ee3f221ca9f789d726a2b3331df4c3a43f4cc741c30a6f1fc7273dcf82ad3e7b85c93a726b62772cf9632e498d8c4fb54a2fe80379fde16f2bf7a87b867d86c9917cb6c8ff807a21391e7ea5a310c2ca9a11da9e9df00a118b85db1abae31025f34c37a0eb42e9a61ebf5e7889b807972731877154da55cbabdc1c316df3c372fdc557db1e6417f9b6fceca04474f077260779c33fa4926d15a8c3018b2f2ad95977376e1f2bd6375b849a5b9ba05e9cf3dc495064d0c55185b811ccb79cd01ce22adf516d66c9c2ab339af045924a669305280299f332223c4c017fae611194e02fc3590ce763dd890034d5813878d279c6e188a5340e4657991edefbad5792534dde0f4feb12c75dc2626ccac66bec0b8714caaaf4f89f09bd8254ae33c55700378af91680e8ed52d92a57c692847df940bc58b3e05ccac827f68c32b44cdf279199800a0ead55031d74f766b7f660077c2cf93a8fa62e65660650ba8fba7ea6b5e803002cf3ae92f1ebedb6b5835e52d9f8a95cbc9caac82c1c4476fad171c0da9cab968b8b8108dd10596df2afde1545587423d0582576d95e7c49926745d8679dde2a86872461839c77458e3bafa980186c494059e90f398f949ff94ffe90e382e853ec201761e7d65635486d829c0dd24dd63965f0ec91bd9d614b581d716ba4b71b774ba32b8948bc184f42728eea5ba15b612be496d8953157781917d57b9615956809897fcae1fb57e772d0c141de97902be2496a201e4b7eeb969e533158a8d02cd4b0ddaa3c8b32701f4f98917367560a381f8d0e32ea9afe0d4162b41f351da8b3c3389662238f3380bf43ac93f6ec9003224e4d72114b9629f52d2734ec2fc9b727ab27d99d6e905afe8fb461f714d1e099aca3eef0777d5cc64e85fdd0d8c9c56cbe13e45a6cab387a2259835b5ac698590144e82fd1fd97729ff16f7c993fa06153673fa8f7d564bdc6c092be4f822eed92178f5f0c213b980a772bdb01331bf5ff91a55fff1b6a23abccf76809d4a132657ee4d1b58f4d3bca61fbbb50ed3a93568096b98ca88566664f1174066d96c8f8266317ab73274f6273e99198fc95d5f90a11756e0b153025cf30239c76313da2a7ee78aa868e4cf100141e0d34daefa9a4f690835ec11322151cf8106225f57cc5ff72a6a41b5de8adba15b1a7e5b5b61ab898caec2c2db567456270eee675cb91fa824027785d1b81d2366350b9cc8d4aecb528a2de8a5af1552f3d1aef6d2db6c9f459577f5f7095a6da41c649cdef0adce85b54ecf0c0e912caa9af52b10651c004506773b01d6cfd9c83f8181d533f4c5e59ba0d06811a40ac66c790984b205273d8849b031630d1b159ddec58d4dd4eafe68786950591b7b640dc98a6cf83474408a0ff59d05f0dfcfbe1f4573e5831cdfc4cb932a09693eabd5a1bd3b150189851decafa4358d6aa7abd5baf9e7c1d0d7c6b2cc60da7ca5d074077fb58b6f3a0f6a5581619b0732543e8e183faa4c2f70454714dc8c540977306a0237c17e16e29242c11809f220232893b4dd761e377630b5992fba32596a22783445e553d41b8ec06b75ad51bcb2777516e3fc3e3e8487dfa71a441ca73a34a75ba6af5279c535b6494fef0f2553366cc983ace4d245bf414a7e659b954a36d925b38566f98e0cc9f1d9db2fee6479de39d368725c1cdd058fa95b3a2fd08e4160a814a283fcbf6e09cf7ce17d2b2f8c903959e33ec1f6a54e687869cfa2241cc5a074ce7ad99a1743680c600fac2525d8c08cbc2acf7fb9092345b3ca3cb015a7e36605b42a64ef5164bd7da8c8c192dcf6e6ef03503a37b020b69a53a49b9afde4a126664de09b230c10a8f22d64ece8c89ebccbe786985aca73f1b536d7590e57cfb3eaf5e707a730ca8ddf9cbbdb2715024081aa476f377159de955c18f2e359e199754a865a7d80bcecc405ea8f388130b33f1a4d91948248abd64a38b4d2ccea824db40b85dda93b772d79ff086abd4991951fd4293bf1e1c24ed059547838157468daaf66976a185bd1abd0ae0cbb9db20fd67eef637b868400c8b42151fe47e7fb73e4b0406c534578f282f28f5eee21df59975f1a9202cb02cdb8ba53e6942bb3e28ecd25729fa8f28ea7a53d624559979bb854d0d4761843eaf49dc0bb8a934e03d1581b6e094ba870858dffda9f848fb932716721159ff989b927885dfbb79c8ff8dbd138af66d07ab951f099c342dca2d5d1a0a25daed003db473086e337ee1ef0e6746d4c1324242373be9977e35e8fba04cbdbc8f72d6a0774f00cb2682dd81daec9453615877c07a2066d6dbf0e1026f4c06912114f0d56ca710cb3e3dece093a3dc42e7a26873f5d13300288565e0e2e3b493600d2de82eb29cc43b53ac53c8554f94a3702df3636daf328dc12cce59322d5b0dbaff926e5959094248ef666edb78859bf12a51c08dee5120afcdc20d3538fa3fe3bdae3c04f923431fbe0385119f434ad16762ffcc06d1a21a6215c48317f894e06e58b6a202626908bd0832d3ee29a3e7fb5982014aa8aaa26e8729a94d6ff6ce99e2a6d9c6f8cd499a39190f409a7eb9977b508c5a4aa706a0d81880d79f89ed6be9e3e32bfe828c1261325e35619a4fa595a7b8911cf0f87559f3cb17af16068533a30c87d84a128f61b07db41f4d47bf73b80bb7138e379d95d8ffb9fdb95a39fedae1cac35f240ca627c8ac6ab6643c10e860d273b46e2e8dd683b525de76d4868f3602fc43fc8533a61772234e8d4c73468e9b3fe4b2642169084bdbcc46bffcc17502d237953aa54b55aa93f9273b1dee09ed162995a0e6ae22dbe772a621f1c58750cb7f36aa4e4006910876db9480d35b0cab071b2c46f133d58af888f6819110ceeedc5a1e2117933122680d56bfd1038367318ebd5f4a3918b0082e1d07c0fc01ff5aadc61b406632fe99dcacb57e57b23e7a9af6756c4dc8c0a70d5a09a36a1b986cf6e42fc0e20b60229223ed63c53706f8f4693d8097b4aaa5df213547c14b5a423b3ded87b47bc7263dac28f0ac5d797744cc02644dbe7a2a3b566f9efa7f143f25d27994fc824aa4ba91757b864b3b1d9c4003728ab2f699b822344bb1e7abd1e34f47a6b7bb21df409be1ac66a2972160119ed52dbebaeb852b5337d7d88d7fbde79b5e6c6d9034c2a0544313a332602d30a429ba695ddfe7f77c7c4e0a807f79d04ef5fe9e8b008a7fa11a483c412e16077f86292982b2bf1c9b57a27cbae32057e2cfc5827e6b1a73b879cd0fb7d142239b00ffd5f4e5796387095aaf90ad49733381a2049f3d1d9db0a6c101b8594ce3c12d59152aba57d920c9817870e08dbcedd6cbac0630c575df9bc1c05f80ac778b8ff16b8b7e7d6a682a8158d1d478e9cfa9dfd1bf343419a86256201f7a7eb93ef4e17187f4312336ef65aba534b2ad2b045d86b22cbee98ea08d8b3e8f735feab48545c7e566be75fa79526715cec5f37b4e417f7ea7ab989a9ec302bac540c648d30703e3e581df9fd8302170b8fbe9b6eeb2003b17b67c524d1ad05cf04ed4226228053a83ab719adff6c8c3b5c8926f4534744969e13467b17d10070d523e6f4cf58b78ec9addda1b2d739aab1c48b7baee173f2b543df8c95f6fa34f216a1ead6ae66b2ea36aaeb716b5f28a25f8eb93f2ffe8676d8af64770196658da7cf1876ca4152da9f7a7f5983056eeb68e73286e796b25a1757d8ad1e931d2c932085ec02c0b54e2a392243591bcfe5be18834d595e77ea33ba189f3ab6cc33d9a15b73166446329076749fbc30c701f00b550dfad9b4e91f8447864ca8e2a8d6d2cecb4b6550f61cebad6d3ae103303d231174020ae4a38fdfb5e669bf8c5d7993cb0c364c19f598b6491dcf519d40b544c9ee30d936d88ed33f28513613183d3da7570478c66729ca65d727a69fb66f258c7cb474ca11a2d5ca7382a46fb6c906eb2c6c37af565671b15e5cac6bea8ff131cf37b8117e7df1d3a7db537963ae5ee83e1a3fb272298a087e76263334e4bd14ad7f23c698346c131914a85960d8a341f4ca8421416f0f0e2031cc79a33796997d050827014ae7a304236f79d7c5d5df4f8758b2a1848b57d4d4a02e136d69a564242976835068ef7247a650ffbb4cc66790a73f10800d684323d820811c6acc133db176d506e1d6ee5a1573d8892f16483ec9ab0b3f602002365d418db51b7d041d50237f4e16bdaf674dcebff0339ea868c071207560d21bc9b9c1160b848abd0319e7c4498271e31376d15ec7267ee1199d67c63b2dcb116b8b99d1537c7694bc2ff2f300387bdcf64fc690a9aa226e2ec344240109c6c162ace333799f0a3d26f1a14af744fc2d34096b1865a38cf3efddb8d544c7ee6f6323aa4b8e24f425c7c4d8479cc5e16a091f94899fadb906c9f17278ac324a60809a8f5cbe67859fa0c928f2099db5f35fd993856fe90ff74cfbfb7102b5fd18aceac44bad9d9764264b0fbe0660cbcd6b0ce72cbbae3bcdbe8ad9ab68e953c46e7556fecbf089e8e88913cf0765f3688bfaa0cd53c38f94770820026da3d3ed82787e218f13059df2aa40e22d7e5e32ea34793ce8476a992fda337bf16aad71628ac99783e515f7e50e285115f81e276d367eb15d2282f114330e3b66859bc18277d1404cdf1b54b4eacb84a1c532668512719a163c21ebbe852377dfb6dfa154e58a5993b14538206aec38bded5fba5d2950538343b8f6fe1a7a1eebcecb4f1fb4bec654b0a700863fdcb9288ec2826fb6d0aaa721b21e04ba4ed1d9b3803ab7fb70a64b199693a8fe0bdccba78f70436b0ea006ae423647f9dde128a492b2096e6dc6c804b436ed5c39e3d4abc9d69d3d31af75296c39a31d6b025cfbd35118dac3297d11de10b490dcfe6afb382f9328483bd2ab1dc1e755f3d6a7021111706b7bae0880da1abd2f77bce7ee3f18cf05228e34484a201d171b5ed38a7fa3afe8e33ff1af20e1a77780a580061030cb93baa82b4f281e876543e0e19c2d8b5b4640e0b7b73d86befc61483d2987dc388970e2a6d3379a9e3d7ab59057a4629af3224a880f1c85953f743ffe04876384f3de7320b2098aebf6dda403c1ab71145a7621123b9ba3424fdf6d3a360ee8282f966a22af0846adee68e18f7fbfbd9235d942e04f93ced20250337ab356c28b95305c1b207469c4bf50f0774e3f6e989a2258035d419121c9f880dac05665e9a5365ddf29d74215cf3599f7bf80c55c3b1e3f9b1b95063ed07895b0927b5b4ba0f067c85b3670e3aaf86017254b1db8f1cf4cf51b0b3faf4b046dbd3278e8c055aa62bad4dbc9a7afc9b0c8ebf180c8aabb96ed3373121044bf5b2e6235830f9f15f8394e05303b68193297f712cfa8e64d7ef0997560aa993231307db60b159934ec512949ca342e9f4b15ff20ced1d25b40aadf5f009b7187a0d6bd5d71eef9e574b4c68ba95850034df5f60cdaeea2f4c0caa32a2d1326b369121a72c29a0f4f98ad76164e614b1d92f5e04d429ba5be51c2039bbef77e8ff35c2823244810e268ba32c49ce0f039f6e910f734b9e202ec64b0a47966685fa1ef40d6c555daca6f043655bdb68fb19f994539e4a6bf153ae3637d6dd66e5069b7a9a7618c7a07bb37a382288571f6dc929595ddf49172434a5c5351dc2f780417c259b5bb0146e7906fe27b23337d3eefae93e99390e9e3ae6630be2cb2a8442ad3734a0213a03886574de01e467c38591217aa1cb1f8ff8de4515a26e49838378a4a24eb071a036168adf9dbf8249cb8611798032157549921857d8f6f9088a658d4b56265edf54caa78189e6c5bef5faac41e6eaae962a2b9c55c8692122eadcb420d9418a42578dbceb5f4a01839afdbf952f40481cf9c8fd21a5fb991a21fa65a63b4ab528a65529f51a9e7f0e4e0dd5c9ca19a7d5f651be5db54f36bcc91a2c003d5d77742b27361a8db52f172b5af161e6f105f620d91085ccfe5c40781b24ae7b4d919321ae93dcc4436c525346a9bbd9e1aec36128aebfe1476dc0b6e726e43638a53d0612950b464b7330d6eb63a628c8fb7186f030cf5a9a36d705e75a5f323a4bf41c89728d074b3ecb23037c6648b6988e407effd5c3e2b545cf885ac6ca78c828f1b71e4829d830acc91f760d941494f85bdb0a0ac1fe11209692ca83bfaec7b88fd134c1ff11977d917101caf395d36119bc210c45a4fe0d0f664aa3df29123d013a91573c2436273fdd84b857ca40bc6bf09bed090765c7ba21f019b07d062fbbabb0ca12445ed75aa6e5d5c357029bf2c23cdfedc24af5d798f58d3d895e8a6e607d3c78bad6938e63524108b846684e8e7c9dc80d749c23d2531c04270246612167d166da29e47fddc0e6670429162f2ec605b9f085cc552adaa088d5354711d06cc4a517ce614a6e5c75b2e747a816b23b226ac29588bfbedeb9ede24d3fce575886d0ea5537825fd2398cefce5aa54ef3fb98437c562322746d843f9afd1c28c07c3eda75da5e896cc5f76f0277fc9e0b6d910cce46b777a624a79d278a9c9aa4b8e337c87f985e1cea322ff267b3f25382ba3cbc95d7fa01a53c0fdaa874f7d2f753e3a3fa4e902f09aa642201cfaaf0d0625449950d22266ae53adb11062919760ee0ddc9c7656f0d89a7ae7d5639532bb17169d4c17613e31ab5957f9cdafa46468d39f3b22452b3002a8f4853b5a5677e0403b9e0414feedb5049e977d0c02553362da1e90eca77c44240aa278a58bf9d243eee140210d96743f892b49c07d2fc543e964b34c3bc92aa6751cf55b12eacc52244f57cd7a57cd66a1ab1280a1cad2275bda097b0474efa83fae45a7b14745a1d45c14605e75ee136249ed124d50a21752b2dee3b6834bc6440560932d4272cbe22bb32cf30a0b72970ddec900996f176cad70c487331fa4cf677659f6b92422f6527bd3389bc98e2b29b63e127317aaa2ec04a145d6c1ff2b747b4721fc0298278bb1f7c305a28422ebcef2d09f8b4475e095bebf2ffb981eb7b75a79f43dbf3c3cf8cfd8df0345027b7d399391ce83800ca7d5cb7c7276a37f9cb1887bcd3397536b8610001b422863f63c11e63a0d1cf9184c3f16fdc77bdd60d17c0f3e29d4260ea7d42c9eea815467feb6c6403b6304dbe1d029ba83bdaa2945ae893b4babdd60589f1f843c411c3653f36f41d640934a3e9f078fdb5f729fde73c2b7c34704a755d8346b06bb593bc36cfb1197a35fd4d86fe2d70ac4a24d31798118fcd9844374cacf997f5758e68fff20cfc662d9beabc6c648c26eafc76de9a254719ce757bbbc6736c96ba37e6fde80aa4e29bc20fc16cc09d4296170679e639629ebd8591588239180717a6e88684fb706e4ed70dd6dc386b1b84810c46ed5b72d55e69bc1b79e5c24efa6762328b0ce17466caabb039f7f01c0dd35a304a9573c96898736658fb158cb059db19d949619c0c4f4d24eeef45edc190df0b451508edd656e7b744ed4189668ca6bcbccfcb91695cf26bdb44fc90bfd223a74d0272fbaebb0beb9d9400bc9f54c35c4f809806ae699d66483fd4974f2fdb6f185fe84e09b7082a7098216baba88de7cbbb7794f0189442105897c9e607e088203722a5316da3830f2d5fb2413ad97d73752035152ce9960d5ddfa0d8d728a0d7f37554937b54acb3c80cbb302269ae1797b6963b44cddbcd934b77efe032da20d1b5059b5314bc6eb4bb032aaf4e94e071833792363accc49c300d878eb1b841e696bbbc01596ac28396437a9b87a59e0328ec716ed6147c86c1eb9dfd98ab829ef949403cf7e1400ab63b2a41e73f94a21bd31314d8d48c101607bcb954d8aa19f4cb165ea6493f72744236959e438b76d8e7ac3afdb5a963d04245ddebb07eda6873f8e3aa3605f7051b5981d9c5fbc2618f42204c9364b74baf34d2a029b6711ad8f5f2b5c762829b452dd3585c0bf4abc7f35b92995c65ac1146dc3f4bb76d8dbfe3fa4e34522cb3f7f6555e506f1f28730eec35504834b8dca76020ca66f52c340924daf7a6a7295bf261cf48215668436f2b8f52a1727bee5965437df4b6df2a5908dfa245a4869bf5ae0ef9cf9b1cdc75434cfffa344d08bd07364b321f72dc4cd51169e09e6bdaa37c20dd047a45ce940bf1c8853b5b47b814b38d0aff37ddc8d6858e87308becf9ddb5849e4a57ef63b7fc7a74a5205db641604df3d68346e8faec5047027f4d4c43b248cebe8bbe6fe5828766cf9b35dfd6798154a84924761c1bc90b6d3160045597a74b7c3e3606312dde2c093859c3c79436cfc6831b283a550e743f3ed692f7848e36ee7b048200bffd90e2d56b38b29f885946f7c7f7795e6b7fcb0ba6d38ca5728b97c062b99ee1319a73cbe236faf98e484968ae4ad7131497189672dc04c31cbc1c62b31654755e25afb78ef19eceff69dda317c3c5b4d838404af90f2bf2add76614d0318fcdcd8a48f5349f2acc454304177298a86023af6709e804b1eda6ea609055e500d3f27899beb920406b7a96408806086752988c1ee6436e3650847aded9aa437a3716c3e1c0a9f58c8e494c14c88d45fffe1d44ac81abe73bf8da54e17ebe50f7bb06085c8023a9a1dff1922ba1643046747d6f763b92467ab7b484c281ea1f94f1c25ee6ac97463dc1507130497f8eeac613b87a82d170b4e9042dec695d9c5d9d882b70c189a03b7af82910d733c31de899324ed79b042bf4f05e89fb9d4a84d69362e59d7925471a720ef369b597954ed1e854edc51d98f6f685feccdb659d6cbace579d41b2d2f8e33f483b54f9a6705e7bc7da75d75b2870e08375c077f6d9a8e3bc031f10a6807684278eacc507bff762c13e11c9e8ef42f0286714c8b14c71f638df0093f0e48d13b0a26dcb896d63e417cf459dbb39c1756a04a5499693980fb0aa9bda72f645b5dc1d97fa6fb8210ecc100d4f9cff60bd598f005ff56f3ab1efb44da5dadb3792991cb317947688e0a793e1315b92f779fe993aedb58c76a83f92f5ded176a85eba1b83ff4a25c48a8bb5ee35740489f3e3a80c001d1a673ef5d59db227bf33274805a3b8ab4a759e06a81834860f25d0b36af507848007f1da10f8d517e648f9f684b297f39d9b0c1619717efdf7588e9f8493d909ee6b17a491f0f5287181dbf00c5fd0b7efca6eb13ac462ac3828f1cdd2d7a0196d17869d4803511e67c03fa9c7e217b97fc4f5ed2bf292946b8f190f6c08257b89f00defb4dcba3f7e0a5ea53938659ce232369a5283474d2c88f5089f20c0300588eb5c450682de446f7424076879282e00c00f9600c8096f9dc4c261f6e9cfc3ed58e726275445f566a0fb47975d64f6ace3e92f58714c7b99a56fb09235cadfe5c686dbad4db4c74871faff1da6c006018bcca44f64db329596e841c3699171f0fab4ae0ef75f2df1b76fa3e43348ef0fc7db8bb3b9130911dbf24159ad80ba6dcf051cdb2c19fb19282aa6689c6b698b56de684bcf769ef213cb34ee50e6c4adc4a8ed3703551030290a73e8046fd9a95bccee269cbf2d0af389c1e3f0f82e06ecc912c61f07885fceea8848d553e777503543cd14893a0387aa630b05f9f36f16adc1ade2d8b9cb13f341e66cc37fbad5d3a056f959f9294b97dd89d5437fcfafc7d2c00b89b82f882a3fa999e3976bf160b132a3234fdd660f80420d9867e3ca4e259ea37d59bf5c629861919f347d7fd4e526458d532a9e295b1e926e385e2c5276dbfe4b9b02600e4b3176ac66dc73b9c69cc003e45b03534e0cc80b7f2473a3e95601dc50032998f3e4611561687477bda06aed416c5ed8efb8242e88217438aab8c645e8b9f808867e1cbbb61a6778eb3596b8cca031bd808154a03309eb65f1c369c045f4c1363fa503a810e3f7c083d3eefa5ecd0547dc77168b1e3365afc26cf176545d62d5ab7a8aa5b26924a42f95d9d7df38622c0b1e8bb5ff4303a170fa8b786025a2aaadf8592a8018880870aa20179861486f8b4ec8e1dfd5677bf293f26f8990af128acf398558b79189ba2c3c720b3b67636334a79d33b34fbce443826be4a29a1504555f89829182a8ae3d7a7e0dfd67795757643f8a2040dfd1b7049dc82874f6aa4a0395744c68ff09bdd408b64c2de9c1602b99f3d2446fc837e720792f2b76bf83b5e19ea7fe49bbfddfb98dad68471748835b5f075fb1915092e05c54d073c287e829fbcdca7f2946af60462601e93ba52a31eab65cee7eafcd10f55bba86e6d6c5647c46e5af48d04d1b5b3034815b1a04eb38f0783539a0929d487c692d97b733f3ab2313e875a9a5bd6a1feb7f6b581b46a54ae29692608f325722a0960d150fa9f29443b76cc880d41d595ce088db54f2a6f411e45da8b2719dbcd4b7b31e074e5f7ecffad74ae908587503e58eb97d70c887978d5448053be6075fdb065404366bc416eaa4c0447e57c732b534735b0b0b30d1895feaf147754f905ef28985722cab9b69eba8c9c15c7f78315892ce9ccd743fb01a101d238ed5e031cfe8abcf6122c73fc45618628f0c2d6e790070cb3d150f71a2c8eb68e8df4ebb3e82931d4aafb1794a92935cd93f3a33b691736f0022d6f0393a1a4c212f93f8dee1378d774801e04dbc30431456e78dbd3bc317b8aebb39190ecc7da389b346ad65e1ec2fc3a1cce062e5acbee0a1b630c14de6c91939c3a4ea67df7d79752f3ab95212474cfbc4c6c7952ab4962e58c90aadb8bbfe1b4e4cd52931be0cd21c35dafa77faf21c552700c53e8af3eb1f3edd6c8435615a4b10ab734dd7c68d1e1468c2286b2023cdb7e36498e89daf7e90017bf1fffebabb0f933bb6acbea1049b621f836391003522fb6c8a787decbf391948f818e2656f0c092de26b95123fe7c846ec9615f4627a935bace8ac2decde8d893f677eeeb02cb258d194ba364bcf8e1f625d739678c88a16096197137ac7c903df0c977405622763b7ca5df8ca785e29a7c92c2192bb91c3903c804a33ffea65f50650873ed3f4aee16145c1458142599d705804d79297e54cf5bcab9c71ebfc6236842a1185353fbc0686596467d198b9a22dda24d274cec1b670a2da4649c4e274df41f7cff764684bdb0d67bb4cec2c77034b34929baf623c27748074846952b6171f588ad9bd931e323ae65e7e83e255a5327678dd7f9ea88af5b1a0ab8e7c249c347465ffd7f45595f22d2ebf0e7000568cca863373d859f747b43c62e8f5ca11d7c5566444a66ba77824ecfd1734b57ca9b692f2f56ebc39b0cf28cb7cea26cfd86c1e216e75eb28ee9e4d8452705afe191411e903b1bf5fc83942bb6a08a0862d1250caeeca996488f6bd3794df7ab8dd0022b566befafd5d14fe47dd14c60b37501d1e507415210ae338ecf6efd3776656e58c0924c63660229048660a7b07c21aaa7de9ecf11236304883d61e1d32301e4786850840aeb682a605e7345fbf92c0e9dc6c9000b05ae3e7be1946162fd892f4d58cf518127cf1de3be4dbee5476fcad79624fffc9ea5f567470bb0f3a6be26b4c147807925cd9023309a5a824a090bffad956993c42ea322ce25e608e88b7f5c0c5ae7890835ba37ee39b58f19511af06b09917f6dd179e5be016bd5fae932438a667cabc7c8aa6d5d8a3d44b76c38cca3caa21d117066be9598c5f6c015e043e099e6bd065c9b9f98fdcfd53e47d782fb4c3203e3ca7df2b1b643646b74c52818df4b9cd97821076177c4ec8e003e2465e71c58d8a71b1c713436cf2c946c1f1e0a700608206e08b0158d91aa382878f655205d57fa6e290c87bd7bb5e01947a57e9749f01c89a752d6d54e05aa35a33bf967bd7ccc1ca088e305d9e7408ddbdfdc676552ac351c3a72f59e52429cd6a58eb13a2d7d6ced613a10be50899b01205745483052dd5fac75897e681e7f8004c0b6beeddab5b0ab85165f18fd18fc6b2e7460a411ba19479581bbb133b8ae15327eac60dd60d443a93deeef4ee7158cb78ef9d9e16d13af050aa35c4bd49ae4ca856dac50623787f0360c20d6dab493333f60e911af597a3b05736f4fc916ac0973d5242b8cc648e0cb69ca1334a51c30f704d0fd05913de07688dd1abfa5ec9d3a733932d79b966a8eb28a650dc59c926fdb70876fc802397e2df85a35faeb5a72d492944cea488c03541e5f0e63154179fec6722210020babfdffa0750a802c4f5d252b7d924343589a77bcaf8a351a5c3fc1867ffca56906790b8bf586f6129aca8004c73ef59f29059b12d1437c433aed993455ffd974d1d390502e6c412bcfffe79f69337e469589e8a71ab1dad66cb41a45cddd8eb37d398a47977d756fc83e45c6fb347447eb57f38a04e54722293bab13136ffbca341e66342e2197c7c4ca07ab5f5cd2c4b5edf556e55ac39842bdf92266a03cac1e091c17bdc51c1e8b48cca05a52c7f2e56bd38a5e54bcfceed1771807a52f57d5e5f82307a5ec3615e9ca245ec3107f48a994a52ace8aba697a01c0fd847d1a43179f58a8d31965cf04037f66e576c1871e1b457de2780fa877b781176d809000827eda3858ed361d79420155cf6e649e94f2becd68704b886a819964a367ed3e222b1b00ecde798588899ce1b27eaadde6d9f1d5c464821a7798e1a94404d32ef8b5416f599161ad7bd8f61e55a37d7d2a37ea62864034ecf7ec12f0c1aa72f6353291669405bf08c45af04caf60a1308f852ee1c0ac6702e1ca732eac978f67246cb7eafd17ef6bbc1d44f0cd668d15e60b8f0077b759f5a1168e8e2a73806b064a4bc5b908b37a968d22992b6653370e43d679f3346a235cd44c89bce089c6199a818178d78e8cb3771b811ab9ee36147036767c2a9c4efac956752e3ece01bab0bf1c60fd71c3a2386568624499dcffd957baf729ef810d77433d7e41c528386e771435c75c65ac5a459bb801cd4bae6bb7ef0d71c87678c704f2cd37d4d48779c27817c531372a103cc2e4007638a203c85e1964ba8d72e9e2657b986789eb1a4c1800329ebc55767c35d3cf1c5524c9819b182bb3be2a1da1cac3759af932ef1b59cfb6a665047f74d00e24f622d5856bbe42a27a43e1ebed8ff061cbc75adad32fc38c968d3da5431f6fa220ba2e7a9be76fa698d22788ebeb0f538c1adacf38a4dc45f9c23fde867db418ca1cb82b4c59cdeb48a6f611edae8615fb39997f88ad8426723047f450bfdbc522b41ac3ec5c6dfaea73a4bff3f56b191b4c233e8e5cbc96d0404a4e381aa3def91c93f8904d9067461f8a024644950e218e26a742d6d332daf9f906a2c4074457c9b6fd4cf22f6af4a6f3602504984b41a8212576b4855c3ab8722c157121545c89fef1144fc466a6faf3cfbfd4d66a31841542a6a6a11383c77dca068eb69539b979bda8d4e8080294ff1102de7ded7f72932492518bec8062ef35b8317c3de48244c79656a75189c7ff2e41ea613dde09911582997034cc55df64f3498ee0a2b6cf943b4ed1584f5ccc9b8788704a876dad6f6905f12883eb57117ac11555eb21620c496eb7166a8a765b858656a3f5d273eee80fb3275e7cd8d1212ceb2dc9f3a90cf1a03a7b990a1362515e88a093edeebe7faa1e9c32d05af6bd86b524cb28cb876f5f9f0dc273b8b816d209940bff15c74e57c26b8567e24703261c56009c648a0c46a9fd0bf8739f78b816db6b6265966d3934cfc8261ab8755602d571c6e86356df3231e8722526bd3a2cbd0b7de71b83d778527bd16c2b5a3ce6dc2801763524432f931dba366e3c0062fd6caf8758b67467e16d70fdcd48b595a74695a7726bbbca8114ea2c71f502eb081081f5546f9daf40a2ca5e9de9de5f8c231e06e333e0be535645ab3d1371aba4e3ac1ee1de22be95ba30aa95df89105ce8ea96a496eeabdc7410d0ea38fecb2f177e655995dc3c0f84a770efa97b03746d3fa623371392ea2a009ba3bbd2bedaec992ffa2a3805056a0735abdfd29fcfa3d811f5fdd21e003ca3bcffa886e6868e0206d45aef529f5a827bbc9bb1da1a19853ec248e10103008f0e406631b84e99931ed5995de03ab079a190c0394caea09cb1e3f8c0303b2c003b36966d94b587b88f43ef4de4451aa9c772a8e835787b62e7c373069946186cb2e66e12c871fcbe2b97d43f2ab120bc28cdd0a3121b716fe4b5e11406d3485a1a65be0437023209a1b2a1664eba70195d36ce897691cc97e20d1ed6667a340384ccaeb3d230152fd75954b804fe6414aca370beec7e66ab6897cdbf1450eb3414104ca7e16e9b83b4fef21013d6ccf78f62977af046233f9fb72d19151b1b054662108beb08d775746ff3e96f5755bd045ece8ed83855eabcee5bcc75fbb3211c1baa1b6b73400d21136fa213ea0f30f2183a6cb182e7939b7e46263352df8f10eb56d0c2ebfe5977e9fb0c3f3c666ed4b8e27f106945e916518253277a421d1f93a8d3f0b0274d49e7a125909ff36794a30dcf0088d121b2a80b963f63c6798cf267f6859dc516ccd829b3e4e834a41dcf9623ec8c6bb50023bc7b06d0969cd1de3aaaac0a4f47cc6bd5d41113cfe9d4f20e472a413e95446f3dc1f9f8efe4065a2a43922d003f8ec00a09a941570bbae89bb62128676557f02d0c7e6ae8534f685bfbb677b0651419b2b0a8bc02408f38f4b7ac2f18b1038704f7ee5d524a8d13ccf6190d21a58a8ad9212744f09e401a0071a37669c1bc3924bb20d6af4c34a7ae2f7d9eedf626a83ee0ad48f6931c2e123d8840b011aa5d6d321ccdce4067330209b6093b008cdc519f455c1a1cd6b4ee01061b8ae0718881b4d51e82f8fca1c726c1d6c763aca390586d2416ada412fd84a21acec1f2e08c2b43eba0192a12a0b36c52f135118915f7422210404ca01fd8abf3cf82b1940425f025d5d283106491171dedf9d52c1be60eed6786516c7c1a3c0482112f19754b618783cbaec528ad82ee27c82a04f8a88ec8abecde4c5c036987426dbce6867e0d967f37d9f22bb24f5ac2d23754801d610606470435eea359086084edb77d9531a6beee5725256f5b2b6c74c7bb6ff4d62169045ca6b647ab03ba7ba83498721a1668f014ebaeaca22ce6e1ab8d80fb46aa57144ffd5507b30302021eb6191f1c611f5da76928f51bc6232b91069d18de75f973da7cf6f11f0ef8659c5bb0e8ce964e1600592603dd3684c92c7fd6de78a506fd724d6fbb33fd2af2fea6c42290eef29f4e79ff46186b194eaf1a6d7cb8758ecfdf384447a8fb4ccfd5f8199eb699f5ccc9266ed0d94512b010e0b7fe72a297d5667ae2da8bfdcab6952b688052c77127d5f8102d98b3dc2a7de53649286d7d23af77cd5b942f911187b0efd21d02ce3a38c4baf31603d350823460b95b34983245883eeb4309550b0e7901db9d4df0b501ec13781c3804ef0fd06425d951822c3daf91c039e6a5604142a197a82f113f2a47067335a620d6ab943ff1d9b856588df81370c99baf26b1fbd4e1e257094536a83df35f6cc276fec461f15547c1b4492d7b60b797ce8804580c2992042ace49b0bcc43a73ff17b1233814112505033045777a667644afa1b91ac4e61e523b6249d1baa5f1561f4ca3efef879dde90109a2fc2c109aff500050b8c62f4dd7c51da1fd2ca8eb89c58aa83c095fca37f68100bcf37986c61d27752930e51d5f2520db88f3cfdef3d91b5d161dcc0f88f1c6355a24c90c827b0e3202d8d8110df3f142d6f75aa20546ecdb15bc5dd361ae03f8286f9eda6a743187985ffe2a0f3e29ada9be1f5eabe840d04002d92ab99d0a0931dec27e488b632c49f14a3a61d492a7323e20c2ac808c9253d318f4a9c4496a4c11d31b7964820afd4f7d33bbb84789b43e67498f9d83d9cc51aed5ffa4e54c7f7f3ece655f71f616524d03ab3050f99bdd5ff4f7ccb5647954faf69c27b9bf3a801e4c26de3fd7f43308b199be86a08d6aabfc4c1a87f5355edc35f947988dac254203fe8272688cb2ca9a3ce40f1f02d7fe4923e3f5d4a293aac084989f9856dd649cecc3995b25601b7af83c84928046b237361d176a5fb3eb86bea32b318df2bcf5cadc943c05003a9ddc9889dac0f80065cf27451c75de6efdbbbdec0dc8e6ac3fa6ca3290d67f3632ed87a4368844aba815a41806821e1cc3fb5c2e5ac4a547d19992832b50569c85942cf220f17227a85510aa9a265d13bffdfff57523b6190eeae040dfb05858532398c5e537b008b7afc0d9b6ff8069ac480dabcbcd3b9f9126eeaffb7edbc9cca3d7c4932faeba989f92dfc3bcb54bc3b101ebf2f4e7f18cec896aabf07040adad41e2f1b7941da90d2072171ce25c3b32ec712ffd18e65b04381585abe5a97be5df100b35024bffa6942cb5a75e74e7c0cacf0160bec0e0a75e42af438ba40fb5bf024384440a31daabfed10a89b1e5b806b4b967dbe72e01d274a21f950de2a79041c5c2bb258c02ee8486550a3c9f8a613f82c39d5fa8f59176a55b3f09c739fc22e7586972e45d4b4eab668fede948771db011ce5a7ccbbb15741da850b02968419009a0850ab93f248738f886d3fb690d55314aa5d4420107fe4cddc0317d96e0b2bfc44307ec5ab6fc63e983f7d810d0a9b96efff627292d1205fad5909091674e1666a922b08b7fa07794744a621f74d4edd079e5cca91e1f699dc26c83791ff7bf78b60597e2324d24649050a64449e6e2ffe3c6553424927ecd17f08d6b86292483f54ed1ccce805367cda4235ff7196af860f49abde249f9dfe555c1b560e6c155b58e30e0c79da156a2bb27d78ccd631299084839529ed9683e1e95a2f74b5c9b0e0cba09673c6fde6dafc4c766593a7843b6f1bc846b051072da2afeca133f7d0985b4565416363ff10e67a84973574cf4abc27eaaa16fcfc53963d4fc08c0a182a19edd5bf50639ad27c40e852235f10669b841c2c9dad6634f737813f9f784e5c7914e97fcf83ed8bb47aa8dd5e40a13e730a8b8ce62b7b3994870df8ef25e35e24eef476f49dacecfa7fd21e1627cac9eababc9af8edef9d5d8ff29c111eaa359116f38f5c484528f1c468fadda2d02618729d55dbec432dff0d3977ff8cc2b62cb137a2f931b7b906f1062f4d28161b176710a4738481cd5b989107da98853ebf8c031d5f146a688e68b900e20a3bac7867ef5ac701698b23ec0deaaf264e7e8c525c958cffe0347a3d96d7eccb174e476765c27616139ada96baa5b332d609b7bee3dfb4085df45521e14ff7ac53c81fd425ba62f67ba97a5446f9480d5a52878e2f21c64953392a07de6d85bb780295bdbea2fcbf0fcaa1a6c13a24fb3e772e689d7b5e3831545715ee85b0431f7e38969c36897cae0ae1c149db5ece8e37f7f282a087ea9d45d65e6a067727d33f22c18797f512a7bbe2e13ffc81785454a14930fd24d6c4c5cef054c2011041c80bd9708a89cff2d47685ee4e06366c7ceff9383f5ef9f3f</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-flip">
      <input class="hbe hbe-input-field hbe-input-field-flip" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-flip" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-flip" data-content="您好, 这里需要输入密码，解密后方可查看内容。">您好, 这里需要输入密码，解密后方可查看内容。</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>python</tag>
        <tag>pytest</tag>
        <tag>serial</tag>
      </tags>
  </entry>
  <entry>
    <title>pyserial 使用指导</title>
    <url>/2023/07/26/pyserial_use_guide/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>利用pyserial，可以访问串口，发送串口命令，当然，根据串口返回结果，判断命令执行正确性。</p>
<p>本文简介pyserial一些常用函数的使用方法与场景，并做一些阐述。</p>
<h1 id="shi-jian">实践</h1>
<h2 id="chu-shi-hua-lian-jie-chuan-kou">初始化(连接串口)</h2>
<h3 id="chuan-kou-lian-jie-shi-li">串口连接示例</h3>
<pre><code class="language-python">&gt;&gt;&gt; import serial
&gt;&gt;&gt; ser = serial.Serial('COM7', 115200, timeout=1)
</code></pre>
<p>不同平台连接不同类型串口，示例如下：</p>
<pre><code class="language-python">ser = serial.Serial("/dev/ttyUSB0", 9600, timeout=0.5) # 使用USB连接串行口
ser = serial.Serial("/dev/ttyAMA0", 9600, timeout=0.5) # 使用树莓派的GPIO口连接串行口
ser = serial.Serial("com1", 9600, timeout=0.5)# winsows系统使用com1口连接串行口
ser = serial.Serial("/dev/ttyS1", 9600, timeout=0.5)# Linux系统使用com1口连接串行口
</code></pre>
<p>连接串口时，除了主要的几个参数显示携带外，其他参数可以使用默认值，当然，可以携带全部参数，示例如下：</p>
<p>当然， 可以在连接串口时，携带上全部参数：</p>
<pre><code class="language-python">ser = serial.Serial(
port=None,              # number of device, numbering starts at
# zero. if everything fails, the user
# can specify a device string, note
# that this isn't portable anymore
# if no port is specified an unconfigured
# an closed serial port object is created
baudrate=9600,          # baud rate
bytesize=EIGHTBITS,     # number of databits
parity=PARITY_NONE,     # enable parity checking
stopbits=STOPBITS_ONE,  # number of stopbits
timeout=None,           # set a timeout value, None for waiting forever
xonxoff=0,              # enable software flow control
rtscts=0,               # enable RTS/CTS flow control
interCharTimeout=None   # Inter-character timeout, None to disable
)
</code></pre>
<h3 id="dui-xiang-shu-xing">对象属性</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>name —— 设备名字</p>
</li>
<li class="lvl-2">
<p>port —— 读或者写端口，比如示例中的’COM7’，这里只接受字符串类型内容</p>
</li>
<li class="lvl-2">
<p>baudrate —— 波特率，比如示例中的115200，波特率端口，默认9600</p>
</li>
<li class="lvl-2">
<p>bytesize —— 字节大小</p>
</li>
<li class="lvl-2">
<p>parity —— 校验位</p>
</li>
<li class="lvl-2">
<p>stopbits —— 停止位，取值(1,2)</p>
</li>
<li class="lvl-2">
<p>timeout —— 读超时设置</p>
</li>
<li class="lvl-2">
<p>writeTimeout —— 写超时</p>
</li>
<li class="lvl-2">
<p>xonxoff —— 软件流控</p>
</li>
<li class="lvl-2">
<p>rtscts —— 硬件流控</p>
</li>
<li class="lvl-2">
<p>dsrdtr —— 硬件流控</p>
</li>
<li class="lvl-2">
<p>interCharTimeout —— 字符间隔超时</p>
</li>
</ul>
<h3 id="shu-xing-jie-shao">属性介绍</h3>
<p>说明：</p>
<p>​    如未显示携带，pyserial设有默认值。</p>
<p><strong>name</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.name
COM7

</code></pre>
<p><strong>port</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.port
COM7
&gt;&gt;&gt; print ser.portstr
COM7
&gt;&gt;&gt;
</code></pre>
<p><strong>baudrate</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.baudrate
115200
&gt;&gt;&gt;
</code></pre>
<p><strong>bytesize</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.bytesize
8
</code></pre>
<p><strong>parity</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.parity
N
</code></pre>
<p><strong>stopbits</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.stopbits
1
</code></pre>
<p><strong>timeout</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.timeout
None
</code></pre>
<p>关于timeout：</p>
<pre><code class="language-shell">timeout=None            # wait forever
timeout=0               # non-blocking mode (return immediately on read)
timeout=x               # set timeout to x seconds (float allowed)
</code></pre>
<p><strong>writeTimeout</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.writeTimeout
None
</code></pre>
<p><strong>xonxoff</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.xonxoff
False
</code></pre>
<p><strong>rtscts</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.rtscts
False
</code></pre>
<p><strong>dsrdtr</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.dsrdtr
False
</code></pre>
<p><strong>interCharTimeout</strong></p>
<pre><code class="language-shell">&gt;&gt;&gt; print ser.interCharTimeout
None
&gt;&gt;&gt;
</code></pre>
<p><strong>一个命令获取当前串口属性信息</strong>：</p>
<pre><code class="language-shell">&gt;&gt;&gt; ser.getSettingsDict
&lt;bound method Serial.getSettingsDict of Serial&lt;id=0x2cc3358, open=True&gt;(port='com7', baudrate=115200, bytesize=8, parity='N', stopbits=1, timeout=None, xonxoff=False, rtscts=False, dsrdtr=False)&gt;
&gt;&gt;&gt;
</code></pre>
<h2 id="cha-kan-pyserial-shu-xing-xin-xi">查看pyserial 属性信息</h2>
<pre><code class="language-shell">&gt;&gt;&gt; import serial
&gt;&gt;&gt; ser = serial.Serial('COM7', 115200)
&gt;&gt;&gt; dir(ser)
['BAUDRATES', 'BYTESIZES', 'PARITIES', 'STOPBITS', '_GetCommModemStatus', '_SAVED_SETTINGS', '__abstractmethods__', '__class__', '__delattr__', '__doc__', '__enter__', '__exit__', '__format__', '__getattribute__', '__hash__', '__init__', '__iter__', '__metaclass__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_cancel_overlapped_io', '_checkClosed', '_checkReadable', '_checkSeekable', '_checkWritable', '_close', '_reconfigure_port', '_update_break_state', '_update_dtr_state', '_update_rts_state', 'applySettingsDict', 'apply_settings', 'baudrate', 'break_condition', 'bytesize', 'cancel_read', 'cancel_write', 'cd', 'close', 'closed', 'cts', 'dsr', 'dsrdtr', 'dtr', 'exclusive', 'fileno', 'flush', 'flushInput', 'flushOutput', 'getCD', 'getCTS', 'getDSR', 'getRI', 'getSettingsDict', 'get_settings', 'inWaiting', 'in_waiting', 'interCharTimeout', 'inter_byte_timeout', 'iread_until', 'isOpen', 'isatty', 'next', 'open', 'out_waiting', 'parity', 'port', 'read', 'read_all', 'read_until', 'readable', 'readall', 'readinto', 'readline', 'readlines', 'reset_input_buffer', 'reset_output_buffer', 'ri', 'rs485_mode', 'rts', 'rtscts', 'seek', 'seekable', 'sendBreak', 'send_break', 'setDTR', 'setPort', 'setRTS', 'set_buffer_size', 'set_output_flow_control', 'stopbits', 'tell', 'timeout', 'truncate', 'writable', 'write', 'writeTimeout', 'write_timeout', 'writelines', 'xonxoff']
&gt;&gt;&gt;
</code></pre>
<p><strong>对象常用方法</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>ser.isOpen() —— 查看端口是否被打开</p>
</li>
<li class="lvl-2">
<p>ser.open() —— 打开端口</p>
</li>
<li class="lvl-2">
<p>ser.close() —— 关闭端口</p>
</li>
<li class="lvl-2">
<p>ser.read() —— 从端口读字节数据。默认1个字节</p>
</li>
<li class="lvl-2">
<p>ser.read_all() —— 从端口接收全部数据，默认4096字节</p>
</li>
<li class="lvl-2">
<p>ser.write(“s”) —— 向端口写数据 “s”</p>
</li>
<li class="lvl-2">
<p>ser.readline() —— 读一行数据</p>
</li>
<li class="lvl-2">
<p>ser.readlines() —— 读多行数据</p>
</li>
<li class="lvl-2">
<p>in_waiting —— 返回接收缓存中的字节数，方法同inWaiting()</p>
</li>
<li class="lvl-2">
<p>flush() —— 等待所有数据写出</p>
</li>
<li class="lvl-2">
<p>flushInput() —— 丢弃接收缓存中的所有数据</p>
</li>
<li class="lvl-2">
<p>flushOutput() —— 终止当前写操作，并丢弃发送缓存中的数据</p>
</li>
<li class="lvl-2">
<p>read_until(“s”) —— 读取串口数据，知道出现预期字符串"s"就终止读取</p>
</li>
<li class="lvl-2">
<p>set_buffer_size(rx_size=value1, tx_size=value2) —— 设置buffer 大小，默认4096bytes，上限2147483647</p>
</li>
<li class="lvl-2">
<p>sendBreak()   —— send break condition</p>
</li>
<li class="lvl-2">
<p>setRTS(level=1)  —— set RTS line to specified logic level</p>
</li>
<li class="lvl-2">
<p>setDTR(level=1) —— set DTR line to specified logic level</p>
</li>
<li class="lvl-2">
<p>getCTS()  —— return the state of the CTS line</p>
</li>
<li class="lvl-2">
<p>getDSR()  —— return the state of the DSR line</p>
</li>
<li class="lvl-2">
<p>getRI()  —— return the state of the RI line</p>
</li>
<li class="lvl-2">
<p>getCD() —— return the state of the CD line</p>
</li>
</ul>
<h1 id="chang-yong-dai-ma-shi-li">常用代码示例</h1>
<p>说明：</p>
<p>​      如下示例，借助虚拟串口软件（Virtual Serial Port Driver Pro）创建了两个虚拟串口（COM7 和 COM8），并将两个串口短接（即COM7与COM8互通，形成回环）</p>
<h3 id="huo-qu-dang-qian-she-bei-shang-suo-you-chuan-kou-xin-xi">获取当前设备上所有串口信息</h3>
<pre><code class="language-python">    @staticmethod
    def list_serial_ports():
        """
        Lists serial port names
        :raises EnvironmentError:   On unsupported or unknown platforms
        :returns: A list of the serial ports available on the system
        """
        if sys.platform.startswith('win'):
            ports = ['COM%s' % (i + 1) for i in range(256)]
        elif sys.platform.startswith('linux') or sys.platform.startswith('cygwin'):
            # this excludes your current terminal "/dev/tty"
            ports = glob.glob('/dev/tty[A-Za-z]*')
        elif sys.platform.startswith('darwin'):
            ports = glob.glob('/dev/tty.*')
        else:
            raise EnvironmentError('Unsupported platform')
    
        result = []
        for port in ports:
            try:
                s = serial.Serial(port)
                s.close()
                result.append(port)
            except (OSError, serial.SerialException):
                pass
    
        return result
</code></pre>
<h3 id="zi-fu-chuan-de-fa-song-jie-shou">字符串的发送接收</h3>
<pre><code class="language-python">import serial
ser = serial.Serial('COM7', 115200)
writen = ser.write('Hello, i send a string command to serial')
print writen
recevied = ser.read(writen )
print recevied
</code></pre>
<p>其中，read(value)方法的参数value为需要读取的字符长度：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>如果指定了value的值，当且仅当串口 buffer内容长度小于value值时，read动作会一直等待，直到串口buffer &gt;= value时，read结束。比如read(10)，而buffer内容长度超过10字节，则只读取前面10个字节内容。</p>
</li>
<li class="lvl-2">
<p>如果想要全部读取，提供两个方法：</p>
</li>
</ul>
<p>​     （1）inWaiting() 或者 in_waiting：监测接收字符。 inWaitting返回接收字符串的长度值，然后把这个值赋给read做参数。</p>
<p>​     （2）read_all() ：读取全部字符</p>
<p>说明:</p>
<p>​    inWaiting()或者in_wating，使用如下：</p>
<pre><code class="language-shell">&gt;&gt;&gt; ser.inWaiting()
36L
&gt;&gt;&gt; ser.in_waiting
36L
&gt;&gt;&gt;
</code></pre>
<p>如果有非零值，说明串口buffer中有内容可读。</p>
<p>​    read_all() 使用如下:</p>
<pre><code class="language-shell">&gt;&gt;&gt; ser.read_all()
'I received what you send, thanks.'
&gt;&gt;&gt;
</code></pre>
<p>还有另外一个方法readall()，但是没有理解掉这个方法，使用readall()读取数据时，无论设置多大的buffer size，无论发送多大的数据包过去，命令始终卡着，无任何输出，即使携带上回车换行也没有效果。</p>
<h3 id="shi-liu-jin-zhi-xian-shi">十六进制显示</h3>
<p>十六进制显示的实质是把接收到的字符串转换成其对应的ASCII码，然后将ASCII码值再转换成十六进制数显示出来，这样就可以显示特殊字符了。</p>
<p>在这里定义了一个函数，如hexShow(argv)，代码如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*

import serial


def hexShow(argv):
    result = ''
    hLen = len(argv)
    for i in xrange(hLen):
        hvol = ord(argv[i])
        hhex = '%02x'%hvol
        result += hhex+' '

    print 'hexShow:', result

ser = serial.Serial('COM8',9600)
str_input = raw_input('Enter some words:')
writen_str = ser.write(str_input)
print "--  writen_str : ({})".format(writen_str)

read_str = ser.read(writen_str)
print "--  read_str : ({})".format(read_str)

hexShow(read_str)

ser.close()
</code></pre>
<p>测试结果如下：</p>
<pre><code class="language-shell">C:\Users\Administrator&gt;python C:\Users\Administrator\Desktop\hexShow.py
Enter some words:hex shows test
--  writen_str : (14)
--  read_str : (hex shows test)
hexShow: 68 65 78 20 73 68 6f 77 73 20 74 65 73 74
</code></pre>
<h3 id="shi-liu-jin-zhi-fa-song">十六进制发送</h3>
<p>十六进制发送实质是发送十六进制格式的字符串，如’\xaa’，‘\x0b’。重点在于怎么样把一个字符串转换成十六进制的格式，有两个误区：</p>
<p>1）‘\x’+'aa’是不可以的，涉及到转义符反斜杠</p>
<p>2）‘\x’+‘aa’和r’\x’+‘aa’也不可以的，这样的打印结果虽然是\xaa，但赋给变量的值却是’\xaa’</p>
<p>这里用到decode函数：</p>
<pre><code class="language-shell">&gt;&gt;&gt; s ='aabbccddee'
&gt;&gt;&gt; s.decode('hex')
'\xaa\xbb\xcc\xdd\xee'
&gt;&gt;&gt;
</code></pre>
<p>需要注意一点，如果字符串 s 的长度为奇数，则decode会报错：</p>
<pre><code class="language-shell">&gt;&gt;&gt; s ='aabbccdde'
&gt;&gt;&gt; s.decode('hex')
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "C:\Python27\lib\encodings\hex_codec.py", line 42, in hex_decode
    output = binascii.a2b_hex(input)
TypeError: Odd-length string
&gt;&gt;&gt;
</code></pre>
<p>可以按照实际情况，用字符串的切片操作，在字符串的开头或结尾加一个’0’。</p>
<p>假如在串口助手以十六进制发送字符串"abc"，那么你在python中则这样操作：</p>
<pre><code class="language-python">serial.write(”\x61\x62\x63") 
</code></pre>
<p>当然，还有另外一个方法也可以达到相同目的：</p>
<pre><code class="language-python">s = "abc"
strHex = binascii.b2a_hex(s)
# print strHex
strhex = strHex.decode("hex")
# print strhex
ser.write(strhex);
</code></pre>
<h3 id="du-qu-chuan-kou-ji-lu-de-zui-hou-yi-xing">读取串口记录的最后一行</h3>
<pre><code class="language-python">    def read_last_line(self):
        """
        Read the last line of output of serial, if not match, return None
        """
        all_line = self.serial.read_all().decode('GBK')
        logging.debug("--  [DEBUG]  all_line : ({})".format(all_line))
        all_line_list = [x for x in all_line.split('\n') if x]
        if len(all_line_list):
            return all_line_list[-1]
        else:
            return
</code></pre>
<h3 id="pan-duan-buffer-shi-fou-you-nei-rong">判断 buffer 是否有内容</h3>
<pre><code class="language-python">    def has_buffer(self):
        """
        Get serial buffer
        @return: True or False
        """
        if self.serial.in_waiting &gt; 0:
            buffer_size = self.serial.in_waiting
            time.sleep(5)
            current_buffer_size = self.serial.in_waiting
            if buffer_size != current_buffer_size:
                return True
        else:
            return False
</code></pre>
<h3 id="du-qu-chuan-kou-nei-rong-bing-ji-lu-dao-wen-jian">读取串口内容并记录到文件</h3>
<pre><code class="language-python">    def write_serial_output_to_file(self, file_name):
        """
        Write serial output into a file
        @param file_name: string, a file name which to record the serial output information
        """
        logging.debug('--  [DEBUG]  Write data into file : (%s)', file_name)

        while True:
            if self.serial.in_waiting &gt; 0:  # If serial has data to read
                full_data = self.serial.readline().decode('GBK').strip()
                # split_data = full_data.splitlines()
                with open(file_name, 'a+') as f:
                    f.write(full_data)
</code></pre>
<h3 id="du-qu-chuan-kou-nei-rong-zhi-dao-pi-pei-dao-yu-qi-zi-fu-chuan">读取串口内容直到匹配到预期字符串</h3>
<pre><code class="language-python">    def read_until_matched(self, key_words):
        """
        Get some info when read from serial until match some key words
        @return:
        """
        logging.debug("--  Get key words : (%s) from serial cache", key_words)

        matched = self.serial.read_until(key_words).decode('GBK')

        return matched
</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>python</tag>
        <tag>serial</tag>
      </tags>
  </entry>
  <entry>
    <title>python操作MySQL数据库基础操作</title>
    <url>/2023/08/19/python_mysql/</url>
    <content><![CDATA[<h1 id="over-view">OverView</h1>
<p>Recently in the revision mysql database, deployed a set of environments, review the installation and deployment, the basic operation of the database sql commands and backup, recovery operations. Incidentally, with the help of pyhton access to the mysql database basic operation of the package, in case of future needs.</p>
<h1 id="code-example">Code Example</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding: UTF-8 -*-

import re
import MySQLdb as mdb


class MysqlDB(object):
    """ Basic methods of operating mysql databases """

    def __init__(self , host="localhost", username="root", password="", port=3306, database="MMSDB"):
        self.host = host
        self.username = username
        self.password = password
        self.database = database
        self.port = port
        self.con = None
        self.cur = None
        try:
            self.con = mdb.connect(host=self.host, user=self.username, passwd=self.password, port=self.port, db=self.database)
            # All queries are run on top of cursor, a module that connects to con.
            self.cur = self.con.cursor()
        except:
            raise "DataBase connect error,please check the db config."

    def close(self):
        """ Close database connection """
        if not  self.con:
            self.con.close()
        else:
            raise "DataBase doesn't connect,close connectiong error;please check the db config."

    def get_version(self):
        """ Get version info of database """
        self.cur.execute("SELECT VERSION()")
        return self.getOneData()

    def get_one_data(self):
        """ Get the result of the previous query as a single result. """
        data = self.cur.fetchone()
        return data

    def creat_table(self, tablename, attrdict, constraint):
        """
        Creating database tables

            args:
                tablename : table name
                attrdict : Attribute key-value pairs,{'book_name':'varchar(200) NOT NULL'...}
                constraint ：primary key constraint,PRIMARY KEY(`id`)
        """
        if self.isExistTable(tablename):
            return
        sql = ''
        sql_mid = '`id` bigint(11) NOT NULL AUTO_INCREMENT,'
        for attr,value in attrdict.items():
            sql_mid = sql_mid + '`'+attr + '`'+' '+ value+','
        sql = sql + 'CREATE TABLE IF NOT EXISTS %s ('%tablename
        sql = sql + sql_mid
        sql = sql + constraint
        sql = sql + ') ENGINE=InnoDB DEFAULT CHARSET=utf8'
        print 'creatTable:'+sql
        self.executeCommit(sql)

    def execute_sql(self, sql=''):
        """
        Execute a sql statement that returns a result set against a read operation

            args:
                sql : sql statement
        """
        try:
            self.cur.execute(sql)
            records = self.cur.fetchall()
            return records
        except mdb.Error,e:
            error = 'MySQL execute failed! ERROR (%s): %s' %(e.args[0],e.args[1])
            print error

    def execute_commit(self, sql=''):
        """
        Execute database sql statements and rollback for failed updates, 
        deletions, transactions, etc.
        """
        try:
            self.cur.execute(sql)
            self.con.commit()
        except mdb.Error, e:
            self.con.rollback()
            error = 'MySQL execute failed! ERROR (%s): %s' %(e.args[0],e.args[1])
            print "error:", error
            return error

    def insert(self, tablename, params):
        """
        Creating database tables

            args:
                tablename : table name
                key: attribute key
                value: value of the attribute
        """
        key = []
        value = []
        for tmpkey, tmpvalue in params.items():
            key.append(tmpkey)
            if isinstance(tmpvalue, str):
                value.append("\'" + tmpvalue + "\'")
            else:
                value.append(tmpvalue)
        attrs_sql = '('+','.join(key)+')'
        values_sql = ' values('+','.join(value)+')'
        sql = 'insert into %s'%tablename
        sql = sql + attrs_sql + values_sql
        print '_insert:'+sql
        self.executeCommit(sql)

    def select(self, tablename, cond_dict='', order='', fields='*'):
        """
        Query data from table

            args：
                tablename  : table name
                cond_dict  : query condition
                order      : sort condition

            example：
                print mydb.select(table)
                print mydb.select(table, fields=["name"])
                print mydb.select(table, fields=["name", "age"])
                print mydb.select(table, fields=["age", "name"])
        """
        consql = ' '
        if cond_dict!='':
            for k, v in cond_dict.items():
                consql = consql+k + '=' + v + ' and'
        consql = consql + ' 1=1 '
        if fields == "*":
            sql = 'select * from %s where ' % tablename
        else:
            if isinstance(fields, list):
                fields = ",".join(fields)
                sql = 'select %s from %s where ' % (fields, tablename)
            else:
                raise "fields input error, please input list fields."
        sql = sql + consql + order
        print 'select:' + sql
        return self.executeSql(sql)

    def insert_many(self, table, attrs, values):
        """
        Inserting Multiple Data

            args：
                tablename  : tbale name
                attrs      : property key
                values     : attribute value

            example：
                table='test_mysqldb'
                key = ["id" ,"name", "age"]
                value = [[101, "liuqiao", "25"], [102,"liuqiao1", "26"], [103 ,"liuqiao2", "27"], [104 ,"liuqiao3", "28"]]
                mydb.insertMany(table, key, value)
        """
        values_sql = ['%s' for v in attrs]
        attrs_sql = '('+','.join(attrs)+')'
        values_sql = ' values('+','.join(values_sql)+')'
        sql = 'insert into %s'% table
        sql = sql + attrs_sql + values_sql
        print 'insertMany:'+sql
        try:
            print sql
            for i in range(0,len(values),20000):
                    self.cur.executemany(sql,values[i:i+20000])
                    self.con.commit()
        except mdb.Error,e:
            self.con.rollback()
            error = 'insertMany executemany failed! ERROR (%s): %s' %(e.args[0],e.args[1])
            print error

    def delete(self, tablename, cond_dict):
        """
        Delete data

            args：
                tablename  : table name 
                cond_dict  : Delete Conditional Dictionary

            example：
                params = {"name" : "caixinglong", "age" : "38"}
                mydb.delete(table, params)

        """
        consql = ' '
        if cond_dict!='':
            for k, v in cond_dict.items():
                if isinstance(v, str):
                    v = "\'" + v + "\'"
                consql = consql + tablename + "." + k + '=' + v + ' and '
        consql = consql + ' 1=1 '
        sql = "DELETE FROM %s where%s" % (tablename, consql)
        print sql
        return self.executeCommit(sql)

    def update(self, tablename, attrs_dict, cond_dict):
        """
        Update data

            args:
                tablename : table name
                attrs_dict : update attribute key-value pair dictionary
                cond_dict : Update the condition dictionary

            example：
                params = {"name" : "caixinglong", "age" : "38"}
                cond_dict = {"name" : "liuqiao", "age" : "18"}
                mydb.update(table, params, cond_dict)

        """
        attrs_list = []
        consql = ' '
        for tmpkey, tmpvalue in attrs_dict.items():
            attrs_list.append("`" + tmpkey + "`" + "=" +"\'" + tmpvalue + "\'")
        attrs_sql = ",".join(attrs_list)
        print "attrs_sql:", attrs_sql
        if cond_dict!='':
            for k, v in cond_dict.items():
                if isinstance(v, str):
                    v = "\'" + v + "\'"
                consql = consql + "`" + tablename +"`." + "`" + k + "`" + '=' + v + ' and '
        consql = consql + ' 1=1 '
        sql = "UPDATE %s SET %s where%s" % (tablename, attrs_sql, consql)
        print sql
        return self.executeCommit(sql)

    def drop_table(self, tablename):
        """
        Drop a table

            args：
                tablename  : table name
        """
        sql = "DROP TABLE  %s" % tablename
        self.executeCommit(sql)

    def delete_table(self, tablename):
        """
        Empty database table

            args：
                tablename  : table name
        """
        sql = "DELETE FROM %s" % tablename
        self.executeCommit(sql)

    def is_exist_table(self, tablename):
        """
        Determine if a data table exists

            args:
                tablename : table name

            Return.
                True if the table exists, False if it doesn't.
        """
        sql = "select * from %s" % tablename
        result = self.executeCommit(sql)
        if result is None:
            return True
        else:
            if re.search("doesn't exist", result):
                return False
            else:
                return True
</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql 备份与恢复详解</title>
    <url>/2023/08/20/mysql_backup_restore/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>MySQL是目前比较流行的关系型数据库管理系统之一，在企业级应用中被广泛使用。无论是研发成员还是数据库管理员，都需要了解MySQL备份与恢复的基本知识。</p>
<p>备份和恢复是为了防止在数据库发生宕机的情况下保证数据不丢失，或者最小程度丢失的解决方法，不仅能够帮助企业保护数据，还能够使系统在不良情况下快速应对，尽可能使其恢复到正常运行状态。MySQL提供了 mysqldump、ibbackup、replication 工具来备份，当然也有一些三方工具，诸如 xtrabacup、LVM快照等。</p>
<p>利用周末时间，整理一下，详细介绍MySQL备份与恢复的操作步骤，并提供一些最佳实践，以帮助读者在保护其MySQL数据库方面走得更远。</p>
<h1 id="huan-jing">环境</h1>
<pre><code class="language-shell">root@ubuntu:~# hostnamectl 
   Static hostname: ubuntu
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 2e28c320b7b64edcb7b039f56050833c
           Boot ID: 928ff3a2a9ef430ba5b923b0d119902f
    Virtualization: vmware
  Operating System: Ubuntu 18.04.6 LTS
            Kernel: Linux 5.4.0-84-generic
      Architecture: x86-64
root@ubuntu:~# mysql --version
mysql  Ver 14.14 Distrib 5.7.42, for Linux (x86_64) using  EditLine wrapper
root@ubuntu:~# 
</code></pre>
<p>并创建了一个名称为 'test’的数据库，存放一张表（user）和一个视图（user_view）：</p>
<pre><code class="language-shell">mysql&gt; create table user (name VARCHAR(25), age INT(3));
Query OK, 0 rows affected (0.02 sec)

mysql&gt; insert into user(name, age) values('zhangsan', 30);
Query OK, 1 row affected (0.00 sec)

mysql&gt; insert into user(name, age) values('lisi', 31);
Query OK, 1 row affected (0.00 sec)

mysql&gt; insert into user(name, age) values('wangwu', 38);
Query OK, 1 row affected (0.00 sec)

mysql&gt; insert into user(name, age) values('cat', 2);
Query OK, 1 row affected (0.00 sec)

mysql&gt; create view user_view as select * from user;
Query OK, 0 rows affected (0.01 sec)

mysql&gt; show tables;
+----------------+
| Tables_in_test |
+----------------+
| user           |
| user_view      |
+----------------+
2 rows in set (0.00 sec)

mysql&gt; select * from tables;
ERROR 1146 (42S02): Table 'test.tables' doesn't exist
mysql&gt; select * from user;
+----------+------+
| name     | age  |
+----------+------+
| zhangsan |   30 |
| lisi     |   31 |
| wangwu   |   38 |
| cat      |    2 |
+----------+------+
4 rows in set (0.00 sec)

mysql&gt;
</code></pre>
<h1 id="1-my-sql-bei-fen">1. MySQL备份</h1>
<p>无论哪种数据库，都应该频繁备份，以确保数据库永远处于最新状态。最好能够制定合理的备份策略，实现定期备份、归档备份文件；备份文件要存放双份，且存在于不同的物理介质上。</p>
<h2 id="1-1-bei-fen-fen-lei">1.1 备份分类</h2>
<p>下面的备份分类中，并不是所有都适配了 Mysql 和 Innodb引擎，所以部分是没有真正的方案，也有些是交叉分类的（比如在热备又在逻辑文件中）。</p>
<h3 id="1-1-1-an-bei-fen-lei-xing">1.1.1 按备份类型</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>热备：在数据库运行过程中直接备份</p>
</li>
<li class="lvl-2">
<p>冷备：在数据库停止的情况下备份，一般直接复制相关的物理文件即可</p>
</li>
<li class="lvl-2">
<p>温备：在数据库运行过程中备份，但对数据库操作有影响，如加个全局读锁以保证备份数据一致性</p>
</li>
</ul>
<h3 id="1-1-2-an-bei-fen-wen-jian">1.1.2 按备份文件</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>逻辑文件：指备份出的文件可读，一般指 SQL 语句（适用库升级，迁移，但恢复时间较长需要执行 SQL 语句）</p>
</li>
<li class="lvl-2">
<p>物理文件：指复制数据库的物理文件</p>
</li>
</ul>
<h3 id="1-1-3-an-bei-fen-nei-rong">1.1.3 按备份内容</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p>日志备份：主要备份 bin-log 日志，然后 replay 来完成 point-in-time</p>
</li>
<li class="lvl-2">
<p>完全备份：对数据库一个完整的备份</p>
</li>
<li class="lvl-2">
<p>增量备份：在上次完全备份的基础上对更改部分进行备份（MySQL 没真正的增量备份，一般通过 bin-log 完成，要借助第三方工具才能实现）</p>
</li>
</ul>
<p>也有按 **物理备份 **与 <strong>逻辑备份</strong> 进行分类的，视角不同，实则殊途同归。</p>
<h2 id="1-2-bei-fen-de-yi-zhi-xing">1.2 备份的一致性</h2>
<p>数据库备份的一致性要求在备份的时候数据在这一时间点上是一致的，比如银行转账，A 转给 B 现金100 RMB，这个事务过程先扣 A 100元，再去 B 加100元，确保前后数据一致，否则会发生恢复数据后金钱对不上的情况。</p>
<p>对于 Innodb 引擎来说，因为其支持 MVCC 功能，所以可以先开启一个事务，然后导出一组相关的表，最后提交来实现一致的备份，当然隔离级别要设置为 REPEATABLE READ</p>
<p>对于 mysqldump 备份工具可以添加 --single-transaction 选项来实现备份一致性（开启事务，设置隔离级别）</p>
<p>下面来说明备份的途径 。</p>
<h1 id="2-bei-fen-yu-hui-fu-chang-yong-cao-zuo-shi-li">2. 备份与恢复常用操作示例</h1>
<h2 id="2-1-bei-fen-my-sql">2.1 备份 MySQL</h2>
<h3 id="2-1-1-bei-fen-quan-bu-shu-ju-ku-de-shu-ju-he-jie-gou">2.1.1 备份全部数据库的数据和结构</h3>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot -p123456 -A &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h3 id="2-1-2-bei-fen-quan-bu-shu-ju-ku-de-jie-gou-jia-d-can-shu">2.1.2 备份全部数据库的结构（加 -d 参数）</h3>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot -p123456 -A -d &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h3 id="2-1-3-bei-fen-quan-bu-shu-ju-ku-de-shu-ju-jia-t-can-shu">2.1.3 备份全部数据库的数据(加 -t 参数)</h3>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot -p123456 -A -t &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h3 id="2-1-4-bei-fen-dan-ge-shu-ju-ku-de-shu-ju-he-jie-gou-shu-ju-ku-ming-mydb">2.1.4 备份单个数据库的数据和结构(,数据库名mydb)</h3>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot-p123456 mydb &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h3 id="2-1-5-bei-fen-dan-ge-shu-ju-ku-de-jie-gou">2.1.5 备份单个数据库的结构</h3>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot -p123456 mydb -d &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h3 id="2-1-6-bei-fen-dan-ge-shu-ju-ku-de-shu-ju">2.1.6 备份单个数据库的数据</h3>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot -p123456 mydb -t &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h3 id="2-1-7-bei-fen-duo-ge-biao-de-shu-ju-he-jie-gou">2.1.7 备份多个表的数据和结构</h3>
<p>数据，结构的单独备份方法与上同。</p>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot -p123456 mydb t1 t2 &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h3 id="2-1-8-yi-ci-bei-fen-duo-ge-shu-ju-ku">2.1.8 一次备份多个数据库</h3>
<p>​</p>
<pre><code class="language-shell">mysqldump -uroot -p123456 --databases db1 db2 &gt; /data/mysql_dump/mydb.sql
</code></pre>
<h2 id="2-2-huan-yuan-my-sql-bei-fen-nei-rong">2.2 还原 MySQL 备份内容</h2>
<p>有两种方式还原，第一种是在 MySQL 命令行中，第二种是使用 SHELL 行完成还原</p>
<p>在系统命令行中，输入如下实现还原：</p>
<p>​</p>
<pre><code class="language-shell">mysql -uroot -p123456 &lt; /data/mysql_dump/mydb.sql
</code></pre>
<h6 id="zai-deng-lu-jin-ru-mysql-xi-tong-zhong-tong-guo-source-zhi-ling-zhao-dao-dui-ying-xi-tong-zhong-de-wen-jian-jin-xing-huan-yuan">在登录进入mysql系统中,通过source指令找到对应系统中的文件进行还原：</h6>
<p>​</p>
<pre><code class="language-shell">mysql&gt; source /data/mysql_dump/mydb.sql
</code></pre>
<p>在 Linux中，通常使用BASH脚本对需要执行的内容进行编写，加上定时执行命令crontab实现日志自动化生成。</p>
<h1 id="3-bei-fen-yu-hui-fu-shi-jian">3. 备份与恢复实践</h1>
<h2 id="3-1-wu-li-bei-fen-yu-hui-fu">3.1 物理备份与恢复</h2>
<h3 id="3-1-1-wu-li-bei-fen">3.1.1 物理备份</h3>
<p>MySQL有一种非常简单的备份方法，就是将MySQL中的数据库文件直接复制出来。这是最简单，速度最快的方法。</p>
<p>不过在此之前，建议将数据库进行一次完整逻辑备份（防患于未然，建议做），然后将服务器停止，这样才可以保证在复制期间数据库的数据不会发生数据冲突。如果在复制数据库的过程中还有数据写入，就会造成数据不一致。这种情况在开发环境可以，但是在生产环境中很难允许备份服务器。</p>
<p><strong>注意：</strong></p>
<p>此方法不适用于InnoDB存储引擎的表，而对于MyISAM存储引擎的表很方便。同时，还原时MySQL的版本最好相同。</p>
<h3 id="3-1-2-wu-li-hui-fu">3.1.2 物理恢复</h3>
<p>物理恢复是将备份文件中的物理文件复制到MySQL服务器的目标目录中。下面是物理恢复的一些步骤：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>停止MySQL服务</p>
</li>
<li class="lvl-2">
<p>复制备份文件到正确的目录</p>
</li>
<li class="lvl-2">
<p>启动MySQL服务</p>
</li>
</ul>
<p>下面是在Linux系统中使用命令行恢复MySQL数据库的一些命令：</p>
<pre><code class="language-shell">service mysql stop

cp 备份文件名 目标目录

service mysql start
</code></pre>
<h2 id="3-2-mysqldump">3.2 mysqldump</h2>
<p>mysqldump 是属于逻辑备份，也是最常见的备份工具了，缺点在于备份和恢复速度不是特别快，因为是单线程。</p>
<h3 id="3-2-1-mysqldump-bei-fen">3.2.1 mysqldump 备份</h3>
<p>语法：</p>
<pre><code class="language-shell">mysqldump [arguments] &gt; dump.sql
</code></pre>
<p>详细语法，可执行 <code> mysqldump --help</code> 进行查看，如下为几个重要的参数介绍：</p>
<pre><code class="language-shell">--all-databases：  备份所有数据库
--databases：      备份指定数据库
--single-transaction：备份一致性
--add-drop-database：添加语句 DROP DATABASE IF EXISTS（默认是 CREATE DATABASE IF NOT EXISTS）
--hex-blob：binary、blog、bit是十六进制不可见，会以十六进制来展示
</code></pre>
<p>示例：</p>
<pre><code class="language-shell">mysqldump -uroot -pp@ssw0rd test &gt; test.sql
</code></pre>
<p>注意：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>mysqldump 可以导出存储过程，导出触发器，导出事件，导出数据，但不能导出视图</p>
</li>
<li class="lvl-2">
<p>如果用户的数据库中还使用了视图，则在用mysqldump备份完数据库后，还需要导出视图的定义，或者备份视图定义的frm文件，并在恢复时进行导入，这样才能保证mysqldump数据库的完全恢复和数据的完整</p>
</li>
</ul>
<p>视图备份与恢复：</p>
<pre><code class="language-shell">root@ubuntu:~# mysql -uroot -pp@ssw0rd test
mysql: [Warning] Using a password on the command line interface can be insecure.
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 12
Server version: 5.7.42-0ubuntu0.18.04.1-log (Ubuntu)

Copyright (c) 2000, 2023, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql&gt; show tables;
+----------------+
| Tables_in_test |
+----------------+
| user           |
| user_view      |
+----------------+
2 rows in set (0.00 sec)

mysql&gt; drop view user_view;
Query OK, 0 rows affected (0.01 sec)

mysql&gt; commit;
Query OK, 0 rows affected (0.00 sec)

mysql&gt; show tables;
+----------------+
| Tables_in_test |
+----------------+
| user           |
+----------------+
1 row in set (0.00 sec)

mysql&gt; exit;
Bye
root@ubuntu:~# mysql -uroot -pp@ssw0rd test &lt; view.sql 
mysql: [Warning] Using a password on the command line interface can be insecure.
root@ubuntu:~# mysql -uroot -pp@ssw0rd test
mysql: [Warning] Using a password on the command line interface can be insecure.
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 14
Server version: 5.7.42-0ubuntu0.18.04.1-log (Ubuntu)

Copyright (c) 2000, 2023, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql&gt; show tables;
+----------------+
| Tables_in_test |
+----------------+
| user           |
| user_view      |
+----------------+
2 rows in set (0.00 sec)

mysql&gt; select * from user_view;
+----------+------+
| name     | age  |
+----------+------+
| zhangsan |   30 |
| lisi     |   31 |
| wangwu   |   38 |
| cat      |    2 |
+----------+------+
4 rows in set (0.00 sec)

mysql&gt; exit;
Bye
root@ubuntu:~# 
</code></pre>
<h3 id="3-2-2-mysqldump-hui-fu">3.2.2 mysqldump 恢复</h3>
<pre><code class="language-shell">mysqldump -uroot -pp@ssw0rd test &lt; test.sql
</code></pre>
<h2 id="3-3-bin-log">3.3 bin-log</h2>
<p>bin-log 是 Mysql 的日志文件。</p>
<h3 id="3-3-1-bei-fen">3.3.1 备份</h3>
<p>先要在 <code>/etc/mysql/mysql.conf.d/mysqld.cnf</code> 中[mysql] section 下增加下面一句话，之后会自动记录，名字按 name.00001 格式来递增滚动，其中 name 为 自定义的log-bin name，如下所示：</p>
<pre><code class="language-text">[mysqld]
# 不赋值默认为主机名
log-bin         = /var/log/mysql/mysql-binlog
server-id       = 1
</code></pre>
<p>重启mysql service后，会在 /var/log/mysql 目录下产生从1 开始的binlog文件：</p>
<pre><code class="language-shell">root@ubuntu:/var/log/mysql# ll
total 28
drwxr-x---  2 mysql adm    4096 Aug 21 13:23 ./
drwxrwxr-x 13 root  syslog 4096 Aug 21 13:22 ../
-rw-r-----  1 mysql adm    3546 Aug 21 13:23 error.log
-rw-r-----  1 mysql adm    5659 Aug 21 13:16 error.log.1.gz
-rw-r-----  1 mysql mysql   154 Aug 21 13:23 mysql-binlog.000001
-rw-r-----  1 mysql mysql    35 Aug 21 13:23 mysql-binlog.index
root@ubuntu:/var/log/mysql# 
</code></pre>
<p><strong>说明：</strong></p>
<p>这里的mysqld.cnf配置文件中一定要赋值 server-id，否则会报如下错误(来自/var/log/syslog)：</p>
<pre><code class="language-shell">Aug 21 13:18:29 ubuntu mysql-systemd-start[2327]: Please take a look at https://wiki.debian.org/Teams/MySQL/FAQ for tips on fixing common upgrade issues.
Aug 21 13:18:29 ubuntu mysql-systemd-start[2327]: Once the problem is resolved, restart the service.
Aug 21 13:18:29 ubuntu systemd[1]: mysql.service: Control process exited, code=exited status=1
Aug 21 13:18:29 ubuntu systemd[1]: mysql.service: Failed with result 'exit-code'.
Aug 21 13:18:29 ubuntu systemd[1]: Failed to start MySQL Community Server.
Aug 21 13:18:29 ubuntu systemd[1]: mysql.service: Service hold-off time over, scheduling restart.
Aug 21 13:18:29 ubuntu systemd[1]: mysql.service: Scheduled restart job, restart counter is at 1.
Aug 21 13:18:29 ubuntu systemd[1]: Stopped MySQL Community Server.
Aug 21 13:18:29 ubuntu systemd[1]: Starting MySQL Community Server...
Aug 21 13:18:29 ubuntu mysql-systemd-start[2335]: ERROR: Unable to start MySQL server:
Aug 21 13:18:29 ubuntu mysql-systemd-start[2335]: 2023-08-21T20:18:29.151581Z 0 [ERROR] You have enabled the binary log, but you haven't provided the mandatory server-id. Please refer to the proper server start-up parameters documentation
Aug 21 13:18:29 ubuntu mysql-systemd-start[2335]: 2023-08-21T20:18:29.151958Z 0 [ERROR] Aborting
</code></pre>
<p>备份命令：</p>
<pre><code class="language-shell">root@ubuntu:/var/log/mysql# mysqlbinlog mysql-binlog.000001 &gt; backup.sql
</code></pre>
<h3 id="3-3-2-hui-fu">3.3.2 恢复</h3>
<p>使用 Mysql 自带的 mysqlbinlog 命令，其作用将二进制的记录转成可见的文本格式（即 SQL 语句），然后交给 mysql 执行可恢复数据，主要参数如下：</p>
<pre><code class="language-text">root@ubuntu:~# mysqlbinlog [option] log_file
--start-position：指定某个起始偏移量来恢复（事务区间）
--stop-positon：指定某个结束偏移量来恢复（事务区间）
--start-datetime: 指定起始时间(日期区间，e.g:2023-08-21 12:10:36)
--stop-datetime: 指定终止时间(日期区间，e.g:2023-08-21 19:29:00)
</code></pre>
<p>恢复命令：</p>
<p>要先登录对应数据库，在mysql里执行source xx.sql进行恢复，参考如下：</p>
<pre><code class="language-shell">root@ubuntu:~# mysql -uroot -pp@ssw0rd test
mysql: [Warning] Using a password on the command line interface can be insecure.
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 3
Server version: 5.7.42-0ubuntu0.18.04.1-log (Ubuntu)

Copyright (c) 2000, 2023, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql&gt; source /var/log/mysql/backup.sql
Query OK, 0 rows affected (0.00 sec)

................... 省略 ...................

ERROR 1050 (42S01): Table 'user_view' already exists
Query OK, 0 rows affected (0.00 sec)

Query OK, 0 rows affected (0.00 sec)

Query OK, 0 rows affected (0.00 sec)

mysql&gt; 
</code></pre>
<p><strong>注意：</strong></p>
<p>在备份bin-log之前，先 FLUSH LOGS，会自动滚动文件，备份滚动后的文件即可：</p>
<pre><code class="language-shell">mysql&gt; flush logs;
Query OK, 0 rows affected (0.01 sec)

mysql&gt; 
</code></pre>
<p>此后，会在目录下生成一个全新数字开始的bin-log文件：</p>
<pre><code class="language-shell">root@ubuntu:/var/log/mysql# ll
total 40
drwxr-x---  2 mysql adm    4096 Aug 21 13:50 ./
drwxrwxr-x 13 root  syslog 4096 Aug 21 13:22 ../
-rw-r--r--  1 root  root   7037 Aug 21 13:45 backup.sql
-rw-r-----  1 mysql adm    3802 Aug 21 13:46 error.log
-rw-r-----  1 mysql adm    5659 Aug 21 13:16 error.log.1.gz
-rw-r-----  1 mysql mysql  3586 Aug 21 13:50 mysql-binlog.000001
-rw-r-----  1 mysql mysql   154 Aug 21 13:50 mysql-binlog.000002
-rw-r-----  1 mysql mysql    70 Aug 21 13:50 mysql-binlog.index
root@ubuntu:/var/log/mysql# 
</code></pre>
<h2 id="3-4-leng-bei">3.4 冷备</h2>
<p>Innodb 冷备是最简单的，通常只需写个脚本来复制 MySQL 的文件，然后将这些文件放到对应数据库的目录下即可实现数据恢复：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>.frm结构文件</p>
</li>
<li class="lvl-2">
<p>.idb独立表空间文件</p>
</li>
<li class="lvl-2">
<p>redo重做日志文件</p>
</li>
<li class="lvl-2">
<p>共享表空间文件</p>
</li>
<li class="lvl-2">
<p>my.cnf配置文件</p>
</li>
</ul>
<p>缺点是：冷备文件比逻辑文件大，因为存放了很多其他数据，而且不能轻易跨平台（SQL 是标准语句，可跨平台）</p>
<h3 id="3-4-1-bei-fen">3.4.1 备份</h3>
<p>首先关闭数据库，然后执行下面的命令</p>
<h4 id="3-4-1-1-cha-kan-mysql-shu-ju-cun-fang-de-mu-lu">3.4.1.1 查看mysql数据存放的目录</h4>
<pre><code class="language-shell"># 	 /var/lib/mysql/data
mysql&gt; show variables like "%datadir%";
+---------------+-----------------+
| Variable_name | Value           |
+---------------+-----------------+
| datadir       | /var/lib/mysql/ |
+---------------+-----------------+
1 row in set (0.00 sec)

mysql&gt;


$cd /var/lib/mysql/
$tar -zcvf mysqlDataBacku.tar.gz  data/
</code></pre>
<h4 id="3-4-1-2-bei-fen-wu-li-wen-jian">3.4.1.2 备份物理文件</h4>
<pre><code class="language-shell">root@ubuntu:~# cd /var/lib/mysql/
root@ubuntu:/var/lib/mysql# 
root@ubuntu:/var/lib/mysql# tar -zcvf mysql_cool_backup.tar.gz  /data/
</code></pre>
<h3 id="3-4-2-hui-fu">3.4.2 恢复</h3>
<pre><code class="language-shell"># 1. 恢复只需将上面的包解压到对应数据库的数据存放目录下
# 2. 恢复前将原数据备份一下
# 3. 重启mysql即可

root@ubuntu:~# cd /var/lib/mysql/
root@ubuntu:/var/lib/mysql# mv /data/ /data_tmp
root@ubuntu:/var/lib/mysql# tar -zxvf mysql_cool_backup.tar.gz
</code></pre>
<h2 id="3-5-xtra-backup">3.5 XtraBackup</h2>
<p>Innodb 官方有提供热备工具 ibbackup 的收费软件。</p>
<p>不过可以借用 XtraBackup 开源的热备工具，备份和恢复速度比 mysqldump 快，具体的安装过程这里不说明了（<code>apt install percona-xtrabackup</code>）。</p>
<h3 id="3-5-1-quan-liang-bei-fen">3.5.1 全量备份</h3>
<h4 id="3-5-1-1-bei-fen">3.5.1.1 备份</h4>
<pre><code class="language-shell">
root@ubuntu:~# innobackupex 
	--defaults-file=/etc/mysql/my.cnf  # 有数据存放地址
	--user=root 
	--password="123456" 
	--databases=test
	--backup /mysqlBackup/		 # 目录下生成日期命名的目录
</code></pre>
<h4 id="3-5-1-2-bei-fen-yi-zhi-xing">3.5.1.2 备份一致性</h4>
<p>备份一致性，回滚未提交的事务及同步已经提交的事务至数据文件使数据文件处于一致性</p>
<pre><code class="language-shell">root@ubuntu:~# innobackupex --apply-log /mysqlBackup/2023-08-20_20-39-19/
</code></pre>
<h4 id="3-5-1-3-hui-fu">3.5.1.3 恢复</h4>
<p>要保证原数据目录是空的，因为目录里有binlog日志</p>
<pre><code class="language-shell">root@ubuntu:~# innobackupex 
	--defaults-file=/etc/mysql/my.cnf 
	--copy-back /mysqlBackup/2023-08-20_20-39-19/
</code></pre>
<h3 id="3-5-2-zeng-liang-bei-fen">3.5.2 增量备份</h3>
<p>当数据量比较大的时候（10G），每次都全量备份不太实际，可采用业务比较闲（比如周末）全量备份，其余时间增量备份的策略</p>
<p>原理：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>首先执行完全备份，并记录下此时检查点 LSN</p>
</li>
<li class="lvl-2">
<p>随后的增量备份中，比较表空间每页 LSN 是否大于上次备份的检查点 LSN，是则备份该页并更新当前检查点 LSN</p>
</li>
</ul>
<h4 id="3-5-2-1-quan-liang-bei-fen">3.5.2.1 全量备份</h4>
<pre><code class="language-shell">root@ubuntu:~# innobackupex 
	--defaults-file=/etc/mysql/my.cnf
	--user=root
	--password="123456"
	--backup /mysqlBackup/
</code></pre>
<h4 id="3-5-2-2-zeng-liang-bei-fen">3.5.2.2 增量备份</h4>
<pre><code class="language-shell">root@ubuntu:~# innobackupex 
 	--defaults-file=/etc/mysql/my.cnf 
 	--user=root 
 	--password=123456 
 	--incremental /backup/ 			# 增量备份文件目录
	--incremental-basedir=/mysqlBackup/2023-08-20_22-09-29/		# 上次全备或增量备份的目录
</code></pre>
<h4 id="3-5-2-3-hui-fu">3.5.2.3 恢复</h4>
<p>保证原数据目录为空</p>
<pre><code class="language-shell">root@ubuntu:~# innobackupex 
	--apply-log /mysqlBackup/2023-08-20_22-09-29/
	--incremental-dir=/mysqlBackup/2023-08-20_22-09-29/
</code></pre>
<h1 id="bei-fen-jiao-ben">备份脚本</h1>
<h2 id="shell-jiao-ben">shell 脚本</h2>
<pre><code class="language-shell">root@ubuntu:~# cat backup_mysql_db.sh 
#!/bin/bash

#保存备份个数，备份30天数据
number=30

#备份保存路径
backup_dir=/root/mysql_backup

#日期
dd=`date +%Y-%m-%d-%H-%M-%S`

#备份工具
tool=mysqldump

# 被备份的DB信息
username=root
password=123456
database_name=test

if [ ! -d $backup_dir ]; then
    mkdir -p $backup_dir;
fi

$tool -u $username -p$password $database_name &gt; $backup_dir/$database_name-$dd.sql

echo "create $backup_dir/$database_name-$dd.dupm" &gt;&gt; $backup_dir/log.txt

#找出需要删除的备份
delfile=`ls -l -crt $backup_dir/*.sql | awk '{print $9 }' | head -1`

#判断现在的备份数量是否大于$number
count=`ls -l -crt $backup_dir/*.sql | awk '{print $9 }' | wc -l`

if [ $count -gt $number ];then
    #删除最早生成的备份，只保留number数量的备份
    rm $delfile
    #写删除文件日志
    echo "delete $delfile" &gt;&gt; $backup_dir/log.txt
fi

root@ubuntu:~# 
</code></pre>
<p>执行结果：</p>
<pre><code class="language-shell">root@ubuntu:~# bash backup_mysql_db.sh 
mysqldump: [Warning] Using a password on the command line interface can be insecure.
root@ubuntu:~# cd mysqlbackup/
root@ubuntu:~/mysql_backup# ll
total 20
drwxr-xr-x 2 root root 4096 Aug 21 14:27 ./
drwx------ 7 root root 4096 Aug 21 14:27 ../
-rw-r--r-- 1 root root  110 Aug 21 14:27 log.txt
-rw-r--r-- 1 root root 3067 Aug 21 14:27 test-2023-08-21-14-27-33.sql
root@ubuntu:~/mysql_backup# 
</code></pre>
<h2 id="python-jiao-ben">python脚本</h2>
<pre><code class="language-python">#!/usr/bin/python
# -*- coding:utf-8 -*-

import os
import time
import logging
import pymysql
import datetime
import subprocess

# log format
logging.basicConfig(format='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s:%(message)s',level=logging.INFO)

# MySQL database details to which backup to be done. Make sure below user having enough privileges to take databases backup.
MYSQL_HOST = 'XXX.XXX.XXX.XXX'
MYSQL_USERNAME = 'XXX'
MYSQL_PORT = 3306
MYQSL_PASSWORD = 'XXX'
DISABLED_DATABASES = {'information_schema', 'mysql', 'performance_schema', 'sys'}
BACKUP_PATH = '/backup/mysql/'
# Getting current datetime to create seprate backup folder.
DATETIME = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
TODAYBACKUPPATH = BACKUP_PATH + MYSQL_HOST + '/' + DATETIME
DAY = 30


def mkdir_if_not_exists(path):
    if not os.path.exists(path):
        os.makedirs(path)
        logging.info("Creating backup folder %s", path)
    else:
        logging.info("Path %s exists, no need to create it", path)


def create_mysql_conn(db="mysql"):
    conn = pymysql.connect(host=MYSQL_HOST, port=MYSQL_PORT, user=MYSQL_USERNAME,
                           password=MYQSL_PASSWORD, db='mysql')
    return conn


def read_all_databases():
    logging.info('Get all of database names from MySQL')

    conn = create_mysql_conn()
    cursor = conn.cursor()
    cursor.execute('show databases')
    res = cursor.fetchall()
    databases = {item[0] for item in res}
    databases = list(databases - DISABLED_DATABASES)
    cursor.close()
    conn.close()

    logging.info('End to get all of database nemes, now get %s', databases)

    return databases


def backup_database(database):
    logging.info('Start to bakcup database {}...'.format(database))

    command = 'mysqldump -h%s -u%s -p%s %s | gzip &gt; %s/%s.sql.gz' % (
        MYSQL_HOST, MYSQL_USERNAME, MYQSL_PASSWORD, database, TODAYBACKUPPATH, database)

    try:
        subprocess.call(command, shell=True)
    except Exception as ex:
        logging.error('Raise error during backup database, backend return : (%s)', str(ex))

    logging.info('End to backup database %s', database)


def del_old_backup(path):
    old_folder = subprocess.Popen("find {}  -maxdepth 3  -mindepth 2 -mtime +{} -type d".format(path, DAY),stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True).communicate()

    logging.info('Now delete file : (%s)', old_folder)

    str_old_folder = old_folder[0].decode("utf-8", errors="ignore")
    logging.info("%s", str_old_folder)
    list_lid_folder = str_old_folder.split('\n')

    for folder in list_lid_folder:
        if folder.strip():
            logging.info("Delete %s", folder)
            os.system("rm -rf {}".format(folder))


def backup():
    mkdir_if_not_exists(TODAYBACKUPPATH)
    databases = read_all_databases()
    for database in databases:
        backup_database(database)
    del_old_backup(BACKUP_PATH)


if __name__ == '__main__':
    backup()
</code></pre>
<h1 id="bei-fen-my-sql-de-zui-jia-shi-jian">备份MySQL的最佳实践</h1>
<p>以下是最佳实践建议，可帮助在备份MySQL数据库时避免一些问题：</p>
<p>1、多种备份方式的组合使用</p>
<p>当备份MySQL数据库时，应使用多种备份方式的组合方式，以确保备份的完整性和稳定性。例如，使用逻辑备份和物理备份的组合，或使用热备和冷备的组合。</p>
<p>备份文件应保留在不同的地方（比如不同的存储主机上），以防止灾难性损失。</p>
<p>2、频繁备份</p>
<p>MySQL数据库应该经常备份，以尽可能减小数据损失。具体的备份频率应该根据业务需要来决定。</p>
<p>3、备份验证</p>
<p>备份文件在完成备份后应该加以验证，这将确保备份的文件完整无损且未被损坏。</p>
<p>4、备份恢复测试</p>
<p>应定期测试备份恢复演示，这将帮助确保备份可以成功地恢复，并且可以提供可靠的备份源。</p>
<p>演示环境尽量是另外一套测试环境，务必避免在生产环境上验证。</p>
<h1 id="jie-yu">结语</h1>
<p>MySQL备份和恢复是保护和维护数据的最基本的方法之一， 结合业务本身，制定合理、合规的备份策略进行备份，保护企业宝贵数据，确保它们用于处于安全保护状态。</p>
]]></content>
      <categories>
        <category>python</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql 增量备份</title>
    <url>/2023/08/22/mysql_auto_backup/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍使用python开发一自动备份MySQL数据库工具，完成MySQL数据库定期备份动作。</p>
<h1 id="huan-jing">环境</h1>
<pre><code class="language-shell">root@ubuntu:~# hostnamectl 
   Static hostname: ubuntu
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 2e28c320b7b64edcb7b039f56050833c
           Boot ID: 928ff3a2a9ef430ba5b923b0d119902f
    Virtualization: vmware
  Operating System: Ubuntu 18.04.6 LTS
            Kernel: Linux 5.4.0-84-generic
      Architecture: x86-64
root@ubuntu:~# mysql --version
mysql  Ver 14.14 Distrib 5.7.42, for Linux (x86_64) using  EditLine wrapper
root@ubuntu:~# 
</code></pre>
<p>并创建了一个名称为 'test’的数据库，存放一张表（user）和一个视图（user_view）：</p>
<pre><code class="language-shell">mysql&gt; create table user (name VARCHAR(25), age INT(3));
Query OK, 0 rows affected (0.02 sec)

mysql&gt; insert into user(name, age) values('zhangsan', 30);
Query OK, 1 row affected (0.00 sec)

mysql&gt; insert into user(name, age) values('lisi', 31);
Query OK, 1 row affected (0.00 sec)

mysql&gt; insert into user(name, age) values('wangwu', 38);
Query OK, 1 row affected (0.00 sec)

mysql&gt; insert into user(name, age) values('cat', 2);
Query OK, 1 row affected (0.00 sec)

mysql&gt; create view user_view as select * from user;
Query OK, 0 rows affected (0.01 sec)

mysql&gt; show tables;
+----------------+
| Tables_in_test |
+----------------+
| user           |
| user_view      |
+----------------+
2 rows in set (0.00 sec)

mysql&gt; select * from tables;
ERROR 1146 (42S02): Table 'test.tables' doesn't exist
mysql&gt; select * from user;
+----------+------+
| name     | age  |
+----------+------+
| zhangsan |   30 |
| lisi     |   31 |
| wangwu   |   38 |
| cat      |    2 |
+----------+------+
4 rows in set (0.00 sec)

mysql&gt;
</code></pre>
<p>说明：</p>
<p>本文只是示例，所以创建的数据库test中表、视图无论结构还是数据量，都非常小，仅做示例使用。</p>
<h1 id="bei-fen-ce-lue">备份策略</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>借助innobackupex实现数据库的备份动作</p>
</li>
<li class="lvl-2">
<p>每天凌晨两点自动进行备份</p>
</li>
<li class="lvl-2">
<p>每周日进行一次全量备份，其他周天则进行增量备份</p>
</li>
<li class="lvl-2">
<p>备份目录保留30天</p>
</li>
</ul>
<p>如下图所示：</p>
<img class="shadow" src="/img/in-post/backup_mysql.bmp" width="1200">
<h1 id="bei-fen-jiao-ben">备份脚本</h1>
<p><code>mysql_backup.py</code> 内容如下：</p>
<pre><code class="language-python">root@ubuntu:~# cat mysql_backup.py 
#!/usr/bin/env python
# -*- coding: UTF-8 -*-

import datetime
import os
import sys
import commands 
import time
import logging
import subprocess

# Set log format
log_file = "/var/log/backup_mysql.log"
logging.basicConfig(format='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s:%(message)s',
                            level=logging.INFO, filename=log_file, filemode='a')

mysql_username = 'root'
mysql_password = 'p@ssw0rd'
incremental_backup_path = '/backup/mysql/incremental'
incremental_backup_base_path = '/backup/mysql/base/'
keep_days = 30
mysql_cnf = "/etc/mysql/my.cnf"


def mkdir_if_not_exists(path):
    if not os.path.exists(path):
        os.makedirs(path)
        logging.info("Creating backup folder %s", path)
    else:
        logging.info("Path %s exists, no need to create it", path)


def juge_weekday():
    cur_day = datetime.datetime.now().strftime("%Y-%m-%d")
    weeks = datetime.datetime.fromtimestamp(time.mktime(time.strptime(cur_day, "%Y-%m-%d"))).weekday() + 1

    return weeks


def full_backup_database(db='mysql'):
    complete_ok = False
    backup_base_path = ''
    full_backup_cmd = "innobackupex  --defaults-file={} --user={} --password={} " \
                      "--databases={} --backup {}".format(mysql_cnf, mysql_username,
                                                          mysql_password, db,
                                                          incremental_backup_base_path)

    logging.info("Start to full backup database : (%s)", db)

    output =  commands.getoutput(full_backup_cmd).strip()

    if 'completed OK' in output:
        complete_ok = True

    for each_line in output.split("\n"):
        if 'Backup created in directory' in each_line:
            backup_base_path = each_line.split()[-1].replace("'", '')

    if not os.path.exists(backup_base_path):
        logging.error("Not find backup base path, exit!!!")
        sys.exit(1)

    if complete_ok:
        logging.info("Full backup database : (%s) success", db)
    else:
        logging.error("Full backup database : (%s) failed, please view log : (%s)", db, output)
        sys.exit(1)


def get_latest_subdir():
    all_subdirs = [incremental_backup_base_path + os.sep + d for d in os.listdir(incremental_backup_base_path) if os.path.isdir(incremental_backup_base_path + os.sep + d)]
    if len(all_subdirs):
        latest_subdir = max(all_subdirs, key=os.path.getmtime)
        return latest_subdir
    else:
        logging.error("Not get apply log path!")
        return

def apply_log(backup_base_path, db='mysql'):
    complete_ok = False
    apply_cmd = "innobackupex --apply-log {}".format(backup_base_path)

    logging.info("Start to apply log")

    output =  commands.getoutput(apply_cmd).strip()
    if 'completed OK' in output:
        complete_ok = True

    if complete_ok:
        logging.info("Apply log : (%s) success", backup_base_path)
    else:
        logging.error("Apply log : (%s) failed, please view log : (%s)", backup_base_path, output)
        sys.exit(1)


def incremental_backup(backup_base_path, db='mysql'):
    complete_ok = False
    incremental_cmd = "innobackupex --defaults-file={} --user={}" \
                      "--password={} --databases={} --incremental {} " \
                      "--incremental-basedir={}".format(mysql_cnf, mysql_username,
                                                        mysql_password, db,
                                                        incremental_backup_path,
                                                        backup_base_path)

    logging.info("Start incremental backup database")

    output =  commands.getoutput(incremental_cmd).strip()
    if 'completed OK' in output:
        complete_ok = True

    if complete_ok:
        logging.info("Incremental backup database : (%s) success", db)
    else:
        logging.error("Incremental backup database : (%s) failed, please view log : (%s)", db, output)
        sys.exit(1)

    logging.info("Success to backup database : (%s)", db)


def del_old_backup(path):
    old_folder = subprocess.Popen("find {}  -maxdepth 3  -mindepth 2 -mtime +{} -type d".format(path, keep_days),stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True).communicate()
    if None not in old_folder:  # Find the folder
        logging.info('Now delete file : (%s)', old_folder)

        # str_old_folder = old_folder[0].decode("utf-8", errors="ignore")
        str_old_folder = old_folder[0]
        logging.info("%s", str_old_folder)
        list_lid_folder = str_old_folder.split('\n')

        for folder in list_lid_folder:
            if folder.strip():
                logging.info("Delete %s", folder)
                os.system("rm -rf {}".format(folder))
    else: #old_folder like this ('', None) if not find folders
        logging.info("No folders find under [{}] to delete, skip".format(path))


def loop_backup_mysql(db):
    weeks = juge_weekday()
    apply_log_path = get_latest_subdir()

    if apply_log_path:
        if weeks == 7:
            full_backup_database(db)
            new_apply_log_path = get_latest_subdir()
            if apply_log_path == new_apply_log_path:
                apply_log(apply_log_path, db)
            else:
                apply_log(new_apply_log_path, db)
        else:
            new_apply_log_path = get_latest_subdir()
            if apply_log_path == new_apply_log_path:
                incremental_backup(apply_log_path, db)
            else:
                incremental_backup(new_apply_log_path, db)
    else:
        # First time to backup, so run full backup
        full_backup_database(db)
        apply_log_path = get_latest_subdir()


if __name__ == '__main__':
    logging.info("-" * 80)
    # If path not exist, create it
    if not os.path.exists(incremental_backup_base_path):
        mkdir_if_not_exists(incremental_backup_base_path)

    if not os.path.exists(incremental_backup_path):
        mkdir_if_not_exists(incremental_backup_path)

    # Backup database
    db = 'test'
    loop_backup_mysql(db)

    # Delete old folders
    del_old_backup(incremental_backup_path)
    del_old_backup(incremental_backup_base_path)

root@ubuntu:~#
</code></pre>
<p><strong>说明：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>日志记录/var/log/backup_mysql.log 文件中</p>
</li>
<li class="lvl-2">
<p>‘/backup/mysql/base/’ 存放全量备份的数据库备份信息</p>
</li>
<li class="lvl-3">
<p>‘/backup/mysql/incremental’ 存放增量数据库的备份信息</p>
</li>
<li class="lvl-2">
<p>判断当前日期是星期几，如果结果是7表明为周日，则进行全量备份，否则进行增量备份</p>
</li>
<li class="lvl-2">
<p>无论是全量备份还是增量备份，备份目录下只保留30天的备份记录，过期目录将被清理掉（先备份后清理）</p>
</li>
</ul>
<h1 id="ding-shi-ren-wu-she-zhi">定时任务设置</h1>
<pre><code class="language-shell">0 2 * * * python /usr/local/bin/mysql_backup.py 
</code></pre>
<p>每天凌晨两点执行备份操作，备份脚本自动识别当前日期是星期几，如果是星期日，则进行全量备份；否则进行增量备份。</p>
<h1 id="hui-fu">恢复</h1>
<p>建议手工进行恢复，参考命令如下：</p>
<pre><code class="language-shell">root@ubuntu:~# innobackupex 
	--apply-log /mysql_backup/2023-08-21_23-19-39/
	--incremental-dir=/mysql_backup/2023-08-21_23-19-39/
</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>AI搜索引擎和代码辅助工具推荐</title>
    <url>/2023/09/03/ai_tools/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>AI 发展越来越快了，抽空搜集了几个好用的AI搜索引擎和代码生成辅助工具，mark之。</p>
<h1 id="ai-sou-suo-yin-qing">AI搜索引擎</h1>
<p>推荐两款好用的AI搜索引擎，如下表所示：</p>
<table>
<thead>
<tr>
<th>工具名称</th>
<th>网址</th>
<th>付费类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>秘塔</td>
<td><a href="https://metaso.cn">https://metaso.cn</a></td>
<td>免费</td>
<td>/</td>
</tr>
<tr>
<td>月之暗面kimi</td>
<td><a href="https://kimi.moonshot.cn">https://kimi.moonshot.cn</a></td>
<td>免费</td>
<td>/</td>
</tr>
</tbody>
</table>
<h1 id="ai-dai-ma-sheng-cheng-fu-zhu">AI代码生成辅助</h1>
<p>代码生成辅助工具可以显著提高开发效率，减少错误，缩短开发周期，并且使得非专业开发者也能更容易地编写和维护代码。然而，这些工具通常不能完全替代人类开发者，特别是在需要创造性思维和复杂问题解决的场景中。开发者仍然需要具备扎实的编程知识和经验，以确保生成的代码符合项目需求和质量标准。</p>
<p>推荐几款AI代码生成辅助工具，如下表所示：</p>
<table>
<thead>
<tr>
<th>工具名称</th>
<th>网址</th>
<th style="text-align:left">付费类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>BlackBox</td>
<td><a href="https://www.blackbox.ai/chat/expert-python">https://www.blackbox.ai/chat/expert-python</a></td>
<td style="text-align:left">免费</td>
<td>/</td>
</tr>
<tr>
<td>perplexity</td>
<td><a href="https://www.perplexity.ai">https://www.perplexity.ai</a></td>
<td style="text-align:left">免费</td>
<td>/</td>
</tr>
<tr>
<td>coze(扣子)</td>
<td>国内：<a href="https://www.coze.cn">https://www.coze.cn</a>  <br>国外：<a href="https://www.coze.com">https://www.coze.com</a></td>
<td style="text-align:left">免费</td>
<td>字节跳动旗下产品，分为国内和国外两个网址。<br>推荐国外版，且可免费使用GPT4 Turbo（需科学上网）。</td>
</tr>
<tr>
<td>ChatHi</td>
<td><a href="http://chat.aimoshu.cc">http://chat.aimoshu.cc</a></td>
<td style="text-align:left">收费</td>
<td>/</td>
</tr>
<tr>
<td>GitHub Copilot</td>
<td><a href="https://www.perplexity.ai">https://www.perplexity.ai</a></td>
<td style="text-align:left">收费</td>
<td>由GitHub、OpenAI、微软联合打造的一个全新的代码生成AI，堪称程序员的智能秘书。  需在Visual Studio Code中安装GitHub Copilot扩展方可使用。</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>借助pytest fixture优化测试用例</title>
    <url>/2023/09/10/pytest_testcase_optimization/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>近期碰到一个问题，信息如下:</p>
<pre><code class="language-python">from selenium import webdriver
from selenium.webdriver.common.by import By

URL = "www.google.com"

def test_click_1():
    driver = webdriver.Chrome()
    driver.get(URL)
    driver.find_element(
        By.XPATH,
        "div[contains(@class, 'item1')]"
    ).click()
    driver.close()


def test_click_2():
    driver = webdriver.Chrome()
    driver.get(URL)
    driver.find_element(
        By.XPATH,
        "div[contains(@class, 'item2')]"
    ).click()
    driver.close()


def test_click_3():
    driver = webdriver.Chrome()
    driver.get(URL)
    driver.find_element(
        By.XPATH,
        "div[contains(@class, 'item3')]"
    ).click()
    driver.close()
</code></pre>
<p>问：上述测试用例，如何优化？</p>
<h1 id="fen-xi">分析</h1>
<p>从示例用例来看，每个test_case中，都有driver的初始化和URL的get动作，以及close()动作；另外就是find_elements要做的事情，除了传递的XPATH元素不一样外，其他动作都一样，所以优化的点有：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>封装driver初始化与URL的get动作</p>
</li>
<li class="lvl-2">
<p>封装close动作</p>
</li>
<li class="lvl-2">
<p>优化find_elements，借助pytest.mark.parametrize实现参数化</p>
</li>
</ul>
<h1 id="you-hua-jie-guo">优化结果</h1>
<pre><code class="language-python">import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By

URL = "www.google.com"


@pytest.fixture()
def fixture_driver():
    driver = webdriver.Chrome()
    driver.get(URL)
    yield driver
    driver.close()


@pytest.mark.parametrize('item', ['item'+str(x) for x in range(1,4)])
def test_case(fixture_driver, item):
    driver.find_elements(By.XPATH, item).click()
</code></pre>
<p>经过优化后，测试用例更简洁、更契合pytest要求。</p>
<h1 id="jie-yu">结语</h1>
<p>这里的优化使用pytest的fixture特性，以及借助parametrize实现参数化。</p>
<p>对于pytest的fixture与pytest.mark.parametrize，近期会抽空整理一份示例并做说明。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest 之 fixture</title>
    <url>/2023/09/24/pytest_fixture_guide/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<h2 id="pytest-de-fixture-shi-shi-yao">pytest的fixture是什么？</h2>
<p>fixture是pytest的大杀器，是pytest特有的功能，是精髓所在，fixture有两种实现方式：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>xunit-style，跟unittest框架的机制非常相似，即setup/teardown系列</p>
</li>
<li class="lvl-2">
<p>自己的fixture机制，以@pytest.fixture装饰器来申明</p>
</li>
</ul>
<p>主要的目的是为了提供一种可靠和可重复性的手法去运行那些最基本的测试内容。</p>
<h2 id="pytest-you-shi">pytest优势</h2>
<p>从功能上看来，它与setup、teardown相似，但是优势明显，如下：</p>
<h3 id="strong-ming-ling-ling-huo-strong"><strong>命令灵活</strong></h3>
<p>​        对于setup.teardown，可以不起这两个名字，即不局限于setup和teardown这几个命名</p>
<h3 id="strong-shu-ju-gong-xiang-strong"><strong>数据共享</strong></h3>
<p>​    （1）在conftest.py配置里写的方法可以实现数据共享，不需要import导入，就能自动找到一些配置，可以跨文件共享</p>
<p>​    （2）按模块化的方式实现，每个fixture都可以互相调用</p>
<h3 id="strong-shi-xian-can-shu-hua-strong"><strong>实现参数化</strong></h3>
<p>​    @pytest.fixture()有5个参数，如下：</p>
<p><code>@pytest.fixture(scope="", params="", autouse="", ids="", name="") </code></p>
<p><strong>(1) scope</strong></p>
<p>scope的层次及神奇的yield组合相当于各种setup和teardown，可以跨函数function，类class，模块module或整个测试session范围</p>
<table>
<thead>
<tr>
<th>取值</th>
<th>范围</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>function</td>
<td>函数级</td>
<td>每个函数或方法都会调用</td>
</tr>
<tr>
<td>class</td>
<td>类级别</td>
<td>每个测试类只运行一次</td>
</tr>
<tr>
<td>module</td>
<td>模块级别</td>
<td>每一个.py文件只调用一次</td>
</tr>
<tr>
<td>package</td>
<td>包级</td>
<td>每一个python包只调用一次</td>
</tr>
<tr>
<td>session</td>
<td>会话级</td>
<td>每次会话只需要运行一次，会话内所有方法及类、模块都共享这个方法</td>
</tr>
</tbody>
</table>
<p><strong>(2) params</strong></p>
<p>参数化（支持，列表，元组，字典列表[{},{},{}]，字典元组({},{},{}) )</p>
<p>params将在下一篇文章中进行描述。</p>
<p><strong>(3) autouse</strong></p>
<p>自动执行fixture，默认False表示不开启，可以设置为True开启自动使用fixture功能，这样用例就不用每次都去传参了(自动调用fixture功能)。</p>
<p>使用autouse时，需要慎重，避免范围失控。</p>
<p><strong>(4) ids</strong></p>
<p>参数化时，给每一个值设置一个变量名</p>
<p>ids将在下篇文章，和params一起进行描述。</p>
<p><strong>(5) name</strong></p>
<p>给@pytest.fixture()标记的方法取一个别名，意义不大</p>
<h1 id="xunit-style-feng-ge">xunit-style 风格</h1>
<p>官方文档：</p>
<p><code>https://docs.pytest.org/en/stable/how-to/xunit_setup.html#xunitsetup</code> <a href="https://docs.pytest.org/en/stable/how-to/xunit_setup.html#xunitsetup">点击跳转</a></p>
<p>总结如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>每个级别的setup/teardown都可以多次复用</p>
</li>
<li class="lvl-2">
<p>如果相应的初始化函数执行失败或者被跳过则不会执行teardown方法</p>
</li>
</ul>
<h2 id="function-ji-bie">function级别</h2>
<p>示例：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


def setup_function(function):
    print('\nDo something before function')


def teardown_function(function):
    print('Do something after function')


def test_case_1():
    print('  Test function-1')


def test_case_2():
    print('  Test function-2')

</code></pre>
<p>文件命名为test_functionLevel.py</p>
<p><strong>输出结果：</strong></p>
<pre><code class="language-shell"># pytest -sq test_functionLevel.py

Do something before function
  Test function-1
.Do something after function

Do something before function
  Test function-2
.Do something after function

2 passed in 0.02s
</code></pre>
<div class="note info"><p><strong>说明：</strong></p>
</div>
<p>通过输出结果我们可以总结：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>setup_function会在每一个测试函数前执行初始化操作</p>
</li>
<li class="lvl-4">
<p>teardown_function会在每一个测试函数执行后执行销毁工作</p>
</li>
</ul>
<h2 id="method-ji-bie">method级别</h2>
<p>示例:</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


class TestMethod(object):

    def setup_method(self, method):
        print('\nBefore')

    def teardown_method(self, method):
        print('After')

    def test_case_1(self):
        print('Test case1')

    def test_case_2(self):
        print('Test case2')
</code></pre>
<p>文件命名为test_methodLevel.py</p>
<p><strong>输出结果</strong></p>
<pre><code class="language-shell">Before
Test case1
.After

Before
Test case2
.After

2 passed in 0.00s
</code></pre>
<div class="note info"><p><strong>说明：</strong></p>
</div>
<p>通过输出结果我们可以总结：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>setup_method会在每一个测试方法前执行初始化操作</p>
</li>
<li class="lvl-4">
<p>teardown_method会在每一个测试方法执行后执行销毁工作，且方法级别的fixture是作用在测试类中的方法上的</p>
</li>
</ul>
<h2 id="class-ji-bie">class级别</h2>
<p>示例</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


class TestClass(object):

    @classmethod
    def setup_class(cls):
        print('\nsetup_class() for {}'.format(cls.__name__))

    @classmethod
    def teardown_class(cls):
        print('teardown_class() for {}'.format(cls.__name__))

    def test_case_1(self):
        print('self.test_case_1()')

    def test_case_2(self):
        print('self.test_case_2()')
</code></pre>
<p>文件命名为test_classLevel.py</p>
<p><strong>输出结果</strong></p>
<pre><code class="language-shell"># pytest -sq test_classLevel.py

setup_class() for TestClass
self.test_case_1()
.self.test_case_2()
.teardown_class() for TestClass

2 passed in 0.02s
</code></pre>
<div class="note info"><p><strong>说明：</strong></p>
</div>
<p>通过输出结果我们可以总结：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>setup_class会在测试类执行前执行一次初始化操作</p>
</li>
<li class="lvl-4">
<p>teardown_class会在测试类执行后执行一次销毁工作，且class级别的fixture需要使用@classmethod装饰</p>
</li>
</ul>
<h2 id="module-ji-bie">module级别</h2>
<p>示例</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


def setup_module(module):
    print('\nsetup_module() for {}'.format(module.__name__))


def teardown_module(module):
    print('teardown_module() for {}'.format(module.__name__))


def test_case_1():
    print('test_case_1()')


def test_case_2():
    print('test_case_2()')


class TestClass(object):

    def test_case_3(self):
        print('self.test_case_3()')

    def test_case_4(self):
        print('self.test_case_4()')

</code></pre>
<p>文件命名为test_moduleLevel.py</p>
<p><strong>输出结果</strong></p>
<pre><code class="language-shell"># pytest -sq test_moduleLevel.py

setup_module() for test_moduleLevel
test_case_1()
.test_case_2()
.self.test_case_3()
.self.test_case_4()
.teardown_module() for test_moduleLevel

4 passed in 0.02s
</code></pre>
<div class="note info"><p><strong>说明：</strong></p>
</div>
<p>通过输出结果我们可以总结：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>setup_module会在测试函数或类执行前执行一次初始化操作</p>
</li>
<li class="lvl-4">
<p>teardown_module会在测试函数或类执行后执行一次销毁工作</p>
</li>
</ul>
<h1 id="pytest-de-fixture-shi-xian-fang-shi">pytest的fixture实现方式</h1>
<p>通过@pytest.fixture装饰器来定义fixture，一个函数被@pytest.fixture装饰，那么这个函数就是fixture。</p>
<p>使用fixture时，分为二个部分：fixture定义、fixture调用。</p>
<p>除此之外，还有fixture的共享机制，嵌套调用机制。</p>
<h2 id="ding-yi-fixture">定义fixture</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>fixture通过函数实现</p>
</li>
<li class="lvl-2">
<p>使用@pytest.fixture进行装饰</p>
<pre><code class="language-python">import pytest

@pytest.fixture()
def login_init():
    print("Start login option")
    yield 
    print("End of login")
</code></pre>
</li>
<li class="lvl-2">
<p>前置准备工作代码和后置清理工作代码，都写在一个函数里面</p>
</li>
<li class="lvl-2">
<p>通过yeild关键字，区分前置代码和后置代码 。yeild之前的代码为前置代码，yeild之后的代码为后置代码</p>
</li>
</ul>
<p>​        在实际应用场景当中，可以只有前置准备工作代码，也可以只有后置清理工作代码。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>fixture有4个作用域</p>
<p>测试会话(session)、测试模块(module)、测试类(class)、测试用例(function)</p>
</li>
</ul>
<p>​       测试会话：pytest执行测试用例的整个过程，称为会话。</p>
<p>​       比如pytest收集到了20条用例并执行完成，这个过程称为测试会话。</p>
<p>​       设置fixture的作用域：通过@pytest.fixture(scope=作用域)来设置。默认情况下，scope=function</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>fixture的返回值设置：yeild 返回值</p>
</li>
</ul>
<p>​        当测试用例当中，要使用fixture里生成的数据时，则需要fixture返回数据。</p>
<p>​        若有数据返回则：yeild 返回值</p>
<h2 id="diao-yong-fixture">调用fixture</h2>
<p>在fixture定义好之后，可以明确：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>fixture处理了哪些前置准备工作、哪些后置清理工作</p>
</li>
<li class="lvl-2">
<p>fixture作用在哪个范围(是测试函数？还是测试类？还是测试会话？还是测试模块？)</p>
</li>
</ul>
<p>在以上两点都定下来了之后，接下来就是在测试用例当中，根据需要调用不同的fixture。</p>
<p>调用方法有两种：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>在测试用例/测试类上面加上：@pytest.mark.usefixture(“fixture的函数名字”)</p>
</li>
<li class="lvl-2">
<p>将fixture函数名，作为测试用例函数的参数</p>
</li>
</ul>
<p>第2种用法，主要是用参数来接收fixture的返回值，以便在测试用例中使用。</p>
<p>第一种方式案例如下：</p>
<pre><code class="language-python">import pytest

@pytest.fixture()
def login_init():
    print("Start login option")
    yield 
    print("End of login")


@pytest.mark.usefixtures("login_init")
def test_login_case():
    print("This is a test case")
</code></pre>
<p>第二种方案如下：</p>
<pre><code class="language-python">import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By

URL = "www.google.com"


@pytest.fixture()
def fixture_driver():
    driver = webdriver.Chrome()
    driver.get(URL)
    yield driver
    driver.close()


def test_case(fixture_driver):
    # fixture_driver 作为参数传入测试用例，接收此函数的返回值driver
    # 即在当前测试用例内部，fixture_driver就是fixture返回的driver对象
    driver.find_elements(By.XPATH, 'item1').click()
</code></pre>
<p>上例中只传递一个fixture 函数作为参数，也可传递多个fixture作为参数：</p>
<pre><code class="language-python">@pytest.fixture()
def user():
    user = "Gavin"
    return user


@pytest.fixture()
def pwd():
    pwd = "123456"
    return pwd


@pytest.fixture()
def role():
    role = 'QA'
    return role


def test_trans_fixture(user, pwd, role):
    """   pass more than one fixture function   """
    print(user, pwd, role)
    assert "Gavin" in str(user)
    assert pwd == "123456"
    assert role == 'Software Tester Enginer'
</code></pre>
<h2 id="strong-fixture-qian-tao-strong"><strong>fixture嵌套</strong></h2>
<p>fixture不但支持共享 ，还支持嵌套使用。<strong>嵌套使用即：一个fixture，可以做另外一个fixture的参数。</strong></p>
<p>如下图所示：名为init2的fixture，可以作为init的参数。</p>
<p>并且，init当中，将init2的返回值，同样返回。</p>
<pre><code class="language-python">import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By

URL = "www.google.com"


@pytest.fixture()
def fixture_driver():
    driver = webdriver.Chrome()
    driver.get(URL)
    yield driver
    driver.close()


@pytest.fixture()
def fixture_button(fixture_driver):
    # fixture_driver 作为 fixture_button 的参数，当用例中调用 fixture_button 时，
    # fixture_button 会自动调用 fixture_driver
    print("I'm fixture_button, start")
    yield fixture_driver
    print("I'm fixture_button, end")
</code></pre>
<h2 id="fixture-de-qi-ta-yong-fa">Fixture的其他用法</h2>
<h3 id="ti-gong-ling-huo-de-lei-si-setup-he-teardown-gong-neng">提供灵活的类似setup和teardown功能</h3>
<p>pytest的fixture另一个强大的功能就是在函数执行前后增加操作，类似setup和teardown操作，但是比setup和teardown的操作更加灵活。具体使用方式是同样定义一个函数，然后用装饰器标记为fixture，然后在此函数中使用一个yield语句，yield语句之前的就会在测试用例之前使用，yield之后的语句就会在测试用例执行完成之后再执行。</p>
<pre><code class="language-python">import pytest

@pytest.fixture()
def run_function():
    print("Run before function...")
    yield
    print("Run after function...")

def test_case_1(run_function):
    print("case 1")

def test_case_2():
    print("case 2")

def test_case_3(run_function):
    print("case 3")
</code></pre>
<p>输出结果如下：</p>
<pre><code class="language-shell"># pytest -sq test_fixture.py
Run before function...
case 1
.Run after function...
case 2
.Run before function...
case 3
.Run after function...

3 passed in 0.02s
</code></pre>
<p>从结果可以看出，“test case 2” 并没有执行 run_function 这个fixture，因为没有传递这个fixture作为函数到 test_case_2；还有另外一个原因：run_function  这个fixture中没有携带autouse和scope参数，默认请看下 autouse=False, scope=“function”，如果更改成如下示例，就是另外一番场景了:</p>
<pre><code class="language-python">import pytest

@pytest.fixture(autouse=True, scope='function')
def run_function():
    print("Run before function...")
    yield
    print("Run after function...")

def test_case_1(run_function):
    print("case 1")

def test_case_2():
    print("case 2")

def test_case_3(run_function):
    print("case 3")
</code></pre>
<p>输出结果:</p>
<pre><code class="language-shell"># pytest -sq test_fixture.py
Run before function...
case 1
.Run after function...
Run before function...
case 2
.Run after function...
Run before function...
case 3
.Run after function...

3 passed in 0.02s
</code></pre>
<p>下文会介绍到autouse的用法，此处不做更详细描述。</p>
<h3 id="li-yong-pytest-mark-usefixtures-die-jia-strong-diao-yong-duo-ge-fixture-strong">利用pytest.mark.usefixtures叠加<strong>调用多个fixture</strong></h3>
<p>如果一个方法或者一个class用例想要同时调用多个fixture，可以使用@pytest.mark.usefixtures()进行叠加。注意叠加顺序，先执行的放底层，后执行的放上层。需注意：</p>
<p>① 与直接传入fixture不同的是，@pytest.mark.usefixtures无法获取到被fixture装饰的函数的返回值；</p>
<p>② @pytest.mark.usefixtures的使用场景是：被测试函数需要多个fixture做前后置工作时使用；</p>
<pre><code class="language-python">import  pytest


@pytest.fixture()
def fixture_func_1():
    print("Before Function 1")
    yield
    print("After Function 1")

@pytest.fixture()
def fixture_func_2():
    print("Before function 2")
    yield
    print("After Function 2")

@pytest.fixture()
def fixture_func_3():
    print("Before Function 3")
    yield
    print("After Function 3")


@pytest.mark.usefixtures("fixture_func_3")  # 最后执行fixture_func_3
@pytest.mark.usefixtures("fixture_func_2")  # 再执行fixture_func_2
@pytest.mark.usefixtures("fixture_func_1")  # 先执行fixture_func_1
def test_func():
    print("This is test case")
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell"># pytest -sq test_fixture3.py
Before Function 1
Before function 2
Before Function 3
This is test case
.After Function 3
After Function 2
After Function 1

1 passed in 0.02s
</code></pre>
<h3 id="fixture-zi-dong-shi-yong-autouse-true">fixture自动使用autouse=True</h3>
<p>当用例很多的时候，每次都传这个参数，会很麻烦。fixture里面有个参数autouse，默认是False没开启的，可以设置为True开启自动使用fixture功能，这样用例就不用每次都去传参了。</p>
<p>autouse设置为True，自动调用fixture功能，所有用例都会生效，<strong>包括类中的测试用例和类以外的测试用例</strong>。</p>
<p>示例：</p>
<pre><code class="language-python">import pytest


@pytest.fixture(autouse=True, scope="function")
def function_autouse():
    """   When autouse is True, each test case, this applies to every test case   """
    print("\n---Before---")
    yield
    print("---After---")

# function_autouse 函数的autouse=True时，无论是否使用usefixtures引用function_autouse, 
# 还是传递 function_autouse 到测试用例，都会执行function_autouse
@pytest.mark.usefixtures("function_autouse")
def test_case01():
    print("Test case 1")

def test_case02():
    print("Test case 2")

class Test:
    def test_case03(self):
        print("Test case 3")
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell"># pytest -sq test_fixture4.py

---Before---
Test case 1
.---After---

---Before---
Test case 2
.---After---

---Before---
Test case 3
.---After---

3 passed in 0.00s
</code></pre>
<h3 id="pytest-fixture-si-chong-zuo-yong-yu">Pytest fixture四种作用域</h3>
<pre><code class="language-python">fixture(scope='function'，params=None，autouse=False，ids=None，name=None)
</code></pre>
<p>上文有提到fixture的5种作用域，这里直接展示示例。</p>
<h4 id="function-ji-bie-1">function级别</h4>
<p>function默认模式为@pytest.fixture() 函数级别，即scope=“function”，scope可以不写。每一个函数或方法都会调用，每个测试用例执行前都会执行一次function级别的fixture。</p>
<pre><code class="language-python">import pytest


# @pytest.fixture(scope="function")等价于@pytest.fixture()
@pytest.fixture(scope="function")
def function_scope():
    """   Use-case level fixtures that scope individual test cases  """
    print("\nBefore function Level")
    yield
    print("After function Level")

# test_01会引用function_autouse函数，test_02没有用修饰器修饰，故不会引用
def test_case01(function_scope):
    print("func 1 print")

def test_case02():
    print("func 2 print")
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell"># pytest -sq test_fixture_scope_function.py

Before function Level
func 1 print
.After function Level
func 2 print
.
2 passed in 0.01s
</code></pre>
<h4 id="class-ji-bie-1">class级别</h4>
<p>fixture的scope值还可以是class，此时则fixture定义的动作就会在测试类class的所有用例之前和之后运行。</p>
<div class="note warning"><p><strong>注意：</strong></p>
</div>
<p>测试类中只要有一个测试用例的参数中使用了class级别的fixture，则在整个测试类的所有测试用例都会调用fixture函数。</p>
<h5 id="yong-li-lei-zhong-de-ce-shi-yong-li-diao-yong-fixture">用例类中的测试用例调用fixture</h5>
<p>执行fixture定义的动作，以及此测试类的所有用例结束后同样要运行fixture指定的动作</p>
<pre><code class="language-python">import pytest


@pytest.fixture(scope="class")
def class_level_autouse():
    """  A class-level fixture that scopes the entire class  """
    print("\n class Before")
    yield
    print("class after")


class TestClassAutoFixture:
    # class级别的fixture任意一个用例引用即可
    def test_class_auto_fixture_1(self, class_level_autouse):
        print("class 1 print")


    def test_class_auto_fixture_2(self):
        print("class 2 print")
</code></pre>
<p>测试类中的第1条测试用例引用了fixture修饰的函数，则整个测试类的所有测试用例都会执行fixture函数的前置操作，在所有用例执行完成后，都会执行fixture函数的后置操作。</p>
<p>输出结果如下：</p>
<pre><code class="language-shell"># pytest -sq test_class_level_autouse1.py

 class Before
class 1 print
.class 2 print
.class after

2 passed in 0.02s
</code></pre>
<h5 id="yong-li-lei-wai-de-ce-shi-yong-li-diao-yong-fixture">用例类外的测试用例调用fixture</h5>
<p>如果在类外的函数中去使用class级别的fixture，则此时在测试类外每个测试用例中，fixture跟function级别的fixture作用是一致的，即在类外的函数中引用了class级别的fixture，则在此函数之前和之后同样去执行fixture定义的对应的操作。</p>
<pre><code class="language-python">import pytest


@pytest.fixture(scope="class")
def class_scope():
    """  A class-level fixture that scopes the entire class  """
    print("\n class Before")
    yield
    print("class after")


class TestClassAutoFixture:
    # class级别的fixture任意一个用例引用即可
    def test_class_auto_fixture_1(self, class_scope):
        print("class 1 print")


    def test_class_auto_fixture_2(self):
        print("class 2 print")


def test_class_auto_fixture(class_scope):
    print("class 3 print")
</code></pre>
<p>如下文所示，测试类外的函数引用了class级别的fixture，则它的作用会等同于function级别的fixture，运行结果如下：</p>
<pre><code class="language-shell"># pytest -sq test_class_level_autouse2.py

 class Before
class 1 print
.class 2 print
.class after

 class Before
class 3 print
.class after

3 passed in 0.02s
</code></pre>
<h4 id="module-ji-bie-1">module级别</h4>
<p>在Python中module即.py文件（可以理解为当前的.py文件为一个测试suit，因为这个.py文件里含有一个或多个测试用例集合），当fixture定义为module时，则此fixture将在当前文件中起作用。</p>
<p>这里需要特别说明的是，当fixture的scope定义为module时，只要当前文件中有一个测试用例使用了fixture，不管这个用例是在类外，还是在类中，都会在当前文件（模块）的所有测试用例执行之前去执行fixture定义的行为以及当前文件的所有用例结束之后同样去执行fixture定义的对应操作。</p>
<pre><code class="language-python">import pytest


@pytest.fixture(scope="module")
def module_scope():
    """  Applies to the entire py file  """
    print("\nBefore module Level")
    yield
    print("After module Level-")
    
    
# 测试类外和测试类内的函数方法都调用了module级别的fixture，但整个py文件只会生效一次fixture。
def test_module_scope_out_class(module_scope):
    print("Yest case of scope")


class TestScope1:
    def test_scope_01(self):
        print("case scope 01")

    def test_scope_02(self, module_scope):
        print("case scope 02")

    def test_scope_03(self):
        print("case scope 03")
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell"># pytest -sq test_module_scope.py

Before module Level
Yest case of scope
.case scope 01
.case scope 02
.case scope 03
.After module Level-

4 passed in 0.01s

</code></pre>
<p>若类中的方法分别调用了class级别的fixture和module级别的fixture，则会两个fixture都生效：</p>
<pre><code class="language-python"># 顺序在前面fixture会先执行
def test_scope_01(self, module_scope, class_scope): 
    print("case scope 01")
</code></pre>
<p>若类中的方法同时调用了function级别、class级别、module级别的fixture，则3种fixture会同时生效：</p>
<pre><code class="language-python"># 顺序在前面fixture会先执行
def test_scope_02(self, module_scope, class_scope, function_scope):  
    print("case scope 02")
</code></pre>
<h4 id="session-ji-bie-shi-yong-conftest-py-gong-xiang-fixture">session级别(使用conftest.py共享fixture)</h4>
<p>当fixture的scope定义为session时，是指在当前目录下的所有用例之前和之后执行fixture对应的操作。</p>
<p><strong>fixture为session级别是可以跨.py模块调用</strong>的，也就是当我们有多个.py文件的用例的时候，如果多个用例只需调用一次fixture，那就可以设置为scope=“session”，并且写到conftest.py文件里。</p>
<p>使用方式：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>定义测试用例文件</p>
</li>
<li class="lvl-2">
<p>构建conftest.py内容</p>
</li>
</ul>
<div class="note info"><p><strong>说明：</strong></p>
</div>
<p>在指定目录下创建<code>conftest.py</code>文件[固定命名，不可修改]，然后在conftest.py文件中定义fixture方法，将scope指定为session，此时在当前目录下只要有一个用例使用了此fixture，则就会在当前目录下所有用例之前和之后会执行fixture定义的对应的操作。</p>
<pre><code class="language-python">import pytest

@pytest.fixture(scope="session")
def session_scope():
    """  A session-level fixture that works for all test cases in that directory  """
    print("\nUse case pre-operations at the session level")
    yield
    print("Post-operation of use cases at the session level")
</code></pre>
<p>定义了session级别的fixture，存放于该用例文件的同一个目录下的conftest.py文件中，该目录下的任一用例文件中的任一测试用例，引用了这个session级别的fixture，则这个session级别的fixture会针对这整个用例文件会生效。若存放在根目录下，则针对整个工程的所有用例都会生效。</p>
<pre><code class="language-python">class TestSessionScopeFixture:
    # session级别的fixture任意一个用例引用即可
    def test_session_scope_fixture_1(self, session_scope):
        print("session 1 print")

    def test_session_scope_fixture_2(self):
        print("session 2 print")


def test_session_scope_fixture():
    print("session 3 print")
</code></pre>
<p>运行结果如下：</p>
<pre><code class="language-shell"># pytest -sq test_fixture_session_scope.py

Use case pre-operations at the session level
session 1 print
.session 2 print
.session 3 print
.Post-operation of use cases at the session level

3 passed in 0.01s
</code></pre>
<h4 id="ids-can-shu-xiu-gai-yong-li-jie-guo-ming-cheng">ids参数-修改用例结果名称</h4>
<p>将在下一篇文字中，结合@pytest.mark.parametrize() 进行描述，本文忽略。</p>
<h4 id="name-can-shu-zhong-ming-ming-fixture-han-shu-ming-cheng">name参数-重命名fixture函数名称</h4>
<p>将在下一篇文字中，结合@pytest.mark.parametrize() 进行描述，本文忽略。</p>
<h4 id="params-can-shu-ti-gong-fan-hui-zhi-gong-ce-shi-han-shu-diao-yong">params参数-提供返回值供测试函数调用</h4>
<p>将在下一篇文字中，结合@pytest.mark.parametrize() 进行描述，本文忽略。</p>
<h4 id="nei-zhi-fixture">内置fixture</h4>
<h5 id="tmpdir-he-tmpdir-factory">tmpdir和tmpdir_factory</h5>
<p>内置的tmpdir和tmpdir_factory负责在测试开始运行前创建临时文件目录，并在测试结束后删除。</p>
<p>如果测试代码要对文件进行读/写操作，那么可以使用tmpdir或tmpdir_factory来创建文件或目录。单个测试使用tmpdir，多个测试使用tmpdir_factory。tmpdir的作用范围是函数级别，tmpdir_factory的作用范围是会话级别。</p>
<pre><code class="language-python">def test_tmpdir(tmpdir):
    # tmpdir already has a path name associated with it
    # join() extends the path to include a filename
    # the file is created when it's written to
    a_file = tmpdir.join('something.txt')

    # you can create directories
    a_sub_dir = tmpdir.mkdir('anything')

    # you can create files in directories (created when written)
    another_file = a_sub_dir.join('something_else.txt')

    # this write creates 'something.txt'
    a_file.write('contents may settle during shipping')

    # this write creates 'anything/something_else.txt'
    another_file.write('something different')

    # you can read the files as well
    assert a_file.read() == 'contents may settle during shipping'
    assert another_file.read() == 'something different'


def test_tmpdir_factory(tmpdir_factory):
    # you should start with making a directory
    # a_dir acts like the object returned from the tmpdir fixture
    a_dir = tmpdir_factory.mktemp('mydir')

    # base_temp will be the parent dir of 'mydir'
    # you don't have to use getbasetemp()
    # using it here just to show that it's available
    base_temp = tmpdir_factory.getbasetemp()
    print('base:', base_temp)

    # the rest of this test looks the same as the 'test_tmpdir()'
    # example except I'm using a_dir instead of tmpdir

    a_file = a_dir.join('something.txt')
    a_sub_dir = a_dir.mkdir('anything')
    another_file = a_sub_dir.join('something_else.txt')

    a_file.write('contents may settle during shipping')
    another_file.write('something different')

    assert a_file.read() == 'contents may settle during shipping'
    assert another_file.read() == 'something different'
</code></pre>
<h5 id="pytestconfig">pytestconfig</h5>
<p>内置的pytestconfig可以通过命令行参数、选项、配置文件、插件、运行目录等方式来控制pytest。</p>
<p>pytestconfig是request.config的快捷方式，它在pytest文档里有时候被称为“pytest配置对象”。</p>
<p>要理解pytestconfig如何工作，可以添加一个自定义的命令行选项，然后在测试中读取该选项。</p>
<pre><code class="language-python">def pytest_addoption(parser):
    """  Add a command line option  """
    parser.addoption(
        "--env", default="test", choices=["dev", "test", "pre"], help="enviroment parameter")
</code></pre>
<p>以 pytest_addoption 添加的命令行选项必须通过插件来实现，或者在项目顶层目录的conftest.py文件中完成。它所在的conftest.py不能处于测试子目录下。</p>
<p>上述是一个传入测试环境的命令行选项，接下来可以在测试用例中使用这些选项。</p>
<pre><code class="language-python">def test_option(pytestconfig):
    print('the current environment is:', pytestconfig.getoption('env'))

pytest -sq test_config.py::test_option
</code></pre>
<p>由于前面的 pytest_addoption 中定义的env的默认参数是test，所以通过 pytestconfig.getoption 获取到的env的值就是test。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>pylint 静态代码检查之 .pylintrc</title>
    <url>/2023/10/03/pylintrc_file/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>平时在vim中编写pytest用例和base class代码时，为了规范化代码风格与一些基本错误的静态代码检查，会借助pylint做代码检查，避免出现一些低级错误。</p>
<h1 id="pylintrc-nei-rong-shi-li-can-kao">.pylintrc内容示例参考</h1>
<p>如下是我自己常用的pylintrc file，pylint的详细信息，请参考官网： <a href="https://docs.pylint.org/#command-line-options">点击跳转</a></p>
<pre><code class="language-text">[MASTER]

# A comma-separated list of package or module names from where C extensions may
# be loaded. Extensions are loading into the active Python interpreter and may
# run arbitrary code
extension-pkg-whitelist=netifaces,xattr,lxml,rados,posix_ipc,

# Add files or directories to the blacklist. They should be base names, not
# paths.
ignore=CVS,nas-migrate

# Add files or directories matching the regex patterns to the blacklist. The
# regex matches against base names, not paths.
ignore-patterns=

# Python code to execute, usually for sys.path manipulation such as
# pygtk.require().
#init-hook=

# Use multiple processes to speed up Pylint.
jobs=1

# List of plugins (as comma separated values of python modules names) to load,
# usually to register additional checkers.
load-plugins=

# Pickle collected data for later comparisons.
persistent=yes

# Specify a configuration file.
#rcfile=

# Allow loading of arbitrary C extensions. Extensions are imported into the
# active Python interpreter and may run arbitrary code.
unsafe-load-any-extension=no


[MESSAGES CONTROL]

# Only show warnings with the listed confidence levels. Leave empty to show
# all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED
confidence=

# Disable the message, report, category or checker with the given id(s). You
# can either give multiple identifiers separated by comma (,) or put this
# option multiple times (only on the command line, not in the configuration
# file where it should appear only once).You can also use "--disable=all" to
# disable everything first and then reenable specific checks. For example, if
# you want to run only the similarities checker, you can use "--disable=all
# --enable=similarities". If you want to run only the classes checker, but have
# no Warning level messages displayed, use"--disable=all --enable=classes
# --disable=W"
disable=blacklisted-name,invalid-name,missing-docstring,empty-docstring,unneeded-not,singleton-comparison,misplaced-comparison-constant,unidiomatic-typecheck,consider-using-enumerate,consider-iterating-dictionary,bad-classmethod-argument,bad-mcs-method-argument,bad-mcs-classmethod-argument,single-string-used-for-slots,line-too-long,too-many-lines,trailing-whitespace,missing-final-newline,trailing-newlines,multiple-statements,superfluous-parens,bad-whitespace,mixed-line-endings,unexpecte-dline-ending-format,bad-continuation,wrong-spelling-in-comment,wrong-spelling-in-docstring,invalid-characters-in-docstring,multiple-imports,wrong-import-order,ungrouped-imports,wrong-import-position,old-style-class,len-as-condition,print-statement,parameter-unpacking,unpacking-in-except,old-raise-syntax,backtick,long-suffix,old-ne-operator,old-octal-literal,import-star-module-level,raw-checker-failed,bad-inline-option,locally-disabled,locally-enabled,file-ignored,suppressed-message,useless-suppression,deprecated-pragma,literal-comparison,no-self-use,no-classmethod-decorator,no-staticmethod-decorator,cyclic-import,duplicate-code,too-many-ancestors,too-many-instance-attributes,too-few-public-methods,too-many-public-methods,too-many-return-statements,too-many-branches,too-many-arguments,too-many-locals,too-many-statements,too-many-boolean-expressions,consider-merging-isinstance,too-many-nested-blocks,simplifiable-if-statement,redefined-argument-from-local,no-else-return,consider-using-ternary,trailing-comma-tuple,unreachable,dangerous-default-value,pointless-statement,pointless-string-statement,expression-not-assigned,unnecessary-pass,unnecessary-lambda,duplicate-key,deprecated-lambda,assign-to-new-keyword,useless-else-on-loop,exec-used,eval-used,confusing-with-statement,using-constant-test,lost-exception,assert-on-tuple,attribute-defined-outside-init,bad-staticmethod-argument,protected-access,arguments-differ,signature-differs,abstract-method,super-init-not-called,no-init,non-parent-init-called,useless-super-delegation,unnecessary-semicolon,bad-indentation,mixed-indentation,lowercase-l-suffix,wildcard-import,deprecated-module,relative-import,reimported,import-self,misplaced-future,fixme,invalid-encoded-data,global-variable-undefined,global-variable-not-assigned,global-statement,global-at-module-level,unused-import,unused-variable,unused-argument,unused-wildcard-import,redefined-outer-name,redefined-builtin,redefine-in-handler,undefined-loop-variable,cell-var-from-loop,bare-except,broad-except,duplicate-except,nonstandard-exception,binary-op-exception,property-on-old-class,logging-not-lazy,logging-format-interpolation,bad-format-string-key,unused-format-string-key,bad-format-string,missing-format-argument-key,unused-format-string-argument,format-combined-specification,missing-format-attribute,invalid-format-index,anomalous-backslash-in-string,anomalous-unicode-escape-in-string,bad-open-mode,boolean-datetime,redundant-unittest-assert,deprecated-method,apply-builtin,basestring-builtin,buffer-builtin,cmp-builtin,coerce-builtin,execfile-builtin,file-builtin,long-builtin,raw_input-builtin,reduce-builtin,standarderror-builtin,unicode-builtin,xrange-builtin,coerce-method,delslice-method,getslice-method,setslice-method,no-absolute-import,old-division,dict-iter-method,dict-view-method,next-method-called,metaclass-assignment,indexing-exception,raising-string,reload-builtin,oct-method,hex-method,nonzero-method,cmp-method,input-builtin,round-builtin,intern-builtin,unichr-builtin,map-builtin-not-iterating,zip-builtin-not-iterating,range-builtin-not-iterating,filter-builtin-not-iterating,using-cmp-argument,eq-without-hash,div-method,idiv-method,rdiv-method,exception-message-attribute,invalid-str-codec,sys-max-int,bad-python3-import,deprecated-string-function,deprecated-str-translate-call,assigning-non-slot,inconsistent-return-statements

# Enable the message, report, category or checker with the given id(s). You can
# either give multiple identifier separated by comma (,) or put this option
# multiple time (only on the command line, not in the configuration file where
# it should appear only once). See also the "--disable" option for examples.
enable=


[REPORTS]

# Python expression which should return a note less than 10 (10 is the highest
# note). You have access to the variables errors warning, statement which
# respectively contain the number of errors / warnings messages and the total
# number of statements analyzed. This is used by the global evaluation report
# (RP0004).
evaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)

# Template used to display messages. This is a python new-style format string
# used to format the message information. See doc for all details
#msg-template=

# Set the output format. Available formats are text, parseable, colorized, json
# and msvs (visual studio).You can also give a reporter class, eg
# mypackage.mymodule.MyReporterClass.
output-format=text

# Tells whether to display a full report or only the messages
reports=yes

# Activate the evaluation score.
score=yes


[REFACTORING]

# Maximum number of nested blocks for function / method body
max-nested-blocks=5


[VARIABLES]

# List of additional names supposed to be defined in builtins. Remember that
# you should avoid to define new builtins when possible.
additional-builtins=

# Tells whether unused global variables should be treated as a violation.
allow-global-unused-variables=yes

# List of strings which can identify a callback function by name. A callback
# name must start or end with one of those strings.
callbacks=cb_,_cb

# A regular expression matching the name of dummy variables (i.e. expectedly
# not used).
dummy-variables-rgx=_$|dummy

# Argument names that match this expression will be ignored. Default to name
# with leading underscore
ignored-argument-names=_.*

# Tells whether we should check for unused import in __init__ files.
init-import=no

# List of qualified module names which can have objects that can redefine
# builtins.
redefining-builtins-modules=six.moves,future.builtins


[FORMAT]

# Expected format of line ending, e.g. empty (any line ending), LF or CRLF.
expected-line-ending-format=

# Regexp for a line that is allowed to be longer than the limit.
ignore-long-lines=^\s*(# )?&lt;?https?://\S+&gt;?$

# Number of spaces of indent required inside a hanging  or continued line.
indent-after-paren=4

# String used as indentation unit. This is usually "    " (4 spaces) or "\t" (1
# tab).
indent-string='    '

# Maximum number of characters on a single line.
max-line-length=80

# Maximum number of lines in a module
max-module-lines=1000

# List of optional constructs for which whitespace checking is disabled. `dict-
# separator` is used to allow tabulation in dicts, etc.: {1  : 1,\n222: 2}.
# `trailing-comma` allows a space between comma and closing bracket: (a, ).
# `empty-line` allows space-only lines.
no-space-check=trailing-comma,dict-separator

# Allow the body of a class to be on the same line as the declaration if body
# contains single statement.
single-line-class-stmt=no

# Allow the body of an if to be on the same line as the test if there is no
# else.
single-line-if-stmt=no


[MISCELLANEOUS]

# List of note tags to take in consideration, separated by a comma.
notes=FIXME,XXX,TODO


[TYPECHECK]

# List of decorators that produce context managers, such as
# contextlib.contextmanager. Add to this list to register other decorators that
# produce valid context managers.
contextmanager-decorators=contextlib.contextmanager

# List of members which are set dynamically and missed by pylint inference
# system, and so shouldn't trigger E1101 when accessed. Python regular
# expressions are accepted.
generated-members=REQUEST,acl_users,aq_parent,sys,requests

# Tells whether missing members accessed in mixin class should be ignored. A
# mixin class is detected if its name ends with "mixin" (case insensitive).
ignore-mixin-members=yes

# This flag controls whether pylint should warn about no-member and similar
# checks whenever an opaque object is returned when inferring. The inference
# can return multiple potential results while evaluating a Python object, but
# some branches might not be evaluated, which results in partial inference. In
# that case, it might be useful to still emit no-member and other checks for
# the rest of the inferred objects.
ignore-on-opaque-inference=yes

# List of class names for which member attributes should not be checked (useful
# for classes with dynamically set attributes). This supports the use of
# qualified names.
ignored-classes=SQLObject,Connection,_socketobject

# List of module names for which member attributes should not be checked
# (useful for modules/projects where namespaces are manipulated during runtime
# and thus existing member attributes cannot be deduced by static analysis. It
# supports qualified module names, as well as Unix pattern matching.
ignored-modules=pyinotify,rados,rbd,_ped,xattr,snack,parted,ceph_argparse,pylibmc,gobject,dbus,ldap,avahi,rrdtool,prctl,common.tools,requests.packages.urllib3.exceptions,src.common.tools.trivial

# Show a hint with possible names when a member name was not found. The aspect
# of finding the hint is based on edit distance.
missing-member-hint=yes

# The minimum edit distance a name should have in order to be considered a
# similar match for a missing member name.
missing-member-hint-distance=1

# The total number of similar names that should be taken in consideration when
# showing a hint for a missing member.
missing-member-max-choices=1


[SIMILARITIES]

# Ignore comments when computing similarities.
ignore-comments=yes

# Ignore docstrings when computing similarities.
ignore-docstrings=yes

# Ignore imports when computing similarities.
ignore-imports=no

# Minimum lines number of a similarity.
min-similarity-lines=4


[SPELLING]

# Spelling dictionary name. Available dictionaries: none. To make it working
# install python-enchant package.
spelling-dict=

# List of comma separated words that should not be checked.
spelling-ignore-words=

# A path to a file that contains private dictionary; one word per line.
spelling-private-dict-file=

# Tells whether to store unknown words to indicated private dictionary in
# --spelling-private-dict-file option instead of raising a message.
spelling-store-unknown-words=no


[LOGGING]

# Logging modules to check that the string format arguments are in logging
# function parameter format
logging-modules=logging


[BASIC]

# Naming hint for argument names
argument-name-hint=(([a-z][a-z0-9_]{2,30})|(_[a-z0-9_]*))$

# Regular expression matching correct argument names
argument-rgx=[a-z_][a-z0-9_]{2,30}$

# Naming hint for attribute names
attr-name-hint=(([a-z][a-z0-9_]{2,30})|(_[a-z0-9_]*))$

# Regular expression matching correct attribute names
attr-rgx=[a-z_][a-z0-9_]{2,30}$

# Bad variable names which should always be refused, separated by a comma
bad-names=foo,bar,baz,toto,tutu,tata

# Naming hint for class attribute names
class-attribute-name-hint=([A-Za-z_][A-Za-z0-9_]{2,30}|(__.*__))$

# Regular expression matching correct class attribute names
class-attribute-rgx=([A-Za-z_][A-Za-z0-9_]{2,30}|(__.*__))$

# Naming hint for class names
class-name-hint=[A-Z_][a-zA-Z0-9]+$

# Regular expression matching correct class names
class-rgx=[A-Z_][a-zA-Z0-9]+$

# Naming hint for constant names
const-name-hint=(([A-Z_][A-Z0-9_]*)|(__.*__))$

# Regular expression matching correct constant names
const-rgx=(([A-Z_][A-Z0-9_]*)|(__.*__))$

# Minimum line length for functions/classes that require docstrings, shorter
# ones are exempt.
docstring-min-length=-1

# Naming hint for function names
function-name-hint=(([a-z][a-z0-9_]{2,30})|(_[a-z0-9_]*))$

# Regular expression matching correct function names
function-rgx=[a-z_][a-z0-9_]{2,30}$

# Good variable names which should always be accepted, separated by a comma
good-names=i,j,k,ex,Run,_

# Include a hint for the correct naming format with invalid-name
include-naming-hint=no

# Naming hint for inline iteration names
inlinevar-name-hint=[A-Za-z_][A-Za-z0-9_]*$

# Regular expression matching correct inline iteration names
inlinevar-rgx=[A-Za-z_][A-Za-z0-9_]*$

# Naming hint for method names
method-name-hint=(([a-z][a-z0-9_]{2,30})|(_[a-z0-9_]*))$

# Regular expression matching correct method names
method-rgx=[a-z_][a-z0-9_]{2,30}$

# Naming hint for module names
module-name-hint=(([a-z_][a-z0-9_]*)|([A-Z][a-zA-Z0-9]+))$

# Regular expression matching correct module names
module-rgx=(([a-z_][a-z0-9_]*)|([A-Z][a-zA-Z0-9]+))$

# Colon-delimited sets of names that determine each other's naming style when
# the name regexes allow several styles.
name-group=

# Regular expression which should only match function or class names that do
# not require a docstring.
no-docstring-rgx=__.*__

# List of decorators that produce properties, such as abc.abstractproperty. Add
# to this list to register other decorators that produce valid properties.
property-classes=abc.abstractproperty

# Naming hint for variable names
variable-name-hint=(([a-z][a-z0-9_]{2,30})|(_[a-z0-9_]*))$

# Regular expression matching correct variable names
variable-rgx=[a-z_][a-z0-9_]{2,30}$


[IMPORTS]

# Allow wildcard imports from modules that define __all__.
allow-wildcard-with-all=no

# Analyse import fallback blocks. This can be used to support both Python 2 and
# 3 compatible code, which means that the block might have code that exists
# only in one or another interpreter, leading to false positives when analysed.
analyse-fallback-blocks=no

# Deprecated modules which should not be used, separated by a comma
deprecated-modules=regsub,TERMIOS,Bastion,rexec

# Create a graph of external dependencies in the given file (report RP0402 must
# not be disabled)
ext-import-graph=

# Create a graph of every (i.e. internal and external) dependencies in the
# given file (report RP0402 must not be disabled)
import-graph=

# Create a graph of internal dependencies in the given file (report RP0402 must
# not be disabled)
int-import-graph=

# Force import order to recognize a module as part of the standard
# compatibility libraries.
known-standard-library=

# Force import order to recognize a module as part of a third party library.
known-third-party=enchant


[DESIGN]

# Maximum number of arguments for function / method
max-args=5

# Maximum number of attributes for a class (see R0902).
max-attributes=7

# Maximum number of boolean expressions in a if statement
max-bool-expr=5

# Maximum number of branch for function / method body
max-branches=12

# Maximum number of locals for function / method body
max-locals=15

# Maximum number of parents for a class (see R0901).
max-parents=7

# Maximum number of public methods for a class (see R0904).
max-public-methods=20

# Maximum number of return / yield for function / method body
max-returns=6

# Maximum number of statements in function / method body
max-statements=50

# Minimum number of public methods for a class (see R0903).
min-public-methods=2


[CLASSES]

# List of method names used to declare (i.e. assign) instance attributes.
defining-attr-methods=__init__,__new__,setUp

# List of member names, which should be excluded from the protected access
# warning.
exclude-protected=_asdict,_fields,_replace,_source,_make

# List of valid names for the first argument in a class method.
valid-classmethod-first-arg=cls

# List of valid names for the first argument in a metaclass class method.
valid-metaclass-classmethod-first-arg=mcs


[EXCEPTIONS]

# Exceptions that will emit a warning when being caught. Defaults to
# "Exception"
overgeneral-exceptions=Exception

</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest 之 pytest.ini</title>
    <url>/2023/10/22/pytest_pytest.ini/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>pytest 配置文件可以改变 pytest 的运行方式，它是一个固定的文件（名称固定，只能是 pytest.ini），读取配置信息，按指定的方式去运行。</p>
<p>pytest.ini 放在项目的根目录下。</p>
<p>简而言之，如果 pytest.ini 有该参数值，在执行的时候，先读取配置文件中的参数，然后取其他地方的（主函数/命令行中）。</p>
<h1 id="zhu-yi-dian">注意点</h1>
<p>pytest.ini 不能使用任何中文符号，包括汉字、空格、引号、冒号等等。</p>
<p>pytest 里面有些文件是非 test 文件</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>pytest.ini</code>：pytest 的主配置文件，可以改变 pytest 的默认行为</p>
</li>
<li class="lvl-2">
<p><code>conftest.py</code>：测试用例的一些 fixture 配置</p>
</li>
<li class="lvl-2">
<p><code>_init_.py</code>：识别该文件夹为 python 的 package 包</p>
</li>
<li class="lvl-2">
<p><code>tox.ini</code> 与 <code>pytest.ini</code> 类似，用 tox 工具时候才有用</p>
</li>
<li class="lvl-2">
<p><code>setup.cfg</code> 也是 ini 格式文件，影响 <code>setup.py</code> 的行为</p>
</li>
</ul>
<h1 id="na-xie-nei-rong-ke-yi-fang-zai-pytest-ini-wen-jian-zhong">哪些内容可以放在 pytest.ini 文件中</h1>
<p>pytest.ini 文件中的内容，来自于 <code> pytest --help</code>， 具体信息，请查阅help，每个参数都有描述说明。</p>
<h1 id="pytest-ini-shi-li">pytest.ini示例</h1>
<p>以下为我的project中使用的 pytest.ini 文件内容，参考如下：</p>
<pre><code class="language-text">[pytest]
log_cli = false
log_level = NOTSET
log_file = ../report/pytest_autotest.log
log_format = %(asctime)s [%(filename)s:%(lineno)-4s] [%(levelname)5s] %(message)s
log_date_format=%Y-%m-%d %H:%M:%S
log_file_format = %(asctime)s [%(filename)s:%(lineno)-4s] [%(levelname)5s] %(message)s
log_file_date_format=%Y-%m-%d %H:%M:%S
log_cli_level = INFO
log_cli_format = %(asctime)s [%(filename)s:%(lineno)-4s] [%(levelname)5s] %(message)s
log_cli_date_format=%Y-%m-%d %H:%M:%S

norecursedirs = .svn .git
console_output_style = count
addopts =-vrs --show-progress --cache-clear --full-trace -p no:warnings
</code></pre>
<p>这里我主要使用：</p>
<p>(1) log记录日志，规定了log level&amp;format&amp;path</p>
<p>(2) 要忽略扫描测试用例的目录（如上，忽略了.svn 和 .git 目录，因为pytest会全目录扫描，指定忽略相关目录，避免无效扫描）</p>
<p>(3) colsole output style</p>
<pre><code class="language-text">[pytest]
console_output_style = classic  #经典样式
console_output_style = progress #带有进度指示器的经典演示
console_output_style = count    #像progress,但将进度显示为已完成的测试数，而不是百分比
</code></pre>
<p>(4) addopts 更改默认命令行选项，经常要用到某些参数，又不想重复输入</p>
<pre><code class="language-text">addopts =  -vv        #以更详细的显示运行结果
           -m smoke   #被标记为 smoke 的用例
          --disable-warnings           # 禁用所有warnings，不建议使用，禁用范围过大, 等同于上面的 “-p no:warnings”
          --alluredir allure_results   # allure报告路径
          --maxfail=2 -rf              # 2个用例失败后退出，并给出详细信息
          --full-trace                 # 不截断任何的tracebacks，打印更详细的错误堆栈信息，默认是截断

</code></pre>
<h1 id="guan-yu-warnning">关于 warnning</h1>
<p>官网给的示例：<a href="https://docs.pytest.org/en/7.4.x/how-to/capture-warnings.html#pytest-mark-filterwarnings">点击跳转</a></p>
<pre><code class="language-python">import warnings
import pytest


def api_v1():
    warnings.warn(UserWarning("api v1, should use functions from v2"))
    return 1


# @pytest.mark.filterwarnings("ignore:api v1")
def test_one():
    assert api_v1() == 1

</code></pre>
<h2 id="jin-yong-warnings-de-fang-shi">禁用warnings的方式</h2>
<pre><code class="language-shell"># 禁用所有warnings，通常不使用，禁用范围过大
pytest  --disable-warnings

# 使用-W选项忽略warning， :: 表示具体的警告类名称   :表示匹配告警中msg的子串
pytest -W ignore::UserWarning
pytest -W "ignore:api v1"   # 这里的 "api v1"，为上面示例代码中 'warnings.warn(UserWarning("api v1, should use functions from v2"))' 的子串，下同
</code></pre>
<h2 id="shi-yong-zhuang-shi-qi-pytest-mark-filterwarnings">使用装饰器@pytest.mark.filterwarnings</h2>
<pre><code class="language-shell"># : 表示匹配告警信息中的msg的子串
@pytest.mark.filterwarnings("ignore:api v1") 

# :: 表示匹配告警信息中的告警类的类名，例如给出代码示例中的告警即可使用如下方式过滤告警

@pytest.mark.filterwarnings("ignore::UserWarning")
</code></pre>
<h2 id="zai-pytest-ini-zhong-jin-xing-gao-jing-guo-lu-gai-wen-jian-xu-yao-cun-fang-dao-xiang-mu-gen-mu-lu">在pytest.ini中进行告警过滤，该文件需要存放到项目根目录</h2>
<pre><code class="language-text">[pytest]
filterwarnings =
    ignore::UserWarning
    ignore::urllib3.exceptions.InsecureRequestWarning
</code></pre>
<h2 id="pytest-ini-zhong-jin-yong-warnings-cha-jian-fang-shi">pytest.ini 中禁用warnings插件方式</h2>
<pre><code class="language-text">[pytest]
addopts = -p no:warnings
</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest 之 conftest.py</title>
    <url>/2023/10/29/pytest_conftest/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p><code>conftest.py</code>文件是pytest框架里面一个很重要的东西，它可以在这个文件里面编写fixture函数，这个fixture函数的作用，就相当于Unittest框架里面的<code>setup()</code>前置函数和<code>teardown()</code>后置函数，虽然pytest框架也有<code>setup()</code>前置函数和<code>teardown()</code>后置函数，但是在实际工作中没必要写在测试用例文件中，直接写在<code>conftests.py</code>里面就好了，pytest框架会自动去找<code>conftest.py</code>文件里面的东西，这样更灵活。</p>
<p>可以看出 conftest.py是 fixture函数的一个集合， 提取公共部分放在这个文件里，然后供其它模块调用。不同于普通被调用的模块，conftest.py使用时不需要导入，pytest会自动查找。</p>
<p>在实际工作中，通常<code>conftest.py</code>和<code>@pytest.fixture()</code>结合使用，实现全局的前后置应用。</p>
<h1 id="conftest-py-shi-yong-chang-jing">conftest.py使用场景</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>每个接口用例需共用到的token/session/cookie</p>
</li>
<li class="lvl-2">
<p>每个接口用例需共用到的测试用例数据</p>
</li>
<li class="lvl-2">
<p>每个接口用例需共用到的配置信息</p>
</li>
</ul>
<p>​    …</p>
<p>简而言之：</p>
<p>​    多个py文件使用同一个前/后置函数，一个fixture函数，在很多case模块中都要用到。</p>
<h1 id="conftest-py-zhong-fixture-de-zuo-yong-yu">conftest.py中fixture的作用域</h1>
<p>fixture的scope参数也适用<code>conftest.py</code>文件中fixture的特性，即有如下范围：</p>
<table>
<thead>
<tr>
<th>取值</th>
<th>范围</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>function</td>
<td>函数级</td>
<td>每个函数或方法都会调用</td>
</tr>
<tr>
<td>class</td>
<td>类级别</td>
<td>每个测试类只运行一次</td>
</tr>
<tr>
<td>module</td>
<td>模块级别</td>
<td>每一个.py文件只调用一次</td>
</tr>
<tr>
<td>package</td>
<td>包级</td>
<td>每一个python包只调用一次</td>
</tr>
<tr>
<td>session</td>
<td>会话级</td>
<td>每次会话只需要运行一次，会话内所有方法及类、模块都共享这个方法</td>
</tr>
</tbody>
</table>
<h2 id="bu-tong-wei-zhi-conftest-py-wen-jian-de-you-xian-ji">不同位置conftest.py文件的优先级</h2>
<p><strong>其作用范围是当前目录包括子目录里的测试模块。</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>比如在测试框架的根目录创建<code>conftest.py</code>文件，文件中的fixture的作用范围是所有测试模块</p>
</li>
<li class="lvl-2">
<p>比如在某个单独的测试文件夹里创建<code>conftest.py</code>文件，文件中fixture的作用范围，就仅局限于该测试文件夹里的测试模块；该测试文件夹外的测试模块，或者该测试文件夹外的测试文件夹，是无法调用到这个<code>conftest.py</code>文件中的fixture。</p>
</li>
<li class="lvl-2">
<p>如果测试框架的根目录和子包中都有<code>conftest.py</code>文件，并且这两个<code>conftest.py</code>文件中都有一个同名的fixture，实际生效的是测试框架中子包目录下的<code>conftest.py</code>文件中配置的fixture(即此场景下子目录下的<code>conftest.py</code>会覆盖父目录的<code>conftest.py</code>)</p>
</li>
</ul>
<h1 id="shi-li">示例</h1>
<p>代码目录结构：</p>
<pre><code class="language-shell">root@Gavin:~/src# tree
.
├── clear_pyc.py
├── conftest.py
├── __init__.py
├── pytest.ini
└── testcase
    ├── account
    │&nbsp;&nbsp; ├── conftest.py
    │&nbsp;&nbsp; ├── __init__.py
    │&nbsp;&nbsp; └── test_account.py
    ├── __init__.py
    └── ldap
        ├── __init__.py
        └── test_ldap.py

3 directories, 10 files
root@Gavin:~/src# 
</code></pre>
<p>两个conftest.py内容参考如下：</p>
<pre><code class="language-python">root@Gavin:~/src# cat conftest.py 
import os
import pytest
import logging


@pytest.fixture(scope='package', autouse=True)
def testsuite_setup_teardown():
    logging.info('------------------------------------- Start to run test case ---------------------------------\n')
    yield
    logging.info('------------------------------------- End to run test case -----------------------------------')


@pytest.fixture(scope='function', autouse=True)
def testcase_setup_teardown():
    case_name = os.environ.get('PYTEST_CURRENT_TEST').split(':')[-1].split(' ')[0]

    logging.info('----------------------------------- Begin ----------------------------------------')
    logging.info('Current test case name : (%s)', case_name)
    yield
    logging.info('----------------------------------- End ------------------------------------------\n')
root@Gavin:~/src# cat testcase/account/conftest.py 
import pytest
import logging


@pytest.fixture(scope='function', autouse="true")
def testsuit_env_check():
    logging.info('----------- [testsuit_env_check] Begin ------------')

    logging.info('--------------- [testsuit_env_check] End ----------------\n')

root@Gavin:~/src# 
</code></pre>
<p>执行用例记录的日志：</p>
<pre><code class="language-shell">root@Gavin:~/src# cat ../report/pytest_autotest.log 
2023-10-30 06:50:48 [conftest.py:8   ] [ INFO] ------------------------------------- Start to run test case ---------------------------------

2023-10-30 06:50:48 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2023-10-30 06:50:48 [conftest.py:18  ] [ INFO] Current test case name : (test_account_01)
2023-10-30 06:50:48 [conftest.py:7   ] [ INFO] ----------- [testsuit_env_check] Begin ------------
2023-10-30 06:50:48 [conftest.py:9   ] [ INFO] --------------- [testsuit_env_check] End ----------------

2023-10-30 06:50:48 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2023-10-30 06:50:48 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2023-10-30 06:50:48 [conftest.py:18  ] [ INFO] Current test case name : (test_account_02)
2023-10-30 06:50:48 [conftest.py:7   ] [ INFO] ----------- [testsuit_env_check] Begin ------------
2023-10-30 06:50:48 [conftest.py:9   ] [ INFO] --------------- [testsuit_env_check] End ----------------

2023-10-30 06:50:48 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2023-10-30 06:50:48 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2023-10-30 06:50:48 [conftest.py:18  ] [ INFO] Current test case name : (test_ldap_01)
2023-10-30 06:50:48 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2023-10-30 06:50:48 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2023-10-30 06:50:48 [conftest.py:18  ] [ INFO] Current test case name : (test_ldap_02)
2023-10-30 06:50:48 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2023-10-30 06:50:48 [conftest.py:10  ] [ INFO] ------------------------------------- End to run test case -----------------------------------
root@Gavin:~/src#
</code></pre>
<p>从测试log看：</p>
<div style="display:inline-block;"><img width="100%" style="float:left; margin-right: 10px;" src="/img/in-post/conftest_scope.png"></div> 
<h1 id="jie-yu">结语</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>conftest.py文件名字是固定的，不能做任何修改，把hook或者fixture写在这个文件里，就会自动去调用</p>
</li>
<li class="lvl-2">
<p>文件和用例文件在同一个目录下，那么conftest.py作用于整个目录，即所有同目录测试文件运行前都会执行conftest.py文件</p>
</li>
<li class="lvl-2">
<p>conftest.py文件不能被其他文件导入</p>
</li>
<li class="lvl-2">
<p>pytest框架中的<code>setup()/teardown()</code>函数，<code>setup_class()/teardown_class()</code>函数，他们是作用于所有用例或者所有类的</p>
</li>
<li class="lvl-2">
<p><code>@pytest.fixtrue()</code>的作用域是既可以部分用例，也可以全部用例的前后置</p>
</li>
<li class="lvl-2">
<p><code>conftest.py</code>文件和<code>@pytest.fxtrue()</code>装饰器结合使用，作用于全局用例的前后置</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest fixture.mark.parametrize</title>
    <url>/2023/10/30/pytest_mark_parametrize/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>pytest中装饰器 <font color="red"><code>@pytest.mark.parametrize</code></font> 可以实现测试用例参数化，类似DDT。</p>
<p>pytest在几个级别上支持测试参数化：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>pytest.fixture()允许对fixture函数进行参数化</p>
</li>
<li class="lvl-2">
<p>@pytest.mark.parametrize允许在测试函数或类中定义多组参数和fixture</p>
</li>
<li class="lvl-2">
<p>pytest_generate_tests允许自定义参数化方案或扩展</p>
</li>
</ul>
<div class="note success"><p>语法格式如下：</p>
</div>
<pre><code class="language-shell">@pytest.mark.parametrize('参数名',list) 
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>第一个参数是字符串，多个参数中间用逗号隔开</p>
</li>
<li class="lvl-2">
<p>第二个参数是list多组数据用元组类型;传三个或更多参数也是这样传。list的每个元素都是一个元组，元组里的每个元素和按参数顺序 一 一 对应</p>
</li>
</ul>
<div class="note success"><p>示例：</p>
</div>
<ul class="lvl-0">
<li class="lvl-2">
<p>传一个参数 @pytest.mark.parametrize(‘参数名’，list) 进行参数化</p>
</li>
<li class="lvl-2">
<p>传两个参数@pytest.mark.parametrize(‘参数名1，参数名2’，[(参数1_data1, 参数2_data1),(参数1_data2, 参数2_data2)]) 进行参数化</p>
</li>
</ul>
<p>详细信息，请继续阅读下文。</p>
<h1 id="shi-yong-shi-li">使用示例</h1>
<h2 id="zhi-chuan-di-yi-ge-can-shu">只传递一个参数</h2>
<h3 id="yi-ge-can-shu-yi-ge-zhi">一个参数一个值</h3>
<p>示例代码如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


@pytest.mark.parametrize("name", ["Gavin"])
def test_case1(name):
    print("\n" + name)
    assert name.lower() == "gavin"
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;pytest -vrs --show-progress --cache-clear --full-trace C:\Users\Wang\Desktop\test_4.py
================================================= test session starts =================================================
platform win32 -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0 -- C:\Users\Wang\AppData\Local\Programs\Python\Python311\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\Wang
plugins: allure-pytest-2.13.2, order-1.1.0, progress-1.2.5, repeat-0.9.1, timeout-2.1.0
collected 1 item

Desktop/test_4.py::test_case1[Gavin] PASSED                                                                      [100%]
____________________ 1 of 1 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _____________________

================================================== 1 passed in 0.02s ==================================================

C:\Users\Wang&gt;
</code></pre>
<h3 id="yi-ge-can-shu-duo-ge-zhi">一个参数多个值</h3>
<p>这种比较常见，示例代码如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


@pytest.mark.parametrize("name", ["Gavin","Json","Bruce","Andy"])
def test_case1(name):
    print("\n" + name)
    assert name.lower() == "gavin"
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;pytest -vrs --show-progress --cache-clear C:\Users\Wang\Desktop\test_4.py
============================================================================================= test session starts ==============================================================================================
platform win32 -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0 -- C:\Users\Wang\AppData\Local\Programs\Python\Python311\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\Wang
plugins: allure-pytest-2.13.2, order-1.1.0, progress-1.2.5, repeat-0.9.1, timeout-2.1.0
collected 4 items

Desktop/test_4.py::test_case1[Gavin] PASSED                                                                                                                                                               [ 25%]
_________________________________________________________________ 1 of 4 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_4.py::test_case1[Json] FAILED                                                                                                                                                                [ 50%]
_______________________________________________________________________________________________ test_case1[Json] _______________________________________________________________________________________________

name = 'Json'

    @pytest.mark.parametrize("name", ["Gavin","Json","Bruce","Andy"])
    def test_case1(name):
        print("\n" + name)
&gt;       assert name.lower() == "gavin"
E       AssertionError: assert 'json' == 'gavin'
E         - gavin
E         + json

Desktop\test_4.py:10: AssertionError
--------------------------------------------------------------------------------------------- Captured stdout call ---------------------------------------------------------------------------------------------

Json
_________________________________________________________________ 2 of 4 completed, 1 Pass, 1 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_4.py::test_case1[Bruce] FAILED                                                                                                                                                               [ 75%]
______________________________________________________________________________________________ test_case1[Bruce] _______________________________________________________________________________________________

name = 'Bruce'

    @pytest.mark.parametrize("name", ["Gavin","Json","Bruce","Andy"])
    def test_case1(name):
        print("\n" + name)
&gt;       assert name.lower() == "gavin"
E       AssertionError: assert 'bruce' == 'gavin'
E         - gavin
E         + bruce

Desktop\test_4.py:10: AssertionError
--------------------------------------------------------------------------------------------- Captured stdout call ---------------------------------------------------------------------------------------------

Bruce
_________________________________________________________________ 3 of 4 completed, 1 Pass, 2 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_4.py::test_case1[Andy] FAILED                                                                                                                                                                [100%]
_______________________________________________________________________________________________ test_case1[Andy] _______________________________________________________________________________________________

name = 'Andy'

    @pytest.mark.parametrize("name", ["Gavin","Json","Bruce","Andy"])
    def test_case1(name):
        print("\n" + name)
&gt;       assert name.lower() == "gavin"
E       AssertionError: assert 'andy' == 'gavin'
E         - gavin
E         + andy

Desktop\test_4.py:10: AssertionError
--------------------------------------------------------------------------------------------- Captured stdout call ---------------------------------------------------------------------------------------------

Andy
_________________________________________________________________ 4 of 4 completed, 1 Pass, 3 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

========================================================================================= 3 failed, 1 passed in 0.06s ==========================================================================================

C:\Users\Wang&gt;
</code></pre>
<h2 id="duo-ge-can-shu">多个参数</h2>
<h3 id="duo-ge-can-shu-duo-ge-zhi">多个参数多个值</h3>
<p>下面是官网的示例：</p>
<pre><code class="language-python"># content of test_expectation.py
import pytest


@pytest.mark.parametrize("test_input,expected", [("3+5", 8), ("2+4", 6), ("6*9", 42)])
def test_eval(test_input, expected):
    assert eval(test_input) == expected
</code></pre>
<p>此示例，参考官网给出的另外一个方案：</p>
<p><code>https://docs.pytest.org/en/stable/how-to/parametrize.html </code> 下 “To parametrize all tests in a module, you can assign to the <a href="https://docs.pytest.org/en/stable/reference/reference.html#globalvar-pytestmark"><code>pytestmark</code></a> global variable:”</p>
<pre><code class="language-python">import pytest

pytestmark = pytest.mark.parametrize("test_input, expected", [("3+5", 8), ("2+4", 6), ("6*9", 42)])


def test_eval(test_input, expected):
    assert eval(test_input) == expected
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;pytest -vrs --show-progress --cache-clear C:\Users\Wang\Desktop\test_expectation.py
============================================================================================= test session starts ==============================================================================================
platform win32 -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0 -- C:\Users\Wang\AppData\Local\Programs\Python\Python311\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\Wang
plugins: allure-pytest-2.13.2, order-1.1.0, progress-1.2.5, repeat-0.9.1, timeout-2.1.0
collected 3 items

Desktop/test_expectation.py::test_eval[3+5-8] PASSED                                                                                                                                                      [ 33%]
_________________________________________________________________ 1 of 3 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_expectation.py::test_eval[2+4-6] PASSED                                                                                                                                                      [ 66%]
_________________________________________________________________ 2 of 3 completed, 2 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_expectation.py::test_eval[6*9-42] FAILED                                                                                                                                                     [100%]
______________________________________________________________________________________________ test_eval[6*9-42] _______________________________________________________________________________________________

test_input = '6*9', expected = 42

    @pytest.mark.parametrize("test_input,expected", [("3+5", 8), ("2+4", 6), ("6*9", 42)])
    def test_eval(test_input, expected):
&gt;       assert eval(test_input) == expected
E       AssertionError: assert 54 == 42
E        +  where 54 = eval('6*9')

Desktop\test_expectation.py:7: AssertionError
_________________________________________________________________ 3 of 3 completed, 2 Pass, 1 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

========================================================================================= 1 failed, 2 passed in 0.03s ==========================================================================================

C:\Users\Wang&gt;
</code></pre>
<h3 id="duo-ge-can-shu-de-hun-he-shi-yong">多个参数的混合使用</h3>
<p>示例代码如下（在官方示例代码上做了调整）：</p>
<pre><code class="language-python">import pytest


@pytest.mark.parametrize("x", [0, 1])
@pytest.mark.parametrize("y", [2, 3])
def test_foo(x, y):
    print("Generate new combinations : {},{}".format(x, y))
</code></pre>
<p>上面示例会产生4个测试用例，输出结果参考如下：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;pytest -vrs --show-progress --cache-clear C:\Users\Wang\Desktop\test_5.py
============================================================================================= test session starts ==============================================================================================
platform win32 -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0 -- C:\Users\Wang\AppData\Local\Programs\Python\Python311\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\Wang
plugins: allure-pytest-2.13.2, order-1.1.0, progress-1.2.5, repeat-0.9.1, timeout-2.1.0
collected 4 items

Desktop/test_5.py::test_foo[2-0] PASSED                                                                                                                                                                   [ 25%]
_________________________________________________________________ 1 of 4 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_5.py::test_foo[2-1] PASSED                                                                                                                                                                   [ 50%]
_________________________________________________________________ 2 of 4 completed, 2 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_5.py::test_foo[3-0] PASSED                                                                                                                                                                   [ 75%]
_________________________________________________________________ 3 of 4 completed, 3 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_5.py::test_foo[3-1] PASSED                                                                                                                                                                   [100%]
_________________________________________________________________ 4 of 4 completed, 4 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

============================================================================================== 4 passed in 0.02s ===============================================================================================

C:\Users\Wang&gt;
</code></pre>
<p>再看个示例：</p>
<pre><code class="language-python">data1 = [1, 2]
data2 = ["python", "Shell"]
data3 = ["Software", "Test", Engineer", "from", "Gavin"]


@pytest.mark.parametrize("a", data1)
@pytest.mark.parametrize("b", data2)
@pytest.mark.parametrize("c", data3)
def test_case3(a, b, c):
    print("[{a} {b} {c}]")
</code></pre>
<p>如上示例，会产生20个测试用例。</p>
<h2 id="can-shu-hua">参数化</h2>
<h3 id="chuan-ru-zi-dian-shu-ju">传入字典数据</h3>
<p>示例代码：</p>
<pre><code class="language-python">import pytest


json=({"username":"Json","password":"Python@123!"},{"username":"Alex","password":"226699"},{"username":"Rita","password":"123456"})

@pytest.mark.parametrize('json', json)
def test_pytest_parametrize(json):
    print(f'dit : \n{json}')
    print(f'username : {json["username"]}, password : {json["password"]}')
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;pytest -vs --show-progress --cache-clear C:\Users\Wang\Desktop\test_pytest_parameter.py
============================================================================================= test session starts ==============================================================================================
platform win32 -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0 -- C:\Users\Wang\AppData\Local\Programs\Python\Python311\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\Wang
plugins: allure-pytest-2.13.2, order-1.1.0, progress-1.2.5, repeat-0.9.1, timeout-2.1.0
collected 3 items

Desktop/test_pytest_parameter.py::test_pytest_parametrize[json0] dit :
{'username': 'Json', 'password': 'Python@123!'}
username : Json, password : Python@123!
PASSED
_________________________________________________________________ 1 of 3 completed, 1 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_pytest_parameter.py::test_pytest_parametrize[json1] dit :
{'username': 'Alex', 'password': '226699'}
username : Alex, password : 226699
PASSED
_________________________________________________________________ 2 of 3 completed, 2 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_pytest_parameter.py::test_pytest_parametrize[json2] dit :
{'username': 'Rita', 'password': '123456'}
username : Rita, password : 123456
PASSED
_________________________________________________________________ 3 of 3 completed, 3 Pass, 0 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

============================================================================================== 3 passed in 0.02s ===============================================================================================

C:\Users\Wang&gt;
</code></pre>
<h3 id="ji-he-biao-ji">集合标记</h3>
<p>示例代码：</p>
<pre><code class="language-python">import pytest


@pytest.mark.parametrize("username,password",
                         [("Json", "123456"), ("Jack", "654321"),
                          pytest.param("Bruce", "123456", marks=pytest.mark.xfail),
                          pytest.param("Alex", "123456", marks=pytest.mark.skip)])
def test_login(username, password):
    print(username + " : " + password)
    assert username == "Jack"
</code></pre>
<p>输出结果：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;pytest -vs --show-progress --cache-clear C:\Users\Wang\Desktop\test_multi_parameter.py
============================================================================================= test session starts ==============================================================================================
platform win32 -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0 -- C:\Users\Wang\AppData\Local\Programs\Python\Python311\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\Wang
plugins: allure-pytest-2.13.2, order-1.1.0, progress-1.2.5, repeat-0.9.1, timeout-2.1.0
collected 4 items

Desktop/test_multi_parameter.py::test_login[Json-123456] Json : 123456
FAILED
___________________________________________________________________________________________ test_login[Json-123456] ____________________________________________________________________________________________

username = 'Json', password = '123456'

    @pytest.mark.parametrize("username,password",
                             [("Json", "123456"), ("Jack", "654321"),
                              pytest.param("Bruce", "123456", marks=pytest.mark.xfail),
                              pytest.param("Alex", "123456", marks=pytest.mark.skip)])
    def test_login(username, password):
        print(username + " : " + password)
&gt;       assert username == "Jack"
E       AssertionError: assert 'Json' == 'Jack'
E         - Jack
E         + Json

Desktop\test_multi_parameter.py:10: AssertionError
_________________________________________________________________ 1 of 4 completed, 0 Pass, 1 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_multi_parameter.py::test_login[Jack-654321] Jack : 654321
PASSED
_________________________________________________________________ 2 of 4 completed, 1 Pass, 1 Fail, 0 Skip, 0 XPass, 0 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_multi_parameter.py::test_login[Bruce-123456] Bruce : 123456
XFAIL
_________________________________________________________________ 3 of 4 completed, 1 Pass, 1 Fail, 0 Skip, 0 XPass, 1 XFail, 0 Error, 0 ReRun _________________________________________________________________

Desktop/test_multi_parameter.py::test_login[Alex-123456] SKIPPED (unconditional skip)
_________________________________________________________________ 4 of 4 completed, 1 Pass, 1 Fail, 1 Skip, 0 XPass, 1 XFail, 0 Error, 0 ReRun _________________________________________________________________

=========================================================================================== short test summary info ============================================================================================
FAILED Desktop/test_multi_parameter.py::test_login[Json-123456] - AssertionError: assert 'Json' == 'Jack'
============================================================================== 1 failed, 1 passed, 1 skipped, 1 xfailed in 0.05s ===============================================================================

C:\Users\Wang&gt;
</code></pre>
<h1 id="xiang-mu-shi-jian">项目实践</h1>
<p>如下为在产品测试中使用到的 parameter 实战示例：</p>
<pre><code class="language-python">    @pytest.mark.parametrize('object_quota',
                             [-1, 0, 1, 1000, 1000000, 1000000000, 1000000000000, 1000000000000000, 1000000000000000000,
                              7168000000000000000])
    @pytest.mark.parametrize('size_quota',
                             [-1,0, 1024, 1048576, 1073741824, 1099511627776, 1125899906842624, 8070450532247928832])
    #@pytest.mark.parametrize('object_quota', [-1, 1])
    #@pytest.mark.parametrize('size_quota',[-1])
    def test_8_0_10647(self, object_quota, size_quota):
        logger.info("8_0-10647:Set value on User Max Size, User Max Objects, Bucket Max Size, Bucket Max Objects fielAccount Quota")
        TestClass.AccountCount = TestClass.AccountCount + 1
        account = "test_8_0_10604_" + str(self.rand_num) + "_" + str(TestClass.AccountCount)
        logger.info("Account: %s", account)
        self.cluster_api.Create_Account(account)
        self.radows.Set_Account_Quota(account, object_quota, size_quota)
        self.radows.Set_Account_Bucket_Quota(account, object_quota, size_quota)
        self.check_cluster_api.Check_Account_Quota(account, object_quota, size_quota)
</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest fixture of ids/name</title>
    <url>/2023/11/02/pytest_fixture_of_ids_name/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>pytest fixture 的ids，需要结合fixture的param使用，其作用是给测试用例名字增加标识，语法格式如下：</p>
<pre><code class="language-shell">@pytest.fixture(scope="", params="", autouse="", ids="", name="")
</code></pre>
<p>本文重点讲述一下ids，顺带介绍下name的用途。</p>
<h1 id="shi-li">示例</h1>
<p>未使用ids情况下</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


@pytest.fixture(params=['Parameter1', 'Parameter2'])
def my_fixture(request):
    return request.param


def test_fixtures_01(my_fixture):
    print('\n Run test_fixtures_01')
    print(my_fixture)


def test_fixtures_02(my_fixture):
    print('\n Run test_fixtures_02')
    print(my_fixture)

</code></pre>
<p>运行效果如下：</p>
<img class="shadow" src="/img/in-post/ids_no_ids.png" width="1200">
<p>带上ids</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


@pytest.fixture(params=['Parameter1', 'Parameter2'], ids=["id-01", "id-02"])
def my_fixture(request):
    return request.param


def test_fixtures_03(my_fixture):
    print('\n Run test_fixtures_03')
    print(my_fixture)


</code></pre>
<p>输出结果：</p>
<img class="shadow" src="/img/in-post/ids_with_ids.png" width="1200">
<p>从输出结果来看，"PASSED"前的中括号里的内容，如第一张图的<code>[Parameter1]</code> ，未携带ids情况下；而携带了ids后，会被ids对应值替换掉。</p>
<h1 id="li-yong-ids-shi-xian-ce-shi-xu-qiu">利用ids实现测试需求</h1>
<h2 id="chang-jing-miao-shu">场景描述</h2>
<p>购买AI智能体，支付状态有三种：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>下单未支付</p>
</li>
<li class="lvl-2">
<p>成功支付</p>
</li>
<li class="lvl-2">
<p>支付失败/放弃支付</p>
</li>
</ul>
<p>这三种状态对应数据库中三种值，分别为0，1，2。 利用ids方式，来简化测试用例。</p>
<h2 id="dai-ma-shi-li">代码示例</h2>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


def init_data(fixture_value):
    if fixture_value == 0:
        return "NoPay"
    elif fixture_value == 1:
        return "PaySuccess"
    elif fixture_value == 2:
        return "DropPay"


@pytest.fixture(params=[0, 1, 2], ids=init_data)
def my_AI_fixture(request):
    req_param = request.param
    print("\nParameter : [{}], status is : [{}]".format(req_param, req_param))
    yield req_param
    print("\n----------------------------------------")


def test_case_01(my_AI_fixture):
    print("\nRun [{}] test case".format(my_AI_fixture))
</code></pre>
<p>运行结果：</p>
<img class="shadow" src="/img/in-post/without_-k_parameter.png" width="1200">
<p>利用 -k 参数，指定要指定的测试用例：</p>
<img class="shadow" src="/img/in-post/with_-k_parameter.png" width="1200">
<div class="note warning"><p>注意:</p>
</div>
<p>-k 后面，字符串一定要使用双引号，单引号不可以。</p>
<p>-k的意思如下：</p>
<pre><code class="language-shell">  -k EXPRESSION    Only run tests which match the given substring expression. An expression is a Python evaluatable expression where all names are substring-matched against test names and their parent classes.
Example: -k 'test_method or test_other' matches all test functions and classes whose name contains 'test_method' or 'test_other', while -k 'not test_method' matches those that don't contain 'test_method' in their names. -k 'not test_method and not test_other' will eliminate the matches. Additionally keywords are matched to classes and functions containing extra names in their 'extra_keyword_matches' set, as well as functions which have names assigned directly to them. The matching is case-insensitive.
</code></pre>
<h1 id="shuo-yi-xia-name-can-shu">说一下 name 参数</h1>
<p>name参数实用性不大，用于给fixture设置别名，或者描述一下这个fixture的用途，示例如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


@pytest.fixture(params=['Parameter1', 'Parameter2'], ids=["id-01", "id-02"], name="Test_Fixture_Name_Daemon")
def my_fixture(request):
    return request.param


def test_fixtures_03(Test_Fixture_Name_Daemon):
    print('\n Run test_fixtures_03')
    print(my_fixture)

</code></pre>
<p>如上图所示，函数传递的fixture，变更成了name。</p>
<h2 id="wen-ti-ru-guo-fixture-zhong-shi-yong-liao-name-can-shu-ce-shi-han-shu-zhong-shi-fou-ke-yi-chuan-di-fixture-han-shu-ming-er-fei-name-dui-ying-zhi">问题：如果fixture中使用了name参数，测试函数中是否可以传递fixture 函数名而非name对应值？</h2>
<p>答案是否定的，测试如下：</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import pytest


@pytest.fixture(params=['Parameter1', 'Parameter2'], ids=["id-01", "id-02"], name="Test_Fixture_Name_Daemon")
def my_fixture(request):
    return request.param


def test_fixtures_03(my_fixture):
    print('\n Run test_fixtures_03')
    print(my_fixture)
</code></pre>
<p>如上，代码执行时报如下错误信息：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;pytest -vrs C:\Users\Wang\Desktop\test_0.py
================================================= test session starts =================================================
platform win32 -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0 -- C:\Users\Wang\AppData\Local\Programs\Python\Python311\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\Wang
plugins: allure-pytest-2.13.2, order-1.1.0, progress-1.2.5, repeat-0.9.1, timeout-2.1.0
collected 1 item

Desktop/test_0.py::test_fixtures_03 ERROR                                                                        [100%]

======================================================= ERRORS ========================================================
_________________________________________ ERROR at setup of test_fixtures_03 __________________________________________
file C:\Users\Wang\Desktop\test_0.py, line 39
  def test_fixtures_03(my_fixture):
E       fixture 'my_fixture' not found
&gt;       available fixtures: Test_Fixture_Name_Daemon, __pytest_repeat_step_number, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
&gt;       use 'pytest --fixtures [testpath]' for help on them.

C:\Users\Wang\Desktop\test_0.py:39
================================================== 1 error in 0.02s ===================================================

C:\Users\Wang&gt;
</code></pre>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>python3 升级pip后找不到pip模块</title>
    <url>/2023/11/09/no_module_named_pip_after_upgrade/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>原本未打算写这个文档的，之前碰到过，但是今天运维同事碰到了此问题，想起以前也碰到过，记录一下。</p>
<p>就目前碰到状况而言，此问题只在python3中发生过，并未在python2中遇见。</p>
<p>言归正传，此次使用的python3环境，提示要升级pip版本，按照要求进行了版本的升级，升级失败，再次尝试安装，提示pip缺失，如下图所示：</p>
<img class="shadow" src="/img/in-post/pip_module_error.png" width="1200">
<p>上图提示python “No module named pip”，升级后导致不能使用pip命令。</p>
<h1 id="yuan-yin">原因</h1>
<p>可能是新旧版本冲突或路径空格导致，尚未找到root cause。</p>
<h1 id="jie-jue-fang-fa">解决方法</h1>
<div class="note success"><h2 id="fang-an-1">方案1</h2>
</div>
<p>适用于windows/Mac/Linux系统</p>
<pre><code class="language-shell">python -m ensurepip
</code></pre>
<p>如下图所示(Windows下结果)：</p>
<img class="shadow" src="/img/in-post/pip_reinstall.png" width="1200">
<div class="note success"><h2 id="fang-an-2">方案2</h2>
</div>
<p>输入如下命令：</p>
<pre><code class="language-shell">curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
python get-pip.py --force-reinstall
</code></pre>
<div class="note success"><h2 id="fang-an-3">方案3</h2>
</div>
<pre><code class="language-shell">apt install --fix-missing python3-pip
</code></pre>
<h1 id="yan-zheng-an-zhuang">验证安装</h1>
<pre><code class="language-shell">pip show pip
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python监听日志变化</title>
    <url>/2023/11/13/monitor_error_log/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>测试过程中需要监控多个日志内容，防止有异常信息在测试过程中被错过，于是构思了这支Script，用于监控给定的Log，当发现list kws中定义的关键字时，自动发送钉钉告警到群组。</p>
<h1 id="dai-ma-shi-li">代码示例</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import time
import argparse
import requests


parser = argparse.ArgumentParser(description='Monitor exception from log files')
parser.add_argument("file_full_path", type=str)
args = parser.parse_args()


def send_notification(content):
    url = "https://oapi.dingtalk.com/robot/send?access_token=xxxxxxxx"
    data = {
        "msgtype": "text",
        "text": {
            "content": "监控报警: 在[{}]中发现异常日志：[{}]".format(args.file_full_path, content)
         }
    }

    res = requests.post(url, json=data)


def follow(file_handler):
    file_handler.seek(0, 2)
    while True:
        line = file_handler.readline()
        if not line:
            time.sleep(0.5)
            continue
        yield line



if __name__  == '__main__':
    kws = ["ERROR", "exception =", "INFO", "DEBUG"]  # Level of INFO and DEBUG, just for debug the script

    print("Monitor log : {}".format(args.file_full_path))
    with open(args.file_full_path, "r") as log_file:
        log_lines = follow(log_file)
        for line in log_lines:
            if (any(kw in line for kw in kws)):
                # print(line)
                send_notification(content)
</code></pre>
<p>执行过程示例如下：</p>
<pre><code class="language-shell">[qatest@iZbp1fl8ef9wkdizi6soq1Z ~]$ python monitor_debug_log.py "/mnt/logs/marketingservice/debug.log"
/usr/lib/python2.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (2.2.1) doesn't match a supported version!
  RequestsDependencyWarning)
Monitor log : /mnt/logs/marketingservice/debug.log

</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Allure Severity Level</title>
    <url>/2023/11/28/allure_severity_level/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>之前项目中一直使用allure来完成html可视化报告的输出，对于一些测试用例级别，如Bigtera使用的是TestLink，设置用例的级别为：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Release Acceptance Test(RAT)</p>
</li>
<li class="lvl-2">
<p>Functional Acceptance Simple Test(FAST)</p>
</li>
<li class="lvl-2">
<p>Task-Oriented Function Test(TOFT)</p>
</li>
<li class="lvl-2">
<p>Force-Error Test(FET)</p>
</li>
<li class="lvl-2">
<p>Boundary Test</p>
</li>
<li class="lvl-2">
<p>Volume Test</p>
</li>
<li class="lvl-2">
<p>Stress Test</p>
</li>
</ul>
<p>大概可以分为：RAT &gt; FAST &gt; TOFT = Boundary = FET &gt; Volume = Stress</p>
<p>也有的公司将用例级别定义为P0, P1, P2之类的级别，数字越小表明功能越核心，描述如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>P0： 核心功能测试用例（冒烟测试），确定此版本是否可测的测试用例，此部分测试用例如果fail会阻碍大部分其他测试用例的验证</p>
</li>
<li class="lvl-2">
<p>P1： 高优先级测试用例，最常执行以保证功能性是稳定的；基本功能测试，和重要的错误、边界测试</p>
</li>
<li class="lvl-2">
<p>P2： 中优先级测试用例，更全面的验证功能的各个方面，异常测试，边界、中断、断网、容错、UI等测试用例</p>
</li>
<li class="lvl-2">
<p>P3:  一般错误，错误不是很明星，小问题，客户要求改善需求体验等问题</p>
</li>
<li class="lvl-2">
<p>P4:  增加用户体验的建议问题，类似enhancement</p>
</li>
</ul>
<p>说了这么多，马上到本文要探讨的核心问题了：</p>
<p>allure支持的用例级别为:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>blocker</p>
</li>
<li class="lvl-2">
<p>critical</p>
</li>
<li class="lvl-2">
<p>normal</p>
</li>
<li class="lvl-2">
<p>minor</p>
</li>
<li class="lvl-2">
<p>trivial</p>
</li>
</ul>
<p>如何将各家自定义的用例级别与allure进行关联呢？</p>
<p>就是说，如何在allure中显示P0/P1/P2/P3 或者 RAT/FAST/TOFT/FET 之类的级别信息在allure html报告中？</p>
<p>一直想解决这个问题，但是allure原生就不支持哦。</p>
<h1 id="guo-cheng">过程</h1>
<p>搜索到一篇文章：<code>https://github.com/allure-framework/allure-js/issues/428</code></p>
<p>这篇文章介绍了作者如上的想法，结果作者以失败而告终。所以：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>修改js文件</p>
</li>
<li class="lvl-2">
<p>修改自己编写的测试用例中的自带级别</p>
</li>
</ul>
<p>上述两个方法，都是无法满足要求的。</p>
<p>于是我找了allure的源码：</p>
<p><code>allure2-2.24.1/allure-generator/src/main/javascript/components/graph-severity-chart/SeverityChartView.js</code></p>
<p>这个js文件中定义了用例的级别：</p>
<p><code>const severities = ["blocker", "critical", "normal", "minor", "trivial"];</code></p>
<p>在 <code>allure2-2.24.1/allure-generator/src/main/java/io/qameta/allure/severity/SeverityLevel.java</code>文件中定义了一个枚举类型：</p>
<pre><code class="language-shell">public enum SeverityLevel implements Serializable {

    BLOCKER("blocker"),
    CRITICAL("critical"),
    NORMAL("normal"),
    MINOR("minor"),
    TRIVIAL("trivial");
</code></pre>
<p>在allure安装好的路径下，查看了allure lib目录下的jar包，有一个名称为 <code>allure-generator-2.24.1.jar</code>， 这个文件很显然是<code>allure2-2.24.1/allure-generator/src/main/java/io/qameta/allure/severity/SeverityLevel.java</code> 所生成的jar包。</p>
<p>到这里，理论上修改java和js文件，重新编译生成jar包，替换掉  <code>allure-generator-2.24.1.jar</code>， 理论上是可以解决掉本文讨论的问题。由于个人没有java开发环境与IDE，就没有再继续往下尝试了。</p>
<h1 id="zong-shu">综述</h1>
<div class="note success"><p>方法一： 修改源码</p>
</div>
<p>修改 allure java源码重新生成jar。</p>
<div class="note success"><p>方法二： 修改用例中级别</p>
</div>
<p>修改测试用例中用例级别，使之匹配allure，比如直接修改数据库。</p>
<p>个人而言，看需要，对于一些无伤大雅的信息展示，无需花费过多时间，打磨更健壮的自动化测试框架才是重中之重，像更换allure默认logo，修改测试用例级别等等一些动作，都是锦上添花，有更好，无则也没啥损失。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>Allure</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Allure</tag>
      </tags>
  </entry>
  <entry>
    <title>《pytest测试指南》-- 前言 PREFACE</title>
    <url>/2023/12/18/pytest_test_guide_preface/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>想写这本书很久了，从2022年初开始规划，断断续续持续了近两年时间，中间因为众所周知的原因而中断了小半年，直至2023年下半年心绪稍微平复后方再续前章，预计2024年过年前能基本结束编写工作。草草的估算了一下书的内容，整体章节超过了600页，不自吹的说，它是目前国内最详细介绍<code>pytest</code>基础功能的一本书，结合了笔者分布式存储项目实践，完整的构建了一套基于Jenkins Pipline 的 CI/CD。现释放出一部分内容，供大家参考。部分内容，由于未来有其他规划/协议，部分释出的文章将加密，读者无密码将无法访问，敬请谅解。</p>
<p>以下内容，为《pytest测试指南》一书的前言。</p>
<h1 id="strong-qian-yan-preface-strong"><strong>前言 PREFACE</strong></h1>
<h1 id="zi-dong-hua-shi-shi-yao">自动化是什么</h1>
<p>自动化指的是利用技术手段，尤其是计算机和机械化的设备，来替代人类执行各种任务和过程。这个概念主要关涉到制造、控制系统（如自动控制）、通信、计算机技术、以及信息技术在内的广泛领域。</p>
<p>自动化的主要目标是提高效率、准确性和持续性。通过减少需要人力参与的工作量，自动化可以降低成本、提高产出、减少错误，并让人力资源得以从事更需要创造性和解决问题能力的工作。在某些场景下，自动化还可以提高安全性，特别是在执行危险或重复性较高的任务时。</p>
<p>在软件领域，自动化可能指：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>测试自动化</strong>：自动执行软件测试任务，包括但不限于单元测试、集成测试、系统测试和验收测试。</p>
</li>
<li class="lvl-2">
<p><strong>部署自动化</strong>：自动化地将软件部署到生产环境或其他测试环境。</p>
</li>
<li class="lvl-2">
<p><strong>业务流程自动化</strong>（BPA）：用软件自动执行重复的业务过程，以提高效率和减少错误。</p>
</li>
<li class="lvl-2">
<p><strong>办公自动化</strong>：使用计算机和软件工具来创建、收集、存储、操纵和传递办公室信息需要的数据和信息。</p>
</li>
</ul>
<p>在制造业和其他工业领域，自动化可能包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>机械化生产线</strong>：使用机器自动进行产品的组装。</p>
</li>
<li class="lvl-2">
<p><strong>工业控制系统</strong>：使用传感器、控制器等自动化工具监控和控制机械或化工过程。</p>
</li>
<li class="lvl-2">
<p><strong>机器人应用</strong>：在生产、搬运、检测、包装等领域使用机器人技术。</p>
</li>
</ul>
<p>自动化在社会各领域的应用日趋广泛，它正成为推动现代工业、提升生产力和创新能力的关键力量。</p>
<h1 id="wei-shi-yao-yao-zuo-zi-dong-hua-ce-shi">为什么要做自动化测试</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>减少手工测试占比</strong></p>
</li>
</ul>
<p>自动化测试可以替代大量的手工机械重复性操作，测试工程师可以把更多的时间和精力放在更重要的工作上。需要注意一点：自动化测试无法代替手工测试，二者相辅相成。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>降低人为错误</strong></p>
</li>
</ul>
<p>在进行软件测试的过程中，由于长时间、高强度或者大负荷的测试工作，导致测试效率和准确性下降，甚至出现错误的情况，这是典型的测试疲劳症状，而自动化测试具有一致性和重复性的特点，测试结果更客观，降低人为错误率，提高了软件测试的准确度、精确度和可信任度。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>提升回归效率</strong></p>
</li>
</ul>
<p>自动化测试可以大幅提升回归测试的效率，测试人员不用花费大量时间去校验原有功能的正确性，最大的优点是非常适合敏捷开发过程中，也就是加入到CI/CD中。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>持续测试系统的稳定</strong></p>
</li>
</ul>
<p>自动化测试可以高效实现某些手工测试无法完成或者代价巨大的测试类型，克服手工的局限性，比如关键核心业务需要7*24小时持续运行的稳定性测试。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>增加竞争力</strong></p>
</li>
</ul>
<p>随着测试行业的发展，测试人员的发展方向越来越广，技术方向也越来越多样化，更多的测试人员开始倾向于往高技术攀爬。而拥有自动化测试开发能力在以后很有可能是我们选择工作的敲门砖。虽然不少人都对这种变化感到惶恐不安，但是更多的人选择站在狂风处，迎接挑战，增加自身的竞业价值。</p>
<h1 id="strong-shi-yao-xiang-mu-gua-he-zi-dong-hua-ce-shi-strong"><strong>什么项目适合自动化测试</strong></h1>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>需求稳定，不频繁变更</strong></p>
</li>
</ul>
<p>测试脚本的稳定性决定了自动化测试的维护成本。如果软件需求变动过于频繁，测试人员需要根据变动的需求来更新测试用例以及相关的测试脚本，而脚本的维护本身就是一个代码开发的过程，需要修改，调试，必要的时候还要修改自动化框架，如果花费的成本高于其节省的成本，那么自动化测试是失败的。我们可以优先对项目中核心模块，相对稳定的模块进行自动化，而变动较大的仍是用手工测试。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>研发和维护周期长</strong></p>
</li>
</ul>
<p>由于自动化测试需求的确定，自动化测试框架的设计，测试脚本的编写与调试均需要相当长的时间来完成。这样的过程本身就是一个测试软件地开发过程，需要较长的时间来完成。如果项目周期比较短，没有足够的时间去支持这样一个过程，那么自动化测试便毫无意义。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>项目资源足够</strong></p>
</li>
</ul>
<p>自动化测试从需求范围的确定，到自动化测试框架的设计，以及脚本的编写与调试，均需要相当长的时间来完成。这样的过程本身就是一个测试软件的开发过程。因此有足够的人力，物力非常重要。</p>
<h1 id="ben-shu-jie-shao-liao-shi-yao">本书介绍了什么</h1>
<p>本书介绍python开源测试框架pytest，分两大章节，以pytest为核心，对每项实用技术进行详细阐述：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>第一章介绍pytest基础知识；</p>
</li>
<li class="lvl-2">
<p>第二章介绍接口自动化实践。</p>
</li>
</ul>
<p>第一章节分11个子章节，每个章节重点介绍pytest的特有特性，并给出完整的代码示例；第二章节为笔者所在公司项目的自动化测试框架设计与开发的介绍，并结合Jenkins实现了每日自动构建。</p>
<p>建议读者先将第一章基础技能夯实，牢牢掌握，再通过后续章节的内容来自己动手编写代码，在工作中实践，在实践中验证学习效果。在工作中可先进行接口测试自动化，再结合Jenkins部署执行，实现公司层面持续集成（CI）和持续部署交付（CD）的落地。</p>
<p>本书所涉及的非测试专业技术，例如Cobbler所涉及的网络方面的知识、Jenkins pipeline所涉及的技能、python语言编程技能知识等，读者可自行学习。</p>
<p>笔者相信，pytest框架在未来一定会大放异彩。</p>
<p>由于笔者水平有限，书中难免存在不妥之处，请读者见谅，并提宝贵意见。</p>
<h1 id="ben-shu-gua-yong-yu-na-xie-ren-qun">本书适用于哪些人群</h1>
<p>本书适用于以下人群：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>自动化测试初学者</p>
</li>
</ul>
<p>对于刚刚接触自动化测试的从业者或爱好者，这本书将是一个很好的起点。它提供了对pytest的基本介绍和指导，帮助读者了解如何使用pytest进行自动化测试。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>经验丰富的自动化测试人员即使是有经验的自动化测试人员，也可能需要回顾某些概念或深入了解某些高级特性。这本书提供了足够的详细信息，以满足这些需求。</p>
</li>
<li class="lvl-2">
<p>希望提高测试效率的开发者对于那些希望提高软件测试效率的开发者来说，这本书将提供有关如何使用pytest进行高效测试的实用建议。</p>
</li>
</ul>
<p>阅读这本书的基本要求包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>对基本的软件测试概念有一定的了解。</p>
</li>
<li class="lvl-2">
<p>熟悉Python编程语言，已具备Python编程的基础知识。</p>
</li>
<li class="lvl-2">
<p>对自动化测试有一定的兴趣和热情。这本书旨在帮助读者在实际项目中应用pytest，因此对自动化测试的兴趣和热情是必不可少的。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>《pytest测试指南》-- 第一章节 前言 PREFACE</title>
    <url>/2023/12/18/pytest_test_guide_part1_preface/</url>
    <content><![CDATA[<p>如下内容，为《pytest测试指南》一书第一大章的前言部分，此大章节共分为11个子章节，每个章节均会详细介绍<code>pytest</code>的特性，并给出完整的代码示例.</p>
<p>本章节为<code>pytest</code>基础知识，内容共分为11个子章节，介绍<code>pytest</code>的基础知识，以及<code>Allure Framework</code>。通过这11个章节的详尽介绍，读者将能够掌握<code>pytest</code>这一功能丰富的测试框架，理解如何运用<code>Allure</code>生成高质量的测试报告，最终提升Python项目的测试实践和质量保障工作。</p>
<h3 id="zhang-jie-1-1-chu-shi-pytest">章节 1-1 初识pytest</h3>
<p>在本章，我们将首先介绍几种常见的Python测试框架如unittest、nose和Unittest，并阐述它们各自的特点和适用场景。然后，我们将详细讲解如何安装和配置pytest，以及如何快速开始编写第一个pytest测试用例。我们还会探讨pytest的优点，比如简洁的语法、强大的功能集合、丰富的插件系统以及出色的可扩展性。</p>
<h3 id="zhang-jie-1-2-pytest-ce-shi-yong-li-zhi-xing">章节 1-2 pytest测试用例执行</h3>
<p>本章着重讲解pytest的用例收集机制，包括pytest如何发现测试文件和用例，以及如何按照特定顺序执行它们。我们还将介绍不同的命令行参数来运行测试用例。此外，我们将讲解pytest的结果状态，包括通过、失败、错误、跳过和xfail等，并解释每种状态的含义。</p>
<h3 id="zhang-jie-1-3-pytest-can-shu-xiang-jie">章节 1-3 pytest参数详解</h3>
<p>在此章节中，我们将深入探讨pytest的命令行参数，如何使用这些参数来自定义测试的执行过程和输出。从基本的设置到更复杂的过滤和选择参数，我们将指导用户如何进行有效的测试配置以适应不同的测试需求。</p>
<h3 id="zhang-jie-1-4-pytest-ce-shi-yong-li-biao-ji">章节 1-4 pytest测试用例标记</h3>
<p>这一部分将详细介绍pytest的标记功能，它允许你给测试添加标签以便对其进行分类或选择性执行。我们将学习如何定义自己的标记，如何使用标记来控制测试的执行，以及如何结合多个标记来实现复杂的测试选择逻辑。</p>
<h3 id="zhang-jie-1-5-pytest-duan-yan">章节 1-5 pytest断言</h3>
<p>断言是测试中验证结果的关键步骤。本章将介绍pytest中的断言机制，它如何区别于其他框架，并且会通过实例说明如何有效地使用断言来确保代码的正确性。同时，我们会探索pytest的断言重写功能，它提供了详细的比较输出，能帮助开发者快速定位问题。</p>
<h3 id="zhang-jie-1-6-pytest-jing-sui-fixture">章节 1-6 pytest精髓-fixture</h3>
<p>fixture是pytest中一个非常强大的特性，它提供了一种模块化和可重用的方式来设置代码的前提条件。在这一章中，我们将介绍fixture的基本概念和用法，如何创建和使用fixture，以及如何利用它们管理测试的上下文环境。</p>
<h3 id="zhang-jie-1-7-pytest-nei-zhi-fixture">章节 1-7 pytest内置fixture</h3>
<p>pytest提供了多种内置的fixture，用于提供常见的测试资源和管理测试生命周期。本章将对常用的内置fixture进行讲解，包括它们的功能和用法，以及如何在你的测试中合理地利用它们。</p>
<h3 id="zhang-jie-1-8-pytest-can-shu-hua">章节 1-8 pytest参数化</h3>
<p>参数化是提高测试效率和覆盖率的关键技巧。本章将探讨pytest的参数化功能，如何使用它来执行同一测试用例的多个变体。我们将通过丰富的示例来展示参数化测试的强大之处，以及如何将其与fixture结合使用。</p>
<h3 id="zhang-jie-1-9-pytest-pei-zhi-wen-jian">章节 1-9 pytest配置文件</h3>
<p>在本章，我们将详细介绍pytest的配置文件(pytest.ini, tox.ini, setup.cfg, pyproject.toml)，它们如何用于定义项目的测试配置，包括添加自定义标记、指定测试路径、插件配置等，以及警告的处理。</p>
<h3 id="zhang-jie-1-10-pytest-cha-jian">章节 1-10 pytest插件</h3>
<p>pytest通过丰富的插件生态提供了无限的扩展能力。本章节将带您了解如何利用已有的pytest插件来扩展测试功能，以及根据自己的测试需求定制和扩展pytest。</p>
<h3 id="zhang-jie-1-11-pytest-yu-allure-jie-he-sheng-cheng-ce-shi-bao-gao">章节 1-11 pytest与Allure结合生成测试报告</h3>
<p>在本章，我们将介绍如何使用Allure生成美观的测试报告。我们会讲解Allure的基本概念、pytest与Allure的集成方法，以及如何生成和定制化测试报告，让读者能够创建出既详细又易于理解的测试结果报告。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>《pytest测试指南》-- 章节1-1 初识pytest</title>
    <url>/2024/01/21/pytest_test_guide_part1_chapter1_getting_to_known_pytest/</url>
    <content><![CDATA[<h1 id="1-1-chang-jian-ji-chong-ce-shi-kuang-jia-dui-bi">1.1 常见几种测试框架对比</h1>
<p>笔者在过往工作经历中使用过几种测试框架，涉及unittest，nose，pytest 和 robot framework：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>unittest: Python自带，最基础的单元测试框架；</p>
</li>
<li class="lvl-2">
<p>nose: 基于unittest开发，易用性好，有许多插件；</p>
</li>
<li class="lvl-2">
<p>pytest: 同样基于unittest开发，易用性好，信息更详细，插件众多；</p>
</li>
<li class="lvl-2">
<p>robot framework：一款基于Python语言的关键字驱动测试框架，有界面，功能完善，自带报告及log清晰美观。</p>
</li>
</ul>
<p>简要对比信息参考如下：</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>unittest</th>
<th>nose</th>
<th>pytest</th>
<th>robot framework</th>
</tr>
</thead>
<tbody>
<tr>
<td>用例编写</td>
<td>继承unittest.TestCase类需要组织各种testSuite断言种类繁多</td>
<td>test开头的方法即可</td>
<td>test开头的方法即可</td>
<td>robot格式，文本文件</td>
</tr>
<tr>
<td>执行器</td>
<td>自己写run_all_tests+discover+CommandParser+…</td>
<td>nosetests …</td>
<td>py.test …</td>
<td>pybot …</td>
</tr>
<tr>
<td>用例发现Discover</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>跳过用例</td>
<td>unittest.skip()unittest.skipIf()raise uniitest.SkipTest</td>
<td>from nose.plugins.skip import SkipTestraise SkipTest</td>
<td>@pytest.mark.skipif( condition)@pytest.mark.xfail</td>
<td>-</td>
</tr>
<tr>
<td>Fixtures</td>
<td>setUp/tearDown@classmethodsetUpClass…</td>
<td>支持</td>
<td>@pytest.fixture(session=“session”, autouse=True)fixture的作用域：function、module、session ，autouse=True使得函数将默认执行</td>
<td>[Setup] …[Teardown] …</td>
</tr>
<tr>
<td>用例标签tags</td>
<td>借助unittest.skip()+comandParser实现</td>
<td>attrib标签from nose.plugins.attrib import attr@attr(speed=‘slow’)def test_big_download(): pass$ nosetests -a speed=slow</td>
<td>@pytest.mark.webtest自定义一个mark，如下，然后 py.test -v -m webtest 只运行标记了webtest的函数， py.test -v -m “not webtest” 来运行未标记webtest的</td>
<td>[Tags] test level1pybot -i/–include tagName C:\TF-Testpybot -e/–exculde level1 *.robot排除</td>
</tr>
<tr>
<td>超时机制Timeout</td>
<td>自己实现</td>
<td>from nose.tools import timedimport time@timed(1)def test_lean_5():time.sleep(2)pass</td>
<td>pip install pytest-timeout<br>@pytest.mark.timeout(60)或 pytest --timeout=300</td>
<td>[Timeout] 3 seconds</td>
</tr>
<tr>
<td>参数化</td>
<td>结合ddt使用</td>
<td>结合ddt使用</td>
<td>@pytest.mark.parametrize(“a,b,expected”, testdata)def test_timedistance_v0(a, b, expected):diff = a - bassert diff == expected</td>
<td>[Template] 1 2 3</td>
</tr>
<tr>
<td>报告</td>
<td>HTMLTestRunner</td>
<td>pip install nose-htmloutput<br>Usage: --with-html --html-file=<br>支持allure</td>
<td>pip install -U pytest-html<br>Usage: py.test --html=./report.html<br>支持allure</td>
<td>支持，默认自动生成</td>
</tr>
<tr>
<td>日志log</td>
<td>自己实现</td>
<td>–nologcapture 不使用log–logging-format=FORMAT使用自定义的格式显示日志–logging-datefmt=FORMAT 和上面类类似，多了日期格式–logging-filter=FILTER日志过滤，一般很少用，可以不关注–logging-clear-handlers 也可以不关注–logging-level=DEFAULT log的等级定义</td>
<td>pytest test_add.py --resultlog=./log.txtpytest test_add.py --pastebin=all</td>
<td>支持，默认自动生成</td>
</tr>
<tr>
<td>只列出用例collect-only</td>
<td>无</td>
<td>nosetests --collect-only/nosetests -v --with-id</td>
<td>–collect-only -v</td>
<td>无</td>
</tr>
<tr>
<td>失败用例重跑rerun failures</td>
<td>无</td>
<td>nosetests -v --failed</td>
<td>pip install -U pytest-rerunfailures@pytest.mark.flaky(reruns=5)py.test --rerun=3</td>
<td>robot --rerunfailed</td>
</tr>
<tr>
<td>baseline对比</td>
<td>无</td>
<td>无</td>
<td>无</td>
<td>无</td>
</tr>
<tr>
<td>并发</td>
<td>改造unittest使用协程并发，或使用线程池+Beautiful Report</td>
<td>命令行并发</td>
<td>pytest-xdist：分发到不用的cpu或机器上</td>
<td>命令行并发</td>
</tr>
<tr>
<td>xml报告</td>
<td>无</td>
<td>–with-xunit</td>
<td>–xunit-file=… /pytest+Allure</td>
<td>–junit-xml=</td>
</tr>
<tr>
<td>Selenium支持</td>
<td>无</td>
<td>无</td>
<td>pytest-selenium</td>
<td>robotframework-seleniumlibraryrobotframwork-selenium2library</td>
</tr>
<tr>
<td>APP支持</td>
<td>无</td>
<td>无</td>
<td>pytest-appium</td>
<td>robotframework-appiumlibrary</td>
</tr>
</tbody>
</table>
<p>总体来说：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>unittest比较基础，二次开发方便，适合高手使用；</p>
</li>
<li class="lvl-2">
<p>pytest/nose更加方便快捷，效率更高，适合小白及追求效率的公司；</p>
</li>
<li class="lvl-2">
<p>robot framework由于有界面及美观的报告，易用性更好，灵活性及可定制性略差。</p>
</li>
</ul>
<h1 id="1-2-chu-shi-pytest">1.2 初识pytest</h1>
<h2 id="1-2-1-pytest-shi-shi-yao">1.2.1 pytest是什么</h2>
<p><code>pytest</code> 是一种功能强大的测试框架，使用Python编程语言开发。它使得编写简单和可扩展的测试代码变得轻松。<code>pytest</code> 支持自动发现和运行测试，提供了丰富的参数、断言机制和插件支持。许多开发人员和公司都使用 <code>pytest</code> 作为编写和执行单元测试、集成测试以及功能、性测试的首选工具。</p>
<p>以下是 <code>pytest</code> 的一些关键特性：</p>
<p><strong>简单的测试编写：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用极简的<code>assert</code>语句，你可以不需要记住复杂的断言，直接对比期望和实际结果。</p>
</li>
<li class="lvl-2">
<p>不需要编写类或方法，普通函数就可以是测试函数。</p>
</li>
</ul>
<p><strong>自动测试发现：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>pytest</code> 可以自动发现以 <code>test_</code> 开头或<code>_test</code>结尾的文件和函数作为测试用例。</p>
</li>
</ul>
<p><strong>详细的测试结果报告：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>pytest</code> 提供详细的错误报告，当测试失败时，会显示哪一行代码失败以及失败的详细信息。</p>
</li>
</ul>
<p><strong>支持fixtures：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>通过使用<code>fixtures</code>，<code>pytest</code> 可以为测试提供创建/销毁和管理资源（如数据库连接、临时的文件等）。这种机制提供了可重用的功能以及设置和清除条件。</p>
</li>
</ul>
<p><strong>参数化测试：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用 <code>pytest.mark.parametrize</code> 装饰器可以轻松地对单个测试实现多个参数组合的测试。</p>
</li>
</ul>
<p><strong>插件系统：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>pytest</code> 有一个广泛的插件生态系统，你可以使用其他开发者写的插件或自己编写插件来扩展其功能。</p>
</li>
</ul>
<p><strong>可集成性：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>pytest</code> 可与许多其他测试和开发工具集成，如测试覆盖率工具 <code>coverage.py</code>，持续集成服务等。</p>
</li>
</ul>
<h2 id="1-2-2-pytest-kuang-jia-jie-gou">1.2.2 pytest框架结构</h2>
<p><code>pytest</code> 的框架结构包含若干核心组件以及配合这些组件使用的各种插件。下面详细介绍其主要组成部分：</p>
<h3 id="1-2-2-1-ce-shi-fa-xian-yu-zhi-xing">1.2.2.1 测试发现与执行</h3>
<p><strong>发现机制</strong>：<br>
<code>pytest</code> 会自动发现测试文件和测试函数。默认情况下，<code>pytest</code> 认为所有匹配 <code>test_*.py</code> 或 <code>*_test.py</code> 的文件是测试文件，并且这些文件中以 <code>test_</code> 开头的函数是测试函数。</p>
<p><strong>执行机制</strong>：当你运行 <code>pytest</code> 命令时，它会调用内部的测试发现机制，寻找所有可用的测试案例，并按照一定顺序执行它们。如果有测试失败，<code>pytest</code> 会提供详细的断言失败报告。</p>
<h3 id="1-2-2-2-cha-jian-xi-tong">1.2.2.2 插件系统</h3>
<p><code>pytest</code> 具有丰富的插件架构，允许通过安装第三方插件或创建自定义插件来扩展其功能。有许多官方和社区提供的插件，如：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>pytest-django</code>：用于Django项目的专有测试工具。</p>
</li>
<li class="lvl-2">
<p><code>pytest-asyncio</code>：为asyncio代码提供测试支持。</p>
</li>
<li class="lvl-2">
<p><code>pytest-xdist</code>：支持分布式测试和并行测试执行。</p>
</li>
<li class="lvl-2">
<p><code>pytest-cov</code>：集成覆盖率报告。</p>
</li>
<li class="lvl-2">
<p><code>pytest-allure</code>：结合allure生成漂亮的可视化html测试报告。</p>
</li>
</ul>
<p>插件可以通过钩子（hook）函数来扩展 <code>pytest</code> 的行为。这些钩子会在测试运行的各个阶段被调用。</p>
<h3 id="1-2-2-3-pei-zhi-wen-jian">1.2.2.3 配置文件</h3>
<p><code>pytest</code> 允许使用配置文件来定制测试行为。最常见的配置文件是 <code>pyproject.toml</code>、<code>pytest.ini</code>、<code>setup.cfg</code> 和 <code>tox.ini</code>。在这些文件中，可以设置不同的选项和插件参数。</p>
<h3 id="1-2-2-4-fixture">1.2.2.4 fixture</h3>
<p><code>pytest</code> 使用 <code>fixture</code> 来设置测试前的环境和上下文。<code>fixture</code> 通过特殊的装饰器 <code>@pytest.fixture</code> 定义，并可以在测试函数中通过参数引用。</p>
<h3 id="1-2-2-5-biao-ji-marking">1.2.2.5 标记（Marking）</h3>
<p>使用 <code>@pytest.mark</code> 装饰器，可以对测试进行分类标记，例如跳过某些测试 (<code>@pytest.mark.skip</code>), 或者为测试添加自定义标签以便于根据标签选择性运行测试。</p>
<h3 id="1-2-2-6-ce-shi-shou-ji-qi-collector">1.2.2.6 测试收集器（Collector）</h3>
<p><code>pytest</code> 有一个测试收集器，其职责是搜集所有需要执行的测试案例。它会递归地搜索测试文件夹，并识别出测试用例。</p>
<h3 id="1-2-2-7-ce-shi-hui-hua-session">1.2.2.7 测试会话（Session）</h3>
<p>从测试收集到测试执行的全部过程，发生在一个 <code>pytest</code> 会话中。在这个会话中，可以访问到所有测试案例以及相关配置。</p>
<h3 id="1-2-2-8-hui-hua-gou-zi-session-hooks">1.2.2.8 会话钩子（Session Hooks）</h3>
<p>这些钩子在整个测试会话过程中被调用，能让插件在测试过程的关键点插入动作。例如：<code>pytest_sessionstart</code>, <code>pytest_sessionfinish</code>。</p>
<h3 id="1-2-2-9-ming-ling-xing-gong-ju-cli">1.2.2.9 命令行工具（CLI）</h3>
<p><code>pytest</code> 提供了命令行工具与用户交互，通过它可以传递不同的参数和选项来控制测试执行的行为，例如指定测试的路径、选择性地运行标记的测试、设置并行测试数量等。</p>
<h3 id="1-2-2-10-jie-guo-bao-gao">1.2.2.10 结果报告</h3>
<p><code>pytest</code> 提供了丰富的结果报告系统，包括控制台输出和（通过插件）XML、HTML等格式的报告。</p>
<h3 id="1-2-2-11-ji-lu-ri-zhi">1.2.2.11 记录/日志</h3>
<p><code>pytest</code> 支持通过 Python 的 logging 模块来记录测试信息，使得调试更加容易。</p>
<h3 id="1-2-2-12-jie-gou-shi-li">1.2.2.12 结构示例</h3>
<pre><code class="language-shell">pytest/
├── _src/
│   ├── config/          # 配置处理
│   ├── hooks/           # 钩子定义
│   ├── common/          # 公共类/函数的封装
│   ├── testcase/        # 测试用例，纯测试基类中函数的调用，完成业务流程的构造
│   ├── testcasebase/    # 测试用例对应的基类
│   ├── fixtures.py      # 处理fixtures的模块
│   ├── run.py          # 控制测试收集和执行的主运行入口
│   └── ...
├── pytest.ini           # pytest配置文件（如果存在）
└── conftest.py          # 局部插件和fixture定义（如果存在）
</code></pre>
<p><code>pytest</code> 的框架结构做到了灵活和强大，支持自定义测试行为，并且提供了丰富的默认选项，使其非常适合各种规模和复杂度的Python项目。因其可扩展性、简洁性和易用性而广受欢迎，是Python社区中常用的测试工具之一。</p>
<h2 id="1-2-3-pytest-de-you-dian-he-te-dian">1.2.3 pytest的优点和特点</h2>
<p>pytest是python的⼀种免费和开源的测试框架，设计的目的是让测试尽可能简单，它的API易于使用，可以通过命令行或者IDE进行测试，全功能且非常成熟，使⽤起来更简洁，效率更⾼。它主要有以下一些特点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>支持多种测试类型：pytest能够支持不同类型的测试，包括单元测试、集成测试、功能测试、性能测试等，可以和Selenium，requests，Appium结合实现web自动化，接口自动化，APP自动化，并能很好的和Jenkins结合进行持续集成。</p>
</li>
<li class="lvl-2">
<p>可扩展性：pytest具有很好的可扩展性，支持自定义 assertion、插件和测试套件运行。除此之外，pytest有很多非常强大的第三方插件，并且这些插件能够实现很多实用的操作。多年来，已经有大量的第三方插件扩展和增强它的功能，当然也可以自定义pytest插件。</p>
</li>
<li class="lvl-2">
<p>灵活的执行策略：pytest支持灵活的用例执行策略，可以并行运行多个测试，从而减少了测试套件的执行时间；可以将某些测试跳过；对某些预期失败的用例标记成失败；支持重复执行失败的用例等等。</p>
</li>
<li class="lvl-2">
<p>强大的配置与fixture：pytest支持参数化（数据驱动）；pytest强大的fixture在不改变被装饰函数的前提下对函数进行功能增强。</p>
</li>
<li class="lvl-2">
<p>完美与Allure结合： pytest可以和Allure结合生成非常美观的可视化TTML测试报告。</p>
</li>
<li class="lvl-2">
<p>兼容性好：pytest支持python 2.x 和 python 3.x，并且与python的标准库和其他常用的python包兼容。在pytest框架下可以执行Unittest框架和 nose框架的用例。</p>
</li>
<li class="lvl-2">
<p>社区支持强大：pytest有一个活跃的社区，提供大量的文档、教程和插件，使得pytest的使用更加容易和高效。</p>
</li>
</ul>
<h2 id="1-2-4-pytest-de-guan-wang-ji-zi-liao-di-zhi">1.2.4 pytest的官网及资料地址</h2>
<p>pytest官网及帮助文档网址： <a href="https://docs.pytest.org/en/latest/%E3%80%82">https://docs.pytest.org/en/latest/。</a><br>
pypi网址：<a href="https://pypi.org/project/pytest/%E3%80%82">https://pypi.org/project/pytest/。</a><br>
GitHub网址： <a href="https://github.com/pytest-dev/pytest/%E3%80%82">https://github.com/pytest-dev/pytest/。</a></p>
<h1 id="1-3-guan-yu-nose-yu-pytest">1.3 关于nose 与 pytest</h1>
<p>nose和pytest都是Python编程语言的测试框架，它们用于编写和运行测试。</p>
<p><strong>nose</strong> 是一个相对较老的测试框架，它因简单易用而受欢迎。nose使用插件可以扩展其功能，并且很容易收集测试，只要遵循简单的命名规则即可。</p>
<p><strong>pytest</strong> 是后来出现的测试框架，但它很快在许多Python开发者中变得流行。pytest提供了一个更丰富的断言模型、更好的支持fixtures的机制、丰富的插件生态系统以及更多的灵活性来定制测试行为。</p>
<p>至于为何nose项目不再活跃，原因包括：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>开发停滞与技术进步</strong>：随着pytest等新的、功能更全面的测试框架的出现，nose的开发逐渐减缓，最终停止。开发人员和社区成员往往更喜欢那些依旧积极发展和解决新问题的工具。</p>
</li>
<li class="lvl-2">
<p><strong>社区支持的转移</strong>：Python社区对nose的支持逐渐转向对pytest的支持，因为pytest提供更先进的功能和改进的用户体验。</p>
</li>
<li class="lvl-2">
<p><strong>官方的决定</strong>：nose的维护者们决定停止维护该项目，这可能是因为资源限制、个人兴趣变化或者pytest已经能够提供更好的替代方案。</p>
</li>
<li class="lvl-2">
<p><strong>nose2的出现</strong>：应注意，nose的一些原始开发者开始工作在nose的后继项目nose2上，这是一个和nose类似的、但更加现代化的工具，它试图解决nose的一些局限性，并且提供一个更好的平台以支持新特性和测试模式。</p>
</li>
</ul>
<p>总之，软件工具和库的可持续性往往会受到社区支持、维护者参与度、以及新技术的影响。面对pytest这样功能强大、更符合当下需求的框架，nose自然而然地被边缘化，并最终进入了维护模式。</p>
<h1 id="1-4-bu-shu-pytest">1.4 部署pytest</h1>
<h2 id="1-4-1-huan-jing-shuo-ming">1.4.1 环境说明</h2>
<p>由于笔者个人习惯问题，直接在<code>Ubuntu23.10 Server</code>下借助vim进行测试用例的编写，准备环境如下：</p>
<pre><code class="language-shell">root@Gavin:~# uname -a
Linux Gavin 6.5.0-13-generic #13-Ubuntu SMP PREEMPT_DYNAMIC Fri Nov  3 12:16:05 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
root@Gavin:~# python3 --version
Python 3.11.6
root@Gavin:~#
</code></pre>
<p>当然，可根据个人习惯，在windows下安装<code>python</code>和<code>pytest</code>，借助<code>python IDE</code>（如PyCharm）进行用例编写。</p>
<h2 id="1-4-2-pytest-an-zhuang">1.4.2 pytest安装</h2>
<p>执行如下命令，安装pytest：</p>
<pre><code class="language-shell">apt install python3-pytest -y
</code></pre>
<p>查看安装的版本信息：</p>
<pre><code class="language-shell">root@Gavin:~# pytest --version
pytest 7.4.0
root@Gavin:~# 
</code></pre>
<p>或者</p>
<pre><code class="language-shell">root@Gavin:~# pip show pytest
Name: pytest
Version: 7.4.0
Summary: pytest: simple powerful testing with Python
Home-page: https://docs.pytest.org/en/latest/
Author: Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin and others
Author-email: 
License: MIT
Location: /usr/lib/python3/dist-packages
Requires: iniconfig, packaging, pluggy
root@Gavin:~#
</code></pre>
<p>显示类似如上信息，表明安装<code>pytest</code>成功，版本为7.4.0。</p>
<h1 id="1-5-pytest-ru-men">1.5 pytest入门</h1>
<h2 id="1-5-1-ji-ben-yong-fa">1.5.1 基本用法</h2>
<p>在<code>pytest</code>中，你的测试文件通常以<code>test_</code>开头，测试函数以<code>test_</code>开头。如下是一个基本的测试示例：</p>
<pre><code class="language-python"># content of test_example.py
def add(a, b):
    return a + b

def test_add():
    assert add(2, 3) == 5
    assert add('space', 'ship') == 'spaceship'
</code></pre>
<p>要运行测试，你只需在命令行中执行<code>pytest</code>：</p>
<pre><code class="language-bash">root@Gavin:~# pytest
</code></pre>
<p><code>pytest</code>将自动发现所有符合命名约定的测试函数和文件，并执行它们。</p>
<h2 id="1-5-2-can-shu-hua-ce-shi">1.5.2 参数化测试</h2>
<p><code>pytest</code>允许你通过一个名为<code>pytest.mark.parametrize</code>的装饰器来参数化测试：</p>
<pre><code class="language-python"># content of test_parametrize.py
import pytest


def add(a, b):
    return a + b


@pytest.mark.parametrize("a,b,expected", [(2, 3, 5), (4, 5, 9), ('a', 'b', 'ab')])
def test_add_param(a, b, expected):
    assert add(a, b) == expected
</code></pre>
<p>通过以上方式，你可以确保<code>test_add_param</code>函数被上述三组参数调用三次。</p>
<h2 id="1-5-3-ce-shi-yu-qi-de-yi-chang">1.5.3 测试预期的异常</h2>
<p>有些时候，我们期望函数在特定情况下抛出异常， <code>pytest</code> 允许我们测试这种行为。</p>
<pre><code class="language-python"># content of test_exception.py
import pytest

def divide(a, b):
    if b == 0:
        raise ValueError("Cannot divide by zero.")
    return a / b

def test_divide_exception():
    with pytest.raises(ValueError):
        divide(1, 0)
</code></pre>
<p><code>divide()</code> 函数在分母为零时抛出 <code>ValueError</code>。我们使用 <code>pytest.raises</code> 上下文管理器来测试这个行为。</p>
<h2 id="1-5-4-shi-yong-fixture-chu-li-ce-shi-qian-hou-de-zhun-bei-he-qing-li">1.5.4 使用 fixture 处理测试前后的准备和清理</h2>
<p><code>fixture</code> 允许你设置一个代码状态，该状态可以被一个或多个测试共享。可以用来初始化数据库、测试数据或其它资源。</p>
<pre><code class="language-python"># content of test_fixtures.py
import pytest

@pytest.fixture
def resource_setup():
    # Setup for test (e.g. establish database connection)
    db_conn = setup_database()  
    yield db_conn
    # Teardown for test (e.g. close database connection)
    teardown_database(db_conn)

def setup_database():
    # Dummy function to illustrate setup
    return "database_connection"

def teardown_database(conn):
    # Dummy function to illustrate teardown
    print(f"Closing {conn}")

def test_db(resource_setup):
    assert resource_setup == "database_connection"
</code></pre>
<p>在这个场景中，<code>resource_setup</code> fixture 负责建立和销毁测试所需的资源（在这个例子中是数据库连接）。<code>test_db()</code> 函数把 fixture 作为参数使用，确保了执行测试时资源已正确设置。</p>
<p>注意，实际代码中 <code>setup_database()</code> 和 <code>teardown_database()</code> 函数会涉及真正的数据库操作，这里仅用字符串和打印语句举例。</p>
<h2 id="1-5-5-tiao-guo-ce-shi-huo-you-tiao-jian-di-tiao-guo-ce-shi">1.5.5 跳过测试或有条件地跳过测试</h2>
<p>在某些情况下，可能需要跳过某个测试，比如当一个外部资源不可用时。</p>
<pre><code class="language-python"># content of test_skip.py
import sys
import pytest

def add(a, b):
    return a + b

@pytest.mark.skip(reason="This function is not yet implemented.")
def test_to_be_skipped():
    # This test will be skipped
    assert add(3, 4) == 7

@pytest.mark.skipif(sys.version_info &lt; (3, 6), reason="requires python3.6 or higher")
def test_skip_if():
    # This test will be skipped on Python versions lower than 3.6
    assert add(3, 4) == 7
</code></pre>
<p><code>@pytest.mark.skip</code> 装饰器表明测试应被跳过，而 <code>@pytest.mark.skipif</code> 装饰器用于条件性地跳过测试。</p>
<h1 id="1-6-ben-zhang-xiao-jie">1.6 本章小结</h1>
<p>在本章节中，开篇对比了几种常见的测试框架，并着重介绍了<code>pytest</code>这个流行的测试框架。我们讲解了<code>pytest</code>的优点，包括易于学习和使用、丰富的插件和扩展、具有灵活的设置和配置选项、支持测试用例的参数化运行等等。本文还提供了有关如何安装和部署<code>pytest</code>的指南，介绍了如何组织测试用例、使用<code>fixture</code>和参数化测试用例等pytest的一些核心概念和最佳实践。</p>
<p>总的来说，<code>pytest</code>提供了一个清晰的测试编写方法和强大的功能，使编写和维护测试变得更简单。这些特性在提高测试的覆盖率和精确度方面发挥着关键作用。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>Change theme from Jekyll to Hexo Matery</title>
    <url>/2024/01/28/change_theme_to_hexo_matery/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>之前的博客使用的是Jekyll，比较简约，今天看到一个蛮炫酷的主题，故而使用它，重新搭建了一下博客，并迁移了旧有博客中的文章内容(少部分博客地址发生了变化，导致相关文章的历史访问记录诸如访问量会从零开始计)。</p>
<h1 id="guo-cheng">过程</h1>
<p>简单记录几个重要的点，防止自己以后忘记。</p>
<h2 id="qu-diao-zhu-ye-tu-pian-fu-ceng">去掉主页图片浮层</h2>
<p>修改 <code>themes/hexo-theme-matery/source/css</code>下<code>matery.css</code>文件</p>
<pre><code class="language-shell">.bg-cover:after {
    position: absolute;
    z-index: 1;
    width: 100%;
    height: 100%;
    display: block;
    left: 0;
    top: 0;
    /* content: ""; */
}
</code></pre>
<p>注释掉上面的<code>content: "";</code>内容即可。</p>
<h2 id="qu-diao-zhu-ye-subtitle-zi-yang">去掉主页subtitle字样</h2>
<p>修改 <code>themes/hexo-theme-matery/layout/_partial/bg-cover-content.ejs</code>中的如下内容：</p>
<pre><code class="language-shell">            &lt;div class="title center-align"&gt;
                &lt;% if (config.subtitle &amp;&amp; config.subtitle.length &gt; 0) { %&gt;
                &lt;%= config.subtitle %&gt;
                &lt;% } else { %&gt;
                    subtitle
                &lt;% } %&gt;
            &lt;/div&gt;
</code></pre>
<p>修改为：</p>
<pre><code class="language-shell">            &lt;div class="title center-align"&gt;
                &lt;% if (config.subtitle &amp;&amp; config.subtitle.length &gt; 0) { %&gt;
                &lt;%= config.subtitle %&gt;
                &lt;% } %&gt;
            &lt;/div&gt;
</code></pre>
<h2 id="dai-ma-gao-liang">代码高亮</h2>
<pre><code class="language-shell"># syntax_highlighter: highlight.js
syntax_highlighter: 
highlight:
  line_number: false
  auto_detect: true
  tab_replace: ''
  wrap: true
  hljs: false
prismjs:
  enable: true
  preprocess: true
  line_number: false
  tab_replace: ''
  theme: 'okaidia'
marked:
  langPrefix: line-numbers language-
</code></pre>
<p><code>syntax_highlighter:</code>为空，则表示禁用默认自带的<code>highlighter</code>代码高亮风格。如上为改用<code>prismjs</code>风格。</p>
<h2 id="fen-lei">分类</h2>
<p>页面想显示分类，有的时候还有子分类，参考如下：</p>
<p>并列分类：</p>
<pre><code class="language-shell">categories:
- [Linux]
- [Tools]
</code></pre>
<p>并列+子分类：</p>
<pre><code class="language-shell">categories:
- [Linux, Hexo]
- [Tools, PHP]
</code></pre>
<h2 id="xiu-gai-liu-yan-ban-ye-mian-zhan-shi-nei-rong">修改留言板页面展示内容</h2>
<p>在<code>themes/hexo-theme-matery/layout/</code>，修改<code>contact.ejs</code>文件：</p>
<pre><code class="language-shell">            &lt;!--valine评论弹幕--&gt;
            &lt;% if (theme.valine &amp;&amp; theme.valine.enable) { %&gt;
                &lt;p&gt;
                    &lt;b&gt;畅所欲言&lt;/b&gt;&lt;br&gt;
                    &lt;b&gt;在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链&lt;/b&gt;&lt;br&gt;
                    &lt;b&gt;友链信息&lt;/b&gt;&lt;br&gt;
                    &lt;b&gt;博客名称: &lt;%- config.title %&gt;&lt;/b&gt;&lt;br&gt;
                    &lt;b&gt;博客网址: &lt;%- config.url %&gt;&lt;/b&gt;&lt;br&gt;
                    &lt;b&gt;博客头像: &lt;%- config.url %&gt;/medias/logo.png&lt;/b&gt;&lt;br&gt;
                    &lt;b&gt;博客介绍: 犹豫就会败北&lt;/b&gt;&lt;br&gt;
                &lt;/p&gt;
                &lt;div class="container"&gt;
                    &lt;section id="custom" class="bb-section"&gt;
                        &lt;div class="row"&gt;
                            &lt;div class="col-md-5"&gt;
                                &lt;form class="form-inline"&gt;
                                    &lt;div class="form-group"&gt;
                                        文字：&lt;input class="form-control" name="info" type="text" placeholder="hello, world"/&gt;
                                    &lt;/div&gt;
                                    &lt;div class="form-group"&gt;
                                        链接：&lt;input class="form-control" name="href" type="text" placeholder="https://github.com/blinkfox/hexo-theme-matery"/&gt;
                                    &lt;/div&gt;
                                    &lt;div class="form-group"&gt;
                                        速度：&lt;input  class="form-control"  name="speed" type="text" placeholder="5~20" value="16" /&gt;
                                    &lt;/div&gt;
                                &lt;/form&gt;
                                &lt;div class="form-group"&gt;
                                    &lt;button id="send"  class="btn" onclick="run()"&gt;留言&lt;/button&gt;
                                    &lt;button id="clear" class="btn " onclick="clear_barrage()"&gt; 清除&lt;/button&gt;
                                &lt;/div&gt;
                            &lt;/div&gt;
                        &lt;/div&gt;
                    &lt;/section&gt;
                &lt;/div&gt;
</code></pre>
<p>调整为：</p>
<pre><code class="language-shell">            &lt;!--valine评论弹幕--&gt;
            &lt;% if (theme.valine &amp;&amp; theme.valine.enable) { %&gt;
                &lt;p&gt;
                    &lt;b&gt;在这里可以留下你的足迹，欢迎在下方留言&lt;/b&gt;&lt;br&gt;
                &lt;/p&gt;
                &lt;div class="container"&gt;
                    &lt;section id="custom" class="bb-section"&gt;
                        &lt;div class="row"&gt;
                            &lt;div class="col-md-5"&gt;
                                &lt;form class="form-inline"&gt;
                                    &lt;div class="form-group"&gt;
                                        文字：&lt;input class="form-control" name="info" type="text" placeholder="hello, world"/&gt;
                                    &lt;/div&gt;
                                    &lt;div class="form-group"&gt;
                                        链接：&lt;input class="form-control" name="href" type="text" placeholder="https://github.com/gavin-wang-note"/&gt;
                                    &lt;/div&gt;
                                    &lt;div class="form-group"&gt;
                                        速度：&lt;input  class="form-control"  name="speed" type="text" placeholder="5~20" value="16" /&gt;
                                    &lt;/div&gt;
                                &lt;/form&gt;
                                &lt;div class="form-group"&gt;
                                    &lt;button id="send"  class="btn" onclick="run()"&gt;留言&lt;/button&gt;
                                    &lt;button id="clear" class="btn " onclick="clear_barrage()"&gt; 清除&lt;/button&gt;
                                &lt;/div&gt;
                            &lt;/div&gt;
                        &lt;/div&gt;
                    &lt;/section&gt;
                &lt;/div&gt;
</code></pre>
<p>改为你自己认为合适的内容即可。</p>
<h2 id="da-shang">打赏</h2>
<p>替换掉<code>themes/hexo-theme-matery/source/medias/reward</code>目录下两个文件即可:</p>
<pre><code class="language-shell">drwxr-xr-x 2 root root  4096 Jan 26 19:25 ./
drwxr-xr-x 7 root root  4096 Jan 26 19:35 ../
-rw-r--r-- 1 root root 57240 Jan 26 19:36 alipay.jpg
-rw-r--r-- 1 root root 34017 Jan 26 19:36 wechat.png
</code></pre>
<h2 id="wen-zhang-front-format">文章Front Format</h2>
<p>修改<code>scaffolds/post.md</code>文件，添加如下内容：</p>
<pre><code class="language-shell">---
title: {{ title }}
date: {{ date }}
author: 
img: 
coverImg: 
top: false 
cover: false 
toc: true 
mathjax: false
password: 
summary: 
keywords: 
tags: 
categories:
---
</code></pre>
<p>介绍如下：</p>
<table>
<thead>
<tr>
<th>Options</th>
<th>Defaults</th>
<th>Description（描述）</th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>Markdown 的文件标题</td>
<td>文章标题,强烈建议填写此选项</td>
</tr>
<tr>
<td>date（日期）</td>
<td>文件创建时的日期时间</td>
<td>发布时间,强烈建议填写这个选项,这是最好的,以确保它是全局唯一的</td>
</tr>
<tr>
<td>author（作者）</td>
<td><code>_config.yml</code> 中的 author</td>
<td>文章作者</td>
</tr>
<tr>
<td>img</td>
<td>文章封面</td>
<td>特征图像,用于显示在文章封面，如果不携带，系统自动从<code>themes/matery/source/medias/featureimages</code>中选取</td>
</tr>
<tr>
<td>top</td>
<td>true</td>
<td>置顶文章(文章是否置顶),如果设置为True，它将被推荐作为在主页顶部。</td>
</tr>
<tr>
<td>hide</td>
<td>false</td>
<td>这篇文章是否显示在首页,如果 隐藏 值是 True ,它将不会显示在首页，即被隐藏。</td>
</tr>
<tr>
<td>cover（封面）</td>
<td>false</td>
<td>v1.0.2版本新增，表示该文章是否需要加入到首页轮播封面中</td>
</tr>
<tr>
<td>coverImg</td>
<td>null</td>
<td>v1.0.2版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td>
</tr>
<tr>
<td>password</td>
<td>null</td>
<td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 password 的值，该值必须是用 SHA256 加密后的密码，防止被他人识破。前提是在主题的 config.yml 中激活了 verifyPassword 选项</td>
</tr>
<tr>
<td>toc</td>
<td>true</td>
<td>是否打开目录,你可以关掉一篇文章的TOC。 启用的前提是主题的 <code>_config.yml</code> 中 <code>toc</code> 是激活的（设置为True）</td>
</tr>
<tr>
<td>mathjax</td>
<td>false</td>
<td>是否启用数学公式支持,是否这篇文章开启 mathjax ,你需要打开它的主题 <code>_config.yml</code> 文件中相关配置。</td>
</tr>
<tr>
<td>summary（总结）</td>
<td>null</td>
<td>文章摘要,自定义文章摘要内容,如果属性有一个值,明信片摘要将显示你设置的文本,否则程序会自动拦截部分文章的内容作为总结。</td>
</tr>
<tr>
<td>categories（类别）</td>
<td>null</td>
<td>文章分类,分类的主题代表一个大分类。</td>
</tr>
<tr>
<td>tags（标签）</td>
<td>null</td>
<td>文章标签,可以有多个标签</td>
</tr>
<tr>
<td>keywords（关键字）</td>
<td>Post Title</td>
<td>文章关键字和搜索引擎优化</td>
</tr>
<tr>
<td>reprintPolicy</td>
<td>cc_by</td>
<td>文章分享政策,值可能是cc_by,cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd cc_by_nc_sa, cc0中的一个。</td>
</tr>
</tbody>
</table>
<h2 id="wen-zhang-jia-mi">文章加密</h2>
<p>借助<code>hexo-blog-encrypt</code>完成文章的加密工作，需要安装:<br>
<code>npm install hexo-blog-encrypt</code></p>
<p>同时，需要在博客的根目录下的<code>_config.yml</code>文件中，增加如下内容：</p>
<pre><code class="language-shell"># Security
encrypt: # hexo-blog-encrypt
  silent: false
  abstract: 这里有东西被加密了，需要输入密码才能查看哦。
  message: 您好, 这里需要输入密码，解密后方可查看内容。
  tags:
  - {name: tagName, password: 密码A}
  - {name: tagName, password: 密码B}
  theme: flip
  wrong_pass_message: 抱歉，密码错误！
  wrong_hash_message: 抱歉, 这个文章不能被校验, 不过你还是能看看解密后的内容。
</code></pre>
<p><code>theme</code>有如下几种风格可选择:</p>
<pre><code class="language-shell">default
blink
shrink
flip
up
surge
wave
xray
</code></pre>
<p>根据个人喜好选择即可，具体信息，请参考<a href="https://www.npmjs.com/package/hexo-blog-encrypt">官网</a>。</p>
<blockquote>
<p><strong>请留意：</strong></p>
</blockquote>
<p>主题中的<code>_config.yml</code>文件，需关闭如下选项：</p>
<pre><code class="language-shell">verifyPassword:
  enable: false
</code></pre>
<p>文章中，需增加如下内容：</p>
<pre><code class="language-shell">password: 123456
theme: flip
</code></pre>
<p>这里<code>theme</code>中的<code>flip</code>，需要和上文中根目录下的<code>_config.yml</code>中<code>theme</code>的值保持一致。</p>
<p>由于本地访问是http方式，推到github上是https方式访问，故而本地http访问时输入密码无任何反应，这是正常现象，推到github上时OK的。</p>
<h2 id="markdown-de-zhi-chi">markdown的支持</h2>
<p>主要做了如下安装动作：</p>
<pre><code class="language-shell">npm un hexo-renderer-marked --save
npm i hexo-renderer-markdown-it --save
npm i markdown-it-footnote --save
npm i markdown-it-footnote --save
npm i markdown-it-footnote --save
npm i markdown-it-named-headings --save
npm i markdown-it-checkbox --save
npm i markdown-it-sub markdown-it-sup --save
npm i markdown-it-imsize --save
npm i markdown-it-mark --save
npm i markdown-it-ins --save
npm i markdown-it-abbr --save
npm i markdown-it-deflist --save
npm i markdown-it-expandable --save
</code></pre>
<p>请务必执行<code>npm list</code>命令检查是否安装成功，如下则表示安装成功：</p>
<pre><code class="language-shell">hexo-site@0.0.0 /root/gavin-wang-note.github.io
├── browser-sync@3.0.2
├── hexo-blog-encrypt@3.1.9
├── hexo-browsersync@0.3.0
├── hexo-deployer-git@4.0.0
├── hexo-filter-github-emojis@3.0.5
├── hexo-generator-archive@2.0.0
├── hexo-generator-category@2.0.0
├── hexo-generator-feed@3.0.0
├── hexo-generator-index@3.0.0
├── hexo-generator-searchdb@1.4.1
├── hexo-generator-sitemap@3.0.1
├── hexo-generator-tag@2.0.0
├── hexo-permalink-pinyin@1.1.0
├── hexo-renderer-ejs@2.0.0
├── hexo-renderer-markdown-it@7.1.1
├── hexo-renderer-pug@3.0.0
├── hexo-renderer-stylus@3.0.1
├── hexo-server@3.0.0
├── hexo-theme-landscape@1.0.0
├── hexo-wordcount@6.0.1
├── hexo@7.1.1
├── markdown-it-abbr@2.0.0
├── markdown-it-checkbox@1.1.0
├── markdown-it-deflist@3.0.0
├── markdown-it-expandable@1.0.2
├── markdown-it-footnote@4.0.0
├── markdown-it-imsize@2.0.1
├── markdown-it-ins@4.0.0
├── markdown-it-mark@4.0.0
├── markdown-it-named-headings@1.1.0
├── markdown-it-sub@2.0.0
└── markdown-it-sup@2.0.0
</code></pre>
<p>更多信息，我参考的是这篇文章<a href="https://seayj.cn/articles/33818/#!">点击跳转</a>。</p>
<h2 id="tu-pian-zeng-jia-jia-zai-guo-cheng">图片增加加载过程</h2>
<p>我参考的是这篇文章<a href="https://lovelijunyi.gitee.io/posts/b8ec.html">点击跳转</a>中的<code>增加载入动画</code>章节内容。</p>
<h2 id="diao-zheng-ye-mian-fen-ye">调整页面分页</h2>
<p>修改<code>{主题}layout/_partial/paging.ejs</code>文件内容，注释掉旧有的</p>
<pre><code class="language-ejs">&lt;div class="center-align b-text-gray"&gt;&lt;%- page.current %&gt; / &lt;%- page.total %&gt;&lt;/div&gt;
</code></pre>
<p>添加如下内容：</p>
<pre><code class="language-ejs">        &lt;div class="page-info col m4 l4 hide-on-small-only"&gt;

        &lt;!-- Modify by Gavin, 2024-02-01
            &lt;div class="center-align b-text-gray"&gt;&lt;%- page.current %&gt; / &lt;%- page.total %&gt;&lt;/div&gt;
        --&gt;

        &lt;!-- Add new content like the fallowing  --&gt;
        &lt;div class="center-align b-text-gray"&gt;
            &lt;a href="/"&gt;«1&lt;/a&gt;

            &lt;% const displayPageNumber = 9; %&gt;
            &lt;% const middle = Math.floor(displayPageNumber / 2); %&gt;
            &lt;% const startPage = Math.max(2, page.current - middle + 1); %&gt;
            &lt;% const endPage = Math.min(page.total-1, startPage + displayPageNumber - 2); %&gt;

            &lt;% if (startPage &gt; 2) { %&gt;
                &lt;span&gt;...&lt;/span&gt;
            &lt;% } %&gt;

            &lt;% for(var i = startPage; i &lt;= endPage; i++) { %&gt;
                &lt;% if (page.current == i) { %&gt;
                    &lt;span&gt;&lt;%= i %&gt;&lt;/span&gt;
                &lt;% } else { %&gt;
                    &lt;a href="/page/&lt;%= i %&gt;"&gt;&lt;%= i %&gt;&lt;/a&gt;
                &lt;% } %&gt;
            &lt;% } %&gt;

            &lt;% if (endPage &lt; page.total - 1) { %&gt;
                &lt;span&gt;...&lt;/span&gt;
            &lt;% } %&gt;

            &lt;a href="/page/&lt;%= page.total %&gt;"&gt;&lt;%= page.total %&gt;»&lt;/a&gt;
        &lt;/div&gt;
</code></pre>
<p>展示效果如下：</p>
<img class="shadow" src="/img/in-post/pagination.png" width="1200">
<h2 id="jian-rong-jekyll-url">兼容Jekyll URL</h2>
<p>由于我是从Jekyll切换到Hexo的，Jekyll文件的命名格式是：<code>2021-05-05-abc_def_ghi.md</code>，切换到hexo后，文章链接展示为<code>https://xxx/2021/02/05/2021-05-05-abc-def-ghi</code>， 而Jekyll中文章链接展示的链接为<code>https://xxx/2021/02/05/abc_def_ghi</code>。为了保证旧文章链接的有效性，需要修改Hexo文章展示的URL。</p>
<p>先修改博客根目录下的<code>_config.yml</code>文件：</p>
<pre><code class="language-shell">permalink_pinyin:
  enable: true
  separator: '_' # default: '-'
</code></pre>
<p>将上面的<code>separator</code>使用中划线修改为下划线。</p>
<p>接着在博客根目录下的scrpits创建refinepermalink.js文件，写入如下内容：</p>
<pre><code class="language-shell">hexo.extend.filter.register('before_post_render', function(data){
	  // 检查日期，如果早于new_format_date，则不做改变
	  var new_format_date = new Date('2000-05-01');
	  if (new Date(data.date) &lt; new_format_date) return data;

	  // 对于日期晚于new_format_date的文章，尝试解析出纯标题部分作为slug
	  var matched = data.source.match(/(\d{4}-\d{2}-\d{2})-(.*)\.md$/);
	  if(matched &amp;&amp; matched[2]) {
		      // 重写slug
		      // data.slug = matched[2].replace(/-/g, '_');
		      data.slug = matched[2];
		    }

	  return data;
});
</code></pre>
<p>重启hexo(hexo clean; hexo g; hexo s)，即可生效。</p>
<h2 id="top-wen-zhang-an-shi-jian-dao-xu-pai-xu">top文章按时间倒序排序</h2>
<p>目前置顶的文章，是安装时间先后顺序排序的，现在想按时间倒序排序。</p>
<p>找到主题目录下<code>layout/_widget/recommend.ejs</code>文件，增加三行代码。</p>
<p>修改前：</p>
<pre><code class="language-javascript">&lt;%
    // get all top posts.
    var topPosts = [];
    if (theme.recommend.useConfig) {
        topPosts = site.data.recommends;
    } else {
        site.posts.forEach(function (post) {
            if (post.top) {
                topPosts.push(post);
            }
        });
    }

    var topPostsCount = topPosts.length;
%&gt;
</code></pre>
<p>修改后:</p>
<pre><code class="language-javaseript">&lt;%
    // get all top posts.
    var topPosts = [];
    if (theme.recommend.useConfig) {
        topPosts = site.data.recommends;
    } else {
        site.posts.forEach(function (post) {
            if (post.top) {
                topPosts.push(post);
            }
        });
    }

    // 对置顶文章按日期进行倒序排序
    topPosts.sort(function(a, b) {
        return b.date - a.date;
    });

    var topPostsCount = topPosts.length;
%&gt;
</code></pre>
<p>然后重启hexo即可。</p>
<h2 id="xiu-gai-guan-yu-ye-mian-de-qi-ta-ji-neng-biao-qian-di-se">修改 “关于” 页面的 “其他技能” 标签底色</h2>
<p>在“分类” 和 “标签”页面，所有的Tag都是有底色的，但是“关于”页面中的“其他技能”却没有底色（都是白色）。</p>
<p>这里修改一下，使用的底色保持和“分类” 和 “标签”页面一致。</p>
<p>找到<code>themes/matery/layout/_widget\my-skills.ejs</code>文件，在文件内容的开头处，增加如下内容：</p>
<pre><code class="language-javascript">    &lt;div class="title center-align" data-aos="zoom-in-up"&gt;
&lt;%
var colorArray = ['#F9EBEA', '#F5EEF8', '#D5F5E3', '#E8F8F5', '#FEF9E7', '#F8F9F9', '#82E0AA', '#D7BDE2', '#A3E4D7', '#85C1E9', '#F8C471', '#F9E79F', '#FFF'];
var getColor = function() {
    return colorArray[Math.floor(Math.random() * colorArray.length)];
}
%&gt;
</code></pre>
<p>再找到这行内容：<code>&lt;% if (site.tags) { %&gt;</code>，删除这行下的如下内容：</p>
<pre><code class="language-javascript">    &lt;div class="other-skills chip-container" data-aos="zoom-in-up"&gt;
        &lt;div class="sub-title center-align"&gt;&lt;i class="fa fa-book"&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;%- __('otherSkills') %&gt;&lt;/div&gt;
        &lt;div class="tag-chips center-align"&gt;
            &lt;% site.tags.map(function(tag) { %&gt;
            &lt;% if (!isInArray(topSkillArr, tag.name)) { %&gt;
            &lt;a href="&lt;%- url_for(tag.path) %&gt;"&gt;
                &lt;span class="chip center-align waves-effect waves-light chip-default"&gt;&lt;%- tag.name %&gt;&lt;/span&gt;
            &lt;/a&gt;
            &lt;% } %&gt;
            &lt;% }); %&gt;
        &lt;/div&gt;
    &lt;/div&gt;
</code></pre>
<p>增加如下内容：</p>
<pre><code class="language-javascript">    &lt;div class="other-skills chip-container" data-aos="zoom-in-up"&gt;
        &lt;div class="sub-title center-align"&gt;&lt;i class="fa fa-book"&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;%- __('otherSkills') %&gt;&lt;/div&gt;
        &lt;div class="tag-chips center-align"&gt;
            &lt;% site.tags.each(function(tag, index) { %&gt;
            &lt;% if (!isInArray(topSkillArr, tag.name)) { %&gt;
            &lt;a href="&lt;%- url_for(tag.path) %&gt;"&gt;
                &lt;span class="chip center-align waves-effect waves-light chip-default" style="background-color: &lt;%- getColor(index) %&gt;"&gt;&lt;%- tag.name %&gt;&lt;/span&gt;
            &lt;/a&gt;
            &lt;% } %&gt;
            &lt;% }); %&gt;
        &lt;/div&gt;
    &lt;/div&gt;
</code></pre>
<p>然后访问下对应页面，即可看到效果。</p>
]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Some tools to troubleshoot Linux performance problems</title>
    <url>/2024/01/31/tools_to_troubleshoot_linux_performance/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>In this article, you’ll learn how to collect information about your Linux system’s performance.</p>
<p>Performance is one of those things that many system administrators dread. Sometimes you don’t even think about it when things are running well. Then, suddenly you get a call from an end user, or even worse, lots of end users, that the application you’re responsible for “feels slow.” Or maybe it’s outright unavailable. Now you have to go into troubleshooting mode.</p>
<p>Where do you start, though? In this article, I’ll walk through some basics, but first, I’ll take a step back. It’s important to have some baseline information about your system before trying to identify problems. Maybe your system is doing something it shouldn’t be, and that is contributing to the high load. Or perhaps it’s doing exactly what it always has, and it’s just under some additional load. Performance troubleshooting starts before a problem occurs by keeping good documentation and historical performance data.</p>
<p>This article summarizes three utilities that provide great initial performance information, command of top, free and vmstat.</p>
<h1 id="start-at-the-atop">Start at the atop</h1>
<p>The first go-to performance troubleshooting tool is atop. The atop utility gives you a great, constantly updated process and performance dashboard. What’s the load of Network?How much memory is in use? What’s the CPU load average? What’s the Disks load average?What’s the load average? What processes are using the most resources? All of this is ready at a moment’s notice in atop.</p>
<img class="shadow" src="/img/in-post/atop-overview.png" width="1200">
<p>In addition, you can filter atop, such as searching for processes (type the letter p and then the process id you want to filter), or even viewing the utilization of each kernel in the system (type the letter l and adjust the number of CPU stats), as well as viewing the memory consumption of each process or service in the system, which is very powerful.</p>
<h1 id="free">free</h1>
<p>This free tool shows the current memory consumption of your system, but free is a little brother to atop.</p>
<pre><code class="language-shell">root@Gavin:~# free
               total        used        free      shared  buff/cache   available
Mem:         6021396      902228     4167908        1916     1220796     5119168
Swap:        4194300           0     4194300
root@Gavin:~#
</code></pre>
<blockquote>
<p><strong>Field descriptions:</strong></p>
</blockquote>
<ul class="lvl-0">
<li class="lvl-2">
<p>total: Indicates the total physical memory size.</p>
</li>
<li class="lvl-2">
<p>used: Indicates how much memory has been used.</p>
</li>
<li class="lvl-2">
<p>free: the amount of free memory.</p>
</li>
<li class="lvl-2">
<p>Shared: the total amount of memory shared by multiple processes.</p>
</li>
<li class="lvl-2">
<p>Buffers/cached: the size of the disk cache.</p>
</li>
</ul>
<blockquote>
<p><strong>Usage Introduction:</strong></p>
</blockquote>
<p>Syntax: <code>free [-hbkmotV][-s &lt;interval seconds&gt;]</code></p>
<p>Additional Note: The free directive displays memory usage, including physical memory, virtual swap file memory, shared memory segments, and buffers used by the system core.</p>
<blockquote>
<p><strong>Parameters:</strong></p>
</blockquote>
<ul class="lvl-0">
<li class="lvl-2">
<p>-b Displays memory usage in Bytes.</p>
</li>
<li class="lvl-2">
<p>-k Shows memory usage in kilobytes (KB).</p>
</li>
<li class="lvl-2">
<p>-m Shows memory usage in MB.</p>
</li>
<li class="lvl-2">
<p>-h Display memory usage in a more user-friendly way.</p>
</li>
<li class="lvl-2">
<p>-o Do not display buffer reconciliation columns.</p>
</li>
<li class="lvl-2">
<p>-s <interval seconds=""> Continuously observe memory usage.</interval></p>
</li>
<li class="lvl-2">
<p>-t Display memory sum column.</p>
</li>
<li class="lvl-2">
<p>-V Display version information.</p>
</li>
</ul>
<p>Remember that the Linux kernel will take available memory and allocate it to disk buffers and cache. Linux will release those resources when the system needs them, so if free suggests that you have no available memory, be sure to check that buffers/cache column before you conclude that you’re out of memory.</p>
<h1 id="vmstat">vmstat</h1>
<p>Using vmstat is another great way to look at your memory consumption.</p>
<pre><code class="language-shell">root@Gavin:~# vmstat 2 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 4165148  52340 1168620    0    0   172   108  111    0  0  1 99  0  0
 1  0      0 4165148  52340 1168620    0    0     0     0   48   76  0  0 100  0  0
 1  0      0 4165148  52340 1168620    0    0     0     0   45   70  0  0 100  0  0
 1  0      0 4165148  52348 1168612    0    0     0     8   54   86  0  0 100  0  0
 1  0      0 4165148  52348 1168620    0    0     0     0   46   73  0  0 100  0  0
root@Gavin:~# 
</code></pre>
<p>It breaks down the buffers and cache, and you’ll also get information about your swap utilization. Swapping is generally a sign that your system is exhausting its higher-performing memory, and it must resort to swapping to disk. This process can have a devastating effect on some applications.</p>
<h1 id="nmon">Nmon</h1>
<p>Nmon (Nigel’s Monitor) is a free tool provided by IBM to monitor the resources of AIX and Linux systems. The tool can collect the server system resource consumption and output a specific file , and can use excel analysis tool (nmon analyser) for statistical analysis of data.</p>
<p>Open source performance monitoring tool for monitoring linux system resource consumption information , and can output the results to a file , and then through the nmon_analyser tool to generate data files and graphical results.</p>
<h2 id="run-nmon">Run nmon</h2>
<p>You can run nmon like this:</p>
<pre><code class="language-shell">nmon
</code></pre>
<img class="shadow" src="/img/in-post/nmon.png" width="1200">
<p>In the interactive window above, you can use the nmon shortcut to display different system resource statistics:</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td>q</td>
<td>Stop and exit Nmon</td>
</tr>
<tr>
<td>h</td>
<td>View help</td>
</tr>
<tr>
<td>c</td>
<td>View CPU statistics</td>
</tr>
<tr>
<td>m</td>
<td>View memory statistics</td>
</tr>
<tr>
<td>d</td>
<td>View hard disk statistics</td>
</tr>
<tr>
<td>k</td>
<td>View kernel statistics</td>
</tr>
<tr>
<td>n</td>
<td>View network statistics</td>
</tr>
<tr>
<td>n</td>
<td>View NFS statistics</td>
</tr>
<tr>
<td>j</td>
<td>View file system statistics</td>
</tr>
<tr>
<td>t</td>
<td>View high-consumption processes</td>
</tr>
<tr>
<td>V</td>
<td>View virtual memory statistics</td>
</tr>
<tr>
<td>v</td>
<td>Detailed Mode</td>
</tr>
</tbody>
</table>
<p>After pressing c, m, d, the following figure shows the consumption of CPU, memory and disk intuitively, press q to exit.</p>
<h2 id="data-collection">data collection</h2>
<p>When performance testing, you need to analyze the change of system resources in a period of time according to the execution of the test scenario, then you need nmon to collect the data and save it, the following parameters are commonly used:</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>-f parameter: generate a file, file name = host name + current time.nmon</p>
</li>
<li class="lvl-2">
<p>-T parameter: show processes with high resource utilization.</p>
</li>
<li class="lvl-2">
<p>-s parameter: -s 10 means collect data every 10 seconds.</p>
</li>
<li class="lvl-2">
<p>-c parameter: -s 10 means collect data every 10 seconds.</p>
</li>
<li class="lvl-2">
<p>-m parameter: Specify the file storage directory</p>
</li>
</ul>
<p>If you collect every 5 seconds, a total of 12 times, that is 1 minute of data (the generated file is marked in red):</p>
<pre><code class="language-shell">root@Gavin:~# nmon -f -s 5 -c 12 -m /root/
</code></pre>
<p>The generated files are referenced below:</p>
<pre><code class="language-shell">root@Gavin:~# ls -l Gavin_240131_1034.nmon 
-rw-r--r-- 1 root root 148714 Jan 31 10:34 Gavin_240131_1034.nmon
root@Gavin:~# 
</code></pre>
<p>The file name consists of:</p>
<p>Hostname_last-two-doubles-of-year-month-date_hour-minute.nmon</p>
<p>If you want to shut down the nmon process after data collection, you need to get the pid of nmon.</p>
<p>The collected data cannot be viewed directly, and the nmon_analyser tool is required to generate data files and graphical results.</p>
<p>Download link:<a href="https://sourceforge.net/projects/nmon/">Download</a></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>performance</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown语法与外挂标签总结</title>
    <url>/2024/02/01/markdown/</url>
    <content><![CDATA[<p>Markdown语法与外挂标签总结</p>
<h1 id="markdown-zi-dai-yu-fa-ge-shi">Markdown自带语法格式</h1>
<h2 id="dai-ma">代码</h2>
<pre><code class="language-python">def greet():
    print("Hello, World!")

greet()
</code></pre>
<h2 id="biao-ti">标题</h2>
<p>Markdown 支持两种标题的语法，类 Atx 和类 Setext 形式。</p>
<p>类 Atx 形式使用 # 数量表示标题的阶数（标准写法）</p>
<p>在行首插入 1 到 6 个 #，对应到标题 1 到 6 阶，例如：</p>
<pre><code class="language-shell"># 这是 H1        # typora 快捷键 Ctrl + 1
## 这是 H2       # typora 快捷键 Ctrl + 2（常用）
### 这是 H3      # typora 快捷键 Ctrl + 3
#### 这是 H4     # typora 快捷键 Ctrl + 4（常用）
##### 这是 H5    # 一般不作使用
###### 这是 H6   # 一般不作使用
</code></pre>
<p>类 Setext 形式则是用底线的形式（认识就行，不作使用）</p>
<p>利用 =（最高阶标题）和 -（第二阶标题），例如：</p>
<pre><code class="language-shell">This is an H1
=============

This is an H2
-------------
</code></pre>
<p>任何数量的 = 和 - 都可以有效果。</p>
<h2 id="wen-zi-yang-shi">文字样式</h2>
<p><u>下划线演示</u></p>
<p>文字<strong>加粗</strong>演示</p>
<p>文字<em>斜体</em>演示</p>
<p>文本<code>高亮</code>演示</p>
<p>文本<s>删除</s>线演示</p>
<p><font size="5">5号字</font><font face="黑体">黑体</font><font color="blue">蓝色</font></p>
<table><tbody><tr><td bgcolor="MistyRose">这里的背景色是：MistyRosen，此处输入任意想输入的内容</td></tr></tbody></table>
<h2 id="yin-yong">引用</h2>
<blockquote>
<p>python<br>
二级引用演示<br>
MySQL</p>
<blockquote>
<p>外键</p>
<p>事务</p>
<p><strong>行级锁</strong>(引用内部一样可以用格式)</p>
</blockquote>
<p>…</p>
</blockquote>
<h2 id="fen-ge-xian">分割线</h2>
<p>可用三个以上的<strong>减号、星号、底线</strong>在一空行中建立一条分隔线，中间可以插入空格，但行内不能有其他东西。</p>
<pre><code class="language-shell">---
***
___
</code></pre>
<p>效果如下：</p>
<hr>
<h2 id="lie-biao-gen-kong-ge-du-ke-yi">列表(*,+,-跟空格都可以)</h2>
<h3 id="wu-xu-lie-biao">无序列表</h3>
<pre><code class="language-shell">* Shell
* Python
* ...

+ Shell
+ Python
+ ...

- Shell
- Python
- ...
</code></pre>
<p>效果如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Shell</p>
</li>
<li class="lvl-2">
<p>Python</p>
</li>
<li class="lvl-2">
<p>…</p>
</li>
</ul>
<ul class="lvl-0">
<li class="lvl-2">
<p>Shell</p>
</li>
<li class="lvl-2">
<p>Python</p>
</li>
<li class="lvl-2">
<p>…</p>
</li>
</ul>
<ul class="lvl-0">
<li class="lvl-2">
<p>Shell</p>
</li>
<li class="lvl-2">
<p>Python</p>
</li>
<li class="lvl-2">
<p>…</p>
</li>
</ul>
<h3 id="you-xu-lie-biao">有序列表</h3>
<pre><code class="language-shell"># 注意后面有空格
1.
2.
3.
4.
</code></pre>
<p>效果如下：</p>
<ol>
<li class="lvl-3">
</li>
<li class="lvl-3">
</li>
<li class="lvl-3">
</li>
<li class="lvl-3">
</li>
</ol>
<h2 id="tu-pian">图片</h2>
<pre><code class="language-shell"># 本地图片
&lt;img src="/img/pusheencode.webp" alt="示例图片" style="zoom:50%;" /&gt;

# 在线图片
![code](https://pic1.zhimg.com/v2-31d8b80413b218910a3ab47bc7679258_r.jpg)
</code></pre>
<p>效果如下：</p>
<img src="/img/pusheencode.webp" alt="本地示例图片" style="zoom:50%;">
<p><img src="https://pic1.zhimg.com/v2-31d8b80413b218910a3ab47bc7679258_r.jpg" alt="在线示例图片"></p>
<h2 id="biao-ge">表格</h2>
<p>语法如下：</p>
<pre><code class="language-shell">|表头内容|表头内容|表头内容|表头内容|
| -------- | -------- | ---- | --- |
|表格内容1|表格内容1|表格内容1|表格内容1|
|表格内容2|表格内容2|表格内容2|表格内容2|
</code></pre>
<p>示例：</p>
<table>
<thead>
<tr>
<th>季度</th>
<th>资金（单位：元）</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>18900</td>
<td>买菜等日常开销</td>
</tr>
<tr>
<td>2</td>
<td>20900</td>
<td>买菜，换手机电池等日常开销</td>
</tr>
<tr>
<td>3</td>
<td>21000</td>
<td>超市购物，日常开销</td>
</tr>
<tr>
<td>4</td>
<td>28790</td>
<td>购买2024年年货是大头</td>
</tr>
</tbody>
</table>
<h2 id="ren-wu-lie-biao">任务列表</h2>
<p>代码：</p>
<pre><code class="language-markdown">- [ ] a task list item
  - [x] completed
  - [ ] incomplete
- [ ] list syntax required
- [x] completed
</code></pre>
<p>显示效果：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><input type="checkbox" id="checkbox0"><label for="checkbox0">a task list item</label></p>
<ul class="lvl-2">
<li class="lvl-4"><input type="checkbox" id="checkbox1" checked="true"><label for="checkbox1">completed</label></li>
<li class="lvl-4"><input type="checkbox" id="checkbox2"><label for="checkbox2">incomplete</label></li>
</ul>
</li>
<li class="lvl-2">
<p><input type="checkbox" id="checkbox3"><label for="checkbox3">list syntax required</label></p>
</li>
<li class="lvl-2">
<p><input type="checkbox" id="checkbox4" checked="true"><label for="checkbox4">completed</label></p>
</li>
</ul>
<h2 id="huan-xing">换行</h2>
<p>Markdown 中，段落之间的换行是通过在段落之间留空行的方式来实现。</p>
<pre><code class="language-shell">段落一

段落二
</code></pre>
<p>但我们会有其他的换行需求，可以这样实现：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>键入 HTML 语言换行标签：<code> </code>（通用）</p>
</li>
<li class="lvl-2">
<p>段落内换行使用换行符 <code> </code>，或者 <code>两个空格</code> + <code>shift-Enter</code>。不推荐使用 <code>\</code> + <code>shift-Enter</code>。</p>
</li>
<li class="lvl-2">
<p>Typora 中，空行中使用四个空格（一个 Tab）可以快速增大段落之间的间距</p>
</li>
</ul>
<p>为了演示效果，举例如下：</p>
<pre><code class="language-markdown">春望&lt;br&gt;唐代：杜甫

国破山河在，城春草木深。  
感时花溅泪，恨别鸟惊心。  
烽火连三月，家书抵万金。  
白头搔更短，浑欲不胜簪。
</code></pre>
<p>春望唐代：杜甫</p>
<p>国破山河在，城春草木深。感时花溅泪，恨别鸟惊心。烽火连三月，家书抵万金。白头搔更短，浑欲不胜簪。</p>
<p>（没有换行符，内容会在一行显示）</p>
<h2 id="duan-shou-suo-jin">段首缩进</h2>
<p>使用 Markdown 写文章不需要段首缩进。但如果你需要的话，可以在段落前面使用：</p>
<h3 id="liang-ge-quan-jiao-kong-ge">两个全角空格</h3>
<p>因为一个全角空格（space）的宽度是整整一个汉字，输入两个全角空格正好是两个汉字的宽度。</p>
<p>全角空格的输入方法为：一般的中文输入法都是按 shift + space，可以切换到全角模式下，输完后再次按 shift + space 切换回正常输入状态。</p>
<h3 id="shi-yong-te-shu-zhan-wei-fu">使用特殊占位符</h3>
<p>使用特殊占位符，不同占位符所占空白是不一样大的。</p>
<pre><code class="language-markdown">&amp;ensp; or &amp;#8194;  表示一个半角的空格
&amp;emsp; or &amp;#8195;  表示一个全角的空格
&amp;emsp;&amp;emsp;       两个全角的空格（用的比较多）
&amp;nbsp; or &amp;#160;   不断行的空白格
</code></pre>
<p>表示一个半角的空格<br>
  表示一个全角的空格<br>
   两个全角的空格（用的比较多）不断行的空白格</p>
<p>结合上面那首古诗，调整如下:</p>
<pre><code class="language-markdown">春&amp;emsp;&amp;emsp;望&lt;br&gt;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;唐代：杜甫

国破山河在，城春草木深。

感时花溅泪，恨别鸟惊心。

烽火连三月，家书抵万金。

白头搔更短，浑欲不胜簪。
</code></pre>
<p>展示效果如下：</p>
<p>春  望<br>    唐代：杜甫</p>
<p>国破山河在，城春草木深。</p>
<p>感时花溅泪，恨别鸟惊心。</p>
<p>烽火连三月，家书抵万金。</p>
<p>白头搔更短，浑欲不胜簪。</p>
<h2 id="zhe-die-nei-rong">折叠内容</h2>
<p>HTML <code>&lt;details&gt;</code> 标签指定了用户可以根据需要打开和关闭的额外细节。</p>
<p>语法：</p>
<pre><code class="language-html">&lt;details&gt; &lt;summary&gt;Title&lt;/summary&gt;
contents ...
&lt;/details&gt;
</code></pre>
<p>内容里面可以嵌套使用 Markdown 语法和 HTML 语法。</p>
<p>效果：</p>
<details><summary>Title</summary>
contents ...</details>
<p>在博客园的 Markdown 中，<code>&lt;details&gt;</code> 标签前面不能为空，要有字符或者空格：</p>
<pre><code class="language-html">&lt;details&gt; &lt;summary&gt;View Code&lt;/summary&gt;
code ...
&lt;/details&gt;
</code></pre>
<p>有的 Markdown 中，可能 <code>summary</code> 标签与正文间要空一行。比如：</p>
<pre><code class="language-html">&lt;details&gt; &lt;summary&gt;View Code&lt;/summary&gt;

code ...

&lt;/details&gt;
</code></pre>
<p>当然，有空行的话比较方便阅读源码。</p>
<h2 id="jiao-zhu">脚注</h2>
<h3 id="yu-fa">语法</h3>
<pre><code class="language-markdown">在这段文字后添加一个脚注[^footnote].

[^footnote]:这里是脚注的内容.
</code></pre>
<blockquote>
<p>footnote 可以是任意英文字符；脚注的内容可以放在文章的任意位置（一般放最后）。</p>
</blockquote>
<h3 id="ju-li">举例</h3>
<pre><code class="language-Markdown">使用 Markdown[^1] 可以效率的书写文档，直接转换成 HTML[^2], 你可以使用 Typora[^T] 软件。

[^1]:Markdown 是一种纯文本标记语言。
[^2]:HyperText Markup Language 超文本标记语言。
[^T]:Typora 官网 &lt;https://typora.io/&gt;
</code></pre>
<p>使用 Markdown<a href="https://keatonlao.gitee.io/a-study-note-for-markdown/syntax/%E8%AF%A6%E7%BB%86%E7%89%88/markdown-%E6%B7%BB%E5%8A%A0%E6%B3%A8%E8%84%9A/#fn:1">1</a> 可以效率的书写文档，直接转换成 HTML<a href="https://keatonlao.gitee.io/a-study-note-for-markdown/syntax/%E8%AF%A6%E7%BB%86%E7%89%88/markdown-%E6%B7%BB%E5%8A%A0%E6%B3%A8%E8%84%9A/#fn:2">2</a>，你可以使用 Typora<a href="https://keatonlao.gitee.io/a-study-note-for-markdown/syntax/%E8%AF%A6%E7%BB%86%E7%89%88/markdown-%E6%B7%BB%E5%8A%A0%E6%B3%A8%E8%84%9A/#fn:3">3</a> 软件。</p>
<blockquote>
<p>脚注显示在文章末尾；脚注后方的链接可以直接跳转回到加注的地方。</p>
</blockquote>
<hr>
<ol>
<li class="lvl-3">
<p>Markdown 是一种纯文本标记语言。 <a href="https://keatonlao.gitee.io/a-study-note-for-markdown/syntax/%E8%AF%A6%E7%BB%86%E7%89%88/markdown-%E6%B7%BB%E5%8A%A0%E6%B3%A8%E8%84%9A/#fnref:1">↩︎</a></p>
</li>
<li class="lvl-3">
<p>HyperText Markup Language 超文本标记语言。 <a href="https://keatonlao.gitee.io/a-study-note-for-markdown/syntax/%E8%AF%A6%E7%BB%86%E7%89%88/markdown-%E6%B7%BB%E5%8A%A0%E6%B3%A8%E8%84%9A/#fnref:2">↩︎</a></p>
</li>
<li class="lvl-3">
<p>Typora 官网 <a href="https://typora.io/">https://typora.io/</a> <a href="https://keatonlao.gitee.io/a-study-note-for-markdown/syntax/%E8%AF%A6%E7%BB%86%E7%89%88/markdown-%E6%B7%BB%E5%8A%A0%E6%B3%A8%E8%84%9A/#fnref:3">↩︎</a></p>
</li>
</ol>
<h2 id="te-shu-fu-hao">特殊符号</h2>
<p>特殊字符是相对于传统或常用的符号外，使用频率较少字符且难以直接输入的符号。比如数学符号；单位符号；<a href="https://baike.baidu.com/item/%E5%88%B6%E8%A1%A8%E7%AC%A6/7337607">制表符</a>等。</p>
<h3 id="shi-yong-te-shu-fu-hao">使用特殊符号</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a href="http://www.fhdq.net/">常用符号大全</a></p>
</li>
<li class="lvl-2">
<p><a href="https://emojipedia.org/">Emoji</a></p>
</li>
</ul>
<p>如果不嫌麻烦，写作时可以灵活运用一些特殊符号，以增加文档的趣味性：</p>
<p>常用排版： ▌▍◆★☆☁➤➜❤➊➋➌</p>
<p>TodoList： ✅☑✓✔√☓☒✘ㄨ✕✖✗❌❎</p>
<p>emoji：🌹🍀🌙🍂🍃🌷💎🔥⭐🍄🏆</p>
<h3 id="shi-yong-html-fu-hao">使用 HTML 符号</h3>
<ul class="lvl-0">
<li class="lvl-2">
<p><a href="https://www.w3school.com.cn/tags/html_ref_symbols.html">HTML 支持的特殊符号：数学符号 / 希腊字母 / 其他</a></p>
</li>
</ul>
<p>HTML 符号也都可以用到 Markdown 中。比如：</p>
<table>
<thead>
<tr>
<th style="text-align:left">结果</th>
<th style="text-align:left">描述</th>
<th style="text-align:left">实体名称</th>
<th style="text-align:left">实体编号</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">←</td>
<td style="text-align:left">left arrow</td>
<td style="text-align:left"><code>←</code></td>
<td style="text-align:left"><code>←</code></td>
</tr>
<tr>
<td style="text-align:left">↑</td>
<td style="text-align:left">up arrow</td>
<td style="text-align:left"><code>↑</code></td>
<td style="text-align:left"><code>↑</code></td>
</tr>
<tr>
<td style="text-align:left">→</td>
<td style="text-align:left">right arrow</td>
<td style="text-align:left"><code>→</code></td>
<td style="text-align:left"><code>→</code></td>
</tr>
<tr>
<td style="text-align:left">↓</td>
<td style="text-align:left">down arrow</td>
<td style="text-align:left"><code>↓</code></td>
<td style="text-align:left"><code>↓</code></td>
</tr>
<tr>
<td style="text-align:left">↔</td>
<td style="text-align:left">left right arrow</td>
<td style="text-align:left"><code>↔</code></td>
<td style="text-align:left"><code>↔</code></td>
</tr>
<tr>
<td style="text-align:left">↵</td>
<td style="text-align:left">carriage return arrow</td>
<td style="text-align:left"><code>↵</code></td>
<td style="text-align:left"><code>↵</code></td>
</tr>
</tbody>
</table>
<h2 id="ceng-ji-lie-biao">层级列表</h2>
<p>语法</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>{ 一级目录名称 }</p>
<ul class="lvl-2">
<li class="lvl-4">{ 二级目录名称 }
<ul class="lvl-4">
<li class="lvl-6">{ 三级目录名称 }
<ul class="lvl-6">
<li class="lvl-8">{ 四级目录名称 }
<ul class="lvl-8">
<li class="lvl-10">{ 五级目录名称 }<br>
…</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>层级列表每下一级的缩进都要比上一级多 2 个 Space 或 1 个Tab，且第一级前面不可超过 3 个空格。层级列表一般仅用一、二、三级列表，第一级的标识为实心圆点，第二级的标识为空心圆点，第三级的标识为实心方点。不过理论上可以有无数层级，但从第三级开始层级标识均为实心方点。</p>
<p>示例</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>文档</p>
<ul class="lvl-2">
<li class="lvl-4">什么是 Hexo</li>
<li class="lvl-4">安装
<ul class="lvl-4">
<li class="lvl-6">安装前提
<ul class="lvl-6">
<li class="lvl-8">安装 Git
<ul class="lvl-8">
<li class="lvl-10">Git 注意事项</li>
</ul>
</li>
<li class="lvl-8">安装 Node.js</li>
<li class="lvl-8">安装 Hexo</li>
</ul>
</li>
</ul>
</li>
<li class="lvl-4">使用</li>
</ul>
</li>
</ul>
<h2 id="liu-cheng-tu">流程图</h2>
<h3 id="heng-xiang-liu-cheng-tu">横向流程图</h3>
<pre><code class="language-markdown">graph LR;
A[Hard edge] --&gt;|Label| B(Round edge)
B --&gt; C{Decision}
C --&gt;|One| D[Result one]
C --&gt;|Two| E[Result two]
</code></pre>
<h3 id="zong-xiang-liu-cheng-tu">纵向流程图</h3>
<pre><code class="language-markdown">graph TD;

A[christmas] --&gt;B(Go shopping)

B --&gt; C{Let me think}

C --&gt;|One| D[Laptop]

C --&gt;|Two| E[iPhone]

C --&gt;|Three|F[Car]
</code></pre>
<h3 id="kong-zhi-tu">控制图</h3>
<pre><code class="language-markdown">st=&gt;start: Start
op=&gt;operation: Your Operation
cond=&gt;condition: Yes or No?
e=&gt;end

st-&gt;op-&gt;cond
cond(yes)-&gt;e
cond(no)-&gt;op
</code></pre>
<h3 id="xu-lie-tu">序列图</h3>
<pre><code class="language-markdown">sequenceDiagram

loop every day

Alice-&gt;&gt;John: Hello John, how are you?

John--&gt;&gt; Alice: Great!

end
</code></pre>
<h3 id="gan-te-tu">甘特图</h3>
<pre><code class="language-markdown">gantt

dateFormat YYYY-MM-DD

title 产品计划表

section 初期阶段

明确需求: 2016-03-01, 10d

section 中期阶段

跟进开发: 2016-03-11, 15d

section 后期阶段

走查测试: 2016-03-20, 9d
</code></pre>
<h1 id="hexo-matery-zhong-shi-yong-markdown">Hexo matery中使用markdown</h1>
<h2 id="note-ti-shi-kuai">NOTE提示块</h2>
<p>语法如下：</p>
<pre><code class="language-shell">{% note success %}
一个 Success 提示
{% endnote %}
</code></pre>
<div class="note success"><p>一个 Success 提示</p>
</div>
<p>提示块可以实现折叠:</p>
<pre><code class="language-shell">{% note success 一个折叠的提示 %}
一个折叠的 Success 提示
{% endnote %}
</code></pre>
<details class="note success"><summary><p>一个折叠的提示</p>
</summary>
  <p>一个折叠的 Success 提示</p>

  </details>
<p>完整的风格示例如下:</p>
<pre><code class="language-shell">{% note default %}
一个 default 提示
{% endnote %}

{% note primary %}
一个 primary 提示
{% endnote %}

{% note success %}
一个 success 提示
{% endnote %}

{% note info %}
一个 info 提示
{% endnote %}

{% note warning %}
一个 warning 提示
{% endnote %}

{% note danger %}
一个 danger 提示
{% endnote %}
</code></pre>
<p>效果如下：</p>
<div class="note default"><p>一个 default 提示</p>
</div>
<div class="note primary"><p>一个 primary 提示</p>
</div>
<div class="note success"><p>一个 success 提示</p>
</div>
<div class="note info"><p>一个 info 提示</p>
</div>
<div class="note warning"><p>一个 warning 提示</p>
</div>
<div class="note danger"><p>一个 danger 提示</p>
</div>
<h2 id="qi-ta-feng-ge-de-ti-shi">其他风格的提示</h2>
<blockquote>
<p>[!NOTE]<br>
Highlights information that users should take into account, even when skimming.</p>
</blockquote>
<blockquote>
<p>[!TIP]<br>
Optional information to help a user be more successful.</p>
</blockquote>
<blockquote>
<p>[!IMPORTANT]<br>
Crucial information necessary for users to succeed.</p>
</blockquote>
<blockquote>
<p>[!WARNING]<br>
Critical content demanding immediate user attention due to potential risks.</p>
</blockquote>
<blockquote>
<p>[!CAUTION]<br>
Negative potential consequences of an action.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong><br>
This is a note</p>
</blockquote>
<blockquote>
<p><strong>Tip</strong><br>
This is a tip</p>
</blockquote>
<blockquote>
<p><strong>Important</strong><br>
This is a important</p>
</blockquote>
<blockquote>
<p><strong>Warning</strong><br>
This is a warning</p>
</blockquote>
<blockquote>
<p><strong>Caution</strong><br>
This is a caution</p>
</blockquote>
<h2 id="shang-xia-biao">上下标</h2>
<p>Html 形式:</p>
<pre><code class="language-shell">Html&lt;sup&gt;上标&lt;/sup&gt;
Html&lt;sub&gt;下标&lt;/sub&gt;
</code></pre>
<p>效果如下:</p>
<p>Html<sup>上标</sup><br>
Html<sub>下标</sub></p>
<p>Markdown 形式：</p>
<pre><code class="language-shell">Markdown^上标^
Markdown~下标~ 
</code></pre>
<p>效果如下:</p>
<p>Markdown<sup>上标</sup><br>
Markdown<sub>下标</sub></p>
<h2 id="markdwon-plugin">markdwon plugin</h2>
<p>安装了下面一些插件:</p>
<pre><code class="language-shell">root@Gavin:~/gavin-wang-note.github.io# npm list |grep markdown
├── hexo-renderer-markdown-it@7.1.1
├── markdown-it-abbr@2.0.0
├── markdown-it-checkbox@1.1.0
├── markdown-it-deflist@3.0.0
├── markdown-it-expandable@1.0.2
├── markdown-it-footnote@4.0.0
├── markdown-it-imsize@2.0.1
├── markdown-it-ins@4.0.0
├── markdown-it-mark@4.0.0
├── markdown-it-named-headings@1.1.0
├── markdown-it-sub@2.0.0
└── markdown-it-sup@2.0.0
root@Gavin:~/gavin-wang-note.github.io#
</code></pre>
<p>简要说明如下：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">语法</th>
<th style="text-align:center">示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>markdown-it-abbr</td>
<td style="text-align:center">注释</td>
<td style="text-align:center">``</td>
<td style="text-align:center"><a href="https://colour008.gitee.io/2023/02/01/Hexo%E9%80%89%E6%8B%A9%E6%9B%B4%E9%AB%98%E7%BA%A7%E7%9A%84Markdown%E6%B8%B2%E6%9F%93%E5%99%A8/image-20230213205008739.png"><img src="https://colour008.gitee.io/2023/02/01/Hexo%E9%80%89%E6%8B%A9%E6%9B%B4%E9%AB%98%E7%BA%A7%E7%9A%84Markdown%E6%B8%B2%E6%9F%93%E5%99%A8/image-20230213205008739.png" alt="img"></a></td>
</tr>
<tr>
<td>markdown-it-emoji</td>
<td style="text-align:center">表情</td>
<td style="text-align:center"><code>:)</code></td>
<td style="text-align:center">������</td>
</tr>
<tr>
<td>markdown-it-footnote</td>
<td style="text-align:center">脚注</td>
<td style="text-align:center"><code>参考文献[^1]</code></td>
<td style="text-align:center">参考文献 [^1]</td>
</tr>
<tr>
<td>markdown-it-ins</td>
<td style="text-align:center">下划线</td>
<td style="text-align:center"><code>下划线</code></td>
<td style="text-align:center">下划线</td>
</tr>
<tr>
<td>markdown-it-mark</td>
<td style="text-align:center">突出显示</td>
<td style="text-align:center"><code>==标记==</code></td>
<td style="text-align:center">标记</td>
</tr>
<tr>
<td>markdown-it-sub</td>
<td style="text-align:center">下标</td>
<td style="text-align:center"><code>H~2~O</code></td>
<td style="text-align:center">H2O</td>
</tr>
<tr>
<td>markdown-it-sup</td>
<td style="text-align:center">上标</td>
<td style="text-align:center"><code>X^2^</code></td>
<td style="text-align:center">X2</td>
</tr>
<tr>
<td>markdown-it-checkbox</td>
<td style="text-align:center">复选框</td>
<td style="text-align:center"><input type="checkbox" id="checkbox5"><label for="checkbox5">选中：- [x]</label></td>
<td style="text-align:center"><a href="https://colour008.gitee.io/2023/02/01/Hexo%E9%80%89%E6%8B%A9%E6%9B%B4%E9%AB%98%E7%BA%A7%E7%9A%84Markdown%E6%B8%B2%E6%9F%93%E5%99%A8/image-20230205104237395.png"><img src="https://colour008.gitee.io/2023/02/01/Hexo%E9%80%89%E6%8B%A9%E6%9B%B4%E9%AB%98%E7%BA%A7%E7%9A%84Markdown%E6%B8%B2%E6%9F%93%E5%99%A8/image-20230205104237395.png" alt="img"></a></td>
</tr>
</tbody>
</table>
<h1 id="hui-zong">汇总</h1>
<h2 id="11-1-markdown-ji-chu-yu-fa">11.1 Markdown 基础语法</h2>
<table>
<thead>
<tr>
<th style="text-align:left">元素</th>
<th style="text-align:left">Markdown 语法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">标题</td>
<td style="text-align:left"><code># H1</code> <br><code>## H2</code> <br><code>### H3</code><br> <code>...</code></td>
</tr>
<tr>
<td style="text-align:left">粗体</td>
<td style="text-align:left"><code>**bold text**</code></td>
</tr>
<tr>
<td style="text-align:left">斜体</td>
<td style="text-align:left"><code>*italicized text*</code></td>
</tr>
<tr>
<td style="text-align:left">引用块</td>
<td style="text-align:left"><code>&gt; blockquote</code></td>
</tr>
<tr>
<td style="text-align:left">有序列表</td>
<td style="text-align:left"><code>1. First item</code><br> <code>2. Second item</code> <br><code>3. Third item</code></td>
</tr>
<tr>
<td style="text-align:left">无序列表</td>
<td style="text-align:left"><code>- First item</code><br> <code>- Second item</code> <br><code>- Third item</code></td>
</tr>
<tr>
<td style="text-align:left">代码</td>
<td style="text-align:left"><code>ˋcodeˋ</code></td>
</tr>
<tr>
<td style="text-align:left">分隔线</td>
<td style="text-align:left"><code>---</code></td>
</tr>
<tr>
<td style="text-align:left">链接</td>
<td style="text-align:left"><code>[title](https://www.example.com)</code></td>
</tr>
<tr>
<td style="text-align:left">图片</td>
<td style="text-align:left"><code>![alt text](image.jpg)</code></td>
</tr>
</tbody>
</table>
<h2 id="markdown-jin-jie-yu-fa">Markdown 进阶语法</h2>
<table>
<thead>
<tr>
<th style="text-align:left">元素</th>
<th style="text-align:left">Markdown 语法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">表格</td>
<td style="text-align:left"><code>| Syntax | Description |</code><br><code>| ----------- | ----------- |</code> <br><code>| Header | Title |</code> <br><code>| Paragraph | Text |</code></td>
</tr>
<tr>
<td style="text-align:left">代码块</td>
<td style="text-align:left"><code>ˋˋˋ</code> <code>{</code> <code>"firstName": "John",</code> <code>"lastName": "Smith",</code> <code>"age": 25</code> <code>}</code> <code>ˋˋˋ</code></td>
</tr>
<tr>
<td style="text-align:left">脚注</td>
<td style="text-align:left"><code>Here's a sentence with a footnote. [^1]</code><br> <code>[^1]: This is the footnote.</code></td>
</tr>
<tr>
<td style="text-align:left">标题编号</td>
<td style="text-align:left"><code>### My Great Heading {‏#custom-id‏}</code></td>
</tr>
<tr>
<td style="text-align:left">定义列表</td>
<td style="text-align:left"><code>term</code> <br><code>: definition</code></td>
</tr>
<tr>
<td style="text-align:left">删除线</td>
<td style="text-align:left"><code>~~The world is flat.~~</code></td>
</tr>
<tr>
<td style="text-align:left">任务列表</td>
<td style="text-align:left"><code>- [‏x] Write the press release</code><br> <code>- [‏ ] Update the website</code> <br><code>- [‏ ] Contact the media</code></td>
</tr>
</tbody>
</table>
<h2 id="markdown-gao-ji-yu-fa">Markdown 高级语法</h2>
<table>
<thead>
<tr>
<th style="text-align:left">元素</th>
<th style="text-align:left">Markdown 语法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">上标</td>
<td style="text-align:left"><code>^上标^</code></td>
</tr>
<tr>
<td style="text-align:left">下标</td>
<td style="text-align:left"><code>~下标~</code></td>
</tr>
<tr>
<td style="text-align:left">指定大小的图片</td>
<td style="text-align:left"><code>![alt text](image.jpg =100x100)</code> <br><code>![alt text](image.jpg =50%x)</code></td>
</tr>
<tr>
<td style="text-align:left">高亮标记</td>
<td style="text-align:left"><code>==Mark Text==</code></td>
</tr>
<tr>
<td style="text-align:left">插入字（下划线）</td>
<td style="text-align:left"><code>++Ins Text++</code></td>
</tr>
<tr>
<td style="text-align:left">缩写注释(abbr)</td>
<td style="text-align:left"><code>*[Abbr]: Abbreviation</code></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>locust接口压测实战</title>
    <url>/2024/02/02/locust/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Locust工具虽然在很多年前使用过，但从未做过相关内容的总结。本次在测试过程中有试用到此工具，故而简单mark一下。</p>
<p>Locust是一个比较容易上手的、开源的分布式用户负载测试工具，它允许你使用Python代码来定义用户行为，并模拟数以万计的用户对网站或应用程序进行压力测试。Locust 在英文中是 蝗虫 的意思：作者的想法是在测试期间，放一大群 蝗虫 攻击您的网站。当然事先是可以用 Locust 定义每个蝗虫（或测试用户）的行为，并且通过 Web UI 实时监视围攻过程。由于其灵活性及易用性，Locust在开发者和测试工程师中相当受欢迎。</p>
<p>Locust 的运行原理是完全基于事件运行的，因此可以在一台计算机上支持数千个并发用户。与许多其他基于事件的应用程序相比，它不使用回调（比如 <code>Nodejs</code> 就是属于回调，Locust 不使用这种的逻辑）。相反，它通过 <code>gevent</code> 使用轻量级进程。测试您站点的每个蝗虫实际上都在其自己的进程中运行。</p>
<h1 id="an-zhuang-locust">安装 locust</h1>
<h2 id="pip-3-an-zhuang-locust">pip3 安装 locust</h2>
<p><code>pip3  install locust</code></p>
<h2 id="cha-kan-shi-fou-an-zhuang-cheng-gong">查看是否安装成功</h2>
<p><code>locust -h</code></p>
<h2 id="yun-xing-locust-fen-bu-zai-duo-ge-jin-cheng-ji-qi-ku">运行 locust 分布在多个进程/机器库</h2>
<p><code>pip3 install pyzmq</code></p>
<h2 id="an-zhuang-web-socket-ya-ce-ku">安装 webSocket 压测库</h2>
<p><code>pip3 install websocket-client</code></p>
<h1 id="task-sequence-lei">TaskSequence 类</h1>
<p>Locust 提供了一些核心的类，使得你可以通过编写Python脚本来定义模拟用户的行为。以下是一些主要的 Locust 类及其作用：</p>
<h2 id="code-http-user-code"><code>HttpUser</code></h2>
<p>这是 Locust 中最常用的类之一，用于模拟发送HTTP请求的用户。继承此类可以定义发送HTTP请求的任务，如访问网页、API调用等。<code>HttpUser</code> 类为你的用户任务提供了 <code>.client</code> 属性，通过这个属性，你可以发起 GET、POST 等请求。</p>
<h2 id="code-task-set-code"><code>TaskSet</code></h2>
<p><code>TaskSet</code> 允许你定义一个用户执行的任务集合。一个 <code>TaskSet</code> 可以包含一个或多个任务，任务之间可以有不同的权重，表示任务被执行的相对概率。<code>TaskSet</code> 可以被嵌套，即一个 <code>TaskSet</code> 中可以包含另一个 <code>TaskSet</code>。</p>
<h2 id="code-task-code"><code>task</code></h2>
<p><code>task</code> 是一个装饰器，用于将某个方法标记为一个任务。这个装饰器可以应用于 <code>HttpUser</code> 和 <code>TaskSet</code> 类下的方法。可以通过为装饰器设置权重参数（一个整数）来调整任务被执行的频率。</p>
<h2 id="code-sequential-task-set-code"><code>SequentialTaskSet</code></h2>
<p>这个类是 <code>TaskSet</code> 的一个特殊版本，它会按照任务被定义的顺序来执行任务，而不是随机选择任务执行。这对于需要以特定顺序执行任务的测试非常有用，比如用户注册流程—先填写表单，然后接收验证邮件，最后验证账号。</p>
<h2 id="code-fast-http-user-code"><code>FastHttpUser</code></h2>
<p>此类与 <code>HttpUser</code> 类似，但使用的是更快、更轻量级的HTTP客户端（基于<code>geventhttpclient</code>）。<code>FastHttpUser</code> 适用于需要极高性能和并发量的场景，但可能不支持 <code>HttpUser</code> 中的某些高级HTTP功能。</p>
<h2 id="code-between-code"><code>between</code></h2>
<p><code>between</code> 是一个函数，用于为用户任务之间的等待时间设置随机时间间隔。该函数接受两个参数，分别表示最小等待时间和最大等待时间。</p>
<h2 id="code-constant-code"><code>constant</code></h2>
<p><code>constant</code> 是另一个用于设置用户任务之间等待时间的函数，其提供了一个固定的等待时间。</p>
<h2 id="shi-yong-shi-li">使用示例</h2>
<pre><code class="language-python">from locust import HttpUser, task, between

class MyUser(HttpUser):
    wait_time = between(1, 5)  # 用户任务之间的等待时间为1到5秒之间的随机值

    @task(2)
    def read_item(self):
        self.client.get("/item")

    @task(1)
    def write_item(self):
        self.client.post("/item", {"data": "value"})
</code></pre>
<p>在这个示例中，<code>MyUser</code> 类继承自 <code>HttpUser</code> 类，代表一个HTTP用户。定义了两个任务：<code>read_item</code> 和 <code>write_item</code>，其中 <code>read_item</code> 的执行频率是 <code>write_item</code> 的两倍。</p>
<h1 id="chu-shi-hua-fang-fa">初始化方法</h1>
<ul class="lvl-0">
<li class="lvl-2">
<p>setup 和 teardown 方法 setup 和 teardown 都是只能运行一次的方法。</p>
<ul class="lvl-2">
<li class="lvl-4">在任务开始运行之前运行setup，而在所有任务完成并且蝗虫退出后运行 teardown；这使你能够在任务开始运行之前做一些准备工作（比如创建数据库，或者打印日志 等等），并在Locust退出之前进行清理。</li>
</ul>
</li>
<li class="lvl-2">
<p>on_start 和 on_stop 方法 每个虚拟用户执行操作时运行on_start方法，退出时执行on_stop方法。</p>
</li>
<li class="lvl-2">
<p>初始化方法的执行顺序 setup &gt; on_start &gt; on_stop &gt; teardown。</p>
</li>
</ul>
<h1 id="qi-dong-fang-shi">启动方式</h1>
<p>常用3种启动方式，直接启动，无web页面启动和分布式启动。</p>
<h2 id="zhi-jie-qi-dong">直接启动</h2>
<pre><code class="language-shell">locust -f your_locust.py
（your_locust.py为执行脚本，可在编译器中直接运行该脚本）
</code></pre>
<h2 id="wu-web-ye-mian-qi-dong">无web页面启动</h2>
<pre><code class="language-shell">locust -f your_locust.py --no-web -c 200 -r 20 -t 1m
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>（–no-web 代表不需要启动UI页面</p>
</li>
<li class="lvl-2">
<p>-c 代表需要并发的用户数</p>
</li>
<li class="lvl-2">
<p>-r 代表每秒并发的用户数</p>
</li>
<li class="lvl-2">
<p>-t 代表需要运行的时间）</p>
</li>
</ul>
<h2 id="fen-bu-shi-qi-dong">分布式启动</h2>
<p>Locust与Jmeter不同，Jmeter进行压测的时候，会一下子使用到CPU的所有核心，但是locust运行时，只会使用到CPU的一个核心，所以当单次运行无法达到想到的压力值。采用分布式运行，可以充分运用到CPU的所有内核，生成更大负载，也可以直接接入远程机，让负载值飞跃增长。</p>
<pre><code class="language-shell">locust -f your_locust.py --master # 指定当前机器为master主机
locust -f your_locust.py --slave --master-host=10.xxx.xxx.xxx # 指定当前机器为从机并指向对应master主机
</code></pre>
<h3 id="ben-di-ji-yun-xing-fen-bu-shi">本地机运行分布式</h3>
<p>主程采用master运行。</p>
<pre><code class="language-shell">locust -f your_locust.py --master # 指定当前机器为master主机
</code></pre>
<p>与旧版locust不同，新版不能使用salve，需要采用worker运行负载，如下。</p>
<pre><code class="language-shell">locust -f locust.py --worker
</code></pre>
<p>每运行一次，就会多一个负载。（最大负载为CPU核心数）</p>
<h3 id="yuan-cheng-ji-jie-he-yun-xing-fen-bu-shi">远程机结合运行分布式</h3>
<p>主机负载同上，当运行负载机时，需要指定主机的IP。如下</p>
<pre><code class="language-shell">locust -f your_locust.py --worker --master-host=IP
</code></pre>
<p>在 Locust 中，你可以通过命令行参数来指定测试的运行时间。使用 <code>-t</code> 或 <code>--run-time</code> 参数后面跟上你想要的运行时间，如 <code>10s</code>（10秒）、<code>5m</code>（5分钟）、<code>1h</code>（1小时）等。</p>
<p>例如，如果你想运行 Locust 测试5分钟，你可以在命令行中这样指定：</p>
<pre><code class="language-shell">locust -f your_locust.py --users 100 --spawn-rate 10 -t 5m
</code></pre>
<p>在这个命令中：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>-f locustfile.py</code> 指定了 Locust 测试脚本文件。</p>
</li>
<li class="lvl-2">
<p><code>--users 100</code> 指定了总共模拟的用户数。</p>
</li>
<li class="lvl-2">
<p><code>--spawn-rate 10</code> 指定了每秒生成用户的速率。</p>
</li>
<li class="lvl-2">
<p><code>-t 5m</code> 或者 <code>--run-time 5m</code> 指定了测试运行的时间，即5分钟。</p>
</li>
</ul>
<p>Locust 会在指定的时间结束后停止运行。这对于需要在持续集成/持续部署 (CI/CD) 管道中自动执行性能测试非常有用。这样你可以确保性能测试不会无限期地运行，而是在完成足够的模拟用户行为后自动停止。</p>
<h1 id="dai-ma-mo-ban">代码模板</h1>
<p>如下模板演示了如何使用 Locust 进行基本的负载测试，包括模拟多种用户行为、使用任务集和处理不同类型的HTTP请求。</p>
<pre><code class="language-python">from locust import HttpUser, TaskSet, task, between

# 定义用户行为
class UserTasks(TaskSet):
    # 通过装饰器设置任务，数字表示任务权重，权重越高任务被选中的概率越大
    @task(2)
    def view_main_page(self):
        # 模拟用户浏览主页
        self.client.get("/")

    @task(1)
    def view_about_page(self):
        # 模拟用户浏览关于页面
        self.client.get("/about")
    
    # 嵌套 TaskSet 示例，用于模拟具有多个步骤的用户交互流程
    @task(1)
    class PostMessage(TaskSet):
        # 步骤1: 浏览到发帖页面
        @task
        def view_post_page(self):
            self.client.get("/post")
        
        # 步骤2: 提交一个帖子
        @task
        def post_message(self):
            self.client.post("/submit", data={"message": "Hello World"})
            # 嵌套任务完成后，调用self.interrupt结束当前TaskSet，返回上一级TaskSet
            self.interrupt()

# 定义用户模拟类
class WebsiteUser(HttpUser):
    tasks = [UserTasks]  # 将用户任务关联到HttpUser
    wait_time = between(1, 5)  # 设置用户执行任务的等待时间，介于1到5秒随机

</code></pre>
<p><strong>说明：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>UserTasks</code> 类继承自 <code>TaskSet</code>，表示一组用户可以执行的任务。你可以在此类中定义多个任务，这些任务可以是访问某个页面、提交表单等。</p>
</li>
<li class="lvl-2">
<p><code>tasks</code> 属性用于将 <code>TaskSet</code> 与用户类 <code>HttpUser</code> 关联起来。该属性可以是一个列表，包含多个 <code>TaskSet</code> 类。</p>
</li>
<li class="lvl-2">
<p><code>wait_time</code> 定义了用户在执行完一个任务后，再执行下一个任务前的等待时间。这里使用了 <code>between</code> 函数，意味着等待时间将在1到5秒之间随机选择。</p>
</li>
<li class="lvl-2">
<p><code>@task</code> 装饰器标记了哪些方法是任务。通过为装饰器提供参数，你可以设置任务的执行权重。未指定权重时，默认为1。</p>
</li>
<li class="lvl-2">
<p><code>self.client.get</code> 和 <code>self.client.post</code> 方法分别用于发起GET和POST请求。<code>HttpUser</code> 类提供的 <code>self.client</code> 属性是一个 <code>Session</code> 对象，用于发起 HTTP 请求，并自动携带任何以前设置的cookies等。</p>
</li>
<li class="lvl-2">
<p>嵌套 <code>TaskSet</code> (<code>PostMessage</code>) 演示了一个更复杂的用户行为，其中用户需要执行一系列有顺序的任务。使用 <code>self.interrupt()</code> 来退出嵌套的任务集合。</p>
</li>
</ul>
<p>这个模板是一个Locust测试的起点，通过自定义和扩展这个模板，你可以为你的应用或服务创建各种复杂的负载测试场景。</p>
<h1 id="shi-zhan">实战</h1>
<h2 id="ce-shi-yao-qiu">测试要求</h2>
<p>假如产品内嵌搜索引擎，简单压测一下搜索能力。</p>
<h2 id="ce-shi-dai-ma">测试代码</h2>
<p>先手工发起对应的业务请求，摘取请求中的Header信息。比如通过Firefox Browser，摘取headers信息：</p>
<pre><code class="language-shell">root@Gavin:~# cat header.search 
Host: search.xxxx.cn
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0
Accept: */*
Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
Accept-Encoding: gzip, deflate, br
Referer: https://search.xxxx.cn/aiSearchPage
RSC: 1
Next-Router-State-Tree: %5B%22%22%2C%7B%22children%22%3A%5B%22aiSearchPage%22%2C%7B%22children%22%3A%5B%22__PAGE__%22%2C%7B%7D%5D%7D%5D%7D%2Cnull%2Cnull%2Ctrue%5D
Next-Router-Prefetch: 1
Next-Url: /aiSearchPage
Connection: keep-alive
Sec-Fetch-Dest: empty
Sec-Fetch-Mode: cors
Sec-Fetch-Site: same-origin
Pragma: no-cache
Cache-Control: no-cache
root@Gavin:~#
</code></pre>
<p>保存为<code>header.search</code>文件，借助如下脚本，转换成JSON格式内容：</p>
<pre><code class="language-shell">root@Gavin:~# cat change_head_to_json.py 
#!/usr/bin/env python

import os
import sys
import json


file_name = "./header.search"
head_json = "./header.json"


def file_check():
    if not os.path.exists(file_name):
        print(f"[ERROR]  Not find file : {file_name}, exit!!!")
        sys.exit(1)


def read_file_content(file_name):
    with open(file_name, 'r', encoding='utf-8') as file:
        return file.read()


def format_header_to_json():
    header_content = read_file_content(file_name)

    # 使用字典推导式将每一行转换为键值对，分割点为第一个": "序列
    headers = {line.split(": ")[0]: line.split(": ")[1] for line in header_content.strip().split("\n")}

    # 将字典转换为JSON并写入文件
    with open(head_json, "w", encoding="utf-8") as json_file:
        json.dump(headers, json_file, indent=4, ensure_ascii=False)


if __name__ == '__main__':
    format_header_to_json()
</code></pre>
<p>然后，编写发起业务请求的脚本，参考如下:</p>
<pre><code class="language-python">#!/usr/bin/env python
# -*- coding:GB2312 -*-

import random
from locust import HttpUser, task, between


class UserRun(HttpUser): 
    wait_time = between(0.1, 0.3)

    def on_start(self):
        print("Start\n")

    @task(2)
    def Agent_Search(self):
        url = 'https://search.xxxx.cn/aiSearchPage/search?q=locust%2520post%25E8%25AF%25B7%25E6%25B1%2582&amp;rid=fwgto8n3F4e6m0nmHJ2X_&amp;modelName=glm-4&amp;_rsc=16qln'
        headers = {
    "Host": "search.xxxx.cn",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0",
    "Accept": "*/*",
    "Accept-Language": "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2",
    "Accept-Encoding": "gzip, deflate, br",
    "Referer": "https://search.xxxx.cn/aiSearchPage",
    "RSC": "1",
    "Next-Router-State-Tree": "%5B%22%22%2C%7B%22children%22%3A%5B%22aiSearchPage%22%2C%7B%22children%22%3A%5B%22__PAGE__%22%2C%7B%7D%5D%7D%5D%7D%2Cnull%2Cnull%2Ctrue%5D",
    "Next-Router-Prefetch": "1",
    "Next-Url": "/aiSearchPage",
    "Connection": "keep-alive",
    "Sec-Fetch-Dest": "empty",
    "Sec-Fetch-Mode": "cors",
    "Sec-Fetch-Site": "same-origin",
    "Pragma": "no-cache",
    "Cache-Control": "no-cache"}

        # 发起请求，并捕获响应以手动处理
        with self.client.get(url, headers=headers, catch_response=True) as response:
            if response.status_code == 200:
                # 当状态码为200时，直接认为请求成功
                response.success()
            elif response.status_code == 404:
                # 即使是404状态，也可以手动将请求标记为成功
                response.failure('Agent search 404！')
            else:
                # 其他情况，默认为失败，无需手动处理
                response.failure('Agent search 接口失败！')

    def on_stop(self):
        print("End\n")
</code></pre>
<h2 id="ce-shi-yun-xing">测试运行</h2>
<pre><code class="language-shell">C:\Users\Wang&gt;locust -f C:\Users\Wang\Desktop\locust_test_script.py --users 100 --spawn-rate 10 -t 5m
[2024-02-02 15:43:34,563] Gavin/INFO/locust.main: Starting web interface at http://localhost:8089 (accepting connections from all network interfaces)
[2024-02-02 15:43:34,570] Gavin/INFO/locust.main: Starting Locust 2.21.0
[2024-02-02 15:49:49,212] Gavin/INFO/locust.runners: Ramping to 100 users at a rate of 10.00 per second
</code></pre>
<p>这个时候，打开<code>http://localhost:8089/</code>网页，会出现如下要配置页面：</p>
<img class="shadow" src="/img/in-post/locust/locust-Start-new-load-test.png" width="600">
<ul class="lvl-0">
<li class="lvl-2">
<p>Number of users ：压力测试的用户总量，如上面的100</p>
</li>
<li class="lvl-2">
<p>Spawn rate：每秒增加的用户量，从10开始增加直到用户总量数停止。</p>
</li>
<li class="lvl-2">
<p>Host：被测接口的域名或<code>IP</code>端口地址(带<code>http://</code>或者<code>https://</code>)</p>
</li>
</ul>
<p>设置好参数后，点击<code>Start swarming</code>按钮，开始测试，各个页面信息介绍如下。</p>
<h2 id="ge-ge-ye-mian-jie-shao">各个页面介绍</h2>
<h3 id="statistics">Statistics</h3>
<img class="shadow" src="/img/in-post/locust/locust-statistics.png" width="1200">
<p>上图显示当前接口的URL，请求量，失败数，请求响应中值，平均值，当前RPS等信息。<br>
RPS（也叫TPS）：每秒钟处理完的事务次数，一般TPS是对整个系统来讲的。一个应用系统1s能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个接口服务的处理能力，用QPS(每秒查询率)比较多。</p>
<p>顺便介绍几个概念：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>PV</code>是指页面被浏览的次数，比如你打开一网页，那么这个网站的<code>PV</code>就算加了一次；</p>
</li>
<li class="lvl-2">
<p><code>TPS</code>是每秒内的事务数，比如执行了<code>DML</code>操作，那么相应的<code>TPS</code>会增加；</p>
</li>
<li class="lvl-2">
<p><code>QPS</code>是指每秒内查询次数，比如执行了<code>SELECT</code>操作，相应的<code>QPS</code>会增加。</p>
</li>
</ul>
<p>不同的应用系统<code>TPS</code>，<code>QPS</code>是没有可对比性的。</p>
<p>例如：</p>
<p>应用A，每个select查询需要1 ms, 一个connection的话，一直不停的执行，1 s 内 可执行1000次，也就是1000 QPS；</p>
<p>应用B，每个select查询需要100 ms, 一个connection的话，一直不停的执行，1 s 内 可执行10次，也就是10 QPS。</p>
<p>上面不同系统的两个<code>QPS</code>是无法对比的，不能说哪个好哪个坏，满足业务要求才是王道。</p>
<h3 id="charts">Charts</h3>
<img class="shadow" src="/img/in-post/locust/locust-charts.png" width="1200">
<p>Charts分为三个部分，分别是：</p>
<p>Total Requests per Second: 展示随着用户的增加，<code>TPS</code>变化数。</p>
<p>Response Times(ms): 展示接口从开始压测，到稳定实时的响应时间，随着压力增加，一般会升高。</p>
<p>Number of Users: 展示从0开始，每秒增加10人，直到总数100后不再增加。</p>
<h3 id="failures">Failures</h3>
<img class="shadow" src="/img/in-post/locust/locust-Failures.png" width="1200">
<p>只有在发生异常情况下，此页面才会有失败，记录失败的HTTP相关信息。</p>
<h3 id="exception">Exception</h3>
<img class="shadow" src="/img/in-post/locust/locust-exception.png" width="1200">
<p>只有当测试脚本发送异常，比如HTTP请求发送失败，此处会记录异常信息，供调试代码使用。</p>
<h3 id="current-ratio">Current Ratio</h3>
<img class="shadow" src="/img/in-post/locust/locust-current-ratio.png" width="1200">
<p>记录当前测试函数（红框中所标示）的ratio信息，100%最好，低于此值则测试预期可能不达标。</p>
<h3 id="download-data">Download Data</h3>
<p>测试数据下载模块， 提供四种类型的<code>CSV</code>格式的下载， 分别是：<code>Statistics、responsetime、failures、exceptions</code>。</p>
<img class="shadow" src="/img/in-post/locust/locust-download-data.png" width="1200">
<h1 id="locust-xiao-jie">Locust小结</h1>
<h2 id="you-shi">优势</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>可编程性</strong>：Locust使用Python，这意味着你可以编写Python脚本来定义复杂的用户行为，利用Python的强大库资源。</p>
</li>
<li class="lvl-2">
<p><strong>轻量级且易于安装</strong>：Locust是一个相对轻量级的工具，安装过程简单方便。</p>
</li>
<li class="lvl-2">
<p><strong>Web界面</strong>：提供一个易于使用的web界面用于启动测试、实时查看测试结果和统计信息。</p>
</li>
<li class="lvl-2">
<p><strong>可扩展性</strong>：支持分布式测试，你可以很容易地通过增加更多的Slave节点来模拟数十万甚至数百万的并发用户。</p>
</li>
<li class="lvl-2">
<p><strong>实时统计</strong>：通过Web UI，Locust能够实时展示请求统计、响应时间图表等数据，使结果分析更为直观。</p>
</li>
<li class="lvl-2">
<p><strong>适用性广</strong>：可以用来测试网站、API、数据库等多种服务的性能。</p>
</li>
</ul>
<h2 id="ju-xian-xing">局限性</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>性能问题</strong>：虽然Locust本身是高效的，但它运行Python脚本，这可能不如一些编译语言（如C++或Go）编写的测试工具性能高。</p>
</li>
<li class="lvl-2">
<p><strong>资源消耗</strong>：在模拟非常高的并发用户数时，Locust（特别是运行Locust的机器）可能会消耗大量的CPU和内存资源。</p>
</li>
<li class="lvl-2">
<p><strong>学习曲线</strong>：对于那些不熟悉Python的用户来说，初学Locust可能会有一定的学习曲线。</p>
</li>
<li class="lvl-2">
<p><strong>对高级负载模式的支持有限</strong>：虽然Locust非常灵活，但在一些非常特定的负载测试场景（如具有复杂的用户会话管理或定制的网络协议）中，可能需要进行相当多的自定义编码。</p>
</li>
<li class="lvl-2">
<p><strong>社区和支持</strong>：尽管Locust有一个活跃的社区，但与某些更成熟的压力测试工具相比（如Jmeter），其用户基础和可用资源可能较少。</p>
</li>
</ul>
<p>总的来说，Locust是一个功能强大且灵活的负载测试工具，特别适合那些熟悉Python并希望快速构建和执行实时监控负载测试的开发者和测试人员。然而，每个工具都有其优势和局限性，选择合适的工具应基于具体的测试需求和场景。</p>
]]></content>
      <categories>
        <category>performance</category>
        <category>locust</category>
      </categories>
      <tags>
        <tag>performance</tag>
        <tag>locust</tag>
      </tags>
  </entry>
  <entry>
    <title>《pytest测试指南》-- 章节1-2 pytest测试用例执行</title>
    <url>/2024/02/17/pytest_test_guide_part1_chapter1_2_run_pytest_case/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，密码错误！" data-whm="抱歉, 这个文章不能被校验, 不过你还是能看看解密后的内容。">
  <script id="hbeData" type="hbeData" data-hmacdigest="5409fff43ef1f283bb61282ff6072d2519c83aaac0d27cdea64563c786f8777a">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-flip">
      <input class="hbe hbe-input-field hbe-input-field-flip" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-flip" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-flip" data-content="您好, 这里需要输入密码，解密后方可查看内容。">您好, 这里需要输入密码，解密后方可查看内容。</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>《pytest测试指南》-- 章节1-3 pytest参数详解PART1</title>
    <url>/2024/03/03/pytest_test_guide_part1_chapter1_3_1_pytest_params/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p><code>pytest</code> 提供了丰富的参数，本文以 <code>pytest 7.4.0</code> 版本为基础，在未安装任何额外插件情况下，分类阐述参数的使用方法与介绍：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>positional arguments</p>
</li>
<li class="lvl-2">
<p>general（通用）</p>
</li>
<li class="lvl-2">
<p>Reporting （报告）</p>
</li>
<li class="lvl-2">
<p>pytest-warnings （告警）</p>
</li>
<li class="lvl-2">
<p>collection （信息收集）</p>
</li>
<li class="lvl-2">
<p>test session debugging and configuration （测试会话调试和配置）</p>
</li>
<li class="lvl-2">
<p>logging （日志记录）</p>
</li>
<li class="lvl-2">
<p>[pytest] ini-options （pytest配置文件–pytest.ini|tox.ini|setup.cfg|pyproject.toml ）</p>
</li>
</ul>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>对于一些常用参数，在本书后续独立章节详细介绍。</p>
</li>
<li class="lvl-2">
<p>本文以 <code>pytest 7.4.0</code> 版本下展示的参数进行说明描述，<code>pytest</code> 版本不同，参数会有些许差异，所以你应当参照你所使用的 <code>pytest</code> 版本的官方文档以获得最准确的信息。</p>
</li>
</ul>
<h1 id="3-1-pytest-can-shu-jie-shao-yu-shi-li">3.1 pytest 参数介绍与示例</h1>
<h2 id="3-1-1-cha-kan-pytest-suo-you-ke-yong-can-shu">3.1.1 查看pytest所有可用参数</h2>
<p>可以使用<code>pytest -h</code> 或者 <code>pytest --help</code> ，查看所有可用参数：</p>
<pre><code class="language-shell">root@Gavin:~# pytest -h
usage: pytest [options] [file_or_dir] [file_or_dir] [...]

positional arguments:
  file_or_dir

general:
  -k EXPRESSION         Only run tests which match the given substring expression. An                             expression is a Python evaluatable expression where all names are                         substring-matched against test names and their parent classes.                           Example: -k 'test_method or test_other' matches all test                                 functions and classes whose name contains 'test_method' or                               'test_other', while -k 'not test_method' matches those that don't                         contain 'test_method' in their names. -k 'not test_method
                        and not test_other' will eliminate the matches. Additionally                             keywords are matched to classes and functions containing extra                           names in their 'extra_keyword_matches' set, as well as functions                         which have names assigned directly to them. The matching is case-                         insensitive.
  -m MARKEXPR           Only run tests matching given mark expression. For example: -m                           'mark1 and not mark2'.
  --markers             show markers (builtin, plugin and per-project ones).
  -x, --exitfirst       Exit instantly on first error or failed test
  --fixtures, --funcargs
                        Show available fixtures, sorted by plugin appearance (fixtures 
                        with leading '_' are only shown with '-v')
  --fixtures-per-test   Show fixtures per test
  --pdb                 Start the interactive Python debugger on errors or 
                        KeyboardInterrupt
  --pdbcls=modulename:classname
                        Specify a custom interactive Python debugger for use with 
                        --pdb.For example: --pdbcls=IPython.terminal.debugger:TerminalPdb
  --trace               Immediately break when running each test
  --capture=method      Per-test capturing method: one of fd|sys|no|tee-sys
  -s                    Shortcut for --capture=no
  --runxfail            Report the results of xfail tests as if they were not marked
  --lf, --last-failed   Rerun only the tests that failed at the last run (or all if 
                        none failed)
  --ff, --failed-first  Run all tests, but run the last failures first. This may re-order
                        tests and thus lead to repeated fixture setup/teardown.
  --nf, --new-first     Run tests from new files first, then the rest of the tests sorted
                        by file mtime
  --cache-show=[CACHESHOW]
                        Show cache contents, don't perform collection or tests. Optional
                        argument: glob (default: '*').
  --cache-clear         Remove all cache contents at start of test run
  --lfnf={all,none}, --last-failed-no-failures={all,none}
                        Which tests to run with no previously (known) failures
  --sw, --stepwise      Exit on test failure and continue from last failing test next
                        time
  --sw-skip, --stepwise-skip
                        Ignore the first failing test but stop on the next failing test.                         Implicitly enables --stepwise.

Reporting:
  --durations=N         Show N slowest setup/test durations (N=0 for all)
  --durations-min=N     Minimal duration in seconds for inclusion in slowest list.
                        Default: 0.005.
  -v, --verbose         Increase verbosity
  --no-header           Disable header
  --no-summary          Disable summary
  -q, --quiet           Decrease verbosity
  --verbosity=VERBOSE   Set verbosity. Default: 0.
  -r chars              Show extra test summary info as specified by chars: (f)ailed,
                        (E)rror, (s)kipped, (x)failed, (X)passed, (p)assed, (P)assed with
                        output, (a)ll except passed (p/P), or (A)ll. (w)arnings are 
                        enabled by default (see
                        --disable-warnings), 'N' can be used to reset the list. (default:
                        'fE').
  --disable-warnings, --disable-pytest-warnings
                        Disable warnings summary
  -l, --showlocals      Show locals in tracebacks (disabled by default)
  --no-showlocals       Hide locals in tracebacks (negate --showlocals passed through
                        addopts)
  --tb=style            Traceback print mode (auto/long/short/line/native/no)
  --show-capture={no,stdout,stderr,log,all}
                        Controls how captured stdout/stderr/log is shown on failed tests.
                        Default: all.
  --full-trace          Don't cut any tracebacks (default is to cut)
  --color=color         Color terminal output (yes/no/auto)
  --code-highlight={yes,no}
                        Whether code should be highlighted (only if --color is also
                        enabled). Default: yes.
  --pastebin=mode       Send failed|all info to bpaste.net pastebin service
  --junit-xml=path      Create junit-xml style report file at given path
  --junit-prefix=str    Prepend prefix to classnames in junit-xml output

pytest-warnings:
  -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS
                        Set which warnings to report, see -W option of Python itself
  --maxfail=num         Exit after first num failures or errors
  --strict-config       Any warnings encountered while parsing the `pytest` section of
                        the configuration file raise errors
  --strict-markers      Markers not registered in the `markers` section of the 
                        configuration file raise errors
  --strict              (Deprecated) alias to --strict-markers
  -c FILE, --config-file=FILE
                        Load configuration from `FILE` instead of trying to locate one of
                        the implicit configuration files.
  --continue-on-collection-errors
                        Force test execution even if collection errors occur
  --rootdir=ROOTDIR     Define root directory for tests. Can be relative path: 
                        'root_dir', './root_dir', 'root_dir/another_dir/'; 
                        absolute path: '/home/user/root_dir'; path with variables: 
                        '$HOME/root_dir'.

collection:
  --collect-only, --co  Only collect tests, don't execute them
  --pyargs              Try to interpret all arguments as Python packages
  --ignore=path         Ignore path during collection (multi-allowed)
  --ignore-glob=path    Ignore path pattern during collection (multi-allowed)
  --deselect=nodeid_prefix
                        Deselect item (via node id prefix) during collection 
                        (multi-allowed)
  --confcutdir=dir      Only load conftest.py's relative to specified dir
  --noconftest          Don't load any conftest.py files
  --keep-duplicates     Keep duplicate tests
  --collect-in-virtualenv
                        Don't ignore tests in a local virtualenv directory
  --import-mode={prepend,append,importlib}
                        Prepend/append to sys.path when importing test modules and
                        conftest files. Default: prepend.
  --doctest-modules     Run doctests in all .py modules
  --doctest-report={none,cdiff,ndiff,udiff,only_first_failure}
                        Choose another output format for diffs on doctest failure
  --doctest-glob=pat    Doctests file matching pattern, default: test*.txt
  --doctest-ignore-import-errors
                        Ignore doctest ImportErrors
  --doctest-continue-on-failure
                        For a given doctest, continue to run after the first failure

test session debugging and configuration:
  --basetemp=dir        Base temporary directory for this test run. (Warning: this 
                        directory is removed if it exists.)
  -V, --version         Display pytest version and information about plugins. When given
                        twice, also display information about plugins.
  -h, --help            Show help message and configuration info
  -p name               Early-load given plugin module name or entry point 
                        (multi-allowed). To avoid loading of plugins, use the `no:`
                        prefix, e.g. `no:doctest`.
  --trace-config        Trace considerations of conftest.py files
  --debug=[DEBUG_FILE_NAME]
                        Store internal tracing debug information in this log file. 
                        This file is opened with 'w' and truncated as a result, care
                        advised. Default: pytestdebug.log.
  -o OVERRIDE_INI, --override-ini=OVERRIDE_INI
                        Override ini option with "option=value" style, e.g. 
                        `-o xfail_strict=True -o cache_dir=cache`.
  --assert=MODE         Control assertion debugging tools.
                        'plain' performs no assertion debugging.
                        'rewrite' (the default) rewrites assert statements in test 
                        modules on import to provide assert expression information.
  --setup-only          Only setup fixtures, do not execute tests
  --setup-show          Show setup of fixtures while executing tests
  --setup-plan          Show what fixtures and tests would be executed but don't execute 
                        anything

logging:
  --log-level=LEVEL     Level of messages to catch/display. Not set by default, so it
                        depends on the root/parent log handler's effective level, where
                        it is "WARNING" by default.
  --log-format=LOG_FORMAT
                        Log format used by the logging module
  --log-date-format=LOG_DATE_FORMAT
                        Log date format used by the logging module
  --log-cli-level=LOG_CLI_LEVEL
                        CLI logging level
  --log-cli-format=LOG_CLI_FORMAT
                        Log format used by the logging module
  --log-cli-date-format=LOG_CLI_DATE_FORMAT
                        Log date format used by the logging module
  --log-file=LOG_FILE   Path to a file when logging will be written to
  --log-file-level=LOG_FILE_LEVEL
                        Log file logging level
  --log-file-format=LOG_FILE_FORMAT
                        Log format used by the logging module
  --log-file-date-format=LOG_FILE_DATE_FORMAT
                        Log date format used by the logging module
  --log-auto-indent=LOG_AUTO_INDENT
                        Auto-indent multiline messages passed to the logging module.
                        Accepts true|on, false|off or an integer.
  --log-disable=LOGGER_DISABLE
                        Disable a logger by name. Can be passed multiple times.

[pytest] ini-options in the first pytest.ini|tox.ini|setup.cfg|pyproject.toml file found:

  markers (linelist):   Markers for test functions
  empty_parameter_set_mark (string):
                        Default marker for empty parametersets
  norecursedirs (args): Directory patterns to avoid for recursion
  testpaths (args):     Directories to search for tests when no files or directories are
                        given on the command line
  filterwarnings (linelist):
                        Each line specifies a pattern for warnings.filterwarnings. 
                        Processed after -W/--pythonwarnings.
  usefixtures (args):   List of default fixtures to be used with this project
  python_files (args):  Glob-style file patterns for Python test module discovery
  python_classes (args):
                        Prefixes or glob names for Python test class discovery
  python_functions (args):
                        Prefixes or glob names for Python test function and method
                        discovery
  disable_test_id_escaping_and_forfeit_all_rights_to_community_support (bool):
                        Disable string escape non-ASCII characters, might cause unwanted
                        side effects(use at your own risk)
  console_output_style (string):
                        Console output: "classic", or with additional progress 
                        information ("progress" (percentage) | "count" | 
                        "progress-even-when-capture-no" (forces progress even when 
                        capture=no)
  xfail_strict (bool):  Default for the strict parameter of xfail markers when not given
                        explicitly (default: False)
  tmp_path_retention_count (string):
                        How many sessions should we keep the `tmp_path` directories, 
                        according to `tmp_path_retention_policy`.
  tmp_path_retention_policy (string):
                        Controls which directories created by the `tmp_path` fixture are 
                        kept around, based on test outcome. (all/failed/none)
  enable_assertion_pass_hook (bool):
                        Enables the pytest_assertion_pass hook. Make sure to delete any 
                        previously generated pyc cache files.
  junit_suite_name (string):
                        Test suite name for JUnit report
  junit_logging (string):
                        Write captured log messages to JUnit report: one of 
                        no|log|system-out|system-err|out-err|all
  junit_log_passing_tests (bool):
                        Capture log information for passing tests to JUnit report:
  junit_duration_report (string):
                        Duration time to report: one of total|call
  junit_family (string):
                        Emit XML for schema: one of legacy|xunit1|xunit2
  doctest_optionflags (args):
                        Option flags for doctests
  doctest_encoding (string):
                        Encoding used for doctest files
  cache_dir (string):   Cache directory path
  log_level (string):   Default value for --log-level
  log_format (string):  Default value for --log-format
  log_date_format (string):
                        Default value for --log-date-format
  log_cli (bool):       Enable log display during test run (also known as "live logging")
  log_cli_level (string):
                        Default value for --log-cli-level
  log_cli_format (string):
                        Default value for --log-cli-format
  log_cli_date_format (string):
                        Default value for --log-cli-date-format
  log_file (string):    Default value for --log-file
  log_file_level (string):
                        Default value for --log-file-level
  log_file_format (string):
                        Default value for --log-file-format
  log_file_date_format (string):
                        Default value for --log-file-date-format
  log_auto_indent (string):
                        Default value for --log-auto-indent
  pythonpath (paths):   Add paths to sys.path
  faulthandler_timeout (string):
                        Dump the traceback of all threads if a test takes more than 
                        TIMEOUT seconds to finish
  addopts (args):       Extra command line options
  minversion (string):  Minimally required pytest version
  required_plugins (args):
                        Plugins that must be present for pytest to run

Environment variables:
  PYTEST_ADDOPTS           Extra command line options
  PYTEST_PLUGINS           Comma-separated plugins to load during startup
  PYTEST_DISABLE_PLUGIN_AUTOLOAD Set to disable plugin auto-loading
  PYTEST_DEBUG             Set to enable debug tracing of pytest's internals


to see available markers type: pytest --markers
to see available fixtures type: pytest --fixtures
(shown according to specified file_or_dir or current dir if not specified; fixtures with leading '_' are only shown with the '-v' option
root@Gavin:~#
</code></pre>
<p>请不要被上面这么多的使用参数吓到，实际常用十之有二。接下来我们将逐一分析每个参数的详细使用方法。</p>
<h2 id="3-1-2-fen-lei-hui-zong">3.1.2 分类汇总</h2>
<p>在Shell执行<code>pytest -h</code>可以看到<code>pytest</code>的命令行参数有这9大类（默认状态、未安装其他插件情况下），共130个，汇总如下表所示：</p>
<table>
<thead>
<tr>
<th style="text-align:left">序号</th>
<th style="text-align:left">类别</th>
<th style="text-align:left">中文名</th>
<th style="text-align:left">包含命令行参数数量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">positional arguments</td>
<td style="text-align:left">形参</td>
<td style="text-align:left">1</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">general</td>
<td style="text-align:left">通用</td>
<td style="text-align:left">20</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left">reporting</td>
<td style="text-align:left">报告</td>
<td style="text-align:left">19</td>
</tr>
<tr>
<td style="text-align:left">4</td>
<td style="text-align:left">pytest-warnings</td>
<td style="text-align:left">pytest警告</td>
<td style="text-align:left">8</td>
</tr>
<tr>
<td style="text-align:left">5</td>
<td style="text-align:left">collection</td>
<td style="text-align:left">收集</td>
<td style="text-align:left">15</td>
</tr>
<tr>
<td style="text-align:left">6</td>
<td style="text-align:left">test session debugging and configuration</td>
<td style="text-align:left">测试session调试和配置</td>
<td style="text-align:left">11</td>
</tr>
<tr>
<td style="text-align:left">7</td>
<td style="text-align:left">logging</td>
<td style="text-align:left">日志</td>
<td style="text-align:left">12</td>
</tr>
<tr>
<td style="text-align:left">8</td>
<td style="text-align:left">ini-options</td>
<td style="text-align:left">pytest.ini/tox.ini/setup.cfg配置文件</td>
<td style="text-align:left">40</td>
</tr>
<tr>
<td style="text-align:left">9</td>
<td style="text-align:left">environment variables</td>
<td style="text-align:left">环境变量</td>
<td style="text-align:left">4</td>
</tr>
</tbody>
</table>
<h1 id="3-2-pytest-help-xin-xi-jie-shao">3.2 pytest help信息介绍</h1>
<h2 id="3-2-1-positional-arguments">3.2.1 positional arguments</h2>
<h3 id="3-2-1-1-can-shu-strong-file-or-dir-strong">3.2.1.1 参数 [<strong>file_or_dir</strong>]</h3>
<p>用途： 指定一个或多个文件/目录</p>
<p>使用方法：</p>
<pre><code class="language-shell">pytest [file_or_dir] [file_or_dir] [...]
</code></pre>
<h2 id="3-2-2-general-xiang-guan-can-shu">3.2.2 general 相关参数</h2>
<h3 id="3-2-2-1-can-shu-code-k-code">3.2.2.1 参数 <code>-k</code></h3>
<p><code>-k</code> 允许你运行名称符合某种表达式的测试用例。当使用 <code>-k</code> 参数时，你可以指定一个字符串表达式，<code>pytest</code> 将遍历项目中的每个测试用例名称，只有那些匹配表达式的测试用例才会被执行。</p>
<p><strong>使用方法：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>特定名称</strong></p>
</li>
</ul>
<p>如果你只想运行测试名称中包含 “login” 的测试用例，可以执行：</p>
<pre><code class="language-shell">pytest -k "login"
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>使用逻辑运算符</strong></p>
</li>
</ul>
<p><code>-k</code> 参数支持逻辑运算符 <code>AND</code>、<code>OR</code> 和 <code>NOT</code>（在 <code>-k</code> 参数中分别使用 <code>and</code>、<code>or</code>、<code>not</code> 关键词表示），比如：</p>
<p>若要运行包含 “login” 或 “logout” 的测试用例，可以执行：</p>
<pre><code class="language-shell">pytest -k "login or logout"
</code></pre>
<p>如果想要执行既包含 “login” 又包含 “account” 的测试用例，可以执行：</p>
<pre><code class="language-shell">pytest -k "login and account"
</code></pre>
<p>若要排除所有包含 “skip” 的测试用例，可以执行：</p>
<pre><code class="language-shell">pytest -k "not skip"
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>结合其他参数</strong></p>
</li>
</ul>
<p><code>-k</code> 参数可以与其他 <code>pytest</code> 命令行选项结合使用，例如 <code>--ignore</code> 或 <code>-v</code>（用于增加详细程度）。</p>
<p><strong>请注意：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>表达式中的关键词大小写不敏感，且支持中文。</p>
</li>
<li class="lvl-2">
<p>确保 <code>-k</code> 参数后面的表达式用双引号或单引号括起来以避免由于 shell 的特殊字符处理而导致的问题。</p>
</li>
<li class="lvl-2">
<p>使用逻辑运算符时（<code>and</code>、<code>or</code>、<code>not</code>），需要按照 Python 逻辑语法规则进行组合。</p>
</li>
</ul>
<p><code>-k</code> 是一个非常有用的参数，可以快速选择子集的测试进行运行，非常适合在开发过程中对特定功能的测试或者当有大量的测试用例，但只有少数需要频繁运行时使用。</p>
<h3 id="3-2-2-2-can-shu-code-m-code">3.2.2.2 参数 <code>-m</code></h3>
<p><code>pytest</code> 提供的 <code>-m</code> 参数允许用户基于标记（mark）来选择运行特定的测试用例。通过使用标记，可以非常灵活地组织测试用例，并据此选择运行特定的一组测试。</p>
<p>使用标记的一个常见场景是对测试用例按照功能、模块或者是测试类型（如冒烟测试、回归测试、测试用例分级别等）进行分组。</p>
<p><strong>使用方法：</strong></p>
<p>以下是如何使用 <code>-m</code> 参数的几个示例：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>基本使用</strong></p>
</li>
</ul>
<p>如果你有一个标记为 <code>migration</code> 的测试用例，你可以使用 <code>-m</code> 参数来只运行所有带有 <code>migration</code> 标记的测试用例。</p>
<pre><code class="language-shell">pytest -m migration
</code></pre>
<p>这条命令会执行所有使用了 <code>@pytest.mark.migration</code> 装饰器的测试用例。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>逻辑运算</strong></p>
</li>
</ul>
<p>与 <code>-k</code> 参数类似，<code>-m</code> 参数也支持简单的逻辑运算符，如 <code>and</code>、<code>or</code> 和 <code>not</code>。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>运行标记为 <code>migration</code> 或者 <code>loopdevice</code> 的测试：</p>
</li>
</ul>
<pre><code class="language-shell">pytest -m "migration or loopdevice"
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>运行同时标记为 <code>migration</code> 和 <code>NAS</code> 的测试：</p>
</li>
</ul>
<pre><code class="language-shell">pytest -m "migration and NAS"
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>运行未标记为 <code>migration</code> 的所有测试：</p>
</li>
</ul>
<pre><code class="language-shell">pytest -m "not migration"
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>结合其他参数</strong></p>
</li>
</ul>
<p><code>-k</code> 和 <code>-m</code>：<code>-m</code> 参数可以与 <code>-k</code> 参数或其它 <code>pytest</code> 参数结合使用，以实现更复杂的测试用例选择。</p>
<pre><code class="language-shell">pytest -m "not migration" -k "iSCSI"
</code></pre>
<p>上面的命令将执行所有未被标记为"migration"且名称中包含 “iSCSI” 的测试用例。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>自定义标记</strong></p>
</li>
</ul>
<p>可以在 <code>pytest.ini</code>、<code>pyproject.toml</code>、<code>tox.ini</code> 或者 <code>setup.cfg</code> 文件中定义自己的标记策略，以避免使用未定义的标记引起的警告。例如，在 <code>pytest.ini</code> 中定义 <code>migraion</code> 和 <code>NAS</code>：</p>
<pre><code class="language-ini">[pytest]
markers =
    migration: mark cases for migration features (deselect with '-m "not migration"')
    NAS: mark cases for all NAS features (deselect with '-m "not NAS"')
</code></pre>
<p>这段配置告诉 <code>pytest</code> 这些标记是已预定义的，并防止在使用未声明的标记时发出警告。</p>
<p><strong>请注意：</strong></p>
<p><code>-m</code> 是一个功能强大的参数，配合标记功能，可以帮助我们灵活地组织和执行测试用例，非常适合管理复杂或大型测试集。</p>
<p>在持续集成/持续部署（CI/CD）环境中，<code>-m</code> 参数经常用于指定运行某类测试，例如只运行与当前开发工作相关的测试。</p>
<h3 id="3-2-2-3-can-shu-code-markers-code">3.2.2.3 参数 <code>--markers</code></h3>
<p><code>pytest</code> 提供的<code>--markers</code> 是一个命令行选项，它提供了显示项目中可用标记（markers）列表的便捷方式。在 <code>pytest</code> 中，标记用于分类和选择测试，通常用于为测试用例添加额外的元数据，诸如区分慢速运行的测试、需要特殊硬件的测试或者指定测试与某个特定功能相关等，这些标记可以后续用来选择性地运行特定的测试用例集合。</p>
<p>当你运行 <code>pytest --markers</code> 命令时，将会列出所有已注册的标记及其相应的说明（如果有的话），包含内置标记和自定义标记。这些信息通常来源于以下几个地方：</p>
<p><strong>内置标记：</strong></p>
<p><code>pytest</code> 具有一些预设（内置）的标记，参考如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>mark.name</code>: 这里的 <code>name</code> 是标记的名称，你可以将这个标记应用到一个测试函数上，然后通过 <code>-m 'name'</code> 选项来运行所有带有这个标记的测试。</p>
</li>
<li class="lvl-2">
<p><code>skip</code>: 这个内置的标记用于不运行那些标记了 <code>@pytest.mark.skip</code> 的测试函数。</p>
</li>
<li class="lvl-2">
<p><code>skipif</code>: 这个标记用作条件跳过，即在满足指定条件时，跳过使用了 <code>@pytest.mark.skipif</code> 的测试函数。</p>
</li>
<li class="lvl-2">
<p><code>xfail</code>: 表示“预期失败”的测试，即这些测试可能由于某种已知的原因无法通过，使用 <code>@pytest.mark.xfail</code> 标记。</p>
</li>
<li class="lvl-2">
<p><code>parametrize</code>: 这个标记允许用户为测试函数提供多组参数，使得同一测试函数可以用不同的数据多次运行。</p>
</li>
<li class="lvl-2">
<p><code>usefixtures</code>: 通过这个标记可以声明测试用例需要使用的 fixture，即在测试运行前后执行的准备和清理/销毁函数。</p>
</li>
<li class="lvl-2">
<p><code>filterwarnings</code>: 这个标记用于过滤掉在测试运行期间触发的特定警告。</p>
</li>
</ul>
<p><strong>自定义标记：</strong></p>
<p>用户可以在测试文件中通过使用装饰器 <code>@pytest.mark.&lt;marker_name&gt;</code> 自定义标记，并且经常在配置文件中对这些标记进行描述。</p>
<p><strong>配置文件中声明的标记：</strong></p>
<p>为了避免在使用未声明的标记时遭受警告，用户在 <code>pytest.ini</code>、<code>pyproject.toml</code>、<code>tox.ini</code> 或 <code>setup.cfg</code> 等配置文件中声明标记及其说明。</p>
<p>例如，在 <code>pytest.ini</code> 文件中定义了两个标记 <code>slow</code> 和 <code>fast</code>，如下所示：</p>
<pre><code class="language-ini">[pytest]
markers =
    slow: mark tests as slow (deselect with '-m "not slow"').
    fast: mark tests that run quickly (deselect with '-m "not fast"').
</code></pre>
<p>那么运行 <code>pytest --markers</code> 将列出所有可用的内置标记以及你定义的 <code>slow</code> 和 <code>fast</code> 标记。</p>
<p>输出结果会类似这样：</p>
<pre><code class="language-shell">@pytest.mark.slow: mark tests as slow (deselect with '-m "not slow"').
@pytest.mark.fast: mark tests that run quickly (deselect with '-m "not fast"').
@pytest.mark.skip(reason=None): skip the given test function with an optional reason. Explanations may be presented with '-rs' or '-rA'.
...
</code></pre>
<p>此列表对于维护测试集合、确保标记使用的一致性以及为新成员快速提供项目内标记概览非常有用。它可作为一个参考手册，帮助团队成员理解每个标记的使用意图和上下文。</p>
<p><strong>请注意：</strong></p>
<p>使用标记的好处是：增加了测试的灵活性和表达力。</p>
<p>用户可以标记慢速的测试、特定组件的测试、需要特定资源的测试、根据功能特性分类的自定义标记等，然后根据需要选择性地运行或跳过它们，这对于管理大型测试套件特别有用。</p>
<h3 id="3-2-2-4-can-shu-code-x-code-huo-zhe-code-exitfirst-code">3.2.2.4 参数 <code>-x</code> 或者 <code>--exitfirst</code></h3>
<p><code>pytest</code> 的 <code>-x</code> 或 <code>--exitfirst</code> 参数是用来选择在第一个错误或失败（failure）出现时立即退出测试运行的。这个选项对于那些需要迅速识别出导致测试失败的问题的情况十分有用，它可以帮助开发人员节省时间，因为他们不必等整个测试套件运行完毕就能开始排查问题。</p>
<p><code>pytest</code> 默认行为是运行所有的测试用例，不论它们成功还是失败，并在最后提供一个汇总报告。如果测试套件非常庞大，第一个错误可能在较早的阶段就发生了，但默认情况下你还是得等到所有测试用例运行完成后才会知道。使用 <code>-x</code> 选项，你可以在测试出现第一个失败时立刻得到反馈，这允许你更快地开始解决问题。</p>
<p>比如说，如果你有一个包含1000个测试用例的测试套件，并且第5个测试用例失败了，<code>pytest -x</code> 会在第5个测试用例失败后立即停止运行，而不是继续执行剩下的995个测试，这样你就可以专注于修复这个第5个测试用例的问题。</p>
<p><strong>使用方法：</strong></p>
<p>在命令行中可以这样使用 <code>-x</code> 选项：</p>
<pre><code class="language-shell">pytest -x
</code></pre>
<p>或使用长形式：</p>
<pre><code class="language-shell">pytest --exitfirst
</code></pre>
<p><strong>请注意：</strong></p>
<p>在某些情况下，比如在持续集成（CI）环境中运行测试时，你可能不想要这种行为，因为你会希望从单次构建中获得尽可能多的反馈信息。所以 <code>-x</code> 参数最适合在开发过程中使用，当你试图找到并修复测试失败的问题时。</p>
<h3 id="3-2-2-5-can-shu-code-fixtures-code">3.2.2.5 参数 <code>--fixtures</code></h3>
<p><code>pytest</code> 的 <code>--fixtures</code> 选项用于显示测试中可用的所有fixture的详细信息。在 <code>pytest</code> 中，fixtures 是一种功能，它们提供了一种固定的基础设施，可以被不同的测试用例所使用。这些fixture可能负责设置数据库、准备测试数据、启动某些服务、创建临时文件、清理某些设置等等。<code>--fixtures</code> 选项会列出所有的fixture及其文档字符串，这有助于开发者了解每个fixture的用途和功能。</p>
<p>而 <code>--funcargs</code> 选项在新版本的 <code>pytest</code> 中已经弃用了，因此它不会被 认可和使用（recognized and used）。过去，<code>--funcargs</code> 是用来展示可用的fixtures，与 <code>--fixtures</code> 类似。如果你尝试使用一个旧版本的 <code>pytest</code> 版本，<code>--funcargs</code> 选项可能仍然存在，但是在当前的 <code>pytest</code> 版本中，应该使用 <code>--fixtures</code> 来获得相同的结果。</p>
<p><strong>使用方法：</strong></p>
<p><code>--fixtures</code> 选项的示例如下：</p>
<pre><code class="language-shell">pytest --fixtures
</code></pre>
<p>这个命令会打印出所有已定义的fixtures，包括它们的名称、所在的测试文件以及配套的文档说明。这对于了解项目中已有的测试资源和如何使用它们来说非常有帮助。</p>
<p>假设你在测试代码中有如下的fixture定义：</p>
<pre><code class="language-python"># content of conftest.py
import pytest

@pytest.fixture
def smtp_connection():
    """Returns a smtp connection instance"""
    import smtplib
    return smtplib.SMTP("smtp.163.com", 587, timeout=5)

@pytest.fixture
def make_customer_record():
    """Create a test customer record"""
    def _make_customer_record(name):
        return {"name": name, "orders": []}
    return _make_customer_record
</code></pre>
<p>运行 <code>pytest --fixtures</code> 命令后，输出结果会包含类似以下内容的记录：</p>
<pre><code class="language-python">----------------------- fixtures defined from conftest -------------------------
make_customer_record -- conftest.py:11
    Create a test customer record

smtp_connection -- conftest.py:6
    Returns a smtp connection instance

</code></pre>
<p>每一个fixture都会携带其注册在 <code>pytest</code> 中的名称和提供的文档字符串。</p>
<p><strong>请注意：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>下划线(_)开头的fixtures，需要使用参数 ‘-v’ 来显示。</p>
</li>
<li class="lvl-2">
<p>从<code>pytest</code> 的 <code>2.3</code> 版本起，<code>--funcargs</code> 参数已被废弃，其功能已由 <code>--fixtures</code> 接替。</p>
</li>
<li class="lvl-2">
<p>使用 <code>--fixtures</code> 可以帮助你查看所有可用的fixtures及其说明，包括内置的、conftest.py中使用的和其他自定义的fixtures。</p>
</li>
</ul>
<h3 id="3-2-2-6-can-shu-code-fixtures-per-test-code">3.2.2.6 参数 <code>--fixtures-per-test</code></h3>
<p>查看每个测试用例实际使用了哪些 fixtures，或是想要查找特定测试用例相关的所有fixtures，你可以简单地在命令行中指定具体的测试用例，配合 <code>--fixtures-per-test</code>  选项，来查看测试用例使用了哪些fixtures。除此之外，借助<code>--setup-show</code> 选项，来查看每个测试用例的 setup 阶段中使用了哪些 fixtures。关于<code>--setup-show</code> 选项，请参考本章节中的“test session debugging and configuration 相关参数”处。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest --fixtures-per-test test_show_fixtures.py
</code></pre>
<p><strong>示例：</strong></p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# cat test_show_fixtures.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

"""
This is an example pytest fixture
"""

import pytest


@pytest.fixture()
def run_function():
    """  This is a function doc info  """
    print("Run before function...")
    yield
    print("Run after function...")


def test_case_1(run_function):
    """  Test case 1  """
    print("case 1")


def test_case_2():
    """  Test case 2  """
    print("case 2")


def test_case_3(run_function):
    """  Test case 3  """
    print("case 3")
root@Gavin:~/code/chapter1-3#
</code></pre>
<p>测试结果：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# pytest --fixtures-per-test test_show_fixtures.py 
============================= test session starts =============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code/chapter1-3
collected 3 items                                                                         

---------------------------- fixtures used by test_case_1 ----------------------
---------------------------- (test_show_fixtures.py:20) ------------------------
run_function -- test_show_fixtures.py:12
    This is a function doc info  

---------------------------- fixtures used by test_case_3 ----------------------
---------------------------- (test_show_fixtures.py:30) ------------------------
run_function -- test_show_fixtures.py:12
    This is a function doc info  

============================= no tests ran in 0.00s ============================
root@Gavin:~/code/chapter1-3# 
</code></pre>
<h3 id="3-2-2-7-can-shu-code-pdb-code">3.2.2.7 参数 <code>--pdb</code></h3>
<p><code>pytest</code> 的 <code>--pdb</code> 选项是一个非常实用的调试助手。当使用这个选项运行测试时，如果发生了一个异常（例如测试失败了），<code>pytest</code> 将自动进入Python的调试器 <code>pdb</code>（Python Debugger）。它允许你在代码中的任何位置进行断点调试，并允许你检查堆栈、变量和执行任意的Python代码。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest --pdb test_file.py
</code></pre>
<p>当你运行以上命令时，如果 <code>test_file.py</code> 中的测试发生错误，<code>pytest</code> 就会在第一个发生错误的地方立即进入 <code>pdb</code> 调试模式。在进入 <code>pdb</code> 后，你可以：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用 <code>list</code> 或 <code>l</code> 命令查看当前的代码。</p>
</li>
<li class="lvl-2">
<p>使用 <code>next</code> 或 <code>n</code> 步过 (step over) 下一行代码。</p>
</li>
<li class="lvl-2">
<p>使用 <code>step</code> 或 <code>s</code> 步入 (step into) 函数或方法。</p>
</li>
<li class="lvl-2">
<p>使用 <code>continue</code> 或 <code>c</code> 继续执行程序直到碰到下一个断点。</p>
</li>
<li class="lvl-2">
<p>使用 <code>quit</code> 或 <code>q</code> 退出调试器。</p>
</li>
<li class="lvl-2">
<p>使用 <code>p</code> 打印一个表达式的值。</p>
</li>
</ul>
<p>这是一个强大的功能，因为它允许你在测试失败时直接从错误点开始调试，而不需要去手动设置断点。这经常被用于复杂的失败，或是那些仅在特定测试环境下发生的问题。</p>
<p>也可以在命令行中组合 <code>--pdb</code> 与其它 <code>pytest</code> 选项一起使用，例如 <code>--maxfail</code> 可以在一定数量的失败之后停止测试:</p>
<pre><code class="language-shell">pytest --pdb --maxfail=2 test_file.py
</code></pre>
<p>此命令告诉 <code>pytest</code> 在两个测试失败后停止执行，并且如果有测试失败，则在第一个失败的测试处打开 <code>pdb</code>。</p>
<p><strong>请注意：</strong></p>
<p>使用 <code>pytest --pdb</code> 可以帮助快速定位测试中的问题，特别是在复杂的测试或难以复现的问题时，它是一个极其有用的工具。不过，要记住，如果在自动化测试系统中运行测试，避免使用 <code>--pdb</code>, 因为它需要交互式输入，可能导致自动化流程暂停。</p>
<p>请记住，在 <code>pdb</code> 调试会话中，你需要了解一些基本的 <code>pdb</code> 命令来有效地进行调试。这个功能是Python标准库的一部分，因此无需额外安装即可与 <code>pytest</code> 一起使用。</p>
<h3 id="3-2-2-8-can-shu-code-pdbcls-code">3.2.2.8 参数 <code>--pdbcls</code></h3>
<p><code>pytest</code> 的 <code>--pdbcls</code> 选项允许用户指定一个自定义的调试器类来代替标准的 <code>pdb</code> 调试器。它非常有用，尤其是当你需要使用不同的特性或者接口来进行调试时。</p>
<p><strong>使用方法：</strong></p>
<p>选项的格式是 <code>--pdbcls=modulename:classname</code>，其中：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>modulename</code> 对应于包含你希望使用的调试器的 Python 模块的名字。</p>
</li>
<li class="lvl-2">
<p><code>classname</code> 是模块中的调试器类的名称。</p>
</li>
</ul>
<p><strong>示例：</strong></p>
<p>如果你想使用 <code>ipdb</code> 作为你的调试器，首先确保你已安装了 <code>ipdb</code> 模块：</p>
<pre><code class="language-shell">pip install ipdb
</code></pre>
<p>然后，运行 <code>pytest</code> 时提供这个参数来使用 <code>ipdb</code> 的功能：</p>
<pre><code class="language-shell">pytest --pdbcls=IPython.terminal.debugger:TerminalPdb
</code></pre>
<p>在这个例子中：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>IPython.terminal.debugger</code> 是含有调试器类的模块名。</p>
</li>
<li class="lvl-2">
<p><code>TerminalPdb</code> 是在 <code>IPython</code> 模块中对应的调试器类名。</p>
</li>
</ul>
<p>使用这个选项时，测试运行时触发的任何异常都会进入由 <code>--pdbcls</code> 指定的调试器而不是标准的 <code>pdb</code>。这就允许你利用你选择的调试器的所有功能，比如 <code>ipdb</code> 提供的更丰富的交互性和更高级的调试工具。</p>
<p>不过，需要注意的是，并不是所有的 Python 调试器都与 <code>pytest</code> 兼容，因此在使用前应确保想用的调试器支持该集成。此外，由于 <code>pytest</code> 本身可能时不时更新，最好查看官方文档来获取最新的兼容性信息和使用指南。</p>
<h3 id="3-2-2-9-can-shu-code-trace-code">3.2.2.9 参数 <code>--trace</code></h3>
<p><code>pytest</code> 的 <code>--trace</code> 选项是一个用于启动调试的实用功能，它在测试执行期间提供了一种直接进入调试模式的方式。</p>
<p>使用 <code>--trace</code> 选项，当 <code>pytest</code> 开始执行一条测试项时，它会自动启动一个调试器。这允许你单步执行代码，检查当前的变量状态，评估表达式等等，就像在典型的调试会话中一样。这个选项在需要理解测试执行流或者排查一个特别复杂的测试失败原因时特别有用。</p>
<p>如下为如何使用 <code>--trace</code> 选项的基本示例：</p>
<pre><code class="language-shell">pytest --trace tests/test_my_feature.py
</code></pre>
<p>在这个例子中，<code>pytest</code> 会执行 <code>tests/test_my_feature.py</code> 文件中所有的测试项，但对于每个测试项，它会在测试函数的开头打开调试器。</p>
<p>比较一下 <code>--pdb</code> 选项，也用于打开调试器，但仅在测试失败时。相反，无论测试是否失败，<code>--trace</code> 都会为每一个测试启动调试器。</p>
<p>这是一个非常给力的工具，但由于它会在每个测试项处停止，如果你有很多测试项，使用它可能不是很高效。通常，仅需针对单个测试或者很小的一组测试使用 <code>--trace</code> 选项，以便可以集中精力进行调试。</p>
<p>此外，<code>--trace</code> 选项会直接进入 <code>pdb</code> 调试器界面，因此对于不熟悉 <code>pdb</code> 命令的用户来说，可能需要一点时间去熟悉。</p>
<p>总体来说，<code>--trace</code> 选项在调试过程中提供了一种更立即的方法来控制测试的执行和分析。它对于快速定位问题和交互式地探究测试行为非常有帮助。</p>
<p>示例如下：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# pytest --trace test_show_fixtures.py 
============================= test session starts =========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code/chapter1-3
collected 3 items

test_show_fixtures.py 
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; PDB runcall (IO-capturing turned off) &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
&gt; /root/code/chapter1-3/test_show_fixtures.py(21)test_case_1()
-&gt; print("case 1")
(Pdb) l
 16  	    print("Run after function...")
 17  	
 18  	
 19  	def test_case_1(run_function):
 20  	    """  Test case 1  """
 21  -&gt;	    print("case 1")
 22  	
 23  	
 24  	def test_case_2():
 25  	    """  Test case 2  """
 26  	    print("case 2")
(Pdb) 
</code></pre>
<h3 id="3-2-2-10-can-shu-code-capture-code">3.2.2.10 参数 <code>--capture</code></h3>
<p>在 <code>pytest</code> 中，<code>-s</code> 或 <code>--capture=no</code> 选项用于禁用所有的标准输出 (<code>stdout</code>) 和标准错误 (<code>stderr</code>) 捕获。通常，<code>pytest</code> 会捕获测试运行时产生的所有输出，并且仅当测试失败时才显示它，有助于在出现问题时保持输出的清晰和集中。然而，在某些情况下，你可能希望在测试执行时直接看到输出，而不是等待测试失败。</p>
<p>举个例子，运行以下命令:</p>
<pre><code class="language-shell">pytest -s test_my_feature.py
</code></pre>
<p>使用 <code>-s</code> 选项，<code>pytest</code> 将会运行 <code>test_my_feature.py</code> 文件中的测试，并将测试执行过程中的任何输出实时显示。这意味着打印到 <code>stdout</code> 或 <code>stderr</code> 的任何内容都会立刻显示在控制台上，而不是在测试结束后。</p>
<p>而 <code>-capture=method</code> 选项则允许更细粒度的控制。这里的 <code>method</code> 可以是以下选项之一：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>no</code>: 不捕获输出，这与 <code>-s</code> 选项相同。</p>
</li>
<li class="lvl-2">
<p><code>fd</code>: 使用文件描述符捕获机制。这种方法可以捕获包括系统调用在内的输出，比如打印到 <code>sys.stdout</code> 和 <code>sys.stderr</code> 的内容。</p>
</li>
<li class="lvl-2">
<p><code>sys</code>: 只捕获写入 <code>sys.stdout</code> 和 <code>sys.stderr</code> Python 文件对象的输出。如果代码直接写入到操作系统提供的文件描述符，这些输出将不会被捕获。</p>
</li>
</ul>
<p>例如，使用文件描述符捕获可以通过以下命令实现：</p>
<pre><code class="language-shell">pytest --capture=fd test_my_feature.py
</code></pre>
<p>与 <code>-s</code> 选项不同，<code>--capture=fd</code> 将允许 <code>pytest</code> 捕获和控制输出，除非你明确要求显示它们。在实践中，根据具体的测试需求和调试偏好，你可能需要选择是否捕获输出以及如何捕获输出。通常情况下，你可能想要看到更多的输出来理解测试的行为，例如在引入新测试或调试现有测试失败时。</p>
<h3 id="3-2-2-11-can-shu-code-s-code">3.2.2.11 参数 <code>-s</code></h3>
<p><code>pytest</code>中的<code>-s</code>参数是禁用捕获输出的简写选项，它的全称是<code>--capture=no</code>。在使用<code>pytest</code>时，通常测试在运行过程中产生的输出会被捕获，这样可以让测试的结果输出更加清晰，因为只有在测试出现错误或失败时，捕获的输出才会显示出来。当你没有使用<code>-s</code>选项时，所有打印到<code>stdout</code>（标准输出）或<code>stderr</code>（标准错误）的内容在测试过程中是看不到的，它们被<code>pytest</code>内部捕获存储起来了。</p>
<p>当使用了<code>-s</code>选项后，测试运行中的输出不再被<code>pytest</code>捕获，而是直接打印出来。例如：</p>
<pre><code class="language-shell">pytest -s chapter1-3/
</code></pre>
<p>这条命令将运行<code>chapter1-3</code>目录下的所有测试，所有输出均会实时地显示在控制台上。这包括<code>print</code>语句、日志消息以及其他脚本可能输出的任何内容。这非常有助于调试测试脚本，特别是当你需要实时地获取反馈信息时。</p>
<p>假设我们有以下的测试用例：</p>
<pre><code class="language-python"># test_example.py
def test_example():
    print("Hello, this is a pytest test case!")
    assert 1 == 1
</code></pre>
<p>运行<code>pytest -s</code>后，你将会看到"Hello, this is a pytest test case!"的输出。如果没有<code>-s</code>选项，这段输出信息将不会被显示。</p>
<p>需要注意的是，虽然<code>-s</code>选项有助于调试，但是如果测试用例本身或被测试的代码需要读取<code>stdin</code>的话，那么使用<code>-s</code>选项可能会产生问题，因为<code>pytest</code>默认会屏蔽掉对<code>stdin</code>的访问，以防止测试在等待输入时挂起。</p>
<h3 id="3-2-2-12-can-shu-runxfail">3.2.2.12 参数 --runxfail</h3>
<p><code>pytest</code> 提供了一种处理预期失败（expected failures）的功能，通过使用 <code>@pytest.mark.xfail</code> 装饰器或使用内联的<code>pytest.mark.skipif</code>装饰器来标记那些由于某些已知问题而预期会失败的测试。这样做可以让这些测试在执行时不影响整个测试套件的结果。</p>
<p>在某些情况下，虽然我们将测试标记为预期失败，但我们可能想要强制执行这些标记为 <code>xfail</code> 的测试，来检查它们是否依然失败，或者是否提早解决了这个问题。这就是 <code>--runxfail</code> 参数的用途。当你在运行 <code>pytest</code> 时添加了 <code>--runxfail</code> 参数，它会执行所有标记为 <code>xfail</code> 的测试，就好像它们没有标记 <code>xfail</code>。</p>
<p>使用方法如下：</p>
<pre><code class="language-shell">pytest --runxfail
</code></pre>
<p>使用 <code>--runxfail</code> 的效果包括：</p>
<p><strong>运行所有标记为 <code>xfail</code> 的测试：</strong></p>
<p><code>--runxfail</code> 使所有使用 <code>@pytest.mark.xfail</code> 标记的测试都会执行，不考虑它们的 <code>xfail</code> 状态。</p>
<p><strong>忽略 <code>xfail</code> 状态：</strong></p>
<p>对于测试执行的结果，<code>--runxfail</code> 参数会导致 <code>pytest</code> 忽略 <code>xfail</code> 状态。即使测试预期失败，它们也会被记录为正常的失败或成功。</p>
<p>换言之，<code>pytest</code>会像平常一样运行这些测试，但不会特别关注预期失败的标记。如果测试失败了，它会被报告为一个普通的失败；如果测试通过了，它就会被报告为通过，不会有任何<code>xfail</code>或<code>xpass</code>的结果。</p>
<p>例如，你有以下的测试代码：</p>
<pre><code class="language-python"># test_example.py
import pytest

@pytest.mark.xfail(reason="This feature is not yet implemented.")
def test_future_feature():
    assert 0

def test_normal_feature():
    assert 1
</code></pre>
<p>在默认情况下运行<code>pytest</code>时，<code>test_future_feature</code>会被标记为<code>xfail</code>。但是，当你使用<code>--runxfail</code>选项运行测试时：</p>
<pre><code class="language-shell">pytest --runxfail test_example.py
</code></pre>
<p>此时，<code>test_future_feature</code>会被视为普通测试用例执行，如果它失败了，它会被报告为失败，不会考虑<code>xfail</code>。</p>
<p><strong>对bug修复测试：</strong></p>
<p>这个参数很有用，比如你修复了一个导致多个测试预期失败的bug，现在想要验证这些修复是否有效。而不是移除或者编辑每个 <code>xfail</code> 标记，你可以简单的使用 <code>--runxfail</code> 来执行这些测试。</p>
<p><strong>输出结果：</strong></p>
<p>即使测试是预期失败的，使用 <code>--runxfail</code> 后，失败结果会以正常的失败（FAIL）报告，而成功则为正常的成功（PASS）。这意味着 <code>xfail</code> 状态不会影响到测试结果的解释。</p>
<p>这个选项在持续集成或者测试环境中也非常有用，你可能想要临时极端地理解哪些 <code>xfail</code> 测试在当前环境中实际上是通过的，或者在排查问题的过程中需要确认这些测试的当前状态。不过，在常规的测试运行中，我们通常不加 <code>--runxfail</code>，让 <code>xfail</code> 的测试保持它们的预期状态。</p>
<h3 id="3-2-2-13-can-shu-code-lf-last-failed-code">3.2.2.13 参数 <code>--lf, --last-failed</code></h3>
<p><code>pytest</code> 提供了一种非常有用的功能来帮助开发者专注于最近失败的测试。通过 <code>--lf</code> 或 <code>--last-failed</code> 选项，<code>pytest</code> 只重新运行最近一次测试运行中失败的那些测试用例。这个选项能够节省时间，特别是处在解决 bug 和测试修复的循环中时，因为你不需要重新运行整个测试套件，只需关注那些失败的测试。</p>
<p>具体使用方法是在命令行中添加该选项：</p>
<pre><code class="language-shell">pytest --last-failed
</code></pre>
<p>或者是使用缩写形式：</p>
<pre><code class="language-shell">pytest --lf
</code></pre>
<p><strong><code>--lf</code> 或 <code>--last-failed</code> 的行为：</strong></p>
<p><strong>执行过滤：</strong></p>
<p>在你下次执行 <code>pytest</code> 时，只有上一次运行中失败的测试会被运行。如果在上一次运行中没有任何测试失败，那么使用 <code>--last-failed</code> 将不会运行任何测试。</p>
<p><strong>节省时间：</strong></p>
<p>这种方式特别有用，因为它可以帮助你专注于修复那些断言失败或出错的测试，而不必等待那些已经通过的测试再次运行。</p>
<p><strong>配合其他策略：</strong></p>
<p>你可以将 <code>--last-failed</code> 与其他 <code>pytest</code> 选项结合使用，例如 <code>-vv</code> 提高输出的详细程度，或者 <code>--pdb</code> 在失败的测试上直接进入调试器。</p>
<p><strong>持久化：</strong></p>
<p><code>pytest</code> 会在 <code>.pytest_cache</code> 目录中存储关于上一次运行哪些测试失败的信息，这样即使你在不同的测试运行之间关闭了你的工作站，<code>--last-failed</code> 也能继续工作。</p>
<p><strong>清除失败记录：</strong></p>
<p>如果想从头运行所有的测试，或者清理掉失败的记录，你可以运行 <code>pytest</code> 而不加任何参数，或者使用 <code>--clear-last-failed</code> 来清除失败的缓存记录。</p>
<p>这个功能在测试开发过程中特别高效，能够显著提高开发者处理失败测试的速度。不过，当你确信所有的问题都已经修复完毕，最好进行一次全面测试，以确保没有其他非预期的问题出现。</p>
<h3 id="3-2-2-14-can-shu-code-ff-failed-first-code">3.2.2.14 参数 <code>--ff, --failed-first</code></h3>
<p><code>pytest</code> 的 <code>--ff</code> 和 <code>--failed-first</code> 选项是用来优化测试运行的。这些选项被设计用于让在上一次运行中失败的测试用例首先执行，这样可以让开发者更快地看到修复这些失败用例是否有效。如果这些之前失败的测试现在都通过了，那么 <code>pytest</code> 将继续执行其余的测试用例。</p>
<p>使用这种方式，测试反馈循环更短，特别是在一个有许多测试用例的大型项目中，你可以更快地知道你的更改是否解决了问题而不必等待整个测试套件完成运行。</p>
<p>具体用法如下:</p>
<pre><code class="language-shell">pytest --failed-first
</code></pre>
<p>或者使用简写形式:</p>
<pre><code class="language-shell">pytest --ff
</code></pre>
<p>在命令执行时，<code>pytest</code> 会首先运行上次失败的测试集，如果这些测试通过，则继续执行剩余的测试集。</p>
<p>例如，假设你有一组测试用例，其中某几个在上次运行时失败了，如果你修改了相关代码以解决这些失败的测试，并想要确认这些修改的效果，可以使用 <code>--ff</code> 选项运行 <code>pytest</code>。这样做不仅可以快速获得关于这些特定测试的反馈，而且一旦这些测试都通过了，剩余的测试也会在之后执行，以确保其他部分的代码仍然是正确的。</p>
<p>就像 <code>--lf</code>（<code>--last-failed</code>）选项一样，<code>--ff</code> 选项依赖于 <code>.pytest_cache</code> 目录中存储的信息，它记录了哪些测试在上次运行中失败。如果你想要从头开始运行所有测试用例或者清除失败的历史，可以使用 <code>--cache-clear</code> 选项来清空缓存。</p>
<h3 id="3-2-2-15-can-shu-code-nf-new-first-code">3.2.2.15 参数  <code>--nf, --new-first</code></h3>
<p><code>pytest</code> 的 <code>--nf</code> 或 <code>--new-first</code> 选项是用于调整测试用例的执行顺序，以便最先运行最新的测试。这个功能特别适用于开发新功能或修复缺陷时，当你添加或修改了测试用例，并希望首先执行这些最新的测试来快速获得反馈。</p>
<p>当使用 <code>--nf</code> 或 <code>--new-first</code> 选项时，<code>pytest</code> 会尝试根据测试用例文件的修改时间来确定测试执行的顺序。较新或最近修改的测试文件中的测试用例会被提前到测试队列的前面。</p>
<p>具体用法如下:</p>
<pre><code class="language-shell">pytest --new-first
</code></pre>
<p>或者使用简写形式:</p>
<pre><code class="language-shell">pytest --nf
</code></pre>
<p>这与 <code>--ff</code>（<code>--failed-first</code>）选项不同，后者是将之前失败的测试用例置于队列前面。<code>--new-first</code> 选项则关注文件的新旧程度。</p>
<p>例如，假设你在开发一个特性并且添加了一些新的测试用例，或者对现有的一个测试文件进行了显著的修改。使用 <code>--new-first</code> 选项可以让你更快地看到这些更改是否成功，因为 <code>pytest</code> 将先运行这些新添加或修改的测试用例。</p>
<p>这是一种有助于提高开发效率的测试策略，尤其是当你正在频繁地添加新测试和更改现有测试时。这样可以先关注新的更改，确保它们按预期工作，然后再关注全局的测试情况。</p>
<p>记住，如果希望运行所有测试用例，而不对顺序做特殊处理，你应该运行裸 <code>pytest</code> 命令，而不带任何排序相关的选项。</p>
<h3 id="3-2-2-16-can-shu-code-cache-show-cacheshow-code">3.2.2.16 参数  <code>--cache-show=[CACHESHOW]</code></h3>
<p><code>pytest</code> 的 <code>--cache-show</code> 选项用于显示缓存内容（默认是<code>.pytest_cache</code>目录），可以查看之前测试运行时所保存的信息，这对调试和理解 <code>pytest</code> 缓存机制非常有帮助。<code>pytest</code> 缓存用于存储跟测试运行相关的数据。例如，<code>--lf</code> （–last-failed）和 <code>--ff</code>（–failed-first）选项依赖于 <code>.pytest_cache</code> 目录中的失败记录来确定失败的测试。</p>
<p><code>pytest</code>的缓存目录结构示例如下：</p>
<pre><code class="language-shell">root@Gavin:~/code# tree -a .pytest_cache/
.pytest_cache/
├── CACHEDIR.TAG
├── .gitignore
├── README.md
└── v
    └── cache
        ├── lastfailed
        ├── nodeids
        └── stepwise

3 directories, 6 files
root@Gavin:~/code# 
</code></pre>
<p>说明如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>.pytest_cache/CACHEDIR.TAG</code>：pytest创建的缓存目录标签。</p>
</li>
<li class="lvl-2">
<p><code>.pytest_cache/.gitignore</code>：pytest测试框架 <code>.pytest_cache</code>的自带的 <code>.gitignore</code>文件。</p>
</li>
<li class="lvl-2">
<p><code>.pytest_cache/README.md</code>： <code>.pytest_cache</code>文件夹介绍。</p>
</li>
<li class="lvl-2">
<p><code>.pytest_cache/v/cache/lastfailed</code>: 上一次运行失败的测试用例。</p>
</li>
<li class="lvl-2">
<p><code>.pytest_cache/v/cache/nodeids</code>: 上一次运行的所有测试用例（无论测试用例的执行结果通过还是失败）。</p>
</li>
<li class="lvl-2">
<p><code>.pytest_cache/v/cache/stepwise</code>：测试用例的路径。</p>
</li>
</ul>
<p>如果指定 <code>--cache-show</code> 而不带任何参数，它将显示所有缓存的信息。你也可以提供具体的键值来查看特定的缓存信息。</p>
<p>具体用法如下:</p>
<pre><code class="language-shell">pytest --cache-show
</code></pre>
<p>这将会打印 <code>.pytest_cache</code> 目录中的所有内容，参考如下：</p>
<pre><code class="language-shell">root@Gavin:~/code# pytest --cache-show
============================== test session starts =============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
cachedir: /root/code/.pytest_cache
------------------------------ cache values for '*' ----------------------------
cache/lastfailed contains:
  {'chapter1-3/test_example.py::test_assert_failed': True}
cache/nodeids contains:
  ['chapter1-3/test_example.py::test_assert_failed',
   'chapter1-3/test_example.py::test_example',
   'chapter1-3/test_example.py::test_future_feature',
   'chapter1-3/test_example.py::test_normal_feature']
cache/stepwise contains:
  []

============================== no tests ran in 0.00s ===========================
root@Gavin:~/code#
</code></pre>
<p>如果你想针对特定缓存项获取详细信息，可以指定该项的名称：</p>
<pre><code class="language-shell">pytest --cache-show=[CACHENAME]
</code></pre>
<p>在这里，<code>[CACHENAME]</code> 应该替换为你希望查看的具体缓存项的名称。</p>
<p>例如：</p>
<pre><code class="language-shell">pytest --cache-show=chapter1-3/test_example.py
</code></pre>
<p>这个命令将会显示与 <code>chapter1-3/test_example.py</code> 相关的缓存信息，这个键值通常包含了上次运行中失败的测试。</p>
<p>缓存功能可以用来存储和检索测试间需要传递的数据。不过，请注意，过多依赖于测试间的缓存可能会导致测试结果不可靠，因为它们可以含有过时的数据，尤其是在代码改动频繁的情况下。</p>
<p>当你对 <code>pytest</code> 缓存机制有了深入理解，并且能够有效利用缓存数据时，<code>--cache-show</code> 就成为了一个非常有用的调试工具。</p>
<h3 id="3-2-2-17-can-shu-code-cache-clear-code">3.2.2.17 参数  <code>--cache-clear</code></h3>
<p><code>pytest</code> 的 <code>--cache-clear</code> 选项用于清除通过 <code>pytest</code> 缓存机制存储在本地的所有缓存数据。<code>pytest</code> 的缓存系统允许跨多次测试运行间存储和复用数据，这些数据默认存储在 <code>.pytest_cache</code> 目录中。使用 <code>--cache-clear</code> 可以删除这个目录下的所有内容，从而清空缓存。</p>
<p>使用 <code>--cache-clear</code> 选项的场景包括但不限制于：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>当你想要重新运行失败的测试而不受之前运行影响时。</p>
</li>
<li class="lvl-2">
<p>当你要清除由于某些原因可能已经不再准确或有用的缓存数据时。</p>
</li>
<li class="lvl-2">
<p>测试过程中某些缓存数据可能导致测试结果不一致，此时清除缓存能够确保每次运行测试都是在干净的状态下开始。</p>
</li>
</ul>
<p>具体的命令如下所示：</p>
<pre><code class="language-shell">pytest --cache-clear
</code></pre>
<p>执行这条命令，<code>pytest</code> 会先删除 <code>.pytest_cache</code> 目录及其内容，然后根据你可能的运行测试命令，开始新的测试运行。</p>
<p>需要注意的是，使用这个选项之后，所有的缓存都会被清除，包括用于 <code>--lf</code>（–last-failed）和 <code>--ff</code>（–failed-first）选项的失败记录。因此，使用它之前请确保你不需要缓存中的任何数据，或者已经做好了相应的数据备份工作。</p>
<h3 id="3-2-2-18-can-shu-code-lfnf-all-none-last-failed-no-failures-all-none-code">3.2.2.18 参数  <code>--lfnf={all,none}, --last-failed-no-failures={all,none}</code></h3>
<p><code>pytest</code> 的 <code>--lfnf</code> 或者全称 <code>--last-failed-no-failures</code> 选项用于指定当没有失败的测试时应该执行哪些测试。这个选项通常与 <code>--last-failed</code> 选项一起使用，后者会使 <code>pytest</code> 只重运行上次运行中失败的测试。</p>
<p><code>--last-failed-no-failures</code> 有两个可能的值：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>all</code>：如果在上次的测试中没有任何失败（或者使用了 <code>--cache-clear</code> 清空了缓存），则运行所有的测试用例。</p>
</li>
<li class="lvl-2">
<p><code>none</code>：如果在上次的测试中没有任何失败，则不运行任何测试用例。</p>
</li>
</ul>
<p>这个选项在持续集成流程中非常有用，让你可以先尝试只重运行那些失败的测试用例。如果在某次运行中所有的失败用例都被修复了，根据 <code>--lfnf</code> 的设置，你可以选择是运行全部测试保证整体健康，还是什么都不做。</p>
<p><strong>使用方法：</strong></p>
<p>如果上次没有失败的测试，运行所有测试：</p>
<pre><code class="language-shell">pytest --last-failed --last-failed-no-failures=all
</code></pre>
<p>如果上次没有失败的测试，不运行任何测试：</p>
<pre><code class="language-shell">pytest --last-failed --last-failed-no-failures=none
</code></pre>
<p><strong>请注意：</strong></p>
<p>这两个选项需要结合使用。如果你没有启用 <code>--last-failed</code>，则 <code>--last-failed-no-failures</code> 选项没有任何效果。当你期望根据失败用例的存在与否来决定运行策略时，这一选项组合尤其有帮助。</p>
<h3 id="3-2-2-19-can-shu-code-sw-stepwise-code">3.2.2.19 参数  <code>--sw, --stepwise</code></h3>
<p><code>pytest</code> 的 <code>--stepwise</code> 选项（缩写为 <code>--sw</code>）是一个有用的调试工具，它允许测试在第一个失败的测试处停止。其功能类似于逐步执行（stepwise），可以帮助你快速定位问题。当你在大型测试集中调试单个失败的测试时，这个选项特别有帮助，因为它避免了在修复当前失败的测试之前需要运行所有其他测试的情况。</p>
<p><strong>使用方法：</strong></p>
<p>开启 stepwise 模式，当遇到第一个失败的测试时立即停止执行剩余的测试:</p>
<pre><code class="language-shell">pytest --stepwise
</code></pre>
<p><strong>详细说明：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>当启用 <code>--stepwise</code> 选项时，<code>pytest</code> 会开始执行测试，一旦遇到第一个测试失败，它就会停止执行。</p>
</li>
<li class="lvl-2">
<p>修复了导致测试失败的问题之后，你可以重新运行带有 <code>--stepwise</code> 选项的 <code>pytest</code>，它将继续从上一次失败的测试处开始执行，而不是从头开始。</p>
</li>
<li class="lvl-2">
<p>如果在 <code>--stepwise</code> 模式下所有的测试都通过了，那么 <code>pytest</code> 将正常退出。</p>
</li>
<li class="lvl-2">
<p>这个选项非常适合那些需要快速迭代和修复单个或一系列测试问题的开发者。</p>
</li>
<li class="lvl-2">
<p>请注意，<code>--stepwise</code> 模式与 <code>pytest</code> 的缓存机制一起工作；它利用缓存来记住上次失败的位置。</p>
</li>
</ul>
<p>可能需要注意的是，如果你的测试依赖于特定的顺序或者有涉及状态的依赖，那么 <code>--stepwise</code> 可能不是最好的选择，因为在测试序列中间的某个点开始执行可能会导致意外的副作用。在这种情况下，使用标准的 <code>--lf</code>（–last-failed）选项可能更加安全，<code>--lf</code> 会重新运行上次运行中失败的所有测试。</p>
<h3 id="3-3-3-20-can-shu-code-sw-skip-stepwise-skip-code">3.3.3.20 参数  <code>--sw-skip, --stepwise-skip</code></h3>
<p><code>pytest</code> 的 <code>--stepwise-skip</code> 选项（可缩写为 <code>--sw-skip</code>）是结合了 <code>--stepwise</code> 功能和忽略跳过（skip）测试的能力。启用这个选项后，<code>pytest</code> 会在遇到第一个失败的测试时停止执行，就像 <code>--stepwise</code> 那样，但它还将自动跳过任何标记为跳过的测试。</p>
<p><strong>使用方法：</strong></p>
<p>在 stepwise 模式下跳过使用 <code>pytest.mark.skip</code> 或 <code>pytest.mark.skipif</code> 标记的测试：</p>
<pre><code class="language-shell">pytest --stepwise --stepwise-skip
</code></pre>
<p><strong>详细说明：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>启用 <code>--stepwise-skip</code> 时，<code>pytest</code> 开始执行测试并跳过任何明确被标记为需要跳过的测试。</p>
</li>
<li class="lvl-2">
<p>一旦遇到第一个测试失败，它就会停止执行后续的测试，就像在标准的 <code>--stepwise</code> 模式下那样。</p>
</li>
<li class="lvl-2">
<p>当你修复了导致停止的测试失败后，可以再次运行 <code>pytest</code> 带上 <code>--stepwise</code> 和 <code>--stepwise-skip</code> 选项，它将从上次失败的测试处继续执行，并且继续跳过那些被标记为跳过的测试。</p>
</li>
<li class="lvl-2">
<p>名为 <code>--sw-skip</code> 的缩写形式可以替代 <code>--stepwise-skip</code> 使用。</p>
</li>
<li class="lvl-2">
<p>类似 <code>--stepwise</code>，这个选项在调试一个大型测试套件时非常有用，尤其是当你希望忽略已知将被跳过的测试，将焦点放在需要修复的失败测试上时。</p>
</li>
<li class="lvl-2">
<p><code>--stepwise-skip</code> 选项创造了一个快速迭代的测试环境，特别是在调试过程中，它绕过了不需要关注的测试，让你可以集中精力在当前失败处一步步前进。</p>
</li>
<li class="lvl-2">
<p>这个选项的使用前提是你的测试套件中包含了使用 <code>pytest.mark.skip</code> 或 <code>pytest.mark.skipif</code> 标记的测试。如果没有这样的跳过标记，它的行为就和标准的 <code>--stepwise</code> 选项一样。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>接口自动化测试的稳定性保证</title>
    <url>/2024/03/09/how_to_ensure_interface_automation_stability/</url>
    <content><![CDATA[<h1 id="jie-kou-zi-dong-hua-ce-shi-de-wen-ding-xing-bao-zheng">接口自动化测试的稳定性保证</h1>
<p>接口自动化测试的稳定性保证主要涉及以下几个方面：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>全面的测试策略：实施包括功能测试、单元测试、性能测试和持续集成/持续部署（CI/CD）在内的全面测试策略，可以确保API不仅稳定且高性能。这种全面的测试方法能够从多个角度验证API的正确运行和性能表现，从而提高其可靠性。</p>
</li>
<li class="lvl-3">
<p>数据量控制机制：在接口自动化测试框架中加入数据量控制机制，以保证接口测试的正确性和稳定性。这有助于避免因大量数据导致的系统压力过大，从而影响测试结果的准确性。</p>
</li>
<li class="lvl-3">
<p>代码质量控制：关注代码的质量问题，减少重复代码和不规范处理，以提升测试执行效率和代码维护的便利性。高质量的代码是保证测试稳定性的基础。</p>
</li>
<li class="lvl-3">
<p>测试环境的稳定性治理：确保有一个稳定的测试环境，这对于接口自动化测试至关重要。一个稳定的测试环境可以减少外部因素对测试结果的影响，提高测试的准确性。</p>
</li>
<li class="lvl-3">
<p>降低对外部依赖：在自动化测试用例中减少对数据库连接等外部资源的依赖，这有助于提高测试的独立性和稳定性。</p>
</li>
<li class="lvl-3">
<p>并发执行测试脚本：通过并发执行测试脚本，可以提高测试效率和覆盖范围，同时也能在一定程度上模拟真实的用户访问场景，从而更全面地评估接口的稳定性和性能。</p>
</li>
<li class="lvl-3">
<p>使用合适的工具和技术：选择适合的接口自动化测试工具和技术，如JMeter、LoadRunner、Postman等，这些工具可以帮助开发者有效地执行测试用例，验证API的功能、性能和兼容性。</p>
</li>
<li class="lvl-3">
<p>实时监测与优化：在部署环境后，实时监测API的运行状态，并根据监测结果进行必要的优化调整，以确保API的稳定运行。</p>
</li>
</ul>
<p>通过上述方法和技术的应用，可以有效地提高接口自动化测试的稳定性和可靠性，从而为用户提供无缝的体验和高质量的服务。</p>
<h1 id="ru-he-shi-shi-quan-mian-de-jie-kou-zi-dong-hua-ce-shi-ce-lue-yi-ti-gao-api-de-wen-ding-xing-he-xing-neng">如何实施全面的接口自动化测试策略以提高API的稳定性和性能？</h1>
<p>实施全面的接口自动化测试策略以提高API的稳定性和性能，可以遵循以下步骤：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>分层测试策略：采用分层测试策略，确保各层工作有明确的测试重心，通过逐层开展螺旋上升的方式进行测试。这样不仅可以促使开发和测试的一体化，提高测试效率，还可以尽早发现程序缺陷，降低缺陷修复成本。</p>
</li>
<li class="lvl-3">
<p>选择合适的接口进行自动化测试：根据项目需求和测试需求，选择合适的API接口进行自动化测试。这包括考虑接口的功能、复杂度以及对业务的影响等因素。</p>
</li>
<li class="lvl-3">
<p>制定合理的测试策略：在实施自动化测试之前，需要确保测试步骤顺序、运行环境配置正确，并且循环次数合理。这些配置的合理性直接影响到测试的效果和效率。</p>
</li>
<li class="lvl-3">
<p>定期回顾和改进测试策略：无论是手动测试还是自动化测试，都需要不断地回顾和改进测试策略。定期回顾测试结果和反馈，找出测试中的瓶颈和问题，并及时进行改进。这有助于持续提升测试的质量和效率。</p>
</li>
<li class="lvl-3">
<p>保障API接口的安全性和稳定性：从多个方面考虑和实施，包括身份认证、防止SQL注入和XSS攻击、加密传输、API版本控制、限流和熔断等措施，以确保API接口的安全性和稳定性。</p>
</li>
<li class="lvl-3">
<p>提高API性能：采取多方面的方法来提高API性能，包括高效的设计原则（如RESTful架构）、利用适当的数据格式等。这些策略有助于创建可扩展和高性能的API。</p>
</li>
<li class="lvl-3">
<p>监测和优化：在整个软件开发生命周期中，从设计和实施到监测和优化，都需要关注API性能的提升。这包括对API的响应时间、吞吐量、可伸缩性和稳定性等方面的持续监测和优化。</p>
</li>
</ul>
<p>通过上述步骤，可以有效地实施全面的接口自动化测试策略，从而提高API的稳定性和性能。</p>
<h1 id="shu-ju-liang-kong-zhi-ji-zhi-zai-jie-kou-zi-dong-hua-ce-shi-zhong-de-ying-yong-an-li-you-na-xie">数据量控制机制在接口自动化测试中的应用案例有哪些？</h1>
<p>数据量控制机制在接口自动化测试中的应用案例主要体现在以下几个方面：</p>
<ul class="lvl-0">
<li class="lvl-4">
<p>数据驱动测试：通过从用例层传入的测试数据进行数据驱动，这种做法可以有效地控制测试数据的数量和质量。例如，aomaker框架就采用了数据驱动的方式，通过@dependence装饰器标注接口的依赖，自动识别并调用依赖，同时结合特殊的变量管理机制来处理上游依赖变量的问题。这种方式不仅提高了测试的效率，也确保了测试数据的准确性和一致性。</p>
</li>
<li class="lvl-4">
<p>测试用例存储方式的选择：在设计接口自动化测试框架时，需要考虑测试用例的存储方式。不同的存储方式（如Excel表格、Yaml文件等）对数据量的控制有着不同的影响。选择合适的存储方式可以在一定程度上控制测试数据的规模，从而优化测试流程和提高测试效率。</p>
</li>
</ul>
<p>数据量控制机制在接口自动化测试中的应用案例包括但不限于数据驱动测试和测试用例存储方式的选择。这些应用案例展示了如何通过技术和策略来有效地管理和控制测试数据的规模，以达到提高测试效率和质量的目的。</p>
<h1 id="dai-ma-zhi-liang-kong-zhi-dui-ti-sheng-jie-kou-zi-dong-hua-ce-shi-wen-ding-xing-de-ying-xiang-ru-he-liang-hua">代码质量控制对提升接口自动化测试稳定性的影响如何量化？</h1>
<p>代码质量控制对提升接口自动化测试稳定性的影响可以通过以下几个方面量化：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>提高测试效率和质量：通过自动化测试工具，可以更全面地覆盖代码，确保所有功能和边缘情况都经过测试，从而提高软件的健壮性。此外，自动化测试可以保证测试结果的准确性和一致性，减少人为因素对测试结果的影响，从而提升测试质量。</p>
</li>
<li class="lvl-3">
<p>减少维护成本：由于接口测试代码本身的多变性，导致自动化脚本的维护成本大大增加。通过代码质量管理，可以减少重复代码和不规范化处理，从而降低维护成本。</p>
</li>
<li class="lvl-3">
<p>降低修复成本：从控制质量的角度来说，单元测试自动化是最应该投入资源去提升覆盖率的。因为代码的质量风险越早发现，修复的成本越低，对最终交付质量的影响也越小。</p>
</li>
<li class="lvl-3">
<p>提升测试执行效率：自动化测试可以快速执行测试用例，节省时间和人力资源。测试人员可以将更多的精力集中在创造性的测试任务上，而不是重复性的手动测试。</p>
</li>
<li class="lvl-3">
<p>便于持续集成和持续交付：接口自动化测试可以与持续集成工具结合使用，实现自动化测试与代码提交、构建、部署等流程的无缝衔接，从而提高整个开发周期的效率和稳定性。</p>
</li>
</ul>
<p>代码质量控制通过提高测试效率和质量、减少维护成本、降低修复成本、提升测试执行效率以及便于持续集成和持续交付等方面，对提升接口自动化测试稳定性具有显著的正面影响。这些影响可以通过具体的性能指标（如吞吐量TPS、响应延迟情况）、测试覆盖率、修复成本以及持续集成的成功率等量化指标来衡量。</p>
<h1 id="zai-jie-kou-zi-dong-hua-ce-shi-zhong-ru-he-you-xiao-jiang-di-dui-wai-bu-yi-lai-bing-ti-gao-ce-shi-du-li-xing">在接口自动化测试中，如何有效降低对外部依赖并提高测试独立性？</h1>
<p>在接口自动化测试中，有效降低对外部依赖并提高测试独立性可以通过以下几种方式实现：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>使用Mock框架：通过Mock框架可以虚拟出一个外部依赖，这样可以在不直接依赖外部服务的情况下进行测试。这种方式可以降低测试组件之间的耦合度，专注于代码的流程与结果，从而提高测试的独立性和效率。</p>
</li>
<li class="lvl-3">
<p>参数化测试：通过将用例中的输入和预期结果作为参数传递，可以在不更改用例结构的情况下执行多个测试场景。这种方法提高了用例的灵活性和独立性。</p>
</li>
<li class="lvl-3">
<p>单元测试：单元测试是一种测试方法，旨在验证软件单元（如函数、方法或类）的独立功能是否符合预期。通过编写高质量的测试代码，可以确保每个单元都能独立工作，减少对其他组件的依赖。</p>
</li>
<li class="lvl-3">
<p>数据驱动的Excel表格设计：通过设计用于数据驱动的Excel表格，可以在自动化框架中预先请求必要的接口以获取请求参数，从而解决接口间数据依赖的问题。这种方法允许在测试特定接口时，根据需要动态地获取所需的数据，而不是硬编码或预设静态数据。</p>
</li>
<li class="lvl-3">
<p>保持测试用例之间的独立性：在设计测试用例时，应遵循保持Case之间独立性的原则，确保每个测试用例能够独立运行。这有助于提高测试的效率和可靠性，因为每个用例都可以独立地验证其功能是否正确。</p>
</li>
</ul>
<p>通过采用Mock框架、参数化测试、单元测试、数据驱动的Excel表格设计以及保持测试用例之间的独立性等方法，可以有效地降低接口自动化测试对外部依赖，并提高测试的独立性。</p>
<h1 id="shi-shi-jian-ce-yu-you-hua-zai-que-bao-api-wen-ding-yun-xing-zhong-de-zui-jia-shi-jian-shi-shi-yao">实时监测与优化在确保API稳定运行中的最佳实践是什么？</h1>
<p>实时监测与优化在确保API稳定运行中的最佳实践主要包括以下几个方面：</p>
<ul class="lvl-0">
<li class="lvl-3">
<p>设定合理的监控指标：首先，需要定义与业务目标和用户期望一致的有意义的监控指标和KPI。这有助于确保监控活动能够有效地反映API的实际表现，并且能够及时发现问题。</p>
</li>
<li class="lvl-3">
<p>实施实时监控和警报：通过实施实时监控和警报机制，可以快速检测到API的问题，并迅速响应。这包括对API的运行状态、性能和健康状况进行实时监测和统计分析，以便及时发现并解决潜在的问题。</p>
</li>
<li class="lvl-3">
<p>完整的API事务监控能力：API监控应从业务视角进行，关注每一次API接口响应时间、可用性和正确性。如果API请求中的任何一个不可用，整个业务的API事务也会变得不可用。因此，实现连续告警是保障业务可用性的关键。</p>
</li>
<li class="lvl-3">
<p>采用安全身份验证与授权机制：为了提高API的安全性，应采用安全的身份验证与授权机制。这有助于确保只有经过授权的用户才能访问API并执行特定操作，从而减少安全风险。</p>
</li>
<li class="lvl-3">
<p>使用威胁检测工具：利用威胁检测工具来查找异常行为，标记或阻止滥用或潜在的攻击。实时监控对于发现和防御潜在的安全威胁至关重要。</p>
</li>
<li class="lvl-3">
<p>监控内容的重要性：在监控第三方API和Web服务时，监控的内容与方式同样重要。可操作的数据才是真正的价值所在，因此需要关注最常见、最有价值的指标。</p>
</li>
</ul>
<p>实时监测与优化在确保API稳定运行中的最佳实践涉及多个方面，包括设定合理的监控指标、实施实时监控和警报、完整的API事务监控能力、采用安全身份验证与授权机制、使用威胁检测工具以及重视监控内容的重要性。这些实践可以帮助企业实时监测和管理API的性能、可用性和安全性，提高系统的稳定性和可靠性。</p>
<h1 id="hui-zong">汇总</h1>
<img class="shadow" src="/img/in-post/API_automation_stability.png" width="800">
]]></content>
      <categories>
        <category>Automation</category>
      </categories>
      <tags>
        <tag>Automation</tag>
      </tags>
  </entry>
  <entry>
    <title>python logging的一个daemon</title>
    <url>/2024/03/31/python_logging_daemon/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>使用了这么多年的pytest了，过往的每个Project一直都有在记录整个Automation运行过程log信息。pytest集成了python的logging模块，使用起来更方便一些。今天闲来无事，看到个图形，想把它记录到log中，故而单独使用python的logging模块小试一下。</p>
<h1 id="python-logging-mo-kuai-jian-jie">python logging模块简介</h1>
<h2 id="ri-zhi-ji-bie">日志级别</h2>
<p>Python 标准库 logging 用作记录日志，默认分为六种日志级别（括号为级别对应的数值）：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>NOTSET（0）</p>
</li>
<li class="lvl-2">
<p>DEBUG（10）</p>
</li>
<li class="lvl-2">
<p>INFO（20）</p>
</li>
<li class="lvl-2">
<p>WARNING（30）</p>
</li>
<li class="lvl-2">
<p>ERROR（40）</p>
</li>
<li class="lvl-2">
<p>CRITICAL（50）</p>
</li>
</ul>
<p>logging 执行时输出大于等于设置的日志级别的日志信息，如设置日志级别是 INFO，则 INFO、WARNING、ERROR、CRITICAL 级别的日志都会输出。</p>
<h2 id="logging-liu-cheng">logging流程</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>Logger：日志，暴露函数给应用程序，基于日志记录器和过滤器级别决定哪些日志有效。</p>
</li>
<li class="lvl-2">
<p>LogRecord ：日志记录器，将日志传到相应的处理器处理。</p>
</li>
<li class="lvl-2">
<p>Handler ：处理器, 将(日志记录器产生的)日志记录发送至合适的目的地。</p>
</li>
<li class="lvl-2">
<p>Filter ：过滤器, 提供了更好的粒度控制,它可以决定输出哪些日志记录。</p>
</li>
<li class="lvl-2">
<p>Formatter：格式化器, 指明了最终输出中日志记录的布局。</p>
</li>
</ul>
<p><img class="shadow" src="/img/in-post/python_logging_flow.png" width="1200"></p>
<p>说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>判断 Logger 对象执行方法（如图中的 info()）时对于设置的级别是否可用，如果可用，则往下执行，否则，流程结束。</p>
</li>
<li class="lvl-2">
<p>创建 LogRecord 对象，如果注册到 Logger 对象中的 Filter 对象过滤后返回 False，则不记录日志，流程结束，否则，则向下执行。</p>
</li>
<li class="lvl-2">
<p>LogRecord 对象将 Handler 对象传入当前的 Logger 对象，（图中的子流程）如果 Handler 对象的日志级别大于设置的日志级别，再判断注册到 Handler 对象中的 Filter 对象过滤后是否返回 True 而放行输出日志信息，否则不放行，流程结束。</p>
</li>
<li class="lvl-2">
<p>如果传入的 Handler 大于 Logger 中设置的级别，也即 Handler 有效，则往下执行，否则，流程结束。</p>
</li>
<li class="lvl-2">
<p>判断这个 Logger 对象是否还有父 Logger 对象，如果没有（代表当前 Logger 对象是最顶层的 Logger 对象 root Logger），流程结束。否则将 Logger 对象设置为它的父 Logger 对象，重复上面的 3、4 两步，输出父类 Logger 对象中的日志输出，直到是 root Logger 为止。</p>
</li>
</ul>
<h2 id="ri-zhi-shu-chu-ge-shi">日志输出格式</h2>
<p>日志的输出格式可以使用设置，默认格式为下图所示。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>WARNING:日志级别</p>
</li>
<li class="lvl-2">
<p>root:Logger实例名称</p>
</li>
<li class="lvl-2">
<p>warn message:日志消息内容</p>
</li>
</ul>
<h1 id="dai-ma-shi-li">代码示例</h1>
<pre><code class="language-python">import logging
from logging.handlers import TimedRotatingFileHandler

class CustomLogger:
    _handlers_checked = set()

    def __init__(self, logger_name='sampleLogger', log_file='app.log', level=logging.INFO, console_output=False):
        self.logger_name = logger_name
        if logger_name not in CustomLogger._handlers_checked:
            self._setup_logger(log_file, level, console_output)
            CustomLogger._handlers_checked.add(logger_name)

    def _setup_logger(self, log_file, level, console_output):
        logger = logging.getLogger(self.logger_name)
        logger.setLevel(level)
        logger.propagate = False

        # Setup the file handler.
        file_handler = TimedRotatingFileHandler(
            log_file, when='D', interval=1, backupCount=5, encoding='utf-8'
        )
        file_handler.suffix = "%Y-%m-%d.log"
        file_handler.setLevel(level)
        file_handler.setFormatter(logging.Formatter('[%(asctime)s]-[%(name)s:%(lineno)d]-[%(levelname)-8s]-%(message)s'))
        logger.addHandler(file_handler)

        # Conditional setup for the console handler.
        if console_output:
            stream_handler = logging.StreamHandler()
            stream_handler.setLevel(level)
            stream_handler.setFormatter(logging.Formatter('[%(asctime)s]-[%(name)s:%(lineno)d]-[%(levelname)-8s]-%(message)s'))
            logger.addHandler(stream_handler)

        self.logger = logger

    def log(self, msg, level='info'):
        getattr(self.logger, level)(msg)

# Usage example:
log_filename = 'my_application.log'
log_level = logging.INFO
console_output = False

my_logger = CustomLogger(log_file=log_filename, level=log_level, console_output=console_output)
my_logger.log('这是一条信息日志。', 'info')
my_logger.log('这是一条警告日志。', 'warning')
my_logger.log(r"""

                                                              _ooOoo_
                                                             o8888888o
                                                             88" . "88
                                                             (| -_- |)
                                                              O\ = /O
                                                          ____/`---'\____
                                                        .   ' \\| |// `.
                                                         / \\||| : |||// \
                                                       / _||||| -:- |||||- \
                                                         | | \\\ - /// | |
                                                       | \_| ''\---/'' | |
                                                        \ .-\__ `-` ___/-. /
                                                     ___`. .' /--.--\ `. . __
                                                  ."" '&lt; `.___\_&lt;|&gt;_/___.' &gt;'"".
                                                 | | : `- \`.;`\ _ /`;.`/ - ` : | |
                                                   \ \ `-. \_ __\ /__ _/ .-` / /
                                           ======`-.____`-.___\_____/___.-`____.-'======
                                                              `=---='

                                           .............................................
                                                  佛祖保佑             永无BUG
                                           .............................................
""")
</code></pre>
<p>日志效果参考如下：</p>
<pre><code class="language-shell">[2024-03-31 11:46:29,741]-[sampleLogger:37]-[INFO    ]-这是一条信息日志。
[2024-03-31 11:46:29,741]-[sampleLogger:37]-[WARNING ]-这是一条警告日志。
[2024-03-31 11:46:29,741]-[sampleLogger:37]-[INFO    ]-
                                                              _ooOoo_
                                                             o8888888o
                                                             88" . "88
                                                             (| -_- |)
                                                              O\ = /O
                                                          ____/`---'\____
                                                        .   ' \\| |// `.
                                                         / \\||| : |||// \
                                                       / _||||| -:- |||||- \
                                                         | | \\\ - /// | |
                                                       | \_| ''\---/'' | |
                                                        \ .-\__ `-` ___/-. /
                                                     ___`. .' /--.--\ `. . __
                                                  ."" '&lt; `.___\_&lt;|&gt;_/___.' &gt;'"".
                                                 | | : `- \`.;`\ _ /`;.`/ - ` : | |
                                                   \ \ `-. \_ __\ /__ _/ .-` / /
                                           ======`-.____`-.___\_____/___.-`____.-'======
                                                              `=---='

                                           .............................................
                                                  佛祖保佑             永无BUG
                                           .............................................
</code></pre>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Allure属性装饰器优化</title>
    <url>/2024/04/01/allure_feature_wrapper/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>Allure HTML报告的强大之处在于它提供了丰富的属性来详细描述测试用例的每一个方面。这些属性不仅让报告内容更加全面，还增加了测试用例的可追溯性、可读性和沟通效率。通过精确的标签，团队成员可以快速理解每个测试的目的、重要性以及与之相关的问题。</p>
<h1 id="allure-shi-li">Allure示例</h1>
<p>下面，我们提供一个代码示例，使用pytest编写一个测试用例，并用Allure装饰器来注解，从而丰富报告内容：</p>
<pre><code class="language-python">import pytest
import allure

@allure.feature('登录功能')
@allure.story('用户正常登录')
@allure.severity(allure.severity_level.CRITICAL)
@allure.link('https://documentation.mysite.com/login-feature', name='登录模块文档')
@allure.issue('https://issue-tracker.mysite.com/issues/123', '登录失败的已知Bug')
@allure.testcase('https://test-tracker.mysite.com/case/456', '登录成功的测试案例')
@allure.title('正常情况下用户能够登录')
def test_login_functionality():
    pass
</code></pre>
<p>在上述代码中，我们使用了如下Allure装饰器：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>@allure.feature 标记了此测试属于哪个较大的功能模块。</p>
</li>
<li class="lvl-2">
<p>@allure.story 描述了具体的用户故事或测试场景。</p>
</li>
<li class="lvl-2">
<p>@allure.title 提供了对测试用例简明扼要的描述。</p>
</li>
<li class="lvl-2">
<p>@allure.severity 标出了测试用例的严重程度或优先级。</p>
</li>
<li class="lvl-2">
<p>@allure.link 提供了相关功能的文档链接。</p>
</li>
<li class="lvl-2">
<p>@allure.issue 提供了与已知Bug关联的链接。</p>
</li>
<li class="lvl-2">
<p>@allure.testcase 提供了测试案例的追踪链接。</p>
</li>
</ul>
<p>当运行这个测试并生成Allure报告时，所有这些细节都会在报告中呈现，使其他团队成员能够轻松查看测试用例的所有相关信息。</p>
<h1 id="you-hua">优化</h1>
<p>要使代码更 Pythonic 并优化用于 Allure 特性设置的代码重复，你可以创建一个装饰器工厂函数，将所有 Allure 相关的设置封装起来。这样的封装可以让你的测试用例代码更简洁、易读，并减少重复代码。以下是一个改进的例子：</p>
<pre><code class="language-python">import pytest
import allure

def allure_attributes(feature, story, title, severity, link=None, issue=None, test_case=None):
    def wrap(func):
        func = allure.feature(feature)(func)
        func = allure.story(story)(func)
        func = allure.title(title)(func)
        func = allure.severity(severity)(func)
        if link:
            func = allure.link(link[0], name=link[1])(func)
        if issue:
            func = allure.issue(issue[0], name=issue[1])(func)
        if test_case:
            func = allure.testcase(test_case[0], name=test_case[1])(func)
        return func
    return wrap

@allure_attributes(
    feature='登录功能',
    story='用户正常登录',
    title='正常情况下用户能够登录',
    severity=allure.severity_level.CRITICAL,
    link=('https://documentation.mysite.com/login-feature', '登录模块文档'),
    issue=('https://issue-tracker.mysite.com/issues/123', '登录失败的已知Bug'),
    test_case=('https://test-tracker.mysite.com/case/456', '登录成功的测试案例')
)
def test_login_functionality():
    pass
</code></pre>
<p>这里，allure_attributes 函数是一个装饰器工厂函数，它允许你传递所有需要的参数，并在内部应用相应的 Allure 装饰器。这样所有的 Allure 相关设置都被整齐地封装进一个单独的声明中，使得最终的测试用例函数保持其清晰和目的性。</p>
<h2 id="zai-ci-you-hua">再次优化</h2>
<p>上述的优化，每次都要传递那么几个固定的参数，不利于后期的拓展，毕竟allure能携带的属性信息还是非常的多的。考虑到此，再次优化一下,希望通过<code>**kwargs</code>来传递不确定的Allure属性参数，这将提供更大的灵活性。</p>
<pre><code class="language-python">import pytest
import allure

def allure_attributes(**kwargs):
    def decorator(func):
        for key, value in kwargs.items():
            if hasattr(allure, key):
                if isinstance(value, tuple) and len(value) == 2:
                    # Assuming tuple contains (url, name)
                    dec = getattr(allure, key)(value[0], name=value[1])
                else:
                    dec = getattr(allure, key)(value)
                func = dec(func)
            else:
                raise AttributeError(f"Allure does not have the attribute '{key}'")
        return func
    return decorator

# 使用方法
@allure_attributes(
    feature='登录功能',
    story='用户正常登录',
    title='正常情况下用户能够登录',
    severity='critical',
    link=('https://documentation.mysite.com/login-feature', '登录模块文档'),
    issue=('https://issue-tracker.mysite.com/issues/123', '登录失败的已知Bug'),
    testcase=('https://test-tracker.mysite.com/case/456', '登录成功的测试案例')
)
def test_login_functionality():
    pass
</code></pre>
<p>在这个版本中，allure_attributes函数通过<code>**kwargs</code>接收任意数量的命名参数，这些参数应对应于Allure提供的装饰器。该装饰器在内部检查了Allure模块是否拥有对应的属性，并适当地对函数应用了装饰器，以此来附加相应的测试元数据。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>Allure</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Allure</tag>
      </tags>
  </entry>
  <entry>
    <title>Allure报告常见封装代码优化</title>
    <url>/2024/04/02/allure_code_wrapping_optimization/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍Allure常见报告的封装，诸如allure的操作步骤、allure附件的上传。有一份代码，尝试优化它，使之更pythonnic。</p>
<h1 id="dai-ma">代码</h1>
<p><a href="http://xn--AllureReportTools-7e90ac052a.py">文件AllureReportTools.py</a>，封装了关于生成Allure报告的常见功能，内容如下所示：</p>
<pre><code class="language-python">import allure

from typing import Any
from pathlib import Path

from json import dumps as json_dumps
from allure_commons.types import AttachmentType


def get_file_property(filepath: str) -&gt; tuple[str, str, str]:
    """
    获取文件属性

    :param filepath:
    :return:
    """
    file = Path(filepath)
    filename = file.name
    file_root_name = file.stem
    filetype = file.suffix[1:]
    return filename, file_root_name, filetype


def allure_step(step: str, var: str | dict) -&gt; None:
    """
    allure 操作步骤

    :param step: 操作步骤
    :param var: 操作步骤中的变量
    :return:
    """
    with allure.step(step):
        allure.attach(
            body=json_dumps(var, ensure_ascii=False, indent=2) if isinstance(var, dict) else var,
            name='JSON Serialize',
            attachment_type=AttachmentType.JSON,
        )


def allure_attach(
    body: Any = None, name: str | None = None, attachment_type: str = 'JSON', extension: Any = None
) -&gt; None:
    """
    allure 报告上传附件

    :param body: 显示的内容
    :param name: 附件名称
    :param attachment_type: 文件类型，默认 JSON
    :param extension:
    :return:
    """
    allure.attach(
        body=body,
        name=name,
        attachment_type=getattr(AttachmentType, attachment_type.upper(), None),
        extension=extension,
    )


def allure_attach_file(filepath: str, name: str | None = None, extension: Any = None) -&gt; None:
    """
    allure 报告上传附件

    :param filepath: 文件路径
    :param name:
    :param extension:
    :return:
    """
    file_property = get_file_property(filepath)
    filename = file_property[0]
    filetype = file_property[2]
    if filetype == 'txt':
        filetype = 'TEXT'
    elif filetype == 'uri':
        filetype = 'URI_LIST'
    allure.attach.file(
        source=filepath,
        name=name or filename,
        attachment_type=getattr(AttachmentType, filetype.upper(), None),
        extension=extension,
    )
</code></pre>
<h1 id="you-hua">优化</h1>
<h2 id="dai-ma-you-hua-dian">代码优化点</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p>使用Python的类型注释来提升代码可读性。</p>
</li>
<li class="lvl-2">
<p>使用pathlib库简化文件操作，避免手动字符串拼接路径。</p>
</li>
<li class="lvl-2">
<p>更合理的函数和变量命名，提升代码可读性。</p>
</li>
<li class="lvl-2">
<p>使用枚举值，避免硬编码文件类型。</p>
</li>
<li class="lvl-2">
<p>精简allure_attach和allure_attach_file方法，提高其可用性。</p>
</li>
</ul>
<h2 id="you-hua-hou-dai-ma-shi-li">优化后代码示例</h2>
<pre><code class="language-python">import allure
import json

from typing import Any
from pathlib import Path
from allure_commons.types import AttachmentType


def get_file_properties(filepath: Path) -&gt; tuple[str, str, str]:
    """
    Obtain properties of the file.
    """
    return filepath.name, filepath.stem, filepath.suffix.lstrip('.')


def serialize_var(var: Any) -&gt; str:
    """
    Serialize variable to a formatted string.
    """
    return json.dumps(var, ensure_ascii=False, indent=2) if isinstance(var, dict) else str(var)


@allure.step('{step}')
def report_step(step: str, var: Any) -&gt; None:
    """
    Record an action step in Allure with its variable.
    """
    allure.attach.body(
        body=serialize_var(var),
        name='json_serialize',
        attachment_type=AttachmentType.JSON,
    )


def attach_to_report(body: Any, name: str = 'attachment', attachment_type: AttachmentType = AttachmentType.JSON) -&gt; None:
    """
    Attach a content to Allure report.
    """
    allure.attach(
        body=body,
        name=name,
        attachment_type=attachment_type
    )


def attach_file_to_report(filepath: Path, name: str | None = None) -&gt; None:
    """
    Attach a file to Allure report.
    """
    name = name or filepath.name
    _, _, file_type = get_file_properties(filepath)
    attach_type = AttachmentType.TEXT if file_type == 'txt' else getattr(AttachmentType, file_type.upper(), AttachmentType.JSON)

    allure.attach.file(
        source=str(filepath),
        name=name,
        attachment_type=attach_type
    )
</code></pre>
<p>在此代码中，每个函数都精确地完成一个单一任务，符合函数编程的原则。代码的可读性和可用性有所提高，附加的命名约定和类型注释有助于未来代码的维护和理解。总之，更pythonnic。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>Allure</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Allure</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Appium初始化driver碰到的问题记录</title>
    <url>/2024/04/02/init_appium_driver_issues/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近在写一个基于pytest+Appium的APP GUI自动化测试框架，使用Appium初始化driver的时候，碰到了各种各样的问题，现把期间碰到的问题做一下小结，供有需要的同学参考。</p>
<h1 id="peng-dao-de-wen-ti-yu-jie-jue-fang-fa">碰到的问题与解决方法</h1>
<p>说明：</p>
<p>如下问题，都是接连出现的，即出现了问题1，解决了问题1，再出现问题2，有一定的关联性。</p>
<h2 id="wen-ti-1-attribute-error-none-type-object-has-no-attribute-to-capabilities">问题1：AttributeError: ‘NoneType’ object has no attribute ‘to_capabilities’</h2>
<pre><code class="language-python">from appium import webdriver
from appium.webdriver.common.appiumby import AppiumBy
from appium.options.android  import UiAutomator2Options

desired_caps = {
    'platformName': 'Android',
    'platformVersion': '10',
    'deviceName': '62b6aca8',
    'automationName': 'UiAutomator2',
    'appPackage': 'com.xkw.client',
    'appActivity': 'com.zxxk.page.main.MainActivity'
}
driver = webdriver.Remote('http://localhost:4723/wd/hub', desired_caps)
</code></pre>
<p>上述代码执行的时候，报错：</p>
<pre><code class="language-python">&gt;&gt;&gt; driver = webdriver.Remote('http://localhost:4723/wd/hub', desired_caps)
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "C:\Users\Wang\AppData\Local\Programs\Python\Python311\Lib\site-packages\appium\webdriver\webdriver.py", line 229, in __init__
    super().__init__(
  File "C:\Users\Wang\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 188, in __init__
    capabilities = options.to_capabilities()
                   ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'to_capabilities'
&gt;&gt;&gt;
</code></pre>
<div class="note success"><p>解决方法：</p>
</div>
<pre><code class="language-python">from appium.webdriver.webdriver import AppiumOptions

appium_options = AppiumOptions()
appium_options.load_capabilities(capabilities)
driver = webdriver.Remote(appium_server_url, options=appium_options)
</code></pre>
<h2 id="wen-ti-2-original-error-neither-android-home-nor-android-sdk-root-environment-variable-was-exported">问题2: Original error: Neither ANDROID_HOME nor ANDROID_SDK_ROOT environment variable was exported.</h2>
<p>在问题1解决后，碰到问题2，报错信息如下：</p>
<pre><code class="language-shell">UnknownError: An unknown server-side error occurred while processing the command. Original error: Neither ANDROID_HOME nor ANDROID_SDK_ROOT environment variable was exported. Read https://developer.android.com/studio/command-line/variables for more details
    at getResponseForW3CError (C:\Program Files\Appium Server GUI\resources\app\node_modules\appium\node_modules\appium-base-driver\lib\protocol\errors.js:804:9)
    at asyncHandler (C:\Program Files\Appium Server GUI\resources\app\node_modules\appium\node_modules\appium-base-driver\lib\protocol\protocol.js:380:37)
&gt;&gt;&gt;
</code></pre>
<div class="note success"><p>解决方法：</p>
</div>
<p>安装android SDK。</p>
<h2 id="wen-ti-3-need-the-android-permission-install-grant-runtime-permissions-permission">问题3：need the android.permission.INSTALL_GRANT_RUNTIME_PERMISSIONS permission</h2>
<p>报错信息如下：</p>
<p>appium You need the android.permission.INSTALL_GRANT_RUNTIME_PERMISSIONS permission to use the Pa…</p>
<div class="note success"><p>解决方法：</p>
</div>
<p>手机开发者模式中开启USB调试（安全设置）</p>
<h2 id="wen-ti-4-unknown-error-an-unknown-server-side-error-occurred-while-processing-the-command-original-error-error-executing-adb-exec">问题4：UnknownError: An unknown server-side error occurred while processing the command. Original error: Error executing adbExec.</h2>
<p>详细报错信息如下：</p>
<pre><code class="language-shell">UnknownError: An unknown server-side error occurred while processing the command. Original error: Error executing adbExec. Original error: 'Command 'C:\\Users\\Wang\\AppData\\Local\\Android\\Sdk\\platform-tools\\adb.exe -P 5037 -s 62b6aca8 install -g 'C:\\Program Files\\Appium Server GUI\\resources\\app\\node_modules\\appium\\node_modules\\io.appium.settings\\apks\\settings_apk-debug.apk'' exited with code 1'; Command output: adb: failed to install C:\Program Files\Appium Server GUI\resources\app\node_modules\appium\node_modules\io.appium.settings\apks\settings_apk-debug.apk: Failure [INSTALL_FAILED_USER_RESTRICTED: Install canceled by user]
</code></pre>
<div class="note success"><p>解决方法：</p>
</div>
<p>开发者模式中允许USB安装apk</p>
<h2 id="wen-ti-5-qi-dong-appium-server-zhuo-mian-ban-bao-cuo">问题5：启动Appium Server桌面版报错</h2>
<p>报错信息如下：</p>
<pre><code class="language-shell">UnknownError: An unknown server-side error occurred while processing the command. Original error: Cannot verify the signature of 'C:\Users\Wang\AppData\Local\Temp\2024219-17712-1k7ahp1.639ci\appium-uiautomator2-server-v4.27.0.apk'. Original error: The 'java.exe' binary could not be found neither in PATH nor under JAVA_HOME (The JAVA_HOME environment variable is not set for the current process)
</code></pre>
<div class="note success"><p>解决方法：</p>
</div>
<p>启动Appium server桌面版本时，配置java_home路径，如：C:\Program Files\Java\jdk-21</p>
<h2 id="wen-ti-6-driver-chu-shi-hua-shi-hou-qi-dong-app-bao-cuo">问题6：driver初始化时候启动APP报错</h2>
<p>报错信息如下：</p>
<pre><code class="language-shell">Stacktrace:
UnknownError: An unknown server-side error occurred while processing the command. Original error: Cannot start the 'com.xkw.client' application. Visit https://github.com/appium/appium/blob/master/docs/en/writing-running-appium/android/activity-startup.md for troubleshooting. Original error: Error executing adbExec. Original error: 'Command 'C:\\Users\\Wang\\AppData\\Local\\Android\\Sdk\\platform-tools\\adb.exe -P 5037 -s 62b6aca8 shell am start -W -n com.xkw.client/com.zxxk.page.main.MainActivity -S -a android.intent.action.MAIN -c android.intent.category.LAUNCHER -f 0x10200000' exited with code 255'; Command output: Security exception: Permission Denial: starting Intent { act=android.intent.action.MAIN cat=[an uid=2000) not exported from uid 10174
</code></pre>
<div class="note success"><p>解决方法：</p>
</div>
<p>出现这样的错误一定是因为当前的appActivity设置的不是app首次进入的appActivity；</p>
<p>获取首次应用的活动名称可以通过 启动一次随机 monkey命令来获取</p>
<pre><code class="language-shell">adb shell
monkey -p com.XXXX.XXX -vvv 1 
</code></pre>
<p>过程参考如下：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;adb shell
lavender:/ $ monkey -p com.xkw.client  -vvv 1
  bash arg: -p
  bash arg: com.xkw.client
  bash arg: -vvv
  bash arg: 1
args: [-p, com.xkw.client, -vvv, 1]
 arg: "-p"
 arg: "com.xkw.client"
 arg: "-vvv"
 arg: "1"
data="com.xkw.client"
:Monkey: seed=1711059478748 count=1
:AllowPackage: com.xkw.client
:IncludeCategory: android.intent.category.LAUNCHER
:IncludeCategory: android.intent.category.MONKEY
// Event percentages:
//   0: 15.0%
//   1: 10.0%
//   2: 2.0%
//   3: 15.0%
//   4: -0.0%
//   5: -0.0%
//   6: 25.0%
//   7: 15.0%
//   8: 2.0%
//   9: 2.0%
//   10: 1.0%
//   11: 13.0%
:Switch: #Intent;action=android.intent.action.MAIN;category=android.intent.category.LAUNCHER;launchFlags=0x10200000;component=com.xkw.client/com.zxxk.page.main.LauncherActivity;end
    // Allowing start of Intent { act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] cmp=com.xkw.client/com.zxxk.page.main.LauncherActivity } in package com.xkw.client
    // Allowing start of Intent { act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] cmp=com.xkw.client/com.zxxk.page.main.LauncherActivity } in package com.xkw.client
Events injected: 1
:Sending rotation degree=0, persist=false
:Dropped: keys=0 pointers=0 trackballs=0 flips=0 rotations=0
## Network stats: elapsed time=27ms (0ms mobile, 0ms wifi, 27ms not connected)
// Monkey finished
lavender:/ $
</code></pre>
<p>这里的’com.zxxk.page.main.LauncherActivity’为启动页，修改后的代码参考如下：</p>
<pre><code class="language-python">from appium import webdriver
from appium.webdriver.webdriver import AppiumOptions
from appium.webdriver.common.appiumby import AppiumBy
from appium.options.android  import UiAutomator2Options

appium_server_url = 'http://localhost:4723/wd/hub'
desired_caps = {
    'platformName': 'Android',
    'platformVersion': '10',
    'deviceName': '62b6aca8',
    'skipServerInstallation': True,
    'automationName': 'UiAutomator2',
    'appPackage': 'com.xkw.client',
    'appActivity': 'com.zxxk.page.main.LauncherActivity'
}

appium_options = AppiumOptions()
appium_options.load_capabilities(desired_caps)
driver = webdriver.Remote(appium_server_url, options=appium_options)
</code></pre>
<h2 id="wen-ti-7-hua-dong-cao-zuo-shi-bao-cuo">问题7：滑动操作时报错</h2>
<p>滑动时碰到：</p>
<pre><code class="language-shell">io.appium.uiautomator2.common.exceptions.InvalidElementStateException: Unable to perform W3C actions. Check the logcat output for possible error reports and make sure your input actions chain is valid.
</code></pre>
<div class="note success"><p>解决方法：</p>
</div>
<p>获取分辨率或屏幕高和宽，上面报错是因为超屏了，超过了高度和宽度导致的。</p>
<p>代码参考如下：</p>
<pre><code class="language-python">    def get_size(self):
        """获取屏幕大小"""
        try:
            logging.info("开始获取设备屏幕大小。")
            size = self.driver.get_window_size()
            width = size.get("width")
            height = size.get("height")
            logging.info("获取设备屏幕大小完成。宽:(%s), 高(%s)", width, height)
            return width, height
        except Exception as err:
            logging.error("获取屏幕尺寸失败 ！ 错误为：(%s", err)
            return None
</code></pre>
<h2 id="wen-ti-8-qi-dong-appium-zhong-fu-an-zhuang-apk">问题8：启动Appium重复安装apk</h2>
<p>每次启动 Appium，运行测试脚本时，都会重新安装 io.appium.uiautomator2.server.apk 和 io.appium.uiautomator2.server.test.apk</p>
<div class="note success"><p>解决方法：</p>
</div>
<p>caps 增加设置：</p>
<pre><code class="language-shell">skipServerInstallation：True
</code></pre>
<p>注意：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>当设备上没有uiautomator2包时，不能设置skipServerInstallation：True</p>
</li>
<li class="lvl-2">
<p>当设备上已安装uiautomator2包，可以设置skipServerInstallation：True -&gt; 解决重复安装问题</p>
</li>
</ul>
<h2 id="wen-ti-9-qi-dong-uiautomatorviewer-shi-bao-cuo">问题9：启动uiautomatorviewer时报错</h2>
<p>报错信息如下：</p>
<pre><code class="language-shell">ERROR: No suitable Java found. In order to properly use the Android Developer
Tools, you need a suitable version of Java JDK installed on your system.
We recommend that you install the JDK version of JavaSE, available here:
  http://www.oracle.com/technetwork/java/javase/downloads

If you already have Java installed, you can define the JAVA_HOME environment
variable in Control Panel / System / Avanced System Settings to point to the
JDK folder.

You can find the complete Android SDK requirements here:
  http://developer.android.com/sdk/requirements.html
</code></pre>
<div class="note success"><p>解决方法：</p>
</div>
<p>这是因为安装了毕竟新的JDK，新版本的JDK中不再含有JRE，而uiautomatorviewer需要JRE。解决方法是安装一个低版本的JDK，比如安装了JDK18，自动会安装JRE18，然后将JRE18路径配置到系统环境变量中。</p>
<h2 id="wen-ti-10-shi-yong-uiautomatorviewer-lian-jie-mo-ni-qi-ye-mian-bao-cuo">问题10：使用uiautomatorviewer连接模拟器页面报错</h2>
<p>报错信息如下:</p>
<pre><code class="language-shell">Error while obtaining UI hierarchy XML file: com.android.ddmlib.SyncException: Remote object doesn't exist!
</code></pre>
<div class="note success"><p>解决方法1：</p>
</div>
<p>杀死adb服务器并重新启动它。</p>
<pre><code class="language-shell">adb kill-server

adb start-server
</code></pre>
<p>命令面板执行这两条命令后再次连接即可</p>
<div class="note success"><p>解决方法2：</p>
</div>
<p>命令面板运行：<code>adb reconnect</code></p>
<p>运行后再次点击连接即可。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>Appium</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Appium</tag>
      </tags>
  </entry>
  <entry>
    <title>markdown文件实现标题缩一级功能</title>
    <url>/2024/04/09/markdown_title_indentation/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>因为最近在整理文档，使用markdown格式编写pytest相关知识点，一个md文件为一个系统性的知识点，现在准备把这些文件合并成一个md文件，各个章节的标题都要缩一级。由于篇幅比较长，接近800页，手工操作会非常耗时，也容易出错，遂写了这个脚本，帮我替换文件中的#，达到md文件缩一级别的目的。操作手法也比较简单，查看markdown文件的源码，拷贝下来贴到文件a.txt中，然后对这个文件进行替换处理，同时要关注文章中有哪些内容也是一#开头的，需要忽略一下，避免误替换。方法也简单，比如：</p>
<pre><code class="language-shell">cat a.txt |grep '^#' |grep [0-9] |grep -v '-' |grep -v 'content' | grep -v '注释' | grep -Evi 'Centos7|This kickstart file|AMD6|S3 takeover IP|/usr/bin/env|没有用修饰器修饰，故不会引用|添加 flake8 的配置|下面我们定义了30个独立的测试用例|应为200，表示成功删除，无返回内容' &gt;b.txt
</code></pre>
<p>检查下b.txt文件，是否还有其他误替换的，再反过滤即可。</p>
<h1 id="dai-ma-shi-xian">代码实现</h1>
<p>如果使用Shell命令，会比较复杂一些，这里使用python实现。直接上代码（比较粗糙，临时顶替，能用就好<sup>-</sup>）</p>
<pre><code class="language-python">import re


def should_replace(line):
    exclude_patterns = [
        '-',
        'content',
        '注释',
        'Centos7',
        'This kickstart file',
        'AMD6',
        'S3 takeover IP',
        '/usr/bin/env',
        '没有用修饰器修饰，故不会引用',
        '添加 flake8 的配置',
        '下面我们定义了30个独立的测试用例',
        '应为200，表示成功删除，无返回内容',
        'Get file of md5',
        '将是',
        'This test will be',
        '检查结果是否为',
        '一般来说，0 表示测试通',
        'cells.insert',
        'Add funcargs as fixtur',
        'Safari',
        'Edge',
        '假设有效的用户名和密码',
        '键名看起来像 ',
        '只会在 number_fixture',
        '设置函数超时限制',
        '将时间向前移动',
        '发起GET请求并设定连接超',
        '这个测试将会运行10次'
    ]
    if line.strip().startswith("#") and any(char.isdigit() for char in line):
        if not any(re.search(pattern, line, re.IGNORECASE) for pattern in exclude_patterns):
            return True
    return False


def process_file(input_filepath, output_filepath):
    with open(input_filepath, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    
    new_lines = []
    for line in lines:
        # 首先确认行是否符合替换的条件
        if should_replace(line):
            # 使用 re.sub 替换行开头第一个 '#' 为 '##'
            # 注意这里的正则表达式
            # '\A#' 匹配字符串开头的 '#'
            # '\A##*#' 匹配字符串开头的连续 '#'，但至少需要有一个 '#'
            line = re.sub(r'\A#', '##', line, count=1)
        new_lines.append(line)

    # 写入新文件
    with open(output_filepath, 'w', encoding='utf-8') as new_file:
        new_file.writelines(new_lines)

# 使用方法：
process_file('a.txt', 'output_filename.txt'
</code></pre>
<p>解释如下：</p>
<p>在这里，我们使用 \A# 正则表达式来确保我们只匹配每一行开头的第一个 #。\A 是正则表达式中用于匹配字符串开始位置的特殊符号。<br>
count=1 参数确保只替换第一次匹配到的 #。这样，如果一行以多个 # 开头，只会将行开头的第一个 # 替换成 ##。其他的 # 将保持不变。</p>
<p>最后，将调整后的内容写入新文件（output_filepath），而不是覆盖原来的文件。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu23下Docker部署</title>
    <url>/2024/04/11/ubuntu_docker/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>很久没有碰Docker了，今天在VM下（基于Ubuntu23 Server）安装docker，记录一下。</p>
<h1 id="an-zhuang-docker">安装Docker</h1>
<p>使用如下脚本，一键部署docker</p>
<pre><code class="language-python">import os
import sys
import subprocess


# 检查当前用户是否是root用户
def is_root_user():
    print("  检查是否为root用户")
    return os.geteuid() == 0

# 尝试执行一个需要sudo权限的命令，判断是否具有sudo权限
def has_sudo_permission():
    print("  检查是否具有sudo权限")
    try:
        # 这里我们尝试更改一个只有root用户才能更改的系统文件的权限
        # 如果有sudo权限，这个命令会被sudo执行并成功更改权限
        # 注意：这是一个无害的命令，只是尝试更改文件的权限并不会真的创建文件
        subprocess.run(['sudo', 'chmod', '755', '/etc/passwd'], check=True,
                       stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return True
    except subprocess.CalledProcessError:
        # 如果捕获到CalledProcessError异常，说明没有sudo权限
        return False

# 检查是否具有执行安装的权限
def check_root_privilege():
    print("\nStep1.检查当前用户是否有root权限")
    if not is_root_user() or not has_sudo_permission():
        print("Error: You must have root privileges to install Docker. Please run as root or use 'sudo'.")
        sys.exit(1)

# 执行命令并检查返回值
def run_command(command):
    try:
        subprocess.run(command, check=True)
    except subprocess.CalledProcessError as e:
        print(f"Error executing command '{' '.join(command)}': {e}")
        sys.exit(1)

# 主函数，安装Docker
def install_docker():
    # 检查当前用户是否是root用户
    check_root_privilege()
    
    # 更新软件包索引
    print('\nStep2.apt-get update')
    run_command(["sudo", "apt-get", "update"])
    
    # 安装Docker所需的依赖包
    print("\nStep3.安装Docker所需的依赖包")
    run_command(["sudo", "apt-get", "install", "-y", "apt-transport-https",
                 "ca-certificates", "curl", "gnupg", "lsb-release"])
    
    # 添加Docker的官方GPG密钥
    print("\nStep4.添加Docker的官方GPG密钥")
    try:
        # 使用Popen来执行管道命令
        process = subprocess.Popen(["curl", "-fsSL", "https://download.docker.com/linux/ubuntu/gpg"],
                                   stdout=subprocess.PIPE)
        # 将curl命令的输出通过管道传递给apt-key add命令
        gpg_key = process.communicate()[0].decode().strip()
        # 添加GPG密钥
        run_command(["echo", gpg_key, "|", "sudo", "apt-key", "add"])
    except subprocess.CalledProcessError as e:
        print(f"Error adding Docker GPG key: {e}")
        sys.exit(1)

    # 设置稳定的Docker仓库
    # 你需要根据你的系统版本替换LSB_RELEASE_OUTPUT变量的值
    print("\nStep5.设置稳定的Docker仓库")

    # 获取系统的LSB版本和发行版代号
    lsb_release_output = subprocess.check_output(['lsb_release', '-cs', '|', 'grep', '-v', 'No']).decode().strip()
    
    run_command(["sudo", "add-apt-repository", "deb [arch=amd64] https://download.docker.com/linux/ubuntu",
                 f"{lsb_release_output}", "docker", "stable"])

    # 移除错误的Docker仓库（如果已添加）
    run_command(["sudo", "rm", "-rf", "/etc/apt/sources.list.d/docker.list"])
    
    # 构造正确的Docker仓库URL
    docker_repository = f"https://download.docker.com/linux/ubuntu {lsb_release_output}"
    
    # 添加Docker的官方仓库到系统的sources.list文件
    run_command(["sudo", "add-apt-repository", " deb [arch=amd64] " + docker_repository + " docker-ce stable"])
    
    # 更新软件包索引
    run_command(["sudo", "apt-get", "update"])

    # 再次更新软件包索引
    print("\nStep6.再次更新软件包索引")
    run_command(["sudo", "apt-get", "update"])
    
    # 安装Docker Engine
    print("\nStep7.安装Docker Engine")
    run_command(["sudo", "apt-get", "install", "-y", "docker-ce", "docker-ce-cli", "containerd.io"])
    
    # 启动Docker服务
    print("\nStep8.启动Docker服务")
    run_command(["sudo", "systemctl", "enable", "docker"])
    run_command(["sudo", "systemctl", "start", "docker"])
    
    print("[Success]Docker has been successfully installed!")

if __name__ == "__main__":
    install_docker()
</code></pre>
<p>执行成功后，检查Docker是否被成功安装：</p>
<pre><code class="language-shell">root@Service:~# docker ps
CONTAINER ID   IMAGE             COMMAND       CREATED        STATUS             PORTS     NAMES
root@Service:~#
</code></pre>
<p>出现如上信息，表明Docker成功安装。</p>
<h1 id="an-zhuang-docker-compose">安装docker-compose</h1>
<p>前往官网<code>https://github.com/docker/compose/releases</code>，查看最新版本，比如v2.26.1，使用如下命令进行安装：</p>
<pre><code class="language-shell">curl -L "https://github.com/docker/compose/releases/download/v2.26.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
</code></pre>
<p>安装后，执行<code>docker-compose --version</code>检查是否安装成功：</p>
<pre><code class="language-shell">root@Service:~# docker-compose --version
Docker Compose version v2.26.1
root@Service:~# 
</code></pre>
<p>如上表示成功安装了docker-compose v2.26.1版本。</p>
<h1 id="an-zhuang-docker-machine">安装docker-machine</h1>
<p>前往官网<code>https://github.com/docker/machine/releases</code>获取最新release版本号，比如<code>v0.16.2</code>，执行如下命令进行安装：</p>
<pre><code class="language-shell">base=https://github.com/docker/machine/releases/download/v0.16.2 &amp;&amp;
curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp;
mv /tmp/docker-machine /usr/local/bin/docker-machine &amp;&amp;
chmod +x /usr/local/bin/docker-machine
</code></pre>
<p>检查安装效果：</p>
<pre><code class="language-shell">root@Service:~# docker-machine --version
docker-machine version 0.16.2, build bd45ab13
root@Service:~# docker-machine ls
NAME   ACTIVE   DRIVER   STATE   URL   SWARM   DOCKER   ERRORS
root@Service:~# 
</code></pre>
<h1 id="docker-machine-shi-yong">docker-machine 使用</h1>
<p>接下来通过 virtualbox 来介绍 docker-machine 的使用方法。其他云服务商操作与此基本一致，具体可以参考每家服务商的指导文档。</p>
<p>说明：</p>
<p>请从<code>https://www.virtualbox.org/wiki/Downloads</code>下载并安装virtualbox，并设置环境变量。</p>
<p>比如我的环境是Ubuntu 23，直接 <code>apt-get install virtualbox</code> 进行安装。</p>
<h2 id="lie-chu-ke-yong-de-ji-qi">列出可用的机器</h2>
<pre><code class="language-shell">root@Service:~# docker-machine ls
NAME   ACTIVE   DRIVER   STATE   URL   SWARM   DOCKER   ERRORS
root@Service:~# 
</code></pre>
<p>显示为空。</p>
<h2 id="chuang-jian-ke-yong-de-ji-qi">创建可用的机器</h2>
<p>创建一台名为 Gavin 的机器:</p>
<pre><code class="language-shell">docker-machine create --driver virtualbox Gavin
</code></pre>
<p>创建过程如下：</p>
<pre><code class="language-shell">root@Service:~# docker-machine create --driver virtualbox Gavin
Creating CA: /root/.docker/machine/certs/ca.pem
Creating client certificate: /root/.docker/machine/certs/cert.pem
Running pre-create checks...
Error with pre-create check: "VBoxManage not found. Make sure VirtualBox is installed and VBoxManage is in the path"
root@Service:~# 
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>–driver：指定用来创建机器的驱动类型，这里是 virtualbox。</p>
</li>
</ul>
<p>这个时候再次列出可用机器：</p>
<pre><code class="language-shell">root@Service:~# docker-machine create --driver virtualbox Gavin
Running pre-create checks...
(Gavin) No default Boot2Docker ISO found locally, downloading the latest release...
(Gavin) Latest release for github.com/boot2docker/boot2docker is v19.03.12
(Gavin) Downloading /root/.docker/machine/cache/boot2docker.iso from https://github.com/boot2docker/boot2docker/releases/download/v19.03.12/boot2docker.iso...
(Gavin) 0%....10%....20%....30%....40%....50%....60%....70%....80%....90%....100%
Creating machine...
(Gavin) Copying /root/.docker/machine/cache/boot2docker.iso to /root/.docker/machine/machines/Gavin/boot2docker.iso...
(Gavin) Creating VirtualBox VM...
(Gavin) Creating SSH key...
(Gavin) Starting the VM...
(Gavin) Check network to re-create if needed...
(Gavin) Found a new host-only adapter: "vboxnet0"
Error creating machine: Error in driver during machine creation: Error setting up host only network on machine start: /usr/bin/VBoxManage hostonlyif ipconfig vboxnet0 --ip 192.168.99.1 --netmask 255.255.255.0 failed:
VBoxManage: error: Code E_ACCESSDENIED (0x80070005) - Access denied (extended info not available)
VBoxManage: error: Context: "EnableStaticIPConfig(Bstr(pszIp).raw(), Bstr(pszNetmask).raw())" at line 252 of file VBoxManageHostonly.cpp
</code></pre>
<p>这里报错了，提示权限问题，暂时没解决掉，先放着吧。</p>
<h1 id="chang-jian-cuo-wu">常见错误</h1>
<h2 id="zhi-xing-docker-compose-up-ti-shi-services-must-be-a-mapping">执行docker-compose up提示’services must be a mapping’</h2>
<pre><code class="language-shell">root@Service:~/composetest# docker-compose up
services must be a mapping
root@Service:~/composetest# 
</code></pre>
<p>错误信息 “services must be a mapping” 表示 docker-compose 命令无法执行，因为在执行过程中没有找到正确格式的 docker-compose.yml 文件，或者该文件格式不正确。对于YML文件，注意如下细节：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>缩进问题：YAML 文件非常依赖正确的缩进，且只接受空格作为缩进字符，不接受制表符（Tab）。请确保每一级缩进都使用了两个或更多的空格，并且层级结构保持一致。</p>
</li>
<li class="lvl-2">
<p>行尾的空格：YAML 文件中的每一行末尾都不能有任何额外的字符，包括空格。</p>
</li>
</ul>
<h2 id="jin-ru-rong-qi-bao-cuo-stat-bin-bash-no-such-file-or-directory-unknown">进入容器报错’stat /bin/bash: no such file or directory: unknown’</h2>
<pre><code class="language-shell">root@Service:~# docker exec -it 085bdc5ed931 /bin/bash
OCI runtime exec failed: exec failed: unable to start container process: exec: "/bin/bash": stat /bin/bash: no such file or directory: unknown
root@Service:~# 
</code></pre>
<p>解决方法：更换shell类型：</p>
<pre><code class="language-shell">root@Service:~# docker exec -it 085bdc5ed931 /bin/bash
OCI runtime exec failed: exec failed: unable to start container process: exec: "/bin/bash": stat /bin/bash: no such file or directory: unknown
root@Service:~# docker exec -it 085bdc5ed931 /bin/sh
/data # 
/data # 
/data # cat /etc/shells 
# valid login shells
/bin/sh
/bin/ash
/data # 
</code></pre>
<p>我们还可以通过echo $SHELL 命令来查看当前使用的Shell类型。</p>
<p>下面我们进行一些常见Shell的讲解：<br>
(1) BourneShell(sh)：是由AT&amp;T Bell实验室的 Steven Bourne为AT&amp;T的Unix开发的，它是Unix的默认Shell，也是其它Shell的开发基础。Bourne Shell在编程方面相当优秀，但在处理与用户的交互方面不如其它几种Shell。</p>
<p>(2) BourneAgain Shell (即bash)：是自由软件基金会(GNU)开发的一个Shell，它是Linux系统中一个默认的Shell。Bash不但与Bourne Shell兼容，还继承了C Shell、Korn Shell等优点。</p>
<p>(3) ash：ash Shell是由Kenneth Almquist编写的，是Linux 中占用系统资源最少的一个小Shell，它只包含24个内部命令，因而使用起来很不方便。</p>
<p>(4) CShell(csh)：是加州伯克利大学的Bill Joy为BSD Unix开发的，共有52个内部命令，与sh不同，它的语法与C语言很相似。它提供了Bourne Shell所不能处理的用户交互特征，如命令补全、命令别名、历史命令替换等。但是，C Shell与BourneShell并不兼容。该Shell其实是指向/bin/tcsh这样的一个Shell，也就是说，csh其实就是tcsh。</p>
<p>(5) KornShell(ksh)：是AT&amp;T Bell实验室的David Korn开发的，共有42 条内部命令，它集合了C Shell和Bourne Shell的优点，并且与Bourne Shell向下完全兼容。Korn Shell的效率很高，其命令交互界面和编程交互界面都很好。</p>
<p>(6) zch：是Linux 最大的Shell之一，由Paul Falstad完成，共有84 个内部命令。如果只是一般的用途，没有必要安装这样的Shell。</p>
<p>注释：bash是 Bourne Again Shell 的缩写，是linux标准的默认shell ，它基于Bourne shell，吸收了C shell和Korn shell的一些特性。bash完全兼容sh，也就是说，用sh写的脚本可以不加修改的在bash中执行。</p>
<h2 id="docker-machine-create-bao-cuo-e-accessdenied-0-x-80070005">docker-machine create 报错 E_ACCESSDENIED (0x80070005)</h2>
<pre><code class="language-shell">(Gavin) Found a new host-only adapter: "vboxnet1"
Error creating machine: Error in driver during machine creation: Error setting up host only network on machine start: /usr/bin/VBoxManage hostonlyif ipconfig vboxnet1 --ip 192.168.99.1 --netmask 255.255.255.0 failed:
VBoxManage: error: Code E_ACCESSDENIED (0x80070005) - Access denied (extended info not available)
VBoxManage: error: Context: "EnableStaticIPConfig(Bstr(pszIp).raw(), Bstr(pszNetmask).raw())" at line 252 of file VBoxManageHostonly.cpp
</code></pre>
<p>解决方法：</p>
<p>暂时未找到有效解决方法，先搁置。</p>
]]></content>
      <categories>
        <category>python</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>python</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Install&amp;configure xmanager under ubuntu23</title>
    <url>/2024/04/15/install_config_xmanager_in_ubuntu23/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>近期有使用到xmanager软件控制Ubuntu，简单记录一下如何在Ubuntu23 上安装&amp;配置xmanager软件。</p>
<h1 id="an-zhuang-amp-pei-zhi-guo-cheng">安装&amp;配置过程</h1>
<h2 id="an-zhuang-gdm">安装gdm</h2>
<pre><code class="language-shell">apt install gdm3 -y
</code></pre>
<h2 id="pei-zhi-lightdm">配置lightdm</h2>
<p>1.新建并编辑配置文件：vi /etc/lightdm/lightdm.conf</p>
<p>粘贴以下内容:</p>
<pre><code class="language-shell">[SeatDefaults]
greeter-show-manual-login=true
xserver-allow-tcp=true

[XDMCPServer]
Enabled=true
Port=177
</code></pre>
<p>2.新建并编辑配置文件：nano /etc/lightdm/gdm.schemas</p>
<p>粘贴以下内容：</p>
<pre><code class="language-shell">&lt;schema&gt;
&lt;key&gt;xdmcp/Enable&lt;/key&gt;
&lt;signature&gt;b&lt;/signature&gt;
&lt;default&gt;true&lt;/default&gt;
&lt;/schema&gt;
</code></pre>
<p>3.安装xubuntu-desktop</p>
<p>xubuntu-desktop用的就是xfce，一个轻量级的unix桌面管理环境，执行以下安装命令：</p>
<pre><code class="language-shell">apt-get update
apt-get upgrade
apt install xfce4
apt install xubuntu-desktop -y
</code></pre>
<p>4.关闭防火墙</p>
<p>关闭防火墙：<code>ufw disable</code>或者允许177端口：<code>ufw allow 177</code></p>
<p>5.修改配置Ubuntu文件</p>
<p>修改配置文件：nano /usr/share/lightdm/lightdm.conf.d/50-ubuntu.conf<br>
内容修改后如下：</p>
<pre><code class="language-shell">[Seat:*]
user-session=ubuntu

[XDMCPServer]
enabled=true

[SeatDefaults]
xserver-allow-tcp=true
</code></pre>
<p>6.重启XDMCP daemon</p>
<p>重启lightdm ： <code>service lightdm restart</code><br>
查看状态：<code>systemctl status lightdm.service</code></p>
<p><strong>说明:</strong></p>
<p>如果没有root权限，有sudo权限，可在相关命令前增加sudo。</p>
<p>进行完上述动作后，在xmanager中新增一个XDMCP，如下图所示：</p>
<img class="shadow" src="/img/in-post/config_xmanager.png" width="400">
<p>然后就可以通过xmanager访问Ubuntu了，和本地访问效果一样。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>xmanager</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>xmanager</tag>
      </tags>
  </entry>
  <entry>
    <title>Install excalidraw under docker</title>
    <url>/2024/04/15/install_excalidraw_under_docker/</url>
    <content><![CDATA[<h1 id="overview">Overview</h1>
<p>Install excalidraw under docker.</p>
<h1 id=""></h1>
<h1 id="install-excalidraw-using-docker">Install Excalidraw using Docker</h1>
<p>Now that Docker is installed, you can pull the Excalidraw Docker image and run it as a container.</p>
<p><code>docker pull docker.io/excalidraw/excalidraw:latest</code></p>
<p>Run the Excalidraw container in detached mode (-d) and map port 8080 on your host to port 80 on the container using the following command:</p>
<p>docker run -p 8080:80 -d <a href="http://docker.io/excalidraw/excalidraw:latest">docker.io/excalidraw/excalidraw:latest</a></p>
<h1 id="check-excalidraw-service">Check excalidraw service</h1>
<pre><code class="language-shell">root@Service:~# docker ps -a
CONTAINER ID   IMAGE                          COMMAND                  CREATED              STATUS                        PORTS                                   NAMES
abe9fa359013   excalidraw/excalidraw:latest   "/docker-entrypoint.…"   About a minute ago   Up About a minute (healthy)   0.0.0.0:8080-&gt;80/tcp, :::8080-&gt;80/tcp   keen_pasteur
085bdc5ed931   redis:alpine                   "docker-entrypoint.s…"   4 days ago           Exited (0) 2 days ago                                                 composetest-redis-1
32c88ec9f1f6   composetest-web                "flask run"              4 days ago           Exited (1) 4 days ago                                                 composetest-web-1
45b89e827bc5   ubuntu                         "/bin/bash"              4 days ago           Exited (137) 2 hours ago                                              heuristic_feistel
ca0493c84c48   dokken/centos-8                "/bin/bash"              4 days ago           Exited (0) 4 days ago                                                 quizzical_hodgkin
root@Service:~#
</code></pre>
<p>CONTAINER ID of <code>abe9fa359013</code> which status is ‘UP’ and healthy.</p>
<h1 id="access-excalidraw">Access Excalidraw</h1>
<p>Now that Excalidraw is running as a Docker container, you can access it through a web browser by navigating to http://your_vps_ip:8080.</p>
<p><code>http://your_vps_ip:8080</code></p>
<p>Replace your_vps_ip with the actual IP address of your VPS.</p>
<h1 id="previews">Previews</h1>
<img class="shadow" src="/img/in-post/excalidraw.png" width="600">
]]></content>
      <categories>
        <category>Docker</category>
        <category>excalidraw</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>excalidraw</tag>
      </tags>
  </entry>
  <entry>
    <title>python assignment expression, :=</title>
    <url>/2024/04/17/python_assignment_expression/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>最近在看《流畅的python》第二版，上册，第二章节有提及到<code>:=</code>，书中举例了一个list中某个值的访问，搜索一下相关资料，学习一下。果真此运算符比书中所提及的功能要丰富的多，故mark一下。</p>
<h1 id="qian-yan">前言</h1>
<p>经资料查询，从Python 3.8开始，引入了一项新的语法特性：“海象运算符”，它的正式名称是 Assignment Expressions（赋值表达式），标记为 <code>:=</code>。这个运算符允许你在表达式内进行变量赋值，从而可以在一个表达式中完成测试和赋值两个动作。由于它的外形像海象的眼睛和长牙，因此社区给它起了个昵称"海象运算符"。</p>
<p>海象运算符的一个典型用途是在条件语句中，它允许在测试某个条件的同时将其值赋给一个变量。不仅如此，它还可用于循环和其他许多场合，从而使代码更加简洁且易于理解。</p>
<h1 id="chang-jing-yi-lie-biao-tui-dao-shi-zhong-yuan-su-fang-wen">场景一：列表推导式中元素访问</h1>
<pre><code class="language-python">[last := x for x in range(10)]
</code></pre>
<p>我们使用 <code>:=</code> 运算符将每个 x 的值赋给 last 变量。注意，这里的 last 实际上并没有在列表推导式中作为变量名 x 的别名使用，而是在整个推导式完成后，将最后一个元素的值赋给 last 变量。这个技巧允许我们在列表推导式完成后，通过 last 变量获取到这个新列表的最后一个元素。</p>
<p>生成的列表包含了从 0 到 9 的整数，如下所示：</p>
<pre><code class="language-python">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
</code></pre>
<p>当你查询 last 变量时，它会返回列表中的最后一个元素，也就是 9。</p>
<p>再比如：</p>
<pre><code class="language-python">&gt;&gt;&gt; import re
&gt;&gt;&gt; data = "Some example numbers: 10, 20, and 30"
&gt;&gt;&gt; (match := re.findall(r'\d+', data))
['10', '20', '30']
&gt;&gt;&gt; match
['10', '20', '30']
&gt;&gt;&gt; 
</code></pre>
<h1 id="chang-jing-er-zai-while-xun-huan-zhong-du-qu-yong-hu-shu-ru-zhi-dao-kong-xing-chu-xian">场景二：在 while 循环中读取用户输入直到空行出现。</h1>
<pre><code class="language-python">
# 传统的写法
user_input = input("Enter message: ")
while user_input:
    print(f'Echo: {user_input}')
    user_input = input("Enter message: ")


# 使用海象运算符
while (user_input := input("Enter message: ")):
    print(f'Echo: {user_input}')
</code></pre>
<p>在这个例子中，使用海象运算符让代码更简洁，减少了重复的 input 调用。</p>
<h1 id="chang-jing-san-zai-if-yu-ju-zhong-shi-yong-tong-shi-ce-shi-he-fu-zhi">场景三：在 if 语句中使用，同时测试和赋值。</h1>
<pre><code class="language-python">data = "Some example numbers: 10, 20, and 30"

# 传统做法
match = re.search('(\d+)', data)
if match:
    print(f"Found a number: {match.group(1)}")

# 使用海象运算符
if match := re.search('(\d+)', data):
    print(f"Found a number: {match.group(1)}")
</code></pre>
<p>在上述例子中，使用海象运算符可以在判断条件真假时同时捕获正则表达式捕获组（在这里是数字）。</p>
<h1 id="chang-jing-si-xu-yao-duo-ci-shi-yong-mou-ge-ang-gui-de-ji-suan-jie-guo-shi">场景四：需要多次使用某个昂贵的计算结果时。</h1>
<pre><code class="language-python">
# 传统做法
result = some_expensive_calculation_function()
if result:
    other_function(result)

# 使用海象运算符
if (result := some_expensive_calculation_function()):
    other_function(result)
</code></pre>
<p>在这个例子中，海象运算符让我们无需调用两次<code>some_expensive_calculation_function()</code>就能够重用其计算结果。</p>
<p>海象运算符提高了代码的可读性和编写效率，在合适的场景下使用可使得代码更加精简和优雅。然而，像所有新引入的语法特性一样，使用时应该注意代码的清晰性和易维护性，过度使用或者在不适当的情况下使用可能会增加代码的复杂性。</p>
<p>注意事项：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>海象运算符只能用于 Python 3.8 及以上版本。</p>
</li>
<li class="lvl-2">
<p>使用海象运算符时，应确保右侧的表达式是安全的，即不会引起异常。如果表达式可能抛出异常，那么使用海象运算符可能会导致代码的错误处理变得复杂。</p>
</li>
<li class="lvl-2">
<p>海象运算符主要用于简化代码，但它并不总是必要的。在某些情况下，使用传统的多行赋值和条件语句可能更清晰。</p>
</li>
</ul>
<p>总之，合理&amp;慎重的使用它!</p>
<p>PS:<br>
写此文纯粹是好奇，但更推荐传统写法。</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>关于+=的谜题</title>
    <url>/2024/04/18/python_puzzles_about/</url>
    <content><![CDATA[<h1 id="guan-yu-de-mi-ti">关于+=的谜题</h1>
<p>代码示例如下：</p>
<pre><code class="language-python">&gt;&gt;&gt; t = (1,2, [30, 40])
&gt;&gt;&gt; t[2] += [40, 50]
</code></pre>
<p>到底会发生下面 4 种情况中的哪一种？</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>A. t 变成 (1, 2, [30, 40, 50, 60])。</p>
</li>
<li class="lvl-2">
<p>B. 因为 tuple 不支持对它的元素赋值，所以会抛出 TypeError 异常。</p>
</li>
<li class="lvl-2">
<p>C. 以上两个都不是。</p>
</li>
<li class="lvl-2">
<p>D. A 和 B 都是对的。</p>
</li>
</ul>
<p>先不要在控制台运行上面的代码，思考一下，答案会是哪个？</p>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<hr>
<p>答案是D，是不是有些出乎意料？</p>
<p>我们来看一下控制台运行效果：</p>
<pre><code class="language-shell">&gt;&gt;&gt; t = (1,2, [30, 40])
&gt;&gt;&gt; t[2]
[30, 40]
&gt;&gt;&gt; t[2] += [40, 50]
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: 'tuple' object does not support item assignment
&gt;&gt;&gt; t
(1, 2, [30, 40, 40, 50])
&gt;&gt;&gt; 
</code></pre>
<p>查看字节码信息：</p>
<pre><code class="language-python">&gt;&gt;&gt; t = (1,2, [30, 40])
&gt;&gt;&gt; import dis
&gt;&gt;&gt; dis.dis('t')
  0           0 RESUME                   0

  1           2 LOAD_NAME                0 (t)
              4 RETURN_VALUE
&gt;&gt;&gt; t[2] += [40, 50]
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: 'tuple' object does not support item assignment
&gt;&gt;&gt; dis.dis('t[2] += [40, 50]')
  0           0 RESUME                   0

  1           2 LOAD_NAME                0 (t)
              4 LOAD_CONST               0 (2)
              6 COPY                     2
              8 COPY                     2
             10 BINARY_SUBSCR
             20 LOAD_CONST               1 (40)
             22 LOAD_CONST               2 (50)
             24 BUILD_LIST               2
             26 BINARY_OP               13 (+=)
             30 SWAP                     3
             32 SWAP                     2
             34 STORE_SUBSCR
             38 LOAD_CONST               3 (None)
             40 RETURN_VALUE
&gt;&gt;&gt;
</code></pre>
<p><code>https://pythontutor.com/</code>展示上述代码效果：</p>
<img class="shadow" src="/img/in-post/谜题-1.png" width="600">
<img class="shadow" src="/img/in-post/谜题-2.png" width="600">
<p>至此得到的教训：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>不要把可变对象放在元组里面</p>
</li>
<li class="lvl-2">
<p>增量赋值不是一个原子操作，上述示例虽然抛出了异常，但还是完成了操作</p>
</li>
<li class="lvl-2">
<p>查看 Python 的字节码并不难，而且它对我们了解代码背后的运行机制很有帮助。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest+Appium+Allure实现APP GUI自动化测试框架设计</title>
    <url>/2024/04/20/pytest_appium_allure_app_gui/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>本文介绍pytest+Appium+Allure完成某APP的GUI自动化测试框架设计，此框架的设计基于PO设计模式。</p>
<p>通过结合pytest的灵活性和Appium的移动测试专长，我们可以创建一个强大的自动化测试解决方案，它不仅能够提高测试效率，还能确保应用在不同设备和操作系统上的一致性和稳定性。</p>
<p>此次间隔10年再次捡起Appium，借助pytest+appium实现了如下功能：</p>
<ol>
<li class="lvl-3">
<p>Windows和Linux平台的支持</p>
</li>
<li class="lvl-3">
<p>支持多设备上测试用例的执行，设备与设备之间用例执行、log记录和report等互相独立，互不干扰</p>
</li>
<li class="lvl-3">
<p>任意一设备异常，不影响用例在其他设备上的正常运行</p>
</li>
<li class="lvl-3">
<p>自动匹配设备数，自动生成不同设备的variables.json文件，借助pytest-variables插件实现配置文件独立性</p>
</li>
<li class="lvl-3">
<p>基于PO设计模式，加上Allure漂亮的测试报告和pytest强大的fixture特性，实现用例分层，降低框架维护难度，让使用者有更多的时间focus on业务逻辑设计</p>
</li>
<li class="lvl-3">
<p>异常用例自动截图并保存到指定目录下</p>
</li>
</ol>
<h1 id="appium-framework-jian-jie">Appium Framework简介</h1>
<p>Appium测试框架，参考下图：</p>
<img class="shadow" src="/img/in-post/Architecture-of-the-Appium-Framework.jpg" width="800">
<p>测试用例执行过程示意图：</p>
<img class="shadow" src="/img/appium/appium8.jpg" width="400">
<img class="shadow" src="/img/appium/appium7.png" width="700">
<img class="shadow" src="/img/appium/appium9.png" width="700">
<p>上图以安卓和默认端口示例说明：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>Client端发送操作指令给Appium Server</p>
</li>
<li class="lvl-2">
<p>Appium Server通过appium-uiautomator2-driver发送JWP协议的请求到Android的appium-uiautomator2-server</p>
</li>
<li class="lvl-2">
<p>appium-uiautomator2-server调用Android系统的 Google UIAutomator2 去以执行自动化具体的操作</p>
</li>
<li class="lvl-2">
<p>操作完成后返回结果对象AppiumResponse给appium-uiautomator2-driver，AppiumServer再返回给Client端，Client端得到最终执行操作的结果</p>
</li>
</ul>
<h1 id="huan-jing-da-jian">环境搭建</h1>
<p>需要安装&amp;配置的软件如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>安装JAVA，设置JAVA_HOME，JRK等相关环境变量</p>
</li>
<li class="lvl-2">
<p>安装Android SDK组件</p>
</li>
<li class="lvl-2">
<p>安装Node.js</p>
</li>
<li class="lvl-2">
<p>安装Appium&amp;pytest以及pytest相关插件</p>
</li>
<li class="lvl-2">
<p>安装Appium-Python-Client</p>
</li>
</ul>
<p>其他python相关安装信息，参考如下：</p>
<pre><code class="language-shell">root@Gavin:~/MobileAppTestFramework# cat requirements.txt 
allure-pytest==2.13.2
allure-python-commons==2.13.2
Appium-Python-Client==4.0.0
pytest==8.0.2
PyYAML==6.0.1
selenium==4.18.1
root@Gavin:~/MobileAppTestFramework# 
</code></pre>
<p>具体的安装&amp;配置细节，非本文重点，就不写了，但在安装ANDROID SDK时需要科学上网。</p>
<p>我的测试环境是Windows 11和 Ubuntu 23两套环境，使得一套代码能够分别在Windows和Linux下运行，做到windows和Linux的兼容。</p>
<h1 id="ce-shi-kuang-jia-she-ji-si-lu-gai-tu">测试框架设计思路概图</h1>
<p>上周有在docker下搭建excalidraw，此次使用excalidraw绘制一张此测试框架设计思路概图，参考如下：</p>
<img class="shadow" src="/img/in-post/Appium自动化设计思路.png" width="800">
<p>简单介绍一下运行运行过程：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>测试环境检查</p>
</li>
</ul>
<p>直接以代码片段示例，下同：</p>
<pre><code class="language-python">def check_platform_and_exit():
    """检查是否为Windows或者linux系统，如果不是，则退出执行。"""
    print("\n检查操作系统类型是否为Windows或者linux")
    if os_type not in ['windows', 'linux']:
        print(f"\n[ERROR]  不支持当前的系统:{os_type}\n")
        sys.exit(1)
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>adb检查</p>
</li>
</ul>
<pre><code class="language-python">    @staticmethod
    def android_home_exists():
        """检查ANDROID_HOME环境变量是否设置"""
        return "ANDROID_HOME" in os.environ

    @staticmethod
    def adb_command(os_type):
        """检查adb命令是否存在"""
        root_dir = os.path.join(os.environ["ANDROID_HOME"], "platform-tools")
        adb_name = "adb.exe" if os_type == 'windows' else "adb"

        for path, _, files in os.walk(root_dir):
            if adb_name in files:
                return os.path.join(path, adb_name)
        return None
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>连接的终端设备检查</p>
</li>
</ul>
<pre><code class="language-python">def check_device_list():
    device_lists = get_device_infos()
    if len(device_lists) &lt; 0:
        print("\n[ERRIR]  Not find any device, exit!!!\n")
        sys.exit(2)

    return device_lists
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>为每个device生成vairables_{device}.json文件</p>
</li>
</ul>
<pre><code class="language-python">    # 先删除所有的variables开头,json结尾的文件
    delete_files()

    # 再生成variable_{device}.json文件
    print(f"\n生成全新的variables*.json文件")
    for device_info in device_lists:
        device_name = device_info['device']
        variable_path = f"{paths['config']}/variables_{device_name}.json"
        print(f"  生成新文件: {variable_path}")
        generate_variables(device_info)

    # 查找所有的variables json文件
    variable_files_list = find_files()
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p>运行测试用例</p>
</li>
</ul>
<pre><code class="language-python">    with Pool(len(device_lists)) as pool:
        pool.map(run_testcases, variable_files_list)
        pool.close()
        pool.join()
</code></pre>
<p>多个设备是户型并行、独立运行的，互不干扰。</p>
<h1 id="ce-shi-kuang-jia-mu-lu-jie-gou">测试框架目录结构</h1>
<p>测试框架目录结构参考如下：</p>
<pre><code class="language-shell">root@Gavin:~/MobileAppTestFramework# tree
.
├── app
│   └── com.xkw.client_3.1.1.1.apk  # apk必须要存在，且必须以英文名命名
├── clear_pyc.py                    # 清理python cache目录和pyc文件
├── common            # 存放基础核心功能
│   ├── app_info.py   # 获取app的相关信息，诸如app_name,app_package_name,launchable_activity等
│   ├── appium_server.py  # 启停appium相关动作
│   ├── base_driver.py    # init driver
│   ├── base_page.py      # 基于W3C WebDriver协议，封装APP通用操作，诸如滑动、点击、文本输入、拖拽等
│   ├── __init__.py
│   ├── locators.py       # 分类存放APP各页面element信息
│   └── utils.py          # 通用函数的封装
├── config
│   ├── config.yml        # 一次配置，终生有效
│   ├── __init__.py
│   ├── variables_4f54ea68.json  # 根据当前机器连接的设备数自动生成，自动删除旧的（如果有）再生成新的
│   └── variables_62b6aca8.json  # 根据当前机器连接的设备数自动生成，自动删除旧的（如果有）再生成新的
├── conftest.py           # scope=package，记录当前正在执行的是哪个用例
├── __init__.py
├── pytest.ini            # 定义pytest默认携带的参数和日志格式
├── README.md
├── requirements.txt
├── run.py                # 执行所有测试用例的入口，方便未来CI/CD使用
├── testcase              # 分类存放APP所有功能的测试用例
│   ├── 01_login
│   │   ├── __init__.py
│   │   └── test_login.py
│   ├── 02_home_page
│   │   ├── __init__.py
│   │   └── test_switch_page.py
│   ├── 03_exam_papers
│   │   └── __init__.py
│   ├── conftest.py
│   └── __init__.py
└── testcasebase          # 存放测试用例基类，基于PO设计模式，未来APP功能有变，只需修改此处下相关文件，而不是调整testcase下用例 
    ├── __init__.py
    ├── login_page.py     # 登录相关测试用例
    └── switch_pages.py   # 页面切换、跳转相关测试用例

9 directories, 29 files
root@Gavin:~/MobileAppTestFramework#
</code></pre>
<p>整体设计思路是基于PO设计模式，借助<code>pytest</code>强大的<code>fixture</code>实现两层<code>conftest.py</code>，做到driver fixture一处定义全局使用，且日志清晰、用例分层、低可维护性和高兼容性。</p>
<h1 id="report-mu-lu">report目录</h1>
<p>目录结构如下：</p>
<pre><code class="language-shell">root@Gavin:~/MobileAppTestFramework/report# tree -L 3
.
├── allure
│&nbsp;&nbsp; ├── 4f54ea68
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── html
│&nbsp;&nbsp; │&nbsp;&nbsp; └── json
│&nbsp;&nbsp; └── 62b6aca8
│&nbsp;&nbsp;     ├── html
│&nbsp;&nbsp;     └── json
├── log
│&nbsp;&nbsp; ├── app_automation_4f54ea68_test.log
│&nbsp;&nbsp; ├── app_automation_62b6aca8_test.log
│&nbsp;&nbsp; ├── appium_4723.log
│&nbsp;&nbsp; └── appium_4724.log
└── screenshot
</code></pre>
<p>日志、报告和截图，都统一存放在report目录下，按子目录来存放。</p>
<h2 id="allure-report">allure report</h2>
<pre><code class="language-shell">├── allure
│&nbsp;&nbsp; ├── 4f54ea68
│&nbsp;&nbsp; └── 62b6aca8
</code></pre>
<p>这里表示allure下有两个设备产生的报告原始json文件，以及生成的html报告数据：</p>
<pre><code class="language-shell">│&nbsp;&nbsp; └── 62b6aca8
│&nbsp;&nbsp;     ├── html
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── app.js
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── data
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── export
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── favicon.ico
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── history
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── index.html
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── plugin
│&nbsp;&nbsp;     │&nbsp;&nbsp; ├── styles.css
│&nbsp;&nbsp;     │&nbsp;&nbsp; └── widgets
│&nbsp;&nbsp;     └── json
│&nbsp;&nbsp;         ├── 00dbf1fe-a6c4-4b2f-b52e-053461299c35-attachment.txt
│&nbsp;&nbsp;         ├── 012a3a65-236a-4b81-aaec-3d8d4146232c-container.json
│&nbsp;&nbsp;         ├── 04913ac1-b897-411e-8986-1df178f27212-attachment.txt
│&nbsp;&nbsp;         ├── 05744b50-6d14-449f-8136-964d217df1ef-container.json
│&nbsp;&nbsp;         ├── 059f4c43-b655-4c6b-a990-2022036a7e67-container.json
│&nbsp;&nbsp;         ├── 05c7ed97-b369-4e3f-8d83-f0ad51a9b4a8-result.json
</code></pre>
<h2 id="log">log</h2>
<pre><code class="language-shell">├── log
│&nbsp;&nbsp; ├── app_automation_4f54ea68_test.log
│&nbsp;&nbsp; ├── app_automation_62b6aca8_test.log
│&nbsp;&nbsp; ├── appium_4723.log
│&nbsp;&nbsp; └── appium_4724.log
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>app_automation_{deviceName}_test.log</code>文件记录对应<code>deviceName</code>上测试用例执行日志</p>
</li>
<li class="lvl-2">
<p><code>appium_{serverPort}.log</code>文件记录对应端口的Appium Server日志信息</p>
</li>
</ul>
<h2 id="screenshot">screenshot</h2>
<p>此目录存放截图文件，只有当用例执行失败的时候才会截图，正常情况下不截图。</p>
<h1 id="pei-zhi-wen-jian">配置文件</h1>
<h2 id="config-config-yml">config/config.yml</h2>
<pre><code class="language-python">root@Gavin:~/MobileAppTestFramework/config# cat config.yml 
platformName: Android
newCommonTimeout: 36000
skipServerInstallation: True
automationName: UiAutomator2
serverPort: 4723
systemPort: 8200
root@Gavin:~/MobileAppTestFramework/config# 
</code></pre>
<h2 id="variables-json">variables.json</h2>
<p>借助pytest的pytest-variables插件，传递不同设备对应的variables.json文件到Appium，从而实现多设备的用例执行。</p>
<p>如下json文件为自动生成，内容参考如下：</p>
<pre><code class="language-shell">root@Gavin:~/MobileAppTestFramework/config# cat variables_4f54ea68.json 
{
    "server": {
        "url": "http://127.0.0.1:4723"
    },
    "caps": {
        "platformName": "Android",
        "newCommonTimeout": 36000,
        "skipServerInstallation": true,
        "automationName": "UiAutomator2",
        "serverPort": 4723,
        "systemPort": 8200,
        "deviceName": "4f54ea68",
        "platformVersion": "10",
        "appPackage": "com.xkw.client",
        "appActivity": "com.zxxk.page.main.LauncherActivity",
        "udid": "4f54ea68"
    }
}root@Gavin:~/MobileAppTestFramework/config# cat variables_62b6aca8.json 
{
    "server": {
        "url": "http://127.0.0.1:4724"
    },
    "caps": {
        "platformName": "Android",
        "newCommonTimeout": 36000,
        "skipServerInstallation": true,
        "automationName": "UiAutomator2",
        "serverPort": 4724,
        "systemPort": 8201,
        "deviceName": "62b6aca8",
        "platformVersion": "10",
        "appPackage": "com.xkw.client",
        "appActivity": "com.zxxk.page.main.LauncherActivity",
        "udid": "62b6aca8"
    }
}root@Gavin:~/MobileAppTestFramework/config#
</code></pre>
<p><strong>说明：</strong></p>
<p>测试框架在设计之初就考虑了多设备、并发执行用例，实现了根据当前OS连接的手机终端设备数（USB或者WIFI连接），自动生成各个设备对应的variables.json文件，在run.py入口文件中并发传递各个variables.json文件，从而实现有多少台设备就能够启动多少个appium server和多少台设备上的测试用例执行，比如说computer连接有10台设备，有300条测试用例，则这10台设备是各自执行这300条测试用例，而且各个设备是<strong>并行执行</strong>的（不是设备1执行完300条用例，设备2再执行这300条用例哦），互不干扰。</p>
<h1 id="dai-ma-shi-li">代码示例</h1>
<h2 id="common-locators-py">common/locators.py</h2>
<p>此文件记录APP的元素信息，内容参考如下：</p>
<pre><code class="language-shell">root@Gavin:~/MobileAppTestFramework/common# cat locators.py 
# -*- coding:UTF-8 -*-
"""分类定义APP各个页面的元素、按钮等信息"""

from appium.webdriver.common.appiumby import AppiumBy

# 启动页同意
agree_btn = (AppiumBy.ID, "com.xkw.client:id/agree_yes")

# 登录页操作
mine_btn = (AppiumBy.ID, "com.xkw.client:id/mine_text")
login_btn = (AppiumBy.ID, "com.xkw.client:id/mine_username")
password_login_btn = (AppiumBy.ID, "com.xkw.client:id/login_mobile_use_password")
username_input = (AppiumBy.ID, "com.xkw.client:id/login_password_username")
password_input = (AppiumBy.ID, "com.xkw.client:id/login_password_password")
login_submit_btn = (AppiumBy.ID, "com.xkw.client:id/login_password_login")
discover_search_box = (AppiumBy.ID, "com.xkw.client:id/discover_search_box")

# 发现页面
discovery_btn = (AppiumBy.ID, "com.xkw.client:id/discover_text")
## 推荐页面
recommend_btn = (AppiumBy.ID, "com.xkw.client:id/recommend_text")
## 分类页面
category_btn = (AppiumBy.ID, "com.xkw.client:id/category_text")
course_synchronization_resources_btn = (AppiumBy.ID, "com.xkw.client:id/category_entrance_left")
knowledge_point_resources_btn = (AppiumBy.ID, "com.xkw.client:id/category_entrance_right")
## 我的页面，上面有定义过，mine_btn

## 通用元素
common_element = (AppiumBy.CLASS_NAME, "android.widget.TextView")
</code></pre>
<h2 id="common-utils-py">common/utils.py</h2>
<p>此文件封装通用的函数，内容参考如下：</p>
<pre><code class="language-python">root@Gavin:~/MobileAppTestFramework/common# cat utils.py 
#!/usr/bin/env python
# -*- encoding:UTF-8 -*-
"""通用函数的封装"""

import os
import glob
import platform

from pathlib import Path


def os_type():
    """获取操作系统类型，返回 'windows'、'linux' 之类的"""
    return platform.system().lower()


def exec_cmd(cmd):
    """执行命令行并返回内容"""
    result = os.popen(cmd).read()
    return result


# 定义和检查关键目录的路径
def define_paths():
    base_path = Path(__file__).resolve().parent.parent

    paths = {
        'app': base_path / 'app',
        'config': base_path / 'config',
        'log': base_path / 'report' / 'log',
        'report': base_path / 'report' / 'allure',
        'screenshot': base_path / 'report' / 'screenshot'
    }

    # 确保所有需要的目录都存在
    for path in paths.values():
        path.mkdir(parents=True, exist_ok=True)

    return paths


def find_files(pattern='config/variables*.json'):
    """Find all files matching the given pattern."""
    return glob.glob(pattern)


def delete_files(pattern='config/variables*.json'):
    """Delete all files matching the given pattern."""
    print("\n删除陈旧的variables*.json文件")
    files_to_delete = glob.glob(pattern)
    for file_path in files_to_delete:
        os.remove(file_path)
        print(f"  Deleted file: {file_path}")

# 可以直接在其他模块中调用 define_paths 获取路径信息
paths = define_paths()
os_type = os_type()
</code></pre>
<h2 id="common-appium-server-py">common/appium_server.py</h2>
<p>此文件封装appium的启停动作，内容参考如下：</p>
<pre><code class="language-python">root@Gavin:~/MobileAppTestFramework/common# cat appium_server.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-
"""Appium启动、关闭、检查相关操作的封装"""

import socket
import logging
import subprocess

from .utils import paths, os_type, exec_cmd


def open_appium(cmd, port):
    """命令启动appium server"""
    release_port(port)
    logging.info(f"open_appium, cmd: {cmd}")
    with subprocess.Popen(cmd, shell=True) as process:
        process.wait()  # 等待命令执行完成

def close_appium():
    """关闭appium服务器"""
    kill_cmd = {"windows": "taskkill /f /im node.exe", "linux": "pkill node"}
    exec_cmd(kill_cmd[os_type])


def is_port_available(host, port):
    """检测端口是否可用"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        if sock.connect_ex((host, port)) == 0:  # Port is open
            return False
    return True


def release_port(port):
    """释放给定的TCP端口"""
    check_cmd = {"windows": f"netstat -ano| findstr {port}", "linux": f"netstat -anp| grep :{port}"}
    result = exec_cmd(check_cmd[os_type])
    if str(port) in result:
        pid = result.strip().split(" ")[-1]
        kill_cmd = {"windows": f"taskkill -f -pid {pid}", "linux": f"kill -9 {pid}"}
        exec_cmd(kill_cmd[os_type])
        return True
    return True
</code></pre>
<h2 id="common-app-info-py">common/app_info.py</h2>
<p>此文件用户安装、卸载APP和APP信息的获取，以及生成variables.json文件，代码片段信息参考如下：</p>
<pre><code class="language-python">root@Gavin:~/MobileAppTestFramework/common# cat app_info.py
#!/usr/bin/env python
# -*- encoding:UTF-8 -*-
"""Get APP info"""

import os
import json
import yaml
import logging
import subprocess

from pathlib import Path

from .utils import paths, exec_cmd, os_type

app_path = paths['app']


def get_udid() -&gt; str:
    """获取iOS设备的udid信息"""
    cmd = "idevice_id -l"
    try:
        # 尝试运行命令并获取输出
        result = subprocess.check_output(cmd.split(), stderr=subprocess.STDOUT).decode("utf-8")
        udid = result.strip()
        if udid:  # 检查结果是否为空
            return udid
        else:
            raise ValueError("No UDID found. Please ensure the device is connected and trusted.")
    except subprocess.CalledProcessError as err:
        # CalledProcessError 将会捕获非零返回码的命令
        print(f"An error occurred while trying to get the UDID: {err.output.decode('utf-8')}")
    except FileNotFoundError as err:
        # FileNotFoundError 表明 idevice_id 命令不在系统路径中
        print("idevice_id command not found. Please install libimobiledevice.")
    except Exception as err:
        # 其他所有异常的通用处理
        print(f"An unexpected error occurred: {str(err)}")

    return None  # 如果有任何错误发生，返回 None


def get_app_name(app_path: Path) -&gt; str:
    """根据apk获取APP name"""
    # 搜索目录下所有的apk和ipa文件
    app_files = list(app_path.glob('*.apk')) + list(app_path.glob('*.ipa'))
    
    # 检查是否仅找到一个应用包文件
    if len(app_files) == 1:
        return app_files[0].name
    elif len(app_files) &gt; 1:
        raise FileNotFoundError(f"{app_path}目录下存在多个测试包，请确保只有一个")
    else:
        raise FileNotFoundError(f"{app_path}目录下没有找到测试包")


def get_app_package_name() -&gt; str:
    """通过aapt命令获取APP package name"""
    app_name = os.path.join(app_path, get_app_name(app_path))
    base_cmd = f"aapt dump badging {app_name}"
    aapt_cmd = {"windows": f"{base_cmd} | findstr package", "linux": f"{base_cmd} | grep package"}

    result = exec_cmd(aapt_cmd[os_type])
    if "package" in result:
        package_name = result.strip().split(" ")[1].split('=')[1].replace("'", "")
        return package_name
    raise NameError("未获取到package name")


def get_app_launchable_activity() -&gt; str:
    """获取APP的launchable activity"""
    app_name = os.path.join(app_path, get_app_name(app_path))
    base_cmd = f"aapt dump badging {app_name}"
    aapt_cmd = {"windows": f"{base_cmd} | findstr launchable", "linux": f"{base_cmd} | grep launchable"}
    result = exec_cmd(aapt_cmd[os_type])
    if "launchable" in result:
        launchable_activity = result.strip().replace("'", "").split()[1].split('=')[-1]
        return launchable_activity
    raise NameError("未获取到launchable activity")


def get_devices_version(device: str) -&gt; str:
    """获取device version信息"""
    if not isinstance(device, str):
        raise TypeError("device type is should string")
    result = exec_cmd(f"adb -s {device} shell getprop ro.build.version.release")
    result = result.strip()
    if "error" not in result:
        return result
    raise AssertionError("获取设备系统版本失败，无法进行正常测试")


def get_all_devices() -&gt; list:
    """获取到所有的可用device信息"""
    result = exec_cmd('adb devices')
    result = result.strip().split(" ")[3].replace("\n", '').replace("\t", ''). \
        replace("attached", '').split('device')


    result.remove('')
    if len(result) == 0:
        raise AssertionError("电脑未连接设备信息，无法进行正常测试")

    return result


def get_device_infos() -&gt; list:
    """构造所有device的platform_version, port, device信息"""
    device_infos = []
    devices = get_all_devices()

    # 从配置文件读取端口信息
    with open(f"{paths['config']}/config.yml", 'r', encoding='utf-8') as file_handle:
        config = yaml.load(file_handle, Loader=yaml.FullLoader)
    server_port = config['serverPort']
    system_port = config['systemPort']
    for index, device in enumerate(devices):
        device_dict = {
            "platform_version": get_devices_version(device),
            "server_port": server_port + index,
            "system_port": system_port + index,
            "device": device
        }
        device_infos.append(device_dict)

    if len(device_infos) &lt; 1:
        raise AssertionError("当前电脑未连接到设备")

    return device_infos


def install_apk(apk_path: str) -&gt; None:
    """安装 APK 文件."""
    try:
        subprocess.run(["adb", "install", apk_path], check=True)
        print("APK 安装成功")
    except subprocess.CalledProcessError:
        print("APK 安装失败")
        raise


def install_ipa(ipa_path: str) -&gt; None:
    """安装 IPA 文件."""
    try:
        subprocess.run(["ideviceinstaller", "-i", ipa_path], check=True)
        print("IPA 安装成功")
    except subprocess.CalledProcessError:
        print("IPA 安装失败")
        raise


def install_apk_ipa(apk_ipa_path: str) -&gt; None:
    """
    安装apk或者ipa文件
    安卓是apk文件，iOS是ipa文件
    """
    if not os.path.exists(apk_ipa_path):
        raise FileNotFoundError('文件路径不存在')
    
    _, ext = os.path.splitext(apk_ipa_path)
    if ext == '.apk':
        install_apk(apk_ipa_path)
    elif ext == '.ipa':
        install_ipa(apk_ipa_path)
    else:
        raise ValueError('不支持的文件类型')


def uninstall_app(device_list: list) -&gt; None:
    """卸载APP"""
    if not isinstance(device_list, list):
        raise TypeError("device_list is not a list!")

    for device_info in device_list:
        _device = device_info.get("device").split(':')[-1]
        _app_name = str(get_app_package_name()).replace("'", '')
        uninstall_cmd = f'adb -s 127.0.0.1:{_device} uninstall "{_app_name}"'
        logging.info("开始卸载设备上的应用，卸载命令：(%s)", uninstall_cmd)
        exec_cmd(uninstall_cmd)


def generate_variables(device_info: dict) -&gt; None:
    # 忽略不写
    # 读取配置文件
    # 增加device信息
    pass
</code></pre>
<h2 id="qi-ta-he-xin-dai-ma-wen-jian-jian-shu">其他核心代码文件简述</h2>
<p>当然，比较核心的是：</p>
<pre><code class="language-shell">-rw-r--r-- 1 root root 3779 Apr 20 14:20 base_driver.py
-rw-r--r-- 1 root root 9634 Apr 20 11:28 base_page.py
</code></pre>
<p><code>base_driver.py</code>文件，根据传入的variables.json，解析其内容，组装desired_caps内容，并初始化driver，确保windows和linux两个平台都能兼容到，且是后台执行appium命令，并增加了容错校验机制，诸如driver init是否成功，以及如何避免appium server还没有初始化好就发起HTTP请求等容错功能。</p>
<p><code>base_page.py</code>文件，封装了所有通用的动作，诸如元素点击、按钮点击、文本内容清除、文本内容输入、拖拽、滑动、缩放、模拟摇一摇等功能。</p>
<p>除此之外，还有顶层的<code>conftest.py</code>，<code>testcase</code>目录下的<code>conftest.py</code>，以及顶层目录下的<code>pytest.ini</code>，这三个文件也是重中之重。</p>
<p>这5个文件共同组成了整个测试框架的核心。</p>
<p><strong>说明：</strong></p>
<p>这几个文件就不贴具体的code了…</p>
<h2 id="ce-shi-yong-li-ji-lei-shi-li">测试用例基类示例</h2>
<p>如下文件，为模拟页面滑动操作，内容参考如下：</p>
<pre><code class="language-python">root@Gavin:~/MobileAppTestFramework/testcasebase# cat switch_pages.py 
# -*- coding:UTF-8 -*-
"""APP各个页面的切换操作的封装"""

import allure

from common import locators
from common.base_page import BasePage


class SwitchPage(BasePage):
    """ APP页面切换操作 """
    def enter_discovery(self):
        """进入发现页面"""
        with allure.step("点击切换到[发现]页面"):
            self.click_element(*locators.discovery_btn, doc='发现')
        with allure.step("检查[发现--首页] 页面元素信息"):
            elements = self.find_elements(*locators.common_element, doc="首页")
            self.check_element(elements, "试卷")
            self.check_element(elements, "杏坛荟")

        with allure.step("向左滑动，切换到[试卷]页面"):
            self.swipe_to_left(doc="试卷")
        with allure.step("检查[发现--试卷]页面元素信息"):
            elements = self.find_elements(*locators.common_element, doc="试卷")
            self.check_element(elements, "新卷上架")
            self.check_element(elements, "套卷")

        with allure.step("继续向左滑动，切换到[书城]页面"):
            self.swipe_to_left(doc="书城")
        with allure.step("检查[发现--书城]页面元素信息"):
            elements = self.find_elements(*locators.common_element, doc="书城")
            self.check_element(elements, "新书上架")
            self.check_element(elements, "加入我们")

        with allure.step("继续向左滑动，切换到[高考]页面"):
            self.swipe_to_left(doc="高考")
        with allure.step("检查[发现--高考]页面元素信息"):
            elements = self.find_elements(*locators.common_element, doc="高考")
            self.check_element(elements, "一轮复习")
            self.check_element(elements, "高考动态")

    def enter_recommend(self):
        with allure.step("点击切换到[推荐]页面"):
            self.click_element(*locators.recommend_btn, doc='推荐')
        with allure.step("检查[推荐]页面元素信息"):
            elements = self.find_elements(*locators.common_element, doc="今日")
            self.check_element(elements, "附近")

    def enter_category(self):
        with allure.step("点击切换到[分类]页面"):
            self.click_element(*locators.category_btn, doc='分类')
        with allure.step("连续多次向左滑动，切换到[中职]页面"):
            self.swipe_to_left(doc="小学")
            self.swipe_to_left(doc="初中")
            self.swipe_to_left(doc="高中")
            self.swipe_to_left(doc="中职")
        with allure.step("检查[中职]页面元素信息"):
            course_exist = self.is_element_exist(*locators.course_synchronization_resources_btn,doc="课程同步资源")
            assert course_exist == True, \
            f"[中职]页面没有找到{locators.course_synchronization_resources_btn}元素信息"

            kb_exist = self.is_element_exist(*locators.knowledge_point_resources_btn, doc="知识点资源")
            assert kb_exist == True, \
            f"[中职]页面没有找到{locators.knowledge_point_resources_btn}元素信息"
</code></pre>
<h2 id="ce-shi-yong-li-shi-li">测试用例示例</h2>
<p>测试用例按功能分目录存放，如下示例为调用基类中操作，实现GUI页面滑动和切换动作，内容参考如下：</p>
<pre><code class="language-python">root@Gavin:~/MobileAppTestFramework/testcase/02_home_page# cat test_switch_page.py 
# -*- coding:UTF-8 -*-
"""APP页面切换测试用例"""

import pytest
import allure

from testcasebase.switch_pages import SwitchPage


@pytest.fixture(scope="module", autouse=True)
def switch_page(appium_driver):
    return SwitchPage(appium_driver)

@allure.feature("页面切换")
class TestSwitchpage:
    """APP页面切换相关的测试用例"""
    @allure.story("首页页面切换")
    @allure.description("首页页面在首页的子页面之间滑动切换")  # 用例的描述
    @allure.severity(allure.severity_level.NORMAL)
    def test_home_page_switch(self, switch_page):
        switch_page.enter_discovery()

    @allure.story("推荐页面")
    @allure.description("推荐页面检查页面内容信息")  # 用例的描述
    @allure.severity(allure.severity_level.NORMAL)
    def test_switch_to_recommend(self, switch_page):
        switch_page.enter_recommend()

    @allure.story("分类页面")
    @allure.description("分类页面检查页面内容信息")  # 用例的描述
    @allure.severity(allure.severity_level.NORMAL)
    def test_switch_to_category(self, switch_page):
        switch_page.enter_category()
</code></pre>
<h1 id="yong-li-yun-xing-xiao-guo">用例运行效果</h1>
<h2 id="windows-xia">Windows下</h2>
<p>连接两台安卓设备：</p>
<pre><code class="language-shell">C:\Users\Wang&gt;adb devices
List of devices attached
4f54ea68        device
62b6aca8        device


C:\Users\Wang&gt;
</code></pre>
<p>运行效果（PyCharm）：</p>
<img class="shadow" src="/img/in-post/Windows_run_appium_testcase.png" width="800">
<h2 id="linux-xia">Linux下</h2>
<p>连接了两台手机，均为安卓：</p>
<pre><code class="language-shell">root@Gavin:~/MobileAppTestFramework# adb devices
List of devices attached
4f54ea68	device
62b6aca8	device

root@Gavin:~/MobileAppTestFramework# 
</code></pre>
<p>运行效果：</p>
<img class="shadow" src="/img/in-post/Linux_run_appium_testcase.png" width="800">
<h1 id="ri-zhi-pian-duan">日志片段</h1>
<p>在Linux下测试框架运行时产生的日志，参考如下：</p>
<pre><code class="language-shell">2024-04-20 14:22:29 [appium_server.py:15  ] [ INFO] open_appium, cmd: appium server -ka 36000 -a 127.0.0.1 -p 4723 --allow-cors --use-plugin relaxed-caps --use-drivers uiautomator2 --use-plugin execute-driver --log "/root/MobileAppTestFramework/report/log/appium_4723.log" --local-timezone &amp;
2024-04-20 14:22:31 [base_driver.py:74  ] [ INFO] desired_caps: {'platformName': 'Android', 'newCommonTimeout': 36000, 'skipServerInstallation': True, 'automationName': 'UiAutomator2', 'serverPort': 4723, 'systemPort': 8200, 'deviceName': '4f54ea68', 'platformVersion': '10', 'appPackage': 'com.xkw.client', 'appActivity': 'com.zxxk.page.main.LauncherActivity', 'udid': '4f54ea68'}
2024-04-20 14:22:37 [conftest.py:45  ] [ INFO] Creating common driver fixture
2024-04-20 14:22:37 [conftest.py:8   ] [ INFO] ------------------------------------- Start to run test case ---------------------------------

2024-04-20 14:22:37 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2024-04-20 14:22:37 [conftest.py:18  ] [ INFO] Current test case name : (test_swipe)
2024-04-20 14:22:37 [base_page.py:26  ] [ INFO] (同意并进入)页面，开始查找元素(('id', 'com.xkw.client:id/agree_yes'))
2024-04-20 14:22:40 [base_page.py:30  ] [ INFO] (同意并进入)页面，查找元素(('id', 'com.xkw.client:id/agree_yes'))成功！
2024-04-20 14:22:40 [base_page.py:66  ] [ INFO] (同意并进入)页面，点击元素(('id', 'com.xkw.client:id/agree_yes'))
2024-04-20 14:22:40 [base_page.py:68  ] [ INFO] (同意并进入)页面，点击元素(('id', 'com.xkw.client:id/agree_yes'))成功！
2024-04-20 14:22:40 [base_page.py:109 ] [ INFO] (发现)页面，开始查找元素(('id', 'com.xkw.client:id/discover_search_box'))
2024-04-20 14:22:46 [base_page.py:111 ] [ INFO] (发现)页面，查找元素(('id', 'com.xkw.client:id/discover_search_box'))成功！
2024-04-20 14:22:46 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2024-04-20 14:22:46 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2024-04-20 14:22:46 [conftest.py:18  ] [ INFO] Current test case name : (test_home_page_switch)
2024-04-20 14:22:46 [base_page.py:26  ] [ INFO] (发现)页面，开始查找元素(('id', 'com.xkw.client:id/discover_text'))
2024-04-20 14:22:47 [base_page.py:30  ] [ INFO] (发现)页面，查找元素(('id', 'com.xkw.client:id/discover_text'))成功！
2024-04-20 14:22:47 [base_page.py:66  ] [ INFO] (发现)页面，点击元素(('id', 'com.xkw.client:id/discover_text'))
2024-04-20 14:22:47 [base_page.py:68  ] [ INFO] (发现)页面，点击元素(('id', 'com.xkw.client:id/discover_text'))成功！
2024-04-20 14:22:47 [base_page.py:42  ] [ INFO] (首页)页面，开始查找一组元素(('class name', 'android.widget.TextView'))
2024-04-20 14:22:48 [base_page.py:46  ] [ INFO] (首页)页面，查找元素(('class name', 'android.widget.TextView'))成功！
2024-04-20 14:22:53 [base_page.py:136 ] [ INFO] 开始获取设备屏幕大小。
2024-04-20 14:22:53 [base_page.py:140 ] [ INFO] 获取设备屏幕大小完成。宽:(1080), 高(2280)
2024-04-20 14:22:53 [base_page.py:150 ] [ INFO] (试卷)页面，开始进行左滑
2024-04-20 14:22:54 [base_page.py:152 ] [ INFO] (试卷)页面，开始左滑完成。
2024-04-20 14:22:55 [base_page.py:42  ] [ INFO] (试卷)页面，开始查找一组元素(('class name', 'android.widget.TextView'))
2024-04-20 14:22:57 [base_page.py:46  ] [ INFO] (试卷)页面，查找元素(('class name', 'android.widget.TextView'))成功！
2024-04-20 14:23:03 [base_page.py:136 ] [ INFO] 开始获取设备屏幕大小。
2024-04-20 14:23:03 [base_page.py:140 ] [ INFO] 获取设备屏幕大小完成。宽:(1080), 高(2280)
2024-04-20 14:23:03 [base_page.py:150 ] [ INFO] (书城)页面，开始进行左滑
2024-04-20 14:23:04 [base_page.py:152 ] [ INFO] (书城)页面，开始左滑完成。
2024-04-20 14:23:04 [base_page.py:42  ] [ INFO] (书城)页面，开始查找一组元素(('class name', 'android.widget.TextView'))
2024-04-20 14:23:06 [base_page.py:46  ] [ INFO] (书城)页面，查找元素(('class name', 'android.widget.TextView'))成功！
2024-04-20 14:23:08 [base_page.py:136 ] [ INFO] 开始获取设备屏幕大小。
2024-04-20 14:23:08 [base_page.py:140 ] [ INFO] 获取设备屏幕大小完成。宽:(1080), 高(2280)
2024-04-20 14:23:08 [base_page.py:150 ] [ INFO] (高考)页面，开始进行左滑
2024-04-20 14:23:09 [base_page.py:152 ] [ INFO] (高考)页面，开始左滑完成。
2024-04-20 14:23:10 [base_page.py:42  ] [ INFO] (高考)页面，开始查找一组元素(('class name', 'android.widget.TextView'))
2024-04-20 14:23:12 [base_page.py:46  ] [ INFO] (高考)页面，查找元素(('class name', 'android.widget.TextView'))成功！
2024-04-20 14:23:14 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2024-04-20 14:23:14 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2024-04-20 14:23:14 [conftest.py:18  ] [ INFO] Current test case name : (test_switch_to_recommend)
2024-04-20 14:23:14 [base_page.py:26  ] [ INFO] (推荐)页面，开始查找元素(('id', 'com.xkw.client:id/recommend_text'))
2024-04-20 14:23:14 [base_page.py:30  ] [ INFO] (推荐)页面，查找元素(('id', 'com.xkw.client:id/recommend_text'))成功！
2024-04-20 14:23:14 [base_page.py:66  ] [ INFO] (推荐)页面，点击元素(('id', 'com.xkw.client:id/recommend_text'))
2024-04-20 14:23:14 [base_page.py:68  ] [ INFO] (推荐)页面，点击元素(('id', 'com.xkw.client:id/recommend_text'))成功！
2024-04-20 14:23:14 [base_page.py:42  ] [ INFO] (今日)页面，开始查找一组元素(('class name', 'android.widget.TextView'))
2024-04-20 14:23:15 [base_page.py:46  ] [ INFO] (今日)页面，查找元素(('class name', 'android.widget.TextView'))成功！
2024-04-20 14:23:17 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2024-04-20 14:23:17 [conftest.py:17  ] [ INFO] ----------------------------------- Begin ----------------------------------------
2024-04-20 14:23:17 [conftest.py:18  ] [ INFO] Current test case name : (test_switch_to_category)
2024-04-20 14:23:17 [base_page.py:26  ] [ INFO] (分类)页面，开始查找元素(('id', 'com.xkw.client:id/category_text'))
2024-04-20 14:23:17 [base_page.py:30  ] [ INFO] (分类)页面，查找元素(('id', 'com.xkw.client:id/category_text'))成功！
2024-04-20 14:23:17 [base_page.py:66  ] [ INFO] (分类)页面，点击元素(('id', 'com.xkw.client:id/category_text'))
2024-04-20 14:23:17 [base_page.py:68  ] [ INFO] (分类)页面，点击元素(('id', 'com.xkw.client:id/category_text'))成功！
2024-04-20 14:23:17 [base_page.py:136 ] [ INFO] 开始获取设备屏幕大小。
2024-04-20 14:23:17 [base_page.py:140 ] [ INFO] 获取设备屏幕大小完成。宽:(1080), 高(2280)
2024-04-20 14:23:17 [base_page.py:150 ] [ INFO] (小学)页面，开始进行左滑
2024-04-20 14:23:19 [base_page.py:152 ] [ INFO] (小学)页面，开始左滑完成。
2024-04-20 14:23:19 [base_page.py:136 ] [ INFO] 开始获取设备屏幕大小。
2024-04-20 14:23:19 [base_page.py:140 ] [ INFO] 获取设备屏幕大小完成。宽:(1080), 高(2280)
2024-04-20 14:23:19 [base_page.py:150 ] [ INFO] (初中)页面，开始进行左滑
2024-04-20 14:23:21 [base_page.py:152 ] [ INFO] (初中)页面，开始左滑完成。
2024-04-20 14:23:21 [base_page.py:136 ] [ INFO] 开始获取设备屏幕大小。
2024-04-20 14:23:21 [base_page.py:140 ] [ INFO] 获取设备屏幕大小完成。宽:(1080), 高(2280)
2024-04-20 14:23:21 [base_page.py:150 ] [ INFO] (高中)页面，开始进行左滑
2024-04-20 14:23:23 [base_page.py:152 ] [ INFO] (高中)页面，开始左滑完成。
2024-04-20 14:23:23 [base_page.py:136 ] [ INFO] 开始获取设备屏幕大小。
2024-04-20 14:23:23 [base_page.py:140 ] [ INFO] 获取设备屏幕大小完成。宽:(1080), 高(2280)
2024-04-20 14:23:23 [base_page.py:150 ] [ INFO] (中职)页面，开始进行左滑
2024-04-20 14:23:24 [base_page.py:152 ] [ INFO] (中职)页面，开始左滑完成。
2024-04-20 14:23:25 [base_page.py:109 ] [ INFO] (课程同步资源)页面，开始查找元素(('id', 'com.xkw.client:id/category_entrance_left'))
2024-04-20 14:23:25 [base_page.py:111 ] [ INFO] (课程同步资源)页面，查找元素(('id', 'com.xkw.client:id/category_entrance_left'))成功！
2024-04-20 14:23:25 [base_page.py:109 ] [ INFO] (知识点资源)页面，开始查找元素(('id', 'com.xkw.client:id/category_entrance_right'))
2024-04-20 14:23:25 [base_page.py:111 ] [ INFO] (知识点资源)页面，查找元素(('id', 'com.xkw.client:id/category_entrance_right'))成功！
2024-04-20 14:23:25 [conftest.py:20  ] [ INFO] ----------------------------------- End ------------------------------------------

2024-04-20 14:23:25 [conftest.py:10  ] [ INFO] ------------------------------------- End to run test case -----------------------------------
2024-04-20 14:23:25 [conftest.py:39  ] [ INFO] Quitting the Appium driver
</code></pre>
<h1 id="jie-yu">结语</h1>
<p>此框架未来改进点：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>微调一下，兼容iOS设备</p>
</li>
<li class="lvl-2">
<p>可与Jenkins结合，使用pipeline实现CI/CD</p>
</li>
</ul>
<p>这只是框架的雏形，尚需填充业务逻辑和测试用例，需要时间逐步丰富此框框。</p>
<h1 id="fu-lu">附录</h1>
<p>附带一下我做的其他项目的CI/CD效果图：</p>
<img class="shadow" src="/img/in-post/pipeline_Process_rendering.png" width="1200">
<img class="shadow" src="/img/in-post/jenkins_build_success.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
        <category>Appium</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>Appium</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>透过adb获取Andriod APP CRASH 时日志信息</title>
    <url>/2024/05/01/use_adb_monkey_get_crash_log/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>以前写个一个类似的脚本，此次在python3下作了调整，支持内嵌adb monkey命令，即自动执行adb monkey命令情况下，自动收集手机log信息。</p>
<h1 id="code">Code</h1>
<p>代码示例参考如下：</p>
<pre><code class="language-python">import os
import re
import sys
import time
import platform
import subprocess


class AppLog:
    '''运行Monkey，并获取Android设备日志'''
    subprocesses = []  # 初始化存储子进程的列表

    def run_adb_monkey(self, package_name, round_count, log_file_path):
        """在后台运行 adb monkey 测试"""
        monkey_command = [
            'adb', 'shell', 'monkey', '-p', package_name, '-v', 
            '--throttle', '500', str(round_count)
        ]

        with open(log_file_path, 'a') as log_file:
            complete_process = subprocess.run(
                monkey_command, 
                stdout=log_file, stderr=log_file, text=True, check=False
            )
        return complete_process

    @staticmethod
    def os_type():
        """获取操作系统类型"""
        return platform.system().lower()

    @staticmethod
    def get_log_file_path(log_name='test_logcat.txt'):
        """定义日志文件路径"""
        return os.path.abspath(os.path.join(os.path.dirname(__file__), log_name))

    @staticmethod
    def android_home_exists():
        """检查ANDROID_HOME环境变量是否设置"""
        return "ANDROID_HOME" in os.environ

    @staticmethod
    def adb_command(os_type):
        """检查adb命令是否存在"""
        root_dir = os.path.join(os.environ["ANDROID_HOME"], "platform-tools")
        adb_name = "adb.exe" if os_type == 'windows' else "adb"

        for path, _, files in os.walk(root_dir):
            if adb_name in files:
                return os.path.join(path, adb_name)
        return None

    @staticmethod
    def get_device_id():
        """获取设备ID"""
        os.system('adb kill-server &amp;&amp; sleep 3 &amp;&amp; adb start-server &amp;&amp; sleep 5')
        devices_output = os.popen("adb devices").read().strip()

        if not devices_output or 'error' in devices_output:
            sys.exit(f'[ERROR] Get devices error: {devices_output}')

        matches = re.findall(r'^(\S+)\tdevice$', devices_output, re.MULTILINE)
        if not matches:
            sys.exit('[ERROR] No devices found or device unauthorized.')

        return matches[0]

    @staticmethod
    def check_logcat_available():
        """检查logcat命令是否可用"""
        log_cat_output = os.popen("adb logcat -g").read()
        if "Unable to open log device" in log_cat_output:
            sys.exit(f'[ERROR] {log_cat_output}')

    def get_log_to_file(self, device_id, file_path):
        """后台调用 logcat 获取日志到文件"""
        clear_buffer_command = ['adb', '-s', device_id, 'logcat', '-c']
        get_log_command = ['adb', '-d', '-s', device_id, 'logcat', '-v', 'time', '-s', '*:W']

        subprocess.run(clear_buffer_command, capture_output=True)
        log_process = subprocess.Popen(
            get_log_command, 
            stdout=open(file_path, 'a'), 
            stderr=subprocess.STDOUT
        )
        return log_process

    def terminate_subprocess(self, process):
        """终止指定的子进程"""
        try:
            process.terminate()  # 尝试安全终止
            process.wait(timeout=5)  # 等待进程终止
        except subprocess.TimeoutExpired:
            process.kill()  # 进程没有响应.terminate()，强制终止

    @staticmethod
    def backup_log_file_if_needed(file_path):
        """备份超过大小的日志文件"""
        if os.path.exists(file_path) and os.path.getsize(file_path) &gt;= 20 * 1024 * 1024:
            timestamp = time.strftime('%Y_%m_%d_%H_%M_%S')
            dirname, basename = os.path.split(file_path)
            name, ext = os.path.splitext(basename)
            new_name = f'{name}_{timestamp}{ext}'
            new_path = os.path.join(dirname, new_name)
            os.rename(file_path, new_path)


if __name__ == '__main__':
    print('-' * 75)
    app_log = AppLog()

    if not app_log.android_home_exists():
        sys.exit("\nANDROID_HOME not set. Please set the Android SDK path in ANDROID_HOME environment variable.\n")
    
    os_type = app_log.os_type()
    adb_path = app_log.adb_command(os_type)
    if not adb_path:
        sys.exit(f'\nADB command not found for OS: {os_type}')

    log_file_path = app_log.get_log_file_path()
    device_id = app_log.get_device_id()
    app_log.check_logcat_available()
    app_log.get_log_to_file(device_id, log_file_path)
    app_log.backup_log_file_if_needed(log_file_path)

    # 运行 adb monkey 命令
    package_name_to_test = 'com.xkw.client'
    monkey_rounds = 1000  # 修改为你想要的轮次数量
    monkey_log_path = app_log.get_log_file_path('monkey_test_log.txt')  # 也可以自定义日志文件的路径   
    monkey_process = app_log.run_adb_monkey(package_name_to_test, monkey_rounds, monkey_log_path)

    if monkey_process.returncode == 0:  # 确保 Monkey 测试顺利完成
        # 获取系统日志
        device_id = app_log.get_device_id()
        log_file_path = app_log.get_log_file_path()
        log_process = app_log.get_log_to_file(device_id, log_file_path)

        # 这里可以实现其他逻辑，例如等待或者处理日志

        # 程序结束前终止logcat日志收集进程
        app_log.terminate_subprocess(log_process)

        # 如果需要，备份日志文件
        app_log.backup_log_file_if_needed(log_file_path)
</code></pre>
]]></content>
      <categories>
        <category>python</category>
        <category>adb</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>adb</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest+Selenium+Allure Web自动化测试框架设计</title>
    <url>/2024/05/06/web_automation/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>五一闲来无事，趁着假期几天，构建了一个Web自动化测试框架基础版，有个架子，也方便未来不时之需。</p>
<p>此次构建基于pytest+selenium4.0+allure，借助pytest的强大能力，基于PO设计模式完成Web测试框架基础搭建工作。</p>
<h1 id="kuang-jia-jie-gou">框架结构</h1>
<pre><code class="language-shell">root@Gavin:~/OrangeHRM_Web_Test_Framework# tree 
.
├── clear_pyc.py
├── config
│&nbsp;&nbsp; ├── config.ini
│&nbsp;&nbsp; ├── config.py
│&nbsp;&nbsp; └── __init__.py
├── conftest.py
├── __init__.py
├── pages
│&nbsp;&nbsp; ├── base_page.py
│&nbsp;&nbsp; ├── dashboard_page.py
│&nbsp;&nbsp; ├── employee_page.py
│&nbsp;&nbsp; ├── __init__.py
│&nbsp;&nbsp; └── login_page.py
├── pytest.ini
├── README.md
├── reports
├── requirements.txt
├── run_tests.py
├── tests
│&nbsp;&nbsp; ├── 01_login
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── __init__.py
│&nbsp;&nbsp; │&nbsp;&nbsp; └── test_login.py
│&nbsp;&nbsp; ├── 02_employee
│&nbsp;&nbsp; │&nbsp;&nbsp; ├── __init__.py
│&nbsp;&nbsp; │&nbsp;&nbsp; └── test_employee.py
│&nbsp;&nbsp; ├── conftest.py
│&nbsp;&nbsp; └── __init__.py
└── utils
    ├── common.py
    ├── __init__.py
    └── path_util.py

8 directories, 24 files
root@Gavin:~/OrangeHRM_Web_Test_Framework# 
</code></pre>
<h1 id="code-jie-shao">Code介绍</h1>
<p><strong>说明：</strong></p>
<p>部分代码未释出.</p>
<h2 id="utils-path-util-py">utils/path_util.py</h2>
<pre><code class="language-python">import os

__all__ = ["get_config_path"]


def get_config_path():
    """
    获取config文件的路径.
    先获得当前的文件的路径，由于config和common同一级，把common替换为config即可.
    """
    return os.path.dirname(os.path.dirname(os.path.realpath(__file__))) + os.sep + "config" + os.sep


def get_report_path():
    """获取测试报告的路径,reports的路径应该在当前目录下"""
    report_path = os.path.dirname(os.path.dirname(os.path.realpath(__file__))) + os.sep + "reports" + os.sep

    return report_path
</code></pre>
<h2 id="utils-common-py">utils/common.py</h2>
<p>这个文件目前要提供的功能是：提供时间戳，方便在封装页面操作时记录诸如元素从不可见到可见、从不可用到可用的时间间隔差。如果未来还有其他通用功能需要增加的，可根据项目实际需求进行添加。</p>
<pre><code class="language-python">#  -*- coding:UTF-8 -*-

import random
import logging
import datetime
from faker import Faker

fake = Faker()

def get_date_time(**kwargs):
    """返回格式化为年月日小时分秒的日期时间字符串"""
    date_time = (datetime.datetime.now() + datetime.timedelta(**kwargs)).strftime('%Y-%m-%d %H:%M:%S')
    logging.debug("Current date time is : (%s)", date_time)
    return date_time

def get_time_stamp(**kwargs):
    """返回当前的Unix时间戳"""
    return datetime.datetime.now().timestamp()

def remove_duplicates_and_empty(lst):
    """列表去重和删除空元素"""
    seen = set()
    result = []
    for item in lst:
        if item not in seen and item:
            seen.add(item)
            result.append(item)
    return result

def generate_full_name():
    """随机生成英文全名、firstname、lastname"""
    first_name = fake.first_name()
    last_name = fake.last_name()
    full_name =  first_name + ' ' + last_name
    return full_name, first_name, last_name

def generate_gender():
    """随机生成性别"""
    return fake.random_element(elements=('Male', 'Female', 'Non-binary'))

def generate_landline_phone():
    """  随机生成座机（固定电话）号码。"""
    area_codes = ['010', '021', '022', '023', '024', '025']
    area_code = random.choice(area_codes)
    number = ''.join(random.choices('0123456789', k=7))  # 随机生成7位数字
    return f"{area_code}-{number}"

def generate_mobile_phone():
    """随机生成11位移动电话号码"""
    # 常见的手机前缀，这里只列举了一部分，可根据需要添加更多
    prefixes = ['130', '131', '132', '133', '134', '135', '136', '137', '138', '139',
                '150', '151', '152', '153', '155', '156', '157', '158', '159',
                '176', '177', '178', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189']
    prefix = random.choice(prefixes)
    suffix = ''.join(random.choices('0123456789', k=8))  # 随机生成8位数字
    return f"{prefix}{suffix}"

def generate_nationality():
    """随机生成国籍"""
    return fake.country()

def generate_address():
    """随机生成家庭住址"""
    return fake.address()

def generate_marital_status():
    """随机生成婚姻状况"""
    return fake.random_element(elements=('Married', 'Single', 'Divorced', 'Widowed'))

def generate_birth_date():
    """随机生成出生年月"""
    return fake.date_of_birth(minimum_age=21, maximum_age=61).isoformat()

def generate_age(min_age=18, max_age=60):
    """生成随机年龄，默认范围18至60岁"""
    return random.randint(min_age, max_age)

def generate_postal_code():
    """随机生成邮编号码"""
    return fake.postcode()

def generate_relation():
    """随机生成人员关系"""
    return fake.random_element(elements=('Spouse', 'Parent', 'Sibling', 'Relative', 'Guardian'))

if __name__ == "__main__":
    print("Full Name (Full, First, Last):", generate_full_name())
    print("Gender:", generate_gender())
    print("Random telephone number:", generate_landline_phone())
    print("Phone Number:", generate_mobile_phone())
    print("Nationality:", generate_nationality())
    print("Address:", generate_address())
    print("Marital Status:", generate_marital_status())
    print("Birth Date:", generate_birth_date())
    print("Postal Code:", generate_postal_code())
    print("Relation:", generate_relation())
</code></pre>
<h2 id="config-config-ini">config/config.ini</h2>
<pre><code class="language-shell">config/config.ini
[orangehrm]
url = http://192.168.23.130/orangehrm-5.6/web/index.php/auth/login
username = admin
password = Huawei123!

[employee]
add_employee_url = http://192.168.23.130/orangehrm-5.6/web/index.php/pim/addEmployee
list_employee_url = http://192.168.23.130/orangehrm-5.6/web/index.php/pim/viewEmployeeList
</code></pre>
<h2 id="config-config-py">config/config.py</h2>
<pre><code class="language-python">from configobj import ConfigObj
from utils.path_util import get_config_path


class GetConfig(object):
    """从config.ini文件中获取配置信息"""
    config = ConfigObj(get_config_path() + "config.ini")

    # 获取登录相关配置信息
    login_url = config['orangehrm']['url']
    username = config['orangehrm']['username']
    password = config['orangehrm']['password']

    # 添加员工配置信息
    add_employee_url = config['employee']['add_employee_url']

    # 搜索添加的员工
    list_employee_url = config['employee']['list_employee_url']
</code></pre>
<h2 id="pages-base-page-py">pages/base_page.py</h2>
<p>Page Object设计模式是一种用于测试自动化的最佳实践，它将每个网页看作一个对象，网页上的元素和操作被封装成统一的接口。这样做的好处是提高了测试代码的可维护性和可读性，同时也方便了测试数据的管理和测试脚本的复用。</p>
<p>在Selenium中使用Page Object设计模式，通常遵循以下步骤：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>创建Page Object类：为每个页面创建一个类，类中的属性代表页面上的元素，方法代表在页面上可以执行的操作。</p>
</li>
<li class="lvl-2">
<p>定义元素定位器：在类中定义元素的定位器（如id、name、css selector等），通常使用By类或直接的定位器字符串。</p>
</li>
<li class="lvl-2">
<p>封装元素操作：为页面上的元素创建方法，封装对这些元素的操作（如点击、输入文本等）。</p>
</li>
<li class="lvl-2">
<p>封装页面操作：创建方法来封装一系列的用户操作，这些操作通常与页面的业务逻辑相关。</p>
</li>
<li class="lvl-2">
<p>实例化Page Object：在测试脚本中实例化页面对象，并使用封装好的方法进行测试。</p>
</li>
</ul>
<p>为了实现所有的测试用例都是在登录成功后执行，以及考虑到异常登录场景，同时还需确保整个用例执行过程无需切换多个浏览器，即在打开的同一个浏览器中完成异常登录、正常登录以及正常登录后的各种功能实现，需要对Selenium的WebDriver和登录OrangeHRM进行封装。同时，根据Page Object设计模式，还需对页面中各种操作，诸如输入框的输入、点击、元素是否可见、元素是否可用、失败截图、被操作元素的着色、查找单个元素、查找多个元素、刷新页面等等进行封装。</p>
<pre><code class="language-python"># -*- coding:UTF-8 -*-

import os
import time
import allure
import random
import logging

from selenium import webdriver
from selenium.common.exceptions import *
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support import expected_conditions as ec
from selenium.webdriver.support.select import Select
from selenium.webdriver.support.wait import WebDriverWait

from utils.common import get_time_stamp
from utils.path_util import get_report_path


class BasePage:
    # 图片文件夹路径
    timeout = 10
    img_path = get_report_path() + os.sep + "screenshots"
    driver = webdriver.Chrome()
    driver.maximize_window()
    driver.implicitly_wait(timeout)  # 设置隐式等待时间

    if not os.path.exists(img_path):
        os.mkdir(img_path, mode=0o777)

    def get_url(self, url):
        """
        访问指定URL
        :param url: 链接地址
        """
        self.driver.get(url=url)

    def get_current_url_path(self):
        """
        获取当前页面的URL
        :return: URL
        """
        current_url = self.driver.current_url
        return current_url

    def set_img_error(self):
        """用例执行失败截图,并且加入allure测试报告中"""
        # 获取图片存储的文件夹
        time_stamp_tag = get_time_stamp()
        img_path = self.img_path + f"/{time_stamp_tag}.png"
        try:
            self.driver.save_screenshot(filename=img_path)
            logging.error(f"截图成功,文件名称：{time_stamp_tag}.png")
            __file = open(img_path, "rb").read()
            allure.attach(__file, "用例执行失败截图", allure.attachment_type.PNG)
        except Exception as err:
            logging.error(f"执行失败截图未能正确添加进入测试报告:{err}")
            raise err

    def set_img_case(self):
        """用例执行完毕截图，并且将截图加入allure测试报告中"""
        with allure.step("关键步骤截图"):
            img_name = get_time_stamp()
            img_path = self.img_path + f"/{img_name}.png"
            try:
                # 截图前等待1秒防止图片没有正常加载
                time.sleep(1)
                self.driver.save_screenshot(filename=img_path)
                logging.debug(f"用例执行完成，截图成功，文件名称:{img_name}.png")
                # 读取图片信息
                __file = open(file=img_path, mode="rb").read()
                allure.attach(__file, "关键步骤截图", allure.attachment_type.PNG)
            except Exception as err:
                logging.error(f"测试结果截图，未能正确添加进入测试报告:{err}")
                raise err

    def element_dyeing(self, element):
        """将被操作的元素染色
        :rollback: 是否将元素回滚
        """
        try:
            self.driver.execute_script(
                "arguments[0].setAttribute('style', 'background: yellow; border: 2px solid red;');",
                element)
        except Exception as err:
            logging.info(f"无法染色染色失效：{err}")
            pass

    def __wait_element_visible(self, model, locator):
        """
        等待元素可见
        :param model: string, 元素所处的页面
        :param locator: tuple, 元素定位表达式
        """
        logging.debug(f"开始等待页面{model}的元素：{locator}可见")
        try:
            # 获取等待开始时间的时间戳
            start_time = get_time_stamp()
            WebDriverWait(self.driver, 10).until(ec.visibility_of_element_located(locator))
            # 计算元素等待的时间
            __wait_time =get_time_stamp() - start_time
            logging.debug(f"页面：{model}上的元素{locator}已可见，共计等待{__wait_time:0.2f}秒")
        except TimeoutException:
            logging.error(f"页面：{model},等待元素{locator}超时")
            self.set_img_error()
            raise TimeoutException(f"页面：{model},等待元素{locator}超时")
        except InvalidSelectorException as err:
            logging.error(f"页面:{model},元素不可见或定位表达式:{locator}异常\n {err}")
            raise InvalidSelectorException('元素定位异常')

    def __wait_element_clickable(self, model, locator):
        """
        等待元素点击
        :param model: string, 元素所处的页面
        :param locator: tuple, 元素定位表达式
        :return: 无返回值
        """
        logging.debug(f"等待页面{model}的元素：{locator}是否可点击")
        try:
            # 获取等待开始时间的时间戳
            start_time = get_time_stamp()
            WebDriverWait(self.driver, 10).until(ec.element_to_be_clickable(locator))
            # 计算元素等待的时间
            __wait_time =get_time_stamp() - start_time
            logging.debug(f"页面：{model}上的元素{locator}已可点击，共计等待{__wait_time:0.2f}秒")
        except TimeoutException as err:
            logging.error(f"页面：{model},等待元素{locator}超时")
            self.set_img_error()
            raise err
        except InvalidSelectorException as err:
            logging.error(f"页面:{model},元素不可点击或定位表达式:{locator}异常\n {err}")
            raise err

    def __wait_element_exit(self, model, locator):
        """
        等待元素存在
        :param model: string, 元素所处的页面
        :param locator: tuple, 元素定位表达式
        """
        logging.debug(f"-开始-等待页面{model}的元素：{locator}存在")
        try:
            # 获取等待开始时间的时间戳
            start_time =get_time_stamp()
            WebDriverWait(self.driver, 10).until(ec.presence_of_element_located(locator))
            # 计算元素等待的时间
            __wait_time =get_time_stamp() - start_time
            logging.debug(f"页面：{model}上的元素{locator}已存在，共计等待{__wait_time:0.2f}秒")
        except TimeoutException as err:
            logging.error(f"页面：{model},等待元素{locator}超时")
            self.set_img_error()
            raise err
        except InvalidSelectorException as err:
            logging.error(f"页面:{model},元素不存在或定位表达式:{locator}异常\n {err}")
            raise err


    ####  由于代码内容较多，中间部分省略，请查看源码获取完整文件  ####

    def refresh_page(self):
        """
        刷新当前页面
        :return: None
        """
        logging.info(f"刷新页面: {self.get_current_url_path()}")
        self.driver.refresh()
</code></pre>
<h2 id="pytest-ini">pytest.ini</h2>
<p>pytest.ini是pytest的重要配置文件，名称和路径固定。此项目中我们希望借助pytest.ini文件完成日志的记录、日志级别的设定、默认参数和插件的使用。</p>
<pre><code class="language-shell">[pytest]
log_cli = 1
log_cli_level = INFO
log_cli_format = %(lineno)-4d [%(levelname)-5s] %(asctime)s %(filename)s - %(message)s
log_file = reports/test.log
log_file_level = INFO
log_file_format = %(lineno)-4d [%(levelname)-5s] %(asctime)s %(filename)s - %(message)s
addopts = -vrsxX -p no:warnings --full-trace --alluredir=reports/json
norecursedirs = .git
console_output_style = count
</code></pre>
<h2 id="tests-conftest-py">tests/conftest.py</h2>
<pre><code class="language-python">import pytest

from pages.login_page import LoginPage
from config.config import GetConfig as config

@pytest.fixture(scope="session", autouse=True)
def login():
    login_page = LoginPage()
    login_page.login(config.username, config.password)
    yield login_page.driver
    login_page.driver.quit()
</code></pre>
<h2 id="deng-lu-ji-lei-shi-li">登录基类示例</h2>
<pre><code class="language-python"># content of pages/login_page.py
# -*- coding:UTF-8 -*-
import logging

from pages.base_page import BasePage
from config.config import GetConfig as config

from selenium.webdriver.common.by import By

class LoginPage(BasePage):
    URL = config.login_url
    USERNAME_INPUT = (By.NAME, "username")
    PASSWORD_INPUT = (By.NAME, "password")
    LOGIN_BUTTON = (By.CLASS_NAME, "orangehrm-login-action")
    INVALID_FAILED = (By.CLASS_NAME, "oxd-alert-content-text")
    LOGIN_SUCCESS = (By.CLASS_NAME, "oxd-main-menu-item--name")
    MUST_INPUT = (By.CLASS_NAME, "oxd-input-group__message")
    LOGOUT_DROPDOWN = (By.CLASS_NAME, "oxd-userdropdown-icon")
    LOGOUT = (By.CLASS_NAME, "oxd-userdropdown-link")

    def login(self, username=None, password=None, login_success=True):
        self.get_url(self.URL)
        self.input_text(self.USERNAME_INPUT, username)
        self.input_text(self.PASSWORD_INPUT, password)
        self.click_element(self.LOGIN_BUTTON)
        # Get element text info
        if login_success:
            logging.info("登录成功后页面元素校验")
            assert '管理员' in self.get_element_text(self.LOGIN_SUCCESS),\
                "[ERROR]  成功登录后，页面没有发现'管理员'字样"
        else:
            if len(username) and len(password):
                logging.info("因输入错误的用户名或密码导致登录失败后的页面元素校验")
                cre_flag = 'Invalid credentials' in self.get_element_text(self.INVALID_FAILED)
                assert cre_flag, \
                    "[ERROR] 输入错误的用户名或密码后，页面缺失'Invalid credentials'字样"
            else:
                logging.info("因输入空的用户名或密码导致登录失败后的页面元素校验")
                need_flag = '需要' in self.get_element_text(self.MUST_INPUT)
                assert need_flag, "[ERROR]  输入空的用户名或密码后，页面缺失'需要'字样"

    def logout(self):
        """
        登出页面，因为conftest.py中定义了一个登录fixture，所以测试登录相关用例的时候，要先登出，此时不quit
        """
        # 点击头像右侧箭头，弹出下拉列表
        self.click_element(self.LOGOUT_DROPDOWN)
        # Get all of elements
        elements = self.find_elements(self.LOGOUT)
        if elements:
            # 有4个元素，分别是关于、Support、更改密码和登出，登出是最后一个
            last_element = elements[-1]
            # self.click_element(last_element)
            last_element.click()
</code></pre>
<h2 id="pages-employee-page-py">pages/employee_page.py</h2>
<p>同理，对于新增雇员及其添加后雇员信息的检查，业务逻辑和业务场景分隔开，即如下两个py文件：</p>
<pre><code class="language-shell">├── pages
│   ├── employee_page.py
├── tests
│   ├── test_employee.py
</code></pre>
<pre><code class="language-python"># -*- coding:UTF-8 -*-
import time
import allure
import logging

from pages.base_page import BasePage
from config.config import GetConfig as config
from utils.common import generate_full_name, remove_duplicates_and_empty

from selenium.webdriver.common.by import By

class EmployeePage(BasePage):
    ADD_EMPLOYEE_URL = config.add_employee_url
    LIST_EMPLOYEE_URL = config.list_employee_url
    FIRST_NAME = (By.NAME, "firstName")
    MIDDLE_NAME = (By.NAME, "middleName")
    LAST_NAME = (By.NAME, "lastName")
    SAVE_BUTTON = (By.CLASS_NAME, "orangehrm-left-space")
    SEARCH_EMPLOYEE = (By.CSS_SELECTOR, 'input[data-v-75e744cd]')
    SEARCH_BUTTOM = (By.CLASS_NAME, "orangehrm-left-space")
    SEARCH_RESULT = (By.CLASS_NAME, "oxd-padding-cell")
    full_name, first_name, last_name = generate_full_name()

    def add_employee(self, firstname=None, moddlename=None, lastname=None):
        firstname = self.first_name if firstname is None else firstname
        lastname = self.last_name if lastname is None else lastname
        logging.info(f"开始添加员工：firsname：（{firstname}）， lastname：（{lastname}）, " \
                      "full_name : ({self.full_name})")
        with allure.step("切换到‘添加员工’页面，并添加员工"):
            self.get_url(self.ADD_EMPLOYEE_URL)
            self.input_text(self.FIRST_NAME, firstname)
            # self.input_text(self.MIDDLE_NAME, moddlename)
            self.input_text(self.LAST_NAME, lastname)
            self.click_element(self.SAVE_BUTTON)
            time.sleep(1)
            logging.info(f"[Success]  完成员工{firstname} {lastname}的添加")

    def navigate_to_employees_list(self):
        with allure.step("跳转页面，跳转到员工列表页面"):
            self.driver.get(self.LIST_EMPLOYEE_URL)
            time.sleep(1)

    def search_new_employee(self, full_name):
        with allure.step("搜索新增加的员工信息"):
            self.input_text(self.SEARCH_EMPLOYEE, full_name)
            self.click_element(self.SEARCH_BUTTOM)
            time.sleep(1) # 等待搜索结果加载

    def verify_search_result(self, first_name, last_name):
        with allure.step("检查搜索结果是否正确"):
            elements = self.find_elements(self.SEARCH_RESULT)
            assert len(elements) &gt; 0, "[ERROR]  没有查询到任何员工信息"
            # 查询到的elements中element.txt内容去重和删除空元素
            search_result = []
            for each_element in elements:
                search_result.append(each_element.text)
            end_result = remove_duplicates_and_empty(search_result)
            search_last_name = end_result[-1]
            search_first_name = end_result[-2]
            assert search_last_name == last_name, f"[ERROR]  没有过滤到{last_name}"
            assert search_first_name == first_name, f"[ERROR]  没有过滤到{first_name}"
            logging.info("[Success]  成功完成账号添加后的检查")
</code></pre>
<h2 id="deng-lu-yong-li-tests-test-login-py">登录用例tests/test_login.py</h2>
<p>test_login.py文件中登录逻辑是对pages/login_page.py中函数的调用，组织成产品登录场景相关测试用例.</p>
<pre><code class="language-python">import pytest

from pages.login_page import LoginPage
from config.config import GetConfig as config


class TestLoginPage(LoginPage):
    # 因为conftest.py 定义的fixture已经被调用，成功登录了，所以先测试“登出”功能
    def test_logout(self):
        self.logout()

    @pytest.mark.parametrize("login_data", [
        # 正确的用户名和错误的密码
        (config.username, "wrong_password"),
        # 错误的用户名和正确的密码
        ("wrong_username", config.password),
        # 错误的用户名和错误的密码
        ("wrong_username", "wrong_password"),
        # 省略用户名
        ("", config.password),
        # 省略密码
        (config.username, ""),
    ])
    def test_failed_login(self, login_data):
        """Login OrangeHRM Web Failure with different credentials"""
        username, password = login_data
        self.login(username, password, login_success=False)

    @pytest.mark.login
    def test_successful_login(self):
        """Login OrangeHRM Web Success"""
        self.login(username=config.username, password=config.password)
</code></pre>
<h2 id="tests-test-employee-py">tests/test_employee.py</h2>
<pre><code class="language-python">from utils.common import generate_full_name
from pages.employee_page import EmployeePage


class TestAddEmployee(EmployeePage):
    full_name, first_name, last_name = generate_full_name()
    def test_add_an_employee(self):
        """Add an employee"""
        self.add_employee(firstname=self.first_name, lastname=self.last_name)
        self.navigate_to_employees_list()
        self.search_new_employee(self.full_name)
        self.verify_search_result(self.first_name, self.last_name)
</code></pre>
<h1 id="ce-shi-yong-li-zhi-xing">测试用例执行</h1>
<h2 id="zhi-xing-ru-kou-run-tests-py">执行入口run_tests.py</h2>
<pre><code class="language-python">import pytest

if __name__ == '__main__':
    pytest.main()
</code></pre>
<p>此入口文件内容简易，可根据实际情况增加内容，与Jenkins完成CI/CD构建工作，诸如增加被测产品是否可达检测、测试环境是否具备测试执行条件（相关安装包，如果没安装自动安装等）、是否有相关权限创建报告目录等信息，具体问题具体分析。</p>
<h2 id="zhi-xing-guo-cheng-yu-xiao-guo">执行过程与效果</h2>
<p>运行成功后，在项目的reports目录下产生json目录和test.log文件，借助allure完成可视化测试报告的输出，如下图所示：</p>
<img class="shadow" src="/img/in-post/allure/web_automation_report.png" width="1200">
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
        <category>Selenium</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title>《pytest测试指南》-- 章节1-3 pytest参数详解PART2</title>
    <url>/2024/05/12/pytest_test_guide_part1_chapter1_3_2_pytest_params/</url>
    <content><![CDATA[<h2 id="3-2-3-reporting-xiang-guan-can-shu">3.2.3 Reporting 相关参数</h2>
<h3 id="3-2-3-1-can-shu-code-durations-n-code">3.2.3.1 参数  <code>--durations=N</code></h3>
<p><code>pytest</code> 的 <code>--durations=N</code> 选项用来显示测试集中耗时最长的 <code>N</code> 个测试步骤。这可以帮助你识别测试中的性能瓶颈并优化那些耗时较多的测试。这个选项对于提高大型测试套件的效率尤其有用。</p>
<p><strong>使用方法：</strong></p>
<p>显示耗时最长的 <code>N</code> 个测试步骤的执行时间：</p>
<pre><code class="language-shell">pytest --durations=N
</code></pre>
<p>其中 <code>N</code> 是一个整数，代表你想显示的慢速测试的数量。</p>
<p><strong>详细说明：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>当你执行 <code>pytest --durations=N</code> 时，测试完成后，<code>pytest</code> 会列出耗时最长的 <code>N</code> 个测试步骤，包括测试函数、测试设置（如 fixture）和测试清理的耗时。</p>
</li>
<li class="lvl-2">
<p>列表将按照耗时排序，最耗时的测试排在最前面。</p>
</li>
<li class="lvl-2">
<p>此功能有助于调试和性能分析，因为它提供了哪些测试或测试步骤导致整体测试时间增长的直接视图。</p>
</li>
<li class="lvl-2">
<p><code>--durations</code> 后面的值 <code>N</code> 必须是一个非负整数。如果设置为 <code>0</code>，将报告所有测试步骤的持续时间；如果设置为正数，比如 <code>--durations=10</code>，将报告耗时最长的前 10 个测试步骤。</p>
</li>
<li class="lvl-2">
<p>报告中显示的时间通常以秒为单位，并且显示测试设置（如 fixture）、测试模块与函数等信息。</p>
</li>
<li class="lvl-2">
<p>这个选项特别有利于在持续集成（CI）流程中识别哪些测试可能需要优化以减少整个测试周期所需的时间。</p>
</li>
</ul>
<p>使用 <code>--durations</code> 选项是提高测试套件效率和性能的一种实用方式。通过识别最耗时的测试，你可以决定是否有可能通过优化代码、减少冗余操作、采用并行测试等措施来减少这些测试的执行时间。</p>
<h3 id="3-2-3-2-can-shu-code-durations-min-n-code">3.2.3.2 参数  <code>--durations-min=N</code></h3>
<p><code>pytest</code> 的 <code>--durations-min=N</code> 选项用来显示测试集中耗时超过<code>N</code>秒的用例、前后置函数（setup、teardown、fixture），识别测试中哪些函数比较耗时。此参数需要结合<code>--durations</code>配合使用，单独使用无法展示出效果，借助此两个选项，优化用例执行时间，提升测试用例/测试套件效率非常有用。</p>
<p><strong>使用方法：</strong></p>
<p>显示耗时超过 <code>N</code> 秒的测试用例、前后置条件：</p>
<pre><code class="language-shell">pytest --durations=0 --durations-min=N
</code></pre>
<p>其中 <code>N</code> 可以是整数，也可以是浮点数，单位是秒，代表你想显示的用例、前后置条件超过给定秒数的用例。此参数与<code>--durations</code>相似，此处不多额外说明。</p>
<p><strong>示例：</strong></p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# ll
total 16
drwxr-xr-x 2 root root 4096 Dec 11 17:01 ./
drwxr-xr-x 7 root root 4096 Dec 11 16:05 ../
-rw-r--r-- 1 root root  476 Dec 11 15:32 test_setup_teardown.py
-rw-r--r-- 1 root root  555 Dec 11 16:13 test_show_fixtures.py
root@Gavin:~/code/chapter1-3# cat test_setup_teardown.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

"""
This is an example of setup and teardown 
"""

import time
import pytest


def setup(autouse=True):
    print("This is a setup")
    time.sleep(2)


def teardown(autouse=True):
    print("This is a teardown")
    time.sleep(5)


def test_case_1():
    """  Test case 1  """
    print("case 1")

def test_case_2():
    """  Test case 2  """
    print("case 2")

def test_case_3():
    """  Test case 3  """
    print("case 3")
root@Gavin:~/code/chapter1-3# cat test_show_fixtures.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

"""
This is an example pytest fixture
"""

import time
import pytest


@pytest.fixture()
def run_function():
    """  This is a function doc info  """
    print("Run before function...")
    yield
    print("Run after function...")


def test_case_1(run_function):
    """  Test case 1  """
    print("case 1")
    time.sleep(3)

def test_case_2():
    """  Test case 2  """
    print("case 2")
    time.sleep(2)

def test_case_3(run_function):
    """  Test case 3  """
    print("case 3")
    time.sleep(4)
root@Gavin:~/code/chapter1-3#
</code></pre>
<p>执行效果：</p>
<p>只携带上<code>--durations</code>参数：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# pytest --durations=3 test_show_fixtures.py test_setup_teardown.py 
============================== test session starts ==========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code/chapter1-3
collected 6 items
test_show_fixtures.py ...                                               [ 50%]
test_setup_teardown.py ...                                              [100%]

============================== slowest 3 durations ===========================
5.01s teardown test_setup_teardown.py::test_case_3
4.00s call     test_show_fixtures.py::test_case_3
3.01s call     test_show_fixtures.py::test_case_1
============================== 6 passed in 16.07s ============================
root@Gavin:~/code/chapter1-3# 
</code></pre>
<p>携带上<code>--durations</code>  和 <code>--durations-min</code>参数：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# pytest --durations=0 --durations-min=3 test_show_fixtures.py test_setup_teardown.py 
============================== test session starts ===========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code/chapter1-3
collected 6 items
test_show_fixtures.py ...                                               [ 50%]
test_setup_teardown.py ...                                              [100%]

=============================== slowest durations ============================
5.00s teardown test_setup_teardown.py::test_case_3
4.01s call     test_show_fixtures.py::test_case_3
3.01s call     test_show_fixtures.py::test_case_1

(15 durations &lt; 3s hidden.  Use -vv to show these durations.)
=============================== 6 passed in 16.05s ===========================
root@Gavin:~/code/chapter1-3# 
</code></pre>
<p>携带上<code>--durations-min</code>参数：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# pytest --durations-min=3 test_show_fixtures.py test_setup_teardown.py 
=============================== test session starts ==========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code/chapter1-3
collected 6 items 
test_show_fixtures.py ...                                               [ 50%]
test_setup_teardown.py ...                                              [100%]

================================ 6 passed in 16.05s ==========================
root@Gavin:~/code/chapter1-3# 
</code></pre>
<p>三种情况综合对比图：</p>
<img class="shadow" src="/img/in-post/chatp1-3_durations相关参数.png" width="800">
<h3 id="3-2-3-3-can-shu-v-verbose">3.2.3.3 参数 -v --verbose</h3>
<p><code>pytest</code> 的 <code>-v</code> 或 <code>--verbose</code> 选项用于让测试运行时输出更详细的信息。通常，<code>pytest</code> 在执行测试时默认会输出一个比较简洁的结果，例如哪些测试通过了，哪些失败了。使用 <code>-v</code> 或 <code>--verbose</code> 选项可以让 <code>pytest</code> 提供更多的细节，比如每个测试函数的名称以及它们的结果。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest -v
</code></pre>
<p>或者</p>
<pre><code class="language-shell">pytest --verbose
</code></pre>
<p><strong>输出对比：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>没有 <code>-v</code></strong>: 默认情况下，当运行 <code>pytest</code> 时，你会看到每个测试文件中通过和失败的测试数量，通常标记为<code>.</code> (通过) 和 <code>F</code> (失败)。</p>
</li>
<li class="lvl-2">
<p><strong>使用 <code>-v</code></strong>: 运行 <code>pytest -v</code> 时，在每个测试之前，你将看到它的完整路径和名称，以及它是通过 (<code>PASSED</code>) 还是失败 (<code>FAILED</code>)。</p>
</li>
</ul>
<p>示例：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# cat test_time1.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-


def test_day_of_week():
    from datetime import datetime
    """  Determine what day of the week it is  """
    today = datetime.now().weekday()
    """  0: 周一; 1: 周二; 2:周三; ......,6:周日  """
    assert today == 1


def test_days_in_year():
    """ Determine if the current year is 365 days long  """
    import datetime
    current_year = datetime.date.today().year
    start_date = datetime.date(current_year, 1, 1)
    end_date = datetime.date(current_year, 12, 31)
    days_count = (end_date - start_date).days + 1
    assert days_count == 365
root@Gavin:~/code/chapter1-3# cat test_time2.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-

import time

def test_AM_or_PM():
    """  Determine current time is AM or PM  """
    AM = PM = False
    current_time = time.localtime()
    if current_time.tm_hour &lt; 12:
        AM = True
    else:
        PM = True

    assert AM is True
    assert PM is False


def test_day_or_night():
    """ Determine whether the current time is day or night  """
    # 0 - 5, 19 - 23 -&gt; night, 6 - 18 -&gt; day
    night_time = day_time = False
    current_time = time.localtime()

    if current_time.tm_hour &lt; 6 or current_time.tm_hour &gt; 18:
        night_time = True
    else:
        day_time = True

    # assert night_time
    assert day_time
root@Gavin:~/code/chapter1-3#
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>没有 <code>-v</code></strong>:</p>
</li>
</ul>
<pre><code class="language-python">root@Gavin:~/code# pytest chapter1-3/test_time1.py chapter1-3/test_time2.py 
============================= test session starts ===========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 4 items                                                                         
chapter1-3/test_time1.py ..                                             [ 50%]
chapter1-3/test_time2.py F.                                             [100%]
============================== FAILURES  =====================================
______________________________ test_AM_or_PM _________________________________

    def test_AM_or_PM():
        """  Determine current time is AM or PM  """
        AM = PM = False
        current_time = time.localtime()
        if current_time.tm_hour &lt; 12:
            AM = True
        else:
            PM = True
    
&gt;       assert AM is True
E       assert False is True

chapter1-3/test_time2.py:15: AssertionError
============================== short test summary info =======================
FAILED chapter1-3/test_time2.py::test_AM_or_PM - assert False is True
============================== 1 failed, 3 passed in 0.03s ===================
root@Gavin:~/code#
</code></pre>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>使用 <code>-v</code></strong>:</p>
</li>
</ul>
<pre><code class="language-python">root@Gavin:~/code# pytest -v chapter1-3/test_time1.py chapter1-3/test_time2.py 
=============================== test session starts ===========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /root/code
collected 4 items                                                       [ 25%]
chapter1-3/test_time1.py::test_days_in_year PASSED                      [ 50%]
chapter1-3/test_time2.py::test_AM_or_PM FAILED                          [ 75%]
chapter1-3/test_time2.py::test_day_or_night PASSED                      [100%]

================================  FAILURES ====================================
________________________________ test_AM_or_PM ________________________________

    def test_AM_or_PM():
        """  Determine current time is AM or PM  """
        AM = PM = False
        current_time = time.localtime()
        if current_time.tm_hour &lt; 12:
            AM = True
        else:
            PM = True
    
&gt;       assert AM is True
E       assert False is True

chapter1-3/test_time2.py:15: AssertionError
===============================  short test summary info =======================
FAILED chapter1-3/test_time2.py::test_AM_or_PM - assert False is True
===============================  1 failed, 3 passed in 0.03s ===================
root@Gavin:~/code#
</code></pre>
<p>在上面的例子中，<code>test_time2.py</code> 中的 <code>test_AM_or_PM</code> 测试失败了，而其他测试都通过了。使用 <code>-v</code> 选项可以让你更清晰地看到每个测试的结果，并有助于在出现问题时进行调试。</p>
<p>该选项对于调试、跟踪运行的特定测试，以及在构建系统和持续集成工具中查看详细的测试执行记录尤其有用。如果你在测试套件中有大量的测试，而其中一些失败了，使用 <code>-v</code> 选项可以帮助你快速定位失败的测试，因此这个选项在测试开发过程中是一个非常有价值的工具。</p>
<h3 id="3-2-3-4-can-shu-no-header">3.2.3.4 参数 --no-header</h3>
<p><code>pytest</code> 的 <code>--no-header</code> 选项是用来在测试运行输出中去掉头部信息的。通常，<code>pytest</code> 在开始运行测试时会打印一些环境和配置的相关信息，这些信息构成了"头部"。使用 <code>--no-header</code> 选项，你可以告知 <code>pytest</code> 省略这些信息，只输出测试结果。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest --no-header
</code></pre>
<p>默认的 <code>pytest</code> 头部信息：</p>
<p>当你运行 <code>pytest</code> 时，它会输出一些诊断信息，如平台信息、Python 版本、<code>pytest</code> 版本、<code>plugins</code> 以及其他相关的配置信息。这些信息通常出现在测试结果的顶部。</p>
<p>示例（带头部信息）：</p>
<pre><code class="language-python">root@Gavin:~/code# pytest chapter1-3/test_time1.py
================================ test session starts ===========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 2 items
chapter1-3/test_time1.py ..                                               [100%]

================================= 2 passed in 0.00s ============================
root@Gavin:~/code#
</code></pre>
<p><strong>示例（没有头部信息，使用 <code>--no-header</code>）：</strong></p>
<pre><code class="language-python">root@Gavin:~/code# pytest --no-header chapter1-3/test_time1.py
================================ test session starts ===========================
collected 2 items
chapter1-3/test_time1.py ..                                               [100%]

================================ 2 passed in 0.00s =============================
root@Gavin:~/code#
</code></pre>
<p>可以看到，使用 <code>--no-header</code> 后，关于平台、Python 版本、pytest 版本及插件的信息都被省略了。只有测试收集和执行的信息被打印出来。这可以让输出看起来更简洁，尤其是在自动化环境中，可能你并不需要这些额外的信息。</p>
<p>这个选项在合并测试结果输出到其他工具或当你只关注测试执行结果时非常有用。如果要了解测试环境的详细信息，运行时则不应该使用 <code>--no-header</code> 选项。</p>
<h3 id="3-2-3-5-can-shu-no-summary">3.2.3.5 参数 --no-summary</h3>
<p><code>pytest</code> 的 <code>--no-summary</code> 选项最初在<code>pytest 7.0</code>中引入，用于在测试运行的输出中省略最后的总结信息，提供一个简短的总结(<code>short test summary info</code>)，指出有多少测试通过、失败、跳过等。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest --no-summary
</code></pre>
<p>默认的 <code>pytest</code> 总结信息：</p>
<p>默认情况下，当测试运行完成后，<code>pytest</code> 会在控制台的运行阶段输出错误点的相关详细信息，以及在控制台的最后输出用例错误状态总结（注意下文中的<code>short test summary info</code>）。</p>
<p><strong>示例（带总结信息）：</strong></p>
<pre><code class="language-python">root@Gavin:~/code# pytest chapter1-3/
============================== test session starts ========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 14 items
chapter1-3/test_example.py .x.F                                       [ 28%]
chapter1-3/test_setup_teardown.py ...                                 [ 50%]
chapter1-3/test_show_fixtures.py ...                                  [ 71%]
chapter1-3/test_time1.py ..                                           [ 85%]
chapter1-3/test_time2.py F.                                           [100%]

============================== FAILURES ====================================
______________________________ test_assert_failed __________________________

    def test_assert_failed():
&gt;       assert all([elem == 1 for elem in list(range(5))])
E       assert False
E        +  where False = all([False, True, False, False, False])

chapter1-3/test_example.py:21: AssertionError
______________________________ test_AM_or_PM _______________________________

    def test_AM_or_PM():
        """  Determine current time is AM or PM  """
        AM = PM = False
        current_time = time.localtime()
        if current_time.tm_hour &lt; 12:
            AM = True
        else:
            PM = True
    
&gt;       assert AM is True
E       assert False is True

chapter1-3/test_time2.py:15: AssertionError
============================= short test summary info =====================
FAILED chapter1-3/test_example.py::test_assert_failed - assert False
FAILED chapter1-3/test_time2.py::test_AM_or_PM - assert False is True
======================== 2 failed, 11 passed, 1 xfailed in 7.06s ==========
root@Gavin:~/code#
</code></pre>
<p><strong>示例（没有总结信息，使用 <code>--no-summary</code>）：</strong></p>
<pre><code class="language-python">root@Gavin:~/code# pytest --no-summary  chapter1-3/
============================= test session starts ===========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 14 items
chapter1-3/test_example.py .x.F                                        [ 28%]
chapter1-3/test_setup_teardown.py ...                                  [ 50%]
chapter1-3/test_show_fixtures.py ...                                   [ 71%]
chapter1-3/test_time1.py ..                                            [ 85%]
chapter1-3/test_time2.py F.                                            [100%]

============================ 2 failed, 11 passed, 1 xfailed in 7.05s =========
root@Gavin:~/code#
</code></pre>
<p>在上面的示例中，使用 <code>--no-summary</code> 选项后，输出中省略了最后的总结行，这样可以使输出更加简洁。</p>
<p>如果用例执行都是成功的，带不带<code>--no-summary</code>并没有什么区别，如下图所示：</p>
<img class="shadow" src="/img/in-post/chatp1-3_no-summary.png" width="800">
<p>这个选项对于想减少输出中的干扰，将测试结果传递给其他工具或者在自动化脚本中处理测试结果时非常有用。如果你只关心测试是否全部通过，而不太在意具体的错误信息，那么 <code>--no-summary</code> 可以帮助清理控制台输出。但如果你需要了解详细的测试报错，比如在调试失败的测试时，那么就不应该使用 <code>--no-summary</code> 选项。</p>
<h3 id="3-2-3-6-can-shu-q-quiet">3.2.3.6 参数 -q, --quiet</h3>
<p><code>pytest</code> 的 <code>-q</code> 或 <code>--quiet</code> 选项是用来减少测试运行输出的冗余信息的，使输出更加简洁。在 <code>pytest</code> 中使用 <code>-q</code> 或 <code>--quiet</code> 时，会减少控制台上打印的日志量，这对于你要快速检查测试是否通过而不需要查看详细的失败信息时很有用。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest -q
</code></pre>
<p>或</p>
<pre><code class="language-shell">pytest --quiet
</code></pre>
<p>这两种方式都会实现同样的效果。</p>
<p>默认 <code>pytest</code> 输出：</p>
<p>在默认设置下，<code>pytest</code> 会显示每个测试文件的每个测试函数的详细结果，以及全面的状态总结。</p>
<p><strong>示例（默认详细度）：</strong></p>
<pre><code class="language-python">root@Gavin:~/code# pytest chapter1-3/test_time1.py chapter1-3/test_time2.py 
============================= test session starts ===========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 4 items
chapter1-3/test_time1.py ..                                             [ 50%]
chapter1-3/test_time2.py F.                                             [100%]
</code></pre>
<p><strong>示例（使用 <code>-q</code> 或 <code>--quiet</code>）：</strong></p>
<pre><code class="language-python">root@Gavin:~/code# pytest -q chapter1-3/test_time1.py chapter1-3/test_time2.py 
..F.                                                                             [100%]
</code></pre>
<p>在使用 <code>--quiet</code> 后，测试的输出变得更加简洁，只显示每个测试点的结果 (<code>.</code> 代表通过, <code>F</code> 代表失败)，并在最后提供失败的测试的简短摘要。如果所有测试都通过，则输出将仅包含测试点的结果。</p>
<p>如果你需要进一步减少输出信息，还可以结合使用 <code>--no-header</code> 和 <code>--no-summary</code> 选项来分别移除头部环境信息和尾部的测试总结，只保留结果指示。这在某些快速检查或大型自动化测试环境中非常有用。</p>
<h3 id="3-2-3-7-can-shu-verbosity-verbose">3.2.3.7 参数 --verbosity=VERBOSE</h3>
<p><code>pytest</code> 的 <code>--verbosity</code> 选项是用来控制测试运行时输出的详细程度的。<code>VERBOSE</code> 是一个整数值，用于指定你希望看到的信息量。当你增加 <code>VERBOSE</code> 的值时，你将会看到更多的信息；当你减少该值时，输出的信息会更少。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest --verbosity=N
</code></pre>
<p>这里 <code>N</code> 是可选的整数值，代表不同的详细级别：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>0</code> (或者不使用 <code>--verbosity</code> 选项)：默认的详细程度，提供中等量的信息，包含每个测试函数的结果和一个简短的总结。</p>
</li>
<li class="lvl-2">
<p><code>1</code>：更详细的输出，类似于不使用任何详细度选项的默认行为，通常显示测试名称和结果。</p>
</li>
<li class="lvl-2">
<p><code>2</code>：更高的详细程度，显示测试的额外信息，如测试的设置和拆解步骤（setup和teardown）。</p>
</li>
<li class="lvl-2">
<p><code>-1</code>：减少输出的详细程度，等同于使用 <code>-q</code> 或 <code>--quiet</code>，会提供更简洁的输出。</p>
</li>
</ul>
<p>说明：</p>
<pre><code class="language-shell">"-vv" === "--verbose --verbose" === "--verbosity=2"
</code></pre>
<p><strong>示例：</strong></p>
<p>假设有如下几个测试：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# cat test_verbosity.py
#!/usr/bin/env python
# -*- coding:utf-8 -*-

import pytest

def test_pass():
    assert 1 == 1

def test_fail():
    assert 1 == 2

def test_skip():
    pytest.skip('skipping this test case')

@pytest.mark.xfail
def test_xfail():
    assert 1 == 2
</code></pre>
<p>减少输出的详细程度（-1）：</p>
<pre><code class="language-python">root@Gavin:~/code# pytest --verbosity=-1 chapter1-3/test_verbosity.py 
.Fsx                                                                [100%]
=============================== FAILURES =================================
_______________________________ test_fail ________________________________
    def test_fail():
&gt;       assert 1 == 2
E       assert 1 == 2

chapter1-3/test_verbosity.py:16: AssertionError
============================== short test summary info ====================
FAILED chapter1-3/test_verbosity.py::test_fail - assert 1 == 2
1 failed, 1 passed, 1 skipped, 1 xfailed in 0.03s
root@Gavin:~/code#
</code></pre>
<p>默认详细度 (<code>0</code> 或没有 <code>--verbosity</code>)：</p>
<pre><code class="language-python">root@Gavin:~/code# pytest --verbosity=0 chapter1-3/test_verbosity.py 
============================== test session starts =========================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 4 items
chapter1-3/test_verbosity.py .Fsx                                     [100%]

============================== FAILURES =====================================
______________________________ test_fail ____________________________________
    def test_fail():
&gt;       assert 1 == 2
E       assert 1 == 2

chapter1-3/test_verbosity.py:16: AssertionError
========================== short test summary info ==========================
FAILED chapter1-3/test_verbosity.py::test_fail - assert 1 == 2
==================1 failed, 1 passed, 1 skipped, 1 xfailed in 0.03s =========
root@Gavin:~/code#
</code></pre>
<p>轻微详细 (<code>1</code>)：</p>
<pre><code class="language-python">root@Gavin:~/code# pytest --verbosity=1 chapter1-3/test_verbosity.py 
============================= test session starts =============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /root/code
collected 4 items
chapter1-3/test_verbosity.py::test_pass PASSED                            [ 25%]
chapter1-3/test_verbosity.py::test_fail FAILED                            [ 50%]
chapter1-3/test_verbosity.py::test_skip SKIPPED (skipping this test case) [ 75%]
chapter1-3/test_verbosity.py::test_xfail XFAIL                            [100%]

============================= FAILURES ========================================
_____________________________ test_fail _______________________________________
    def test_fail():
&gt;       assert 1 == 2
E       assert 1 == 2

chapter1-3/test_verbosity.py:16: AssertionError
============================ short test summary info ==========================
FAILED chapter1-3/test_verbosity.py::test_fail - assert 1 == 2
=============== 1 failed, 1 passed, 1 skipped, 1 xfailed in 0.03s =============
root@Gavin:~/code#
</code></pre>
<p>高详细度 (<code>2</code>):</p>
<pre><code class="language-python">root@Gavin:~/code# pytest --verbosity=2 chapter1-3/test_verbosity.py 
=========================== test session starts ===============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0 -- /usr/bin/python3
cachedir: .pytest_cache
rootdir: /root/code
collected 4 items
chapter1-3/test_verbosity.py::test_pass PASSED                                 [ 25%]
chapter1-3/test_verbosity.py::test_fail FAILED                                 [ 50%]
chapter1-3/test_verbosity.py::test_skip SKIPPED (skipping this test case)      [ 75%]
chapter1-3/test_verbosity.py::test_xfail XFAIL                                 [100%]

============================== FAILURES ========================================
______________________________ test_fail _______________________________________
    def test_fail():
&gt;       assert 1 == 2
E       assert 1 == 2

chapter1-3/test_verbosity.py:16: AssertionError
============================== short test summary info =========================
FAILED chapter1-3/test_verbosity.py::test_fail - assert 1 == 2
================ 1 failed, 1 passed, 1 skipped, 1 xfailed in 0.03s =============
root@Gavin:~/code# 
</code></pre>
<p>从结果上看，<code>-v</code>  和  <code>-vv</code>的输出结果非常接近，甚至某些情况下内容一致。</p>
<p>每个测试的执行状态都会以不同程度的详细信息显示出来。在命令行中找到适合你当前需求的详细程度可以帮你更快地理解测试结果。高详细度非常有用，例如，当你需要调试测试问题或者理解测试执行的流程时。而在自动化环境或持续集成系统中，你可能会想要减少输出的详细程度。</p>
<h3 id="3-2-3-8-can-shu-r-chars">3.2.3.8 参数 -r chars</h3>
<p><code>pytest</code> 的 <code>-r</code> 选项用于自定义结果输出的详细程度(默认: ‘fE’)。它允许你通过使用不同的字符选择要显示的测试结果类型。</p>
<p><strong>使用方法：</strong></p>
<pre><code class="language-shell">pytest -r chars
</code></pre>
<p>其中，<code>chars</code> 是一组字符，每个字符代表一种特定的测试结果。字符可以组合使用，每种字符的含义如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>F</code>：显示失败的测试 (FAILURES).</p>
</li>
<li class="lvl-2">
<p><code>E</code>：显示错误的测试 (ERRORS).</p>
</li>
<li class="lvl-2">
<p><code>S</code>：显示跳过的测试 (SKIPPED).</p>
</li>
<li class="lvl-2">
<p><code>X</code>：显示预期失败但通过的测试 (XFAIL)，即意外的成功测试。</p>
</li>
<li class="lvl-2">
<p><code>x</code>：显示预期失败的测试（即本来就预期会失败，但失败了并不影响测试结果）。</p>
</li>
<li class="lvl-2">
<p><code>P</code>：显示通过的测试 (PASSED).</p>
</li>
<li class="lvl-2">
<p><code>p</code>：显示通过的测试（部分，如果有使用 <code>-k</code> 提供表达式仅部分测试通过）。</p>
</li>
<li class="lvl-2">
<p><code>a</code>：显示所有测试（all）。</p>
</li>
<li class="lvl-2">
<p><code>A</code>：自动分页显示测试结果，这有助于防止在跑大量测试时屏幕滚动过快过多。</p>
</li>
</ul>
<p><strong>示例：</strong></p>
<p>假设我们有以下测试用例，有的通过了，有的失败了，有的被跳过：</p>
<pre><code class="language-python">root@Gavin:~/code/chapter1-3# cat test_parameter_r.py 
#!/usr/bin/env python
# -*- coding:utf-8 -*-


import pytest


def test_pass():
    assert 1 == 1


def test_fail():
    assert 0 == 1


def test_skip():
    pytest.skip('skipping this test case.')


@pytest.mark.xfail
def test_xfail():
     assert 1 == 2


@pytest.mark.xfail
def test_xpass():
    assert 2 == 2
root@Gavin:~/code/chapter1-3#
</code></pre>
<p>我们可以使用不同的 <code>-r</code> 选项来自定义我们想要显示哪些类型的结果。</p>
<p>只显示失败 (<code>F</code>) 和 错误 (<code>E</code>):</p>
<pre><code class="language-shell">pytest -rFE
</code></pre>
<pre><code class="language-python">root@Gavin:~/code# pytest -rFE chapter1-3/test_parameter_r.py 
============================ test session starts =============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 5 items
chapter1-3/test_parameter_r.py .FsxX                                    [100%]

================================= FAILURES ===================================
_________________________________ test_fail __________________________________
    def test_fail():
&gt;       assert 0 == 1
E       assert 0 == 1

chapter1-3/test_parameter_r.py:13: AssertionError
========================== short test summary info ===========================
FAILED chapter1-3/test_parameter_r.py::test_fail - assert 0 == 1
======= 1 failed, 1 passed, 1 skipped, 1 xfailed, 1 xpassed in 0.03s =========
root@Gavin:~/code#
</code></pre>
<p>显示失败 (<code>F</code>), 跳过 (<code>S</code>), 预期失败但通过 (<code>x</code>), 和 预期失败 (<code>X</code>):</p>
<pre><code class="language-shell">pytest -rFSxX
</code></pre>
<pre><code class="language-python">root@Gavin:~/code# pytest -rFSxX chapter1-3/test_parameter_r.py 
============================  test session starts ============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 5 items
chapter1-3/test_parameter_r.py .FsxX                                    [100%]

=============================  FAILURES ======================================
_____________________________ test_fail ______________________________________
    def test_fail():
&gt;       assert 0 == 1
E       assert 0 == 1

chapter1-3/test_parameter_r.py:13: AssertionError
==========================  short test summary info ==========================
FAILED chapter1-3/test_parameter_r.py::test_fail - assert 0 == 1
SKIPPED [1] chapter1-3/test_parameter_r.py:17: skipping this test case.
XFAIL chapter1-3/test_parameter_r.py::test_xfail
XPASS chapter1-3/test_parameter_r.py::test_xpass 
======== 1 failed, 1 passed, 1 skipped, 1 xfailed, 1 xpassed in 0.03s ========
root@Gavin:~/code#
</code></pre>
<p>使用 <code>-r</code> 选项可以帮助你创建更易于阅读和理解的测试输出。你可以根据你的需要和测试的上下文环境，选择合适的组合。在一些持续集成环境中，通常只关心失败的测试结果，那么只需包含 <code>-rF</code> 选项即可。而在日常开发中，了解哪些测试被跳过可能也很重要，那么 <code>-rFS</code> 就会有所帮助。</p>
<h3 id="3-2-3-9-can-shu-disable-warnings-disable-pytest-warnings">3.2.3.9 参数 --disable-warnings, --disable-pytest-warnings</h3>
<p><code>pytest</code> 是一个非常流行的 Python 测试框架，它有很多可以控制测试行为和输出的命令行选项。在执行测试时，你可能会遇到警告信息，这些警告可能来自于测试代码本身或者使用的第三方库。虽然警告信息可以提供有用的信息，但有时候你可能想要在测试输出中隐藏这些警告信息，以便专注于测试结果。</p>
<p><strong>使用方法：</strong></p>
<p><code>pytest</code> 提供了两个选项来禁用警告信息：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>--disable-warnings</code></p>
</li>
</ul>
<p>该选项将会禁用所有测试运行中的警告信息，包括来自 Python 内部函数和第三方库的警告。这可以让你的测试结果输出更加清晰，只包含测试执行的结果信息。</p>
<pre><code class="language-shell">pytest --disable-warnings
</code></pre>
<p>加入此参数后，任何使用 Python 标准库 <code>warnings</code> 发出的警告，以及第三方库生成的警告都不会在测试输出中显示。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>--disable-pytest-warnings</code></p>
</li>
</ul>
<pre><code class="language-shell">pytest --disable-pytest-warnings
</code></pre>
<p>该选项用于禁用由 <code>pytest</code> 产生的警告，但从实际使用效果看， 与<code>--disable-warnings</code>效果相同。</p>
<p><strong>示例：</strong></p>
<pre><code class="language-python">root@Gavin:~/code# cat chapter1-3/test_warnings.py 
#!/usr/bin/env python
# -*- coding:UTF-8 -*-


import warnings


def api_v1():
    warnings.warn(UserWarning("api v1, should use functions from v2"))
    return 1


def test_one():
    assert api_v1() == 1
root@Gavin:~/code#
</code></pre>
<p>不携带<code>--disable-warnings</code>或者<code>--disable-pytest-warnings</code>的效果:</p>
<pre><code class="language-python">root@Gavin:~/code# pytest chapter1-3/test_warnings.py 
============================== test session starts ============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 1 item
chapter1-3/test_warnings.py .                                            [100%]

============================ warnings summary =================================
chapter1-3/test_warnings.py::test_one
  /root/code/chapter1-3/test_warnings.py:9: UserWarning: api v1, should use functions from v2
    warnings.warn(UserWarning("api v1, should use functions from v2"))

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================== 1 passed, 1 warning in 0.00s =======================
root@Gavin:~/code#
</code></pre>
<p>携带<code>--disable-warnings</code>的效果:</p>
<pre><code class="language-python">root@Gavin:~/code# pytest --disable-warnings chapter1-3/test_warnings.py 
============================= test session starts =============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 1 item
chapter1-3/test_warnings.py .                                           [100%]

========================== 1 passed, 1 warning in 0.00s =======================
root@Gavin:~/code#
</code></pre>
<p>携带<code>--disable-pytest-warnings</code>的效果:</p>
<pre><code class="language-python">root@Gavin:~/code# pytest --disable-pytest-warnings chapter1-3/test_warnings.py 
============================= test session starts =============================
platform linux -- Python 3.11.6, pytest-7.4.0, pluggy-1.2.0
rootdir: /root/code
collected 1 item
chapter1-3/test_warnings.py .                                           [100%]

==========================  1 passed, 1 warning in 0.00s ======================
root@Gavin:~/code# 
</code></pre>
<p><strong>请注意：</strong></p>
<p><strong>不显示警告并不意味着问题已经解决。</strong> 通常，警告信息是有其存在的目的，它们可能指出了代码潜在的问题，例如过时的函数使用、不建议的做法、未来可能出现的问题等。因此，在禁用警告输出时，请确保你理解为什么要这么做，并且已经考虑到了可能的影响。在开发过程中解决这些警告通常是一个更好的做法。</p>
<h3 id="3-2-3-10-can-shu-showlocals">3.2.3.10 参数 --showlocals</h3>
<p><code>pytest</code> 中的 <code>-l</code> 或 <code>--showlocals</code> 选项是用来在测试失败的报告信息中显示局部变量的值。这对于调试失败的测试特别有用，因为它允许开发者看到当测试失败时，在测试函数以及涉及的其他相关代码中的局部变量的精确值。</p>
<p>这个选项可以让你更快地理解为什么测试失败了，尤其是在复杂的测试场景中，其中可能需要理解不同函数和对象的状态。</p>
<p><strong>使用方法：</strong></p>
<p>在运行 <code>pytest</code> 命令时，加上 <code>-l</code> 或 <code>--showlocals</code> 选项：</p>
<pre><code class="language-shell">pytest -l
# 或者
pytest --showlocals
</code></pre>
<p><strong>示例：</strong></p>
<p>假如我们在<code>chapter1-3/test_example.py</code>文件中有以下的测试函数：</p>
<pre><code class="language-python">def test_assert_example():
    a = 5
    b = 10
    assert a + b == 20
</code></pre>
<p>不加 <code>-l</code> 或 <code>--showlocals</code> 选项，当测试失败时，默认的输出可能只告诉你 <code>assert</code> 语句失败了，但不会告诉你 <code>a</code> 和 <code>b</code> 的值是多少。</p>
<p>如果使用了 <code>-l</code> 或 <code>--showlocals</code> 选项，当测试失败了，<code>pytest</code> 会在报告信息中包括 <code>a</code> 和 <code>b</code> 的值，输出类似下面这样：</p>
<pre><code class="language-python">============================== FAILURES ====================================
______________________________ test_assert_example _________________________

    def test_assert_example():
        a = 5
        b = 10
&gt;       assert a + b == 20
E       assert (5 + 10) == 20

a          = 5
b          = 10

chapter1-3/test_example.py:27: AssertionError
</code></pre>
<p>在这里，你可以清楚地看到 <code>a</code> 和 <code>b</code> 的值，并且能够推断出为什么 <code>assert</code> 断言失败了。</p>
<p><strong>说明：</strong></p>
<p>虽然 <code>--showlocals</code> 选项在定位问题时非常有用，但它可能会导致报告输出变得非常长，尤其是当测试用例涉及的局部变量很多时。所以，建议仅在需要调试特定失败的测试时使用这个选项，或者结合其他命令行选项使用，如 <code>-k</code> 选项，以只针对某些特定的测试输出局部变量。</p>
<h3 id="3-2-3-11-can-shu-no-showlocals">3.2.3.11 参数 --no-showlocals</h3>
<p>在 <code>pytest</code> 中，<code>--no-showlocals</code> 选项用于禁止在测试失败的报告信息中显示局部变量的值。通常，<code>pytest</code> 会自动显示测试失败时的局部变量和它们的值，这有助于调试和快速地识别问题所在。然而，有时你可能会想要一个更简洁的失败报告，不包括局部变量的详细信息，尤其是当局部变量太多或它们的输出太长、过于冗余的时候。</p>
<p><strong>使用方法：</strong></p>
<p>当你运行 <code>pytest</code> 并希望隐藏失败测试中的局部变量，在命令行中加入 <code>--no-showlocals</code> 选项：</p>
<pre><code class="language-shell">pytest --no-showlocals
</code></pre>
<p>使用这个选项后，即使测试失败，<code>pytest</code> 也不会显示局部变量和它们的值。这会给你一个更简洁的失败输出，可能仅包含失败的 <code>assert</code> 语句和一些基本的错误信息。</p>
<p><strong>请注意：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p>当命令行中同时存在 <code>--showlocals</code>（或 <code>-l</code>）和 <code>--no-showlocals</code> 选项时，后出现的选项会覆盖前面的。</p>
</li>
<li class="lvl-2">
<p>由于 <code>pytest</code> 默认不显示局部变量，所以在许多情况下不需要显式地使用 <code>--no-showlocals</code> 选项，除非你想要覆盖配置文件中的设置（例如在 <code>pytest.ini</code> 或 <code>pyproject.toml</code> 中配置了显示局部变量）。</p>
</li>
</ul>
<p><strong>示例：</strong></p>
<p>假设你在配置文件中设置了默认显示局部变量的值，如下：</p>
<pre><code class="language-ini"># content of pytest.ini
[pytest]
showlocals = true
</code></pre>
<p>当你想要在特定的测试运行中去除这个行为，可以在命令行中使用 <code>--no-showlocals</code> 来覆盖配置文件中的设置：</p>
<pre><code class="language-shell">pytest --no-showlocals
</code></pre>
<p>在这种情况下，即使 <code>pytest.ini</code> 配置是显示局部变量，使用了 <code>--no-showlocals</code> 选项的测试运行将不展示失败测试的局部变量。</p>
<h3 id="3-2-3-12-can-shu-tb-style">3.2.3.12 参数 --tb=style</h3>
<p><code>pytest</code> 的 <code>--tb=style</code> 选项用于指定当测试失败时，堆栈跟踪（traceback）的输出格式。<code>style</code> 是一个参数，它可以取不同的值来更改堆栈跟踪的显示方式。这允许开发者根据个人喜好或特定调试需求选择不同的堆栈跟踪显示风格。</p>
<p>下面是 <code>--tb</code> 选项可以接受的几个不同的值：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>auto</code>：默认的选项，会智能地缩短跟踪输出，通常只显示最后几行。</p>
</li>
<li class="lvl-2">
<p><code>long</code>：最详细的跟踪格式，它会展示所有的相关调用，不进行任何裁剪，这对于理解复杂错误非常有帮助。</p>
</li>
<li class="lvl-2">
<p><code>short</code>：这将产生一个较短的跟踪，其中只包含引发错误的行数，而不包含整个堆栈跟踪。</p>
</li>
<li class="lvl-2">
<p><code>line</code>：这个选项只显示导致异常的那一行代码，省去所有额外的跟踪信息。</p>
</li>
<li class="lvl-2">
<p><code>no</code>：没有跟踪输出。</p>
</li>
<li class="lvl-2">
<p><code>native</code>：使用 Python 标准库的跟踪打印。</p>
</li>
</ul>
<p><strong>使用方法：</strong></p>
<p>在运行 <code>pytest</code> 命令时，加上 <code>--tb</code> 选项和相应的参数值：</p>
<pre><code class="language-shell">pytest --tb=short # 使用短格式的跟踪
pytest --tb=long  # 使用长格式的跟踪
pytest --tb=line  # 只显示导致测试失败的代码行
pytest --tb=no    # 完全不显示跟踪
</code></pre>
<p><strong>示例：</strong></p>
<p>假如我们在<code>chapter1-3/test_example.py</code>文件中有以下的测试函数会抛出一个异常：</p>
<pre><code class="language-python">def test_divide():
    num = 10
    denom = 0
    assert num / denom == 0
</code></pre>
<p>在这里，测试失败不仅因为断言错误，还因为有一个除以零的错误。</p>
<p>运行 <code>pytest</code> 带有不同的 <code>--tb</code> 选项会产生不同的输出：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>--tb=short</code> 只会显示异常的相关代码行和一个简短的错误提示。</p>
</li>
<li class="lvl-2">
<p><code>--tb=long</code> 会展示更多有关调用堆栈的信息，有时这可以包括你的测试函数之外的代码。</p>
</li>
<li class="lvl-2">
<p><code>--tb=no</code> 不显示任何跟踪信息，只告诉你哪些测试失败了。</p>
</li>
</ul>
<p>如下图所示：</p>
<img class="shadow" src="/img/in-post/chatp1-3_tb.png" width="800">
<p>选择适合你当前调试任务的 <code>--tb</code> 风格可以帮助你更快地定位问题。</p>
<h3 id="3-2-3-13-can-shu-show-capture-no-stdout-stderr-log-all">3.2.3.13 参数 --show-capture={no,stdout,stderr,log,all}</h3>
<p><code>pytest</code> 提供了 <code>--show-capture</code> 选项，允许用户控制在测试失败或测试执行过程中产生的标准输出(<code>stdout</code>)、标准错误(<code>stderr</code>)和日志输出的显示行为。根据选项后面的参数，<code>pytest</code> 将会决定在测试报告中展现哪些类型的捕获输出。</p>
<p>参数选项如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>no</code>：完全不显示任何捕获的输出。</p>
</li>
<li class="lvl-2">
<p><code>stdout</code>：只显示测试中捕获的标准输出(<code>stdout</code>)。</p>
</li>
<li class="lvl-2">
<p><code>stderr</code>：只显示测试中捕获的标准错误(<code>stderr</code>)。</p>
</li>
<li class="lvl-2">
<p><code>log</code>：只显示测试中捕获的日志输出。</p>
</li>
<li class="lvl-2">
<p><code>all</code>：显示所有类型的捕获输出，包括<code>stdout、stderr</code>和<code>log</code>。</p>
</li>
</ul>
<p><strong>使用方法：</strong></p>
<p>在运行 <code>pytest</code> 命令时，可以加上 <code>--show-capture</code> 选项和所需的参数值：</p>
<pre><code class="language-shell">pytest --show-capture=no     # 不展示任何捕获的输出
pytest --show-capture=stdout # 只展示标准输出
pytest --show-capture=stderr # 只展示标准错误
pytest --show-capture=log    # 只展示日志输出
pytest --show-capture=all    # 展示所有捕获的输出
</code></pre>
<p><strong>示例：</strong></p>
<p>假设在<code>chapter1-3/test_example.py</code>文件中有这样的一个测试函数，它打印了一些信息到标准输出，并记录了一个日志消息：</p>
<pre><code class="language-python">import logging

def test_output_example():
    print("Hello, this is stdout!")
    logging.warning("This is a warning log message.")
    assert 0 
</code></pre>
<p>根据你使用的 <code>--show-capture</code> 选项，输出结果会有所不同：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>运行 <code>pytest --show-capture=no</code> 不会在失败报告中包含任何<code>Hello, this is stdout!</code>或日志消息。</p>
</li>
<li class="lvl-2">
<p>运行 <code>pytest --show-capture=stdout</code> 仅会包含<code>Hello, this is stdout!</code>。</p>
</li>
<li class="lvl-2">
<p>运行 <code>pytest --show-capture=log</code> 仅会包含<code>This is a warning log message.</code>。</p>
</li>
<li class="lvl-2">
<p>运行 <code>pytest --show-capture=all</code> 会包含<code>Hello, this is stdout!</code>和<code>This is a warning log message.</code>。</p>
</li>
</ul>
<p>根据你的需求，可以选择适当的设置来帮助你专注于特定类型的输出，是调试更简洁、更有效。</p>
<h3 id="3-2-3-14-can-shu-full-trace">3.2.3.14 参数 --full-trace</h3>
<p><code>pytest</code> 的 <code>--full-trace</code> 选项提供了在测试失败时显示完整的堆栈跟踪信息，而不是仅显示直接与测试用例相关的部分。它通常用于调试复杂的问题，当需要了解事件是如何从调用堆栈的更深层次传播出来的时候特别有用。</p>
<p>在没有任何堆栈跟踪参数的默认情况下，<code>pytest</code> 可能会截断部分跟踪信息来提供更简洁的输出。然而，当事情变得复杂，你可能会需要看到详尽的调用信息来诊断问题。这时，<code>--full-trace</code> 就显得非常有用，因为它可以提供最全面的跟踪信息，包括库函数和内部调用在内的所有调用栈信息。</p>
<p><strong>使用方法：</strong></p>
<p>当执行 <code>pytest</code> 命令时，如果想要启用完整的堆栈跟踪，可以添加 <code>--full-trace</code> 选项：</p>
<pre><code class="language-shell">pytest --full-trace
</code></pre>
<p><strong>示例：</strong></p>
<p>假设在<code>chapter1-3/test_example.py</code>文件中有一个测试函数，它调用了几层函数，并且在内部某处发生了异常：</p>
<pre><code class="language-python">def helper_function():
    raise ValueError("An error occurred.")

def another_function():
    helper_function()

def test_another_example():
    another_function()
</code></pre>
<p>在运行 <code>pytest</code> 而不带 <code>--full-trace</code> 时，输出可能只会显示与 <code>test_another_example</code> 直接相关的异常信息。而使用了 <code>--full-trace</code> 的命令，将会输出完整的堆栈跟踪，包括 <code>helper_function</code> 和 <code>another_function</code> 的调用信息，这在理解异常的来源时非常有帮助。</p>
<p><strong>请注意：</strong></p>
<p>这个选项可能会导致非常长的输出，特别是当测试调用了许多层次的外部库或框架代码时。在寻找复杂问题的解决方案时，详细的堆栈信息才是最有用的；在其他时候，可能更倾向于较为简洁的输出。</p>
<h3 id="3-2-3-15-can-shu-color-color">3.2.3.15 参数 --color=color</h3>
<p><code>pytest</code> 的 <code>--color</code> 选项用于控制 <code>pytest </code>输出到控制台时使用的颜色。终端的颜色输出有助于区分测试的不同状态，比如成功、失败或跳过的测试。</p>
<p><code>--color</code> 选项接受以下参数：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>auto</code>：<code>pytest</code> 会自动检测终端是否支持颜色输出，并相应地启用或禁用颜色。这是默认行为。</p>
</li>
<li class="lvl-2">
<p><code>yes</code> 或 <code>true</code>：在 <code>pytest</code>输出中强制使用颜色，即使检测到终端不支持颜色输出。</p>
</li>
<li class="lvl-2">
<p><code>no</code> 或 <code>false</code>：在 <code>pytest</code> 输出中禁用颜色，即使终端支持颜色。</p>
</li>
</ul>
<p>使用这个选项可以强制启用或禁用颜色输出，方便在不同的环境或情况下定制化 <code>pytest </code>的表现。这对于在不支持颜色的环境（例如某些持续集成系统的日志）查看输出或者创建无颜色的日志文件时非常有用。</p>
<p><strong>使用方法：</strong></p>
<p>在运行 <code>pytest</code> 命令时，可以加上 <code>--color</code> 选项和对应的值：</p>
<pre><code class="language-shell">pytest --color=yes  # 强制使用颜色输出
pytest --color=no   # 禁用颜色输出
pytest --color=auto # 自动检测（默认）
</code></pre>
<p>根据你的终端和个人喜好，你可以选择使用这个选项来定制化 <code>pytest</code> 的输出。在某些情况下，如果终端不支持颜色而你又想要有色输出，或者你想在不同的显示背景（比如白色和黑色背景的终端中）都有良好的可读性，这个选项就特别有用。</p>
<h3 id="3-2-3-16-can-shu-code-highlight-yes-no">3.2.3.16 参数 --code-highlight={yes,no}</h3>
<p><code>pytest</code> 的 <code>--code-highlight</code> 选项用于控制在测试失败时是否显示语法高亮的代码。这个特性旨在提升输出的可读性，让用户更容易地理解代码中的错误和测试结果。</p>
<p><strong>可选参数说明：</strong></p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>yes</code> 或 <code>true</code>：启用语法高亮。当测试失败时，<code>pytest</code> 将显示语法高亮的代码段，以帮助用户快速识别代码结构和重要部分。</p>
</li>
<li class="lvl-2">
<p><code>no</code> 或 <code>false</code>：禁用语法高亮。测试失败时，<code>pytest</code> 将显示没有高亮的代码段。</p>
</li>
</ul>
<p><strong>示例：</strong></p>
<p>如果你想运行 <code>pytest</code> 并启用代码高亮，可以这样使用命令：</p>
<pre><code class="language-shell">pytest --code-highlight=yes
</code></pre>
<p>反之，如果你希望禁用代码高亮，使用以下命令：</p>
<pre><code class="language-shell">pytest --code-highlight=no
</code></pre>
<p>默认情况下，<code>pytest</code> 通常会根据输出环境自动决定是否使用代码高亮。例如，在大多数现代终端中，<code>pytest</code> 会自动启用代码高亮，因为它可以帮助开发者更好地阅读和理解输出结果。然而，在某些环境中，比如纯文本日志文件或不支持高亮的输出设备中，你可能会想禁用这个特性。</p>
<p>禁用代码高亮可能会在将测试结果导出到不支持颜色和格式化的系统时有所帮助，因为高亮代码可能包括特殊字符序列，这些在没有正确解释它们的情况下会干扰文本的阅读。</p>
<h3 id="3-2-3-17-can-shu-pastebin-mode">3.2.3.17 参数 --pastebin=mode</h3>
<p><code>pytest</code> 的 <code>--pastebin</code> 选项允许你将测试失败的完整报告上传到一个公共的 <code>pastebin</code> 服务中，这样可以非常方便地与他人分享测试报告。上传后，<code>pytest</code> 会提供一个 URL，你可以将这个 URL 发送给其他人，以便他们可以查看测试报告的内容。</p>
<p>这个选项接受以下参数（即 <code>mode</code>）：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p><code>failed</code>：只上传失败的测试报告。</p>
</li>
<li class="lvl-2">
<p><code>all</code>：上传所有测试的报告，无论是成功还是失败。</p>
</li>
</ul>
<p><strong>使用方法：</strong></p>
<p>例如，如果你只想上传那些失败的测试报告，你应该在运行 <code>pytest</code> 时这样使用命令：</p>
<pre><code class="language-shell">pytest --pastebin=failed
</code></pre>
<p>如果想上传所有的测试报告，也就是包括成功和失败的测试，你可以这样使用：</p>
<pre><code class="language-shell">pytest --pastebin=all
</code></pre>
<p>使用这个功能时，需要注意的是，任何上传到 <code>pastebin</code> 的内容实际上是公开的，它可能会被搜索引擎索引，或者被任何知道该 URL 的人访问。因此，在上传敏感测试报告之前，请考虑测试报告中可能包含的数据和信息。另外，请注意，这个功能依赖于公共的 <code>pastebin</code> 服务是否可用，以及 <code>pytest</code> 是否能够支持当前可用的 <code>pastebin API</code>。上传服务可能因维护、<code>API</code> 更改或其他原因而不可用。</p>
<h3 id="3-2-3-18-can-shu-junit-xml-path">3.2.3.18 参数 --junit-xml=path</h3>
<p><code>pytest</code> 的 <code>--junit-xml</code> 选项允许用户生成一个 <code>JUnit</code> 格式的 XML 文件，通常这种类型的文件用来与持续集成 (CI) 系统一起使用，如<code> Jenkins、TeamCity</code> 或者任何其他支持 <code>JUnit</code> 格式的系统。<code>JUnit XML</code> 报告提供了一种标准化的测试结果报告格式，使得不同的工具和系统能够解读和展示测试结果。</p>
<p><strong>使用方法：</strong></p>
<p>你需要指定一个文件路径来保存 XML 报告。如果指定路径的目录尚未存在，<code>pytest</code> 会尝试创建它。</p>
<p>例如，如果你想保存测试结果到当前目录下的 <code>report.xml</code> 文件，可以这样使用该命令：</p>
<pre><code class="language-shell">pytest --junit-xml=report.xml
</code></pre>
<p>如果你想保存到一个具体的目录（假设目录已经存在），可以这样做：</p>
<pre><code class="language-shell">pytest --junit-xml=path/to/report/directory/report.xml
</code></pre>
<p>使用这个参数后，<code>pytest</code> 将在测试完成后生成一个 XML 文件，其中包含了测试套件的详细结果，如测试用例的名称、测试状态（成功、失败、错误、跳过等）、以及其他可能的错误信息和日志。</p>
<p>持续集成工具可以配置为在构建过程结束时读取这个文件，以收集和展示测试结果，有助于开发和测试团队快速定位和解决问题。</p>
<p><code>--junit-xml</code> 选项是一个重要的功能，尤其是在自动化测试和CI/CD流程中，因为它有助于跨不同环境和工具共享和分析测试结果。</p>
<h3 id="3-2-3-19-can-shu-junit-prefix-str">3.2.3.19 参数 --junit-prefix=str</h3>
<p><code>pytest</code> 的 <code>--junit-prefix</code> 选项用来为生成的 <code>JUnit XML</code> 报告中的测试用例名称添加一个前缀。这在当你要将多个测试报告合并起来时非常有用，或者当你在不同的环境（例如：不同的操作系统或不同的环境配置下）运行了多次测试，并希望在报告中更容易区分这些测试。</p>
<p><strong>使用方法：</strong></p>
<p>当运行 <code>pytest</code> 并且生成 <code>JUnit XML</code> 报告文件时，使用 <code>--junit-prefix</code> 选项可以为每个测试用例的名称前加上指定的字符串。</p>
<p>例如，假设你的项目在 Python 3.9 和 Python 3.11 两个版本的环境下测试，并且你想在<code>JUnit</code>报告中区分这两个环境的测试结果。你可以分别为每个环境指定不同的前缀：</p>
<pre><code class="language-shell">pytest --junit-xml=report39.xml --junit-prefix=py39
</code></pre>
<p>和</p>
<pre><code class="language-shell">pytest --junit-xml=report311.xml --junit-prefix=py311
</code></pre>
<p>在上述例子中，<code>py39</code> 和 <code>py311</code> 就是添加到对应环境测试用例名称前的前缀字符串。在最终生成的 <code>report39.xml</code> 和 <code>report311.xml</code> 文件中，测试用例的名称将包含这些指定的前缀，这有助于在后续的测试报告分析或者在持续集成的测试结果展示中清晰地区分不同环境的测试结果。</p>
<p>在 CI 系统中合并多个报告时，这样的前缀可以防止测试用例的名称冲突，并提供一个更清晰的报告结构。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
  <entry>
    <title>借助pytest hook获取用例执行结果信息汇总</title>
    <url>/2024/05/24/pytest_cases_result_summary/</url>
    <content><![CDATA[<h1 id="gai-shu">概述</h1>
<p>pytest hook功能很强大，本文简要概述如何借助pytest的<code>pytest_runtest_makereport</code>&amp;<code>pytest_sessionstart</code>这两个hook，实现用例执行结果的汇总。</p>
<p>至于pytest hook知识点，非本文介绍内容，请读者另行查阅资料。</p>
<h1 id="yu-qi-xiao-guo">预期效果</h1>
<p>预期达到的效果如下：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>1.结果写入文件</p>
</li>
<li class="lvl-2">
<p>2.预期内容参考如下：</p>
</li>
</ul>
<pre><code class="language-shell">---------summary----------
passed: 1
failed: 2
skipped: 1
error: 1
xfailed: 0
xpassed: 1
---------details----------
[failed]
dir1/test_case_name01
dir1/test_case_name02
dir1/test_case_name03
dir2/test_case_name01

[skipped]
test_case_name

[error]
test_case_name

[xfailed]
test_case_name
# 如果没有，则显示为  --

[xpassed]
  --
</code></pre>
<h1 id="code">Code</h1>
<h2 id="code-conftest-py-code"><code>conftest.py</code></h2>
<pre><code class="language-python">import pytest
from collections import defaultdict

# 初始化一个字典，用于保存各种测试状态的数量和测试名称列表
test_results_summary = defaultdict(lambda: {"count": 0, "cases": []})

def pytest_sessionstart(session):
    session.results_summary = test_results_summary

@pytest.hookimpl(hookwrapper=True)
def pytest_runtest_makereport(item, call):
    outcome = yield
    report = outcome.get_result()
    global test_results_summary
    
    # 处理测试过程中的结果
    if report.when == 'call':
        if report.failed:
            if "xfail" in item.keywords:
                test_results_summary["xfailed"]["count"] += 1
                test_results_summary["xfailed"]["cases"].append(item.nodeid)
            else:
                test_results_summary["failed"]["count"] += 1
                test_results_summary["failed"]["cases"].append(item.nodeid)
        elif report.skipped:
            test_results_summary["skipped"]["count"] += 1
            test_results_summary["skipped"]["cases"].append(item.nodeid)
        elif "xfail" in item.keywords:
            test_results_summary["xpassed"]["count"] += 1
            test_results_summary["xpassed"]["cases"].append(item.nodeid)
        else:
            test_results_summary["passed"]["count"] += 1
    elif report.failed:
        test_results_summary["error"]["count"] += 1
        test_results_summary["error"]["cases"].append(item.nodeid)

def pytest_sessionfinish(session, exitstatus):
    with open('test_results_summary.txt', 'w') as f:
        f.write("---------summary----------\n")
        for key, value in session.results_summary.items():
            f.write(f"{key}: {value['count']}\n")
        
        f.write("---------details----------\n")
        for key, value in session.results_summary.items():
            if value["cases"]:
                f.write(f"[{key}]\n" + "\n".join(value["cases"]) + "\n")
            else:
                f.write(f"[{key}]\n  --\n")
</code></pre>
<h1 id="xiao-guo-jian-yan">效果检验</h1>
<p>先写一段测试代码<code>test_various_statuses.py</code>，涵盖各种用例执行状态：</p>
<pre><code class="language-python"># content of test_various_statuses.py
# -*- coding:UTF-8 -*-


import pytest


# 这个测试会通过
def test_passed():
    assert True


# 这个测试会失败
def test_failed():
     assert False


# 这个测试主动抛异常会失败
def test_failed_raise():
    raise Exception("An unexpected error occurred")


# 这个测试会被标记为预期失败，但如果通过了，它将被标记为XPASS
@pytest.mark.xfail
def test_xpass():
   assert True


# 这个测试被标记为预期失败，并且它确实失败了，因此它将被标记为XFAIL
@pytest.mark.xfail
def test_xfailed():
    assert False


# 这个测试会被跳过
@pytest.mark.skip(reason="This test is skipped for demonstration purposes")
def test_skipped():
    assert True


# 使用一个会发生错误的fixture
@pytest.fixture
def error_fixture():
    raise Exception("Error in fixture")


# 这个测试使用了一个错误的fixture，即使测试代码本身是正常的
def test_with_error_fixture(error_fixture):
    assert True
</code></pre>
<p>执行测试用例：</p>
<pre><code class="language-shell">root@Gavin:~/test_result_summary# ll
total 16
drwxr-xr-x  2 root root 4096 May 24 11:50 ./
drwx------ 43 root root 4096 May 24 11:48 ../
-rw-r--r--  1 root root 1977 May 24 11:41 conftest.py
-rw-r--r--  1 root root 1009 May 24 11:32 test_various_statuses.py
root@Gavin:~/test_result_summary# pytest -s test_various_statuses.py 
================================================================================================================== test session starts ===================================================================================================================
platform linux -- Python 3.11.6, pytest-8.0.2, pluggy-1.4.0
Test order randomisation NOT enabled. Enable with --random-order or --random-order-bucket=&lt;bucket_type&gt;
sensitiveurl: .*
rootdir: /root/test_result_summary
plugins: cov-4.1.0, order-1.2.0, random-order-1.1.1, tornasync-0.6.0.post2, check-2.2.2, instafail-0.5.0, allure-pytest-2.13.2, asyncio-0.23.6, selenium-4.1.0, xdist-3.5.0, variables-3.1.0, rerunfailures-13.0, html-4.1.1, progress-1.2.5, metadata-3.0.0, twisted-1.14.1, picked-0.5.0, anyio-4.3.0, Faker-24.0.0, trio-0.8.0, repeat-0.9.3, base-url-2.1.0, dependency-0.6.0, timeout-2.2.0
asyncio: mode=Mode.STRICT
collected 7 items                                                                                                                                                                                                                                        

test_various_statuses.py .FFXxsE

========================================================================================================================= ERRORS =========================================================================================================================
_______________________________________________________________________________________________________ ERROR at setup of test_with_error_fixture ________________________________________________________________________________________________________

    @pytest.fixture
    def error_fixture():
&gt;       raise Exception("Error in fixture")
E       Exception: Error in fixture

test_various_statuses.py:44: Exception
======================================================================================================================== FAILURES ========================================================================================================================
______________________________________________________________________________________________________________________ test_failed _______________________________________________________________________________________________________________________

    def test_failed():
&gt;        assert False
E        assert False

test_various_statuses.py:15: AssertionError
___________________________________________________________________________________________________________________ test_failed_raise ____________________________________________________________________________________________________________________

    def test_failed_raise():
&gt;       raise Exception("An unexpected error occurred")
E       Exception: An unexpected error occurred

test_various_statuses.py:20: Exception
================================================================================================================ short test summary info =================================================================================================================
FAILED test_various_statuses.py::test_failed - assert False
FAILED test_various_statuses.py::test_failed_raise - Exception: An unexpected error occurred
ERROR test_various_statuses.py::test_with_error_fixture - Exception: Error in fixture
========================================================================================= 2 failed, 1 passed, 1 skipped, 1 xfailed, 1 xpassed, 1 error in 0.11s ==========================================================================================
root@Gavin:~/test_result_summary#
</code></pre>
<p>用例执行结束后，会产生文件<code>test_results_summary.txt</code>:</p>
<pre><code class="language-shell">root@Gavin:~/test_result_summary# ll
total 28
drwxr-xr-x  4 root root 4096 May 24 11:50 ./
drwx------ 43 root root 4096 May 24 11:48 ../
-rw-r--r--  1 root root 1977 May 24 11:41 conftest.py
drwxr-xr-x  2 root root 4096 May 24 11:50 __pycache__/
drwxr-xr-x  3 root root 4096 May 24 11:50 .pytest_cache/
-rw-r--r--  1 root root  364 May 24 11:50 test_results_summary.txt
-rw-r--r--  1 root root 1009 May 24 11:32 test_various_statuses.py
root@Gavin:~/test_result_summary#
</code></pre>
<p>其内容参考如下：</p>
<pre><code class="language-shell">root@Gavin:~/test_result_summary# cat test_results_summary.txt 
---------summary----------
passed: 1
failed: 2
xpassed: 1
skipped: 1
error: 1
---------details----------
[passed]
  --
[failed]
test_various_statuses.py::test_failed
test_various_statuses.py::test_failed_raise
[xpassed]
test_various_statuses.py::test_xpass
[skipped]
test_various_statuses.py::test_xfailed
[error]
test_various_statuses.py::test_with_error_fixture
root@Gavin:~/test_result_summary#
</code></pre>
<p>符合预期要求。</p>
<h1 id="jie-yu">结语</h1>
<p>上述代码仅是个示例，抛砖引玉，在具体自动化Project中，可按自己的需求调整此文件位置、名称、内容展示等信息。</p>
<p>也可以将此文件的部分内容（如担心非passed状态用例数太多，引发文档内容过多）作为邮箱附件发送CI/CD构建通知。</p>
]]></content>
      <categories>
        <category>Automation</category>
        <category>pytest</category>
      </categories>
      <tags>
        <tag>Automation</tag>
        <tag>pytest</tag>
      </tags>
  </entry>
</search>
