<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="关于软件测试, 与你一起发现更大的世界">
    <meta name="keywords"  content="Gavin的博客, Gavin Blog, 博客, 个人网站">
    <meta name="theme-color" content="#000000">
    
    <!-- Open Graph -->
    <meta property="og:title" content="Demo for trasferring large file from break point - Gavin的博客 | Gavin Blog">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="Overview
">
    
    <meta property="article:published_time" content="2021-01-10T00:00:00Z">
    
    
    <meta property="article:author" content="Gavin">
    
    
    <meta property="article:tag" content="Linux">
    
    
    <meta property="og:image" content="http://0.0.0.0:4000/img/avatar-gavin.jpg">
    <meta property="og:url" content="http://0.0.0.0:4000/2021/01/10/Demo_for_trasferring_large_file/">
    <meta property="og:site_name" content="Gavin的博客 | Gavin Blog">
    
    <title>Demo for trasferring large file from break point - Gavin的博客 | Gavin Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://0.0.0.0:4000/2021/01/10/Demo_for_trasferring_large_file/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/gavin-blog.min.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Gavin change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->

<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Gavin Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="gavinblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/index.html">Home</a>
                    </li>
                    
                    
                    
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="/archive/">Archive</a>
                    </li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#gavinblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __GavinNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __GavinNav__.close()
        }else{
            __GavinNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close GavinNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __GavinNav__.close();
    })
</script>


    <!-- Post Header -->



<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/home-bg.jpg');
        background: ;
    }

    
</style>

<header class="intro-header" >

    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=Linux" title="Linux">Linux</a>
                        
                    </div>
                    <h1>Demo for trasferring large file from break point</h1>
                    
                    <h2 class="subheading">Demo for trasferring large file from break point</h2>
                    <span class="meta">Posted by Gavin on January 10, 2021</span>
                </div>
            </div>
        </div>
    </div>
</header>






<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<h1 id="overview">Overview</h1>

<p>Daemon of python script tools to transfer larger of S3 Objects</p>

<h2 id="file-list">File list</h2>

<ul>
  <li><code class="highlighter-rouge">bigtera_download_file.py</code> for downloading file from S3 from breakpoint</li>
  <li><code class="highlighter-rouge">bigtera_multipart_upload.py</code> for uploading file to S3 from breakpoint</li>
  <li><code class="highlighter-rouge">obsync.py</code> for RRS to S3 from breakpoint</li>
</ul>

<h2 id="usage">Usage</h2>

<h3 id="setup-environment">Setup environment</h3>

<ol>
  <li>Install Python2.7</li>
  <li>Install library</li>
</ol>

<p>Run the following command in command line</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>pip install boto
pip install filechunkio
</pre></td></tr></tbody></table></code></pre></div></div>

<ol>
  <li>Create S3 account and  bucket in cluster</li>
</ol>

<h3 id="configuration">Configuration</h3>

<p>Change configuration in the head part of <code class="highlighter-rouge">bigtera_download_file.py</code>  and <code class="highlighter-rouge">bigtera_multipart_upload.py</code></p>

<h3 id="test-downloading-file-from-breakpoint">Test downloading file from breakpoint</h3>

<ol>
  <li>Run <code class="highlighter-rouge">python bigtera_download_file.py</code> in command line</li>
  <li><code class="highlighter-rouge">CTRL+C</code> to stop downloading process</li>
  <li>Run <code class="highlighter-rouge">python bigtera_download_file.py</code> again</li>
  <li>Check downloading status</li>
</ol>

<h3 id="test-uploading-file-from-breakpoint">Test uploading file from breakpoint</h3>

<ol>
  <li>Run <code class="highlighter-rouge">python bigtera_multipart_upload.py</code> in command line</li>
  <li><code class="highlighter-rouge">CTRL+C</code> to stop uploading process</li>
  <li>Run <code class="highlighter-rouge">python bigtera_multipart_upload.py</code> again</li>
  <li>Check uploading status</li>
</ol>

<h3 id="content-of-scripts">Content of Scripts</h3>
<p>bigtera_download_file.py</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
</pre></td><td class="rouge-code"><pre><span class="c1">#!/usr/bin/env python
</span>
<span class="kn">from</span> <span class="nn">boto.s3.connection</span> <span class="kn">import</span> <span class="n">S3Connection</span>
<span class="kn">from</span> <span class="nn">boto.s3.connection</span> <span class="kn">import</span> <span class="n">OrdinaryCallingFormat</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">StringIO</span> <span class="kn">import</span> <span class="n">StringIO</span>
<span class="kn">import</span> <span class="nn">configparser</span>


<span class="n">HOST</span> <span class="o">=</span> <span class="s">'172.17.59.72'</span>
<span class="n">S3_AK</span> <span class="o">=</span> <span class="s">'JF06KCDJIAMO8Q3OJQAS'</span>
<span class="n">S3_AS</span> <span class="o">=</span> <span class="s">'gHnrKj1Vlb6s9IQZRrMDywhTLeNBL2UUMCGeetsf'</span>
<span class="n">S3_BUCKET</span> <span class="o">=</span> <span class="s">'andy_bucket'</span>
<span class="n">S3_KEY</span> <span class="o">=</span> <span class="s">'ubuntu-16.04-server-amd64.iso'</span>
<span class="n">LOCAL_FILE</span> <span class="o">=</span> <span class="s">'E:</span><span class="se">\\</span><span class="s">code</span><span class="se">\\</span><span class="s">s3_multipart_upload</span><span class="se">\\</span><span class="s">localfile.iso'</span>

<span class="c1"># Use a chunk size of 10 MiB (feel free to change this, &gt;=5MB)
</span><span class="n">CHUNK_SIZE</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">10</span>


<span class="k">def</span> <span class="nf">create_s3_connection</span><span class="p">():</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">S3Connection</span><span class="p">(</span><span class="n">calling_format</span><span class="o">=</span><span class="n">OrdinaryCallingFormat</span><span class="p">(),</span>
                     <span class="n">host</span><span class="o">=</span><span class="n">HOST</span><span class="p">,</span> <span class="n">is_secure</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                     <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">S3_AK</span><span class="p">,</span>
                     <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">S3_AS</span><span class="p">,</span>
                     <span class="n">validate_certs</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">c</span>


<span class="k">def</span> <span class="nf">get_obj_io_ctx</span><span class="p">(</span><span class="n">s3_key_obj</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">s3_key_obj</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">None</span>
    <span class="n">io_ctx</span> <span class="o">=</span> <span class="n">StringIO</span><span class="p">()</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="n">offset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"Range"</span><span class="p">:</span> <span class="s">"bytes={}-{}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">offset</span><span class="o">+</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="n">s3_key_obj</span><span class="p">.</span><span class="n">get_contents_to_file</span><span class="p">(</span><span class="n">io_ctx</span><span class="p">,</span> <span class="n">headers</span><span class="p">)</span>
    <span class="n">io_ctx</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">io_ctx</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">create_s3_connection</span><span class="p">()</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">get_bucket</span><span class="p">(</span><span class="n">S3_BUCKET</span><span class="p">)</span>

    <span class="n">key</span> <span class="o">=</span> <span class="n">S3_KEY</span>
    <span class="n">config_file</span> <span class="o">=</span> <span class="s">'.'</span> <span class="o">+</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">basename</span><span class="p">(</span><span class="n">LOCAL_FILE</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.conf'</span>

    <span class="n">s3_key_obj</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">get_key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">s3_key_obj</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s">" does't exists!"</span><span class="p">)</span>
        <span class="nb">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">total_file_size</span> <span class="o">=</span> <span class="n">s3_key_obj</span><span class="p">.</span><span class="n">size</span>
    <span class="n">remaining</span> <span class="o">=</span> <span class="n">total_file_size</span>

    <span class="n">part_size</span> <span class="o">=</span> <span class="n">CHUNK_SIZE</span>
    <span class="n">part_num</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">config</span> <span class="o">=</span> <span class="n">configparser</span><span class="p">.</span><span class="n">ConfigParser</span><span class="p">()</span>
    <span class="n">config</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>

    <span class="n">stored_total_file_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">getint</span><span class="p">(</span><span class="s">"bigtera_config"</span><span class="p">,</span> <span class="s">"total_file_size"</span><span class="p">,</span> <span class="n">fallback</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">stored_chunk_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">getint</span><span class="p">(</span><span class="s">"bigtera_config"</span><span class="p">,</span> <span class="s">"chunk_size"</span><span class="p">,</span> <span class="n">fallback</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">stored_downloaded_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">getint</span><span class="p">(</span><span class="s">"bigtera_config"</span><span class="p">,</span> <span class="s">"downloaded_size"</span><span class="p">,</span> <span class="n">fallback</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">seek_first</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="k">if</span> <span class="n">stored_total_file_size</span> <span class="o">==</span> <span class="n">total_file_size</span> <span class="ow">and</span> <span class="n">stored_chunk_size</span> <span class="o">==</span> <span class="n">CHUNK_SIZE</span><span class="p">:</span>
        <span class="n">remaining</span> <span class="o">=</span> <span class="n">stored_total_file_size</span> <span class="o">-</span> <span class="n">stored_downloaded_size</span>
        <span class="n">part_num</span> <span class="o">=</span> <span class="n">stored_downloaded_size</span> <span class="o">/</span> <span class="n">stored_chunk_size</span>
        <span class="n">open_option</span> <span class="o">=</span> <span class="s">"r+b"</span>
        <span class="n">seek_first</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">open_option</span> <span class="o">=</span> <span class="s">"wb"</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">LOCAL_FILE</span><span class="p">,</span> <span class="n">open_option</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">while</span> <span class="n">remaining</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">part_num</span> <span class="o">*</span> <span class="n">part_size</span>
            <span class="n">length</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">remaining</span><span class="p">,</span> <span class="n">part_size</span><span class="p">)</span>
            <span class="n">s3_obj_io_ctx</span> <span class="o">=</span> <span class="n">get_obj_io_ctx</span><span class="p">(</span><span class="n">s3_key_obj</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">length</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">seek_first</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
                <span class="n">seek_first</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">s3_obj_io_ctx</span><span class="p">.</span><span class="n">read</span><span class="p">())</span>
            <span class="n">remaining</span> <span class="o">=</span> <span class="n">remaining</span> <span class="o">-</span> <span class="n">length</span>

            <span class="n">downloaded_size</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">length</span>
            <span class="n">percentage</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">downloaded_size</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="n">total_file_size</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">percentage</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>
                <span class="n">percentage</span> <span class="o">=</span> <span class="mi">100</span>
            <span class="k">print</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">downloaded_size</span><span class="p">)</span> <span class="o">+</span> <span class="s">'/'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">total_file_size</span><span class="p">)</span> <span class="o">+</span> <span class="s">'  '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">percentage</span><span class="p">)</span> <span class="o">+</span> <span class="s">'%'</span><span class="p">)</span>

            <span class="n">part_num</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">configfile</span><span class="p">:</span>
                <span class="n">config</span><span class="p">[</span><span class="s">'bigtera_config'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">config</span><span class="p">[</span><span class="s">'bigtera_config'</span><span class="p">][</span><span class="s">'total_file_size'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">total_file_size</span><span class="p">)</span>
                <span class="n">config</span><span class="p">[</span><span class="s">'bigtera_config'</span><span class="p">][</span><span class="s">'chunk_size'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">CHUNK_SIZE</span><span class="p">)</span>
                <span class="n">config</span><span class="p">[</span><span class="s">'bigtera_config'</span><span class="p">][</span><span class="s">'downloaded_size'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">downloaded_size</span><span class="p">)</span>

                <span class="n">config</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">configfile</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">total_file_size</span> <span class="o">==</span> <span class="n">downloaded_size</span><span class="p">:</span>
                <span class="n">os</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>bigtera_multipart_upload.py</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
</pre></td><td class="rouge-code"><pre><span class="c1">#!/usr/bin/env python
</span>
<span class="kn">from</span> <span class="nn">boto.s3.connection</span> <span class="kn">import</span> <span class="n">S3Connection</span>
<span class="kn">from</span> <span class="nn">boto.s3.connection</span> <span class="kn">import</span> <span class="n">OrdinaryCallingFormat</span>
<span class="kn">from</span> <span class="nn">boto.s3.multipart</span> <span class="kn">import</span> <span class="n">MultiPartUpload</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">filechunkio</span> <span class="kn">import</span> <span class="n">FileChunkIO</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="c1"># import time
</span>

<span class="n">HOST</span> <span class="o">=</span> <span class="s">'172.17.59.72'</span>
<span class="n">S3_AK</span> <span class="o">=</span> <span class="s">'JF06KCDJIAMO8Q3OJQAS'</span>
<span class="n">S3_AS</span> <span class="o">=</span> <span class="s">'gHnrKj1Vlb6s9IQZRrMDywhTLeNBL2UUMCGeetsf'</span>
<span class="n">S3_BUCKET</span> <span class="o">=</span> <span class="s">'andy_bucket'</span>

<span class="n">LARGE_FILE</span> <span class="o">=</span> <span class="s">'E:</span><span class="se">\\</span><span class="s">code</span><span class="se">\\</span><span class="s">s3_multipart_upload</span><span class="se">\\</span><span class="s">ubuntu-16.04-server-amd64.iso'</span>

<span class="c1"># Use a chunk size of 10 MiB (feel free to change this, &gt;=5MB)
</span><span class="n">CHUNK_SIZE</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">10</span>


<span class="k">def</span> <span class="nf">create_s3_connection</span><span class="p">():</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">S3Connection</span><span class="p">(</span><span class="n">calling_format</span><span class="o">=</span><span class="n">OrdinaryCallingFormat</span><span class="p">(),</span>
                     <span class="n">host</span><span class="o">=</span><span class="n">HOST</span><span class="p">,</span> <span class="n">is_secure</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                     <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">S3_AK</span><span class="p">,</span>
                     <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">S3_AS</span><span class="p">,</span>
                     <span class="n">validate_certs</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">c</span>


<span class="k">def</span> <span class="nf">query_pending_parts</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
    <span class="n">response_all_multipart_upload</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># print('Current pending parts in S3:')
</span>    <span class="n">multipart_uploads_filter</span> <span class="o">=</span> <span class="p">{</span><span class="s">'key_marker'</span><span class="p">:</span> <span class="n">key</span><span class="p">}</span>
    <span class="n">all_multipart_uploads</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">get_all_multipart_uploads</span><span class="p">(</span><span class="o">**</span><span class="n">multipart_uploads_filter</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">one_multipart_upload</span> <span class="ow">in</span> <span class="n">all_multipart_uploads</span><span class="p">:</span>
        <span class="n">response_multipart_upload</span> <span class="o">=</span> <span class="p">{</span><span class="s">'key'</span><span class="p">:</span> <span class="n">one_multipart_upload</span><span class="p">.</span><span class="n">key_name</span><span class="p">,</span>
                                     <span class="s">'upload_id'</span><span class="p">:</span> <span class="n">one_multipart_upload</span><span class="p">.</span><span class="nb">id</span><span class="p">,</span>
                                     <span class="s">'parts'</span><span class="p">:</span> <span class="p">[]</span>
                                     <span class="p">}</span>
        <span class="n">mp</span> <span class="o">=</span> <span class="n">MultiPartUpload</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="n">mp</span><span class="p">.</span><span class="n">key_name</span> <span class="o">=</span> <span class="n">one_multipart_upload</span><span class="p">.</span><span class="n">key_name</span>
        <span class="n">mp</span><span class="p">.</span><span class="n">bucket_name</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">name</span>
        <span class="n">mp</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="n">one_multipart_upload</span><span class="p">.</span><span class="nb">id</span>
        <span class="n">all_parts</span> <span class="o">=</span> <span class="n">mp</span><span class="p">.</span><span class="n">get_all_parts</span><span class="p">()</span>
        <span class="n">one_multipart_upload_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_parts</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">' upload_id:'</span> <span class="o">+</span> <span class="n">one_multipart_upload</span><span class="p">.</span><span class="nb">id</span> <span class="o">+</span> <span class="s">'   key:'</span> <span class="o">+</span> <span class="n">one_multipart_upload</span><span class="p">.</span><span class="n">key_name</span> <span class="o">+</span>
              <span class="s">'        parts:'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">one_multipart_upload_len</span><span class="p">))</span>
        <span class="c1"># print('one_multipart_upload length:' + str(one_multipart_upload_len))
</span>        <span class="k">for</span> <span class="n">one_parts</span> <span class="ow">in</span> <span class="n">all_parts</span><span class="p">:</span>
            <span class="n">response_part</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">'part_number'</span><span class="p">:</span> <span class="n">one_parts</span><span class="p">.</span><span class="n">part_number</span><span class="p">,</span>
                <span class="s">'etag'</span><span class="p">:</span> <span class="n">one_parts</span><span class="p">.</span><span class="n">etag</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'"'</span><span class="p">,</span> <span class="s">''</span><span class="p">),</span>
                <span class="s">'size'</span><span class="p">:</span> <span class="n">one_parts</span><span class="p">.</span><span class="n">size</span>
            <span class="p">}</span>
            <span class="n">response_multipart_upload</span><span class="p">[</span><span class="s">'parts'</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">response_part</span><span class="p">)</span>
        <span class="n">response_all_multipart_upload</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">response_multipart_upload</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">response_all_multipart_upload</span>


<span class="k">def</span> <span class="nf">upload_left</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">full_file_path</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">pending_multipart_upload</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>

    <span class="n">source_size</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">stat</span><span class="p">(</span><span class="n">full_file_path</span><span class="p">).</span><span class="n">st_size</span>

    <span class="n">pending_upload_id</span> <span class="o">=</span> <span class="n">pending_multipart_upload</span><span class="p">[</span><span class="s">'upload_id'</span><span class="p">]</span>
    <span class="c1"># pending_key = pending_multipart_upload['key']
</span>
    <span class="n">mp</span> <span class="o">=</span> <span class="n">MultiPartUpload</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">mp</span><span class="p">.</span><span class="n">key_name</span> <span class="o">=</span> <span class="n">key</span>
    <span class="n">mp</span><span class="p">.</span><span class="n">bucket_name</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">name</span>
    <span class="n">mp</span><span class="p">.</span><span class="nb">id</span> <span class="o">=</span> <span class="n">pending_upload_id</span>

    <span class="c1"># Use a chunk size of 10 MiB (feel free to change this)
</span>    <span class="c1"># chunk_size = 1024 * 1024 * 10
</span>    <span class="c1"># chunk_size = CHUNK_SIZE
</span>    <span class="n">chunk_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">source_size</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">)))</span>

    <span class="c1"># Send the file parts, using FileChunkIO to create a file-like object
</span>    <span class="c1"># that points to a certain byte range within the original file. We
</span>    <span class="c1"># set bytes to never exceed the original file size.
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">chunk_count</span><span class="p">):</span>
        <span class="n">part_num</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">chunk_size</span> <span class="o">*</span> <span class="n">i</span>
        <span class="n">upload_bytes</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="n">source_size</span> <span class="o">-</span> <span class="n">offset</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">FileChunkIO</span><span class="p">(</span><span class="n">full_file_path</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="nb">bytes</span><span class="o">=</span><span class="n">upload_bytes</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="n">md5</span><span class="p">()</span>
            <span class="n">m</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">fp</span><span class="p">.</span><span class="n">readall</span><span class="p">())</span>
            <span class="n">chunk_md5</span> <span class="o">=</span> <span class="nb">unicode</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">hexdigest</span><span class="p">())</span>
            <span class="n">found_part</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">for</span> <span class="n">one_part</span> <span class="ow">in</span> <span class="n">pending_multipart_upload</span><span class="p">[</span><span class="s">'parts'</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">part_num</span> <span class="o">==</span> <span class="n">one_part</span><span class="p">[</span><span class="s">'part_number'</span><span class="p">]</span> <span class="ow">and</span> \
                        <span class="n">upload_bytes</span> <span class="o">==</span> <span class="n">one_part</span><span class="p">[</span><span class="s">'size'</span><span class="p">]</span> <span class="ow">and</span> \
                        <span class="n">chunk_md5</span> <span class="o">==</span> <span class="n">one_part</span><span class="p">[</span><span class="s">'etag'</span><span class="p">]:</span>
                    <span class="c1"># print(one_part)
</span>                    <span class="n">found_part</span> <span class="o">=</span> <span class="bp">True</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">found_part</span> <span class="ow">is</span> <span class="bp">True</span><span class="p">:</span>
                <span class="c1"># pass
</span>                <span class="k">continue</span>
            <span class="n">fp</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">mp</span><span class="p">.</span><span class="n">upload_part_from_file</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">part_num</span><span class="o">=</span><span class="n">part_num</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'%d/%d uploaded'</span> <span class="o">%</span> <span class="p">(</span><span class="n">part_num</span><span class="p">,</span> <span class="n">chunk_count</span><span class="p">))</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Finish the upload
</span>        <span class="k">return</span> <span class="n">mp</span><span class="p">.</span><span class="n">complete_upload</span><span class="p">()</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">mp</span><span class="p">.</span><span class="n">cancel_upload</span><span class="p">()</span>
        <span class="k">raise</span> <span class="n">e</span>


<span class="k">def</span> <span class="nf">upload_large_file</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">full_file_path</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
    <span class="c1"># 100MB
</span>    <span class="n">large_file_threshold</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>

    <span class="k">if</span> <span class="n">chunk_size</span> <span class="o">&lt;</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">:</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>

    <span class="n">all_pending_multipart_uploads</span> <span class="o">=</span> <span class="n">query_pending_parts</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>

    <span class="c1"># Get file info
</span>    <span class="n">source_size</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">stat</span><span class="p">(</span><span class="n">full_file_path</span><span class="p">).</span><span class="n">st_size</span>

    <span class="n">pending_multipart_upload</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">one_pending_multipart_upload</span> <span class="ow">in</span> <span class="n">all_pending_multipart_uploads</span><span class="p">:</span>
        <span class="c1"># In real product,we need check file-key-upload_id relation
</span>        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="n">one_pending_multipart_upload</span><span class="p">[</span><span class="s">'key'</span><span class="p">]:</span>
            <span class="n">pending_multipart_upload</span> <span class="o">=</span> <span class="n">one_pending_multipart_upload</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="n">source_size</span> <span class="o">&gt;=</span> <span class="n">large_file_threshold</span> <span class="ow">and</span> <span class="n">pending_multipart_upload</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'keep uploading!'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">upload_left</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">full_file_path</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">pending_multipart_upload</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'No pending upload exits! Upload_from_beginning!'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">upload_from_beginning</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">full_file_path</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">upload_from_beginning</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">full_file_path</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>

    <span class="n">source_size</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">stat</span><span class="p">(</span><span class="n">full_file_path</span><span class="p">).</span><span class="n">st_size</span>

    <span class="c1"># Create a multipart upload request
</span>    <span class="n">mp</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">initiate_multipart_upload</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="c1"># keep file-key-upload_id relation for production use
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'Uploading file:'</span> <span class="o">+</span> <span class="n">full_file_path</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Key in S3:'</span> <span class="o">+</span> <span class="n">key</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'upload_id:'</span> <span class="o">+</span> <span class="n">mp</span><span class="p">.</span><span class="nb">id</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'--------------------'</span><span class="p">)</span>

    <span class="c1"># Use a chunk size of 10 MiB (feel free to change this)
</span>    <span class="c1"># chunk_size = 1024 * 1024 * 10
</span>    <span class="c1"># chunk_size = CHUNK_SIZE
</span>    <span class="n">chunk_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">source_size</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">)))</span>

    <span class="c1"># Send the file parts, using FileChunkIO to create a file-like object
</span>    <span class="c1"># that points to a certain byte range within the original file. We
</span>    <span class="c1"># set bytes to never exceed the original file size.
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">chunk_count</span><span class="p">):</span>
        <span class="n">part_num</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">chunk_size</span> <span class="o">*</span> <span class="n">i</span>
        <span class="n">upload_bytes</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="n">source_size</span> <span class="o">-</span> <span class="n">offset</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">FileChunkIO</span><span class="p">(</span><span class="n">full_file_path</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span> <span class="nb">bytes</span><span class="o">=</span><span class="n">upload_bytes</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">mp</span><span class="p">.</span><span class="n">upload_part_from_file</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="n">part_num</span><span class="o">=</span><span class="n">part_num</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="s">'%d/%d uploaded'</span> <span class="o">%</span> <span class="p">(</span><span class="n">part_num</span><span class="p">,</span> <span class="n">chunk_count</span><span class="p">))</span>
        <span class="c1"># print('sleeping 1 second ...')
</span>        <span class="c1"># time.sleep(1)
</span>    <span class="k">return</span> <span class="n">mp</span><span class="p">.</span><span class="n">complete_upload</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">create_s3_connection</span><span class="p">()</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">get_bucket</span><span class="p">(</span><span class="n">S3_BUCKET</span><span class="p">)</span>

    <span class="n">full_file_path</span> <span class="o">=</span> <span class="n">LARGE_FILE</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">basename</span><span class="p">(</span><span class="n">full_file_path</span><span class="p">)</span>

    <span class="n">upload_large_file</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">full_file_path</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">CHUNK_SIZE</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>obsync.py</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661
662
663
664
665
666
667
668
669
670
671
672
673
674
675
676
677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761
762
763
764
765
766
767
768
769
770
771
772
773
774
775
776
777
778
779
780
781
782
783
784
785
786
787
788
789
790
791
792
793
794
795
796
797
798
799
800
801
802
803
804
805
806
807
808
809
810
811
812
813
814
815
816
817
818
819
820
821
822
823
824
825
826
827
828
829
830
831
832
833
834
835
836
837
838
839
840
841
842
843
844
845
846
847
848
849
850
851
852
853
854
855
856
857
858
859
860
861
862
863
864
865
866
867
868
869
870
871
872
873
874
875
876
877
878
879
880
881
882
883
884
885
886
887
888
889
890
891
892
893
894
895
896
897
898
899
900
901
902
903
904
905
906
907
908
909
910
911
912
913
914
915
916
917
918
919
920
921
922
923
924
925
926
927
928
929
930
931
932
933
934
935
936
937
938
939
940
941
942
943
944
945
946
947
948
949
950
951
952
953
954
955
956
957
958
959
960
961
962
963
964
965
966
967
968
969
970
971
972
973
974
975
976
977
978
979
980
981
982
983
984
985
986
987
988
989
990
991
992
993
994
995
996
997
998
999
1000
1001
1002
1003
1004
1005
1006
1007
1008
1009
1010
1011
1012
1013
1014
1015
1016
1017
1018
1019
1020
1021
1022
1023
1024
1025
1026
1027
1028
1029
1030
1031
1032
1033
1034
1035
1036
1037
1038
1039
1040
1041
1042
1043
1044
1045
1046
1047
1048
1049
1050
1051
1052
1053
1054
1055
1056
1057
1058
1059
1060
1061
1062
1063
1064
1065
1066
1067
1068
1069
1070
1071
1072
1073
1074
1075
1076
1077
1078
1079
1080
1081
1082
1083
1084
1085
1086
1087
1088
1089
1090
1091
1092
1093
1094
1095
1096
1097
1098
1099
1100
1101
1102
1103
1104
1105
1106
1107
1108
1109
1110
1111
1112
1113
1114
1115
1116
1117
1118
1119
1120
1121
1122
1123
1124
1125
1126
1127
1128
1129
1130
1131
1132
1133
1134
1135
1136
1137
1138
1139
1140
1141
1142
1143
1144
1145
1146
1147
1148
1149
1150
1151
1152
1153
1154
1155
1156
1157
1158
1159
1160
1161
1162
1163
1164
1165
1166
1167
1168
1169
1170
1171
1172
1173
1174
1175
1176
1177
1178
1179
1180
1181
1182
1183
1184
1185
1186
1187
1188
1189
1190
1191
1192
1193
1194
1195
1196
1197
1198
1199
1200
1201
1202
1203
1204
1205
1206
1207
1208
1209
1210
1211
1212
1213
1214
1215
1216
1217
1218
1219
1220
1221
1222
1223
1224
1225
1226
1227
1228
1229
1230
1231
1232
1233
1234
1235
1236
1237
1238
1239
1240
1241
1242
1243
1244
1245
1246
1247
1248
1249
1250
1251
1252
1253
1254
1255
1256
1257
1258
1259
1260
1261
1262
1263
1264
1265
1266
1267
1268
1269
1270
1271
1272
1273
1274
1275
1276
1277
1278
1279
1280
1281
1282
1283
1284
1285
1286
1287
1288
1289
1290
1291
1292
1293
1294
1295
1296
1297
1298
1299
1300
1301
1302
1303
1304
1305
1306
1307
1308
1309
1310
1311
1312
1313
1314
1315
1316
1317
1318
1319
1320
1321
1322
1323
1324
1325
1326
1327
1328
1329
1330
1331
1332
1333
1334
1335
1336
1337
1338
</pre></td><td class="rouge-code"><pre>"""
obsync.py: common library for ezobsync and s3backup
"""
from boto.exception import S3ResponseError
from boto.s3.connection import OrdinaryCallingFormat, SubdomainCallingFormat
from boto.s3.connection import S3Connection
from boto.s3.key import Key
from boto.s3.multipart import MultiPartUpload
from lxml import etree
from ezs3.log import EZLog
import boto
import errno
import hashlib
import os
from StringIO import StringIO
import tempfile
import time
import traceback
import xattr
import shutil

try:
    import cloudfiles
except ImportError:
    cloudfiles = None

logger = EZLog.get_logger(__name__)

ACL_XATTR = "rados.acl"
META_XATTR_PREFIX = "rados.meta."
BREAK_POINT_META = "break_point"
CONTENT_TYPE_XATTR = "rados.content_type"
# for FileStore xattr
SRC_MULTIPART_ETAG_XATTR = "rados.meta.srcetag"
MD5_XATTR = "rados.md5"
MTIME_XATTR = "rados.mtime"

# It is also in-memory chunk size; don't set it too large!
MULTIPART_THRESH = 10485760
# For S3 backup from breakpoint,100MB
BREAKPOINT_THRESHOLD = 100 * 1024 * 1024


class ObsyncException(Exception):
    def __init__(self, ty, e):
        if (isinstance(e, str)):
            # from a string
            self.tb = "".join(traceback.format_stack())
            self.comment = e
        else:
            # from another exception
            self.tb = traceback.format_exc(100000)
            self.comment = None
        self.ty = ty


class ObsyncTemporaryException(ObsyncException):
    """
    A temporary obsync exception.
    The user may want to retry the operation that failed.
    We can create one of these from a string or from another exception.
    """
    def __init__(self, e):
        ObsyncException.__init__(self, "temporary", e)


class ObsyncPermanentException(ObsyncException):
    """
    A permanent obsync exception.
    We can create one of these from a string or from another exception.
    """
    def __init__(self, e):
        ObsyncException.__init__(self, "permanent", e)


def test_xattr_support(path):
    test_file = path + "/$TEST"
    f = open(test_file, 'w')
    f.close
    try:
        xattr.set(test_file, "test", "123", namespace=xattr.NS_USER)
        if xattr.get(test_file, "test", namespace=xattr.NS_USER) != "123":
            raise ObsyncPermanentException(
                "test_xattr_support: failed to set an xattr and "
                "read it back.")
    except IOError:
        exc = "You do not appear to have xattr support at {}".format(path)
        logger.error(exc)
        raise ObsyncPermanentException(exc)
    finally:
        os.unlink(test_file)


def xattr_is_metadata(k):
    # miscellaneous user-defined metadata
    if (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
        return True
    # content-type
    elif (k == CONTENT_TYPE_XATTR):
        return True
    return False


def mkdir_p(path):
    try:
        os.makedirs(path)
    except OSError, exc:
        if exc.errno != errno.EEXIST:
            raise ObsyncTemporaryException(exc)
        if not os.path.isdir(path):
            raise ObsyncTemporaryException(exc)


def bytes_to_str(b):
    return ''.join(["%02x" % ord(x) for x in b]).strip()


def get_md5(f, block_size=2**20):
    mtime = os.stat(f.name).st_mtime
    try:
        stored_md5 = xattr.get(f.name, MD5_XATTR, namespace=xattr.NS_USER)
        stored_mtime = xattr.get(f.name, MTIME_XATTR, namespace=xattr.NS_USER)
        if str(mtime) == stored_mtime:
            return stored_md5
    except IOError as e:
        if e.errno != errno.ENODATA:
            raise

    md5 = hashlib.md5()
    while True:
        data = f.read(block_size)
        if not data:
            break
        md5.update(data)
    md5sum = md5.hexdigest()
    file_set_md5(f.name, md5sum, mtime)

    return md5sum


def file_set_md5(path, md5, mtime=None):
    if not mtime:
        mtime = str(os.stat(path).st_mtime)
    xattr.set(path, MD5_XATTR, md5, namespace=xattr.NS_USER)
    xattr.set(path, MTIME_XATTR, str(mtime), namespace=xattr.NS_USER)


def strip_prefix(prefix, s):
    if not (s[0:len(prefix)] == prefix):
        return None
    return s[len(prefix):]


def etag_to_md5(etag):
    if (etag[:1] == '"'):
        start = 1
    else:
        start = 0
    if (etag[-1:] == '"'):
        end = -1
    else:
        end = None
    return etag[start:end]


# Escaping functions.
#
# Valid names for local files are a little different than valid object
# names for S3. So these functions are needed to translate.
#
# Basically, in local names, every sequence starting with a dollar sign is
# reserved as a special escape sequence. If you want to create an S3 object
# with a dollar sign in the name, the local file should have a double dollar
# sign ($$).
#
# TODO: translate local files' control characters into escape sequences.
# Most S3 clients (boto included) cannot handle control characters in S3 object
# names.
# TODO: check for invalid utf-8 in local file names. Ideally, escape it, but
# if not, just reject the local file name. S3 object names must be valid
# utf-8.
#
# ----------        -----------
# In S3             Locally
# ----------        -----------
# foo/              foo$slash
#
# $money            $$money
#
# obj-with-acl      obj-with-acl
#                  .obj-with-acl$acl
def s3_name_to_local_name(s3_name):
    # Now we treat an object which names end with slash as a local folder
    return s3_name

def local_name_to_s3_name(local_name):
    # Now we treat a local folder as a prefix object
    return local_name

###### ACLs #######
READ = 1
WRITE = 2
READ_ACP = 4
WRITE_ACP = 8
FULL_CONTROL = READ | WRITE | READ_ACP | WRITE_ACP

PERM_MAP = {
    "FULL_CONTROL": FULL_CONTROL,
    "READ": READ,
    "WRITE": WRITE,
    "READ_ACP": READ_ACP,
    "WRITE_ACP": WRITE_ACP
}


def perm_to_str_list(perm):
    perms = []
    if perm == FULL_CONTROL:
        perms.append("FULL_CONTROL")
    elif (perm &amp; READ):
        perms.append("READ")
    elif (perm &amp; WRITE):
        perms.append("WRITE")
    elif (perm &amp; READ_ACP):
        perms.append("READ_ACP")
    elif (perm &amp; WRITE_ACP):
        perms.append("WRITE_ACP")
    return perms


ACL_TYPE_CANON_USER = "canon:"
ACL_TYPE_EMAIL_USER = "email:"
ACL_TYPE_GROUP = "group:"
ALL_ACL_TYPES = [ACL_TYPE_CANON_USER, ACL_TYPE_EMAIL_USER, ACL_TYPE_GROUP]

S3_GROUP_AUTH_USERS = ACL_TYPE_GROUP + "AuthenticatedUsers"
S3_GROUP_ALL_USERS = ACL_TYPE_GROUP + "AllUsers"
S3_GROUP_LOG_DELIVERY = ACL_TYPE_GROUP + "LogDelivery"

NS = "http://s3.amazonaws.com/doc/2006-03-01/"
NS2 = "http://www.w3.org/2001/XMLSchema-instance"


def get_user_type(utype):
    for ut in [ACL_TYPE_CANON_USER, ACL_TYPE_EMAIL_USER, ACL_TYPE_GROUP]:
        if utype[:len(ut)] == ut:
            return ut
    raise ObsyncPermanentException("unknown user type for user %s" % utype)


def strip_user_type(utype):
    for ut in [ACL_TYPE_CANON_USER, ACL_TYPE_EMAIL_USER, ACL_TYPE_GROUP]:
        if utype[:len(ut)] == ut:
            return utype[len(ut):]
    raise ObsyncPermanentException("unknown user type for user %s" % utype)


def grantee_attribute_to_user_type(utype):
    if (utype == "Canonical User"):
        return ACL_TYPE_CANON_USER
    elif (utype == "CanonicalUser"):
        return ACL_TYPE_CANON_USER
    elif (utype == "Group"):
        return ACL_TYPE_GROUP
    elif (utype == "Email User"):
        return ACL_TYPE_EMAIL_USER
    elif (utype == "EmailUser"):
        return ACL_TYPE_EMAIL_USER
    else:
        raise ObsyncPermanentException("unknown user type for user %s" % utype)


def user_type_to_attr(t):
    if (t == ACL_TYPE_CANON_USER):
        return "CanonicalUser"
    elif (t == ACL_TYPE_GROUP):
        return "Group"
    elif (t == ACL_TYPE_EMAIL_USER):
        return "EmailUser"
    else:
        raise ObsyncPermanentException("unknown user type %s" % t)


def add_user_type(user):
    """
    All users that are not specifically marked as something else
    are treated as canonical users
    """
    for atype in ALL_ACL_TYPES:
        if (user[:len(atype)] == atype):
            return user
    return ACL_TYPE_CANON_USER + user


class AclGrant(object):
    def __init__(self, user_id, display_name, permission):
        self.user_id = user_id
        self.display_name = display_name
        self.permission = permission

    def translate_users(self, xusers):
        # Keep in mind that xusers contains user_ids of the form "type:value"
        # So typical contents might be like { canon:XYZ =&gt; canon.123 }
        if self.user_id in xusers:
            self.user_id = xusers[self.user_id]
            # It's not clear what the new pretty-name should be, so just leave it blank.
            self.display_name = None

    def equals(self, rhs):
        if self.user_id != rhs.user_id:
            return False
        if self.permission != rhs.permission:
            return False
        # ignore display_name
        return True


class AclPolicy(object):
    def __init__(self, owner_id, owner_display_name, grants):
        self.owner_id = owner_id
        self.owner_display_name = owner_display_name
        self.grants = grants  # dict of { string -&gt; ACLGrant }

    @staticmethod
    def create_default(owner_id):
        grants = {}
        grants[ACL_TYPE_CANON_USER + owner_id] = \
            AclGrant(ACL_TYPE_CANON_USER + owner_id, None, FULL_CONTROL)
        return AclPolicy(owner_id, None, grants)

    @staticmethod
    def from_xml(s):
        root = etree.parse(StringIO(s))

        owner_id_node = root.find("{%s}Owner/{%s}ID" % (NS, NS))
        owner_id = owner_id_node.text
        owner_display_name = root.find("{%s}Owner/{%s}DisplayName" % (NS, NS))
        if owner_display_name is not None:
            owner_display_name = owner_display_name.text

        grantlist = root.findall("{%s}AccessControlList/{%s}Grant" % (NS, NS))
        grants = {}

        for g in grantlist:
            grantee = g.find("{%s}Grantee" % NS)
            if "type" in grantee.attrib:
                grantee_type = grantee.attrib["type"]
            else:
                grantee_type = grantee.attrib["{%s}type" % NS2]

            user_type = grantee_attribute_to_user_type(grantee_type)

            if user_type == ACL_TYPE_CANON_USER:
                user_id = grantee.find("{%s}ID" % NS).text
                display_name = grantee.find("{%s}DisplayName" % NS)
                if display_name is not None:
                    display_name = display_name.text
            elif user_type == ACL_TYPE_EMAIL_USER:
                user_id = grantee.find("{%s}EmailAddress" % NS).text
                display_name = None
            elif user_type == ACL_TYPE_GROUP:
                user_id = grantee.find("{%s}URI" % NS).text
                display_name = None
            else:
                raise ObsyncPermanentException("unknown ACL grantee type")

            permission = g.find("{%s}Permission" % NS).text
            perm = PERM_MAP[permission]
            grant_user_id = user_type + user_id
            if grant_user_id not in grants:
                grants[grant_user_id] = AclGrant(grant_user_id, display_name, perm)
            else:
                grants[grant_user_id].permission |= perm

        return AclPolicy(owner_id, owner_display_name, grants)

    def to_xml(self):
        root = etree.Element("AccessControlPolicy", nsmap={None: NS})
        owner = etree.SubElement(root, "Owner")
        id_elem = etree.SubElement(owner, "ID")
        id_elem.text = self.owner_id
        if self.owner_display_name:
            display_name_elem = etree.SubElement(owner, "DisplayName")
            display_name_elem.text = self.owner_display_name

        access_control_list = etree.SubElement(root, "AccessControlList")
        for k, g in self.grants.items():
            perms = perm_to_str_list(g.permission)
            for perm in perms:
                grant_elem = etree.SubElement(access_control_list, "Grant")
                grantee_elem = etree.SubElement(
                    grant_elem, "{%s}Grantee" % NS, nsmap={None: NS, "xsi": NS2})

                user_type = get_user_type(g.user_id)
                grantee_elem.set("{%s}type" % NS2, user_type_to_attr(user_type))

                if user_type == ACL_TYPE_CANON_USER:
                    user_id_elem = etree.SubElement(grantee_elem, "{%s}ID" % NS)
                    user_id_elem.text = strip_user_type(g.user_id)
                    if g.display_name:
                        display_name_elem = etree.SubElement(
                            grantee_elem, "{%s}DisplayName" % NS)
                        display_name_elem.text = g.display_name
                elif user_type == ACL_TYPE_EMAIL_USER:
                    email_elem = etree.SubElement(
                        grantee_elem, "{%s}EmailAddress" % NS)
                    email_elem.text = strip_user_type(g.user_id)
                elif user_type == ACL_TYPE_GROUP:
                    group_elem = etree.SubElement(grantee_elem, "{%s}URI" % NS)
                    group_elem.text = strip_user_type(g.user_id)
                else:
                    raise ObsyncPermanentException("unknown ACL grantee type")

                permission_elem = etree.SubElement(grant_elem, "{%s}Permission" % NS)
                permission_elem.text = perm
        return etree.tostring(root, encoding="UTF-8")

    def translate_users(self, xusers):
        # Owner ids are always expressed in terms of canonical user id
        user = ACL_TYPE_CANON_USER + self.owner_id
        if (user in xusers):
            self.owner_id = strip_user_type(xusers[user])
            self.owner_display_name = ""

        for k, g in self.grants.items():
            g.translate_users(xusers)

    def get_all_users(self):
        """ Get a list of all user ids referenced in this ACL """
        users = {}
        users[ACL_TYPE_CANON_USER + self.owner_id] = 1
        for k, g in self.grants.items():
            users[k] = 1
        return users.keys()

    def set_owner(self, owner_id):
        self.owner_id = owner_id
        self.owner_display_name = ""

    def equals(self, rhs):
        if (self.owner_id != rhs.owner_id):
            return False
        for k, g in self.grants.items():
            if k not in rhs.grants:
                return False
            if not g.equals(rhs.grants[k]):
                return False
        for l, r in rhs.grants.items():
            if l not in self.grants:
                return False
            if not r.equals(self.grants[l]):
                return False
        return True


class Object(object):

    def __init__(self, name, md5, size, meta):
        if isinstance(name, unicode):
            self.name = name
        else:
            self.name = name.decode('UTF-8')
        self.md5 = md5
        self.size = int(size)
        if SRC_MULTIPART_ETAG_XATTR in meta:
            self.md5 = meta[SRC_MULTIPART_ETAG_XATTR]
            del meta[SRC_MULTIPART_ETAG_XATTR]
        self.meta = meta
        self.is_folder = False
        if name.endswith("/"):
            self.is_folder = True

    def __str__(self):
        return u"(name: {}, size: {}: md5: {}, meta: {}, is_folder: {})".format(self.name, self.size, self.md5, self.meta, self.is_folder)

    def should_check_etags(self, rhs, check_etags):
        if check_etags == "never":
            return False
        if check_etags == "relaxed":
            logger.debug(
                "ETAGS: --check-etags={0}, self.md5 = {1}, rhs.md5 = {2}"
                .format(check_etags, self.md5, rhs.md5)
            )
            return not ('-' in self.md5 or '-' in rhs.md5)
        return True

    def equals(self, rhs, ignore_empty_s3_meta=False, cmp_etag="always"):
        if self.is_folder and rhs.is_folder:
            if (self.name != rhs.name):
                logger.debug("EQUALS: self.name = %s, rhs.name = %s" % (self.name, rhs.name))
                return False
            return True
        else:
            if (self.name != rhs.name):
                logger.debug("EQUALS: self.name = %s, rhs.name = %s" % (self.name, rhs.name))
                return False
            if (self.should_check_etags(rhs, cmp_etag) and self.md5 != rhs.md5):
                logger.debug("EQUALS: self.md5 = %s, rhs.md5 = %s" % (self.md5, rhs.md5))
                return False
            if (self.size != rhs.size):
                logger.debug("EQUALS: self.size = %d, rhs.size = %d" % (self.size, rhs.size))
                return False
            for k, v in self.meta.items():
                if k not in rhs.meta:
                    logger.debug("EQUALS: rhs.meta lacks key %s" % k)
                    return False
                if (rhs.meta[k] != v):
                    logger.debug(
                        "EQUALS: self.meta[%s] = %s, rhs.meta[%s] = %s" % (k, v, k, rhs.meta[k])
                    )
                    return False
            if self.meta or not ignore_empty_s3_meta:
                for k, v in rhs.meta.items():
                    if k not in self.meta:
                        logger.debug("EQUALS: self.meta lacks key %s" % k)
                        return False
            logger.debug("EQUALS: the objects are equal.")
            return True

    def local_name(self):
        local_name = s3_name_to_local_name(self.name)
        if not isinstance(local_name, unicode):
            local_name = local_name.decode('UTF-8')
        return local_name

    def local_path(self, base):
        if not isinstance(base, unicode):
            base = base.decode('UTF-8')
        if self.is_folder:
            full_path = os.path.join(base, self.name)
        else:
            full_path = os.path.join(base, self.local_name())
        return full_path.encode('UTF-8')

    @staticmethod
    def from_file(obj_name, path):
        f = open(path, 'r')
        try:
            md5 = get_md5(f)
        finally:
            f.close()
        size = os.path.getsize(path)
        meta = {}
        try:
            xlist = xattr.get_all(path, namespace=xattr.NS_USER)
        except IOError, e:
            if e.errno == 2:
                return meta
            else:
                raise ObsyncTemporaryException(e)
        for k, v in xlist:
            if xattr_is_metadata(k):
                meta[k] = v
        #print "Object.from_file: path="+path+",md5=" + bytes_to_str(md5) +",size=" + str(size)
        return Object(obj_name, md5, size, meta)

    @staticmethod
    def from_folder(obj_name, path):
        return Object(obj_name, 'd41d8cd98f00b204e9800998ecf8427e', 0, {})


class Store(object):
    @staticmethod
    def make_store(type, is_dst, create, akey, skey, dry_run, **kwargs):
        if (type == 's3'):
            try:
                store = S3Store(kwargs['host'], kwargs['bucket'],
                                kwargs['prefix'], create, akey, skey, dry_run,
                                is_secure=True)
                logger.info("Connect to S3 store via HTTPS successfully.")
            except Exception as e:
                store = S3Store(kwargs['host'], kwargs['bucket'],
                                kwargs['prefix'], create, akey, skey, dry_run,
                                is_secure=False)
                logger.info("Connect to S3 store via HTTP successfully.")
            return store
        elif (type == 'swift'):
            return SwiftStore(kwargs['host'], kwargs['bucket'],
                              kwargs['prefix'], create, akey, skey, dry_run,
                              False)
        elif (type == 'file'):
            return FileStore(kwargs['path'], create, dry_run,
                             kwargs.get('follow_symlinks', False))
        raise ObsyncPermanentException('Unknown store type: "%s"' % type)


class LocalCopy(object):

    def __init__(self, obj_name, path, path_is_temp):
        self.obj_name = obj_name
        self.path = path
        self.path_is_temp = path_is_temp

    def remove(self):
        if self.path_is_temp and (self.path is not None):
            os.unlink(self.path)
        self.path = None
        self.path_is_temp = False

    def __del__(self):
        self.remove()


class LocalAcl(object):

    @staticmethod
    def from_xml(obj_name, xml):
        acl_policy = AclPolicy.from_xml(xml)
        return LocalAcl(obj_name, acl_policy)

    @staticmethod
    def get_empty(obj_name):
        return LocalAcl(obj_name, None)

    def __init__(self, obj_name, acl_policy):
        self.obj_name = obj_name
        self.acl_policy = acl_policy

    def equals(self, rhs, ignore_empty_s3_acl=False):
        """ Compare two LocalAcls """
        if self.acl_policy is None:
            return (ignore_empty_s3_acl or rhs.acl_policy is None)
        if rhs.acl_policy is None:
            return (self.acl_policy is None)
        return self.acl_policy.equals(rhs.acl_policy)

    def translate_users(self, xusers):
        """ Translate the users in this ACL """
        if (self.acl_policy is None):
            return
        self.acl_policy.translate_users(xusers)

    def set_owner(self, owner_id):
        if (self.acl_policy is None):
            return
        self.acl_policy.set_owner(owner_id)

    def write_to_xattr(self, file_name):
        """ Write this ACL to an extended attribute """
        if (self.acl_policy is None):
            return
        xml = self.acl_policy.to_xml()
        xattr.set(file_name, ACL_XATTR, xml, namespace=xattr.NS_USER)


###### S3 store #######
def s3_key_to_meta(k):
    meta = {}
    if (k.__dict__.has_key("content_type")):
        meta[CONTENT_TYPE_XATTR] = k.content_type
    for k, v in k.metadata.items():
        meta[META_XATTR_PREFIX + k] = v
    return meta


def meta_to_s3_key(key, meta):
    for k, v in meta.items():
        if (k == CONTENT_TYPE_XATTR):
            key.set_metadata("Content-Type", v)
        elif (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
            k_name = k[len(META_XATTR_PREFIX):]
            key.set_metadata(k_name, v)
        else:
            raise ObsyncPermanentException("can't understand meta entry: %s" % k)


def meta_to_dict(meta):
    result = {}
    for k, v in meta.items():
        if (k == CONTENT_TYPE_XATTR):
            result["Content-Type"] = v
        elif (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
            k_name = k[len(META_XATTR_PREFIX):]
            result[k_name] = v
        else:
            raise ObsyncPermanentException("can't understand meta entry: %s" % k)
    return result


class S3StoreIterator(object):
    """S3Store iterator"""
    def __init__(self, bucket, blrs):
        self.bucket = bucket
        self.blrs = blrs

    def __iter__(self):
        return self

    def next(self):
        # This will raise StopIteration when there are no more objects to
        # iterate on
        key = self.blrs.next()
        # Issue a HEAD request to get content-type and other metadata
        k = self.bucket.get_key(key.name)
        ret = Object(key.name, etag_to_md5(key.etag), key.size, s3_key_to_meta(k))
        return ret


class S3Store(Store):
    def __init__(self, host, bucket_name, object_prefix, create, akey, skey,
                 dry_run, is_secure):
        self.host = host
        self.bucket_name = bucket_name
        self.key_prefix = object_prefix
        self.dry_run = dry_run

        self.conn = S3Connection(calling_format=OrdinaryCallingFormat(),
                                 host=self.host, is_secure=is_secure,
                                 aws_access_key_id=akey, aws_secret_access_key=skey)

        try:
            self.bucket = self.conn.get_bucket(self.bucket_name)
        except S3ResponseError as e:
            if e.status == 301: # Moved Permanently, try subdomain format
                self.conn = S3Connection(
                    calling_format=SubdomainCallingFormat(),
                    host=self.host, is_secure=is_secure,
                    aws_access_key_id=akey,
                    aws_secret_access_key=skey
                )
                try:
                    self.bucket = self.conn.get_bucket(self.bucket_name)
                except S3ResponseError as e:
                    if e.status == 404:
                        self.bucket = None
                    else:
                        raise e
            elif e.status == 404:
                self.bucket = None
            else:
                raise e

        if self.bucket is None: # Not Found
            if create:
                if not self.dry_run:
                    self.bucket = self.conn.create_bucket(self.bucket_name)
            else:
                raise ObsyncPermanentException(
                    "The bucket does not exist and we are not to create it."
                )

    def __str__(self):
        return "s3://" + self.host + "/" + self.bucket_name + "/" + self.key_prefix

    def get_acl(self, obj):
        acl_xml = self.bucket.get_xml_acl(obj.name)
        return LocalAcl.from_xml(obj.name, acl_xml)

    def make_local_copy(self, obj):
        k = Key(self.bucket)
        k.key = obj.name
        temp_file = tempfile.NamedTemporaryFile(prefix='/run/shm/', mode='w+b', delete=False).name
        try:
            k.get_contents_to_filename(temp_file)
        except Exception, e:
            os.unlink(temp_file)
            raise ObsyncTemporaryException(e)
        return LocalCopy(obj.name, temp_file, True)

    def all_objects(self):
        if self.bucket is None:
            return []
        blrs = self.bucket.list(prefix=self.key_prefix)
        return S3StoreIterator(self.bucket, blrs.__iter__())

    def get_object_size(self, obj):
        k = self.bucket.get_key(obj.name)
        if (k is None):
            return 0
        return k.size

    def locate_object(self, obj):
        if self.bucket is None:
            return None
        k = self.bucket.get_key(obj.name)
        if (k is None):
            logger.debug(u"S3Store: cannot locate obj: {}".format(obj.name))
            return None
        else:
            logger.debug(u"S3Store: located obj: {}".format(obj.name))
        return Object(obj.name, etag_to_md5(k.etag), k.size, s3_key_to_meta(k))

    def multipart_upload(self, store, acl, obj):
        pass

    def query_existing_multipart_uploads_in_s3(self, obj):
        multipart_uploads_filter = {'key_marker': obj.name}
        all_multipart_uploads = self.bucket.get_all_multipart_uploads(**multipart_uploads_filter)
        if len(all_multipart_uploads) &gt;= 1:
            logger.debug(u"S3Store: multipart_uploads exists '{}'".format(obj.name))
            existing_parts = []
            mpu = MultiPartUpload(self.bucket)
            mpu.key_name = obj.name
            mpu.bucket_name = self.bucket_name
            mpu.id = all_multipart_uploads[0].id

            all_parts = mpu.get_all_parts()
            for one_parts in all_parts:
                response_part = {
                    'part_number': one_parts.part_number,
                    'etag': one_parts.etag.replace('"', ''),
                    'size': one_parts.size
                }
                existing_parts.append(response_part)
            return {'mpu': mpu, 'parts': existing_parts}

        else:
            return None

    def get_obj_ioctx_md5(self, ioctx):
        if self.dry_run:
            return ''
        m = hashlib.md5()
        m.update(ioctx.read())
        md5 = m.hexdigest()
        ioctx.seek(0)

        return md5

    def upload(self, src, obj):
        if self.dry_run:
            return

        logger.debug(u"S3Store: upload obj '{}'".format(obj.name))

        if obj.size &lt;= MULTIPART_THRESH:
            k = Key(self.bucket)
            k.key = obj.name
            meta_to_s3_key(k, obj.meta)
            ioctx = src.get_obj_ioctx(obj)
            k.set_contents_from_file(ioctx)
        else:
            if obj.size &gt;= BREAKPOINT_THRESHOLD:
                existing_multipart_upload = self.query_existing_multipart_uploads_in_s3(obj)
            else:
                # For small files,just upload them again
                existing_multipart_upload = None

            if existing_multipart_upload is not None:
                logger.info(u"S3Store: uploading file from breakpoint: '{}'".format(obj.name))
                # There some parts in S3,keep uploading ...
                mpu = existing_multipart_upload['mpu']
                try:
                    remaining = obj.size
                    part_num = 0
                    part_size = MULTIPART_THRESH

                    while remaining &gt; 0:
                        current_part_num = part_num + 1
                        offset = part_num * part_size
                        length = min(remaining, part_size)
                        ioctx = src.get_obj_ioctx(obj, offset, length)

                        local_etag = unicode(self.get_obj_ioctx_md5(ioctx))
                        found_part = False
                        for one_part in existing_multipart_upload['parts']:
                            # we'd better check etag.
                            if current_part_num == one_part['part_number'] and \
                                    length == one_part['size'] and \
                                    local_etag == one_part['etag']:
                                found_part = True
                                break
                        if found_part is False:
                            logger.debug(u"S3Store: uploading part: '{}'".format(current_part_num))
                            mpu.upload_part_from_file(ioctx, current_part_num)
                        else:
                            logger.debug(u"S3Store: found part: '{}'".format(current_part_num))

                        remaining -= length
                        part_num += 1

                    logger.info(u"S3Store: Ready to complete_upload: '{}'".format(obj.name))
                    mpu.complete_upload()
                except Exception as e:
                    # Something is wrong.Maybe there are garbage data.Remove them.
                    logger.warning(u"S3Store: Something is wrong.cancel_upload: '{}'".format(obj.name))
                    mpu.cancel_upload()
                    raise e

            else:
                mpu = self.bucket.initiate_multipart_upload(obj.name, metadata=meta_to_dict(obj.meta))
                try:
                    remaining = obj.size
                    part_num = 0
                    part_size = MULTIPART_THRESH

                    while remaining &gt; 0:
                        offset = part_num * part_size
                        length = min(remaining, part_size)
                        ioctx = src.get_obj_ioctx(obj, offset, length)
                        mpu.upload_part_from_file(ioctx, part_num + 1)
                        remaining -= length
                        part_num += 1

                    mpu.complete_upload()
                except Exception as e:
                    # Do NOT cancel for large file.We will use previous parts in future.
                    if obj.size &lt; BREAKPOINT_THRESHOLD:
                        mpu.cancel_upload()
                    raise e

    def set_acl(self, src_acl, obj):
        if src_acl.acl_policy is not None:
            xml = src_acl.acl_policy.to_xml()
            try:
                def fn():
                    self.bucket.set_xml_acl(xml, obj.name)
                do_with_s3_retries(fn)
            except boto.exception.S3ResponseError, e:
                logger.error(
                    "ERROR SETTING ACL on object '{}'\n"
                    "************* ACL: *************\n"
                    "{}\n"
                    "********************************\n"
                    .format(obj.name, str(xml))
                )
                raise ObsyncTemporaryException(e)

    def remove(self, obj):
        if self.dry_run:
            return
        self.bucket.delete_key(obj.name)
        logger.debug("S3Store: removed %s", obj.name)

    def clear(self):
        pass

    def get_obj_ioctx(self, obj, offset=None, length=None):
        k = self.bucket.get_key(obj.name)
        if k is None:
            return None
        ioctx = StringIO()
        headers = None
        if offset is not None and length is not None:
            headers = {
                "Range": "bytes={}-{}".format(offset, offset+length-1)
            }
        k.get_contents_to_file(ioctx, headers)
        ioctx.seek(0)
        return ioctx


# Some S3 servers offer "eventual consistency."
# What this means is that after a change has been made, like the creation of an
# object, it takes some time for this change to become visible to everyone.
# This potentially includes the client making the change.
#
# This means we need to implement a retry mechanism for certain operations.
# For example, setting the ACL on a newly created object may fail with an
# "object not found" error if the object creation hasn't yet become visible to
# us.
def do_with_s3_retries(fn):
    if (os.environ.has_key("DST_CONSISTENCY") and
            os.environ["DST_CONSISTENCY"] == "eventual"):
        sleep_times = [5, 10, 60, -1]
    else:
        sleep_times = [-1]
    for stime in sleep_times:
        try:
            fn()
            return
        except boto.exception.S3ResponseError, e:
            if (stime == -1):
                raise ObsyncTemporaryException(e)
            logger.warning(
                "encountered s3 response error: %s: " \
                    "retrying operation after %d second delay",
                str(e), str(stime)
            )
            time.sleep(stime)


###### Swift store #######
def swift_object_to_meta(obj):
    meta = {}
    if (obj.__dict__.has_key("content_type")):
        meta[CONTENT_TYPE_XATTR] = obj.content_type
    for k, v in obj.metadata.items():
        meta[META_XATTR_PREFIX + k] = v
    return meta


def meta_to_swift_object(obj, meta):
    for k, v in meta.items():
        if (k == CONTENT_TYPE_XATTR):
            obj.metadata["Content-Type"] = v
        elif (k[:len(META_XATTR_PREFIX)] == META_XATTR_PREFIX):
            k_name = k[len(META_XATTR_PREFIX):]
            obj.metadata[k_name] = v
        else:
            raise ObsyncPermanentException("can't understand meta entry: %s" % k)
        obj.sync_metadata()


class SwiftStoreIterator(object):
    """SwiftStore iterator"""
    def __init__(self, container, object_list):
        self.container = container
        self.generator = (o for o in object_list)

    def __iter__(self):
        return self

    def next(self):
        # This will raise StopIteration when there are no more objects to
        # iterate on
        obj = self.generator.next()
        obj = self.container.get_object(obj.name)
        ret = Object(obj.name, etag_to_md5(obj._etag), obj.size, swift_object_to_meta(obj))
        return ret


class SwiftStore(Store):
    def __init__(self, authurl, container_name, object_prefix, create, akey,
                 skey, dry_run, is_secure):
        self.host = authurl
        self.container_name = container_name
        self.object_prefix = object_prefix
        self.dry_run = dry_run

        self.conn = cloudfiles.get_connection(
            username=akey, api_key=skey, authurl=self.host
        )
        try:
            self.container = self.conn.get_container(self.container_name)
        except cloudfiles.errors.NoSuchContainer:
            self.container = None

        if self.container is None:
            if create:
                if not self.dry_run:
                    self.container = self.conn.create_container(
                        self.container_name
                    )
            else:
                raise ObsyncPermanentException(
                    "%s: no such container as %s" % (self.host, self.container_name)
                )

    def __str__(self):
        return "swift://{}/{}/{}".format(
            self.host, self.container_name, self.object_prefix
        )

    def get_acl(self, obj):
        raise NotImplementedError   # We always use --no-preserve-acls right now

    def make_local_copy(self, obj):
        o = self.container.get_object(obj.name)
        temp_file = tempfile.NamedTemporaryFile(mode='w+b', delete=False).name
        try:
            o.save_to_filename(temp_file)
        except Exception, e:
            os.unlink(temp_file)
            raise ObsyncTemporaryException(e)
        return LocalCopy(obj.name, temp_file, True)

    def all_objects(self):
        if self.container is None:
            return []
        object_list = self.container.get_objects(prefix=self.object_prefix)
        return SwiftStoreIterator(self.container, object_list)

    def locate_object(self, obj):
        if self.container is None:
            return None
        try:
            o = self.container.get_object(obj.name)
        except cloudfiles.errors.NoSuchObject:
            return None
        return Object(obj.name, etag_to_md5(o._etag), o.size, swift_object_to_meta(o))

    def upload(self, src, obj):
        if self.dry_run:
            return

        logger.debug(u"SwiftStore: upload obj '{}'".format(obj.name))

        o = self.container.create_object(obj.name)

        if obj.size &lt;= MULTIPART_THRESH:
            ioctx = src.get_obj_ioctx(obj)
            o.write(ioctx)
            meta_to_swift_object(o, obj.meta)
        else:
            raise NotImplementedError("obj size too large. not supported")

    def set_acl(self, src_acl, obj):
        if src_acl.acl_policy is not None:
            #FIXME: no acls for swift yet
            pass

    def remove(self, obj):
        if self.dry_run:
            return
        self.container.delete_object(obj.name)
        logger.debug("SwiftStore: removed %s", obj.name)

    def clear(self):
        pass

    def get_obj_ioctx(self, obj, offset=None, length=None):
        try:
            o = self.container.get_object(obj.name)
            ioctx = StringIO()
            if offset is None or length is None:
                o.read(buffer=ioctx)
            else:
                o.read(offset=offset, size=length, buffer=ioctx)
            ioctx.seek(0)
            return ioctx
        except cloudfiles.errors.NoSuchObject:
            return None


###### FileStore #######
class FileStoreIterator(object):
    """FileStore iterator"""
    def __init__(self, base, follow_symlinks=False):
        self.base = base
        self.generator = os.walk(base, followlinks=follow_symlinks)
        self.path = ""
        self.files = []

    def __iter__(self):
        return self

    def next(self):
        while True:
            if (len(self.files) == 0):
                self.path, dirs, self.files = self.generator.next()
                self.files.extend(dirs)
                continue
            path = os.path.join(self.path, self.files[0])
            self.files = self.files[1:]
            # Ignore non-files when iterating.
            if os.path.isfile(path):
                obj_name = local_name_to_s3_name(path[len(self.base)+1:])
                return Object.from_file(obj_name, path)
            elif os.path.isdir(path):
                return Object.from_folder(path[len(self.base)+1:] + "/", path)


class FileStore(Store):
    def __init__(self, url, create, dry_run, follow_symlinks=False):
        # Parse the file url
        self.base = url
        self.dry_run = dry_run
        self.follow_symlinks = follow_symlinks
        if (self.base[-1:] == '/'):
            self.base = self.base[:-1]
        if create:
            if not self.dry_run:
                mkdir_p(self.base)
        elif not os.path.isdir(self.base):
            raise ObsyncPermanentException("NonexistentStore")

        if os.path.isdir(self.base):
            test_xattr_support(self.base)

    def __str__(self):
        return "file://" + self.base

    def get_acl(self, obj):
        try:
            xml = xattr.get(obj.local_path(self.base), ACL_XATTR,
                            namespace=xattr.NS_USER)
        except IOError, e:
            #print "failed to get XML ACL from %s" % obj.local_name()
            if e.errno == 61:
                return LocalAcl.get_empty(obj.name)
            raise ObsyncPermanentException(e)
        return LocalAcl.from_xml(obj.name, xml)

    def make_local_copy(self, obj):
        return LocalCopy(obj.name, obj.local_path(self.base), False)

    def all_objects(self):
        if os.path.isdir(self.base):
            return FileStoreIterator(self.base, self.follow_symlinks)
        else:
            return []

    def locate_object(self, obj):
        path = obj.local_path(self.base)
        if obj.is_folder:
            found = os.path.isdir(path)
            if found:
                return Object.from_folder(obj.name, path)
            else:
                return None
        else:
            found = os.path.isfile(path)
            logger.debug("FileStore::locate_object: %s object '%s'",
                         "found" if found else "did not find", obj.name)
            if (not found):
                return None
            return Object.from_file(obj.name, path)

    def upload(self, src, obj):
        if self.dry_run:
            return

        logger.debug(u"FileStore: upload obj '{}'".format(obj.name))

        lname = obj.local_name()
        d = os.path.join(self.base, lname).encode("UTF-8")
        mkdir_p(os.path.dirname(d))

        if obj.is_folder:
            d = os.path.join(self.base, obj.name).encode("UTF-8")
            mkdir_p(d)
        else:
            if obj.size &lt;= MULTIPART_THRESH:
                ioctx = src.get_obj_ioctx(obj)
                with open(d, "wb") as f:
                    f.write(ioctx.read())
            else:
                try:
                    break_point = 0
                    offset = 0
                    if os.path.isfile(d):
                        try:
                            value = xattr.get(d, BREAK_POINT_META, namespace=xattr.NS_USER)
                            break_point = int(value)
                            logger.info('break point for {} is {}'.format(d, break_point))
                        except Exception as e:
                            logger.error(u"failed to get break_point xatr for {} {}".format(d,str(3)))
                            pass

                    if break_point % MULTIPART_THRESH != 0 or break_point &gt; obj.size:
                        logger.info('break point for {} is {}'.format(d, break_point))
                        break_point = 0;

                    remaining = obj.size - break_point
                    part_num = break_point / MULTIPART_THRESH
                    part_size = MULTIPART_THRESH

                    seek_first = False
                    if break_point != 0:
                        seek_first = True
                        open_option = "r+b"
                    else:
                        open_option = "wb"

                    with open(d, open_option) as f:
                        while remaining &gt; 0:
                            offset = part_num * part_size
                            length = min(remaining, part_size)
                            ioctx = src.get_obj_ioctx(obj, offset, length)
                            if seek_first:
                                f.seek(offset)
                                seek_first = False
                            f.write(ioctx.read())
                            remaining -= length
                            part_num += 1

                    if break_point != 0:
                        f = open(d, 'r')
                        try:
                            md5 = get_md5(f)
                        finally:
                            f.close()
                        if md5 != obj.md5:
                            logger.info("file md5 {} is not equal to {}".format(md5, obj.md5))
                            remaining = break_point
                            part_num = 0
                            part_size = MULTIPART_THRESH

                            with open(d, open_option) as f:
                                while remaining &gt; 0:
                                    offset = part_num * part_size
                                    length = min(remaining, part_size)
                                    ioctx = src.get_obj_ioctx(obj, offset, length)
                                    f.write(ioctx.read())
                                    remaining -= length
                                    part_num += 1
                    try:
                        xattr.remove(d, BREAK_POINT_META, namespace=xattr.NS_USER)
                    except Exception as e:
                        pass

                except Exception as e:
                    if break_point == 0 and offset &gt;= 10* MULTIPART_THRESH:
                        xattr.set(d, BREAK_POINT_META, str(int(offset)),namespace=xattr.NS_USER)
                        logger.error('failed to upload ,set break point to {}'.format(offset))
                    raise e

        # Store metadata in extended attributes
        file_set_md5(d, obj.md5)
        for k, v in obj.meta.items():
            xattr.set(d, k, v, namespace=xattr.NS_USER)

    def set_acl(self, src_acl, obj):
        if not obj.is_folder:
            lname = obj.local_name()
            d = os.path.join(self.base, lname).encode("UTF-8")
            mkdir_p(os.path.dirname(d))
            src_acl.write_to_xattr(d)

    def remove(self, obj):
        if self.dry_run:
            return
        path = os.path.join(self.base, obj.name.encode("UTF-8"))
        try:
            if os.path.isfile(path):
                os.unlink(path)
            if os.path.isdir(path):
                shutil.rmtree(path)
        except Exception:
            logger.warning("FileStore: remove %s failed", obj.name)

        logger.debug("FileStore: removed %s", obj.name)

    def clear(self):
        for entry in os.listdir(self.base):
            path = os.path.join(self.base, entry)
            if os.path.isfile(path):
                os.unlink(path)
            elif os.path.isdir(path):
                shutil.rmtree(path)

    def get_obj_ioctx(self, obj, offset=None, length=None):
        if obj.is_folder:
            return StringIO("")
        else:
            path = obj.local_path(self.base)
            found = os.path.isfile(path)
            if not found:
                return None
            with open(path, "rb") as f:
                if offset is not None:
                    f.seek(offset)
                if length is not None:
                    return StringIO(f.read(length))
                else:
                    return StringIO(f.read())

</pre></td></tr></tbody></table></code></pre></div></div>


                <hr style="visibility: hidden;">
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2020/12/29/upgrade_testlink_from_1.9.10_to_1.9.20/" data-toggle="tooltip" data-placement="top" title="CentOS6.5 testlink-1.9.10升级到1.9.20">
                        Previous<br>
                        <span>CentOS6.5 testlink-1.9.10升级到1.9.20</span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2021/02/09/config_QCT_network_config/" data-toggle="tooltip" data-placement="top" title="Config QCT switch port network">
                        Next<br>
                        <span>Config QCT switch port network</span>
                        </a>
                    </li>
                    
                </ul>
                <hr style="visibility: hidden;">

                
                <!-- disqus 评论框 start -->
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                <!-- disqus 评论框 end -->
                

                
            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                


<section>
    
        <hr class="hidden-sm hidden-xs">
    
    <h5><a href="/archive/">FEATURED TAGS</a></h5>
    <div class="tags">
        
        
        
        </a>
        
        
                <a data-sort="0189" 
                    href="/archive/?tag=oracle"
                    title="oracle"
                    rel="77">oracle</a>
        
                <a data-sort="0197" 
                    href="/archive/?tag=Linux"
                    title="Linux"
                    rel="69">Linux</a>
        
                <a data-sort="0240" 
                    href="/archive/?tag=shell"
                    title="shell"
                    rel="26">shell</a>
        
                <a data-sort="0244" 
                    href="/archive/?tag=Automation"
                    title="Automation"
                    rel="22">Automation</a>
        
                <a data-sort="0248" 
                    href="/archive/?tag=ceph"
                    title="ceph"
                    rel="18">ceph</a>
        
                <a data-sort="0250" 
                    href="/archive/?tag=python"
                    title="python"
                    rel="16">python</a>
        
                <a data-sort="0260" 
                    href="/archive/?tag=Jenkins"
                    title="Jenkins"
                    rel="6">Jenkins</a>
        
                <a data-sort="0261" 
                    href="/archive/?tag=S3"
                    title="S3"
                    rel="5">S3</a>
        
                <a data-sort="0261" 
                    href="/archive/?tag=nose"
                    title="nose"
                    rel="5">nose</a>
        
                <a data-sort="0262" 
                    href="/archive/?tag=JBOD"
                    title="JBOD"
                    rel="4">JBOD</a>
        
                <a data-sort="0262" 
                    href="/archive/?tag=Megacli"
                    title="Megacli"
                    rel="4">Megacli</a>
        
                <a data-sort="0262" 
                    href="/archive/?tag=awk"
                    title="awk"
                    rel="4">awk</a>
        
                <a data-sort="0262" 
                    href="/archive/?tag=performance"
                    title="performance"
                    rel="4">performance</a>
        
                <a data-sort="0262" 
                    href="/archive/?tag=perl"
                    title="perl"
                    rel="4">perl</a>
        
                <a data-sort="0263" 
                    href="/archive/?tag=ESXi"
                    title="ESXi"
                    rel="3">ESXi</a>
        
                <a data-sort="0263" 
                    href="/archive/?tag=cosbench"
                    title="cosbench"
                    rel="3">cosbench</a>
        
                <a data-sort="0263" 
                    href="/archive/?tag=iSCSI"
                    title="iSCSI"
                    rel="3">iSCSI</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=%E8%99%9A%E6%8B%9F%E5%8C%96"
                    title="虚拟化"
                    rel="2">虚拟化</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=APP"
                    title="APP"
                    rel="2">APP</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=Disk"
                    title="Disk"
                    rel="2">Disk</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=PVE"
                    title="PVE"
                    rel="2">PVE</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=RAID"
                    title="RAID"
                    rel="2">RAID</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=bzip2"
                    title="bzip2"
                    rel="2">bzip2</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=mds"
                    title="mds"
                    rel="2">mds</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=netconsole"
                    title="netconsole"
                    rel="2">netconsole</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=network"
                    title="network"
                    rel="2">network</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=pbzip2"
                    title="pbzip2"
                    rel="2">pbzip2</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=pytest"
                    title="pytest"
                    rel="2">pytest</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=sed"
                    title="sed"
                    rel="2">sed</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=ssh"
                    title="ssh"
                    rel="2">ssh</a>
        
                <a data-sort="0264" 
                    href="/archive/?tag=tr"
                    title="tr"
                    rel="2">tr
    </div>
</section>


                <!-- Friends Blog -->
                
<hr>
<h5>FRIENDS</h5>
<ul class="list-inline">
  
  <li><a href=""></a></li>
  
  <li><a href="http://bean-li.github.io/">Bean Li</a></li>
  
  <li><a href="https://zphj1987.com/">武汉-磨渣</a></li>
  
</ul>

            </div>
        </div>
    </div>
</article>

<!-- add support for mathjax by voleking-->






<!-- disqus 公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "Gavin";
    var disqus_identifier = "/2021/01/10/Demo_for_trasferring_large_file";
    var disqus_url = "http://0.0.0.0:4000/2021/01/10/Demo_for_trasferring_large_file/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus 公共JS代码 end -->




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'right',
          // icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- SNS Link -->
                


<ul class="list-inline text-center">


  
  
  
  
  
  
  
</ul>

                <p class="copyright text-muted">
                    Copyright &copy; Gavin Blog 2023
                    <br>
                    Powered by <a href="https://gavin-wang-note.github.io/index.html">Gavin Blog</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=gavinpro&repo=gavin.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/gavin-blog.min.js "></script>

<!-- Service Worker -->

<script src="/js/snackbar.js "></script>
<script src="/js/sw-registration.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Gavinblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->





<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->

<script>
    // dynamic User by Gavin
    var _gaId = 'UA-49627206-1';
    var _gaDomain = '';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>



<!-- Baidu Tongji -->



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog (selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector),a,n,t,l,i,c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#"+$(this).prop('id');
            t = $(this).text();
            c = $('<a href="'+i+'" rel="nofollow">'+t+'</a>');
            l = $('<li class="'+n+'_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function(e){
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Gavin to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->



</body>

</html>
